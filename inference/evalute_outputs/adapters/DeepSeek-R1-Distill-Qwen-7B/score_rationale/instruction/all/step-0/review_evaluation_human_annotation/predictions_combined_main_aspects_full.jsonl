{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the dataset, noting that it is artificially created and may contain noise, such as misinformation or outofcontext images. The reviewer suggests that the authors should provide more analysis on the dataset\"s quality and the amount of noise it might contain. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the dataset and the potential issues with its creation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the concern about the dataset\"s quality, suggesting that the authors should provide more analysis on the dataset\"s noise and potential issues. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point raises a concern about the dataset\"s potential noise, specifically questioning the priseness of the collected tweets and the presence of misinformation or outofcontext images. The reviewer suggests that the authors should provide more analysis on the dataset\"s quality and noise. However, the comment lacks specific examples or references to support the claim about the dataset\"s potential issues. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the paper, noting that it is artificially created and may contain noise, such as misinformation or outofcontext images. The reviewer suggests that the authors should provide more analysis on the dataset\"s quality and the amount of noise it might contain. This feedback is clear and actionable, as it highlights a specific area for improvement and encourages the authors to enhance the robustness of their dataset. However, the comment could be more helpful if it provided examples or guidance on how to conduct this analysis. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not explore the theoretical properties of the proposed algorithm, specifically mentioning the convergence properties. However, it does not provide explicit guidance on what specific aspects of the theory should be explored or how the convergence properties should be demonstrated. The action is implicit, as the authors can infer that they need to include a discussion on the theoretical properties and convergence of the algorithm, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of exploration into the theoretical properties of the proposed algorithm, specifically mentioning the convergence properties. However, it does not specify which part of the paper should be revised or how the theoretical properties should be addressed. The authors can infer that this relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. The comment is specific in identifying the need for theoretical exploration but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not explore the theoretical properties of the proposed algorithm, specifically mentioning the convergence properties. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper does not explore the theoretical properties of the proposed algorithm, particularly the convergence properties. This feedback is clear and actionable, as it directs the authors to include a discussion on the theoretical aspects of their algorithm, which is crucial for a comprehensive understanding of the work. However, the comment could be more helpful if it provided suggestions on how to approach this theoretical exploration or examples of relevant theories that could be applied. Despite this, the feedback is 4 as it highlights a significant gap in the paper that the authors should address to enhance the quality and depth of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically questioning why the authors did not consider the \"and\" operator or elementwise max, which correspond to the ideas of union and intersection. While the comment implies that the authors should consider these operators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these operators. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, \"261&272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of operators used, particularly the \"and\" operator or elementwise max, and why they were not considered. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically the \"and\" operator or elementwise max, and why they were not considered. The reviewer suggests that these operators correspond to the ideas of union and intersection, which are typically associated with the \"or\" operator and elementwise min. The comment implies that the authors should consider these operators, but it does not provide specific reasoning or evidence to support why these operators were not chosen. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the reasoning behind the choice of operators. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically the \"and\" operator or elementwise max, which correspond to the ideas of union and intersection. The reviewer questions why these operators were not considered, implying that the choice of operators might not be optimal. This feedback is 3 as it identifies a potential area for improvement in the paper\"s methodology or analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or why the chosen operators might be better. To be more helpful, the comment could provide examples or reasoning for why the chosen operators are preferable. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the description of HIERENC, suggesting that the approach of averaging the representations of all possible entity instantiations may introduce noise. However, it does not provide explicit guidance on how the authors should address this issue or suggest a specific alternative approach. The comment implies that the authors should clarify the description or consider a different method, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear explanation of the issue with the description of HIERENC, detailing the concern about averaging representations of all possible entity instantiations and suggesting that this approach may introduce noise. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging the representations of all possible entity instantiations may introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is correct, which would likely introduce noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the potential issues based on the provided reasoning, which limits the verifiability score. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of HIERENC, suggesting that the approach of averaging the representations of all possible entity instantiations may introduce noise. This feedback is 3 as it highlights a specific area of concern that the authors need to clarify or address. However, the comment lacks detailed guidance or suggestions on how the authors might improve the description or mitigate the noise issue. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should explain their selection process, it does not provide explicit instructions or concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and possibly discuss the impact of their selection on performance estimation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the rationale and its impact on performance estimation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the rationale behind selecting only 10 answers from all correct answers and its potential impact on performance estimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. The comment is 3 as it prompts the authors to consider the implications of their selection process, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should revise their description to clarify the data selection process, specifically mentioning Li et al. (2019a) and providing an example of how to do so. The comment is explicit in its request for a revision and provides concrete guidance on how to improve the clarity and precision of the description. The authors know exactly what needs to be done to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the potential confusion in the description of the data selection process, suggesting that the authors should mention Li et al. (2019a) earlier to clarify the data source. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors have misrepresented the data selection process, suggesting that the data used is a subset of Li et al. (2019a)\"s dataset. The comment provides a specific example of lines in the paper that indicate this issue, making the claim 4. However, it lacks detailed reasoning or references to fully substantiate the claim, which could be improved by providing more context or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of the data selection process in the paper. It points out that the authors seem to suggest that they selected sentences from raw data, but later lines indicate that the data already contains syntactic information. The reviewer suggests that the description could be revised to clarify this point, specifically mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific suggestion for improvement that could enhance the clarity and precision of their manuscript. However, the comment could be more helpful if it included additional guidance on how to revise the description or examples of how to present the information more effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and whether it includes user waiting time. While it identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the purpose of the average duration and possibly provide additional context or explanation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the purpose of the average duration reported in the table and whether it includes user waiting time. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the purpose of the average duration reported in Table 1 and whether it includes user waiting time. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the purpose of the average duration reported in Table 1 and whether it includes user waiting time. This is a clear and actionable piece of feedback that highlights a gap in the explanation of the data presented in the paper. By pointing out this issue, the comment provides the authors with a concrete direction to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of how to clarify the purpose of the average duration. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action, as it provides a clear and specific request for additional information. The authors know exactly what needs to be addressed and how to improve the clarity of their table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what information is missing and how it should be presented. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for clarification in Table 4, namely the splits used for obtaining the ATIS numbers. This feedback is actionable, as it provides a clear direction for the authors to improve the clarity and transparency of their results. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment provides some value but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the phrase \"on par or better\" should be corrected due to a cognitive bias in NLP research. However, it does not provide specific guidance on how to correct the wording or what specific changes should be made. The comment implies that the authors should address the issue, but it lacks concrete instructions or examples of how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 791, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential cognitive bias in the wording used (\"on par or better\") and suggests that this should be corrected. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the phrase \"on par or better\" should be corrected due to a cognitive bias in NLP research. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the bias or how to address it. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording used in the paper, specifically the phrase \"on par or better\" at line 791. It points out a cognitive bias among NLP researchers that may lead to misinterpretation of results, suggesting that the phrase should be corrected. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to correct the wording or what specific changes should be made. The feedback is 3 as it directs the authors to a potential area of improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results in Table 3, specifically regarding the comparison of performance metrics between different methods. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these questions or what specific aspects they should consider when interpreting the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the interpretation of results, particularly regarding the comparison of performance metrics between different methods. The comment specifies what needs to be addressed in terms of understanding the results, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions about the interpretation of results in Table 3, specifically regarding the comparison of performance metrics between different methods. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of performance metrics between different methods. While it identifies areas where clarification is needed, it does not provide specific suggestions or guidance on how the authors might address these questions or improve the interpretation of their results. The comment lacks actionable feedback, making it 3 as it highlights potential areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between \"accuracy\" and \"standard deviation,\" while others do not. This inconsistency affects the \"beauty\" of the table, which is a subjective measure of clarity and presentation. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest a specific correction. The action is implicit, as the authors can infer that they need to standardize the presentation of these items, but the comment lacks concrete details on how to achieve this standardization. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between \"accuracy\" and \"standard deviation\" in some items, which affects the \"beauty\" of the table. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is inconsistency in the presentation of data in Table 2 and Table 3, specifically regarding the spacing between \"accuracy\" and \"standard deviation.\" However, the comment does not provide any supporting evidence, examples, or references to justify why this inconsistency affects the \"beauty\" of the table. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of data in Table 2 and Table 3, noting inconsistencies in the spacing between \"accuracy\" and \"standard deviation.\" This observation is clear and actionable, as it highlights a potential source of confusion or inconsistency in the table\"s appearance. However, the comment does not provide further guidance on how the authors might address this issue or suggest ways to improve the clarity of the table. While it points out a problem, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a missing antecedent for the phrase \"both tasks\" and provides specific guidance on how to check the references for format, including capitalization and bibliographic details. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The comment also suggests specific references to consider, such as Grice, Sorower et al and the verbnet reference, which adds further detail to the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"both tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the missing antecedent and the need to check references for format, including capitalization and bibliographic details. This provides the authors with a clear understanding of what needs to be corrected or improved. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references should be checked for format, specifically mentioning capitalization and bibliographic details. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues that need to be addressed. The lack of detailed guidance or examples renders the claim 3, as the authors would need to infer the specific issues from the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, namely the missing antecedent for the phrase \"both tasks.\" It also provides clear guidance on how to check the references for format, including capitalization and bibliographic details, referencing specific works like Grice, Sorower et al and the verbnet reference. This feedback is actionable and provides the authors with a clear direction for improving the accuracy and professionalism of their references. However, the comment could be more helpful if it included additional suggestions on how to ensure the references are correctly formatted or if it provided examples of how to format them. Overall, the comment is 4 as it addresses a specific issue and offers actionable advice, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of novelty in the paper, specifically noting that adversarial attacks on text have been previously explored in many NLP and imagetext models. It mentions that the paper only applies similar ideas to videotext models, implying that the contribution is not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty of their work or what specific changes could be made to make their contribution more original. As a result, the comment is 1, as it does not offer any actionable steps for the authors to improve their draft.", "grounding_specificity_rationale": "The comment highlights a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been previously explored in many NLP and imagetext models. It also notes that the paper only applies similar ideas to videotext models. However, the comment does not specify which part of the paper discusses these related works or where the authors might address the novelty issue. This makes it difficult for the authors to pinpoint the exact sections that need revision or improvement. While the comment provides some context, it lacks full grounding and specificity, as it does not clearly identify the parts of the paper being addressed or what specific changes are needed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically noting that adversarial attacks on text have been previously explored in many NLP and imagetext models. It mentions that the paper only applies similar ideas to videotext models, implying that the contribution is not novel. However, the comment does not provide specific examples or references to support the claim that these attacks have been previously explored. Without detailed evidence or references, the claim is 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been previously explored in many NLP and imagetext models. It mentions that the paper only applies similar ideas to videotext models, implying that the contribution is not novel. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or address this issue. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the explanations for features in Section 3.2 are somewhat intertwined and confusing. It suggests that the section would be more coherently organized if it were divided into separate paragraphs dedicated to each of the lexical features and sentencelevel features. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the organization of the section. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: organizing the explanations for features into separate paragraphs dedicated to lexical features and sentencelevel features. This guidance is actionable and provides a concrete direction for the authors to follow, making the comment 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are somewhat intertwined and confusing. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the explanations for features in Section 3.2, noting that they are somewhat intertwined and confusing. It provides a clear suggestion for improvement by recommending that the section be more coherently organized with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is actionable and offers a concrete way for the authors to enhance the clarity and organization of their paper, making it 4. However, it could be more helpful if it included additional suggestions on how to achieve this organization or examples of how to structure the paragraphs. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the amount of space dedicated to the assumptions and experimental results in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue, such as suggesting ways to condense the content or reorganize the paper. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of dedicating a whole section and experimental results to assumptions, which is a specific aspect of the paper. However, it does not explicitly mention which section or part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the concern about the amount of space dedicated to assumptions and experimental results, providing clear guidance on what the authors might consider problematic. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the amount of space dedicated to assumptions and experimental results, suggesting that it is excessive. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the amount of space dedicated to assumptions and experimental results in the paper. It acknowledges the effort put into fleshing out the assumptions but points out that devoting a whole section and experimental results to this aspect may be excessive. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending ways to condense the content or reorganize the paper. While it highlights a potential inefficiency, the feedback is incomplete and does not provide actionable advice, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an ablation study is needed to demonstrate the importance of the postprocessing steps proposed in the paper. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that an ablation study is necessary but are not provided with specific guidance on how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients and the proposed postprocessing steps to filter out \"falsepositive\" neurons. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that an ablation study is needed to demonstrate the importance of these postprocessing steps, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of integrated gradients for measuring attribution has been studied in existing papers, and that the paper proposes postprocessing steps to filter out \"falsepositive\" neurons. However, it does not provide specific references to these existing studies or detailed examples of how the postprocessing steps have been studied. The comment suggests that an ablation study is needed to demonstrate the importance of these steps, but without further elaboration or evidence, the claim remains 3. The authors would need to conduct additional research to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of demonstration of the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. It suggests that an ablation study could be conducted to address this gap. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to design or execute the ablation study. This limits the comment\"s helpfulness, as the authors are left to infer the necessary steps without explicit instructions. Therefore, the comment is 3, as it points out a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to identify an antecedent when the prediction is a pronoun, suggesting that the authors\" proposed method of matching the head of noun phrases may not be sufficient. While the comment implies that the authors should address this issue, it does not provide explicit guidance or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or improve their method for handling such cases. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the method used to identify an antecedent when the prediction is a pronoun, specifically mentioning the authors\" proposed method of matching the head of noun phrases. This provides some level of grounding as it relates to a specific part of the paper, but it does not explicitly mention which section or figure this issue pertains to, making it weakly grounded. The comment is specific in identifying the issue with the method and the lack of clarity when the head word is not a pronoun. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the method used to identify an antecedent when the prediction is a pronoun, specifically mentioning the authors\" proposed method of matching the head of noun phrases. However, it does not provide any supporting evidence, reasoning, or references to justify why this method might be insufficient or how it could be improved. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the method used to identify an antecedent when the prediction is a pronoun, pointing out a potential issue with the authors\" proposed method of matching the head of noun phrases. This feedback highlights a gap in the methodology and suggests that the authors need to address this issue to improve their approach. However, the comment does not provide detailed guidance or suggestions on how to resolve this problem or what specific improvements could be made. While it identifies a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the comparison between the proposed models and models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and questions whether this is sufficiently described. The comment implies that the authors should include more baselines based on related work to strengthen the paper. While the action is implicit, it is concrete in terms of suggesting the inclusion of additional baselines. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the comparison between the proposed models and models that only consider different senses but not sememes, specifically mentioning the MST baseline as an example. This provides some grounding as the authors can infer that the comment relates to the section discussing model comparisons. However, the comment does not explicitly mention which part of the paper this comparison is discussed, making it weakly grounded. The comment is specific in suggesting the inclusion of more baselines based on related work to strengthen the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the comparison between the proposed models and models that only consider different senses but not sememes. It questions whether the MST baseline is an example of such a model and suggests that the paper lacks sufficient description of this aspect. The comment implies that the paper would be stronger with more baselines based on related work. However, the claim is not fully supported by specific examples or references to the MST baseline or other relevant baselines. The reasoning is somewhat vague, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison between the proposed models and models that only consider different senses but not sememes. It questions whether the MST baseline is an example of such a model and suggests that the paper lacks sufficient description of this aspect. The comment also recommends including more baselines based on related work to strengthen the paper. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by expanding the comparison and baselines. However, it could be more helpful if it included examples of relevant baselines or provided more detailed guidance on how to incorporate them. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of inconsistency between evaluating with gold answers and human evaluation. However, it does not explicitly instruct the authors to make this change or provide specific guidance on how to incorporate the example. The action is implicit and somewhat vague, as the authors can infer that they need to include an example of inconsistency, but they may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an improvement by providing an example of inconsistency between evaluating with gold answers and human evaluation. The comment specifies what needs to be addressed, namely the example of inconsistency, which helps the authors understand the issue and how to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract could be improved by providing an example of inconsistency between evaluating with gold answers and human evaluation. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue effectively. The lack of concrete examples or references to similar inconsistencies makes the claim 3, as it highlights a potential area for improvement but lacks the necessary details to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a potential improvement in the abstract by suggesting that it could be made more intriguing by providing an example of inconsistency between evaluating with gold answers and human evaluation. This feedback is 3 as it highlights a specific area for enhancement, which could help the authors make their abstract more compelling. However, the comment lacks depth and does not provide detailed guidance on how to incorporate the example or what specific inconsistencies should be highlighted. While it offers a direction for improvement, it does not fully support the authors in executing the suggestion, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect or improve the clarity of their explanation. The comment lacks specific instructions or concrete steps for the authors to take, leaving them uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the selection of frame similarity factors and attributes similarity factors, which suggests that it is relevant to the methodology or results sections of the paper. However, it does not specify which part of the paper these factors are discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the selection process, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any supporting evidence, reasoning, or examples to justify why this lack of clarity is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. This is a clear and actionable piece of feedback that can help the authors clarify their methodology and improve the transparency of their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. As it stands, the comment is 3, as it highlights a critical area for improvement but lacks depth and guidance for the authors to fully address the concern."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include some discussions on the convergence of the proposed joint learning process, specifically mentioning the need to explain how stable points in probabilistic metric space are obtained. This feedback provides a clear and explicit action for the authors to take, which is to add these discussions. However, it does not provide specific guidance on what aspects of convergence or stable points should be addressed, leaving some room for interpretation. The action is concrete but could be more detailed, making it 4.", "grounding_specificity_rationale": "The comment suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically mentioning the need to explain how stable points in probabilistic metric space are obtained. This feedback is specific in its request for additional information to help readers understand the methodology. However, it does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically mentioning the need to explain how stable points in probabilistic metric space are obtained. This claim is 3 as it highlights a potential gap in the paper\"s explanation of the methodology. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Additional details or evidence would be necessary for the claim to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include discussions on the convergence of the proposed joint learning process, particularly focusing on how stable points in probabilistic metric space are obtained. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s clarity and comprehensibility. By addressing this point, the authors can help readers better understand the methodology and its implications. However, the comment could be more helpful if it offered specific guidance on how to discuss convergence or stable points. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests discussing the results for the task of inferring knowledge on objects and including results for model (B). Additionally, it advises using the same terminology for the model in Tables 1 and 2. The comment also questions the mention of \"latent in verbs\" regarding objects, implying that this should be addressed. These suggestions are clear and provide concrete steps for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections (681 and 778) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, including discussing the results for the task of inferring knowledge on objects, including results for model (B), and using consistent terminology for the model in Tables 1 and 2. Additionally, it questions the mention of \"latent in verbs\" regarding objects, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: one asking for discussion of results for a specific task and inclusion of results for model (B), and another questioning the mention of \"latent in verbs\" regarding objects. The first part is a request for clarification and does not contain a subjective claim. The second part is a question seeking clarification, which also does not constitute a claim. Therefore, the comment is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct areas. First, it suggests discussing the results for the task of inferring knowledge on objects and including results for model (B), which could enhance the comprehensiveness of the paper. Second, it questions the mention of \"latent in verbs\" regarding objects, implying that this should be addressed. These suggestions are clear and provide the authors with concrete steps to improve their draft. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these suggestions or if it provided examples of how to present the results. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential error in the wording of a sentence in the paper, suggesting that it should be corrected to reflect a bidirectional encoder instead of a single vector. While the comment identifies a specific issue, it does not provide explicit guidance on how to correct the sentence or suggest alternative phrasing. The action is implicit, as the authors can infer that they need to revise the sentence, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence in the paper, \"We train a GRU that encodes a source sentence into a single vector,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the wording of the sentence and suggests a correction, indicating that the sentence should refer to a bidirectional encoder instead of a single vector. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct, suggesting that it should refer to a bidirectional encoder instead of a single vector. The reviewer provides a specific example from Figure 2 to support this claim, which adds a layer of verifiability. However, the comment could be strengthened by explaining why the bidirectional encoder is more appropriate in this context or providing additional references to support the claim. Overall, the comment is 4, as it provides a clear rationale and an example, but it could benefit from more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific error in the wording of a sentence in the paper, pointing out that it should refer to a bidirectional encoder instead of a single vector. This feedback is clear and actionable, as it directs the authors to correct the sentence to improve the accuracy of their description. By addressing this issue, the authors can enhance the clarity and correctness of their paper. However, the comment could be more helpful if it provided additional context or explanation on why the bidirectional encoder is more appropriate in this context. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment implies that the authors should add these baselines, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to implement these additional baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. However, the comment lacks specific reasoning or evidence to support why character embeddings would be a meaningful addition or how they would enhance the paper\"s contribution. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment acknowledges that the paper is a straightforward extension of existing retrofitting work, which is a neutral observation. It suggests that including additional baselines, such as character embeddings, could provide a more comprehensive comparison. While the comment identifies a potential area for improvement, it lacks specificity and does not offer detailed guidance on how to implement these additional baselines or why they would be beneficial. The feedback is 3 as it prompts the authors to consider expanding their work, but it could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas where the baseline models are weak. It suggests that the authors should compare their models to Campos et al. (2020) and other domain adaptation methods cited in Section 8. Additionally, it provides a minor correction to a sentence. The comment is explicit in its suggestions, specifying which comparisons should be made and offering a concrete correction. This provides clear guidance for the authors to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the baseline models and the sentence correction, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of comparison to Campos et al. (2020) and other domain adaptation methods, and provides a concrete correction to a sentence. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests specific comparisons to Campos et al. (2020) and other domain adaptation methods. However, the comment lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. The mention of a sentence correction is a factual statement without any supporting context or explanation. As a result, the claim is 3, as it provides a direction for improvement but lacks sufficient justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the baseline models used in the paper. It points out the lack of comparison to Campos et al. (2020), which also uses feedback in QA tasks, and suggests that the authors should include such a comparison. Additionally, it mentions the absence of comparisons with other domain adaptation methods cited in Section 8. The comment also provides a minor correction to a sentence, which is a small but actionable piece of feedback. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to conduct these comparisons or by providing more detailed guidance on the sentence correction. Overall, the feedback is 4 as it directs the authors to specific areas for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, as it provides a specific change to make. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the potential use of \"Exact Match ratio\" as the yaxis label. This provides clear guidance on what aspect of the figure needs attention. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change to the yaxis label in Figure 5, specifically recommending the use of \"Exact Match ratio\" instead of \"Exact Match ratio\" directly. This is a factual suggestion based on the current label used in the figure. The comment does not express an opinion, judgment, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending a change to the yaxis label. It clearly identifies a potential issue with the current label and offers a direct correction, which is valuable for the authors to enhance the accuracy and readability of their paper. This feedback is precise and constructive, making it 5 for the authors to address the issue effectively."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the lack of description regarding the societal biases in the knowledge bases inserted into the study. It also questions the example of Figure mentioned in the comments. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve the clarity of their description. The feedback is vague and lacks concrete steps for the authors to follow, making it difficult for them to know what specific actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the lack of description regarding societal biases in the knowledge bases inserted into the study and questions the example of Figure mentioned in the comments. However, it does not specify which part of the paper these concerns pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the lack of description regarding societal biases in the knowledge bases inserted into the study and questions the example of Figure mentioned in the comments. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of supporting evidence or references renders the claim 1, as the authors would need to infer the issues without clear justification. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises concerns about the lack of description regarding societal biases in the knowledge bases inserted into the study and questions the example of Figure mentioned in the comments. While it identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their description. The feedback is 3 as it highlights areas for improvement, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it is easier to demonstrate that something (e.g., attention in sequencetosequence MTL) is not working, but the value lies in identifying the reasons for failure and proposing changes to the attention mechanism to make it work. However, the comment does not provide explicit guidance or concrete steps on how the authors should approach this task. It lacks specific instructions or examples on how to analyze the failure or what changes to make to the attention mechanism. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique about the approach of demonstrating that something is not working, suggesting that the value lies in identifying the reasons for failure and proposing changes to the attention mechanism. However, it does not specify which part of the paper this critique is based on, nor does it provide specific details on what aspects of the attention mechanism should be analyzed or changed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that demonstrating a failure is easier than identifying the reasons for failure and proposing changes to the attention mechanism. However, the comment does not provide specific examples, reasoning, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a thoughtful critique of the approach taken in the paper, suggesting that demonstrating the failure of a particular mechanism (e.g., attention in sequencetosequence MTL) is easier than identifying the reasons for its failure and proposing changes to make it work. This feedback highlights a valuable perspective on the importance of understanding the limitations and potential improvements of the mechanism. However, the comment lacks specific guidance or suggestions on how the authors might address this critique or what steps they could take to improve their work. While it offers a direction for further exploration, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to justify the reason for not including strong baselines in Table 3, specifically mentioning that MCNC should have many strong baselines that are not compared here, such as those in 1. This direct request provides a clear and specific action for the authors to take, which is to provide justification for the absence of these baselines. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification for not including strong baselines in Table 3, such as those mentioned in 1. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of strong baselines in Table 3, suggesting that MCNC should have many strong baselines that are not compared here, such as those in 1. However, the comment does not provide any specific reasoning or evidence to support why these baselines are missing or why they should be included. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, pointing out that MCNC should have many strong baselines that are not compared here, such as those mentioned in 1. This feedback is clear and actionable, as it directs the authors to justify the absence of these baselines in their table. By addressing this issue, the authors can improve the comprehensiveness and robustness of their presentation. However, the comment could be more helpful if it provided additional guidance on how to justify the inclusion of these baselines or examples of strong baselines that should be considered. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on a supplemental space, which makes it not truly independent. It specifically mentions references to the supplement, such as S3.1 and the model comparison, and notes that the paper is not truly independent due to this reliance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete actions or recommendations for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper\"s reliance on a supplemental space, indicating that the paper is not truly independent due to this reliance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not truly independent due to its reliance on a supplemental space, specifically referencing S3.1 and the model comparison. However, the comment lacks detailed reasoning or examples to support this claim. It does not provide specific instances or evidence of how the reliance on the supplement affects the independence of the paper. As a result, the claim is not 5, as it lacks sufficient justification or examples to substantiate the assertion. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reliance on a supplemental space, which undermines its independence. It specifically points out references to the supplement, such as S3.1 and the model comparison, and notes that the paper is not truly independent due to this reliance. This feedback is clear and actionable, as it highlights a critical weakness in the paper\"s structure and suggests that the authors should address this issue to ensure the paper\"s independence. However, the comment could be more helpful if it provided specific suggestions on how to achieve independence or alternative approaches to present the findings without relying on a supplement. Overall, the comment is 4, as it effectively identifies a problem and provides a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add information about the input being word embeddings, similar to Lample et al., and to clarify the source language of the input (whether it is in the source language or in English). It also mentions that the authors have already provided a response regarding the figure. These instructions are clear and specific, providing the authors with a direct action to take and concrete details on how to implement the changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the addition of information about the input being word embeddings, similar to Lample et al., and clarifies the source language of the input (whether it is in the source language or in English). Additionally, it mentions that the authors have already provided a response regarding the figure. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the input type and source language in their paper, specifically mentioning the use of word embeddings and the source language of the input. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that this clarification is necessary. The authors are informed of the need to make this change, but the comment does not provide detailed reasoning or evidence to justify the necessity of this clarification. Therefore, the claim is 3, as it requires further elaboration to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors clarify the input type and source language in their paper. It explicitly mentions the use of word embeddings, similar to Lample et al., and questions the source language of the input, whether it is in the source language or in English. This guidance is clear and directly addresses potential ambiguities in the paper, helping the authors improve the clarity and precision of their work. However, the comment could be more helpful if it included suggestions on how to present this information or examples of how to clarify the source language. Overall, the feedback is 4 as it provides clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the experiments section, suggesting that the paper should be stronger. It points out that the setting is limited to extremely lowresource regimes and that sentence classification is an easier task, implying that the proposed augmentation method could be applicable to more NLP tasks. However, the comment does not provide explicit guidance on how to address these issues or suggest specific improvements. The authors are left to infer that they need to expand their experiments to include more tasks and possibly adjust their methodology. While the action is implicit, it is 3 as it gives a general direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section, which is a specific part of the paper. It highlights the limitation of the experiments being limited to extremely lowresource regimes and suggests that the proposed augmentation method could be applicable to more NLP tasks. However, the comment does not specify which particular experiments or results are being criticized, making it weakly grounded. The authors can infer that it relates to the experimental section, but they would need to determine the exact parts. The comment is specific in detailing the weaknesses and suggesting potential improvements, but without explicit references, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the experiments are weaker than expected for a short paper, suggesting that the augmentation method could be more broadly applicable. The reviewer provides specific examples, such as the limited setting to extremely lowresource regimes and the easier nature of sentence classification, which are relevant to the augmentation method\"s potential applications. However, the comment lacks detailed reasoning or references to support the claim that the augmentation method could be used on more tasks. While the examples are relevant, the lack of further justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experimental section. It points out that the experiments are limited to extremely lowresource regimes, which may not cover all realworld applications where data augmentation is needed. Additionally, it notes that sentence classification is an easier task, suggesting that the proposed augmentation method could be applicable to more NLP tasks. While the comment highlights these areas for improvement, it lacks specific suggestions or guidance on how to address these issues or expand the scope of the experiments. The feedback provides some insight into potential areas for enhancement but does not offer detailed, actionable steps for the authors to follow. Therefore, the comment is 3, as it identifies areas for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant given the challenges of distinguishing nodes as the number increases. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what changes could be made to improve the paper. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant given the challenges of distinguishing nodes as the number increases. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its questioning but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant due to the challenges of distinguishing nodes as the number increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether concept map extraction should be treated as a separate task, suggesting that it might be redundant given the challenges of distinguishing nodes as the number increases. This feedback highlights a potential area for improvement in the paper, prompting the authors to reconsider their approach to concept map extraction. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes could be made to improve the paper. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance for the authors to address a specific point related to the traits of the experts and the justification for annotation by experts. It asks for a description of the traits of the experts, the reason for annotation outside commercial values, and whether the experts are linguistic or domain experts. It also questions whether annotation differs from nonexperts and introduces any linguistic challenges. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the traits of the experts, the justification for annotation by experts, and the differences between annotation by experts and nonexperts. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the traits of the experts and the justification for annotation by experts. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a detailed and actionable feedback by questioning the justification for annotation by experts, particularly in the context of linguistic annotation. It prompts the authors to clarify the traits of the experts, the reasons for annotation outside commercial values, and whether the annotation differs from what nonexperts would do. This feedback is clear and constructive, offering specific areas for the authors to address and improve their draft. However, it could be more helpful if it included suggestions on how to justify the choice of experts or provide examples of linguistic challenges. Overall, the comment is 4 as it guides the authors toward a more robust justification for their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a misleading statement in the paper, specifically in lines 102106. It points out that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion in the preceding section. This feedback provides a clear and explicit action for the authors to take, which is to correct the misleading statement. The comment also specifies what needs to be addressed, making it 5. The authors know exactly what part of the paper is problematic and what needs to be revised to avoid the misleading statement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, pointing out that \"such distribution\" cannot refer to the discussion in the preceding section. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion in the preceding section. However, the comment does not provide any additional context, reasoning, or examples to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text in Lines 102106, noting that the phrase \"such distribution\" is misleading because it cannot refer to the preceding discussion. This feedback is clear and actionable, as it points out a potential error in the paper that could mislead readers. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided suggestions on how to correct the misleading statement or offered guidance on how to avoid such issues in the future. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would benefit from including examples of their system applied to actual texts, compared to other components and models. While the comment implies that the authors should provide these examples, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to implement this suggestion, such as which examples to include or how to compare them to other components and models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, which implies that it is related to the evaluation or results sections of the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for examples, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors would benefit from including examples of their system applied to actual texts, compared to other components and models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that including examples of the system applied to actual texts would be beneficial, particularly compared to other components and models. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion. The authors are left with a general idea of what could be improved but without clear direction on how to achieve it. Therefore, the comment is 3, as it points out a potential enhancement but does not fully support the authors in making the necessary improvements. This aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that several claims from the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to perform a more detailed analysis of certain claims but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that several claims from the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or provide any guidance on how to conduct this analysis. Without specific references to the claims or detailed suggestions, the authors cannot confidently determine which parts of the paper need attention or how to improve them. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point suggests that several claims from the paper would benefit from more indepth analysis. However, it does not provide any specific examples or reasoning to support why these claims need more detailed analysis. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that several claims from the paper would benefit from more indepth analysis. While it identifies an area for improvement, it lacks specificity and does not provide detailed guidance on which claims need more analysis or how to conduct this analysis. The comment is vague and does not offer actionable advice, making it 2. The authors are left with a general idea of what needs to be improved but without clear direction on how to proceed. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two specific areas for improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397) and questions the clarity of Equation (7) in line 472, suggesting that the lefthand side should be a conditional probability. The comment provides clear and direct actions for the authors to take, specifying what needs to be clarified or defined. This makes the comment 5, as it gives precise guidance on how to enhance the clarity and accuracy of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved: the pooling method used for embedding features and the clarity of Equation (7), including the definitions of the random variables E_i and the potential issue with the lefthand side of the equation being a conditional probability. This provides clear guidance on what needs to be clarified or corrected in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: questioning the clarity of the pooling method used for embedding features and suggesting that Equation (7) is not clear enough. The first part is a request for clarification, which does not contain a claim. The second part questions the clarity of Equation (7) and suggests that the lefthand side should be a conditional probability. This is a request for clarification and does not contain a subjective claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two key areas of the paper that need improvement. First, it questions the clarity of the pooling method used for embedding features, specifically referencing line 397. This is a clear request for clarification, which can help the authors improve the transparency and understanding of their methodology. Second, the comment addresses the clarity of Equation (7) in line 472, questioning whether E_i represents the type or identity of the AC i and suggesting that the lefthand side of the equation should be a conditional probability. This feedback is detailed and constructive, offering specific guidance on how to enhance the clarity and accuracy of the paper. By addressing these points, the authors can significantly improve the comprehensibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study them or discuss them further. The reviewer suggests that the paper should go deeper into these topics. While the comment implies that the authors should expand on the discussion of these hypotheses, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors know they need to delve deeper into the topics but are not given concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper raises hypotheses about multilinguality and country/languagespecific bias but does not actually study or discuss them, which is misleading. The comment suggests that the paper should go deeper into these topics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study or discuss them. The reviewer suggests that the paper is misleading and should go deeper into these topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study or discuss them. This feedback is valuable as it highlights a critical gap in the paper\"s exploration of these hypotheses. However, the comment could be more helpful by suggesting specific ways the authors might address this gap, such as recommending additional experiments or analyses to test the hypotheses. While it points out an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider using a set of handcrafted features, similar to those used by Uto et al. (2020), to potentially improve the performance of their work. While the suggestion is explicit, it lacks concrete guidance on how to implement this change or what specific features to use. The authors are given a direction but not detailed instructions on how to execute it, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using a set of handcrafted features, similar to those used by Uto et al. (2020), to potentially improve the performance of the work. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result that could be improved. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a set of handcrafted features, similar to those used by Uto et al. (2020), could potentially improve the performance of the work. The comment references Uto et al. (2020)\"s system, which achieved a QWK of 0.801, implying that using the same feature set could improve the results. This provides a logical basis for the suggestion, as it draws on existing work to support the claim. However, the comment could be strengthened by providing more specific details or examples of how these features could be implemented or what aspects of the current work could be improved. Overall, the claim is 4, as it is supported by a reference to an external work, but it could be more robust with additional details.", "helpfulness_rationale": "The review comment suggests that the use of feature engineering could potentially improve the performance of the work, referencing a similar approach used by Uto et al. (2020). This feedback is 3 as it provides a direction for the authors to consider, potentially leading to improvements in their results. However, the comment lacks specific guidance on how to implement this suggestion or what specific features to use, which would make it more actionable. The authors are given a starting point but not detailed instructions on how to proceed, which limits the comment\"s helpfulness. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation process. It asks whether the CS is used to augment the training material and, if so, what data split was used. While the comment identifies specific questions that the authors should address, it does not provide explicit instructions or concrete guidance on how to address these questions. The authors can infer that they need to clarify the use of the CS and the data split, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) and its role in the evaluation process. It specifically asks whether the CS is used to augment the training material and, if so, what data split was used. However, it does not explicitly mention which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the use and role of the CS, providing clear guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) and its role in the evaluation process. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment \"No\".", "helpfulness_rationale": "The review comment raises questions about the use of the Challenge Set (CS) and its role in the evaluation process. It specifically asks whether the CS is used to augment the training material and, if so, what data split was used. This feedback is 3 as it identifies a potential area of confusion and prompts the authors to clarify their methodology. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered guidance on how to improve the clarity of the methodology section. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the paper\"s claim regarding the model\"s generalization to different knowledge. It questions the representation of the substructure as a sequence of words and suggests that constituent parse might not be straightforward for this purpose. Additionally, the reviewer hesitates to label the substructure as \"knowledge,\" arguing that it is more accurately described as syntax or semantics. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it challenging for the authors to know what specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim regarding the model\"s generalization to different knowledge, specifically questioning the representation of the substructure as a sequence of words and suggesting that constituent parse might not be straightforward for this purpose. It also questions the use of the term \"knowledge\" in the context of the substructure, suggesting it might be misleading. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of the model\"s generalization or the representation of knowledge. The comment is specific in detailing the issues with the representation and the potential mislabeling of the substructure. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the paper\"s claim regarding the model\"s generalization to different knowledge. The reviewer questions the representation of the substructure as a sequence of words and suggests that constituent parse might not be straightforward for this purpose. Additionally, the reviewer hesitates to label the substructure as \"knowledge,\" arguing that it is more accurately described as syntax or semantics. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claim. The authors would need to further explore and clarify these points to fully understand and address the feedback. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a critical point about the paper\"s claim regarding the model\"s generalization to different knowledge. It questions the representation of the substructure as a sequence of words and suggests that constituent parse might not be straightforward for this purpose. The reviewer also hesitates to label the substructure as \"knowledge,\" arguing that it is more accurately described as syntax or semantics. This feedback is valuable as it challenges the authors to clarify and justify their claims, potentially leading to significant improvements in the paper. However, the comment could be more helpful if it provided specific suggestions or examples for addressing these concerns. Overall, the comment is 4 as it prompts the authors to reconsider their assumptions and potentially improve the clarity and accuracy of their claims."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the performance of the clustering approach on nouns and raises a question about the gap between the oracle GAP for PPDBClus and other clustering approaches. It also contradicts a claim made in the paper regarding the generalizability of the clustering approach. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback lacks actionable steps, leaving the authors uncertain about how to respond to the issues raised. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the clustering approach on nouns and raises a concern about the gap between the oracle GAP for PPDBClus and other clustering approaches. It also contradicts a claim made in the paper regarding the generalizability of the clustering approach. However, the comment does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the results or discussion sections, the lack of explicit references makes the comment weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises concerns about the performance of the clustering approach on nouns and the gap between the oracle GAP for PPDBClus and other clustering approaches. It also contradicts a claim made in the paper regarding the generalizability of the clustering approach. The comment provides logical reasoning by explaining the implications of the performance disparity and how it challenges the claim of generalizability. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concerns raised.", "helpfulness_rationale": "The review comment raises concerns about the performance of the clustering approach on nouns and questions the generalizability of the approach, as evidenced by the gap between the oracle GAP for PPDBClus and other clustering approaches. It provides a logical reasoning for the concern, explaining how the performance disparity challenges the claim of generalizability. However, the comment could be more helpful by offering specific suggestions or guidance on how the authors might address these concerns, such as proposing additional experiments or analyses to better understand the performance differences. While it identifies a significant issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion in section 5.2 is abstract and lacks insight into why the new model is better than MH. It suggests that the authors provide examples of spurious structures to clarify the discussion. While the comment implies that the authors should include examples, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the discussion is abstract and lacks insight into why the new model is better than MH, and it suggests providing examples of spurious structures to clarify the discussion. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the abstractness of the discussion in section 5.2 and suggests that it lacks insight into why the new model is better than MH. However, it does not provide any specific examples or reasoning to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the discussion is abstract or lacks insight. As a result, the claim is considered 1 due to the absence of supporting details or examples. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in section 5.2, noting that it lacks insight into why the new model is better than MH. It suggests that the authors provide examples of spurious structures to clarify the discussion. This feedback is clear and actionable, as it guides the authors to enhance the clarity and depth of their discussion by offering concrete examples. However, the comment could be more helpful if it included specific examples or suggestions on how to present these examples effectively. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations for certain matrices, which could help in comparing parsing results. However, it does not provide explicit instructions on how to implement this suggestion or what specific aspects should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and the details of the comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with specific parameterizations for certain matrices, which could help in comparing parsing results. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing the parameterizations and the potential issue with comparing parsing results, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with specific parameterizations for certain matrices, which could help in comparing parsing results. However, the comment lacks specific examples or detailed reasoning to support why this approach would be beneficial or how it would improve the comparison. Without explicit justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment suggests adding a baseline smaller PCFG with specific parameterizations for certain matrices, which could help in comparing parsing results. However, the comment lacks detailed guidance on how to implement this suggestion or what specific aspects should be compared. While it provides a direction for improvement, it does not offer actionable steps or detailed reasoning, making it 3. The authors may gain some insight into potential areas for enhancement but would need to infer the exact actions to take. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include the maximum number of tasks performed by any annotator in their work. This is an explicit action, as it clearly states what needs to be added to the paper. However, it does not provide specific guidance on how to determine or present this information, leaving the authors to infer the exact steps to take. The action is concrete but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is stating the maximum number of tasks done by any annotator. This provides clear guidance on what additional information should be included. Therefore, this comment is categorized as 5.", "verifiability_rationale": "The review point suggests that the authors should include the maximum number of tasks performed by any annotator. However, it does not provide any reasoning, examples, or references to support why this information is important or how it would benefit the paper. Without additional context or justification, the claim remains 1, as it lacks the necessary evidence or explanation to guide the authors in making an informed decision. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include the maximum number of tasks performed by any annotator. This is a clear and actionable piece of feedback that can help the authors enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or explanation on why this information is important or how it might impact the paper\"s conclusions. Despite this, the suggestion is clear and actionable, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the experiments and their relevance to the research question and hypothesis. However, it does not provide explicit guidance or suggestions on how the authors should clarify or improve this understanding. The feedback lacks actionable details, such as specific areas that need further explanation or examples of how to better integrate the empirical results. As a result, the authors are left without clear direction on how to address the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s focus on empirical results and analyses, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear issue regarding the difficulty in understanding the overall picture of the experiments and their relevance to the research question and hypothesis. The comment requests clarification on how the experiments fit together and what they reveal about the research question and hypothesis. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the experiments and their relevance to the research question and hypothesis. However, it does not provide specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the authors are struggling to grasp the significance of their empirical results. As a result, the claim is 1 due to the absence of supporting details, making it difficult for the authors to address the feedback effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while it contains many empirical results and analyses, it lacks a clear understanding of what these results reveal about the research question and the specific hypothesis being tested. The reviewer questions how the different pieces of the puzzle presented in the experiments fit together and what they collectively tell us about the underlying research question. This feedback is valuable as it highlights a critical gap in the paper\"s presentation and analysis, prompting the authors to clarify and integrate their findings more effectively. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or integration of the results. Overall, the comment is 3 as it points out an important area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is an explicit action, as it clearly states what the authors should do to improve their draft. The comment provides a concrete direction for the authors to take, making it 5. The authors know exactly what needs to be done to enhance their draft, which aligns with the criteria for a score of 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in its suggestion to include a particular baseline, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. However, it does not provide any reasoning or evidence to support why this inclusion would be beneficial or how it would improve the paper. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that could enhance the paper by providing additional context and insights into the performance of the methods. By including this baseline, the authors can better understand the effectiveness of their methods and how they compare to existing approaches. However, the comment could be more helpful if it provided some guidance on how to implement this suggestion or why it is particularly relevant. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the lack of numerical results in the paper and expresses curiosity about applying the work to popular algorithms and comparing their performance with existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific numerical results should be included. The action is implicit, as the authors can infer that they need to add numerical results, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results in the paper and expresses curiosity about applying the work to popular algorithms and comparing their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include these results. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks numerical results, which is a factual observation. It expresses curiosity about applying the work to popular algorithms and comparing their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that numerical results are missing or to explain why this is a significant issue. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results. It expresses curiosity about how the work can be applied to popular algorithms and how its performance compares with existing DP algorithms. This feedback is 3 as it highlights an area where the paper could be strengthened by providing concrete numerical evidence. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending particular algorithms to test or how to present the results effectively. While it prompts the authors to consider this aspect, it does not offer detailed direction for improvement, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), which are used by other methods like MoCo and SimCLR. While the comment implies that the authors should conduct these additional experiments, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper these comparisons are made in, making it weakly grounded. The comment is specific in suggesting additional experiments to include, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific comparisons are necessary or how they would enhance the study. Without such details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental comparisons by suggesting that the proposed InvP method should be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), which are used by other methods like MoCo and SimCLR. This feedback is actionable as it provides a specific direction for the authors to enhance their experimental setup, potentially leading to more comprehensive and robust results. However, the comment could be more helpful if it included a brief explanation of why these wider backbones are relevant or how they might impact the results. Overall, the comment is 4 as it offers a clear suggestion for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not welldrawn and recommends that the authors either formalize this connection or adjust the language to clarify it. While the comment implies that the authors should take action to improve the formalization or language, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should formalize the connection or adjust the language. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not welldrawn and recommends that the authors either formalize it or adjust the language to clarify it. However, it does not specify which part of the paper discusses the probabilistic connection, making it weakly grounded. The comment is specific in its suggestion to formalize the connection or adjust the language, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not welldrawn and suggests that the authors should either formalize it or adjust the language to clarify it. However, the comment lacks specific examples or detailed reasoning to support why the probabilistic connection is not welldrawn or how it could be improved. Without concrete evidence or references, the claim is 3, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the probabilistic connection in the paper, suggesting that it is not welldrawn and could be more formally established or clearly articulated. This feedback is 3 as it points out a specific area that needs attention and provides a direction for improvement. However, the comment could be more actionable by offering specific suggestions on how to formalize the connection or clarify the language. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to present the evidence or what kind of evidence would be most effective. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting the need for empirical evidence to support the claim, but without clear guidance on how to present this evidence, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include specific evidence that would strengthen their argument and provide a more robust validation of their claims. However, the comment could be more helpful if it offered suggestions on how to present this evidence or what type of empirical results would be most effective. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the applicability of their training scheme. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is covered, the comment lacks full grounding. It is specific in identifying the concern about scalability, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the claim is considered 2, as it provides some reasoning but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While this feedback identifies a potential limitation of the proposed method, it lacks specific suggestions or guidance on how the authors might address this issue or improve the applicability of their training scheme. The comment provides some insight into a potential weakness but does not offer actionable steps for the authors to take. Therefore, it is 3, as it highlights an important consideration but does not fully support the authors in making improvements. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the sufficiency of the dataset period and the types of style shifts observed. It suggests that the authors should provide answers to these questions to better understand what the model is capturing. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide answers to the questions raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of datasets, specifically questioning whether a 4year period is sufficient to study style shifts and what types of style shifts occur within that timeframe. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where datasets are discussed. The comment is specific in its inquiry about the sufficiency of the dataset period and the types of style shifts observed, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the sufficiency of the dataset period and the types of style shifts observed, suggesting that the authors should provide answers to these questions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why a 4year period is insufficient or what specific style shifts are being considered. This lack of detailed justification makes the claim difficult for the authors to address effectively, rendering the comment 1.", "helpfulness_rationale": "The review comment raises a critical question about the sufficiency of the dataset period and the types of style shifts observed, which is essential for understanding what the model is capturing. By questioning the dataset\"s timeframe and the nature of style shifts, the comment prompts the authors to provide more detailed and comprehensive information in their draft. This feedback is clear and actionable, as it directs the authors to address a significant aspect of their study that could impact the validity and interpretation of their results. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of style shifts. Overall, the comment is 4 as it identifies a critical area for improvement and encourages the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct the placement of a callout in Table 5 to Table 3 and to ensure that the callout for Figure 6 is properly directed. These are clear and direct actions that the authors can take to improve their draft. The feedback provides specific guidance on where to make the necessary changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout placement, indicating that the callout should be moved from Table 5 to Table 3. Additionally, it points out an issue with the callout for Figure 6, specifying that it is not directing properly. This level of detail provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate comments: one about the placement of a callout in Table 5 and another about the callout for Figure 6. Both comments are factual and descriptive, providing specific instructions for correction without making any subjective claims or judgments. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out errors in the placement of callouts in the paper. It clearly instructs the authors to correct the callout from Table 5 to Table 3 and to ensure that the callout for Figure 6 is properly directed. This level of detail is 5 as it guides the authors on exactly what needs to be corrected, making it easier for them to improve their draft. The comment is clear, precise, and provides clear direction for improvement, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a significant concern with the experiments section, noting that the paper only reports self comparisons and lacks motivation. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform these comparisons and understand the reasoning behind it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue of only reporting self comparisons and the lack of motivation, suggesting that comparisons with SketchRNN could be performed in a generative setting. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only reports self comparisons and lacks motivation, which is a significant concern. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting to address this issue. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why self comparisons are insufficient or how comparisons with SketchRNN would improve the motivation. This makes the claim 3, as it provides a direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the experiments section, noting that the paper only reports self comparisons and lacks motivation. It suggests that comparisons with SketchRNN could be performed in a generative setting to address this issue. This feedback is clear and actionable, as it points out a specific area for improvement and provides a concrete suggestion for enhancing the motivation and comprehensiveness of the experiments. However, the comment could be more helpful if it included additional guidance on how to conduct these comparisons or why they are necessary. Overall, the comment is 4, as it provides valuable insight into a critical area of the paper that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more analysis and comments are needed on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\" claim that both CNNs and ViTs benefit similarly from increased model capacity. The reviewer provides specific examples from Figure 3, such as DeiTB not outperforming DeiTT and DeiTS on certain datasets, and notes that CNNs can provide more consistent improvements as model capacity increases. This feedback is explicit and provides concrete guidance on what additional analysis and comments are needed to address the issue. The authors are given clear direction on how to improve their draft by expanding on these points, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) and challenges the authors\" claim that both CNNs and ViTs benefit similarly from increased model capacity. The comment includes specific examples from Figure 3, such as DeiTB not outperforming DeiTT and DeiTS on certain datasets, and notes that CNNs can provide more consistent improvements as model capacity increases. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity,\" but the reviewer disagrees, providing specific examples from Figure 3. The reviewer notes that DeiTB does not outperform DeiTT and DeiTS on certain datasets, and that CNNs can provide more consistent improvements as model capacity increases. This detailed analysis supports the claim with specific data points and examples, making the comment 4. However, the comment could be further strengthened by referencing specific studies or literature that supports the observed trends, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the authors\" claim that both CNNs and ViTs benefit similarly from increased model capacity. It suggests that the authors should provide more analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. The reviewer supports this suggestion by pointing out specific inconsistencies in the results, such as DeiTB not outperforming DeiTT and DeiTS on certain datasets, and notes that CNNs can provide more consistent improvements as model capacity increases. This feedback is clear and actionable, offering the authors a specific direction for enhancing their analysis and improving the clarity of their results. However, it could be more helpful if it included suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is not difficult to follow but points out several places that may cause confusion. However, it does not specify which parts of the paper are causing confusion or provide any guidance on how to address these issues. The lack of explicit actions or concrete suggestions makes it difficult for the authors to know what specific changes to make to improve the clarity of the paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not difficult to follow but points out several places that may cause confusion. However, it does not specify which parts of the paper are causing confusion, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity regarding the nature of the confusion or the specific areas that need clarification. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies several places that may cause confusion. However, it does not provide specific examples or detailed reasoning to support the claim that these places are confusing. Without concrete evidence or examples, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion. However, it does not provide specific examples or detailed feedback on what aspects are confusing or how they could be clarified. Without actionable guidance or suggestions, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is 2, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the statement \"However, there is no corresponding set of tools for the reinforcement learning setting\" is false, as it provides references to support this claim. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the absence of tools for the reinforcement learning setting. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, as it points out the lack of corresponding tools and provides references to support the claim. This combination of weak grounding and specificity aligns with the label 3.", "verifiability_rationale": "The review point claims that the statement \"However, there is no corresponding set of tools for the reinforcement learning setting\" is false, as it provides references to support this claim. The inclusion of references makes the claim verifiable, as it offers a basis for the assertion. However, the comment could be strengthened by explicitly listing the references or providing more detailed reasoning about why the statement is false. Despite this, the presence of references makes the claim 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper that is deemed false, as it provides references to support the assertion. This feedback is valuable as it highlights a potential error or misrepresentation in the paper, allowing the authors to address and correct it. However, the comment could be more helpful if it provided additional context or suggested ways to improve the accuracy of the statement. Overall, the comment is 3 as it points out a critical issue that needs attention, but it lacks depth and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on standard techniques, are not easily understood by a fair degree of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or to suggest ways to improve the clarity or understanding of the techniques. Without actionable advice or specific suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the results for being based on \"standard\" techniques but notes that they are not obvious a priori, requiring a fair degree of technical competency. However, it does not specify which results or sections of the paper are being discussed, making it difficult for the authors to pinpoint the exact parts needing improvement. The comment lacks specificity regarding what aspects of the techniques are unclear or how they could be made more accessible. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results, while based on standard techniques, are not obvious a priori and require a fair degree of technical competency. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to illustrate the complexity or lack of intuitiveness in the results, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the results for being based on \"standard\" techniques but notes that they are not obvious a priori, requiring a fair degree of technical competency. While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. The comment highlights a concern but does not offer guidance on improving the clarity or accessibility of the results, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should make a distinction between hard prompt work updates to the frozen model (e.g., Schick and Sch\u00fctez) and those that don\"t. This is an explicit suggestion for the authors to clarify their distinction in the paper. However, the comment does not provide specific guidance on how to implement this distinction or where in the paper this clarification should be made. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a distinction between hard prompt work updates to the frozen model (e.g., Schick and Sch\u00fctez) and those that don\"t. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should make a distinction between hard prompt work updates to the frozen model (e.g., Schick and Sch\u00fctez) and those that don\"t. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is important or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending that the authors make a distinction between hard prompt work updates to the frozen model (e.g., Schick and Sch\u00fctez) and those that don\"t. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the clarity and precision of the paper. By addressing this distinction, the authors can improve the readability and understanding of their work. However, the comment could be more helpful if it included additional context or explanation on why this distinction is important or how it would benefit the paper. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the disparity in the amount of data used to train the text disambiguation model and the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions to take to improve the draft. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the disparity in the amount of data used to train two different models: the text disambiguation model and the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or where the data disparity is mentioned, making it weakly grounded. The comment is specific in detailing the issue and questioning the conclusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the disparity in data usage between two models, questioning the conclusion that the direct model is clearly better. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the conclusion is questionable. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the disparity in the amount of data used to train two different models, which could impact the conclusion about their performance. It raises a valid concern that the small difference in performance might question the superiority of the direct model over the baseline. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important consideration, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks clear motivation for GaRare and provides a specific request for evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback provides explicit and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the lack of motivation and evidence for GaRare and its advantages over GaLore, as well as the need for a more detailed algorithmic presentation. However, it does not specify which part of the paper discusses GaRare or GaLore, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing evidence for GaRare\"s advantages and clarifying the process of recovering updated parameters from projected gradients. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation and evidence for GaRare\"s advantages over GaLore, and it suggests a more detailed algorithmic presentation is needed. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some indication of the problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of motivation and evidence for GaRare\"s advantages over GaLore. It suggests that the authors need to provide a clearer justification and theoretical analysis to support the use of GaRare. Additionally, the comment highlights the need for a more detailed algorithmic presentation, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is clear and actionable, offering specific areas for improvement that could enhance the paper\"s theoretical and practical contributions. However, it could be more helpful if it included examples or suggestions on how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for the performance of the proposed model without considering the relevant attention retrieval from the attention memory, specifically referencing Figure 4 left. This provides clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an ablation study on the visDial dataset and questions the performance of the proposed model without considering relevant attention retrieval. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of two parts: a request for an ablation study on the visDial dataset and a question about the performance of the proposed model without considering relevant attention retrieval. The first part is a request for an additional experiment, which is a common practice in research to validate results. The second part is a question seeking clarification on a specific aspect of the model. Neither part contains subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also raises a specific question about the performance of the model without considering relevant attention retrieval, referencing Figure 4 left. This feedback is clear and constructive, offering a concrete way for the authors to enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4, as it effectively directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing link to similar work on Continuous Conditional Random Fields (Ristovski 2013) and Continuous Conditional Neural Fields (Baltrusaitis 2014). While it identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this gap or incorporate these references into their work. The action is implicit, as the authors can infer that they need to include these works in their literature review or discussion, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a missing link to similar work on Continuous Conditional Random Fields (Ristovski 2013) and Continuous Conditional Neural Fields (Baltrusaitis 2014). However, it does not specify which part of the paper this link should be addressed in, making it weakly grounded. The comment is specific in identifying the need to include these references, but without clear guidance on where to incorporate them, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields (Ristovski 2013) and Continuous Conditional Neural Fields (Baltrusaitis 2014). However, the comment does not provide specific reasoning or evidence to support this claim, such as examples of how these works differ or how they could be integrated into the current work. Without detailed justification or references, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (Ristovski 2013) and Continuous Conditional Neural Fields (Baltrusaitis 2014), which could provide valuable context and comparison for the current work. However, the comment lacks specificity and does not offer actionable guidance on how the authors might incorporate these references into their paper or discuss their relevance. While it highlights an important area for improvement, the feedback could be more helpful with additional details or suggestions on how to address the gap. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should explain why WPA works, specifically asking about the model\"s predictions with np.ones input and whether any input could serve as a white paper. It also notes that Figure 2 suggests Gaussian noise input does not work as well as WPA and questions why this is the case. The comment implies that the authors should provide more insight into the functionality of WPA, which is crucial for future research directions. While the action is implicit, it is concrete in terms of what the authors need to do\u2014explain the mechanism of WPA and its effectiveness. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, explaining why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. The comment also suggests that the authors should provide insights into how WPA works, which is important for future research directions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide an explanation of why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. The comment implies that the current results, which show that WPA improves test performance, do not offer insights into its functionality. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current results are insufficient. This lack of detailed justification makes the claim 3, as the authors would need to further develop the explanation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the authors spend considerable time demonstrating the improvement of WPA over the original model but fail to provide insights into how WPA works. This is crucial for understanding its functionality and potential applications, which could guide future research directions. The comment suggests that the authors should explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not perform as well. It also questions the lack of insight into WPA\"s effectiveness, which is important for the paper\"s comprehensiveness. While the comment highlights a critical area for improvement, it could be more helpful by offering specific suggestions or examples on how to address these questions. Overall, the feedback is 4 as it directs the authors to a significant aspect of their work that needs further exploration and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" The reviewer implies that the authors should provide more clarification on this point. While the action is explicit\u2014asking for clarification\u2014the comment does not provide specific guidance on what aspects need clarification or how the authors should address this issue. The lack of concrete details makes the action somewhat vague, leaving the authors with a general direction but without specific steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this comparison is made, making it weakly grounded. The comment is specific in suggesting that the authors provide more clarification on this point, but it lacks detailed guidance on what aspects of the method part need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential overlap between the method part of the paper and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This observation highlights a possible redundancy or lack of originality in the method description. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from the related work. While it points out a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors are given a clue but not a comprehensive roadmap for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the fairness of comparing the proposed method with others and suggests exploring the potential of the proposed technique in promoting existing class incremental semantic segmentation methods. While it implies that the authors should address these issues, it does not provide explicit instructions or concrete guidance on how to do so. The comment is 3 as it identifies areas for improvement but lacks detailed steps or suggestions for the authors to follow.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with others and suggests exploring the potential of the proposed technique in promoting existing class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its questions about fairness and potential applications, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with others and suggests exploring the potential of the proposed technique in promoting existing class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the proposed method with others, suggesting that it may not be appropriate. It also implies that the proposed technique could potentially enhance existing class incremental semantic segmentation methods. While the comment identifies a potential issue with the comparison, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their work. The feedback is 3 as it prompts the authors to consider the fairness of their comparisons and the potential applications of their method, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the two important parameters/thresholds mentioned in Section 2 are not discussed or mentioned in the experimental section (Section 3). This implies that the authors should provide information on how these parameters are set and how sensitive the performance is to them. While the comment identifies a gap in the paper, it does not explicitly instruct the authors to include this information in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should add this information but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of discussion or mention of how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters in the experimental section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a gap in the paper by noting that the experimental section does not discuss or mention the parameters mentioned in Section 2, specifically the minimum cluster size and conductance threshold. This claim is 3 as it points out a missing element in the experimental section, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of these parameters and their impact on performance, which limits the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that the experimental section does not discuss or mention the two important parameters/thresholds mentioned in Section 2, namely the minimum cluster size and the conductance threshold. This feedback is clear and actionable, as it directs the authors to provide additional information on how these parameters are set and how sensitive the performance is to them. By addressing this feedback, the authors can improve the comprehensiveness and clarity of their experimental section, ensuring that readers understand the significance of these parameters. However, the comment could be more helpful if it included suggestions on how to present this information effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 4 is written in a very terse manner, possibly due to space constraints, and suggests that a slower development would make it easier to read. While the comment identifies an issue with the writing style, it does not provide specific guidance on how to improve the section or what aspects should be expanded. The action is implicit, as the authors can infer that they need to slow down the development of Section 4, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is written in a very terse manner and suggests that a slower development would improve readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is written in a very terse manner, possibly due to space constraints, and suggests that a slower development would improve readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what makes the section terse or how a slower development would enhance readability, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style in Section 4, noting that it is written in a very terse manner. It suggests that a slower development could improve readability, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific suggestions on how to enhance the readability or what aspects of the section could be expanded. While it points out a potential area for improvement, it does not offer actionable guidance or detailed advice, making it 3. The authors would gain some insight but may need to make significant changes on their own to address the feedback effectively."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a belief that the use of reinforcement learning for a static Visual Question Answering (VQA) task may be a potential weakness, suggesting that it could make the approach less dataefficient and harder to train models using gradient descent. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. It lacks concrete steps or actionable advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the use of reinforcement learning for a static VQA task, suggesting that it may be a potential weakness. However, it does not specify which part of the paper this concern pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the approach\"s potential weakness but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the use of reinforcement learning for a static VQA task, suggesting that it may be a potential weakness. However, the comment lacks specific reasoning or examples to support this claim. It does not provide detailed evidence or references to substantiate the assertion that this approach is less dataefficient or harder to train. Without such supporting details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some intuition but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment raises a concern about the use of reinforcement learning for a static VQA task, suggesting that it may be a potential weakness. This feedback is 3 as it identifies a potential area for improvement in the approach, which could lead to more dataefficient and easiertotrain models. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable advice or detailed reasoning, the authors may struggle to understand how to make the necessary adjustments. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete actions for the authors to take, making the comment 5. The authors know exactly what needs to be added to their draft to address the feedback provided.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the distribution of video lengths within the benchmark, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a table showing the distribution of video lengths and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the distribution of video lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests including a table and explaining the balanced representation of video lengths across categories. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include a table and explanation provides some guidance, but more detailed evidence or examples would be needed for the claim to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the distribution of video lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper lacks relevant explanations. It provides clear and actionable feedback by suggesting the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This feedback is 5 as it guides the authors on what specific elements need to be added to improve the clarity and comprehensiveness of their work. By addressing this feedback, the authors can enhance the robustness and transparency of their study, making the comment highly valuable for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the implementation of the bilinear layer, asking for clarification on its differences from other approaches that use bilinear pooling. It specifically inquires about the dimensionality of embeddings, the use of the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still applied. While the comment poses questions that could guide the authors in clarifying their methodology, it does not explicitly instruct them to make these changes or provide concrete steps for addressing the issues. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the implemented bilinear layer differs from other approaches that use bilinear pooling, and it questions the major differences, such as the dimensionality of embeddings and the use of the Hadamard product and MCB approaches. Additionally, it inquires about the compression of representations using Equation (3). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the implementation of the bilinear layer, rather than making subjective claims or judgments. It does not contain any opinions, suggestions, or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the implementation of the bilinear layer, seeking clarification on its differences from other approaches that use bilinear pooling. It specifically asks about the dimensionality of embeddings, the use of the Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still applied. While the comment identifies areas for clarification, it does not provide actionable suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it points out specific areas that need further explanation, but it lacks depth and detailed advice, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should take a cautious approach regarding the contribution until the dataset is publicly available. However, it does not provide specific guidance on how to implement this cautious approach or what steps the authors should take to address this issue. The comment lacks concrete instructions or suggestions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the promised dataset is not yet publicly available, implying that the authors should take a cautious approach regarding this contribution until the dataset is accessible. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the dataset is mentioned. Without explicit references, the authors may find it challenging to identify the exact part of the paper that needs attention. While the comment is specific in its suggestion, it lacks grounding as it does not point to a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset is not yet publicly available, suggesting a cautious approach should be taken regarding this contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the dataset\"s availability is a concern or how it affects the contribution. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of public availability of the promised dataset. It suggests that the authors should take a cautious approach regarding this contribution until the dataset is accessible. While the comment highlights a concern, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the contribution is appropriately handled. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it less useful for the authors to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the novelty of the proposed method, noting that it is too similar to existing attentional modules from previous works. It suggests that the group attention design is related to ResNeSt but does not discuss this in the paper. The comment implies that the authors should address the novelty issue and provide a more detailed discussion of the differences between their method and existing ones. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the novelty. The action is implicit and somewhat vague, as the authors need to infer that they should address the novelty issue and provide a more detailed discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, noting that it is too similar to existing attentional modules from previous works. It specifically mentions the group attention design being related to ResNeSt, which is not discussed in the paper. This provides some grounding as it references specific works, but the authors might need to infer which parts of the paper are being discussed. The comment is specific in detailing the similarities and suggesting that the group attention design is related to ResNeSt, which could help the authors understand the issue. However, it lacks full grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited, as it is too similar to existing attentional modules from previous works. The reviewer supports this claim by referencing specific works 1, 2, 3 and noting that the group attention design is related to ResNeSt, which is not discussed in the paper. However, the comment lacks detailed examples or specific comparisons to substantiate the claim fully. While the references provide some context, the reviewer does not elaborate on how the proposed method differs from the existing ones or how it could be more novel. This makes the claim 3, as it provides a basis for the critique but requires more detailed explanation to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the novelty of the proposed method, noting that it is too similar to existing attentional modules from previous works. It provides specific references to previous studies, such as 1, 2, 3, and mentions that the group attention design is related to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to address the novelty of their work. However, the comment could be more helpful if it offered suggestions on how to differentiate the proposed method from existing ones or provided guidance on how to enhance its originality. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind using cosine similarity to illustrate the results of the latter loss term in Eqn 13. It suggests that since the preactivation values of two networks are the same membrane potentials, their output cosine similarity would be very high. The comment implies that the authors should consider directly illustrating the results of the latter loss term instead of using cosine similarity. However, it does not provide explicit guidance on how to implement this change or what specific aspects should be illustrated. The action is implicit and somewhat vague, as the authors need to infer the exact action to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rationale behind using cosine similarity to illustrate the results of the latter loss term in Eqn 13. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term in Eqn 13. It suggests that since the preactivation values of two networks are the same membrane potentials, their output cosine similarity would be very high. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach might be questioned or why it should be reconsidered. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using cosine similarity to illustrate the results of the latter loss term in Eqn 13. It points out that since the preactivation values of two networks are the same membrane potentials, their output cosine similarity would be very high. The comment suggests that the authors should consider directly illustrating the results of the latter loss term instead of using cosine similarity. While the comment identifies a potential issue with the methodology, it does not provide specific guidance or suggestions on how to address this concern or improve the illustration. The feedback is 3 as it prompts the authors to reconsider their approach, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, such as AB. It suggests that these TTA methods, which focus on updating model parameters, should be compared with the paper\"s focus on adjusting input data. The comment implies that the authors should conduct experiments to demonstrate the superiority of data processing over model parameter adjustment. While the action is implicit, it is concrete as it provides a clear direction for the authors to take, which is to include a comparison based on experimental results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of comparison with testtime adaptation (TTA) methods, such as AB, in the context of robustness in video action recognition. It highlights the focus of these TTA methods on updating model parameters and contrasts it with the paper\"s focus on adjusting input data. The comment suggests that a comparison should be made based on experimental results. However, it does not explicitly mention a specific section or part of the paper where this comparison should be made, making it weakly grounded. The comment is specific in detailing what is missing and how it should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of comparison with testtime adaptation (TTA) methods, such as AB, in the context of robustness in video action recognition. The reviewer suggests that these TTA methods, which focus on updating model parameters, should be compared with the paper\"s focus on adjusting input data. The comment provides a logical reasoning by explaining the contrast between the two approaches and suggesting that a comparison based on experimental results would be beneficial. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, such as AB, which are relevant to the issue of robustness in video action recognition. It highlights the contrast between these TTA methods, which focus on updating model parameters, and the paper\"s focus on adjusting input data. The comment suggests that a comparison should be made based on experimental results to demonstrate the superiority of data processing over model parameter adjustment. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft by including a comparison with TTA methods. However, the comment could be more helpful if it included suggestions on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies an error in Section 3.2.1, specifically pointing out that the first expression for J(\u03b8) is incorrect and should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This feedback provides a clear and direct action for the authors to correct the expression in their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J(\u03b8), stating that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)) instead of the incorrect expression. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and should be Q(s_t^0, \u03c0_\u03b8(s_t^0)) instead. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to correct it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in Section 3.2.1, pointing out that the first expression for J(\u03b8) is incorrect and should be Q(s_t^0, \u03c0_\u03b8(s_t^0)) instead. This feedback is clear and actionable, providing the authors with a precise correction to make. By addressing this error, the authors can improve the accuracy and correctness of their work. The comment is concise and directly instructs the authors on what needs to be fixed, making it 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues that need attention, including the need for capitalization of certain words in references and the publication details of specific papers. However, it does not provide explicit instructions on how to correct these issues or suggest specific actions for the authors to take. The feedback is vague and lacks concrete guidance, leaving the authors uncertain about how to address the capitalization errors or the publication details. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"p.8\" and \"p. 13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment also specifies the issues, such as the need for capitalization of certain words in references and the publication details of specific papers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a list of observations regarding the capitalization of certain words in references and the publication details of specific papers. These are factual statements that do not contain subjective claims, opinions, or suggestions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several issues with the formatting and capitalization of references, specifically mentioning the need for proper capitalization of words like \"ai\" and \"bayesian\" in various references. It also provides specific examples of papers and their publication details, such as Dusenberry et al. (2020) being published in ICML 2020 and Osawa et al. (2019) in NeurIPS 2019. While the comment highlights important areas for correction, it lacks actionable guidance on how the authors should address these issues or what specific changes are needed. The feedback is 3 as it points out areas for improvement but does not provide detailed instructions for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the model parameters for task 1 and the lambda chosen for the Boltzmann policy. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates might be used. This feedback provides clear and direct actions for the authors to take, specifying what information is missing and what needs to be clarified. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"task 1\" and \"Boltzmann policy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014model parameters for task 1 and the lambda chosen for the Boltzmann policy\u2014and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the model parameters and the choice of lambda for the Boltzmann policy. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model parameters for task 1 and the lambda chosen for the Boltzmann policy are not clearly specified. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates might be used. This feedback is clear and actionable, as it directs the authors to provide additional information that is crucial for understanding the methodology and results of their work. By addressing these points, the authors can improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized the importance of this detail. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model. It asks the authors to provide an explanation for why this might be happening. While the comment implies that the authors should clarify this observation, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine how to address the question themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance impact of applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, and why this might be affecting performance compared to when CBN is applied to layers 4 and 3 only. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model. It asks for an explanation of why this might be happening. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or the need for clarification. Without additional context or analysis, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, particularly layer 2 in addition to layers 3 and 4. It asks for an explanation of why this might be affecting performance compared to when CBN is applied to layers 4 and 3 only. This feedback is 3 as it identifies a potential issue with the experimental setup and prompts the authors to clarify their findings. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. To be more helpful, the comment could include specific questions or suggestions for further investigation. Therefore, it aligns with a score of 3, indicating that the comment provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of comparison with a relevant method proposed by 1, which uses both intertask and intratask ensembles. The reviewer explicitly suggests that the authors should include a method comparison or performance comparison to address this gap. This feedback provides a clear and direct action for the authors to take, specifying what needs to be added to the paper. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with a relevant method proposed by 1, which uses both intertask and intratask ensembles. It explicitly suggests that the authors should include a method comparison or performance comparison. However, the comment does not specify which part of the paper should include this comparison, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors did not include a comparison with a relevant method proposed by 1, which uses both intertask and intratask ensembles. The reviewer provides a specific reference to 1 and suggests that the authors should include a method comparison or performance comparison. This claim is 3 as it references a specific method and provides a logical basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how the comparison would be beneficial. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a relevant method proposed by 1, which uses both intertask and intratask ensembles. It suggests that the authors should include a method comparison or performance comparison to address this gap. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft by incorporating additional comparisons. However, the comment could be more helpful if it offered suggestions on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, leaving the authors uncertain about what specific changes to make to clarify the confusion. As a result, the comment is 1 because it does not offer a clear path for improvement.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the confusion caused by the required implicit call to the Witness oracle. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location for improvement. While the authors might have an idea of where this concept is introduced, the comment lacks full grounding. It is specific in identifying the problem but not in providing detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this confusion or improve the clarity of their explanation. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the limitation of the proposed method in handling headpose and suggests that it should be conditioned similarly to a previous work, Gafni et al. (ICCV 2021). However, it does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate the previous work into their methodology. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore or adapt their approach based on the previous work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the proposed method\"s inability to handle headpose, suggesting that it should be conditioned similarly to a previous work, Gafni et al. (ICCV 2021). This provides a clear direction for improvement, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the methodology or results sections. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the proposed method\"s inability to handle headpose, suggesting that it should be conditioned similarly to a previous work, Gafni et al. (ICCV 2021). The comment implies that the current approach is insufficient and suggests a potential improvement by referencing a previous work. However, it does not provide specific reasoning or evidence to support why the proposed method should be conditioned in this way or how it differs from the previous work. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical issue regarding the proposed method\"s inability to handle headpose, suggesting that it should be conditioned similarly to a previous work, Gafni et al. (ICCV 2021). This feedback is valuable as it points out a potential limitation of the current approach and suggests a direction for improvement by referencing existing work. However, the comment could be more helpful if it provided specific guidance on how to condition the headpose parameters or offered suggestions for integrating the previous work into the methodology. Despite this, the comment is 4 as it identifies a significant area for enhancement and provides a rationale for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both involve artificial patterns appearing rarely in the training set. It references specific works by Chen et al. (2017) and Gu et al. (2019) to support this claim. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate the insights from the referenced works. The action is implicit and vague, as the authors are left to infer that they need to explore or discuss these similarities further. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of spurious features being similar to backdoor triggers, providing examples from Chen et al. (2017) and Gu et al. (2019) to support the claim. This level of detail helps the authors understand what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both involve artificial patterns appearing rarely in the training set. The comment references specific works by Chen et al. (2017) and Gu et al. (2019) to support the claim, providing a logical basis for the assertion. However, the comment could be strengthened by including more detailed comparisons or examples from these references to further substantiate the claim. Overall, the comment is 4, as it provides a clear rationale but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both involve artificial patterns appearing rarely in the training set. It references specific works by Chen et al. (2017) and Gu et al. (2019) to support the claim, providing a clear and actionable insight for the authors. By highlighting this connection, the comment guides the authors to consider the impact of such spurious examples on their model\"s training and generalization. However, the comment could be more helpful if it offered suggestions on how to address or mitigate this issue. Overall, the feedback is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component and has been emphasized multiple times, but it suggests that the optimization algorithm is directly taken from previous works, which reduces the contribution. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the contribution of their work. The comment implies that the authors should clarify the originality of their optimization algorithm, but it lacks concrete steps or specific actions to take. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is a main focus of the paper. However, it does not specify which part of the paper discusses this optimization, making it weakly grounded. The comment is specific in identifying that the optimization algorithm is directly taken from previous works, which reduces the contribution. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization algorithm is directly taken from previous works, which reduces the contribution. However, the comment does not provide specific references or examples to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or examples makes the claim 2, as it requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s focus on structural optimization, noting that the optimization algorithm appears to be directly taken from previous works. This observation could be valuable for the authors to consider, as it highlights a possible lack of originality in their contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their work. While it points out a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipelinestyle method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment does not provide specific guidance on how the authors should address these issues or what changes could be made to improve the results or the introduction of the baseline models. The feedback lacks explicit instructions or concrete suggestions for action, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of a pipelinestyle method with two models, specifically noting that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these experiments or models, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific in detailing the issue with the pipeline method and the lack of introduction of baseline models, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipelinestyle method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipelinestyle method, noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models in the experiments are not well introduced. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors\" attention to areas needing clarification and improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for Visual Question Answering (VQA), specifically citing A. This provides a clear and direct action for the authors to take, ensuring they address the issue of not mentioning related work in the introduction. The comment is specific and gives concrete guidance on what needs to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work on modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of related work on modular networks for VQA, such as A. This provides clear guidance on what the authors should include in their introduction. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction lacks mention of related work on modular networks for Visual Question Answering (VQA), specifically citing A. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of mention of related work on modular networks for Visual Question Answering (VQA). It provides a clear and actionable suggestion by recommending that the authors include such related work, specifically citing A. This feedback is valuable as it directs the authors to a critical aspect of their introduction that needs attention, helping them to enhance the comprehensiveness and depth of their paper. However, the comment could be more helpful if it provided additional context or explanation on why this omission is significant. Overall, the comment is 4, as it effectively guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include a comparison with these methods, but the comment lacks concrete details on how to implement this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should contrast their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it relates to the discussion or results sections. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. However, the comment lacks specific references or detailed reasoning to support this claim. It does not provide examples or comparisons that would help the authors understand the extent of the gap or how to address it. As a result, the claim is 3, as it provides a general observation but lacks the necessary details to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s focus, specifically noting that the authors primarily focus on SSC and do not contrast their method with subsequent methods like TSC and greedy subspace clustering by Park. This is a valuable observation as it highlights an area where the authors could enhance their work by providing a more comprehensive comparison. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional experiments or analyses. While it points out an important area for improvement, the feedback could be more actionable with detailed suggestions. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests renaming a column in Table 1 to clarify the distinction between fully supervised and semisupervised training, and proposes specifying the data used to train different parts of the model with two new columns. These actions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as renaming a column to clarify the distinction between fully supervised and semisupervised training, and suggesting the inclusion of two new columns to specify the data used for training. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between fully supervised and semisupervised training in their proposed method. It provides a specific example by mentioning that the proposed framework row in Table 1 refers to the semisupervised version, and suggests renaming the column to \u201cFully supervised\u201d and proposing two new columns to specify the data used for training. This feedback is 4 as it provides a clear example and logical reasoning for the suggested changes, but it could be strengthened by referencing specific sections or providing more detailed guidance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors clarify the distinction between fully supervised and semisupervised training in their proposed method. It offers a concrete example by pointing out that the proposed framework row in Table 1 refers to the semisupervised version, and suggests renaming the column to \"Fully supervised.\" Additionally, the comment proposes a more comprehensive approach by specifying the data used to train different parts of the model with two new columns: \"Mixture training data\" and \"Single source data.\" This detailed guidance empowers the authors to significantly improve the clarity and organization of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the small contributions of the current work compared to previous methods, such as NCNet 6 and Sparse NCNet 21. It suggests that the work is mostly engineering and points out that it is challenging to differentiate it from its predecessors due to similar performance in practice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their work. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the paper\"s contributions, mentioning \"small contributions over previous methods\" and \"mostly (good) engineering.\" It also notes that it is challenging to differentiate the work from its predecessors due to similar performance. However, it does not specify which part of the paper this critique pertains to, nor does it provide detailed guidance on how to address these issues. The lack of specific references or detailed feedback makes it difficult for the authors to pinpoint areas for improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work has small contributions compared to previous methods like NCNet 6 and Sparse NCNet 21, and that it is mostly engineering. The comment also notes that it is challenging to differentiate the work from its predecessors due to similar performance. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique effectively. The absence of concrete evidence or references to substantiate the claims makes the comment 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment provides a balanced critique of the paper, noting that the contributions are small compared to previous methods like NCNet 6 and Sparse NCNet 21. It also points out that the work is mostly engineering in nature and that it is challenging to differentiate it from its predecessors due to similar performance. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these issues or improve their work. While it identifies areas for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insight but not enough detail to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to remove statements about \"semantic\" segmentation being a lowlevel cue, as it is not accurate. This provides a clear and direct action for the authors to take, leaving no ambiguity about what needs to be done. The comment is specific in its request, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of \"semantic\" segmentation being considered a lowlevel cue, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The comment is specific in its suggestion to remove statements about semantic segmentation being a lowlevel cue, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. It suggests that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. This feedback is clear and actionable, providing the authors with a direct and specific direction for improvement. However, the comment could be more helpful if it offered additional context or suggestions on how to address the issue or why it is important to clarify this point. Overall, the comment is 4 as it effectively guides the authors in making a necessary correction to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning is lower than without a dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or reinforcement learning is not used. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to include these cases in their tables to provide a complete picture of the experiment. The action is implicit and somewhat vague, as it lacks concrete instructions on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the performance comparison between reinforcement learning and dependency tree, and it points out the absence of cases where either component is not used. This provides clear guidance on what needs to be addressed in the tables. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning is lower than without a dependency tree, and that the two tables do not list the cases where either component is not used. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide any references or evidence to substantiate the assertion about the performance comparison or the absence of cases in the tables. This makes the claim 2, as the authors would need to infer the basis of the claim and may require additional information to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning is lower than without a dependency tree. It also points out that the two tables do not list the cases where either dependency tree or reinforcement learning is not used. This feedback is 3 as it highlights a potential gap in the presentation of the results, prompting the authors to consider including these cases in their tables for a more comprehensive analysis. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how to present the missing cases effectively. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comprehensive experimental evaluation across multiple datasets from Federated learning benchmarks. It explicitly suggests that the authors should consider adding results from relevant works like FedProx and FedMAX, which provide details on different datasets and model types. The comment also implies that if the experimental evaluation were more comprehensive, the paper would be stronger. While the action is explicit, it lacks concrete guidance on which specific datasets or aspects to include in the evaluation. Therefore, the comment is 3, as it provides a clear direction but requires the authors to determine the exact implementation details.", "grounding_specificity_rationale": "The comment identifies a specific weakness in the paper, namely the lack of comprehensive experimental evaluation across multiple datasets from Federated learning benchmarks. It explicitly mentions the absence of results on the CIFAR10 dataset and suggests considering other datasets like LEAF, FedProx, and FedMAX. This provides clear guidance on what needs to be addressed in the experimental section. However, the comment does not specify which part of the paper should be revised or how the authors should incorporate these suggestions. While the authors can infer that it pertains to the experiments section, the comment lacks full grounding. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s main weakness lies in the experiments section, specifically noting that the results are limited to the CIFAR10 dataset and do not consider other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 3 as it provides a logical reasoning for the limitation of the experiments, suggesting that the authors should expand their evaluation to include a broader range of datasets. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comprehensive experimental evaluation across multiple datasets from Federated learning benchmarks. It points out that the results are limited to the CIFAR10 dataset and suggests that the authors should consider other datasets like LEAF, FedProx, and FedMAX for a more thorough evaluation. The comment also provides guidance by recommending that the authors consult relevant works for details on different datasets and model types. This feedback is clear and actionable, offering the authors a clear direction for improving their experimental evaluation and enhancing the paper\"s contribution. However, it could be more helpful if it included specific suggestions on how to incorporate these additional datasets or models into the evaluation. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim made in the paper, specifically questioning whether the improvement in accuracy and completeness can be seen from the table. It also suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using additional datasets for further validation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim in question, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the validity of the claim and suggesting the use of another dataset for the ablation study. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper, specifically regarding the improvement in accuracy and completeness as seen in a table. The reviewer suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, to provide additional evidence. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use another dataset is a reasonable one, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the claim made in the paper, specifically questioning whether the improvement in accuracy and completeness can be seen from the table. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, to provide additional evidence. This feedback is 3 as it prompts the authors to consider a more comprehensive evaluation of their claim. However, the comment could be more helpful if it provided specific guidance on how to conduct the additional analysis or why the suggested datasets are appropriate. Overall, the comment offers a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, questioning its ecological validity and suggesting that considering multiple vulnerabilities at a time might be more appropriate. It also points out that the results are difficult to interpret. While the comment highlights potential issues, it does not provide explicit guidance on how the authors should address these concerns or improve their methodology. The authors are left to infer that they need to reconsider their approach and possibly provide more detailed explanations or analyses to address the critique. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete instructions on how to implement them.", "grounding_specificity_rationale": "The comment addresses the methodology for vulnerability discovery, specifically questioning its ecological validity and suggesting that considering multiple vulnerabilities at a time might be more appropriate. It also critiques the results, stating that they are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not direct. The comment is specific in detailing the issues with the methodology and the interpretation of results, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the methodology for vulnerability discovery, questioning its ecological validity and suggesting that considering multiple vulnerabilities at a time might be more appropriate. The reviewer also critiques the results, stating that they are difficult to interpret. While the comment provides some logical reasoning about the potential issues with the methodology, it lacks specific examples or references to previous work that have considered multiple vulnerabilities simultaneously. This makes the claim 3, as the authors would need to further explore and substantiate the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the methodology for vulnerability discovery, questioning its ecological validity and suggesting that considering multiple vulnerabilities at a time might be more appropriate. It also critiques the results, stating that they are difficult to interpret. While the comment identifies potential weaknesses in the methodology, it lacks specific suggestions or guidance on how the authors might address these issues or improve their approach. The feedback provides some insight into areas for improvement but does not offer actionable steps or detailed explanations, making it 3. The authors would need to further explore and address these concerns on their own, which limits the comment\"s usefulness. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It also points out that while Theorem 1 and 2 demonstrate that GCL conforms to a clearer community structure, the relationship with degree bias is not intuitive enough. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is somewhat vague, as it identifies areas for improvement but lacks concrete instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific theorems, Theorem 1 and 2, which are mentioned in the paper. This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment is also specific, as it highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure and points out that the relationship with degree bias is not intuitive enough. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Theorem 1 and 2 prove that GCL conforms to a clearer community structure via intracommunity concentration and intercommunity scatter, but its relationship with degree bias is not intuitive enough.\" This claim is 3 as it references specific theorems and provides a logical reasoning for the lack of intuition regarding the relationship with degree bias. However, the comment lacks detailed examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the relationship between GCL and degree bias is not clearly explained, despite Theorem 1 and 2 demonstrating that GCL conforms to a clearer community structure. This feedback is 3 as it highlights a gap in the explanation that the authors need to address. However, the comment could be more actionable by suggesting specific ways to clarify this relationship or providing examples of how to enhance the explanation. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for specific networks. While the comment highlights a potential issue or area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they need to clarify these aspects, but the comment lacks concrete steps or details on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for specific networks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for specific networks. This is a request for clarification rather than a subjective claim or judgment. It does not contain any opinions, suggestions, or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for specific networks. This is a relevant point that could help the authors clarify their methodology and ensure the accuracy of their results. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies an area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the notation used in the paper, specifically the explicit split between \"static\" and temporal features into two variables. The reviewer suggests that this requires more information than is provided in the paper, such as what S and Xt represent. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the notation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context or explanation regarding the variables S and Xt. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the notation and the explicit split between \"static\" and temporal features into two variables, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion caused by the notation and the lack of information about what S and Xt represent. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation used in the paper is confusing due to the explicit split between \"static\" and temporal features into two variables, specifically mentioning the lack of information about what S and Xt represent. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, particularly the explicit split between \"static\" and temporal features into two variables. It highlights the confusion caused by the lack of information about what S and Xt represent, which is crucial for understanding the notation. While the comment points out a potential area for improvement, it lacks specific suggestions or guidance on how the authors might clarify the notation or provide additional context. This limits the comment\"s usefulness, as it provides some insight but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper deals with many graph notions and suggests that the writing is generally good but could be improved with more details. It specifically mentions the need for more details on the resistance distance and Alg. 1, providing examples of what could be clarified (e.g., definitions of A_t, Y_t, etc.). While the comment identifies specific areas for improvement, it does not explicitly instruct the authors to provide these details. The action is implicit and somewhat vague, as the authors need to infer that they should add more details to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many graph notions\" and \"the writing is generally good,\" allowing the authors to identify the parts of the paper being addressed. It also specifies what needs to be improved, such as providing more details on the resistance distance and Alg. 1, including brief sentences defining terms like A_t, Y_t, etc. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper deals with many graph notions and that the writing is generally good but could be improved with more details. The comment provides specific suggestions for improvement, such as providing more details on the resistance distance and Alg. 1, including brief sentences defining terms like A_t, Y_t, etc. This level of detail offers a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing examples or references to specific sections where these details are lacking. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the complexity of the paper due to its extensive coverage of graph notions but highlights that the writing is generally good. It suggests that more details could be provided, specifically mentioning the need for clearer explanations of the resistance distance and Algorithm 1, including brief definitions of terms like A_t, Y_t, etc. This feedback is actionable as it points out specific areas where the paper could be improved, offering a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it provided examples or suggestions on how to improve these sections. Overall, the comment is 4, as it provides valuable insights and actionable feedback for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the originality of the paper is limited due to the nonnovelty of the main idea of variable splitting and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the originality of their work or suggest ways to differentiate their contribution from existing literature. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the originality of the paper, specifically mentioning that the main idea of variable splitting and the algorithm are not new. However, it does not specify which part of the paper discusses these concepts or how they relate to the originality claim. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks specificity and grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting and the algorithm are not new. However, the comment does not provide any supporting evidence, references, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the originality of the paper is limited due to the nonnovelty of the main idea of variable splitting and the algorithm. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might enhance the originality of their work. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the shape model invariance study, specifically questioning whether the evaluation on transformations of training images is sufficient to prove the point. It suggests that there should be quantitative results on testing images. While the comment implies that the authors should include testing image evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional evaluations on testing images. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the sufficiency of evaluation on training image transformations and suggesting the need for quantitative results on testing images. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images in proving the point about shape model invariance. It suggests that there should be quantitative results on testing images. However, the comment does not provide specific examples, reasoning, or references to support why the current evaluation is insufficient or how testing images would provide a more comprehensive understanding. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the shape model invariance study, specifically questioning whether the evaluation on transformations of training images is sufficient to prove the point. It suggests that there should be quantitative results on testing images to fully substantiate the claim. This feedback is 3 as it highlights a gap in the evaluation process and prompts the authors to consider additional testing image evaluations. However, the comment could be more actionable by providing specific suggestions on how to conduct these evaluations or by offering examples of what kind of quantitative results would be beneficial. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include a discussion and comparison with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. This provides a clear and direct action for the authors to take, specifying what needs to be addressed to improve their draft. The comment is specific and actionable, as it outlines the exact steps the authors should follow to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"AAAI15 paper\" and the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a discussion and comparison with the mentioned paper to provide a better understanding of the stateoftheart. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors missed a related work by Ghoshdastidar and Dukkipati, specifically mentioning the \"AAAI15 paper\" and its relevance to the authors\" work. The comment suggests that this paper should be discussed and compared to provide a better understanding of the stateoftheart. However, the comment lacks specific details or references to the sections of the paper where this comparison should be made, or it does not provide a clear rationale for why this comparison is necessary. As a result, the claim is 3, as it provides a general suggestion but lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a related work that the authors missed, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. It suggests that this paper should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a discussion of this related work in their draft. However, the comment could be more helpful if it provided specific guidance on how to integrate this comparison into the paper or what aspects of the related work should be emphasized. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two main concerns regarding the computational efficiency and scalability of the method. First, it questions the scalability of the method on normal machines with a couple of cores, suggesting that the authors should explore this aspect. Second, it points out a potential issue with the Sinkhorn method, asking how the authors compute exactly optimal transport from the doubly stochastic matrix it produces. While the comment identifies specific areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these concerns. The authors can infer that they need to investigate scalability and clarify the computation of optimal transport, but the lack of concrete steps makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the computational efficiency and scalability of the method, specifically mentioning the time it takes to compute the optimal transport distance on a 36core machine. It also raises a question about how the Sinkhorn method produces a doubly stochastic matrix and how this relates to optimal transport. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing the issues with scalability and the computation of optimal transport, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the computational efficiency and scalability of the method, specifically questioning whether it scales on normal machines with a couple of cores. It also points out a potential issue with the Sinkhorn method, asking how the authors compute exactly optimal transport from the doubly stochastic matrix it produces. While the comment identifies specific areas of concern, it lacks detailed reasoning or references to support these claims. The authors would need to infer the issues and address them, making the comment 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two main concerns regarding the computational efficiency and scalability of the method. It questions the scalability of the method on normal machines with a couple of cores and points out a potential issue with the Sinkhorn method, asking how the authors compute exactly optimal transport from the doubly stochastic matrix it produces. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these concerns. The authors are left with a general idea of what needs to be explored but without detailed direction on how to proceed. Therefore, the comment is 3, as it provides insight into potential weaknesses but does not offer actionable steps for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights that the paper was difficult to follow, despite being read multiple times. However, it does not provide any explicit or implicit suggestions for improvement. The authors are left without guidance on how to enhance the clarity of the experimental procedures and evaluations. Without specific advice or examples, the authors may struggle to address the issue of difficulty in following the paper. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper was difficult to follow, but it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. Additionally, it lacks specificity regarding what aspects of the experimental procedures or evaluations are unclear. Without explicit references or detailed guidance, the authors cannot confidently determine which parts need improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" but it does not provide any specific examples or details to support this claim. Without additional context or evidence, such as unclear sections or procedures, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment highlights a significant issue with the paper\"s readability, noting that it was difficult to follow despite being read multiple times. However, it does not provide specific suggestions or guidance on how the authors might improve the clarity of their experimental procedures or evaluations. Without actionable feedback or detailed examples, the authors are left without a clear path to enhance the comprehensibility of their work. Therefore, the comment is 2, as it identifies a problem but lacks depth and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis and suggests that this might not be an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their draft. Without specific suggestions or actions, the authors are left without direction on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim that \"INRs operate on a perdatainstance basis\" and suggests that this might not be an advantage, providing a clear rationale for why this claim might not be beneficial. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"INRs operate on a perdatainstance basis,\" suggesting that this might not be an advantage. The reviewer provides a logical reasoning by stating that a model capable of handling only a single time series data is almost useless. However, the comment lacks specific examples or references to support the claim that this limitation is a significant drawback. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis, suggesting that this might not be an advantage. The reviewer provides a logical reasoning by pointing out that a model capable of handling only a single time series data is almost useless. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. While it identifies a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. The authors would gain some insight into the issue but would need to explore it further on their own. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a limitation in the experiments, noting that most of them are limited to RoBERTabase and raises the question of whether the results can be generalized to other models with learnable APEs. It suggests investigating the generalization across different model sizes, objective functions, and architectures, such as GPT2. The comment also provides a concrete example by mentioning the inclusion of more analysis and discussion for GPT2, specifically referencing Figure 2. This level of detail provides clear guidance on what the authors should do to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most of the experiments\" and \"Section 4.1.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of generalization to other models with learnable APEs, suggesting the need to investigate differences in model size, objective function, and architecture. The comment further provides a concrete example by mentioning the inclusion of more analysis and discussion for GPT2, particularly referencing Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the experiments, specifically questioning whether the results can be extended to models with learnable APEs beyond RoBERTabase. The reviewer suggests investigating the impact of model size, objective function, and architecture on the results, including GPT2. While the comment provides a logical reasoning for the need to generalize the findings, it lacks specific examples or references to support the claim. The suggestion to include more analysis and discussion for GPT2 is a helpful suggestion but does not provide detailed evidence or references to substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental section, noting that most experiments are limited to RoBERTabase and raises the question of whether the results can be generalized to other models with learnable APEs. It provides a clear and actionable suggestion to investigate the generalization across different model sizes, objective functions, and architectures, such as GPT2. The comment also offers a concrete example by referencing Figure 2 for GPT2, which can guide the authors in expanding their analysis. This feedback is 5 as it directs the authors to a critical area for improvement and provides specific guidance on how to address it, making it a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other areas, such as NLP or simpler models like CNNs, and suggests that the authors should explore this. While the comment implies that the authors should consider generalizing their method to different architectures and tasks, it does not provide explicit guidance on how to implement this exploration. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments or analyses to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the applicability of the model and experiments to other areas, such as NLP or simpler models like CNNs, and suggests that the authors should explore this. The comment provides a clear direction for improvement by highlighting the potential generalization of the method to different architectures and tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the applicability of the model and experiments to other areas, such as NLP or simpler models like CNNs, and suggests that the authors should explore this. The comment implies that the current focus on transformers in vision might limit the generalizability of the method. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning and provide additional context to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant question about the applicability of the model and experiments to other areas, such as NLP or simpler models like CNNs. It suggests that the authors should explore the generalizability of their method beyond transformers in vision. This feedback is valuable as it prompts the authors to consider the broader applicability of their work, which could enhance the paper\"s relevance and impact. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct such an exploration. Overall, the comment is 4 as it identifies an important area for improvement and encourages the authors to consider a broader scope of applications for their method."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate Transferable to Adversarial Samples (TTA) methods on more conditions of natural distribution shift, specifically mentioning WILDS 9. While the comment implies that the authors should conduct additional evaluations, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to implement the suggested evaluation or what specific aspects of WILDS should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance of TTA methods,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting that the authors evaluate TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS 9. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using nonstandard benchmarks breaks popular TTA methods and suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS 9. However, the comment does not provide specific reasoning or evidence to support why nonstandard benchmarks would break TTA methods or how WILDS 9 would enhance the evaluation. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of nonstandard benchmarks in the context of Transferable to Adversarial Samples (TTA) methods. It suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS 9, could strengthen the paper. This feedback is 3 as it points out a specific area for improvement and provides a direction for further exploration. However, the comment could be more actionable by offering specific guidance on how to conduct these evaluations or by suggesting additional references or experiments that could be included. Overall, the comment provides some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the required condition on the learning rate, specifically that it scales with the number of samples, which may not be scalable. The reviewer questions the practicality of this condition, noting that in practice, the step size does not grow with the sample size, which could lead to unreasonably large learning rates on largescale datasets. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The feedback is implicit and lacks concrete details, making it difficult for the authors to know how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the required condition on the learning rate, noting that it scales with the number of samples and questioning its scalability. It also mentions the practicality of this condition, noting that in practice, the step size does not grow with the sample size, which could lead to unreasonably large learning rates on largescale datasets. This provides a clear and specific point of concern, allowing the authors to identify the part of the paper being addressed. However, the comment does not explicitly mention which section or figure this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the learning rate condition, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable. The reviewer supports this claim by noting that in practice, the step size does not grow with the sample size, which could lead to unreasonably large learning rates on largescale datasets. This reasoning is logical and provides a clear explanation of why the condition may not be realistic. However, the comment could be strengthened by referencing specific examples or studies where this issue has been observed, which would make the claim more robust. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could benefit from additional evidence or references.", "helpfulness_rationale": "The review comment identifies a critical issue with the required condition on the learning rate, specifically that it scales with the number of samples, which may not be scalable. The reviewer points out that in practice, the step size does not grow with the sample size, which could lead to unreasonably large learning rates on largescale datasets. This feedback is valuable as it highlights a potential flaw in the theoretical assumptions of the paper, prompting the authors to reconsider the scalability of their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative conditions that could be explored. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that needs further consideration and refinement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the significance of the paper, suggesting that the use of tensor networks to represent PMF of discrete variables is not clearly explained in terms of their utility to machine learning algorithms or their ability to analyze algorithms. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the paper\"s significance. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the significance of the paper, specifically questioning how the use of tensor networks to represent PMF of discrete variables is useful for machine learning algorithms or for analyzing algorithms. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in its critique, it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because it does not clearly explain how tensor networks are useful for machine learning algorithms or for analyzing algorithms. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence leaves the claim 1, as it does not provide a clear path for the authors to address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the significance of the paper, specifically questioning how the use of tensor networks to represent PMF of discrete variables is relevant to machine learning algorithms or for analyzing algorithms. This critique highlights a potential weakness in the paper\"s contribution, suggesting that the authors need to better articulate the practical applications or relevance of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the paper\"s significance. While it identifies an important area for improvement, the feedback could be more helpful if it provided actionable advice or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use a more convincing setting for their experiments, similar to the one used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification by He et al., EMNLP 2018. The comment implies that the authors should directly sample unlabeled data from millions of reviews, which is a specific and concrete action. It provides a clear direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of a more convincing setting similar to the one used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification by He et al., EMNLP 2018. This guidance is specific and provides a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of a perfectly balanced unlabeled dataset is impractical in realworld applications. It suggests that the authors should use a more convincing setting, similar to the one used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification by He et al., EMNLP 2018. The comment provides a reference to a specific study, which supports the claim by offering a precedent for the suggested approach. This makes the claim 4, as it is supported by a relevant reference but lacks detailed reasoning or examples within the comment itself. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a limitation in the use of a perfectly balanced unlabeled dataset from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications. It suggests that the authors should consider a more convincing setting, similar to the one used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification by He et al., EMNLP 2018. This feedback is clear and actionable, providing the authors with a specific reference and a concrete suggestion for improvement. By guiding the authors to adopt a more realistic and practical approach, the comment is 5 in enhancing the relevance and applicability of their work. Therefore, it deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of how to sample from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue with sampling from the leverage score in 3. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their understanding of the sampling process. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the sampling process from the DPP, particularly when the eigenfunctions e_n are inaccessible. It references a similar problem with sampling from the leverage score in 3, which provides some context but does not explicitly mention the section of the paper where this issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in identifying the problem with sampling from the DPP, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue with sampling from the leverage score in 3. The comment suggests that the problem with sampling from the DPP is not fundamentally different from that of the leverage score, implying that the DPP might not offer any advantage in this context. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the DPP sampling is not easier than the leverage score. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the methodology, particularly regarding the sampling process from the DPP when the eigenfunctions e_n are inaccessible. It draws a parallel to a similar problem encountered with sampling from the leverage score in 3, suggesting that the DPP sampling might not offer any advantage over the leverage score. This feedback is 3 as it highlights a potential weakness in the methodology and provides a reference for further exploration. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their understanding of the sampling process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential limitation in the paper, specifically the lack of evaluation on the generalization of observations to fewshot learners beyond Prototypical Networks. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should consider addressing this limitation, but it does not specify how to do so or what specific aspects should be evaluated. Without actionable guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the generalization of observations to fewshot learners beyond Prototypical Networks, which is relevant to the paper\"s contributions. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The authors might infer that it relates to the evaluation or discussion sections, but this inference is not direct. The comment is specific in identifying the need for evaluation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the generalization of observations to fewshot learners beyond Prototypical Networks, which may limit the scope of the submission\"s contributions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, specifically the lack of evaluation on the generalization of observations to fewshot learners beyond Prototypical Networks. This is an important aspect that could impact the scope of the submission\"s contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments or analyses could be conducted to explore this area. While it highlights a critical area for improvement, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that Equation 3 may not adequately address the issue. However, it does not provide explicit guidance on how to improve the approach or suggest specific actions for the authors to take. The comment implies that the authors should consider how to handle the problem mentioned, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the contribution of different modalities and instances, specifically mentioning Equation 3 and its removal of the modal subset of all instances. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the contribution of different modalities and instances, but it lacks grounding as it does not reference a specific section or equation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities and instances, suggesting that Equation 3 may not adequately address the issue. However, the comment lacks specific examples or detailed reasoning to support the claim that Equation 3 fails to handle the problem. Without explicit evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the contribution of different modalities and instances, suggesting that Equation 3 may not adequately address the issue. It provides a specific example of instances with good performance in different modalities and questions the approach taken in Equation 3. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the abstract effectively explains the proposed idea but lacks a description of how the idea was evaluated and the outcomes of these evaluations. It also mentions minor language issues. While the comment identifies a gap in the abstract, it does not provide explicit guidance on how to address this gap or suggest specific improvements. The authors are left to infer that they need to include more details about the evaluation process and outcomes, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the abstract, which is a specific part of the paper, making it fully grounded. It highlights the lack of description on how the proposed idea was evaluated and the outcomes of these evaluations, providing specific feedback on what needs to be included. However, it also mentions minor language issues, which adds some specificity but does not fully address the evaluation aspect. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks a description of how the idea was evaluated and the outcomes of these evaluations. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The mention of minor language issues is also vague and does not provide a basis for improvement. As a result, the comment is considered 1 due to the lack of supporting evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the abstract, noting that it effectively explains the proposed idea but lacks a description of how the idea was evaluated and the outcomes of these evaluations. This feedback is clear and actionable, as it directs the authors to include more detailed information about their evaluation process and results. However, the comment also mentions minor language issues, which could be addressed with a more focused suggestion. Overall, the comment provides valuable guidance for enhancing the clarity and comprehensiveness of the abstract, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a lack of confidence in the experimental results of the paper, particularly regarding the examples used to motivate the solution for POMDP problems with nonconvex value functions. The reviewer points out that there are no experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection, and questions the usefulness of the experiments section. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to include experiments on these specific settings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results of the paper and the specific examples used to motivate the solution for POMDP problems with nonconvex value functions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the experiments, questioning the lack of experiments on the mentioned settings and the usefulness of the experiments section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a lack of confidence in the experimental results of the paper, particularly regarding the examples used to motivate the solution for POMDP problems with nonconvex value functions. The reviewer questions the absence of experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. However, the comment does not provide specific examples or detailed reasoning to support the claim that the experiments are not useful. The lack of detailed justification or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the claim is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment expresses a lack of confidence in the experimental results of the paper, particularly regarding the examples used to motivate the solution for POMDP problems with nonconvex value functions. The reviewer points out that there are no experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection, which makes the experiments section not quite useful. This feedback highlights a significant gap in the paper\"s experimental validation, suggesting that the authors should include experiments on these specific settings to strengthen their claims. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific aspects of the experiments should be explored. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a confusion in the description of the MFDA setting, specifically regarding the use of unlabeled data in source domains. It suggests that the problem setting description differs significantly from the original MFDA paper (Yue et al., 2021a), where the target data is unlabeled. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion or clarify the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description of the MFDA setting. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the description of the MFDA setting, particularly the use of unlabeled data in source domains and the discrepancy with the original MFDA paper (Yue et al., 2021a). The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing due to a discrepancy in the use of unlabeled data in source domains compared to the original MFDA paper. The reviewer provides a specific reference to the original MFDA paper (Yue et al., 2021a) to support the claim, which helps the authors understand the context and the issue. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current description differs from the original, or by explaining why the discrepancy is problematic. Overall, the claim is 4, as it is supported by a reference but lacks additional depth and explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the Method Section, noting the confusion regarding the use of unlabeled data in source domains and the discrepancy with the original MFDA paper (Yue et al., 2021a). It provides a clear and actionable suggestion for clarification, which is valuable for the authors to improve the clarity and consistency of their paper. However, the comment could be more helpful if it offered additional guidance on how to address the confusion or suggested specific ways to clarify the description. Overall, the feedback is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that epochwise analysis, particularly in finite sum settings, could provide insights into the behaviors of optimization algorithms. It provides examples of how this analysis might be useful, such as investigating the effects of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. While the comment provides a clear direction for the authors to consider, it does not specify which aspects of the analysis should be focused on or how to implement this suggestion. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis, particularly in finite sum settings, could provide insights into the behaviors of optimization algorithms. It provides examples of how this analysis might be useful, such as investigating the effects of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. However, the comment does not specify which part of the paper this analysis should be applied to, making it weakly grounded. The suggestion is specific in terms of what could be explored, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis, particularly in finite sum settings, could provide insights into the behaviors of optimization algorithms. It provides examples of how this analysis might be useful, such as investigating the effects of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. While the comment provides some logical reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claim. The authors would need to further explore these ideas to fully understand and address the suggestions. Therefore, the comment is 3, as it provides a basis for the claim but requires additional details to be fully substantiated.", "helpfulness_rationale": "The review comment provides a valuable insight by suggesting that epochwise analysis, particularly in finite sum settings, could offer deeper insights into the behaviors of optimization algorithms. It offers specific examples, such as investigating the effects of batch size or different sampling strategies on the progress of algorithms after each full pass of data, which could be particularly useful for comparative analysis between deterministic and stochastic methods. This feedback is clear and actionable, as it guides the authors on how to enhance their analysis and potentially improve the understanding of optimization algorithm behaviors. However, the comment could be more helpful if it included specific suggestions on how to implement this analysis or provided examples of how it might be applied. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the immense workload and incremental contribution, as well as the lack of proper citations and essential RAG algorithms. It suggests that the paper should include key baselines like MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to incorporate these suggestions or which parts of the paper should be revised. The authors can infer that they need to address these issues, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides a detailed critique of the paper, mentioning specific issues such as the immense workload, incremental contribution, and the lack of proper citations. It also suggests that the paper should include essential RAG algorithms like MedRetriever and KGRAG. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the combination of GraphRAG and GraphCare and the lack of citations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s contribution is incremental and suggests that it is a combination of GraphRAG and GraphCare 1. It also points out the lack of proper citations for key baselines and suggests including essential RAG algorithms like MedRetriever 2 and KGRAG 3. The comment provides specific references to support the claim about the combination of GraphRAG and GraphCare, making the claim 4. However, it could be strengthened by providing more detailed reasoning or examples of how the paper could be improved. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several issues that need to be addressed. It points out that the workload is immense but the contribution is incremental, suggesting that the paper is essentially a combination of GraphRAG and GraphCare 1. Additionally, it notes the lack of proper citations for key baselines and suggests including essential RAG algorithms like MedRetriever 2 and KGRAG 3. This feedback is clear and actionable, offering specific suggestions for improvement that could enhance the paper\"s contribution and comprehensiveness. However, the comment could be more helpful if it provided additional context or explanation on why these suggestions are necessary. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of distinguishing between the three classes of extreme speech, specifically questioning the differentiation between derogatory and exclusionary extreme speech. It provides an example from the sample data file to illustrate the issue, asking why a particular instance is classified as exclusionary extreme speech rather than derogatory. The comment implies that the authors should clarify this distinction, but it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction and provide a rationale for the classification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of distinguishing between the three classes of extreme speech, particularly questioning the differentiation between derogatory and exclusionary extreme speech. The comment provides a concrete example from the sample data file and asks for clarification on the role of local regulation in annotations, which further specifies what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the difficulty in distinguishing between different classes of extreme speech, specifically derogatory and exclusionary. It provides a specific example from the sample data file to illustrate the issue, asking why a particular instance is classified as exclusionary extreme speech. The comment also questions the role of local regulation in annotations and its implications for zeroshot crosscountry classification. This level of detail and specific example provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or literature that address similar classification challenges, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of distinguishing between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file to illustrate the confusion, asking why a particular instance is classified as exclusionary extreme speech. This feedback is clear and actionable, as it prompts the authors to clarify the distinction in their definitions and provide a rationale for the classification. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional examples or references to support the issue. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement is due to the network design exploiting spatial redundancies or the nature of ImageNet, where a large fraction of images can be processed with glances, giving an unfair advantage to algorithms that skip layers or channels. This feedback provides clear and specific actions for the authors to take, including what data to include and what analysis to perform. The explicit nature of the instructions and the detailed guidance on what needs to be addressed make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the need to show a graph of T vs the number of images and Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, including the need to analyze whether the performance improvement stems from the network design or the nature of ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It raises a question about whether the performance improvement is due to the network design exploiting spatial redundancies or the nature of ImageNet, where a large fraction of images can be processed with glances, giving an unfair advantage to algorithms that skip layers or channels. While the comment provides a logical reasoning for the need to include specific data, it lacks specific references or examples to fully substantiate the claim. The authors would need to further develop the rationale to fully understand the basis of the suggestion. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires additional evidence to be fully convincing.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This request is clear and would help the authors better understand the relationship between computational efficiency and performance. Additionally, the comment raises an important question about whether the performance improvement is due to the network design exploiting spatial redundancies or the nature of ImageNet, which is crucial for understanding the limitations and strengths of the approach. By addressing these points, the authors can significantly enhance the clarity and impact of their work. The feedback is detailed and constructive, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should make their explanation more mathematically precise, potentially at the cost of complicating other equations. It also questions the notation used for the loss function, suggesting that it should be introduced beforehand. While the comment implies that the authors should clarify their explanation and introduce notation, it does not provide explicit instructions on how to achieve this. The actions are implicit and somewhat vague, as the authors need to infer the specific changes needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for mathematical correctness and the introduction of notation, allowing the authors to identify the specific parts of the paper being addressed. It also specifies the issue with the notation, suggesting that \"L_l\" should be introduced beforehand. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: questioning the mathematical correctness of the explanation and suggesting that the notation \"L_l\" should be introduced beforehand. The first part is a request for clarification, not a claim, as it does not express an opinion or judgment. The second part also suggests a potential improvement but does not provide a claim or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper. First, it questions the mathematical correctness of the explanation, suggesting that it might be improved to avoid complicating other equations. This is a valuable suggestion that could enhance the clarity and precision of the paper. Second, the comment points out a potential issue with the notation used for the loss function, questioning why it is denoted as \"L_l\" instead of just \"L\" and suggesting that the notation should be introduced beforehand. This feedback is actionable and provides clear guidance on how to improve the paper\"s clarity and consistency. However, the comment could be more helpful if it offered additional context or examples of how to address these issues. Overall, the comment is 4 as it identifies specific areas for improvement and provides actionable suggestions, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the context of sequential ensembling, specifically the potential issue of noise accumulation in homomorphic encryption. It suggests that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit, as the authors can infer that they need to explore ways to mitigate the noise accumulation issue, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to sequential ensembling and the potential problem of noise accumulation in the context of homomorphic encryption. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the context of sequential ensembling, particularly the potential issue of noise accumulation in homomorphic encryption. It highlights that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment points out an important consideration, it lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. The feedback is 3 as it directs the authors\" attention to a critical area that needs exploration, but it does not provide detailed steps or insights for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as both the baseline and timeaware models perform similarly. The reviewer suggests that under different timestep scenarios, the proposed method might be more effective. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or explore different timestep scenarios. The action is implicit and vague, as the authors are left to infer that they need to consider varying timestep scenarios to evaluate the proposed method. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the baseline and timeaware models performing similarly when trained and evaluated with the same timestep, and it suggests considering different timestep scenarios to evaluate the proposed method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same, as both the baseline and timeaware models perform similarly. The reviewer suggests that under different timestep scenarios, the proposed method might be more effective. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3, as it provides some justification but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, noting that both the baseline and timeaware models perform similarly. It suggests that under different timestep scenarios, the proposed method might be more effective. This feedback is 3 as it identifies a potential limitation in the evaluation and provides a direction for further exploration. However, the comment could be more actionable by offering specific suggestions on how to address this issue or by providing examples of scenarios where the proposed method might perform better. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that while the \"Broader Impacts and Limitations\" section mentions that obtaining fully disentangled latent vectors is a limitation, it does not provide specific details on how this is achieved or how it is guaranteed without certain biases. The comment implies that the authors should clarify this aspect in their draft. However, it does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on disentanglement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed and ensuring it is free from certain biases. It references the \"Broader Impacts and Limitations\" section, which provides some context, but the authors may not be able to confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification on how disentanglement is achieved and guaranteed, but it lacks detailed guidance on what specific information is needed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions that obtaining fully disentangled latent vectors is a limitation, but it does not provide specific details on how this is achieved or how it is guaranteed without certain biases. The comment implies that the authors should clarify this aspect, but it lacks explicit examples or references to support the claim. This makes the claim 3, as the authors would need to infer the specific details that need to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the paper\"s explanation of disentanglement. It points out that while the \"Broader Impacts and Limitations\" section mentions that obtaining fully disentangled latent vectors is a limitation, it does not provide specific details on how this is achieved or how it is guaranteed without certain biases. This feedback is clear and actionable, as it directs the authors to clarify and elaborate on the disentanglement process in their work. However, the comment could be more helpful if it provided examples or suggestions on how to address this issue. Overall, the comment is 4 as it highlights a critical area for improvement and prompts the authors to provide more detailed explanations."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity of their proposed method with the previous result in a stronglyconvex concave case. While the comment implies that the authors should apply this standard regularization trick, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use a standard regularization trick and may not be entirely sure how to implement it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how to implement this suggestion. The authors might infer that it relates to the section discussing the complexity or results, but this inference is not direct. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim remains 1, as it lacks the necessary details to substantiate the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with the previous result in a stronglyconvex concave case. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or why it is necessary. The comment highlights a methodological aspect that could enhance the paper\"s rigor but does not offer actionable steps for the authors to take. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This action is explicit, as it clearly states what needs to be added to the graph. The comment also provides a specific reason for this addition, explaining that it would help determine whether mean teacher accelerates or slows down learning. The authors know exactly what action to take and why it is important, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This guidance is precise and helps the authors understand what needs to be added to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This claim is 3 as it provides a logical reasoning for the suggestion, explaining that it could help determine whether mean teacher accelerates or slows down learning. However, the comment lacks specific examples or references to support the claim, which would make it more robust. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This addition would allow the authors to determine whether mean teacher accelerates or slows down learning, providing valuable insights into the impact of these regularization techniques. The comment is clear and directly instructs the authors on how to enhance their analysis and results presentation. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two separate issues. First, it questions how the paper deals with different types of inputs, such as biomedical signals or speech, and suggests that it would be valuable to discuss and present solutions in the paper. This is an explicit action, as it clearly instructs the authors to address this aspect. Second, it mentions that the citation seems disordered, but this part lacks specific guidance on how to improve the citation order. The first part of the comment is 5, while the second part is vague and lacks concrete instructions. Overall, the comment provides a clear action for one part but is somewhat vague for the other, making it 3.", "grounding_specificity_rationale": "The comment addresses two separate issues. First, it questions how the paper deals with different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions. This part is 1 as it does not specify which section of the paper this issue pertains to. Second, it mentions that the citation seems disordered, but this is also 1 as it does not specify which citations are disordered or how they should be ordered. Since the comment lacks specific references or sections, it is 1 at all. The comment is also not specific because it does not provide detailed guidance on how to address the issues of input types or citation order. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises two separate issues: the handling of different types of inputs and the disordered citation. The first part suggests that the paper should discuss and present solutions for dealing with various input types, which is a reasonable suggestion for improvement. However, the comment does not provide specific examples or references to support this claim, making it 3. The second part mentions that the citation seems disordered, but it lacks detailed justification or examples of what constitutes a disordered citation. Overall, the comment is 3 due to the lack of specific evidence or references to support the claim about the citation order.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning how it deals with different types of inputs, such as biomedical signals or speech. It suggests that the paper should discuss and present solutions for handling these diverse inputs, which is a valuable piece of feedback for improving the paper. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending particular methods or approaches. Additionally, the comment mentions that the citation seems disordered but does not offer any specific advice on how to improve the citation order. While the comment highlights an area for improvement, it lacks actionable and detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relationship between Eq. 4 and Eq. 3, specifically asking if the u^l in Eq. 3 tends to be 1 if Eq. 4 stands. This is an explicit question that the authors can directly address by providing an explanation or clarification. Additionally, the comment notes that the improvement of the designed solutions in Table 5 is not significant on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This observation suggests that the authors should consider providing more detailed analysis or justification for the lack of significant improvement. While the comment does not explicitly instruct the authors to do so, the implicit request for further explanation and analysis is clear. Therefore, the comment is 4, as it provides clear guidance on what needs to be addressed but lacks concrete instructions on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment addresses two distinct points. First, it questions the relationship between Eq. 4 and Eq. 3, specifically asking if the u^l in Eq. 3 tends to be 1 if Eq. 4 stands. This part is fully grounded as it explicitly mentions Eq. 3 and Eq. 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the relationship between these equations. Second, the comment discusses the lack of significant improvement in the designed solutions in Table 5, providing specific examples from the OfficeHome dataset. This part is also 5, as it clearly identifies the issue and provides examples. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a question seeking clarification about the relationship between Eq. 4 and Eq. 3, which is a request for explanation rather than a claim. The second part makes a statement about the lack of significant improvement in the designed solutions in Table 5, providing specific examples from the OfficeHome dataset. This statement is 3 as it provides specific data points to support the claim, but it could be strengthened with more detailed analysis or comparison to other datasets. Overall, the comment is 3 due to the specific examples provided, but it could be more robust with additional justification or context.", "helpfulness_rationale": "The review comment addresses two distinct points. First, it raises a question about the relationship between Eq. 4 and Eq. 3, specifically asking if the u^l in Eq. 3 tends to be 1 if Eq. 4 stands. This is a clear and actionable question that the authors can address by providing an explanation or clarification, which would enhance the clarity of their work. Second, the comment notes that the improvement of the designed solutions in Table 5 is not significant on some datasets, such as OfficeHome, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This observation suggests that the authors should consider providing more detailed analysis or justification for the lack of significant improvement. While the comment identifies an area for improvement, it could be more helpful by offering specific suggestions on how to address the issue or by providing additional context or examples. Overall, the comment is 4 as it provides clear feedback on areas that need attention and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a missing reference in the face recognition experiment, specifically mentioning \"Baidu\" work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and providing a link to the work. It also notes that the VRF achieves a higher accuracy than the result in Table 3 of the paper. While the comment explicitly points out the missing reference, it does not provide detailed guidance on how the authors should incorporate this information into their draft. The authors are left to infer that they should include this reference and possibly discuss its relevance to their work. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing stateoftheart references, such as Baidu\"s work, and provides a comparison with the results in Table 3 of the paper. The comment specifies what needs to be addressed, including the inclusion of the missing reference and the discussion of its relevance. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning Baidu\"s work and providing a link to the relevant paper. The comment also compares the VRF\"s performance with the results in Table 3 of the paper, suggesting that the VRF achieves a higher accuracy. This claim is supported by specific references and detailed comparisons, making it 5. The authors can use this information to understand the context and improve their draft by incorporating the missing references and discussing their relevance.", "helpfulness_rationale": "The review comment identifies a specific issue with the face recognition experiment by pointing out the absence of a relevant stateoftheart reference, namely Baidu\"s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It provides a direct link to the work and mentions that the VRF achieves a higher accuracy than the results in Table 3 of the paper. This feedback is clear and actionable, as it directs the authors to include the missing reference and discuss its relevance to their work. By doing so, the authors can enhance the comprehensiveness and credibility of their paper. However, the comment could be more helpful if it suggested how to integrate this information into the discussion or provided additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the generalization. The action is implicit and vague, as it does not specify how to modify the template mapping or what specific changes should be made to enhance generalization. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the question answering process, specifically mentioning the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the potential issue with generalization for questions not classified as \"Whtypes\" or transformable, providing some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, which involves template mapping to transform questions into masked statements, might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It highlights a concern that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment points out a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization. The feedback is 3 as it directs the authors\" attention to a critical area that needs improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform 1 as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this claim or incorporate the cited work into their paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of a volumetric representation in the deformation field, suggesting it is not a novel idea and referencing VolumeDeform 1. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the idea being noninnovative, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform 1 as an example. This provides a specific reference to support the claim, making it more verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from VolumeDeform 1 to fully substantiate the claim. Overall, the comment is 4, as it offers a clear basis for the critique but lacks depth in explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, specifically regarding the use of a volumetric representation in the deformation field. It references VolumeDeform 1 as an example of a similar approach, suggesting that the idea is not novel. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or differentiate their work from existing literature. While it highlights a potential weakness, it lacks actionable feedback or detailed advice, making it 3. The authors would gain some insight into the need for novelty but would need to seek further guidance to fully address the critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it negatively impacts the accuracy scores. The reviewer suggests that this issue should be discussed or acknowledged in the main text with more detail. While the comment implies that the authors should address this point, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand on this issue in their discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the accuracy scores, noting that they have dropped from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in the main text with more detail. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, as evidenced by a drop from 70.4 to 55.6 on TRIP. The comment provides specific numerical data to support the claim, making it 4. However, it could be strengthened by referencing specific studies or comparisons that have shown similar tradeoffs between consistency and accuracy, which would provide additional context and support for the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it negatively impacts the accuracy scores. The reviewer suggests that this issue should be discussed or acknowledged in the main text with more detail. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs further exploration or discussion. By addressing this point, the authors can improve the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to enhance the discussion or presented examples of similar studies that have successfully balanced these aspects. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action that the authors can take to improve their draft by properly attributing the example. The comment provides clear guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to cite the source of the example appropriately. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is clearly inspired by a previous work, and it suggests that the authors should cite the source appropriately. However, the comment does not provide any specific reference or evidence to support this claim, leaving the authors without a clear basis for determining which previous work is being referenced. Without additional context or references, the claim remains 1, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the rockpaperscissors example, noting that it is clearly inspired by a previous work. It provides a clear and actionable suggestion to cite the source appropriately. This feedback is helpful as it guides the authors to properly attribute the example, which is crucial for academic integrity and to avoid plagiarism. However, the comment could be more helpful if it provided additional context or suggested where the example might be found in previous work. Despite this, the comment is 4 as it directs the authors to a necessary improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited nature of the innovations in network architecture design and constraint embedding, noting that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the innovations or improve the performance, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights the limited nature of the innovations in network architecture design and constraint embedding, noting that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper this observation pertains to, such as specific sections, figures, or tables. The authors might infer that it relates to the discussion or results sections, but this inference is not direct. The comment lacks specificity regarding what aspects of the innovations are limited or how the performance is constrained. Therefore, the comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, specifically noting that performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the innovations in network architecture design and constraint embedding, noting that the performance is constrained by the performance of the oracle expert. While it highlights an area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or enhance their work. Without detailed suggestions or examples, the authors are left with a general understanding of the problem but without clear direction on how to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that comparing the model\"s performance only on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also implies that the authors should provide performance comparisons for models pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or which aspects to focus on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of comparing the model\"s performance only on synthetic data, suggesting that demonstrating the importance of the proposed three projection errors is more preferred. It also implies that the authors should provide performance comparisons for models pretrained on synthetic data but finetuned on realworld datasets with different losses. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as demonstrating the importance of the three projection errors and providing performance comparisons. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that comparing the model\"s performance only on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors. The reviewer provides a logical reasoning by suggesting that the authors should provide performance comparisons for models pretrained on synthetic data but finetuned on realworld datasets with different losses. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of the suggested comparisons, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the model\"s performance comparison, specifically noting that it is only evaluated on synthetic data. It suggests that demonstrating the importance of the proposed three projection errors is more preferred and implies that the authors should provide performance comparisons for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, as it provides a specific direction for improving the evaluation of the model\"s performance. However, it could be more helpful if it included examples or detailed guidance on how to conduct these comparisons. Overall, the comment is 4, as it offers valuable insights and suggestions for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should take the embedding of the first subword token as the verb embedding and mentions a common practice of averaging over subword representations, referencing a specific example. This provides clear guidance on what the authors should do to improve their draft, making the comment 5. The explicit suggestion and concrete reference to a common practice give the authors a precise action to take, ensuring they know exactly how to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper, \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the common practice of averaging over subword representations, which is a clear and specific point of concern. The reference to Hewitt and Manning (2019, footnote 4)(https://aclanthology.org/N191419.pdf) further supports the claim with an external reference, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is common to average over subword representations, as evidenced by the reference to Hewitt and Manning (2019, footnote 4)(https://aclanthology.org/N191419.pdf). This provides a specific example of a common practice, making the claim 4. However, the comment could be strengthened by explaining why averaging is a common practice or how it impacts the current work. Overall, the comment is 4 due to the reference, but it could be more robust with additional explanation.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion by pointing out a potential issue with the methodology described in the paper. It highlights that taking the embedding of the first subword token as the verb embedding is a common practice, as evidenced by a reference to Hewitt and Manning (2019, footnote 4)(https://aclanthology.org/N191419.pdf). This feedback is valuable as it directs the authors to consider a common practice and potentially improve their approach by aligning with established methods. However, the comment could be more helpful if it provided additional context or explanation on why this practice is relevant or how it could be integrated into the current work. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risk, which is crucial for the clinical scoring system. It also recommends proving the feasibility of the generated scoring system and discussing the differences between the traditional method and the proposed method. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct these analyses or what specific aspects to focus on. The actions are explicit but somewhat vague, as the authors need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model AUC\" and the \"related studies,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as conducting calibration curves to demonstrate consistency between predicted scores and actual risk, proving the feasibility of the generated scoring system, and discussing the differences between the traditional method and the proposed method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model AUC can assess the discriminant ability but may be difficult to demonstrate consistency between predicted scores and actual risk. It suggests that calibration curves should be used to show agreement and that the feasibility of the generated scoring system should be proven. The comment provides a logical reasoning for the need to address these aspects, particularly in the context of clinical scoring systems. However, it lacks specific examples or references to support the claim about the difficulty in demonstrating consistency. While the reasoning is sound, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s methodology, particularly regarding the assessment of the model\"s discriminant ability and the consistency between predicted scores and actual risk. It suggests conducting calibration curves to demonstrate agreement, which is crucial for clinical scoring systems. Additionally, the comment recommends proving the feasibility of the generated scoring system and discussing the differences between the traditional method and the proposed method. These suggestions are clear and constructive, offering the authors a clear path for improving the paper\"s clarity and relevance. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these analyses. Overall, the feedback is 4, as it effectively directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two observations: the range of ID and OOD not being significantly affected by sparsification, and Lemma 2 requiring an identical mean as an assumption for DICE. It notes that these conditions are crucial for DICE but are not well discussed, particularly regarding how to ensure DICE meets these conditions. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The authors are left to infer that they need to discuss these aspects more thoroughly, but without concrete steps, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the observations about the range of ID and OOD not being significantly affected by sparsification and the requirement for an identical mean in Lemma 2, which is crucial for DICE. The comment further specifies the need for a discussion on how to ensure DICE meets these conditions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes two observations: the range of ID and OOD not being significantly affected by sparsification, and Lemma 2 requiring an identical mean as an assumption for DICE. The comment questions the importance of these conditions for DICE and suggests that they are not well discussed. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed justification or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific observations from Figure 4 and Lemma 2 that are not well discussed in the context of DICE. It points out that the range of ID and OOD does not change much with sparsification, and Lemma 2 requires an identical mean as an assumption for DICE. The comment suggests that these conditions are crucial for DICE but are not adequately addressed in the paper. While the feedback highlights important areas that need further discussion, it lacks specific suggestions or guidance on how to improve the discussion or address these issues. This limits the comment\"s helpfulness, as the authors are left to infer the necessary steps without clear direction. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown at update time. It also suggests that the bolded sections on page 6 should be broken out into separate paragraphs to improve readability. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question and reformat the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of integrating over all possible environments and suggesting that the bolded sections should be broken into separate paragraphs for better readability. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown at update time. It also suggests that the bolded sections on page 6 should be broken into separate paragraphs for better readability. While the comment poses a question and provides a suggestion, it does not contain an opinion, judgment, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of integrating over all possible environments for the update to be meaningful, assuming the true environment is unknown at update time. It also suggests that the bolded sections on page 6 should be broken into separate paragraphs to improve readability. While the comment identifies a potential issue with the presentation of the text, it does not provide specific guidance or suggestions on how to address these concerns. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, suggesting that they are not strong or fair. It questions the use of position kernels in all baselines and suggests that the default settings of these baselines should be considered. Additionally, it points out the absence of baselines related to BO with discrete and categorical variables and recommends comparing the proposed approach with these baselines. The comment also notes that the paper lacks discussion on the limitations or societal impacts of the proposed approach. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific comparisons or detailing the limitations. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses several aspects of the paper, including the experiments, baselines, and societal impacts. It explicitly mentions the use of position kernels in all baselines and suggests comparing the proposed approach with baselines related to BO with discrete and categorical variables. Additionally, it notes the absence of discussion on the limitations or societal impacts of the proposed approach. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of default settings and the comparison with specific baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the experiments, suggesting that they are not strong or fair. It questions the use of position kernels in all baselines and suggests that the default settings of these baselines should be considered. The comment also points out the absence of baselines related to BO with discrete and categorical variables and recommends comparing the proposed approach with these baselines. Additionally, it notes the lack of discussion on the limitations or societal impacts of the proposed approach. While the comment raises valid concerns, it lacks specific examples or references to substantiate the claims about the experiments being weak or unfair. The suggestion to compare with specific baselines could be more robust with additional details. Therefore, the comment is 3, as it provides a logical basis for the claims but lacks detailed evidence or references to fully substantiate the critique.", "helpfulness_rationale": "The review comment provides several valuable insights and suggestions for improvement. It questions the strength and fairness of the experiments, suggesting that the use of position kernels in all baselines could be questioned and that the default settings of these baselines should be considered. The comment also points out the absence of baselines related to BO with discrete and categorical variables and recommends comparing the proposed approach with these baselines. Additionally, it notes the lack of discussion on the limitations or societal impacts of the proposed approach, which is an important area for the paper to address. While the comment identifies several areas for improvement, it could be more helpful by providing specific examples or guidance on how to address these issues. Overall, the feedback is 4 as it directs the authors to important aspects that need attention, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific observation about the correlation dropping after a short period of training and increasing with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes could be made to improve the draft. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific observation about the correlation dropping after a short period of training and increasing with more training iterations. However, it does not specify which part of the paper this observation is made in, such as a particular section, figure, or table. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in detailing what is observed, it lacks grounding as it does not provide enough context or reference to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it impacts the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation dropping after a short period of training and increasing with more training iterations. While it highlights an interesting pattern, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or improve their draft. Without actionable feedback or constructive advice, the authors are left without a clear path to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sparsity patterns and their performance, suggesting that the authors should provide more insight into what is happening. It also mentions the presentation of bits in Section 4.3, indicating that the authors should clarify this aspect. While the comment implies that the authors should provide more detailed analysis or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insight and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the sparsity patterns and their performance, suggesting that the authors should provide more insight into what is happening. It also mentions the presentation of bits in Section 4.3, indicating that the authors should clarify this aspect. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to Section 4.3, but this inference is not direct. The comment is specific in its request for more insight and clarification, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the sparsity patterns and their performance, suggesting that the authors should provide more insight into what is happening. However, it does not make a subjective claim or suggestion that requires verification. It is a request for clarification and does not contain any claims that need justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the sparsity patterns and their performance, suggesting that the authors should provide more insight into what is happening. It also mentions the presentation of bits in Section 4.3, indicating that the authors should clarify this aspect. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider additional analysis or clarification, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or that the paper should mention it. This feedback provides a clear and direct action for the authors to take, specifying what is missing and how it should be addressed. The comment is explicit and concrete, giving the authors a precise understanding of what needs to be corrected or clarified in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the temperature \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature \u03c4 is missing or how it should be included. This lack of detailed explanation or examples makes the claim difficult for the authors to address effectively, rendering the comment 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature \u03c4 is missing and should be included. This feedback is clear and actionable, as it points out a critical omission that could affect the validity and clarity of the paper. By suggesting that the temperature should be shown rigorously or mentioned explicitly, the comment provides the authors with a concrete direction for improving their draft. However, the comment could be more helpful if it offered additional guidance on how to incorporate the temperature or suggested alternative approaches to address the issue. Overall, the comment is 4 as it highlights a significant area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add a citation on differential privacy, specifically mentioning a standard work like 2. This direct and specific instruction provides clear guidance on what the authors should do to improve their draft. The action is explicit and concrete, leaving no ambiguity about how to implement the suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is adding a citation on differential privacy, suggesting a standard work like 2. This provides clear guidance on what the authors should include to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. However, it does not provide any reasoning or justification for why this citation is necessary or how it would benefit the reader. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment is 4 as it provides a specific and actionable suggestion for improvement. By recommending the addition of a citation on differential privacy, it offers a clear direction for the authors to enhance the credibility and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or explanation on why the citation is relevant or how it would benefit the reader. Overall, the feedback is clear and actionable, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two separate points of feedback. The first point questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is 3 as it challenges the claim and prompts the authors to reconsider the assumptions. However, it does not provide specific guidance on how to address this concern or what alternative assumptions might be considered. The second point identifies an error in the inequality on line 310, noting that it has the wrong sign compared to line 227. This is a concrete action that the authors can take to correct the inequality, making this part of the comment 5. Overall, the comment provides a mix of implicit and explicit actions, with one part being 5 and the other 3.", "grounding_specificity_rationale": "The comment addresses two specific parts of the paper. First, it questions the claim in the first paragraph of Section 3.2, suggesting that the assumption about the test set being drawn from the same distribution as the query set is not as extreme as implied. This provides a clear reference to a specific section of the paper, making it fully grounded. Second, it identifies an error in the inequality on line 310, noting that it has the wrong sign compared to line 227. This is also fully grounded as it explicitly mentions specific lines in the paper. The comment is specific in both instances, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim questions the extremity of the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This claim is 3 as it provides a logical reasoning based on common assumptions in machine learning. The second claim identifies an error in the inequality on line 310, noting that it has the wrong sign compared to line 227. This claim is 5 as it provides a specific example of an error that can be easily corrected by the authors. Overall, the comment is 4, as it provides clear reasoning for the first claim and a specific error for the second claim, but could be strengthened with more detailed explanation for the first claim.", "helpfulness_rationale": "The review comment provides two separate pieces of feedback. The first comment challenges the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is 3 as it prompts the authors to reconsider the assumptions and potentially strengthen their methodology. However, it lacks specific guidance on how to address this concern or what alternative assumptions might be considered. The second comment identifies a specific error in the inequality on line 310, noting that it has the wrong sign compared to line 227. This is 5 as it provides a clear and actionable suggestion for the authors to correct the inequality, improving the accuracy of their results. Overall, the comment offers a mix of feedback, with one part being 5 and the other 3, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. Additionally, it recommends including a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. The comment is 5 as it offers specific actions and details on how to address the concerns raised. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to identify the specific parts of the paper being addressed. It also specifies the need for a comparison with other methods like CaCE or raw gradients, as well as a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. This claim is 3 as it provides a logical reasoning for the need for comparison, but it lacks specific examples or references to substantiate the claim fully. The suggestion to include a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space is also a logical recommendation but lacks detailed evidence or references. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should compare their use of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. Additionally, it recommends including a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space, which could enhance the paper\"s discussion. This feedback is clear and constructive, offering the authors a clear path for improving the depth and rigor of their analysis. However, the comment could be more helpful if it provided examples or specific comparisons to guide the authors in making these improvements. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective of the current manuscript to prior efforts. While the action is implied, it is explicit in its request for a comparison. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects should be highlighted. The authors are left to infer that they need to include a comparison, but without detailed instructions, the action remains somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective of the current manuscript to prior efforts. However, it does not specify which part of Section 6 this comparison should be made, leaving the authors to infer that it relates to the entire section. The comment is specific in suggesting a comparison to prior efforts, but it lacks grounding as it does not pinpoint the exact part of the paper that needs this comparison. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective of the current manuscript to prior efforts. However, it does not provide specific examples or references to prior efforts that would make this comparison more concrete. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion without sufficient support or detail.", "helpfulness_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective of the current manuscript to prior efforts. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to consider how their work aligns with or differs from existing contributions. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be highlighted. Without more detailed instructions, the authors may struggle to implement this suggestion effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the performance of the model is closely related to the number of scenarios used for training. It implies that examining the performance with different numbers of scenarios could provide additional insights. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of varying scenario numbers on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests examining the performance with different numbers of scenarios, implying that the number of scenarios used for training might influence the results. However, it does not specify which part of the paper this observation pertains to, such as specific sections or results that should be revisited. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting an area for further exploration but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training, implying that examining performance with different numbers of scenarios could provide additional insights. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the performance of the model is closely related to the number of scenarios used for training. It implies that examining the performance with different numbers of scenarios could provide additional insights. However, the comment does not specify which scenarios should be considered or how this could impact the results, leaving the authors with a general direction but without detailed guidance. While it points out a potential area for improvement, the feedback lacks specificity and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relationship between generating a quality label and the model\"s ability to predict it. It questions whether disturbances in the training data might affect the model\"s performance in generating correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions to take to improve the draft. The action is implicit and vague, as it does not specify how to test the model\"s robustness or what experiments should be conducted. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the relationship between generating a quality label and the model\"s ability to predict it. It questions whether disturbances in the training data might affect the model\"s performance in generating correct quality labels. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this topic is covered, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in its questioning but weakly grounded due to the absence of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the relationship between generating a quality label and the model\"s ability to predict it. It questions whether disturbances in the training data might affect the model\"s performance in generating correct quality labels. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that generating a quality label does not necessarily mean the model can predict it. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the relationship between generating a quality label and the model\"s ability to predict it. It questions whether disturbances in the training data might affect the model\"s performance in generating correct quality labels. This feedback is 3 as it prompts the authors to consider the robustness of their model and the potential impact of data disturbances on its performance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what experiments could be conducted to test the model\"s robustness. While it identifies an important area for consideration, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights that the authors conduct comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their experiments, address potential issues, or provide further analysis. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the authors\" conduct of comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in detailing the types of experiments conducted, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point describes the authors\" conduct of comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment acknowledges the authors\" comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any critical feedback, suggestions, or guidance on how the authors might improve their experiments or address potential issues. Without actionable advice or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the paper\"s approach, noting that it only represents a first step towards real strategic settings. It highlights a discrepancy between the paper\"s claim of \"strategic predictions\" and the fact that the opponent does not behave strategically. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their work to align with the paper\"s claims. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s approach, suggesting that it only represents a first step towards real strategic settings. It highlights a discrepancy between the paper\"s claim of \"strategic predictions\" and the fact that the opponent does not behave strategically. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in its critique but weakly grounded due to the absence of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s approach is only a first step towards real strategic settings, as it does not fully account for the opponent\"s strategic behavior. The reviewer provides a specific critique by stating that the opponent does not behave strategically, which supports the claim. However, the comment lacks detailed examples or references to substantiate the claim further, making it 3. The authors would need to infer the basis of the critique, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s approach, noting that it only represents a first step towards real strategic settings. It highlights a discrepancy between the paper\"s claim of \"strategic predictions\" and the fact that the opponent does not behave strategically. This feedback is 3 as it points out a critical area for improvement, suggesting that the authors need to address the strategic aspects of the opponent\"s behavior. However, the comment could be more helpful if it provided specific suggestions or examples on how to incorporate strategic considerations into the model. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that Appendix A.2 does not clearly illustrate the state space representation of the environment. However, it does not provide any explicit guidance or suggestions on how the authors should improve this illustration. The action is implicit, as the authors can infer that they need to enhance the clarity of the state space representation, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an area for improvement but does not provide specific instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Appendix A.2 does not illustrate the state space representation of the environment clearly.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the state space representation of the environment in Appendix A.2. While it points out a potential area for improvement, it does not provide any suggestions or guidance on how the authors might enhance the clarity of this illustration. Without actionable feedback or detailed suggestions, the authors are left with a general idea of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it highlights a specific area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation of the authors\" approach, noting that it is only applicable to small or mediumscale problems and may not be effective for truly large problems due to overwhelming current LPsolvers. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might adapt their approach for larger problems or suggest alternative methods. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the authors\" approach, noting that it is only applicable to small or mediumscale problems and may not be effective for truly large problems due to overwhelming current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide details on how this limitation affects the approach or suggest ways to address it. Without specific references or detailed guidance, the authors cannot confidently determine which sections or aspects of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and may not be effective for truly large problems due to overwhelming current LPsolvers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The absence of detailed reasoning or evidence makes the claim 2, as it provides a general observation without sufficient justification or examples. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, noting that it is only applicable to small or mediumscale problems and may not be effective for truly large problems due to overwhelming current LPsolvers. This feedback highlights a critical weakness in the scalability of the approach, which is an important consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might adapt their approach for larger problems or what alternative methods could be considered. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential limitation but does not offer detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the bounded noise assumption and suggests that it is somewhat restrictive in stochastic optimization literature. It references several works that have attempted to extend these noise conditions, such as A. Khaled and P. Richt\u00b4arik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate these references into their work. The action is implicit and vague, as the authors are left to infer that they should consider these extensions but are not given concrete steps on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the bounded noise assumption and references specific works that have extended these noise conditions in stochastic optimization literature. However, it does not specify which part of the paper this discussion pertains to, such as a particular section or analysis where the bounded noise assumption is discussed. The authors might infer that it relates to the methodology or assumptions section, but this inference is not direct. The comment is specific in detailing the need to consider extensions of noise conditions, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point discusses the bounded noise assumption and references specific works that have extended these noise conditions in stochastic optimization literature. The mention of these references provides some support for the claim that the bounded noise assumption is somewhat restrictive. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to further explore these references to understand the extent of the restriction and how it impacts the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the bounded noise assumption, which is common but somewhat restrictive in stochastic optimization literature. It provides references to works that have extended these noise conditions, suggesting that the authors could benefit from considering these extensions. However, the comment lacks specific guidance on how the authors might incorporate these references or extend their work in this area. While it offers a direction for improvement, the feedback could be more actionable by providing concrete suggestions or examples of how to integrate these extensions into the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the overall motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might clarify this motivation or what specific aspects need to be improved. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the motivation for using characteristic function regularization. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide details on what aspects of the motivation are unclear or how the authors might address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the motivation for using characteristic function regularization. However, it does not provide specific suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is limited to a combination of existing techniques and claims that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might expand their work or differentiate their contribution from existing literature. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specificity regarding the techniques mentioned, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, specifically mentioning adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer supports this claim by referencing specific works (Lykouris et al., 2018 and Zhou et al., 2021) and notes that the combination of these techniques is not surprising, suggesting that the contribution might be incremental. This provides a logical basis for the claim, as it references specific techniques and their applications, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these techniques are combined or their limitations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the contribution might be incremental, as these techniques are already established. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors could differentiate their work or expand upon these techniques. Without actionable feedback or constructive advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the aggregation operation after \"Integration\" and to provide more details in the main paper. It also mentions acknowledging the structure of other architectures if they are referred to. This feedback is clear and provides concrete guidance on what needs to be done to improve the paper. The authors know exactly what actions to take to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and the \"aggregation operation after \"Integration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the aggregation operation and the need for more details in the main paper. Additionally, it suggests acknowledging the structure of other architectures if they are referred to. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the aggregation operation after \"Integration.\" It provides a clear and actionable suggestion to include more details in the main paper and to acknowledge the structure of other architectures if they are referred to. This feedback is valuable as it guides the authors on how to improve the clarity and comprehensiveness of their work, making it 4. However, the comment could be more helpful if it provided additional context or examples of how to clarify the aggregation operation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies several writing issues, including grammatical errors, abuse of mathematical symbols, and unclear sentences. However, it does not provide specific guidance on which parts of the paper are problematic or how the authors should address these issues. The feedback lacks actionable details, such as examples of grammatical errors or suggestions for improving clarity. As a result, the authors are left without a clear understanding of what needs to be corrected or how to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies several writing issues, such as grammatical errors, abuse of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact areas needing revision. The lack of specific references or examples of the writing issues makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuse of mathematical symbols, and unclear sentences. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed evidence or examples makes the claim 2, as the authors would need to infer the specific problems without clear guidance. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies several writing issues, such as grammatical errors, abuse of mathematical symbols, and unclear sentences, which are common in academic writing. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address these issues. Without detailed guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to improve the draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests that if the figures do not show results for untrained networks, the authors should run corresponding experiments and add these results to the figures and Table 1. Additionally, it clarifies a point about random data in Figure 3c, asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The reviewer also suggests clarifying whether the nonrandom data is normalized and ideally showing examples of the random data in the appendix. These suggestions are concrete and provide clear guidance on what needs to be done to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified and improved, such as the importance of including results for untrained networks, the need to clarify the training of networks on random data, and the suggestion to show examples of random data in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and suggestions for improving the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, identifying areas where the paper could be improved. It suggests that if the figures do not show results for untrained networks, the authors should run corresponding experiments and include these results in the figures and Table 1. Additionally, it clarifies a point about the training of networks on random data, asking for clarification on whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The comment also suggests showing examples of the random data in the appendix, which would provide further clarity. This level of detail and constructive feedback is valuable for the authors, as it guides them on how to enhance the clarity and comprehensiveness of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide any explicit or implicit suggestions for the authors to address this question or clarify the term. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Without any direction or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is being questioned, namely the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"100 steps\" in the context of search models comparison. It seeks clarification on whether this refers to 100 sampled strategies. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it highlights a specific area that needs clarification, but it lacks depth and actionable advice, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the unexplored nature of using energy models for image generation and suggests further exploration. It also points out that the motivation and goals of the model are similar to a prior VAE paper, advising the authors to refer to the related work review for further details. While the comment provides a clear direction for the authors to consider, it does not offer specific guidance on how to conduct the exploration or what aspects to focus on. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the unexplored nature of using energy models for image generation and suggests further exploration. It also points out that the motivation and goals of the model are similar to a prior VAE paper, advising the authors to refer to the related work review for further details. However, the comment does not specify which part of the paper discusses the use of energy models or the related work, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is underexplored compared to GANs and VAEs, suggesting further exploration. It also notes that the motivation and goals of the model are similar to a prior VAE paper, providing a reference to the related work review. This claim is supported by logical reasoning and a reference to a prior study, making it 4. However, the comment could be strengthened by providing more specific examples or detailed comparisons to enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the underexplored nature of using energy models for image generation and suggests further exploration, which is a valuable insight for the authors. It also points out that the motivation and goals of the model are similar to a prior VAE paper, advising the authors to refer to the related work review for further details. This feedback is 3 as it highlights an area for potential improvement and provides a reference for further exploration. However, the comment could be more helpful if it offered specific suggestions or guidance on how to conduct the exploration or how to differentiate the model from the prior VAE paper. Overall, the comment provides some direction but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests repeating the experiments and conducting a statistical significance analysis on the results, which would help determine if the improvement over previous methods is meaningful. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what steps to follow to address the concerns raised. The suggestion to repeat experiments and analyze statistical significance adds specificity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the results, such as the lack of reporting mean and standard deviation, and the difficulty in determining statistical significance. Additionally, the comment suggests repeating experiments and conducting statistical significance analysis, providing clear guidance on how to address these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, with a range of 0.2%1%, and that the results in Table 1 and Fig.5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis. While the comment provides a logical reasoning for the claim about the small improvement, it lacks specific examples or references to support the claim about the lack of mean and standard deviation reporting. This makes the claim 3, as the authors would need to infer the need for statistical significance analysis without explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, with a range of 0.2%1%. It also points out that the results in Table 1 and Fig.5 do not report the mean and standard deviation, making it difficult to determine the statistical significance of the results. The reviewer suggests repeating the experiments and conducting a statistical significance analysis to address these concerns. This feedback is clear and actionable, providing the authors with specific steps to enhance the robustness and reliability of their results. However, the comment could be more helpful if it offered additional guidance on how to conduct the statistical analysis or what specific statistical tests to use. Overall, the comment is 4 as it directs the authors toward improving the quality and significance of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should evaluate their method on a different benchmark, such as Atari, to assess its generalizability to other domains. It provides a clear and concrete action by recommending a specific experiment to be conducted. The suggestion is direct and offers a clear path for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, specifically the tasks from Meta World, a robotic manipulation domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the evaluation, namely the difficulty in judging generalizability to other domains, and provides a concrete suggestion to run experiments on a different benchmark, such as Atari, to verify the method\"s applicability to discrete action spaces and highdimensional observations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on a single domain, Meta World, and suggests that this limits the ability to generalize the results to other domains. The reviewer recommends running experiments on a different benchmark, such as Atari, to address this issue. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the recommendation for using Atari as a benchmark. This makes the claim 3, as the authors would need to further explore and justify the recommendation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on a single domain, Meta World, which is a robotic manipulation domain. This makes it difficult to assess the generalizability of the results to other domains. The reviewer provides a clear and actionable suggestion to run experiments on a different benchmark, such as Atari, which is commonly used in the literature. This recommendation would help the authors verify whether the method works with discrete action spaces and highdimensional observations, thereby enhancing the robustness and applicability of their findings. The feedback is specific and provides a concrete direction for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more detailed analysis of what the model does is missing, which could be interesting. However, it does not provide explicit guidance on what specific analysis is needed or how to conduct it. The suggestion is implicit, as the authors can infer that they need to include an analysis, but it lacks concrete details on how to implement this analysis. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that a more detailed analysis of what the model does is missing, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that an analysis is missing, but it does not provide detailed guidance on what aspects of the model\"s functionality should be analyzed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a more detailed analysis of what the model does is missing, which could be interesting. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general idea but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the strengths of the method and the thoroughness of the experiments but points out a potential area for improvement: a more detailed analysis of what the model does. This feedback is 3 as it identifies a specific aspect that could enhance the paper\"s contribution and understanding. However, the comment lacks depth and does not provide specific suggestions or guidance on how to conduct this analysis, which would make it more actionable. Therefore, the comment offers some insight but does not fully support the authors in making significant improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a lack of clarity in the task setup, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback provides a clear and direct action for the authors to take, which is to clarify these details in their paper. The comment is specific and actionable, as it gives the authors a precise direction on what needs to be addressed to improve the clarity of their task setup. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the task setup, including which notes in the EHR are used as input and how far away the outcomes are from the last note date. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the task setup is not described clearly, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this lack of clarity is problematic or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup in the paper, pointing out that it is not clearly described. It provides a concrete example of what is unclear, such as which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is actionable and provides the authors with a clear direction to improve the clarity and comprehensiveness of their task setup description. By addressing this feedback, the authors can enhance the readability and understanding of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension of the paper. It also provides a specific example of a paper that should be referenced for comparison. The comment is clear and provides concrete guidance on how the authors should reorganize their paper to include the approach section and adjust the use of supplementary material. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the supplementary material, stating that it should be used as additional information rather than an extension of the paper. The comment provides a clear request for the authors to include the approach section in the main paper and adjust the use of supplementary material. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed justification or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of the approach section in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension of the paper. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the structure and organization of their paper. However, the comment could be more helpful if it offered suggestions on how to integrate the supplementary material more effectively or provided examples of how to present the supplementary information. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the statement in the introduction about the biological plausibility of backpropagation is too weak and suggests that it is widely accepted as biologically implausible. However, it does not provide specific guidance on how the authors should address this issue or what changes could be made to strengthen the statement. The comment lacks explicit instructions or concrete details on how to improve the statement, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and 1, as it does not provide actionable feedback for the authors to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, noting that it is too weak and suggesting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, given that it is widely accepted as biologically implausible. This claim is supported by a logical reasoning that references the common acceptance of backpropagation as biologically implausible. However, the comment could be strengthened by providing specific references or examples to substantiate the claim, which would make it 5. As it stands, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the statement about the biological plausibility of backpropagation is too weak and suggests that it is widely accepted as biologically implausible. This feedback is clear and actionable, as it directs the authors to reconsider the phrasing of their statement to make it more accurate and impactful. By addressing this point, the authors can improve the clarity and strength of their introduction, ensuring that their claims are wellsupported and aligned with existing knowledge. Therefore, the comment is 4, as it provides a clear direction for improvement but could be further enhanced with additional suggestions on how to strengthen the statement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the heuristic design of the modulator and suggests that there might be scalability issues requiring tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve the modulator. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the heuristic design of the modulator and suggests that there might be scalability issues requiring hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or where the scalability issues are mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the modulator is discussed, the comment lacks full grounding. It is specific in suggesting that there might be scalability issues, but it does not provide detailed guidance on how to address them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and suggests that there might be scalability issues requiring tedious hyperparameter tuning for diverse training data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the heuristic design of the modulator, suggesting that there might be scalability issues requiring tedious hyperparameter tuning for diverse training data. While it highlights a concern, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the modulator\"s scalability. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without clear steps to resolve it. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the experiments, suggesting that incorporating domain knowledge into the structure of f_R and f_P could be beneficial. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the experiments. The comment implies that the authors should consider reducing the reliance on domain knowledge, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiments performed in the paper, specifically mentioning the use of f_R and f_P. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment does provide some specificity by suggesting that incorporating domain knowledge into the structure of f_R and f_P could be beneficial, but it does not explicitly detail what needs to be addressed or improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that incorporating domain knowledge into the structure of f_R and f_P could be beneficial, but it does not provide specific examples or reasoning to support this claim. The comment lacks detailed evidence or references to substantiate the assertion that a less informed f_R/f_P would require impractical amounts of data. Without concrete examples or further explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, specifically noting that incorporating domain knowledge into the structure of f_R and f_P could be beneficial. However, it does not provide specific suggestions or guidance on how to address this issue or what changes could be made to improve the experiments. While the comment highlights a potential area for improvement, it lacks actionable feedback or detailed advice, making it 3. The authors may gain some insight into the need for domain knowledge integration but would need to explore the comment further to fully understand and address the feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the necessity of obtaining labeled data for imitation learning and points out the absence of experiments on the challenges of obtaining this data and the impact of labeled data size on performance. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should conduct experiments to explore these aspects but lacks concrete steps or details on how to implement this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of obtaining labeled data for imitation learning and points out the absence of experiments on the challenges of obtaining this data and the impact of labeled data size on performance. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for experiments on data acquisition challenges and performance variations with different data sizes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of obtaining labeled data for imitation learning and questions the absence of experiments on data acquisition challenges and performance variations with different data sizes. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that these experiments are missing or necessary. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some indication of a potential issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of experiments on the challenges of obtaining labeled data for imitation learning and how performance might vary with different sizes of labeled data. This feedback is 3 as it highlights an area that could be explored to strengthen the paper. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular experiments or analyses to conduct. While it points out a potential weakness, the comment could be more actionable with additional details or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of overparameterization on generalization, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they need to explore or clarify this aspect, but the comment lacks concrete steps or details on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the implications of overparameterization on generalization, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. However, it does not specify which part of the paper this concern is related to, such as a particular section or discussion on generalization bounds. The authors might infer that it relates to the sections discussing generalization or overparameterization, but this inference is not direct. The comment is specific in its questioning but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the implications of overparameterization on generalization, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. The reviewer provides a logical reasoning by noting that overparameterization can lead to memorization and good generalization, but it is unclear if this connection is relevant to the paper\"s context. The comment is 3 as it provides a logical basis for the concern but lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the implications of overparameterization on generalization, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. It highlights a potential issue that the authors acknowledge in the conclusion but does not fully address. The comment provides a logical reasoning for the concern but lacks specific suggestions or guidance on how the authors might explore or clarify this aspect. While it identifies a potential weakness, it does not offer actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might explore these implications or what specific steps they should take to enhance the generalizability of their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the limitation but lacks grounding as it does not provide clear guidance on which parts of the paper should be revised or expanded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but lacks thorough exploration of the implications for other NLP tasks, limiting the generalizability of the results. While the comment identifies a potential limitation, it does not provide specific examples or detailed reasoning to support the claim. The lack of explicit evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential gap in the generalizability of the results, which is an important consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might explore these implications or enhance the generalizability of their findings. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative terminology. The comment implies that the authors should clarify the use of \"certificate\" to avoid confusion, but it lacks concrete steps or suggestions for implementation. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the term \"certificate\" at line 267, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the potential misinterpretation of the term \"certificate\" due to its strong meaning in complexity theory. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or evidence makes the claim 1, as it does not provide a clear basis for the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors clarify their terminology to avoid confusion for readers. However, the comment does not provide specific suggestions or examples of how to address this issue, such as alternative terms or contexts where \"certificate\" is appropriately used. While it highlights a potential area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the recent findings regarding untrained neural networks used for inverse problems in imaging, as demonstrated by Ulyanov et al. in CVPR 2018. It also recommends placing the current method in context and ideally comparing it with these methods. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate these references or conduct the comparison. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the OOD experiments\" and \"inverse problems in imaging,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests mentioning recent findings regarding untrained neural networks used for inverse problems, placing the current method in context, and ideally comparing it with these methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current method\"s ability to generalize outofdistribution (OOD) is interesting, but it also suggests that recent findings regarding untrained neural networks, such as those by Ulyanov et al. (CVPR 2018), could be relevant. The comment provides a logical reasoning by referencing a specific paper, which supports the claim. However, it could be strengthened by explaining how these findings relate to the current work or why they are relevant. Overall, the comment is 4, as it provides a clear reference and logical reasoning, but it could benefit from more detailed explanation or examples.", "helpfulness_rationale": "The review comment is 4 as it identifies an interesting aspect of the OOD experiments and suggests placing the current method in context by mentioning recent findings regarding untrained neural networks used for inverse problems in imaging. It provides a clear direction for the authors to enhance the paper by comparing their method with these recent findings. However, the comment could be more helpful if it included specific references or examples of these recent findings, or if it offered more detailed guidance on how to integrate this information into the paper. Overall, the feedback is actionable and provides valuable insight for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments are limited to toy data and suggests that the method\"s performance should be evaluated on a range of real data problems where barycenters can be used. While the comment implies that the authors should consider expanding their experiments to include realworld scenarios, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are limited to toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used. However, the comment does not specify which part of the paper discusses the experiments or where the suggestion to expand the data set is made, making it weakly grounded. The comment is specific in suggesting that the authors should consider realworld data scenarios, but without explicit references, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that the method\"s performance should be evaluated on real data where barycenters can be used. However, the comment does not provide specific examples of real data problems or references to studies that have successfully applied barycenters in such contexts. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the relevance of the suggestion without explicit support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are limited to toy data. It suggests that the method\"s performance should be evaluated on realworld data where barycenters can be used, which is an interesting and relevant area for further exploration. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or what specific realworld data sets could be considered. The feedback is 3 as it points out a potential direction for enhancing the study, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that more experiments on deeper networks, such as ResNet50 and MobileNet, are needed to strengthen the paper. It also provides specific references to support the suggestion, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. This explicit guidance on what additional experiments to conduct and which references to use provides clear and concrete actions for the authors to take. The inclusion of references ensures that the authors have a clear understanding of the direction to follow, making the comment 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on deeper networks, such as ResNet50 and MobileNet, to strengthen the paper. It provides specific references to support the suggestion, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. However, the comment does not specify which part of the paper these experiments should be conducted on, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting additional experiments and providing references, but it lacks grounding in terms of where these experiments should be integrated into the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50 and MobileNet, are needed to strengthen the paper. It provides specific references to support this suggestion, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. These references offer a logical basis for the claim, as they demonstrate the potential benefits of exploring these network structures. However, the comment could be strengthened by providing a more detailed explanation of how these experiments would enhance the paper or by discussing the specific aspects of the current experiments that could be improved. Overall, the comment is 4, as it is supported by references but could benefit from additional explanation.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks, such as ResNet50 and MobileNet, are needed to strengthen the paper. It provides specific references to support this suggestion, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. This feedback is clear and actionable, as it guides the authors on what additional experiments to conduct and which references to include to support their claims. However, the comment could be more helpful if it provided a brief explanation of how these experiments would enhance the paper or discussed the potential benefits of exploring these network structures. Overall, the comment is 4, as it offers valuable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the proposed sample selection mechanism and its role in preserving the label distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects they should consider to clarify the mechanism. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the proposed sample selection mechanism and its role in preserving the label distribution. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its inquiry, it lacks grounding as it does not provide enough context or references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the proposed sample selection mechanism and its role in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the proposed sample selection mechanism and its role in preserving the label distribution. While it identifies a potential area of confusion, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the mechanism. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential weakness but does not offer actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results/analysis, despite being detailed and comprehensive, only evaluate two relatively old and small models. This feedback highlights a potential limitation in the scope of the evaluation. However, it does not provide explicit guidance on how the authors should address this issue or suggest additional models to include. The action is implicit, as the authors can infer that they need to expand the evaluation to include more models, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the results/analysis, noting that despite being detailed and comprehensive, only two relatively old and small models are evaluated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation of evaluating only two models, but without clear guidance on how to address this issue, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results/analysis, despite being detailed and comprehensive, only evaluate two relatively old and small models. This claim is 3 as it highlights a potential limitation in the scope of the evaluation. However, the comment lacks specific examples or references to support the claim, such as mentioning specific models or providing context on why these models are considered \"old and small.\" This makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the results/analysis, noting that despite being detailed and comprehensive, only two relatively old and small models are evaluated. This feedback highlights a gap in the scope of the evaluation, suggesting that the authors should consider expanding their evaluation to include more models. While the comment points out a specific area for improvement, it lacks detailed guidance or suggestions on how to address this issue or what additional models could be considered. The feedback is 3 as it prompts the authors to broaden their evaluation, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem in the current stochastic problem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should consider improving the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit guidance on how to implement this reformulation or what specific changes should be made to Algorithm 1. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the suggestion to reformulate the proxlinear subproblem using the conjugate function and claims that this would make the motivation of Algorithm 1 unclear. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in the current stochastic problem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning based on the potential reformulation, but it lacks specific examples or references to support the claim fully. The authors would need to explore this idea further to understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential reformulation of the proxlinear subproblem in the context of a stochastic problem, suggesting that it can be reformulated using the conjugate function to align with the subproblem in Algorithm 1. This insight could enhance the motivation and clarity of Algorithm 1 by providing a clearer rationale for its design. However, the comment does not offer specific guidance on how to implement this reformulation or what specific improvements it would bring. While it provides a valuable observation, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the relationship between KD (Knowledge Distillation) and LS (Label Smoothing) and suggests that KD can be viewed as a special form of LS under certain conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might explore this relationship further or incorporate it into their work. As a result, the comment lacks actionability, leaving the authors without any clear steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), acknowledging that they are not identical but suggesting that KD can be viewed as a special form of LS under certain conditions. However, the comment does not specify which part of the paper this discussion pertains to, such as a particular section, table, or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its analysis of the relationship between KD and LS, but without clear grounding, it does not provide the authors with precise guidance on how to improve their draft. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment does not provide any detailed reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), noting that they are not identical but suggesting that KD can be viewed as a special form of LS under certain conditions. This observation provides a valuable insight into the theoretical underpinnings of the methods discussed in the paper. However, the comment does not offer specific suggestions or guidance on how the authors might explore or utilize this relationship in their work. While it highlights an important aspect of the paper, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity in terms of actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should include more recent works and results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. It provides a clear and concrete action by specifying the need to include results on largescale datasets and mentions the inclusion of more recent works. This feedback is direct and provides specific guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Competing dynamicpruning methods\" and \"ImageNet,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more recent works and results on largescale datasets like ImageNet to further verify the effectiveness of the proposed method. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only includes results on smallscale datasets and suggests including results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. While the comment highlights a potential limitation in the scope of the experiments, it does not provide specific examples or references to support the claim that the competing dynamicpruning methods are outdated. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only includes results on smallscale datasets and suggests that more recent works and results on largescale datasets, such as ImageNet, should be included to further verify the effectiveness of the proposed method. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the comprehensiveness and robustness of their experimental results. By suggesting the inclusion of more recent and diverse datasets, the comment empowers the authors to make significant improvements to their draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data. This is a direct and clear request for clarification, giving the authors a specific action to take. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the degradation in performance when using additional information about missing, wrong, or redundant data. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the performance degradation observed when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is a request for clarification regarding the performance degradation observed when using additional information about missing, wrong, or redundant data. It is specific and actionable, as it prompts the authors to provide an explanation for this phenomenon, which could help them understand and address the issue. However, the comment could be more helpful if it suggested potential causes or provided guidance on how to investigate the issue further. Overall, the feedback is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific sections of the paper that are difficult to read and suggests that the author should provide clearer explanations of the methods. It includes specific examples, such as the stacked LSTM in Figure 2(a) and the sentence in line 96, which are not clearly explained. The comment implies that the authors should elaborate on these points to improve readability. While the action is implicit, the authors can infer that they need to provide clearer explanations for the methods mentioned. However, the comment does not specify how to improve the explanations, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the first two sections, and provides detailed examples of what is unclear, like the explanation of the stacked LSTM in Figure 2(a) and the sentence in line 96. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what needs to be addressed, such as the lack of clarity in explaining the stacked LSTM and the sentence in line 96. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are difficult to read due to unclear explanations of the methods. The reviewer provides specific examples, such as the stacked LSTM in Figure 2(a) and the sentence in line 96, to illustrate the lack of clarity. However, the comment does not provide detailed reasoning or references to support why these examples are unclear or how they could be improved. This makes the claim 3, as the authors would need to infer the issues and address them themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific sections of the paper that are difficult to read, particularly the first two sections. It highlights the lack of clarity in explaining the methods, such as the stacked LSTM in Figure 2(a) and the sentence in line 96. By pointing out these specific areas of confusion, the comment provides the authors with clear and actionable feedback on how to improve the readability and clarity of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of clearer explanations. Overall, the feedback is 4 as it directs the authors\" attention to critical areas needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and that the authors should explain the \"scramble network\" better. While the comment explicitly states the need for more descriptive captions and provides a specific suggestion about explaining the scramble network, it does not offer detailed guidance on how to achieve these improvements. The authors are given a clear direction to enhance the clarity of their captions and explanations, but the comment lacks concrete steps on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive and explains the \"scramble network\" better. However, it does not specify which captions or figures are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need improvement. Additionally, while the comment provides a general suggestion to improve the clarity of captions and explanations, it lacks specific guidance on how to achieve this. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive and that the \"scramble network\" should be better explained. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the captions should be more descriptive and that the \"scramble network\" should be better explained. While it identifies areas for improvement, it lacks specific guidance or examples on how to enhance the captions or clarify the explanation of the scramble network. The feedback is 3 as it points out potential weaknesses, but it does not provide actionable steps for the authors to take to address these issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to increase task difficulty. It implies that the authors should provide a clearer rationale for this choice. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explain the motivation for this choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of randomly sampled CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice, asking why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to increase task difficulty. While the comment raises a valid concern about the lack of motivation, it does not provide specific examples or references to support the claim that this choice is not well motivated. The authors are left to infer the reasoning behind the critique, making it 3. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the motivation behind using randomly sampled CIFAR images as backgrounds to increase task difficulty. It questions why this particular choice is considered interesting, prompting the authors to provide a clearer rationale for their experimental design. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a gap in the paper\"s analysis, specifically the missing analysis on the flatness of the minima. It explains that while the paper argues for the flat minima, the analysis is incomplete because it only considers the averaged loss across noiseinjected models and provides convergence analysis on this loss. The comment suggests that to claim the flatness of the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional analysis on the losses of the noiseinjected models. The comment also provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of flatness, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis, namely the missing analysis on the flatness of the minima. The comment provides a clear suggestion for improvement by recommending that the authors conduct additional analysis on the losses of the noiseinjected models after training. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s argument about the proposed method finding flat minima is not supported by an analysis of flatness. The reviewer points out that the loss used for training the base model is the averaged loss across noiseinjected models, and while convergence analysis is provided, it does not ensure the flatness of the minima. The comment suggests that to claim the flatness of the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noiseinjected models after training is required. This claim is 4 as it provides a logical reasoning and a specific suggestion for improvement, but it could be strengthened with more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper\"s analysis, specifically the missing analysis on the flatness of the minima. It points out that while the paper argues for the proposed method finding flat minima, the analysis is incomplete because it only considers the averaged loss across noiseinjected models and provides convergence analysis on this loss. The comment suggests that to claim the flatness of the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required. This feedback is clear and actionable, providing the authors with a specific direction to enhance their analysis and improve the paper\"s claims. However, it could be more helpful if it included suggestions on how to conduct this additional analysis or provided examples of how to interpret the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the text inside the figure and the labels are too small to read without zooming and suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to adjust the font size of the text in the figure and labels to match the size of the manuscript text. The comment is specific and concrete, giving the authors precise guidance on how to improve the readability of their figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the text is too small to read without zooming, and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels is too small to read without zooming, suggesting that they should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the overall presentation of the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the text in the figure and labels, noting that they are too small to read without zooming. It suggests that the text should be roughly the same size as the manuscript text, which is a clear and actionable piece of feedback. This feedback is valuable as it provides the authors with a concrete step to improve the readability and accessibility of their figures, ensuring that the visual elements align with the textual content. By addressing this issue, the authors can enhance the overall quality and clarity of their manuscript. Therefore, the comment is 4, as it offers clear guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This feedback provides a clear and direct action for the authors to take, which is to revise the introduction. However, it does not specify how to make the introduction clearer or what specific changes are needed. While the action is explicit, the lack of detailed guidance on how to improve the introduction makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction is unclear or how it should be revised. This lack of detail makes it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is not clear and suggesting that the introduction should be revised to make the paper easier to follow. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to enhance the introduction or examples of what could be improved. Despite this, the comment is 4 as it highlights a critical area for revision, guiding the authors toward a more coherent and understandable presentation of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that while it is intuitive to include multiple local prompts, the features and their positions vary across different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes could be made to improve the draft. Without specific suggestions or actions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of including multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the problem with the inclusion of multiple local prompts, but it lacks grounding as it does not reference a specific section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that including multiple local prompts is intuitive, but notes that the features and their positions vary across different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the inclusion of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation highlights a potential inconsistency or lack of clarity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the consistency of their approach. Without actionable feedback or detailed advice, the authors are left with a general observation that lacks practical value. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the validation of the alignment between relabeled reward data and human annotator judgments. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should validate this alignment more thoroughly, but it lacks concrete steps or examples of how to do so. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the validation of the alignment between relabeled reward data and human annotator judgments. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for validation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the validation of the alignment between relabeled reward data and human annotator judgments. It highlights a gap in the paper that needs to be addressed to ensure the reliability of the experimental results. However, the comment does not provide specific suggestions or guidance on how the authors might improve this validation process. While it points out an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading, possibly with reference to the supplement. It implies that the authors should consider improving the presentation. The suggestion to replace some of the natural language descriptions with notation and to add breakout diagrams showing the attention mechanisms provides concrete actions for the authors to take. This feedback is explicit and offers specific guidance on how to enhance the clarity and readability of the model presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation, suggesting the replacement of natural language descriptions with notation and the addition of breakout diagrams to illustrate attention mechanisms. This level of detail provides the authors with a clear understanding of what needs to be addressed and how to do it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading, possibly with reference to the supplement. The reviewer recommends improving the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment provides a logical suggestion for enhancing clarity, it lacks specific examples or references to support the claim that the model is complicated or that the current presentation is insufficient. This makes the claim 3, as the authors would need to infer the basis of the suggestion and may require further elaboration to fully understand the reasoning behind it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the model and suggests ways to improve its presentation in section 4. It recommends replacing natural language descriptions with mathematical notation and adding breakout diagrams to illustrate attention mechanisms. This feedback is actionable and provides specific suggestions for enhancing the clarity and readability of the model presentation. By offering concrete steps, the comment empowers the authors to make significant improvements to their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or improve their experimental setup. The action is implicit and vague, as it does not specify how to expand the experiments or what additional experiments could be conducted to enhance the method\"s value. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation of conducting experiments on a limited number of molecules and providing indistribution testing for these samples. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the experimental scope and suggests that the method\"s value would be limited if it requires training for each molecule individually. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples, suggesting that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim is considered 2, as it provides some reasoning but lacks the necessary details to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that this limitation could limit the value of the method if it requires training for each molecule individually. This feedback is 3 as it highlights a critical weakness in the experimental design, prompting the authors to consider the scope and applicability of their method. However, the comment could be more helpful if it provided suggestions on how to address this limitation or expanded on the implications of the limited experimental scope. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to simplify the symbols, which would be necessary for the authors to improve the clarity of their work. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the complexity of symbols used in the paper, which is a specific issue. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where symbols are used. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the problem with the symbols, but without grounding, it lacks actionable guidance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not provide any specific examples or references to support this claim, nor does it offer any suggestions for simplification or improvement. Without detailed evidence or reasoning, the claim remains 1, making it difficult for the authors to address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out that the symbols used in the paper are complicated and timeconsuming to understand. While it identifies a potential issue with the clarity of the paper, it lacks specific suggestions or guidance on how the authors might simplify the symbols or improve their presentation. Without actionable feedback or detailed examples, the authors are left without a clear path to address the concern. Therefore, the comment is 2, as it highlights a problem but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about Figure 3, specifically about the origin of the test data and whether there is a ground truth available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the test data and its source. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the origin of the test data and the availability of a ground truth, which provides a direct point for the authors to address. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the origin of the test data and the availability of a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about Figure 3, asking for clarification on the origin of the test data and whether a ground truth is available. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the clarity and comprehensiveness of their work. By addressing this question, the authors can improve the transparency and reproducibility of their results. However, the comment could be more helpful if it suggested ways to address the issue or provided examples of how to clarify the figure. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, has been used in most experiments except Experiment 1b. The reviewer questions whether adding periodicity to the spectral kernel would be sufficient to capture all results at a similar level to the explicitly compositional model. While the comment poses a question, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of periodicity on their model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiment 1b\" and \"all of the experiments except Experiment 1b,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. The comment further suggests a potential modification to the comparison model by adding periodicity to the spectral kernel to capture results at a similar level to the explicitly compositional model. This provides clear guidance on what needs to be addressed or explored in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, has been used in most experiments except Experiment 1b. The reviewer questions whether adding periodicity to the spectral kernel would be sufficient to capture all results at a similar level to the explicitly compositional model. While the comment poses a logical question, it lacks specific examples or references to support the claim that periodicity is a critical factor. This makes the claim 3, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an important question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model used in most experiments cannot capture periodic relationships, except for Experiment 1b. The reviewer questions whether adding periodicity to the spectral kernel would be sufficient to capture all results at a similar level to the explicitly compositional model. This feedback is valuable as it prompts the authors to consider the role of periodicity in their results and explore potential modifications to their model. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this question or what experiments could be conducted to test the hypothesis. Overall, the comment is 4 as it identifies a critical area for further exploration and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. It also points out that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific suggestions or actions for the authors to take to improve the writing or formatting. It lacks concrete guidance on what aspects of the writing or formatting need improvement or how to address the issues. As a result, the authors are left without clear direction on how to enhance their draft, making the comment 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, especially in figures and tables. However, the comment does not specify which sections of the paper are poorly written or lack proper presentation, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while it points out the need for better presentation and formatting, it does not provide specific suggestions on how to achieve this. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, especially in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or examples of what is missing in the presentation or formatting, the authors may find it challenging to address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment indicates that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. It also points out that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment lacks specific suggestions or actionable feedback on how to improve the writing or formatting. It does not provide detailed guidance on what aspects of the presentation or formatting need enhancement, leaving the authors with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on what aspects of orthogonality should be elaborated upon or how to enhance the detail. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking in detail or what specific aspects of orthogonality need to be expanded upon. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be detailed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it could be improved. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of orthogonality should be expanded upon or how to enhance the detail. This limits the utility of the feedback for the authors, as it does not offer actionable steps for improvement. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the novelty of the paper\"s contribution, suggesting that the result about optimal regularization removing double descent might not be as novel as it appears, given prior work on samplewise multiple descent in linear regression. However, it does not provide explicit guidance on how the authors should address this concern or how they might highlight the novelty of their result. The comment implies that the authors should clarify the novelty of their contribution, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper\"s contribution, specifically questioning whether the result about optimal regularization removing double descent is novel given prior work on samplewise multiple descent in linear regression. However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the novelty of the result, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of the paper\"s contribution by referencing prior work on samplewise multiple descent in linear regression. It suggests that the paper should better highlight the novelty of its result in relation to prior results. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper\"s contribution is not novel. The lack of explicit evidence or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s contribution, specifically questioning whether the result about optimal regularization removing double descent is novel given prior work on samplewise multiple descent in linear regression. This feedback is 3 as it prompts the authors to reconsider the novelty of their contribution and to better highlight it in relation to prior results. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or clarify the novelty of their result. While it identifies an area for improvement, it does not provide actionable steps for the authors to take, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the proposed methods, noting that they are two independent methods with little inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the connection between the methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically mentioning the contrastive training objective and contrastive search. However, it does not specify which part of the paper these methods are discussed in, making it weakly grounded. The comment does specify the issue, which is the lack of inner connection between the two methods in terms of intuition and algorithm. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are two independent methods with little inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed methods, noting that they are two independent methods with little inner connection in terms of intuition and algorithm. This feedback highlights a gap in the paper that could impact the coherence and effectiveness of the proposed approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connection between the methods. While it points out a problem, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions highlight areas that need clarification, they do not provide explicit instructions or suggestions for the authors to address these issues. The authors are left to infer that they need to explain the discrepancies and possibly conduct additional ablation studies. However, the comment lacks concrete guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking why the results of Table 6 are not aligned with Table 1 and what about the ablation studies of MCT without the adaptive metrics. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the results and methodology, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or recommendations that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions: one about the alignment of results between Table 6 and Table 1 (MCTpair), and another about the ablation studies of MCT without the adaptive metrics. While the comment identifies areas that need clarification, it does not provide actionable feedback or suggestions on how the authors might address these issues. The questions prompt the authors to consider potential discrepancies or omissions in their analysis, but without further guidance, the authors may struggle to determine the exact steps to take. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses have been conducted in prior works, suggesting that the current work may not offer novel contributions. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve their draft. The comment implies that the authors should consider how their work differs from existing studies, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not provide the authors with clear direction on how to enhance their work. Therefore, it is rated as a 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, such as \"RobustBench\" and \"CIFAR10.1, CINIC10, CIFAR10C,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, and it provides examples of these analyses, such as the study on the robustness of CIFAR10 models on distribution shifts. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, specifically mentioning \"RobustBench\" and citing a relevant reference. It also provides examples of these analyses, such as the study on the robustness of CIFAR10 models on distribution shifts. The inclusion of specific references and examples supports the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or additional references to fully substantiate the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overlap with prior works, specifically mentioning that similar analyses have been conducted on distribution shifts, such as in RobustBench and other studies. It provides specific examples, like the work on CIFAR10.1, CINIC10, and CIFAR10C, which were also studied in this work. This feedback is 3 as it highlights areas where the current work may not offer novel contributions, prompting the authors to consider how their work differs or how it can be differentiated from existing studies. However, the comment could be more helpful if it offered suggestions on how to address these overlaps or how to differentiate the current work. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks used in the bAbi dataset are too simplistic and could be solved by the final model. It implies that more detailed discussions are needed to justify the choice of subtasks. However, the comment does not provide specific guidance on how to address this issue or what additional discussions are required. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the subtasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks used in the bAbi dataset are too simplistic and could be solved by the final model, implying that more detailed discussions are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more discussions are required, but without clear guidance on what those discussions should include, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the 10 subtasks used in the bAbi dataset are too simplistic and could be solved by the final model, suggesting that more detailed discussions are needed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 2, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment points out that the 10 subtasks used in the bAbi dataset are too simplistic and could potentially be solved by the final model. It suggests that more detailed discussions are needed to justify the choice of subtasks. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance or suggestions on how to address this concern or what additional discussions would be beneficial. The feedback is 3 as it highlights a potential weakness, but it could be more actionable with more detailed guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or an extension to longer subsequences. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider whether the restriction is a limitation or if it can be extended, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or an extension to longer subsequences. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the restriction, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or an extension to longer subsequences. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this restriction is considered limiting or to suggest how it could be addressed. Without additional context or justification, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or an extension to longer subsequences. While the comment identifies a potential limitation in the approach, it does not provide specific guidance or suggestions on how the authors might address this issue or explore longer subsequences. The feedback is 3 as it prompts the authors to consider the implications of their current restriction, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also mentions the absence of related work, which seems relevant to the paper\"s novelty. However, the comment does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the term and possibly include related work to support their claims. The action is implicit and somewhat vague, as it lacks concrete instructions on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the term \"sequence of episodes\" and suggesting that practice and evaluation might be the two types of this sequence. Additionally, it points out the absence of related work, which is relevant to the paper\"s novelty. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also mentions the absence of related work, which seems relevant to the paper\"s novelty. However, the comment lacks specific examples or references to support the claim that the work is novel or that the term \"sequence of episodes\" is unclear. Without detailed justification or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the term \"sequence of episodes\" and suggests that practice and evaluation might be the two types of this sequence. It also points out the absence of related work, which seems relevant to the paper\"s novelty. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies areas for clarification and potential weaknesses, it does not provide actionable feedback or detailed advice, making it 3. The authors are left to infer the necessary changes, which limits the utility of the comment. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions whether the study about different subdomain sizes is an \"ablation\" study, suggesting that it is not because the authors are not removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the study to make it an ablation study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions whether the study about different subdomain sizes is an \"ablation\" study, suggesting that it is not because the authors are not removing a component of the method. However, it does not specify which part of the paper this study is located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the study need to be clarified or addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions whether the study about different subdomain sizes is an \"ablation\" study, suggesting that it is not because the authors are not removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the classification of the study on different subdomain sizes as an \"ablation\" study. It points out that the authors are not removing a component of the method, which is a key characteristic of ablation studies. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their study. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor for semantic segmentation, given that it uses similar operators. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor for semantic segmentation, given that it uses similar operators. This provides clear guidance on what aspect of the paper needs further consideration or clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification or suggestion, rather than making a subjective claim or judgment. It does not contain any opinions, assertions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor for semantic segmentation, given that it uses similar operators. This question prompts the authors to consider an additional aspect of their work that could potentially enhance its applicability or relevance. However, the comment does not provide specific guidance or suggestions on how to address this question or what potential benefits might arise from including AccNet. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the new proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what additional steps could be taken to improve the evaluation. Without specific guidance or recommendations, the authors are left without a clear understanding of how to enhance the robustness or generalizability of their proposed metric. As a result, the comment lacks actionability, as it does not offer any actionable steps for the authors to take. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the new proposed metric is only tested on a single dataset, which is a specific issue. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation of testing on a single dataset, but without clear guidance on how to address this issue, the authors may find it challenging to improve their draft. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which is a limitation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the validity of the metric. Without additional context or explanation, the authors may find it difficult to understand the importance of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the new proposed metric, noting that it is only tested on a single dataset. This is a relevant observation that could impact the validity and generalizability of the proposed metric. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or methods for broader evaluation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture against other architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture against other architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include comparisons with AutoDial and AdaBN, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture against other architectural competitors like AutoDial and AdaBN. However, the comment does not provide specific examples or references to these competitors, making it difficult for the authors to understand the exact nature of the suggested comparisons. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific comparisons needed to strengthen the evaluation.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the evaluation section of the paper. It suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture against other architectural competitors, such as AutoDial and AdaBN. This feedback is actionable and offers a clear direction for enhancing the robustness and comprehensiveness of the evaluation. However, the comment could be more helpful if it provided additional context or explanation on why these specific competitors are relevant or how they might impact the evaluation. Overall, the comment is 4 as it guides the authors on a meaningful enhancement to their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of definition for abbreviations like \"NE\" and the undefined superscript notation in Equation 6, which can hinder understanding. It also provides references to papers that discuss similar issues. While the comment identifies specific areas needing clarification, it does not explicitly instruct the authors to define the abbreviations or clarify the notation. The references are provided for context, but the action is implicit and somewhat vague. Therefore, the comment is 3, as it gives a clear idea of what needs to be addressed but lacks concrete guidance on how to implement the changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and equations, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the undefined abbreviations and the undefined superscript notation in Equation 6, which hindered understanding. Additionally, the comment provides references to relevant literature, which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined and that the superscript notation in Equation 6 is undefined, which hinders understanding. The comment provides references to papers that discuss similar issues, which adds credibility to the claim. However, the explanation could be more detailed, such as specifying which abbreviations are undefined and how the undefined notation affects the understanding of the paper. Overall, the comment is 4, as it provides some support but lacks detailed reasoning or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the lack of definition for abbreviations like \"NE\" and the undefined superscript notation in Equation 6, which can hinder understanding. It also provides references to relevant literature that discuss similar issues, which adds context and helps the authors understand the significance of these problems. While the comment highlights important areas for clarification, it could be more helpful by offering specific suggestions on how to define the abbreviations or clarify the notation. Overall, the feedback is 3 as it points out critical areas needing attention but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the evaluation or the baselines, leaving the authors without any clear direction on how to address the issue. As a result, the comment lacks actionability, as it does not offer any actionable steps for the authors to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation being weak and the baselines not being designed for fair classification. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of specific details about the baselines or the evaluation process further complicates the authors\" ability to address the issue. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation in the paper, specifically noting that the baselines used are not designed for fair classification. This feedback is valuable as it highlights a critical weakness in the methodology, which could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but requires further elaboration to be fully comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting in the first three paragraphs of section 2 is not clearly spelled out, which could lead to confusion about the authors\" intentions. It suggests that the authors might be trying to present a more general approach than what is actually implemented, which could muddle the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be spelled out more clearly. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of their explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in spelling out the setting in these paragraphs. The comment suggests that the authors might be trying to present a more general approach than what is actually implemented, which could muddle the exposition. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the setting in the first three paragraphs of section 2 is not clearly spelled out, potentially leading to confusion about the authors\" intentions. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the authors are trying to present a more general approach than what is actually implemented. As a result, the claim is not wellsupported, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors might be trying to present a more general approach than what is actually implemented, which could lead to confusion in the exposition. While the comment highlights a potential weakness, it lacks specific guidance or suggestions on how the authors might clarify the setting or improve the exposition. This limits the comment\"s usefulness, as it provides insight into a problem but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of using old baselines like R3D and C3D for the experiments and suggests that the proposed method should be compared to more recent 3D CNNs like X3D and SlowFast. It implies that the authors should consider whether their method offers advantages over these newer approaches. While the comment suggests a specific area for improvement, it does not provide explicit instructions or concrete steps on how to conduct this comparison or what specific advantages to highlight. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and determine the exact nature of the advantage. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments and the choice of baselines, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it questions the choice of baselines and suggests comparing the proposed method to more recent 3D CNNs like X3D and SlowFast, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that the proposed method should be compared to more recent 3D CNNs like X3D and SlowFast, which are known for reducing computational complexity. The comment implies that the proposed method may not offer a significant advantage over these newer approaches. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the experiments are not convincing. It provides a logical suggestion for improvement but does not offer detailed evidence or references to support the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of baselines in the experiments, questioning whether the proposed method offers a significant advantage over existing approaches. It suggests comparing the method to more recent 3D CNNs like X3D and SlowFast, which are known for reducing computational complexity. This feedback is 3 as it prompts the authors to consider a more comprehensive evaluation of their method against stateoftheart approaches. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what specific advantages the proposed method might have over the suggested baselines. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of how the attention module is integrated into the ResNet20 architecture during the search process. It specifically asks for clarification on the number of attention modules used, their placement, and whether they are placed after each block or stage. The comment implies that the authors should provide a detailed explanation to address this lack of clarity. While the action is implicit, it is concrete because it specifies what needs to be clarified. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"ResNet20 architecture,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of unclear integration details, asking for clarification on the number of attention modules used, their placement, and whether they are placed after each block or stage. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the attention module is integrated into the ResNet20 architecture during the search process. It specifically asks for clarification on the number of attention modules used, their placement, and whether they are placed after each block or stage. While the comment identifies a potential area of confusion, it does not provide any supporting evidence, reasoning, or references to justify the claim. This makes the claim 2, as the authors would need to infer the need for clarification themselves.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module into the ResNet20 architecture during the search process. It asks for clarification on the number of attention modules used, their placement, and whether they are placed after each block or stage. This feedback is clear and actionable, as it prompts the authors to provide detailed information that would enhance the clarity of their methodology. By addressing this feedback, the authors can improve the transparency and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions: the precise bitrate range used for BDrate comparison and a suggestion to include a related work about implementing a content adaptive algorithm in learned video compression. While the first question is explicit, the second suggestion is implicit, as it implies that the authors should consider discussing or comparing their method with the referenced work. The comment provides some guidance but lacks concrete instructions on how to address the first question or how to incorporate the suggested related work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific aspects of the paper: the performance of the proposed method at different bitrates and the suggestion to include a related work on content adaptive algorithms in learned video compression. The first part of the comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"low bitrate\" performance, allowing the authors to identify the relevant sections. The second part suggests a related work, which is also fully grounded as it mentions a specific paper by Guo Lu et al. However, the comment lacks specificity regarding what aspects of the proposed method\"s performance at high and low bitrates need clarification or improvement. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point consists of two parts: questioning the performance of the proposed method at low bitrates and suggesting a related work for discussion. The first part is a question seeking clarification, which does not contain a claim. The second part suggests a related work, which is a request for discussion rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific points for the authors to consider. First, it questions the performance of the proposed method at low bitrates, specifically asking for clarification on the precise bitrate range used for BDrate comparison. This is a clear and actionable suggestion that could help the authors refine their results and provide a more accurate analysis. Second, the comment suggests including a related work about implementing a content adaptive algorithm in learned video compression, referencing a specific paper by Guo Lu et al. This is a valuable suggestion that could enhance the paper\"s context and relevance. Overall, the comment provides clear and actionable feedback that can guide the authors in improving their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should differentiate between the allornothing or cutoff phenomenon and usual statistical bounds, which are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction clearer, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine how to implement this differentiation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this differentiation. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify the exact areas needing revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should differentiate between the allornothing or cutoff phenomenon and usual statistical bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is important or how it impacts the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should differentiate between the allornothing or cutoff phenomenon and usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is 3 as it identifies a potential area for clarification that could enhance the paper\"s understanding and relevance. However, the comment lacks specific guidance on how to achieve this differentiation or why it is crucial for the paper\"s context. Without detailed suggestions or examples, the authors may struggle to incorporate this feedback effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, it does not provide explicit guidance on what specific improvements should be made or how the analysis should be expanded. The comment implies that the authors should conduct additional analysis, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements on three tasks over previous works and selfimplemented baselines, indicating that these improvements are marginal. It also suggests that further analysis beyond the main experiments is not sufficient. However, the comment does not specify which tasks or experiments are being referred to, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing the issue of marginal improvements and insufficient analysis, but without explicit grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to previous works or selfimplemented baselines, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. This feedback highlights a potential gap in the paper\"s results and analysis, indicating that the authors need to provide more comprehensive evidence or deeper exploration of their findings. However, the comment lacks specific suggestions or guidance on how to address this issue or what additional analysis might be necessary. While it identifies a critical area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates depend on Theorem 8, which is located at the end of the appendix. However, it does not provide any guidance on how the authors should address this issue or improve the clarity of the proof. The comment lacks explicit instructions or concrete suggestions for the authors to make the proof clearer or more understandable. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the proof of Theorem 8. The comment highlights a specific area that needs attention, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. However, the comment does not provide any specific reasoning or examples to support why the proof is unclear or how it affects the overall understanding of the convergence rates. Without detailed justification or references, the claim remains 1, as it lacks the necessary evidence or explanation to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all linear convergence rates depend on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it highlights a potential area of confusion for readers, specifically the lack of clarity in the proof of Theorem 8. However, the comment does not provide any suggestions or guidance on how the authors might improve the clarity of the proof or address the issue. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without clear steps to resolve it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper. First, it points out a potential inaccuracy in the description of the Walkman algorithm, suggesting that it is not accurate to claim that all works are based on simple SGD for decentralized optimization. This feedback is explicit and provides a clear action for the authors to correct the statement. Second, it highlights an issue with the reference to \"It\" in Section 3, which lacks a clear reference, making it difficult for the authors to understand what is being referred to. While the first part is explicit, the second part is somewhat vague, as it does not provide specific guidance on how to resolve the reference issue. Overall, the comment is 4, as it provides clear guidance on one part and a general suggestion on another, but the second part could be more detailed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it provides detailed feedback on the inaccuracies in the description of the Walkman algorithm and the reference to \"It\" in Section 3, which lacks clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim is based on a specific reference to the Walkman algorithm and its solution using ADMM, which is clearly supported by the mention of Mao et al., 2020. This provides a solid foundation for the claim, making it 5. The second claim addresses a reference in Section 3, which lacks a clear reference, making it 3. The comment provides a logical reasoning for the first claim but lacks detailed explanation for the second, which is why it is categorized as 3. Therefore, the overall assessment is consistent with the labels provided.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct aspects of the paper. First, it points out a potential inaccuracy in the description of the Walkman algorithm, suggesting that it is not accurate to claim that all works are based on simple SGD for decentralized optimization. This feedback is clear and provides a concrete suggestion for improvement. Second, the comment highlights an issue with the reference to \"It\" in Section 3, which lacks a clear reference, making it difficult for the authors to understand what is being referred to. While the first part is 5, the second part is less so due to its vagueness. Overall, the comment is 4 as it provides clear guidance on one aspect and a general suggestion on another, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation of the main theoretical result, which requires Gaussian features and noise, a strong assumption. It suggests that the authors should compare their rates to existing literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and determine the best way to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the main theoretical result in the paper, specifically noting that it provides utility guarantees only under the assumption of Gaussian features and noise. This allows the authors to identify the specific part of the paper being discussed, making the comment fully grounded. The comment also suggests comparing the rates achieved by the proposed procedure to existing rates in the literature, which provides a clear direction for improvement. However, the comment does not specify which specific rates or comparisons are needed, making it specific but not fully detailed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper is limited to Gaussian features and noise, which is a strong assumption. It also suggests that the authors should compare their rates to existing literature. While the comment highlights a limitation, it lacks specific examples or references to support the claim about the strength of the assumption. The suggestion to compare rates to existing literature is logical but lacks detailed guidance on how to do so. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s main theoretical result, which requires Gaussian features and noise. It highlights this as a strong assumption, especially since previous algorithms do not rely on this requirement. The comment suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable piece of feedback for improving the paper\"s relevance and impact. However, the comment could be more helpful if it provided specific examples of existing literature or detailed guidance on how to conduct this comparison. Overall, the feedback is 4 as it points out a critical area for improvement and suggests a meaningful direction for further analysis, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This is an explicit suggestion for an action, as it clearly states what the authors should do to improve their draft. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects of the comparison should be emphasized. While the action is clear, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made in, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a comparison, but without clear grounding, it is challenging for the authors to know where to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This claim is 3 as it provides a specific suggestion for comparison, which could help the authors understand the potential benefits of their extension. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to explore this suggestion themselves to fully understand its implications.", "helpfulness_rationale": "The review comment suggests a specific comparison between the proposed extension and the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their draft by including a comparison with a wellestablished method. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what aspects of the comparison should be emphasized. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method, as there are several works that focus on the same questions. While the comment implies that the authors should add more experiments, it does not specify which additional baselines or works should be included or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer which specific experiments to add and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to include more experimental comparisons to demonstrate the effectiveness of the proposed method. The comment suggests comparing with additional works, such as 1,2,3, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include more comparisons with existing works to demonstrate the effectiveness of the proposed method. The comment provides a specific example of works that focus on similar questions, such as 1,2,3, which supports the claim. However, the comment lacks detailed reasoning or examples of how these additional comparisons would enhance the paper or why they are necessary. While the suggestion is logical, the lack of specific guidance or detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their method with two baselines. It suggests that there are other works that focus on similar questions and implies that adding more experimental comparisons would better demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s experimental section. However, it could be more helpful if it offered specific examples of the additional works or detailed guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their experimental evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the paper. The suggestion is concrete, as it outlines the specific changes required to enhance the paper\"s results and conclusions. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that presenting average results on the test set would be more convincing. However, the comment lacks specific examples or references to support the claim, such as which studies or methods are typically used for presenting such results. This makes the suggestion 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the dev set with hyperparameter search and model selection on the dev set, which is not sufficient for convincing evidence. The reviewer strongly suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing the authors with a specific direction to improve the robustness and reliability of their results. By addressing this suggestion, the authors can enhance the credibility and comprehensiveness of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the study, including the number of topics, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents in the training and testing sets. These questions imply that the authors should provide more detailed information about the dataset and its parameters in the main paper. While the actions are implicit, they are concrete and specific, as they clearly outline what information is missing and how it should be presented. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the study, specifically regarding the number of topics, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents in the training and testing sets. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or dataset description sections. The comment is specific in detailing what information is missing, such as the number of topics and the size of the dataset. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the study, including the number of topics, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents in the training and testing sets. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the dataset used in the study, specifically regarding the number of topics, the method for obtaining topicword parameters, the size of the AG news dataset, and the number of documents in the training and testing sets. These questions highlight areas where the authors need to provide more detailed information in their paper. By addressing these questions, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized the importance of these details. Overall, the feedback is 3 as it identifies specific areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat limited, as it only compares against three basic alternatives and ignores other NAS approaches like supernet and oneshot methods. However, it does not provide explicit guidance on how the authors should address this limitation or what specific comparisons should be included. The action is implicit, as the authors can infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BRPNAS\" and the analysis on it, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited comparison to only three basic alternatives and the omission of other NAS approaches like supernet and oneshot methods. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is somewhat limited, as it only compares against three basic alternatives and ignores other NAS approaches like supernet and oneshot methods. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand the extent of the limitation or how to address it. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet and oneshot methods. This feedback is 3 as it highlights a gap in the analysis that the authors should consider expanding to provide a more comprehensive evaluation. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provided examples of other NAS approaches that could be included. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a preference for focusing on the main point of the paper, which is the effectiveness of prototypes for fewshot learning, rather than the zeroshot version and its connection to density estimation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve the paper\"s focus. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these aspects are distracting from the main point of the paper. However, it does not specify which part of the paper discusses these elements, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in identifying the issue of distraction from the main point but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a distraction in the paper, specifically the zeroshot version and its connection to density estimation, which are considered more of an aesthetic argument than a technical one. This feedback is 3 as it highlights an area that could be improved by focusing more on the main point of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or integrate these elements more effectively. Therefore, the comment offers some insight but lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address this issue or what specific details should be included. The action is implicit and somewhat vague, as the authors know they need to provide more information but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking\u2014more information on the translation and filtering methodology. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that details about the filtering process used to create the Arabic climate change QA dataset are lacking. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to fully substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized the importance of this detail in the context of the study. Overall, the comment is 4 as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiment results are lacking in terms of different attacks and thresholds, which could influence the detection performance. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback implies that the authors should consider adding more experiments or analyses to explore the impact of different thresholds and attacks, but it lacks concrete instructions on how to implement these suggestions. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiment results are lacking in terms of different attacks and thresholds, and how different thresholds influence detection performance. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors might infer that it relates to the experimental results section, but this inference is not direct. The comment is specific in identifying the need for more varied attacks and thresholds, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results are lacking in terms of different attacks and thresholds, and how they influence detection performance. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results section, noting that the results are lacking in terms of different attacks and thresholds, and how they influence detection performance. This feedback is 3 as it highlights a gap in the analysis that the authors should address. However, the comment does not provide specific suggestions or guidance on how to enhance the experiment results or what additional experiments or analyses could be conducted to address the identified issue. While it points out a direction for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should train a discriminator on the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4, where the discriminator is coadapting with the generator and might get stuck at a local optimum. While the comment provides a clear action\u2014training a discriminator and comparing it to Figure 1\u2014the lack of specific guidance on how to implement this training or what specific aspects to focus on makes the action somewhat vague. The authors know they need to perform this task, but the comment does not provide detailed instructions on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should train a discriminator on the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. Additionally, it clarifies the difference between Figure 1 and Figure 4, noting that the discriminator in Figure 4 coadapts with the generator and might get stuck at a local optimum. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should train a discriminator on the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4, where the discriminator coadapts with the generator and might get stuck at a local optimum. The comment provides a logical reasoning by explaining the difference between the two figures and the implications of this difference. However, it lacks specific examples or references to support the claim fully, which could enhance the verifiability. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the evaluation of the paper\"s claim regarding reducing exposure bias. It recommends training a discriminator on the learned model to confirm the claim, similar to Figure 1, and highlights the difference between this approach and Figure 4, where the discriminator coadapts with the generator. This feedback is actionable and offers a clear direction for the authors to enhance their evaluation process, potentially leading to more robust conclusions. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or what specific aspects of the evaluation should be focused on. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their evaluation methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify the impact of using different image sizes and variations of ResNets on the performance difference. While the comment implies that the authors should provide more information or analysis regarding this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional details or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the impact of using different image sizes and variations of ResNets on performance differences. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the impact of using different image sizes and variations of ResNets on performance differences. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is a request for clarification regarding the impact of using different image sizes and variations of ResNets on performance differences. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice or detailed feedback, making it 3. It gives the authors a direction to consider but does not fully support their need for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, specifying that they need to include a detailed description of the Algorithm. The comment is specific and concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not specify which part of the paper this Algorithm is discussed in, making it weakly grounded. The comment is specific in its request for a detailed description of the Algorithm, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail to aid in understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by enhancing the clarity and comprehensibility of the Algorithm description. However, the comment could be more helpful if it offered additional guidance on how to effectively present the Algorithm or what aspects of the Algorithm should be emphasized. Despite this, the comment is 4 as it directs the authors toward a significant improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a runtime comparison at test time, given that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup. While the action is implied, it is explicit in its request for a comparison. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on, making the action somewhat vague. The authors can infer that they need to include a runtime comparison, but the lack of detailed instructions on how to do so makes the action 3.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison at test time, given that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a runtime comparison, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from including a runtime comparison at test time, given the mention of using Chebyshev polynomials for speedup. This feedback is 3 as it identifies a potential area for improvement that could enhance the paper\"s contribution and clarity. However, the comment lacks specificity regarding which aspects of the runtime comparison should be included or how it would be conducted, leaving the authors with a general direction but without detailed guidance. To be more helpful, the comment could specify what kind of runtime comparison would be most informative or how it would demonstrate the benefits of using Chebyshev polynomials. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method beyond digit or text images, specifically asking if it can be used on natural images like CIFAR10. While the comment implies that the authors should consider expanding the scope of their method, it does not provide explicit guidance or suggestions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the method\"s applicability to natural images. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method beyond digit or text images, specifically mentioning MNIST, SVHN, and CIFAR10. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the method is described. The comment is specific in its inquiry about the applicability of the method to natural images, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method beyond digit or text images, specifically mentioning MNIST, SVHN, and CIFAR10. While the comment raises a relevant question about the method\"s potential applications, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the applicability of the proposed method beyond digit or text images, specifically questioning its use on natural images like CIFAR10. This feedback is valuable as it prompts the authors to consider the broader applicability and potential realworld relevance of their method. However, the comment lacks specific suggestions or guidance on how the authors might explore this aspect further or what additional experiments or analyses could be conducted to address the question. While it identifies an important area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while the style design is clean, the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezing together. This feedback highlights a specific issue with the organization of the prompts, suggesting that the authors need to improve the structure or spacing of these sections. However, the comment does not provide explicit guidance on how to reorganize the prompts or suggest specific changes to achieve better organization. The action is implicit and somewhat vague, as the authors can infer that they need to reorganize the prompts but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the organization of the prompts, noting that all sentences squeeze together. This provides clear guidance on what needs to be addressed in terms of improving the organization of the prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences squeeze together. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim about the organization of the prompts. Without additional context or explanation, the authors may find it challenging to understand the specific issues with the organization of the prompts. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Table 6 and 7, noting that the sentences are squeezed together, which can affect readability. This feedback is clear and actionable, as it highlights a particular area that needs improvement. However, the comment could be more helpful if it provided suggestions on how to reorganize the prompts or improve the spacing to enhance readability. Despite this, the comment still offers valuable guidance for the authors to enhance the clarity and presentation of their work. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the figures are not clear, specifically mentioning that the relation of the 3 subfigures in Figure 2 is confusing. It also notes that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. While the comment identifies specific issues, it does not provide explicit guidance on how to improve the clarity of the figures or suggest specific actions to take. The authors are left to infer that they need to clarify the figure\"s layout and label the modules, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figures, such as the confusion in the relation of the 3 subfigures and the lack of labeling for modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning confusion in the relation of the 3 subfigures in Figure 2 and the lack of labeling for modules like CMAF, L_BT, and VoLTA. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the problems based on the description provided, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly noting confusion in the relation of the 3 subfigures in Figure 2 and the lack of labeling for certain modules. This feedback is clear and actionable, as it highlights areas where the figures could be improved to better convey the information. By addressing these issues, the authors can enhance the clarity and interpretability of their figures, which is crucial for effectively communicating their findings. However, the comment could be more helpful if it provided suggestions on how to improve the labeling or clarify the figure\"s layout. Overall, the comment is 4 as it directs the authors\" attention to critical areas needing improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should address the omission of FFNs by either providing an approximation or noting that it is an open problem. It explicitly recommends adding a line or two to clarify this point, which provides a clear and concrete action for the authors to take. The comment is specific in its suggestion, offering a direct way to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the omission of FFNs and the need to address this issue, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should either provide an approximation or note that it is an open problem, offering clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the omission of FFNs due to a linear decomposition issue could be addressed by existing work or by noting it as an open problem. The comment implies that the authors should consider this aspect, but it does not provide specific references or examples of existing work that could address the issue. The lack of detailed justification or evidence makes the claim 3, as the authors would need to conduct further research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the omission of FFNs due to a linear decomposition issue and suggests that the authors should address this by either providing an approximation or noting that it is an open problem. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper\"s clarity and comprehensiveness. By addressing this point, the authors can provide readers with a clearer understanding of the limitations and potential solutions, which is valuable for improving the draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the use of perplexity as a measure of semantic information retention after finetuning and questions the control of domain drift and catastrophic forgetting. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their methodology. The feedback is vague and lacks concrete steps for the authors to take, leaving them uncertain about how to respond to the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the use of perplexity as a measure of semantic information retention after finetuning and questions the control of domain drift and catastrophic forgetting. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in identifying the need for addressing domain drift and catastrophic forgetting but does not provide detailed guidance on how to do so. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of semantic information retention after finetuning and questions the control of domain drift and catastrophic forgetting. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the use of perplexity as a measure of semantic information retention after finetuning and questions the control of domain drift and catastrophic forgetting. It highlights a potential issue with the methodology and suggests that the authors should address these factors to ensure the robustness of their approach. However, the comment does not provide specific suggestions or guidance on how to control for domain drift or catastrophic forgetting, leaving the authors with a general idea of what needs improvement but without detailed direction. While it identifies a potential weakness, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the number of images affects the model performance and whether more training images make the performance worse or better. It also suggests explaining BYOL for its first appearance in the abstract. While the questions are explicit, they do not provide concrete guidance on how to address them or what specific changes should be made to the draft. The authors are left to infer that they need to conduct experiments or provide additional analysis to answer these questions, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks explicit guidance on execution.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments. The authors might infer that these questions relate to the methodology or results sections, but this inference is not direct. The comment is specific in its questions but lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the impact of the number of images on model performance and the explanation of BYOL in the abstract. These are factual inquiries rather than subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: how the number of images impacts the model performance and whether more training images make the performance worse or better. It also suggests explaining BYOL for its first appearance in the abstract. While the comment identifies areas for clarification and potential improvement, it lacks specific guidance or suggestions on how to address these issues. The questions are clear but do not provide actionable steps for the authors to take, making the feedback 3. The authors are left to infer that they need to conduct further analysis or provide additional context, but the comment does not offer detailed guidance on how to do so. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the strength of the observed effects but points out a lack of clarity regarding why the method works, particularly concerning the L_pixel component. It suggests that providing stronger arguments or intuitions about why these specific losses are \"bound to help\" would be beneficial. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the observed effects and the lack of clarity regarding why the method works, particularly concerning the L_pixel component. However, it does not specify which part of the paper discusses these effects or the L_pixel component, making it weakly grounded. The comment is specific in suggesting that stronger arguments or intuitions about why the particular losses are \"bound to help\" would be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding why the method works, particularly concerning the L_pixel component. It suggests that providing stronger arguments or intuitions about why these specific losses are \"bound to help\" would be beneficial. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the explanation is unclear. This lack of detailed justification makes the claim 3, as the authors would need to infer the need for more detailed explanations themselves.", "helpfulness_rationale": "The review comment acknowledges the strength of the observed effects but points out a lack of clarity regarding why the method works, particularly concerning the L_pixel component. It suggests that providing stronger arguments or intuitions about why these specific losses are \"bound to help\" would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance the explanation and reasoning in their paper. However, the comment could be more helpful if it provided specific examples or suggestions on how to strengthen the argument. Overall, the comment is 4, as it effectively guides the authors to improve their draft by addressing a critical gap in the explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning the need to discuss sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and provides concrete guidance on what additional details should be included to enhance the Related Work section. The authors know exactly what aspects to address and how to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be included in the Related Work section, such as discussing sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods for handling very long documents. This level of detail helps the authors understand exactly what aspects of the Related Work section need improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section is lacking details and suggests specific methods and limitations that should be discussed. The comment provides a list of existing methods, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, which are referenced by numbers. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more context or explanation on why these specific methods are relevant or how they relate to the current work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the Related Work section by pointing out the lack of detailed discussion on existing methods and their limitations, particularly in the context of longcontext language models. It provides specific suggestions for what should be included, such as discussing sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is clear and actionable, offering the authors a clear path to enhance the Related Work section by providing a more comprehensive overview of existing methods. The detailed suggestions make the comment 5, as it empowers the authors to significantly improve their draft by addressing these specific areas of weakness."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the dataset size, questioning whether 44k dialogues is enough to capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as recommending additional data collection strategies or alternative approaches to mitigate the dataset size limitations. The action is implicit and vague, as the authors are left to infer that they need to consider the dataset size or explore alternative methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the dataset size and the number of dialogues, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the sufficiency of the dataset size in capturing a wide range of user traits and personalities across different content topics. The comment further questions the dataset size in comparison to typical training data for LLMs, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the dataset size, questioning whether 44k dialogues is enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are trained on trillions of tokens, suggesting that the dataset is insufficient. This claim is 3 as it provides a logical comparison between the dataset size and typical training data for LLMs, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the dataset size, questioning whether 44k dialogues is enough to capture a wide range of user traits and personalities across different content topics. It compares this dataset size to the typical training data for LLMs, which are trained on trillions of tokens, suggesting that the dataset is insufficient. This feedback is 3 as it identifies a potential weakness in the dataset size and provides a logical comparison to typical training data. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue, such as recommending additional data collection strategies or alternative approaches to mitigate the dataset size limitations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider expanding their analysis to include real and categorical features, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of binary features and the potential applicability to real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, given that the work uses only binary features. However, the comment lacks specific examples or references to support the claim that the method is not applicable to these types of features. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the method to real and categorical features, given that the work uses only binary features. This is a relevant point that could impact the generalizability and practicality of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or modifications to the method. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing needs improvement and acknowledges that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. The feedback lacks explicit instructions or concrete suggestions for the authors to address the unclear points, leaving them without a clear path for action. As a result, the comment is 1 because it does not provide actionable steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment indicates that the writing needs improvement and acknowledges that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. Without specific references to sections, sentences, or examples, the authors cannot confidently determine which parts of the paper need attention. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"the writing should be improved\" and acknowledges that some points in the paper are unclear. However, it does not provide any specific examples or detailed reasoning to support the claim that the writing is unclear or needs improvement. Without additional context or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the writing needs improvement and acknowledges that some points in the paper are unclear. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to enhance the writing or clarify the unclear points. Without detailed guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to address the issues. As a result, the comment is 2, as it points out a general area for improvement but does not offer specific advice or direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics, such as BERTScore, to evaluate their results. This is an explicit action, as it clearly indicates what the authors should do to improve their draft. However, it does not provide specific guidance on which other metrics to use or how to implement this suggestion effectively. While the action is clear, the lack of detailed instructions on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use alternative metrics, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any justification or reasoning for why these metrics are necessary or how they would improve the evaluation. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. This is a clear and actionable suggestion that could enhance the robustness and comprehensiveness of the evaluation. However, the comment does not specify which other metrics should be considered or provide guidance on how to implement this suggestion effectively. While it offers a direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric with other metrics from the literature on LLM evaluation. It also implies that the authors should clarify under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. While the comment provides a clear direction for comparison and suggests a specific area for clarification, it does not offer detailed guidance on how to conduct this comparison or what specific aspects to focus on. The action is explicit but somewhat vague, as it lacks concrete steps for execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench\" and \"other metrics proposed in the literature,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests comparing SynTextBench with other metrics and clarifying the conditions for using SynTextBench over other metrics, such as MMLU or Big Bench for language generation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare the SynTextBench metric with other metrics from the literature on LLM evaluation. It also implies that the authors should clarify under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. The comment provides a logical reasoning by suggesting a comparison with existing metrics and highlights the need for clarification on the conditions for using SynTextBench. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improvement by recommending a comparison of the SynTextBench metric with other metrics from the literature on LLM evaluation. It also highlights the need for clarification on the conditions under which SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. This feedback is clear and actionable, offering the authors a specific area for further analysis and comparison, which can enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to conduct this comparison. Overall, the comment is 4, as it provides valuable insights and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point highlights that the algorithm for constructing coresets is not novel, as it extends existing coreset frameworks for classical kmeans and (k,z) clusterings to a kernelized setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the algorithm for constructing coresets, noting that it is not novel as it extends existing coreset frameworks for classical kmeans and (k,z) clusterings to a kernelized setting. However, it does not specify which part of the paper discusses the algorithm or the coreset frameworks, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the novelty issue, it lacks grounding as it does not provide clear guidance on where the authors should focus their improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel, as it extends existing coreset frameworks for classical kmeans and (k,z) clusterings to a kernelized setting. This claim is 3 because it references existing coreset frameworks, providing a basis for the assertion. However, the comment lacks specific examples or detailed references to these frameworks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it extends existing coreset frameworks for classical kmeans and (k,z) clusterings to a kernelized setting. While this observation is accurate, the comment does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or specific recommendations, the authors are left without a clear path forward for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing and annotations are difficult to follow, but it does not provide specific guidance on how to improve this aspect. The comment lacks explicit instructions or suggestions for enhancing the clarity of the writing or annotations. Without concrete advice or examples, the authors are left without a clear understanding of what needs to be done to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the writing and annotations are difficult to follow, but it does not specify which parts of the paper are affected or how the writing could be improved. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Poor writing and annotations are a little hard to follow.\" However, it does not provide any specific examples or details to support this claim, such as which sections are difficult to follow or how the writing could be improved. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow, but it lacks specificity and does not provide any actionable advice or suggestions for improvement. Without detailed guidance on how to enhance clarity or structure, the authors are left without a clear path forward. This makes the comment 2, as it identifies a problem but does not offer a solution. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific observations about the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also raises a question about the discrepancy in F1 scores when comparing the proposed method to a specific setting. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve the draft. The authors are left to infer that they need to explain the limited SOTA performances and clarify the F1 score discrepancy, but without concrete suggestions, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific metrics and settings being discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proposed method\"s performance, noting that only 8 out of 14 evaluation metrics achieve SOTA performances and questioning the discrepancy in F1 scores under a specific setting. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations about the performance of the proposed method in Table 2 and a question regarding the discrepancy in F1 scores under a specific setting. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific observations about the performance of the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also raises a question about the discrepancy in F1 scores under a specific setting, which could be an area for further investigation. While the comment highlights important aspects of the method\"s performance, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it identifies areas for improvement but does not provide detailed direction for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors only consider ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including all reports, but it lacks concrete steps or details on how to implement this change. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the labeling of ECG segments, but it lacks grounding as it does not reference a particular section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the consideration of ECG segments with only one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any supporting evidence, reasoning, or references to justify why including all reports would be easier or more beneficial. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the argument. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be easier. This feedback highlights a potential limitation in the current approach and prompts the authors to reconsider their methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential area for improvement, the feedback is incomplete and could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this incremental step or what specific aspects need to be clarified or improved. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not specify which part of the paper this comment is addressing, such as a particular section, figure, or discussion. Additionally, the comment lacks specificity regarding what aspects of the solution need to be clarified or improved. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the proposed solution is an incremental step considering a relaxation proposed by Guzman et. al. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this incremental step or improve their work. The comment lacks actionable advice or constructive feedback, leaving the authors without a clear understanding of what needs to be done to enhance their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the paper lacks a thorough discussion of the scalability bounds of FedDES, specifically mentioning the absence of a clear discussion on memory requirements or computational complexity. This feedback provides a direct and concrete action for the authors to take, which is to include a detailed discussion on these aspects. The comment is clear and specific, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper\"s discussion of scalability bounds, particularly the lack of a thorough exploration of the upper limits of FedDES\"s scalability. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely a discussion of memory requirements or computational complexity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion of the scalability bounds of FedDES, specifically mentioning the absence of a clear discussion on memory requirements or computational complexity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks thorough discussion, namely the scalability bounds of FedDES. It points out the absence of a clear discussion on memory requirements or computational complexity, which are crucial aspects for understanding the scalability of the proposed method. This feedback is clear and actionable, as it directs the authors to address a significant gap in their analysis. However, the comment could be more helpful if it provided suggestions on how to explore these aspects or included examples of how to discuss them effectively. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the current instances have a limited number of variables. This implies that the authors should consider expanding the scope of their experiments to include more complex instances. However, the comment does not provide specific guidance on how to implement this suggestion or what specific constraints or variables should be included. The action is implicit and somewhat vague, as the authors need to infer the need for more instances and determine how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have a limited number of variables. This implies that the authors should consider expanding the scope of their experiments to include more complex instances. However, the comment does not specify which part of the paper discusses the instances or variables, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have a limited number of variables. This raises a concern about the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that generating more instances would address the concern. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental design, specifically the limited number of variables in the instances. It suggests that generating instances with more constraints and variables could help address this concern, particularly in relation to the ability of large language models (LLMs) to model problems with large instance sizes. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to consider expanding their experiments. However, the comment could be more actionable by providing specific suggestions on how to generate these additional instances or by discussing the implications of such an expansion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several ways to improve the results presentation. It explicitly recommends improving the labeling of the yaxis in Figures 2 and 3, suggesting a scatter plot with x/y axes representing runtime and performance. It also advises highlighting the best results in tables. While the comment provides clear and concrete actions for the authors to take, it does not specify how to implement these suggestions, such as which figures to focus on or how to highlight the best results. The actions are explicit and concrete, but the comment could be more actionable if it included more detailed guidance on execution. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests improvements in the presentation of results, specifically mentioning Figures 2 and 3. It provides specific feedback on the labeling of the yaxis and the lack of representation of runtime in these figures. The suggestion to use a scatter plot with x/y axes representing runtime and performance is clear and specific. Additionally, the comment advises highlighting the best results in tables, which is also a specific suggestion. However, the comment does not explicitly mention which parts of the paper these figures are in, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests improvements in the presentation of results, specifically mentioning the ambiguity in the yaxis label and the lack of representation of runtime in Figures 2 and 3. It proposes using a scatter plot with x/y axes representing runtime and performance to aid in understanding the results. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the current presentation is ambiguous or ineffective. The suggestion to highlight best results in tables is also a constructive piece of feedback but does not provide detailed reasoning or evidence. Therefore, the comment is 3, as it offers a plausible suggestion but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the presentation of results. It suggests enhancing the clarity of the yaxis labels in Figures 2 and 3 by using a scatter plot with x/y axes representing runtime and performance. This suggestion could help the reader better understand and interpret the results. Additionally, the comment advises highlighting the best results in tables, which is a clear and constructive suggestion for improving the readability of the paper. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback is 4 as it offers clear directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the impact of the base node on the ordering, key nodes for attention, and model performance in NodeSort. While it implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or evidence to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the impact of the base node on the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the impact of the base node on the ordering, key nodes for attention, and model performance in NodeSort. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement.", "helpfulness_rationale": "The review comment raises a question about the impact of the base node on the ordering, key nodes for attention, and model performance in NodeSort. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their understanding of the mechanism. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be explored or clarified. Therefore, it is rated as 2, as it provides some insight but lacks depth and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, questioning its purpose. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what changes could be made to the figure or the explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the direction of the arrow in Figure 2, questioning its purpose and suggesting that it should influence n^(i). This provides clear guidance on what aspect of the figure needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the direction of the arrow in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning its purpose and suggesting that it should influence n^(i). This feedback is 3 as it identifies a potential issue with the figure\"s representation and prompts the authors to reconsider the direction of the arrow. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the figure. While it points out a potential area for clarification, it does not offer actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific issue with the use of abbreviations in the paper, noting that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback provides a clear and direct action for the authors to take, which is to define the abbreviations used in the paper. The comment is specific and actionable, as it clearly indicates what needs to be addressed and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviations, noting that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning \"AR\" in Table 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of the issue or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, noting that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it directs the authors to define the abbreviations used in the paper to avoid confusion. By addressing this issue, the authors can improve the clarity and readability of their work. However, the comment could be more helpful if it provided examples of other abbreviations that need clarification or suggested ways to present the information more effectively. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the technical considerations of using advantage instead of q value in the analysis. It does not explicitly instruct the authors to address this concern or provide guidance on how to do so. The action is implicit, as the authors can infer that they need to consider other technical aspects related to the choice of using advantage instead of q value. However, the comment lacks concrete details on what specific considerations should be explored or how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations of using advantage instead of q value in the analysis. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or analysis sections, but this inference is not direct. The comment is specific in its inquiry about the technical considerations, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the technical considerations of using advantage instead of q value in the analysis. It does not make a subjective claim or suggestion but rather seeks clarification or further exploration of the topic. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations of using advantage instead of q value in the analysis. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects to consider. The comment lacks depth and actionable advice, making it 3 as it prompts the authors to think more critically about their methodology. However, it does not fully support the authors in making improvements, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the setting of Unsupervised Online Adaptation, suggesting that the process is not truly unsupervised because it requires annotations. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the unsupervised nature of the adaptation process, but it lacks concrete steps or examples for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the setting of Unsupervised Online Adaptation, mentioning that the process is not truly unsupervised because it requires annotations. It references Section 3.1, which allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity in detailing what aspects of the adaptation process are problematic or how they should be revised. While the authors can determine the relevant section, the comment does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is \"strange\" because it requires annotations, which contradicts the claim of being unsupervised. The comment references Section 3.1, which presumably describes the model\"s requirements, providing some context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the process is not truly unsupervised. The absence of specific evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the process requires annotations, which contradicts the claim of being unsupervised. This feedback is clear and highlights a specific concern that could impact the validity of the methodology. However, the comment does not provide suggestions or guidance on how the authors might address this issue or improve the clarity of their approach. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, whereas most compared baselines set all sample weights to 1. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete instructions on whether the authors should adjust the sample weights or provide additional justification for the differences in weights. The action is implicit and vague, as the authors are left to infer that they need to address the fairness of the comparison but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the fairness of the performance comparison, noting that VINS uses different sample weights during training, while most compared baselines set all sample weights to 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS uses different sample weights during training, while most compared baselines set all sample weights to 1. This claim is 3 as it provides a specific example of a difference in the experimental setup that could affect the fairness of the comparison. However, the comment lacks detailed reasoning or references to support why this difference is significant or how it impacts the results. The authors would need to further explore and justify this claim themselves, making the comment 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, while most compared baselines set all sample weights to 1. This observation is valuable as it highlights a potential source of bias or unfairness in the comparison, which the authors should consider addressing. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative weighting strategies or additional analyses to mitigate the unfairness. While it points out an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the method if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. It merely points out a concern without offering guidance on how to address it or suggest improvements. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue with the time complexity of the method if the reply buffer is too large, referencing a specific paper for context. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with time complexity and provides a reference for further reading. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper for context. However, the comment lacks detailed reasoning or explanation of why this is the case or how it impacts the overall performance of the method. The reference to \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning\" provides some context, but it does not fully substantiate the claim. The authors would need to make significant effort to understand and address the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method if the reply buffer is too large, referencing a specific paper for context. While it highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. The comment lacks actionable advice or detailed feedback, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. It references specific works (16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45) to support the suggestion. While the comment provides a clear direction for improvement, it does not specify which baselines or modifications should be considered or how they should be integrated into the paper. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to involve other baselines and modify the SGM formulation, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. The comment references specific works (16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45) to support the suggestion, providing a logical basis for the claim. However, the comment does not explicitly explain why these specific baselines or modifications are relevant or how they would improve the paper. This makes the claim 3, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. It references specific works (16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45) to support the suggestion, providing a clear direction for improvement. However, the comment lacks specific guidance on which baselines or modifications should be considered, and it does not explain how these changes would enhance the paper\"s contribution or clarity. While it offers a valuable suggestion, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of the paper\"s contributions. This is a direct and clear action, leaving no ambiguity about what needs to be done. The comment is specific in its request, as it clearly specifies the elements that need to be included in the conclusion and summary. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and summary of the paper\"s contributions need to be provided. However, it does not specify which part of the paper this suggestion pertains to, such as the conclusion section or the summary section. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the conclusion or summary need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a brief conclusion and summary of the paper\"s contributions need to be provided. However, it does not offer any supporting evidence, reasoning, or examples to justify why this is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a straightforward and actionable suggestion for improvement by recommending that the authors include a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and directly instructs the authors on what needs to be added to enhance the completeness and clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively summarize the contributions or what specific elements should be included in the conclusion. Despite this, the comment is 4 as it directs the authors toward a clear and necessary enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify this point, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"synthetic experiment in a nonseparable case\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the inseparability of the data distribution from the network model, prompting the authors to clarify this aspect. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution in Figure 1 is inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the synthetic experiment in a nonseparable case, specifically questioning how the data distribution in Figure 1 is inseparable from the network model. This feedback highlights a gap in the explanation or justification provided in the paper, prompting the authors to clarify this aspect. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional analysis or clarifications. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further compare their proposed framework with a method designed to defend against multiple attacks, as this would provide more meaningful results. The comment implies that this comparison should be included in the paper, but it does not specify which specific method should be used or how to present the comparison. While the action is clear in terms of what needs to be done, it lacks concrete details on how to execute it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, implying that this comparison would enhance the paper\"s results. However, it does not specify which particular method should be used for this comparison, leaving the authors to infer the specific method. The comment is 1 as it does not explicitly mention a section or part of the paper where this comparison should be made. It is also not specific because it does not provide detailed guidance on how to conduct the comparison or what results would be expected. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, implying that this would enhance the paper\"s results. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the rationale behind the suggestion. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general suggestion without sufficient justification or examples. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should further compare their proposed framework with a method designed to defend against multiple attacks, as this would provide more meaningful results. It acknowledges the interesting study presented in the paper but emphasizes the need for additional comparisons to enhance its relevance and impact. While the comment identifies a potential area for improvement, it lacks specific guidance on which method to compare with or how to present the results effectively. This limits the comment\"s helpfulness, as it provides a general suggestion without actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or improve the presentation of their results. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to rectify the problem. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results and the issue of disregarding safety violations in the first 1000 episodes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem with the presentation of results and the reason for this presentation, which is the disregard of safety violations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. However, the comment lacks any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that they are convoluted and that the results disregard the safety violations of the agent in the first 1000 episodes. This feedback is 3 as it highlights a potential problem with the clarity and comprehensiveness of the results. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve the presentation of their results. Without actionable guidance or specific recommendations, the authors may struggle to make meaningful improvements based solely on this feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment explicitly points out these errors, it does not provide detailed guidance on how to correct them or suggest specific changes to make the writing clearer. The authors can infer that they need to revise these parts to improve the clarity and professionalism of the paper, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages (\"page 5\" and \"page 1\"), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as \"informative informative\" and \"performance\" on page 1, which lacks a title. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are writing errors in the paper, specifically mentioning \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any explanation or reasoning for why these errors are problematic or how they affect the paper\"s quality. Without additional context or justification, the authors may find it challenging to understand the significance of these errors and how to address them. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While it points out these issues, it does not provide detailed guidance on how to correct them or suggest improvements to enhance the clarity and professionalism of the writing. The feedback is 3 as it highlights areas for improvement, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to elaborate more on why the statement in Theorem 4.1 holds, specifically mentioning that it would be useful to explain this in the main text. The action is clear and direct, providing the authors with a specific task to improve the explanation. However, the comment does not provide detailed guidance on how to elaborate on this point, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the statement on line 134 should be elaborated more in the main text to explain why it holds, particularly in the context of the RNN converging to the nearest fixed point compared to the URNN. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a statement and a suggestion for elaboration. The statement claims that the statement on line 134 is only true for a standard sigmoid function and depends on the maximum slope. The reviewer suggests that it would be useful to elaborate on why this holds, particularly in the context of the RNN converging to the nearest fixed point compared to the URNN. While the comment provides some reasoning, it lacks specific examples or references to support the claim fully. The suggestion for elaboration is clear, but the overall claim is 3 due to the need for more detailed explanation or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific statement in the paper that requires further elaboration, particularly in the context of Theorem 4.1. It suggests that the authors should provide a clearer explanation of why the statement holds, especially in relation to the convergence behavior of the RNN compared to the URNN. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and depth of their explanation. However, the comment could be more helpful if it included specific suggestions on how to elaborate on the statement or provided examples of how to improve the explanation. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out a concern about the low efficiency of pairwise matching, which could hinder its practical application. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential solutions, alternative approaches, or specific actions the authors should take to enhance the efficiency. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the efficiency of pairwise matching, which is described as \"very low,\" and its impact on practical applications. However, it does not specify which part of the paper discusses pairwise matching or where this issue is addressed. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of efficiency could be improved or how the authors might address this issue. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, which could hinder its practical application. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the efficiency of pairwise matching, noting that it is very low and could hinder practical applications. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable feedback or detailed insights, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. While the comment implies that the authors should reconsider how they allocate Figure 1, it does not provide specific guidance on how to improve the allocation or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact nature of the improvement needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1\" and suggests that its allocation is too naive, implying that the authors should reconsider how it is presented. However, it does not specify which part of Figure 1 is problematic or how it should be improved. The comment also advises that the authors could have edited the space of the main paper more wisely, but it does not provide specific guidance on how to do so. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support why the allocation is considered naive or how it could be improved. Without concrete evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a minor weakness in the paper, specifically the allocation of Figure 1, which is described as too naive. It suggests that the authors could have edited the space of the main paper more wisely. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to address the issue or what changes could be made to enhance the figure\"s allocation. The feedback is 3 as it points out a potential area for improvement, but it does not provide detailed direction or actionable steps for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans based on Table 2. The comment suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the method. The feedback is implicit and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the need for manual design based on ground truth, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans based on Table 2, indicating a lack of comparability. Additionally, it suggests that the proposed method may be difficult to generalize to new datasets without ground truth summaries. However, the comment does not explicitly mention which part of the paper this issue is discussed in, such as specific sections or tables. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans based on Table 2, indicating potential difficulties in generalization. The comment provides a logical reasoning by highlighting the unrealistic nature of manual design and the lack of comparability, which supports the claim. However, it could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans based on Table 2, suggesting potential difficulties in generalization to new datasets without ground truth summaries. This feedback is clear and actionable, as it highlights a critical issue with the methodology and provides a direction for improvement by suggesting that the authors should consider methods that do not rely on predefined plans. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these limitations. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the first sentence of the abstract. This is a direct and clear action, providing the authors with a specific task to improve their draft. The comment is concrete, as it specifies exactly what needs to be done, leaving no ambiguity about the authors\" responsibilities. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first sentence of the abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done, which is rewriting the first sentence of the abstract. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning or justification for why this change is necessary or how it would improve the abstract. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that the first sentence of the abstract needs to be rewritten. However, it lacks depth and does not provide any guidance on why this change is necessary or how it might improve the abstract. The comment does not offer suggestions for what aspects of the sentence could be improved or what specific changes might be beneficial. While it points out a potential area for enhancement, the lack of detailed feedback limits its usefulness to the authors. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but lacks comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method appears more complex than necessary and implies that there might be a simpler principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how the authors should simplify the method or identify the underlying principle. The feedback lacks concrete steps or actionable advice, leaving the authors uncertain about how to address the concern. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method appears more complex than necessary and implies that there might be a simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what specific aspects of the method are overly complex or what simpler principle could be identified. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or clarification. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method appears more complex than necessary, implying that there might be a simpler principle driving the quality gains. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the method appears more complex than necessary and implies that there might be a simpler principle driving the quality gains. However, it does not provide specific details or suggestions on how the authors could simplify the method or identify the underlying principle. The feedback lacks actionable guidance or concrete examples, making it challenging for the authors to address the concern effectively. As a result, the comment is 2, as it points out a potential issue but does not offer a clear path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects should be considered to ensure it is a significant contribution. The action is implicit and vague, as the authors are left to infer that they need to add a method to improve transferability but are not given concrete steps or criteria for determining significance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests adding a method on top of other methods to improve transferability but argues that this is not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what aspects of transferability should be improved or how this addition would be significant. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of transferability are being questioned or how the proposed method would improve it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that adding a method on top of other methods to improve transferability is good but not a significant contribution. However, the comment lacks specific reasoning or examples to support why this addition would not be considered a significant contribution. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While it provides a rationale for why the addition might not be a major contribution, it lacks specific guidance or suggestions on how to achieve this or what aspects of transferability should be emphasized. The comment offers some insight but does not fully support the authors in making improvements to their draft. Therefore, it is 3, as it provides a direction for potential enhancement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the hGRU architecture appears to be adhoc and not wellmotivated. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve the motivation behind the architecture. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture as being adhoc and not wellmotivated. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the architecture are adhoc or poorly motivated, such as specific design choices or motivations. Without explicit references or detailed feedback, the authors may struggle to address the critique effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc and not well motivated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the hGRU architecture appears to be adhoc and not wellmotivated, which is a critical observation for the authors to address. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might improve the motivation or justification for their architecture. Without actionable feedback or detailed examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it identifies a potential issue but does not offer a comprehensive solution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions: one about the use of s_n instead of s_t in Algorithm 1 Line 8, and another about the asymptotic performance of the proposed method. It also suggests that the authors provide average return results with more environment steps. While the first question is explicit, the second part is more of a request for additional information rather than a direct action. The comment is 4 as it provides clear guidance on what the authors should investigate and potentially include in their work, but it could be more specific about how to address the asymptotic performance question. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of s_n instead of s_t and suggests providing average return results with more environment steps. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a question about the use of s_n instead of s_t in Algorithm 1 Line 8 and a request for additional information on the asymptotic performance of the proposed method. The first part is a question seeking clarification, while the second part is a request for more detailed information. Neither part contains subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions: one about the use of s_n instead of s_t in Algorithm 1 Line 8, and another about the asymptotic performance of the proposed method. It also suggests providing average return results with more environment steps. While the comment identifies areas for clarification and potential improvement, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges, particularly the difference between this analysis and that of Zhang et al. While the comment implies that the authors should provide a detailed explanation, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides some guidance on what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of Adam under the (L0,L1)smoothness condition, specifically questioning the clarity of challenges and suggesting that the authors should explain the differences from Zhang et al. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in its request for clarification and explanation regarding the challenges and differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of challenges when analyzing Adam under the (L0,L1)smoothness condition and suggests that standard analysis could be applied. It implies that the authors should explain the challenges, particularly the difference from Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis could be applied. Without explicit evidence or references, the claim remains 3, as it provides a general observation without detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges, especially the difference from Zhang et al. This feedback is 3 as it points out a specific area for improvement in the paper\"s explanation. However, it lacks detailed guidance or examples on how to address these challenges, which would make the comment more actionable. Therefore, the comment provides some insight but could be more helpful with additional details or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests taming the statement about the neural network \"memorizing\" critical points, indicating that this might not be accurate in the context of TopoNet 24. It also points out that the method section is wordy and could be compressed to focus on essential definitions. Additionally, the reviewer notes the presence of several grammatical errors, specifically mentioning the need to focus on plurals and articles. While the comment provides some guidance on how to improve the statement and the method section, it lacks explicit instructions on how to make these changes. The suggestions are somewhat vague and require the authors to infer the exact actions to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"34\" and \"TopoNet 24,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the statement about the neural network \"memorizing\" critical points, suggesting that this might not be accurate in the context of TopoNet. Additionally, the comment points out grammatical errors in the method section, indicating that it could be compressed to focus on essential definitions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a comment on the statement \"to force the neural network to memorize them\" and a request for the method section to be more concise. The first part suggests that the statement might be inaccurate, referencing TopoNet 24. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The second part is a request for clarification, not a claim. Overall, the comment is 3 due to the lack of detailed justification for the first part, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on two main aspects: the statement about the neural network \"memorizing\" critical points and the method section. It suggests taming the statement, indicating that the claim might not be accurate in the context of TopoNet 24. This feedback is 3 as it highlights a potential issue with the statement, prompting the authors to reconsider their wording. However, the comment could be more helpful if it provided additional context or examples to support the claim. Additionally, the comment points out grammatical errors in the method section, which is a clear and actionable suggestion for improvement. Overall, the comment offers some guidance but could be more comprehensive and detailed to be fully helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights that most person reID methods are based on pedestrian detectors and mentions the existence of endtoend methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or incorporate new methods into their work. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about person reID methods, noting that most are based on pedestrian detectors and mentioning the existence of endtoend methods. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on what the authors should address or improve. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the methods are being discussed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that most person reID methods are based on pedestrian detectors and mentions the existence of endtoend methods. However, it lacks specific references or detailed reasoning to support this claim. The comment does not provide enough context or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a factual observation about the prevalence of pedestrian detectorbased methods in person reID and mentions the existence of endtoend methods. However, it does not offer any critical analysis, suggestions, or guidance on how the authors might address this observation or improve their work. Without actionable feedback or insights, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete instruction on how to improve their draft. The comment is explicit and gives a precise action to be performed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is adding a first sentence to introduce what this section is about. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce what Section 3.2 is about. This is a request for a specific change, not a claim or opinion, and does not require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests adding a first sentence to introduce what Section 3.2 is about. This feedback is clear and provides a direct way for the authors to improve the clarity and organization of their paper. By addressing this suggestion, the authors can enhance the readability and coherence of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaning of \"initial rationale selector\" and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify this term, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term and determine its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"initial rationale selector\" and suggesting that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question and a comment about the meaning of \"initial rationale selector\" and its implications. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"initial rationale selector\" and suggests that if it were perfect, no additional work would be needed. This feedback highlights a potential ambiguity in the terminology used in the paper, which could hinder understanding or interpretation. However, the comment does not provide specific guidance or suggestions on how the authors might clarify this term or address the issue. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a specific suggestion for improving the clarity of the text by recommending that the definition of uncertainty be updated to clarify the distinction between epistemic model uncertainty and posterior distribution. The comment explicitly instructs the authors to update the text to include this clarification, making the action clear and concrete. The authors know exactly what change to make to enhance the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of uncertainty, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the text be updated to clarify the distinction between epistemic model uncertainty and posterior distribution. This guidance is actionable and provides a concrete direction for enhancing the clarity of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of uncertainty should be clarified by specifying that the epistemic model uncertainty is represented in the prior distribution and can be updated to a posterior distribution upon observing data. This claim is 3 as it provides a logical reasoning for the suggestion, explaining the need for clarity in the definition of uncertainty. However, the comment lacks specific examples or references to support the claim fully, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It identifies a potential area of confusion regarding the definition of uncertainty and offers a clear explanation of how to clarify it. By recommending that the text be updated to specify that the epistemic model uncertainty is represented in the prior distribution and can be updated to a posterior distribution upon observing data, the comment helps the authors enhance the precision and clarity of their explanation. This feedback is valuable as it guides the authors in making a significant improvement to their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the use of domain ontologies to avoid placeholder generation in evaluated responses, and another about the number of questions created for a zeroshot intent classifier and the accuracy of the system. While these questions prompt the authors to clarify certain aspects of their methodology, they do not provide explicit instructions or suggestions for action. The authors can infer that they need to address these questions, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for clarification but does not offer detailed instructions on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of domain ontologies to avoid placeholder generation and inquires about the number of questions created for a zeroshot intent classifier and the accuracy of the system. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology and results, rather than making subjective claims or opinions. It does not contain any claims that require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the methodology and results of the paper. The first question asks whether the authors also experimented with the use of domain ontologies to avoid the generation of placeholders in the evaluated responses. The second question inquires about the number of questions created for the zeroshot intent classifier and the accuracy of the system. While the comment identifies areas for clarification, it does not provide actionable suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it highlights important aspects that need further explanation, but it lacks depth and specificity in terms of how the authors can enhance their work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include citations to recent papers on selfplay and populationplay with respect to exploration and coordination. This provides a clear and direct action for the authors to take, as they can refer to specific papers mentioned in the comment. The suggestion is concrete, as it specifies which papers to include, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include citations to recent papers on selfplay and populationplay with respect to exploration and coordination. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or discussion where these citations should be added. While the authors might infer that it relates to the discussion of related work or the context of their work, the lack of explicit grounding makes it challenging to pinpoint the exact area needing revision. The comment is specific in suggesting the inclusion of certain citations, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks citations to recent works on selfplay and populationplay with respect to exploration and coordination. The comment provides specific references, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which are wellknown papers in the field. This level of detail provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by explaining how these citations would enhance the paper\"s context and relevance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks citations to recent works on selfplay and populationplay with respect to exploration and coordination. It provides specific references, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which are wellknown papers in the field. This feedback is clear and actionable, as it guides the authors to include relevant citations that would enhance the context and relevance of their work. However, the comment could be more helpful if it explained how these citations would specifically benefit the paper or provided examples of how they might be integrated. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their method with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action, as it clearly instructs the authors to include a comparison with specific types of methods. However, the comment does not provide detailed guidance on how to conduct this comparison or which specific methods to consider, leaving the authors to infer the exact steps needed. While the action is clear, the lack of concrete details makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the method with other selfsupervised learning methods not based on contrastive learning. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on which specific methods should be considered for comparison. This makes it difficult for the authors to pinpoint the exact section or elements of the paper that need revision. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the method with other selfsupervised learning methods not based on contrastive learning. However, it does not provide any specific examples or references to support this claim, nor does it explain why such a comparison would be beneficial or necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how it could be implemented. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the method with other selfsupervised learning methods not based on contrastive learning. This is a relevant and actionable suggestion that could help the authors enhance the comprehensiveness and impact of their work by highlighting the differences and potential advantages of their approach over existing methods. However, the comment lacks specific guidance on which methods to consider for comparison or how to present this comparison effectively. While it provides a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. It suggests that the authors clarify this distinction. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"abstention process,\" allowing the authors to accurately identify the part of the paper being discussed. It also specifies the issue by asking how the abstention process differs from a decision threshold used by the models, prompting the authors to clarify this distinction. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the abstention process and its relationship to decision thresholds. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. This is a relevant and clear point that could help the authors clarify their methodology. However, the comment does not provide suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies an area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the experimental setup, specifically regarding the switch in BPE vocabulary types (uncased and cased). It also asks whether the change in BPE could cause variance in performance. While the comment implies that the authors should explain this switch, it does not provide explicit instructions or concrete guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for the switch in BPE vocabulary and its impact on performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and COCOLM, suggesting that the performance of these models is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It raises a question about the parameter efficiency of COCOLM and its applicability to related works. The comment also questions the experimental setup, specifically the switch in BPE vocabulary types (uncased and cased) and its potential impact on performance. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issues with the comparison and the experimental setup, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides examples of these models with similar sizes to COCOLM, which supports the claim. However, the comment does not explicitly state that the authors should address this issue or provide a detailed explanation of the comparison. The reasoning is 3 as it provides a basis for the claim but lacks specific examples or detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. This observation is important for the authors to consider in their analysis. The comment also questions the experimental setup, specifically the switch in BPE vocabulary types (uncased and cased), and whether this change could affect performance. This line of inquiry is valuable as it prompts the authors to consider the robustness of their experimental setup and the potential impact of different vocabulary types on performance. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these concerns. Overall, the feedback is 3 as it identifies areas for improvement and prompts the authors to consider additional aspects of their experimental setup, but it could be more comprehensive with detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis from line 128 to 149 is not convincing enough and provides specific observations about the class selectivity scores of the GSP50 and ResNet50 models. It suggests that the authors should explain why the observation indicates that GSP50 learns better representations. The comment also references external works to support the analysis. While the comment identifies a specific area for improvement and provides some guidance on what needs to be clarified, it lacks detailed instructions on how to address the issue or what specific aspects should be expanded upon. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed observations about the class selectivity scores of the GSP50 and ResNet50 models, explaining how these observations indicate that GSP50 learns better representations. The comment also references external works to support the analysis, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis from line 128 to 149 is not convincing enough, based on the observation that the GSP50 model has smaller class selectivity scores compared to ResNet50. The reviewer supports this claim by referencing two external works, 1 and 2, which provide theoretical and empirical evidence for the relationship between class selectivity and feature learning. This reference to external literature strengthens the claim, making it 4. However, the comment could be further strengthened by providing more detailed explanations or examples from the referenced works. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the analysis is not convincing enough, particularly regarding the class selectivity scores of the GSP50 and ResNet50 models. It provides a clear observation that GSP50 shares more features with ResNet50, which may indicate that GSP50 learns more classspecific features. The comment also references external works to support the analysis, which adds credibility to the feedback. However, the comment could be more helpful if it provided specific suggestions on how the authors might improve the analysis or presented alternative perspectives. Overall, the comment is 4 as it highlights a critical area for improvement and provides some guidance, but it could be more comprehensive with additional details or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some conclusions in the paper are not convincing, specifically mentioning the exploration of combination methods and the potential of rehearsalfree continual learning with featurereplay methods. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their conclusions. The feedback lacks actionable details, such as recommending specific experiments or analyses to strengthen the conclusions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific conclusions in the paper, such as the belief that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It also mentions the exploration of combination methods and provides references to other works, such as R1, R2, and R3, which are relevant to the discussion. However, the comment does not explicitly mention which part of the paper these conclusions are discussed in, making it weakly grounded. The authors can infer that it relates to the conclusions or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with the conclusions and suggesting potential areas for improvement by referencing other works. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some conclusions are not convincing, specifically mentioning the exploration of combination methods and the potential of rehearsalfree continual learning with featurereplay methods. The reviewer supports this claim by referencing specific works, such as R1, R2, and R3, which are cited as examples of featurereplay methods in continuous learning. This provides a logical basis for the claim, as the references are relevant and provide context for the reviewer\"s critique. However, the comment could be strengthened by providing more detailed explanations or examples of how these references relate to the paper\"s conclusions. Overall, the comment is 4, as it is supported by references but could benefit from additional elaboration.", "helpfulness_rationale": "The review comment identifies a lack of convincing conclusions in the paper, specifically mentioning the exploration of combination methods and the potential of rehearsalfree continual learning with featurereplay methods. It provides references to other works, such as R1, R2, and R3, which are relevant to the discussion. This feedback is 3 as it highlights areas where the paper could be strengthened by referencing existing literature and suggesting potential improvements. However, the comment could be more helpful if it offered specific suggestions on how the authors might address these issues or integrate the referenced works into their own research. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could consider comparing with a chainofthought prompting approach as a more meaningful baseline. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is clear but inferred, and the suggestion is concrete, providing a specific example of a meaningful baseline to consider. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of meaningful baselines and suggesting a specific alternative for comparison, namely a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors limit their comparisons to simple naive baselines, suggesting that a chainofthought prompting approach would be a more meaningful baseline. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed justification or evidence makes the claim 3, as it requires more information to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of meaningful baselines. It highlights that while the authors mention various model criticism techniques in Section 2, they limit their comparisons to simple naive baselines. The comment suggests that the authors could consider comparing with a chainofthought prompting approach as a more meaningful baseline. This feedback is clear and actionable, providing the authors with a specific direction to enhance the validity and comprehensiveness of their comparisons. However, the comment could be more helpful if it offered additional suggestions or examples of other meaningful baselines to consider. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings where labels are not available. While the comment poses a question, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify their pretraining approach and its generalization capabilities, but the comment lacks concrete details on how to implement this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings where labels are not available. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these details are typically discussed. The comment is specific in its questioning about the pretraining approach and its generalization capabilities, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment \"No\".", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings where labels are not available. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some observations and design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes are needed to make their work hardware and software independent. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue with the hardware and software dependence of some observations and design decisions. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the design decisions are hardware and software dependent, or how this dependence could be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the hardware and software dependence of some observations and design decisions. While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. Without detailed suggestions or examples, the authors are left without a clear path forward for improvement. Therefore, the comment is 2, as it highlights a concern but does not offer substantial guidance for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the results of the ablation study. It asks whether the observed differences are noticeable or due to noise or randomness in the training process. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The questions are more of a request for clarification rather than actionable steps for improvement. Therefore, the comment is vague and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the results of the ablation study, specifically questioning whether the observed differences are noticeable or due to noise or randomness in the training process. However, it does not specify which part of the paper these questions pertain to, such as specific sections or tables where the ablation study is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in its questioning about the accuracy of the ground truth and the results, but without grounding, it lacks clarity on which parts need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the accuracy of the ground truth and the results of the ablation study. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, making the comment \"No\".", "helpfulness_rationale": "The review comment raises questions about the accuracy of the ground truth and the results of the ablation study, specifically questioning whether the observed differences are noticeable or due to noise or randomness in the training process. While it identifies areas of concern, it does not provide specific suggestions or guidance on how the authors might address these issues. The questions are more of a request for clarification rather than actionable feedback, making the comment 3. It could be more helpful if it offered suggestions on how to improve the accuracy of the ground truth or how to better assess the significance of the results. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experimental details in the main text and the lack of explanations or interpretations in the Appendix, specifically mentioning the PCA experiments in Figures 3, 7, and 8. While it identifies a gap in the presentation, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include more details and explanations in the main text and the Appendix. The action is implicit and somewhat vague, as it lacks concrete instructions on what specific details should be added or how to improve the explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (3, 7, and 8) where PCA experiments are discussed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the absence of experimental details and explanations in the Appendix, particularly regarding the PCA experiments. The comment provides clear guidance on what needs to be addressed, such as including more details and explanations in the main text and the Appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many important experimental details are missing or included in the Appendix, which lacks explanations or interpretations. The comment provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more examples or references to similar issues in the literature, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s presentation, specifically the lack of experimental details and explanations in the main text and the Appendix. It highlights specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained, indicating a clear area for improvement. By pointing out these omissions, the comment provides the authors with a concrete direction to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present these details or interpretations more effectively. Overall, the feedback is 4 as it directs the authors\" attention to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of new evaluation metrics and the need for an indepth exploration of the reasons behind the experimental results. However, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to propose new metrics and conduct further analysis, but without specific suggestions or steps, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the need for an indepth exploration of the reasons behind the experimental results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for new metrics and a deeper analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks new evaluation metrics and only uses existing ones linearly combined. It also suggests that the experimental analysis section needs an indepth exploration of the reasons behind the results. However, the comment does not provide specific examples or references to support the claim about the lack of new metrics or the need for deeper analysis. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand and address the issues without further guidance.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the lack of new evaluation metrics and the need for a deeper exploration of the reasons behind the experimental results. While it highlights these issues, it does not provide specific suggestions or guidance on how to address them. The comment is 3 as it points out areas for improvement, but it lacks actionable advice or detailed feedback that would help the authors make concrete changes to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific issue with the notation K, which is used both for a known kernel function and the number of layers. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a direct suggestion to clarify the notation, which is a concrete action that the authors can easily implement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (e.g., L166 and L176) where the notation K is used, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation K, which is being used ambiguously for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the notation K, which is used ambiguously in the paper. It provides clear examples of where this ambiguity occurs, such as lines 166 and 176. This direct and specific reference to the problematic notation makes the claim 5, as it provides a clear and actionable suggestion for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation K, which is used ambiguously in the paper. It points out that K is used both for a known kernel function and the number of layers, which can lead to confusion for readers. This feedback is clear and actionable, as it directs the authors to clarify the notation to avoid ambiguity. By addressing this issue, the authors can improve the clarity and readability of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the practical impact of the weak recovery problem studied, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the practical relevance of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the weak recovery problem studied in the paper, suggesting that it is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique, it lacks grounding as it does not provide clear references to the paper\"s content. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and that the AMP algorithm may not be useful for nonGaussian problems, limiting its practical impact. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the practical impact of the weak recovery problem studied, suggesting that the AMP algorithm may not be useful for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s scope and could guide the authors to consider the practical relevance of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the practical applicability of their findings. While it identifies an important area for consideration, the feedback could be more helpful with additional details or recommendations. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the authors\" claim regarding the relevance of human cognition in their study. It questions whether the authors are suggesting that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR affects the likelihood of selforganization succeeding or failing. The reviewer suggests that it would be surprising if behavioral economists studying this problem ignore these aspects and implies that the authors should provide more citations for comparison with previous studies. While the comment highlights a potential issue and suggests a direction for further clarification, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their claims and provide additional citations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the authors\" claim regarding the relevance of human cognition in their study. It questions whether the authors are suggesting that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR affects the likelihood of selforganization succeeding or failing. The comment also suggests that it would be surprising if behavioral economists studying this problem ignore these aspects and implies the need for more citations for comparison with previous studies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\" claim and suggests a need for further clarification and citations. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the authors\" claim regarding the relevance of human cognition in their study. It questions whether the authors are suggesting that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR affects the likelihood of selforganization succeeding or failing. The reviewer suggests that it would be surprising if behavioral economists studying this problem ignore these aspects and implies the need for more citations for comparison with previous studies. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide more detailed reasoning or evidence to address the concern effectively.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the authors\" claim regarding the relevance of human cognition in their study. It questions whether the authors are suggesting that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR affects the likelihood of selforganization succeeding or failing. The reviewer suggests that it would be surprising if behavioral economists studying this problem ignore these aspects and implies the need for more citations for comparison with previous studies. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their claims. The feedback is 3 as it prompts the authors to clarify their arguments and provide more context, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated, specifically mentioning the use of \"pioneering contributions herald a new era in robotic adaptability.\" It also notes that word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the wording, it does not provide explicit guidance on how to revise the language to be less exaggerated or more precise. The authors are left to infer that they need to adjust the language, but without concrete suggestions, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the conclusion of the paper, specifically pointing out that the wording is overly exaggerated and suggesting that the word choice is a bit flamboyant in multiple places. However, it does not specify which parts of the conclusion are overused or provide detailed feedback on how to revise the language. The authors can infer that it relates to the conclusion, but they cannot pinpoint the exact sections that need attention. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific because it lacks detailed guidance on how to improve the wording. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning \"pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete instances of the exaggerated wording or a clear rationale for why it is problematic, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggesting that the word choice is a bit flamboyant in multiple places. This feedback is 3 as it highlights areas where the language could be improved to be more precise and less impactful. However, the comment lacks detailed suggestions or examples of how to revise the language to achieve this, leaving the authors with a general idea of what needs to be addressed but without specific guidance on how to implement the changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, with specific metrics to focus on. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed\u2014performing these experiments and comparing the metrics. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to enhance their draft by recommending the performance of ablation experiments. It specifies the metrics to consider, such as the number of learnable parameters and GFLOPs, when comparing the proposed method with other methods like TubeR. This feedback is clear and constructive, offering a concrete step for the authors to take in order to strengthen their experimental evaluation and demonstrate the effectiveness of their method. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or why these metrics are particularly important. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment also mentions writing style and other issues but does not specify how these should be improved. While the authors can infer that they need to include comparisons to baselines, the lack of concrete suggestions or examples makes the action vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment also mentions writing style and other issues, but it does not provide specific guidance on how to address them. Therefore, the comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that the paper lacks comparison to simple feature acquisition baselines like expected utility, which is a significant weakness. However, the comment does not provide specific examples or references to these baselines, making it difficult for the authors to understand and address the issue. The lack of detailed justification or evidence for the claim makes it 2, as the authors would need to infer the importance of the comparison without explicit guidance. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. This is a critical point that could strengthen the paper\"s argument and demonstrate the effectiveness of the proposed approach. However, the comment does not provide specific suggestions or examples of how the authors might address this issue, such as which baselines to compare against or how to structure the comparison. Additionally, the comment mentions writing style and other issues but does not offer detailed guidance on how to improve these aspects. While the feedback highlights an important area for improvement, it lacks actionable and specific suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It asks about other bit operations, provides more explanations for Figure 5a, and inquires about the handling of DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference 15 did to strengthen the paper. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are implicit and somewhat vague, as the authors need to infer what specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific elements of the paper, such as \"11 is wonderful,\" \"Figure 5a,\" and the handling of DVS input. However, it does not explicitly mention which sections or parts of the paper these elements are discussed in, making it weakly grounded. The comment is specific in its suggestions, such as asking for more explanations of Figure 5a and suggesting the analysis of energy consumption as in reference 15. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions and suggestions rather than claims. It asks for more explanations and provides a suggestion to analyze energy consumption as in reference 15. Since it does not contain subjective opinions, judgments, or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several points of interest and suggests areas for improvement. It questions the relevance of \"11\" and asks for more explanations regarding Figure 5a, which could help clarify the paper\"s findings. Additionally, it inquires about the handling of DVS input when the input is in aer format and suggests analyzing energy consumption, similar to reference 15, to strengthen the paper. While the comment identifies specific areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it provides direction for the authors to enhance their draft, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, particularly in the context of differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. The comment implies that the authors should provide more detailed explanations to address this issue. While the action is implicit, it is concrete in terms of what needs to be clarified. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the combination of historical observations with inputs known over all time, particularly in the context of differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, particularly in the context of sequence length differences. It mentions that the text discusses separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. While the comment identifies a potential area for improvement, it does not provide specific examples or detailed reasoning to support the claim that this is a significant issue. The lack of detailed justification or examples makes it challenging for the authors to understand the importance of addressing this point. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the combination of historical observations with inputs known over all time, particularly in the context of sequence length differences (L vs L+M). It points out that while the text mentions separate embedding and addition with positional encoding, it lacks clarification on how these embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide additional details to improve the clarity and comprehensibility of their methodology. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how others have handled similar challenges. Overall, the comment is 4, as it effectively highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the novelty of the paper\"s approach, suggesting that the introduction of multigranularity and multiscale for enhancing model performance is a common approach in convolutional networks and not an innovative contribution when applied to the field of MLMs. It also points out that some algorithms used in the article from object detection only enhance information on the input side, while many MLMs can already perform object detection tasks themselves. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how the authors might improve the novelty of their contribution or address the issues raised. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper\"s approach, suggesting that the introduction of multigranularity and multiscale for enhancing model performance is a common approach in convolutional networks and not an innovative contribution when applied to the field of MLMs. It also points out that some algorithms used in the article from object detection only enhance information on the input side, while many MLMs can already perform object detection tasks themselves. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of specific references or detailed guidance on how to address these issues limits the comment\"s effectiveness. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the novelty of the paper\"s approach, suggesting that the introduction of multigranularity and multiscale for enhancing model performance is a common approach in convolutional networks and not an innovative contribution when applied to the field of MLMs. The reviewer provides a logical reasoning by pointing out that many algorithms used in object detection can already perform object detection tasks, implying that the approach is not novel. However, the comment lacks specific references or examples to support the claim that the approach is not innovative or novel. This makes the claim 3, as it provides a general rationale but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the paper\"s approach, suggesting that the introduction of multigranularity and multiscale for enhancing model performance is a common approach in convolutional networks and not an innovative contribution when applied to the field of MLMs. It also points out that some algorithms used in the article from object detection only enhance information on the input side, while many MLMs can already perform object detection tasks themselves. This feedback highlights a potential issue with the paper\"s originality and suggests that the authors need to reconsider their approach to ensure it is truly innovative. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the novelty of their contribution. While it identifies a problem, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential issues with similarityaware positive sample selection in GNNbased encoder oversmoothing and the impact on generalization performance. It suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on which specific experiments to perform or how to design them. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential issues with similarityaware positive sample selection in GNNbased encoder oversmoothing and the impact on generalization performance. It suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the encoder oversmoothing or the experiments conducted, making it weakly grounded. The comment is specific in its suggestions for further experiments, but without explicit grounding, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential issues with similarityaware positive sample selection in GNNbased encoder oversmoothing and the impact on generalization performance. The reviewer questions whether selecting similar nodes or graphs could lead to oversmoothing and whether this selection without perturbation noise would affect generalization. The comment suggests that the authors should conduct more experiments on different downstream tasks and domains to address these concerns. However, the comment lacks specific examples, detailed reasoning, or references to support the claims about oversmoothing or generalization issues. This makes the claim 3, as the authors would need to further develop their understanding to address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the potential issues with similarityaware positive sample selection in GNNbased encoder oversmoothing and the impact on generalization performance. It questions whether selecting similar nodes or graphs could lead to oversmoothing and whether this selection without perturbation noise would affect generalization. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies a potential weakness in the methodology and provides a direction for improvement, it lacks specific suggestions or guidance on how to design these additional experiments. This makes the feedback 3, as it highlights areas for improvement but does not fully support the authors in executing them. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that more discussion on the power of different architectures would be beneficial. While the comment implies that the authors should provide more analysis or discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion of different architectures. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more discussion on the power of different architectures, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question and a suggestion for more discussion on the power of different architectures. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that more discussion on the power of different architectures would be beneficial. While the comment identifies an area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for expansion, but it does not offer actionable steps or examples to guide the authors in making improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their methods across different splits of trainvaltest instead of relying on different initialisation seeds to obtain robust results. This feedback provides a clear and explicit action for the authors to take, specifying that they should consider varying the splits of the training, validation, and test sets. The suggestion is concrete, as it outlines a specific method for improving the robustness of the results. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the methods across different splits of trainvaltest instead of relying on different initialisation seeds to obtain robust results. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where this evaluation should be conducted. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would provide more robust results compared to relying on different initialisation seeds. This claim is 3 as it provides a logical reasoning for why varying splits might be more beneficial. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the robustness of the results by recommending that the authors evaluate their methods across different splits of trainvaltest instead of relying on different initialisation seeds. This feedback is clear and offers a concrete way for the authors to enhance the reliability and generalizability of their findings. By addressing this suggestion, the authors can potentially improve the robustness of their results, making the comment 5. However, it could be more helpful if it included additional guidance on how to implement this suggestion or why this approach is expected to yield better results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first two bullet points about contributions, located at the end of the introduction, can be combined together. This is a clear and explicit action, as it provides a direct instruction for the authors to merge the two points. The comment also offers concrete guidance on how to implement this action, by specifying which parts need to be combined. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions\" located at the end of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely combining these two bullet points. This guidance is actionable and provides a concrete step for the authors to take, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the first two bullet points about contributions in the introduction can be combined together. However, it does not provide any reasoning, justification, or examples to support why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft by recommending that the first two bullet points about contributions, located at the end of the introduction, can be combined together. This feedback is clear and directly addresses a potential redundancy or duplication in the paper, offering a concrete step for the authors to take to enhance the clarity and conciseness of their work. By providing a specific suggestion, the comment empowers the authors to make a meaningful improvement to their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the types of situations or social norms, such as physical or psychological safety, are not clearly described in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify these concepts or improve the clarity of their presentation. Without specific suggestions or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the clarity of the types of situations or social norms mentioned in the main paper. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the description of these concepts, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms, such as physical or psychological safety, are not clearly described in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the types of situations or social norms mentioned in the main paper. It highlights that these concepts are not clearly described, which is a significant concern for the paper\"s comprehensibility and impact. However, the comment does not provide any suggestions or guidance on how the authors might improve the clarity of these concepts or integrate them more effectively into the paper. Without actionable feedback or specific advice, the authors are left without a clear path to address the identified issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more baselines and test more domains to strengthen their empirical results. It also points out that the choices of weighting and the way of learning density functions are not strongly motivated, implying that the authors should provide more justification for these choices. While the comment implies that the authors should conduct additional experiments and provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more baselines and domains should be compared and tested, respectively, to strengthen the empirical results. It also points out that the choices of weighting and the way of learning density functions are not strongly motivated, implying that the authors should provide more justification for these choices. However, the comment does not specify which sections or parts of the paper should include these additional comparisons or domains, making it weakly grounded. The suggestion to include more baselines and domains is specific, but without explicit references to sections, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines and domains should be compared and tested to strengthen the empirical results. It also questions the motivation behind the choices of weighting and the way of learning density functions, implying that these choices are not strongly justified. However, the comment lacks specific examples or references to support the claim that the current choices are not wellmotivated or that additional baselines and domains would provide stronger results. This makes the claim 3, as the authors would need to provide more detailed reasoning or evidence to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include more baselines and test more domains to strengthen their empirical results. It also points out that the choices of weighting and the way of learning density functions are not strongly motivated, implying that the authors should provide more justification for these choices. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address these issues or what specific baselines or domains should be considered. The feedback is 3 as it highlights important aspects that could enhance the paper\"s empirical evaluation, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a direct and clear action, providing the authors with a specific task to address. The comment is explicit and concrete, as it clearly identifies what needs to be done and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is defining the dashed lines in these figures. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to define the dashed lines in figures 2AB and 4B. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a request for clarification, specifically asking the authors to define the dashed lines in figures 2AB and 4B. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is vague and lacks actionable advice, making it 2. The authors are left with a request for clarification but without any further direction on how to improve their draft. Therefore, the comment aligns with a score of 2, indicating that it is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the results are not comparable to existing methods, implying that the proposed methods may not be significant. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the significance of their proposed methods. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, implying that the proposed methods may not be significant. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the results are not comparable to existing methods. Without explicit references to sections, figures, or specific results, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable to existing methods. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods may not be significant. However, the comment lacks specific examples or references to existing methods that could be used for comparison, making it difficult for the authors to understand the basis of this claim. Without detailed justification or evidence, the claim remains 1, as it does not provide a clear rationale or examples to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential issue with the significance of the proposed methods, suggesting that the results are not comparable to existing methods. However, it lacks specificity and does not provide detailed feedback or suggestions on how the authors might address this concern. Without actionable guidance or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically the DeCorr method, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. The reviewer also notes that the paper lacks enough insights into the unique challenges of overcorrelation in recommender systems, despite proposing modifications like different penalty coefficients for users and items. However, the comment does not provide explicit guidance or concrete suggestions on how the authors could address these issues or enhance the novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to explore and address the unique challenges of overcorrelation in recommender systems. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically the DeCorr method, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. The reviewer also notes that the paper lacks enough insights into the unique challenges of overcorrelation in recommender systems, despite proposing modifications like different penalty coefficients for users and items. However, the comment does not specify which sections of the paper should be revised or expanded to address these issues, making it weakly grounded. The comment is specific in detailing what is considered lacking in novelty and contribution, but it does not provide explicit guidance on how to improve the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically the DeCorr method, in a specific application domain. The reviewer supports this claim by pointing out that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim about the lack of unique insights or contributions. While the authors might infer that the paper lacks originality, the lack of explicit examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically the DeCorr method, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment points out that the paper lacks enough insights into the unique challenges of overcorrelation in recommender systems, despite proposing modifications like different penalty coefficients for users and items. While the comment provides some insight into the potential areas for improvement, it lacks specific suggestions or actionable guidance on how the authors could address these challenges or enhance the novelty of their work. The feedback is 3 as it directs the authors to consider the unique aspects of their study, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear explanations of some symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies an issue with the figure and suggests that the reviewer is curious about a specific aspect, it does not provide explicit guidance on how to clarify the symbols or address the question about redundancy and interference. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the symbols and explore the question about redundancy and interference. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the ambiguity in the figure due to unclear explanations of some symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear explanations of some symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not clearly explained, which could hinder understanding. It also raises a question about information redundancy and interference in the multisphere icosahedral discretization process, prompting the authors to consider this aspect. While the comment highlights a potential weakness in the figure and suggests an area for further exploration, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, which is acceptable for Gaussian kernels. However, it notes that Matern kernels, which are another popular class, have spectra that decay polynomially, making the results potentially restrictive. While the comment identifies a potential limitation, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should consider including Matern kernels or discuss the implications of their assumption. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the paper regarding the assumption about the spectrum of a kernel being subgaussian. It highlights that while Gaussian kernels are in this class, Matern kernels, which are another popular class, have spectra that decay polynomially, potentially making the results restrictive. This provides a clear and specific point for the authors to consider, allowing them to identify the part of the paper that needs attention. However, the comment does not explicitly mention which section or part of the paper this issue pertains to, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It supports this claim by noting that while Gaussian kernels are in this class, Matern kernels, which are another popular class, have spectra that decay polynomially. This provides a logical reasoning for the potential restriction of the results. However, the comment could be strengthened by providing more detailed examples or references to specific studies that discuss the implications of this assumption. Overall, the claim is 4, as it is supported by logical reasoning but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s results, specifically regarding the assumption that the spectrum of a kernel is subgaussian. It points out that while Gaussian kernels are in this class, Matern kernels, which are another popular class, have spectra that decay polynomially, potentially making the results restrictive. This feedback is clear and actionable, as it highlights a specific area where the authors might need to expand their analysis or discussion. However, the comment could be more helpful if it provided suggestions on how to address this limitation or explored the implications of this assumption. Overall, the comment is 4, as it provides valuable insight into a potential weakness in the paper\"s results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain. It provides a clear action by recommending that the authors include a detailed discussion on this topic. Additionally, the comment implies that the authors should consider the comparison with the ablation study in Table 5, which further supports the need for detailed discussion. The suggestion is concrete and provides a clear direction for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of detailed discussion on the unsupervised pretraining in the main paper and suggests that it is more important than other modules presented in the paper. The comment provides a clear recommendation for the authors to focus more on the pretraining method, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by the data in Table 4. However, it lacks detailed discussion on this topic in the main paper, which is a concern. The reviewer suggests that the unsupervised pretraining is more important than other modules, as evidenced by the comparison with the ablation study in Table 5. While the comment provides some logical reasoning and a reference to a comparison, it lacks specific examples or detailed analysis to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but lacks detailed discussion in the main paper. It suggests that the authors should focus more on this aspect, as it is more important than other modules presented in the paper, as evidenced by the comparison with the ablation study in Table 5. This feedback is clear and actionable, providing the authors with a specific area to improve their draft by enhancing the discussion on unsupervised pretraining. The suggestion for focusing on this aspect is constructive and can lead to significant improvements in the paper\"s presentation and analysis. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of ELMs (male or female) and whether the gender of the speaker needs to be known beforehand. It suggests that this might be a drawback because accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their methodology. The action is implicit and vague, as it does not specify how to resolve the concern or what changes could be made to the draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the selection of ELMs (male or female) and whether the speaker\"s gender needs to be known beforehand. It suggests that this might be a drawback because accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the necessity of knowing the speaker\"s gender beforehand, but without clear grounding, the authors cannot easily identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the selection of ELMs (male or female) and whether the speaker\"s gender needs to be known beforehand. It suggests that this might be a drawback because accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that this is a drawback. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the selection of ELMs (male or female) and whether the speaker\"s gender needs to be known beforehand. It suggests that this might be a drawback because accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. While it identifies a potential limitation, it lacks actionable advice or detailed feedback, making it 3. The authors gain some insight into a potential area of concern but are left without clear direction on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide specific examples of where the writing is unclear or how the authors can simplify it. Without explicit guidance or concrete suggestions, the authors are left to infer that they need to revise the writing to make it clearer. This lack of detailed guidance makes the comment 3, as the authors can identify the need for improvement but may struggle to determine the exact steps to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment indicates that the writing is difficult to follow in many places and suggests it can be simplified. However, it does not specify which sections or parts of the paper are challenging to follow, nor does it provide details on what aspects of the writing could be improved. Without specific references or examples, the authors cannot confidently determine which parts need revision or clarification. This makes the comment weakly grounded, as it lacks specific guidance on what needs to be addressed, and it is not specific in detailing the issues. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests it can be simplified. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the writing is difficult to follow in many places and suggests that it can be simplified. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors might simplify the writing or what aspects are particularly challenging. Without actionable advice or examples, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, merely adding a new loss to 31. However, it does not provide any explicit or implicit actions for the authors to take to improve the paper. There is no guidance on how the authors might enhance the technical depth or address the incremental nature of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning the addition of a new loss to 31. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is 1 as it does not provide clear references or specific areas within the paper that are being criticized. Additionally, while it points out a lack of technical substance, it does not specify what aspects of the paper could be improved to address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, merely adding a new loss to 31. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the paper, noting that it is incremental and lacks technical substance, merely adding a new loss to 31. This feedback highlights a critical weakness in the paper\"s contribution, suggesting that it does not provide substantial new insights or advancements. However, the comment does not offer any specific suggestions or guidance on how the authors might address this issue or enhance the technical depth of their work. Without actionable advice or constructive feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide some intuition about the proof of Theorem 1 and questions the dependency of the invertible function $f^*$ on the fixed $P^*$. It also asks about the practical determination of which $P^*$ to fix. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to elaborate on the proof and explore the dependency of $f^*$ on $P^*$, but the comment lacks detailed guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and the invertible function $f^*$, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed questions about the proof of Theorem 1, the dependency of $f^*$ on $P^*$, and practical considerations for determining which $P^*$ to fix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the proof of Theorem 1 and the dependency of the invertible function $f^*$ on the fixed $P^*$. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are purely factual and seek clarification, making the comment \"No\".", "helpfulness_rationale": "The review comment provides specific questions and suggestions for improvement regarding the paper\"s content. It asks for intuition about the proof of Theorem 1, which could help the authors enhance the understanding of the theoretical basis of their work. Additionally, it questions the dependency of the invertible function $f^*$ on the fixed $P^*$ and seeks clarification on how to determine which $P^*$ to fix in practice. These questions are actionable and provide the authors with clear directions for improving their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how to enhance the proof. Overall, the feedback is 4 as it guides the authors toward specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the use of different variables (X and H^(1)) in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to improve the consistency of the equations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of different variables (X and H^(1)) in these equations, prompting the authors to explain why they are not analogous. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the use of different variables in equations (7) and (10). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of different variables (X and H^(1)) in equations (7) and (10), questioning why they are not analogous. While it identifies a potential inconsistency in the equations, it does not provide any suggestions or guidance on how the authors might address this issue or improve the consistency of their equations. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors could provide empirical evidence to support the claim that their model captures the diffusion phenomena in realworld scenarios. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a concern about the applicability of the model to realworld diffusion processes, which is a specific issue. However, it does not explicitly mention which part of the paper this concern pertains to, making it weakly grounded. The comment is specific in suggesting that the authors provide empirical evidence to support the claim that their model captures diffusion phenomena in realworld scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors should provide empirical evidence to support their claim. However, the comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand and address the concern effectively. The absence of detailed reasoning or evidence makes the claim 2, as it provides a direction for improvement but lacks the necessary support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the interesting problem and elegant solutions presented in the paper but highlights the need for empirical evidence to support the claim that the proposed model captures diffusion phenomena in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by including empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct or present this evidence. Overall, the comment is 4, as it effectively guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to better understand its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on which datasets to use or how to analyze the results. Therefore, the comment is 3, as it provides a general direction for improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to better understand its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the need for more datasets, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to better understand its performance. However, it does not provide any specific reasoning, examples, or references to support why testing on more datasets would be beneficial or how it would improve the understanding of the method\"s performance. The lack of detailed justification or evidence makes the claim 1, as the authors would need to make an educated guess about the reasoning behind the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on two datasets. This is a relevant observation that could impact the generalizability and robustness of the method\"s performance. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation, such as recommending additional datasets or explaining why the current datasets might not be sufficient. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their contribution. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, specifically mentioning that combining attention with other linear mechanisms is not novel. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution are considered noninnovative. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision or clarification. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper\"s note on this. However, the comment lacks specific examples or references to support the claim that the contribution is not novel. Without detailed evidence or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper\"s note on this. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve their contribution. Without actionable feedback or guidance, the comment does not assist the authors in making improvements to their draft. Therefore, it is rated as 2, as it identifies a potential issue but lacks depth and direction for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a plot showing how different weights of the model change after unlearning, which could help identify which layers are most affected. This feedback is explicit, as it clearly states what the authors should do, and it is concrete because it specifies exactly what kind of plot to include. The authors know exactly how to apply this action, making the comment 5.", "grounding_specificity_rationale": "The comment suggests providing a plot to show how different weights of the model change after unlearning, which could help identify which layers are most affected. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a plot, but without clear grounding, the authors may struggle to determine where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot to show how different weights of the model change after unlearning, which could help identify which layers are most affected. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this plot is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to improve their draft. It recommends including a plot to visualize how different weights of the model change after unlearning, which could help identify which layers are most affected. This feedback is clear and offers a concrete way for the authors to enhance the interpretability of their results, making it 4. However, the comment could be more helpful if it provided additional guidance on how to create the plot or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the paper is limited, specifically mentioning that the ENCODE part has already been proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes the M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or how they could enhance the paper\"s contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the novelty of the paper and the ENCODE part, which has already been proposed in 10. It also specifies the incremental contribution, which lies in the decomposition part, factorizing the M_v into factor D and slices Phi_v. However, the comment does not explicitly mention which part of the paper this relates to, such as a specific section or methodology section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in detailing what is considered novel and what the incremental contribution is. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part has already been proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes the M_v into factor D and slices Phi_v. This claim is 3 as it provides a specific reference to an existing work (10) and logically explains the incremental contribution. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a perceived limitation in the novelty of the paper, specifically pointing out that the ENCODE part has already been proposed in 10. It also mentions that the incremental contribution lies in the decomposition part, which factorizes the M_v into factor D and slices Phi_v. While the comment highlights a potential issue with the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback lacks actionable advice, making it 3 as it points out a potential weakness but does not offer a clear path for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they seem to lie in the same sphere but this is not mentioned in the paper. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they seem to lie in the same sphere but this is not mentioned in the paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the issue of the domain of the inputs not being mentioned, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they seem to lie in the same sphere but this is not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they seem to lie in the same sphere but this is not mentioned in the paper. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is 2, as it points out a potential area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the performance comparison with another work that also proposes a CLN (region proposal generation algorithm). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should conduct such a comparison, what specific aspects to focus on, or how to present the results. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to follow to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison with another work that proposes a CLN (region proposal generation algorithm). However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the performance comparison with another work that proposes a CLN (region proposal generation algorithm). However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\"s claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance comparison with another work that proposes a CLN (region proposal generation algorithm). However, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of the comparison should be considered. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft in response to this feedback. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the presentation is too equationdriven and that the notation, especially in Chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to create the figure or what specific aspects of the notation should be clarified. The action is implicit and somewhat vague, as the authors know they need to improve the presentation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Chapter 3\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the issue of the presentation being too equationdriven and the convoluted nature of the notation, suggesting that an illustrative figure would be helpful. This provides clear guidance on what needs to be improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in Chapter 3 is convoluted and hard to follow. The reviewer suggests that an illustrative figure would be helpful. However, the comment lacks specific examples or detailed reasoning to support why the presentation is too equationdriven or why the notation is convoluted. Without concrete evidence or examples, the claim is 3, as it provides a general observation but lacks the detailed justification needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in Chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in Section 3 would be helpful. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and effectiveness of the presentation. However, the comment could be more helpful if it offered additional guidance on how to create the illustrative figure or what specific aspects of the notation should be clarified. Despite this, the comment is 4 as it directs the authors\" attention to a critical area for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the use of Z\u00e2\u0080\u0099 as the empty set. It highlights a discrepancy between the expectation that x and y would be independent given W, but contradicts this with Equation (7). While the comment points out a specific issue, it does not provide explicit guidance on how the authors should address this conflict or suggest a resolution. The action is implicit and somewhat vague, as the authors need to infer that they should reconcile this discrepancy, but without concrete steps, the action remains unclear. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, providing a clear explanation of the issue. The comment specifies what needs to be addressed, namely the potential conflict and the discrepancy between the expectation and the equation. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the use of Z\u00e2\u0080\u0099 as the empty set. The reviewer provides a logical reasoning by explaining that if Z\u00e2\u0080\u0099 is the empty set, x and y should be independent given W, but Equation (7) contradicts this. This reasoning is clear and provides a specific example of the conflict, making the claim 5. The comment is wellsupported by logical reasoning and a concrete example, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with Lemma 2, particularly the conflict between the second rule and the definition of minimal conditional dependence. It highlights a discrepancy where, if Z\u00e2\u0080\u0099 is considered the empty set, x and y should be independent given W, but Equation (7) contradicts this. This feedback is clear and actionable, as it points out a potential error in the paper\"s formulation and suggests that the authors should reconcile this discrepancy. However, the comment could be more helpful if it provided guidance on how to address the conflict or suggested a possible resolution. Overall, the comment is 4 as it directs the authors\" attention to a critical issue that needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies an area for improvement, it does not provide explicit guidance on how to enhance the subscripts or suggest specific changes. The action is implicit, as the authors can infer that they need to improve the visual presentation, but it lacks concrete details on how to achieve this enhancement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be enhanced for better readability and aesthetic appeal. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is lacking or how it could be improved. Without additional context or suggestions, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2, as it provides a general suggestion but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of the data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a concrete suggestion for improving the visual presentation, which is a critical aspect of effectively communicating results. By addressing this feedback, the authors can enhance the clarity and visual appeal of their work, making the comment 5. However, the comment could be more helpful if it provided additional guidance on how to improve the subscripts or suggested specific design elements to consider. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their bias in estimating the real gradient distribution. The reviewer expresses confusion about why Online Normalization is considered unbiased while Batch Normalization is biased. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this confusion or clarify the distinction in their paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the difference between Batch Normalization and Online Normalization, particularly their bias in estimating the real gradient distribution. However, it does not specify which part of the paper discusses this claim, making it weakly grounded. The comment is specific in detailing the confusion about why Online Normalization is unbiased and Batch Normalization is biased. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their bias in estimating the real gradient distribution. The reviewer expresses confusion about why Online Normalization is considered unbiased while Batch Normalization is biased. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or justification makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their bias in estimating the real gradient distribution. The reviewer expresses confusion about why Online Normalization is considered unbiased while Batch Normalization is biased. However, the comment does not provide any actionable feedback or suggestions for the authors to address this confusion or improve their understanding of the topic. Without specific guidance or insights, the authors are left without a clear path forward for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a significant issue that violates the 9page paper limit. This comment provides a clear and direct action for the authors to take, which is to address the whitespace issue. However, it does not offer specific guidance on how to improve the whitespace or suggest alternative formatting strategies. While the action is explicit, the lack of detailed instructions on execution makes it 3. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem by mentioning that equations are crammed together and captions are too close to the figures, which provides clear guidance on what needs to be addressed. The comment further supports the claim by stating that this issue violates the 9page paper limit, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, which violates the 9page paper limit. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the whitespace reduction has caused a significant issue. Without such details, the claim remains 1, as it is difficult for the authors to understand the extent of the problem or how to address it. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace throughout, which violates the 9page paper limit. This is a clear and actionable feedback that can help the authors understand the extent of the problem and make necessary adjustments to meet the formatting requirements. However, the comment could be more helpful if it provided suggestions on how to improve the whitespace or offered alternative formatting strategies. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited and suggests that the main novelty is reflected in the scheme or procedure. However, it does not provide explicit guidance on what specific aspects are lacking or how the authors should address this issue. The comment implies that the authors should expand on the technical details and formulations, but it does not offer concrete steps or suggestions for how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a concern about the technical details and formulations being limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment lacks specificity regarding what aspects are lacking in terms of technical details or formulations. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 1, as it lacks the necessary information to substantiate the argument. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the novelty is reflected in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors could address this issue or improve the technical aspects of their work. The feedback lacks actionable advice, such as recommending additional details or specific areas for expansion. As a result, the comment offers limited value to the authors in terms of improving their draft, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should clarify this concept. The action is implicit, as the authors can infer that they need to address the ambiguity, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. This question is specific and directly addresses a potential area of confusion in the paper. However, it does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the section discussing local interactions, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. This is a request for clarification rather than a claim that requires verification. The comment does not express an opinion, judgment, or suggestion that needs evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the concept of local interactions. It specifically asks whether the term refers to interactions within a time window or within the same modality. This question highlights a critical area of confusion that the authors need to clarify to ensure the clarity of their work. By addressing this issue, the authors can improve the understanding of their methodology and enhance the overall quality of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify the concept or examples of how to do so. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to comment on how the archetype positions are updated after initialisation. This is a direct and clear request for additional explanation or clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it clearly identifies what needs to be addressed and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear about the algorithm, namely the update process of the archetype positions after initialisation. The comment requests a comment on this aspect, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the update process of the archetype positions after initialisation in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of confusion regarding the update process of the archetype positions after initialisation in Algorithm 2. By pointing out this ambiguity, the comment provides the authors with a clear and actionable suggestion to clarify their methodology. However, the comment could be more helpful if it offered additional guidance on how to address this issue or suggested potential ways to improve the clarity of the explanation. Overall, the feedback is clear and actionable, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several areas where additional information is missing and suggests that these details should be included in the supplement. Specifically, it mentions the need to record parameters for the MRI, preprocessing steps, and the conditions under which the restingstate was recorded (eyesopen or eyesclosed). Additionally, it requests a brief explanation of the harmonization technique and the number of regions in the parcellation. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific elements of the empirical study, such as recording parameters for MRI, preprocessing steps, and the conditions under which the restingstate was recorded. It also suggests including a brief explanation of the harmonization technique and the number of regions in the parcellation. This provides clear guidance on what information is missing and how it should be presented. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that important information about the empirical study is missing and should be included in the supplement. It specifically mentions details such as MRI parameters, preprocessing steps, recording conditions, and the number of regions in the parcellation. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claim that these details are missing. The suggestion is based on logical reasoning about the importance of detailed information in empirical studies, but without additional context or evidence, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, suggesting that they should be included in the supplement. It specifically mentions details such as MRI parameters, preprocessing steps, recording conditions (eyesopen or eyesclosed), and the number of regions in the parcellation. Additionally, it requests a brief explanation of the harmonization technique. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. By addressing these points, the authors can enhance the comprehensiveness and clarity of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a major risk associated with methods that exploit relationships between action units, specifically the variability in cooccurrences across different datasets. It provides a concrete example of how this variability can manifest, using Figure 1 as a reference. The comment suggests that the paper lacks crossdataset experiments to test the generalization of such work. This feedback is explicit and provides a clear action for the authors to take, which is to conduct crossdataset experiments. The suggestion is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the variability in cooccurrences of action units across different datasets and suggests a potential solution by recommending crossdataset experiments. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may have a major risk due to variability across datasets. It provides a specific example of AU6 occurring in different contexts and suggests that crossdataset experiments could test the generalization of such work. The comment is 4 as it logically explains the issue and provides a clear example, but it could be strengthened by referencing specific studies or datasets to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically the variability in cooccurrences across different datasets. It provides a concrete example of how this variability can manifest, using Figure 1 as a reference, and suggests that the paper lacks crossdataset experiments to test the generalization of such work. This feedback is clear and actionable, offering a specific suggestion for improvement by recommending crossdataset experiments. The comment effectively highlights a critical weakness in the paper and provides a constructive path for the authors to enhance their work. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide a more detailed description of the Starcraft environment, possibly in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact nature of the additional description needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide a more detailed description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this description should be included in, making it weakly grounded. The comment is specific in its suggestion to include more details about the Starcraft environment, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide a more detailed description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning or evidence to support why this additional description is necessary or beneficial. The comment lacks detailed justification or examples, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors provide a more detailed description of the Starcraft environment, potentially in an appendix. This feedback is 3 as it identifies a specific area for improvement, which is the inclusion of additional context or details about the environment. However, the comment lacks depth and does not specify what aspects of the Starcraft environment should be elaborated upon or how this additional information would benefit the paper. While it points out a potential area for enhancement, it does not offer actionable guidance on how to achieve this improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization is actually beneficial for supervised learning in deep neural networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this critique, improve the draft, or incorporate the theoretical work mentioned. As a result, the authors are left without any actionable steps to follow, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement about overparametrization leading to overfitting and worse performance, and provides context by mentioning the benefits of overparametrization in supervised learning for deep neural networks. Additionally, it references theoretical work, which adds depth to the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the statement that \"overparametrization invariably overfits the data and results in worse performance,\" suggesting that overparametrization is actually beneficial for supervised learning in deep neural networks. The reviewer supports this claim by referencing theoretical work, such as 1, which provides a basis for the critique. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques a statement about overparametrization leading to overfitting and worse performance, suggesting that this is not the case in practice. It acknowledges the benefits of overparametrization in supervised learning for deep neural networks and references theoretical work to support this claim. This feedback is 3 as it challenges the authors to reconsider their assumptions and provides a rationale for why overparametrization might be beneficial. However, it lacks specific guidance or suggestions on how the authors could address this critique or incorporate the theoretical work into their paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the timeconsuming nature of the training process due to the pixellevel shape model and the highorder factor graph used in the parsing model. It suggests that the authors should describe and compare the processing efficiency of their training and testing with existing work. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to conduct these comparisons or what specific metrics should be used. The action is implicit and somewhat vague, as the authors need to infer the need for efficiency comparisons and determine the best way to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the training process due to the pixellevel shape model and the highorder factor graph used in the parsing model. It suggests that the authors should describe and compare the processing efficiency of their training and testing with existing work. However, the comment does not specify which part of the paper discusses the training process or the parsing model, making it weakly grounded. The comment is specific in suggesting that the authors should compare their processing efficiency with existing work, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the training process is timeconsuming due to the pixellevel shape model and the highorder factor graph used in the parsing model. The comment suggests that the authors should describe and compare the processing efficiency of their training and testing with existing work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the timeconsuming nature of the process. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the training process due to the pixellevel shape model and the highorder factor graph used in the parsing model. It suggests that the authors should describe and compare the processing efficiency of their training and testing with existing work. This feedback is 3 as it highlights a potential weakness in the methodology and provides a direction for improvement by suggesting a comparison with existing work. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using more recent and effective domain adaptation methods to improve the performance of their framework. It implies that the current method is outdated and suggests that the authors should explore alternative approaches. While the comment implies that the authors should use other domain adaptation methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider using more advanced methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the combination of two existing techniques and suggests that the domain adaptation method used is outdated. It implies that the authors should consider using more recent and effective domain adaptation methods. However, the comment does not specify which part of the paper discusses the combination of techniques or the domain adaptation method, making it weakly grounded. The suggestion to use other domain adaptation methods is specific, as it clearly indicates what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have combined two existing techniques without innovation, suggesting that the adversarial attack or correction method and the domain adaptation method used are not novel. It also criticizes the use of an outdated domain adaptation method, which was proposed eight years ago, and suggests that more recent and effective methods should be considered. The comment provides a logical reasoning by pointing out the lack of innovation and the use of outdated methods, which supports the claim. However, it does not provide specific references to prior work or examples of more recent methods, which would strengthen the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s approach, noting that the authors have combined two existing techniques without introducing any innovation. It points out that the adversarial attack or correction method and the domain adaptation method used are not novel, as they have been proposed by prior work. Additionally, the comment critiques the use of an outdated domain adaptation method, which was proposed eight years ago, and suggests that the authors should consider using more recent and effective methods to improve performance. This feedback is clear and actionable, as it directs the authors to explore more advanced and relevant techniques in the field. However, the comment could be more helpful if it provided specific examples of recent domain adaptation methods or suggested how to integrate them into the framework. Overall, the comment is 4, as it effectively guides the authors toward enhancing their work by incorporating more modern approaches."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a discussion on the creation of the prompt dataset for the fewshot case, along with its source. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is specific and concrete, leaving no ambiguity about the required changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests discussing the creation of the prompt dataset for the fewshot case, including its source. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a discussion on the prompt dataset and its source, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset (for the fewshot case) creation, along with its source, should be included. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors include a discussion on the creation of the prompt dataset for the fewshot case, along with its source. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by addressing a potential gap in the discussion. However, the comment could be more helpful if it offered additional guidance on how to effectively present this information or why it is important. Despite this, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from an incremental engineering paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not specify which part of the paper this issue is related to, nor does it provide details on what aspects of the motivation are unclear or how the paper might be incremental. Without specific references or detailed feedback, the authors cannot confidently determine which sections or elements need attention. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"very difficult to follow the motivation\" and suggests that it appears to be an incremental engineering paper. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 1 due to the lack of supporting details or examples.", "helpfulness_rationale": "The review comment points out that the motivation of the paper is difficult to follow and suggests that the paper may appear to be an incremental engineering paper. While it identifies a potential issue with the paper\"s structure or presentation, it lacks specific guidance or suggestions on how the authors might improve the clarity of the motivation or differentiate their work from incremental engineering. The feedback is 3 as it highlights an area for improvement, but it does not provide actionable steps or detailed advice for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It provides a specific example, mentioning that the authors note the method underperforms in Atlantis due to repetitive background sounds, which the reviewer expects the weighting method might have helped remedy. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the study and understand the reasoning behind it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, which is a specific suggestion for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment does specify what the authors should do\u2014conduct an ablation study to evaluate the weighting method\u2014providing some level of specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It provides a specific example, mentioning that the authors note the method underperforms in Atlantis due to repetitive background sounds, which the reviewer expects the weighting method might have helped remedy. This reasoning is logical and provides a clear example of a scenario where the weighting method could be beneficial. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore and understand the reasoning behind the suggestion to fully address it.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which is a specific and actionable suggestion for the authors to improve their draft. It provides a concrete example, noting that the method underperforms in Atlantis due to repetitive background sounds, which the reviewer expects the weighting method might have helped remedy. This feedback is clear and provides a direction for the authors to enhance their work by exploring the effectiveness of their weighting method. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It highlights that the authors have designed a new dataset based on an existing dataset, SQUALL, and mentions a synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It specifically mentions the design of a new dataset based on an existing dataset, SQUALL, and a synthetic benchmark paper. However, the comment does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these discussions occur, the comment lacks full grounding. It is specific in identifying the issue of novelty and incremental nature but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and incremental nature, specifically mentioning the design of a new dataset based on an existing dataset, SQUALL, and a synthetic benchmark paper. The comment provides some context by mentioning the specific design choices, but it does not offer detailed reasoning or examples to fully substantiate the claim. This makes the claim 3, as the authors would need to infer the lack of novelty and incremental nature themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It highlights that the authors have designed a new dataset based on an existing dataset, SQUALL, and mentions a synthetic benchmark paper based on a single question template. While this feedback points out a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable advice, making it 3 as it alerts the authors to a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include more game environments. While the comment implies that the authors should conduct additional experiments, it does not specify which additional environments should be considered or how this would impact the results. The action is implicit and somewhat vague, as the authors need to infer the specific environments to include and the extent to which they should expand the experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be expanded to include more game environments, indicating a need for additional experiments. However, it does not specify which game environments should be considered or how this would impact the results. The authors can infer that the comment relates to the experimental section, but they cannot pinpoint the exact part of the paper that needs improvement. The lack of specificity in suggesting additional environments or detailing the impact of expanding the experiments makes the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental design, noting that only one game environment is used. It suggests that more experiments are necessary to provide a more comprehensive evaluation. While the comment highlights an important area for improvement, it lacks specific guidance on which additional environments should be considered or how the experiments could be expanded. This limits the utility of the feedback for the authors, as it provides a general direction but lacks actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests using solid examples to support this explanation. This feedback provides a clear and direct action for the authors to take, specifying what needs to be addressed and how to do it. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain why removing certain assumptions, like bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for examples to support the explanation of the contribution, but without clear grounding, the authors may struggle to identify the exact section where this explanation should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are critical or how their removal impacts the contribution. Without this additional context, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. This feedback is clear and actionable, as it prompts the authors to provide a rationale or examples to support the significance of their contribution. However, the comment could be more helpful if it offered guidance on how to effectively present this explanation or suggested specific examples to illustrate the importance of these assumptions. Overall, the comment is 4 as it directs the authors toward a critical aspect of their work that needs further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the authors\" claim of implementing ImageNet for the first time, noting that it is slow and has low accuracy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements, alternative approaches, or additional experiments to validate their claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of implementing ImageNet for the first time, noting that it is slow and has low accuracy. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some specific details about the performance metrics, it lacks grounding as it does not reference a specific section or figure. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors have implemented ImageNet for the first time but notes that it is slow and has low accuracy, providing specific metrics such as the time required to test an ImageNet picture and the accuracy rate. This claim is supported by concrete data, making it 4. However, the comment could be strengthened by referencing specific studies or comparisons to establish the significance of these metrics. Overall, the comment provides a solid foundation for the claim, but it could be more robust with additional evidence or context. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the authors\" claim of implementing ImageNet for the first time, noting that it is slow and has low accuracy. It provides specific metrics, such as the time required to test an ImageNet picture and the accuracy rate, which are crucial for understanding the problem. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their implementation. While it highlights a critical weakness, it does not provide enough detail or direction for the authors to make meaningful improvements. Therefore, the comment is 3, as it points out a problem but does not offer comprehensive guidance for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, which would help clarify the context for readers. Additionally, it requests an explanation of the correspondence between the learning curves and MPHATE in Figure 3, which is a specific request for detailed analysis. The comment also poses questions about the learning curves, such as why the authors want to look at them, whether worseperforming models always result in structural collapse, and what specific accuracy numbers are being referred to. These questions and suggestions provide clear guidance on how the authors can improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for additional explanations of the experimental setting for continual learning and the correspondence between learning curves and MPHATE. The comment further requests clarification on why the authors want to look at the learning curves, whether worseperforming models always result in structural collapse, and what specific accuracy numbers are being referred to. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification, rather than making subjective claims or judgments. It does not contain any opinions, suggestions, or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the draft. It requests additional explanations regarding the experimental setting for continual learning, which can help clarify the context for readers. Additionally, it asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3, which is a clear request for detailed analysis. The comment also poses questions about the learning curves, such as why the authors want to look at them, whether worseperforming models always result in structural collapse, and what specific accuracy numbers are being referred to. These questions and suggestions provide valuable guidance for the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered more detailed feedback or examples. Overall, the comment is 4 as it directs the authors to specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in the context of graph anomaly detection. It suggests that labeled data, with its exact labels, could provide effective information for consistency training. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate labeled data into their consistency training process. The action is implicit, as the authors need to infer that they should explore using labeled data for consistency training, but it lacks concrete details on how to implement this idea. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in the context of graph anomaly detection. It references two specific works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which provides context for the discussion. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or figure. While the authors might infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of labeled data for consistency training, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in the context of graph anomaly detection. It references two specific works that discuss graph contrastive learning, which could provide relevant context and support for the suggestion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that labeled data could be beneficial for consistency training. The references provided are relevant but do not directly address the specific concern raised in the comment. Therefore, the claim is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in the context of graph anomaly detection. It suggests that labeled data, with its exact labels, could provide effective information for consistency training, which is a relevant consideration for the authors. However, the comment does not provide specific guidance or suggestions on how the authors might incorporate labeled data into their consistency training process. While it prompts the authors to explore this idea, it lacks actionable advice or detailed examples, making it 3. The authors would gain some insight into a potential area of improvement but would need to further develop the comment to fully benefit from it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to reorganize and further improve the experimental section. It highlights that the current content does not effectively showcase the superiority of the method and suggests including specific experimental suggestions based on the article\"s characteristics. This feedback provides clear and concrete actions for the authors to take, such as reorganizing the content and incorporating the suggested experimental elements. The explicit nature of the instructions and the detailed guidance make this comment 5.", "grounding_specificity_rationale": "The comment suggests reorganizing and improving the experimental section, indicating that the current content does not effectively highlight the superiority of the method. It provides specific suggestions for what should be included in the experimental suggestions, such as the characteristics of the article. However, the comment does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental section needs reorganization and improvement, specifically mentioning that the current content does not effectively highlight the superiority of the method. However, the comment lacks specific examples or detailed reasoning to support why the current experimental content is insufficient or how it could be improved. Without concrete evidence or suggestions, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a need for reorganization and improvement in the experimental section, noting that the current content does not effectively highlight the superiority of the method. It provides specific suggestions for what should be included in the experimental suggestions, such as the characteristics of the article. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their experimental section. However, it could be more helpful if it included examples or detailed guidance on how to reorganize the content. Overall, the comment is 4 as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in detecting outofdistribution samples. It suggests that the authors should report the classification accuracy on ImageNet data and provide theoretical justifications. While the comment implies that the authors should conduct additional experiments and provide theoretical support, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the classification accuracy of the proposed network compared to the standard softmax network, specifically in detecting outofdistribution samples. It suggests reporting the classification accuracy on ImageNet data and provides a request for theoretical justifications. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the classification section, but this inference is not as direct as it could be. The comment is specific in suggesting what needs to be addressed, such as reporting classification accuracy and providing theoretical justifications. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in detecting outofdistribution samples. The reviewer suggests that the authors should report the classification accuracy on ImageNet data and provide theoretical justifications. This claim is 3 as it highlights a potential issue with the proposed network and suggests a specific area for further investigation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to conduct additional experiments and provide theoretical support to address the concern fully.", "helpfulness_rationale": "The review comment raises a valid concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in detecting outofdistribution samples. It suggests that the authors should report the classification accuracy on ImageNet data and provide theoretical justifications to address this issue. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by conducting additional experiments and providing theoretical support. However, the comment could be more helpful if it included examples of how to conduct these experiments or suggested specific theoretical frameworks to consider. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of implementing and testing the argument that recognition lists are recalled based on items, particularly in the context of old vs new judgments. It questions the feasibility of effectively implementing such a list and testing concrete predictions with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit and vague, as it lacks concrete steps or examples for the authors to follow. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It highlights the difficulty in implementing and testing such a list with simulations. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the challenge of implementing and testing the argument, but without explicit grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of implementing and testing the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. The reviewer questions the feasibility of effectively implementing such a list and testing concrete predictions with simulations. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that this approach is difficult to implement or test. Without these elements, the claim remains somewhat vague and challenging for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the practicality of implementing and testing the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the feasibility of effectively implementing such a list and testing concrete predictions with simulations. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the fairness of the experimental comparison, suggesting that the proposed method was pretrained before the finetuning stage, which may not be the case for the compared methods. It implies that the authors should clarify whether the compared methods were initialized with the same or similar pretrained models. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization conditions of the compared methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental comparison with other methods, specifically mentioning the pretraining stage of the proposed method and suggesting that the compared methods may not have been initialized with the same or similar pretrained models. It references Table 1, which implies that the authors can identify the specific part of the paper being addressed. However, the comment does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison and suggesting that the authors clarify the initialization conditions of the compared methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair due to the pretraining stage of the proposed method. It suggests that the compared methods may not have been initialized with the same or similar pretrained models, which could affect the fairness of the comparison. The comment references Table 1 to support the claim, providing a specific example where the proposed method without SSL performs worse than most compared methods. This level of detail and reference makes the claim 4, as it provides a clear basis for the critique. However, the comment could be strengthened by further elaboration on the implications of the pretraining stage on the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the experimental comparison, suggesting that the proposed method was pretrained before the finetuning stage, which may not be the case for the compared methods. It highlights a specific concern regarding the initialization conditions of the compared methods, as evidenced by the results in Table 1. The comment provides a clear and actionable suggestion for the authors to clarify the initialization conditions of the compared methods, which could significantly improve the fairness and validity of the experimental comparison. However, the comment could be more helpful if it offered additional guidance on how to address this issue or suggested specific changes to the draft. Overall, the feedback is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors explore the performance of their proposed method when equipped with better metadata embeddings, referencing a specific paper for comparison. This feedback is explicit and provides concrete guidance on how the authors can enhance their work by incorporating better metadata embeddings. The suggestion is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests exploring the performance of the proposed method with better metadata embeddings, providing a clear direction for improvement. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the metadata used in the zeroshot learning results on the CUB dataset is \"attribute,\" which is good for fair comparison. However, it suggests that better metadata embeddings options are available and recommends exploring the performance of the proposed method with these better embeddings, referencing a specific paper. The comment provides a logical reasoning by suggesting an improvement and referencing a relevant work, which supports the claim. However, it lacks specific examples or detailed explanations of the better metadata embeddings options, which could enhance the verifiability. Therefore, the comment is 4, as it provides a clear direction for improvement but could be strengthened with more detailed evidence.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors explore the performance of their proposed method when equipped with better metadata embeddings, referencing a specific paper for comparison. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating more advanced metadata embeddings. The suggestion is wellsupported by the reference to a relevant paper, making it 5 for the authors to consider and implement. Therefore, the comment aligns with a score of 5, indicating it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests including a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This provides a clear and concrete action for the authors to take, as it specifies exactly what visualization to include and how it can demonstrate the practical benefits of SGC. The comment is 5 because it offers a direct and detailed instruction on how to improve the paper by adding a specific type of plot. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the flexibility and granularity of SGC compared to PEFT methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff compared to PEFT methods, which typically target computeconstrained scenarios. The reviewer suggests including a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about the flexibility and granularity of SGC. The suggestion to include a plot is clear, but the overall claim is not fully substantiated with detailed evidence or references, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the applicability of SGC compared to PEFT methods, particularly in terms of practicality and finegrained control. It suggests including a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This feedback is clear and actionable, as it provides a specific and visual way to demonstrate the practical benefits of SGC. By offering a concrete suggestion for improving the paper, the comment empowers the authors to enhance the clarity and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of Gerrymandering compared to Independent. It also suggests that the code should be published if ERM and plugin have similar performance to Kearns et al., with the main advantage being computation time. While the comment implies that the authors should investigate the training time difference and consider publishing the code, it does not provide explicit instructions or concrete steps on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically mentioning the German and Law school datasets and their training time in the context of Gerrymandering compared to Independent. It also suggests that the code should be published if ERM and plugin have similar performance to Kearns et al., with the main advantage being computation time. This provides a clear reference to the specific part of the paper being discussed, making it fully grounded. The comment is also specific as it outlines what needs to be addressed regarding the training time and the potential benefits of publishing the code. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of Gerrymandering compared to Independent. It also suggests that the code should be published if ERM and plugin have similar performance to Kearns et al., with the main advantage being computation time. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the training time difference is reasonable or why publishing the code would be beneficial. The lack of detailed justification or examples makes the claim 2, as the authors may find it challenging to understand the basis of the critique and address it effectively.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time difference between the German and Law school datasets in the context of Gerrymandering compared to Independent. It suggests that the code should be published if ERM and plugin have similar performance to Kearns et al., with the main advantage being computation time. While the comment identifies a potential area for improvement by suggesting publication of the code, it lacks specific guidance or suggestions on how to address the training time difference or why it might be reasonable. The feedback is 3 as it prompts the authors to consider publishing the code, but it could be more actionable with additional details or reasoning. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and provides specific questions about the current form of CD and the use of entropy as a measure of spreading. It explicitly asks for clarification on line 113 and line 115, indicating that the authors need to address these points. The comment is clear and provides concrete actions for the authors to take, such as expanding on alternate formulations and clarifying the use of entropy. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (113 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues by asking for additional information on possible alternate formulations for Confidence Diversity (CD) and questions the use of entropy as a measure of spreading. This provides clear guidance on what needs to be clarified or expanded upon. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for clarification rather than making subjective claims or judgments. It does not present opinions, recommendations, or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also raises questions about the current form of CD and the use of entropy as a measure of spreading, particularly referencing lines 113 and 115. This feedback is clear and constructive, as it guides the authors to clarify and expand on certain aspects of their work, which can enhance the comprehensiveness and depth of the paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of alternate formulations. Overall, the comment is 4 as it identifies areas for improvement and provides a foundation for the authors to build upon."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy between the human baseline and the model baseline, noting that the human baseline is weaker due to the limited duration of speech recordings. It also points out a misleading statement in the abstract regarding the human baseline. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the human baseline, specifically mentioning the duration of speech recordings and the comparison with the model baseline. It also critiques the abstract for a misleading statement regarding the human baseline. However, the comment does not specify which part of the paper discusses the human baseline or the exact issue with the abstract, making it weakly grounded. The comment is specific in detailing the issue with the human baseline and the misleading statement in the abstract. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is weaker than the model baseline due to the limited duration of speech recordings (1 hour instead of 15 hours). It also critiques the abstract for a misleading statement regarding the human baseline. The comment provides a logical reasoning for the claim, explaining the discrepancy in the duration of speech recordings and its impact on the baseline comparison. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline in the paper, noting that the human baseline is based on only 1 hour of speech recordings compared to the full 15 hours used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline. The comment also critiques the abstract for a misleading statement regarding the human baseline, which could be misleading given the limited duration of speech recordings. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity of their claims. The feedback is 3 as it points out areas for improvement but could be more actionable with additional details or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a strong assumption regarding the termination states of instructions, noting that labeling a large number of data manually is expensive in the general case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggest alternative approaches. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of labeling costs, it lacks grounding as it does not provide clear guidance on where in the paper this issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is strong and expensive to label data manually. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption regarding the termination states of instructions, noting that it is expensive to label a large number of data manually in the general case. This feedback highlights a critical aspect of the methodology that could impact the practicality or feasibility of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in describing the nature of the contribution with respect to ECE_sweep, specifically mentioning that it involves a way to choose the number of bins using data, which is akin to autotuning a hyperparameter. The reviewer suggests that the paper should be more upfront about its contribution. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it or what changes should be made to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the nature of the contribution with respect to ECE_sweep, specifically mentioning the use of data to choose the number of bins, which is akin to autotuning a hyperparameter. This provides a clear indication of what needs to be clarified in the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of unclear contribution description. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper with respect to ECE_sweep is not clearly described, specifically mentioning that it involves a way to choose the number of bins using data, akin to autotuning a hyperparameter. The reviewer suggests that the paper should be more upfront about its contribution. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the contribution is unclear. This makes the claim 3, as the authors would need to infer the lack of clarity themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper\"s contribution regarding ECE_sweep. It points out that the contribution involves a method for choosing the number of bins using data, which is akin to autotuning a hyperparameter. The reviewer suggests that the paper should be more upfront about its contribution, which would help the authors clarify their work. While the comment highlights a critical area for improvement, it lacks specific suggestions or examples on how to enhance the clarity of the contribution. Providing more detailed guidance would make the feedback more actionable, but it is still 3 as it directs the authors\" attention to an important aspect of their work. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE (e.g., RL methods), none of them are used as a baseline. However, it does not provide any explicit or implicit suggestions for how the authors should address this gap. There is no guidance on whether the authors should include these methods as baselines or how they might do so. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of baseline methods for training NMT models beyond MLE, as discussed in the related work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The absence of detailed evidence or examples makes the claim 2, as it provides some indication of the problem but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE (e.g., RL methods), none of them are used as a baseline. This feedback highlights an area where the authors could provide more comprehensive context or comparison, potentially improving the depth and relevance of their discussion. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending the inclusion of baseline comparisons or further discussion of these methods. While it points out an important area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the term \"efficient proxy,\" suggesting that it might refer to a particular proxy rather than a family of proxies. However, it does not provide explicit guidance or suggestions on how the authors should clarify this point in their draft. The comment implies that the authors should address the ambiguity, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the term \"efficient proxy,\" suggesting that it might refer to a particular proxy rather than a family of proxies. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the discussion of proxies or efficiency, but this inference is not direct. The comment is specific in its questioning but lacks grounding as it does not pinpoint the exact location in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the term \"efficient proxy,\" suggesting that it might refer to a particular proxy rather than a family of proxies. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the term \"efficient proxy,\" suggesting that it might refer to a particular proxy rather than a family of proxies. This feedback highlights a potential ambiguity in the terminology used in the paper, which could lead to confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this point or address the ambiguity. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point describes a specific methodological approach used by the authors, involving the stacking of methods from Mirzasoleiman et al., 2020 and a Grouplearning setting, followed by the use of DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this approach could be improved, enhanced, or modified. Without any actionable suggestions or recommendations, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a specific description of the methods used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and a Grouplearning setting, followed by the use of DBSCAN for clustering. However, it does not specify which part of the paper this description is related to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the methods used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point describes a specific methodological approach used by the authors, involving the stacking of methods from Mirzasoleiman et al., 2020 and a Grouplearning setting, followed by the use of DBSCAN for clustering. However, the comment does not provide any justification or reasoning for why this approach is problematic, how it compares to other methods, or what specific issues it might be addressing. Without additional context or explanation, the claim lacks support and is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific description of the methodology used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and a Grouplearning setting, followed by the use of DBSCAN for clustering. However, it does not offer any critical analysis, suggestions for improvement, or guidance on how this approach could be enhanced or evaluated. Without actionable feedback or insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests that the authors should explore the resilience of the metrics to different random projection matrices. It implies that the authors should consider constructing pathological projection matrices to test the robustness of their metrics. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analysis to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.a)\" and the specific part of the paper being addressed, allowing the authors to accurately identify the section being discussed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests exploring the resilience of the metrics to different random projection matrices. The comment provides a clear direction for the authors to consider additional analysis or experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests that the authors should explore the resilience of the metrics to different random projection matrices. The reviewer provides a logical reasoning by questioning the robustness of the metrics to different projection matrices, which is a valid concern. However, the comment lacks specific examples or references to support the claim that random projections are unlikely to skew the metrics. This makes the claim 3, as it provides a basis for the concern but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests that the authors should explore the resilience of the metrics to different random projection matrices. It implies that the authors might have missed this aspect in the appendix and suggests that it would be helpful to see the resilience of the metrics to different random projection matrices. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what specific analyses should be conducted. The feedback is 3 as it points out a potential weakness in the paper, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It asks for an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests adding the model used explicitly to the appendix. These specific and concrete actions give the authors clear guidance on how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified or added, such as examples of synthetic data, definitions of \"support data\" and \"predicted training count data,\" and the explicit mention of the model used. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims that require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It asks for clarification on the type of synthetic data used, the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly mentioning the model used in the appendix. These requests for clarification and explicit information are clear and would help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what kind of data or definitions might be expected. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation of FGT is only used to assess the performance of the proposed method in an ablation study, suggesting that it should be used to evaluate the performance of the proposed method and the comparative methods. While the comment implies that the evaluation should be expanded, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to adjust their evaluation approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited use of FGT evaluation in the ablation study and suggests that it should be used to evaluate the performance of the proposed method and comparative methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT is only used to assess the performance of the proposed method in an ablation study, suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is only used to assess the performance of the proposed method in an ablation study. It suggests that this evaluation should be used to assess the performance of the proposed method and the comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement in the evaluation process. However, the comment could be more helpful if it offered additional guidance on how to conduct this evaluation or provided examples of how to integrate this feedback into the manuscript. Overall, the comment is 4, as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the model appears overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what aspects of the model\"s simplicity need to be reconsidered or improved. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or discussion. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity need to be reconsidered or improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model appears overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the model appears overly simple, which is both a feature and a bug. While it identifies a potential issue with the model\"s complexity, it does not provide specific guidance or suggestions on how to address this concern. The feedback lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer actionable feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), suggesting that its broader impact may be limited. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might broaden the impact of their work or what specific changes could be made to achieve this. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on a narrow task (climate change QA) in a specific language (Arabic), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the limited broader impact of the work, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the work, noting that it is focused on a narrow task (climate change QA) in a specific language (Arabic). This observation highlights a potential issue with the broader impact of the work. However, the comment does not provide specific suggestions or guidance on how the authors might broaden the scope or address this limitation. While it points out a concern, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights the use of the winnertakeall property in previous works and questions the originality of the paper due to its simplified settings. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the paper could be improved or what specific aspects need to be addressed to enhance its originality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of the winnertakeall property in previous works, specifically mentioning NNbased clustering algorithms and referencing a specific section (Sec 5). This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies the issue by questioning the originality of the paper\"s contribution, given that most findings have been reported in previous works. However, it does not provide specific suggestions on how to address this issue or what novel contributions the paper could offer. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the winnertakeall property has been widely used in previous works, such as NNbased clustering algorithms, and questions the paper\"s originality due to its simplified settings. The comment references a specific section (Sec 5) to support its claim, providing a basis for the critique. However, the comment lacks detailed examples or specific references to previous works that have used the winnertakeall property, which would strengthen the claim. Additionally, it does not provide a clear rationale for why the paper\"s findings are not novel, given the simplified settings. Therefore, the claim is 3, as it provides some support but lacks depth and specificity.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works such as NNbased clustering algorithms. It questions how the paper contributes novelly to the understanding of this behavior, especially given its simplified settings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or detailed critique, the authors are left without a clear path forward for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of some runtimes from the experiments to assist readers in applying the method. While the comment provides explicit actions\u2014mentioning the computational cost and including runtime examples\u2014the instructions for execution are somewhat vague. The authors know they need to include these elements, but the comment does not specify which sections to place them in or how to present the information effectively. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of runtimes from the experiments to assist readers in applying the method. However, the comment does not specify which part of the paper should include these details, making it weakly grounded. The suggestion is specific in terms of what needs to be added, but without clear grounding, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method and include runtime examples from the experiments. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the computational cost is negligible. The suggestion is 3 as it offers a plausible rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of runtimes from the experiments to assist readers in applying the method. This feedback is clear and constructive, offering the authors a clear direction for improving the clarity and utility of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present the computational cost and runtimes effectively. Overall, the comment is 4 as it directs the authors toward enhancing the paper\"s clarity and applicability."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends that the authors provide a more detailed explanation of the EEG token quantization process, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and specific, giving the authors a direct action to take\u2014elucidating the procedure in greater detail. The comment also suggests a specific area of interest, which adds depth to the action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide a more detailed explanation of the EEG token quantization process, particularly focusing on the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents ambiguous EEG topography plots, which could lead to confusion in interpretation. The reviewer recommends that the authors provide a more detailed explanation of the EEG token quantization process, specifically focusing on the role of the spatial arrangement of EEG sensors. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a more detailed explanation is logical but could be strengthened with additional context or examples. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it presents ambiguous EEG topography plots during the EEG token quantization process. The reviewer suggests that the authors provide a more detailed explanation of the procedure, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and interpretability of their results. By addressing this suggestion, the authors can improve the comprehensibility of their work and provide readers with a clearer understanding of the methodology. Therefore, the comment is 4, as it offers a specific and constructive suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should address the problem in a more direct way, implying that the current approach of leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case, is not sufficient. However, the comment does not provide explicit guidance on how to achieve this or what specific changes should be made to the draft. The action is implicit and vague, as it lacks concrete details on how to improve the approach or what specific aspects need to be addressed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should address the problem in a more direct way, implying that the current approach of leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case, is not sufficient. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this topic is covered, the comment lacks full grounding. It is specific in suggesting that the approach is not direct, but it does not provide detailed guidance on how to improve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should address the problem in a more direct way, suggesting that leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case, is not sufficient. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the approach taken by the authors, specifically that they are leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem, implying that the authors should consider a more direct method. However, the comment lacks specificity and does not provide detailed guidance on how the authors might improve their approach or what specific aspects of the problem need to be addressed. Without actionable suggestions or examples, the feedback is 3 as it highlights a potential weakness but does not offer a clear path for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing a work by NguyenTang et al. (2021) that uses moment matching. The reviewer implies that this should be discussed in the context of various approaches to DRL, even though the paper currently uses quantile regression. While the comment suggests a specific area for improvement, it does not provide explicit guidance on how to incorporate this information into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of moment matching in their literature review. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely the discussion of using moment matching for distributional reinforcement learning (DRL), referencing a specific work by NguyenTang et al. (2021). The comment provides a clear direction for improvement by suggesting that this should be discussed alongside other approaches to DRL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing a work by NguyenTang et al. (2021) that uses moment matching. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the paper currently uses quantile regression. The claim is supported by a specific reference to a relevant work, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching differs from quantile regression in the context of DRL. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that it lacks relevant literature on using moment matching for distributional reinforcement learning (DRL). It references a specific work by NguyenTang et al. (2021) that uses moment matching, which is a relevant approach in the field. The comment provides a clear and actionable suggestion for the authors to include this information in their literature review, even though the paper currently uses quantile regression. This feedback is valuable as it guides the authors to expand their discussion on DRL approaches and incorporate a more comprehensive review of the literature. However, the comment could be more helpful if it provided additional context or explanation on why this inclusion is important. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include baselines for their code completion tasks, specifically mentioning Copilot as a commercial application that could be compared. It provides a clear action by specifying which baselines to include and how to test them on a smaller subset of RepoEval. The suggestion is concrete and direct, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including baselines for code completion tasks, specifically mentioning Copilot as a commercial application that could be compared. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include comparisons with stateoftheart code completion systems, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include baselines for their code completion tasks, specifically mentioning Copilot as a commercial application that could be compared. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of why these baselines are essential or how they would enhance the paper. The comment does not provide enough context or evidence to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include baselines for their code completion tasks. It provides a concrete example of a commercial application, Copilot, which could be used as a baseline. This feedback is clear and actionable, as it guides the authors on what additional comparisons to include in their work. However, the comment could be more helpful if it provided more detailed reasoning or examples of why these baselines are important or how they would enhance the paper. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should consider the criteria behind this selection and explore other tasks or datasets that might yield different insights. While the comment implies that the authors should provide more justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should justify their selection and consider additional tasks or datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), raising questions about generalizability. It suggests that the authors should consider the criteria behind this selection and explore other tasks or datasets that might yield different insights. However, the comment does not specify which part of the paper discusses the evaluation on MTEB, making it weakly grounded. The comment is specific in its request for additional justification and exploration, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should consider the criteria behind this selection and explore other tasks or datasets that might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice is problematic or how it could be improved. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions the criteria behind this selection and suggests that exploring other tasks or datasets could provide different insights. This feedback is 3 as it prompts the authors to consider a broader scope of evaluation, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or examples of alternative tasks or datasets to consider. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction mentions \"modelling curves,\" but it is not immediately clear what is being modelled, presumably tumor growth. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify this point or what specific changes are needed to make it more understandable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in what is being modelled in the context of modelling curves, presumably tumor growth. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction mentions \"modelling curves,\" but it is not immediately clear what is being modelled, presumably tumor growth. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph mentions \"modelling curves\" but does not clearly specify what is being modelled, presumably tumor growth. This feedback is 3 as it highlights a potential area of confusion for readers, which could be clarified to improve the paper\"s clarity. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could suggest ways to clarify the modeling process or provide examples of what could be modelled. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns. First, it questions the reason for using shift=0 being better than shift~ N (0, \u03c3\u00b2), as both cases involve domain shifts. Second, it suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in) distribution. While the first point is a question seeking clarification, the second point is an explicit action for the authors to take, which is to include performance comparisons on test samples from the observational distribution. The action is concrete, as it specifies what needs to be done, but it is phrased as a request rather than a direct command. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the \"shiftedMNIST\" dataset, specifically questioning why shift=0 is better than shift~ N (0, \u03c3\u00b2) and suggesting that it would be useful to show performance on test samples from the observational (in) distribution. However, it does not specify which part of the paper discusses the shiftedMNIST dataset, making it weakly grounded. The comment is specific in its request for performance comparisons, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts. The first part questions the reason for using shift=0 being better than shift~ N (0, \u03c3\u00b2), as both cases involve domain shifts. This is a subjective claim that requires more detailed explanation or evidence to be 5. The second part suggests showing performance on test samples from the observational (in) distribution, which is a request for clarification rather than a claim. Overall, the comment is 3 due to the first part, as it raises a question that could be explored further with additional justification or evidence, but the second part is not a claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two concerns. First, it questions the rationale behind using shift=0 being better than shift~ N (0, \u03c3\u00b2), as both cases involve domain shifts. This is a valid point that could be explored further to understand the underlying reasons for the choice of shift values. Second, the comment suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in) distribution. This is a constructive suggestion that could help the authors better understand the generalization capabilities of their model. While the comment identifies an area for improvement, it could be more helpful by providing specific guidance on how to address the first concern or by suggesting additional experiments. Overall, the comment is 4 as it provides actionable feedback and highlights important areas for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of detail in the experimental description, suggesting that it would benefit from increased clarity to help readers judge the results. It implies that the authors should provide more detailed information about the experimental setup, methodology, and results. However, the comment does not specify what aspects of the description need to be clarified or how the authors should present the information to improve clarity. The action is implicit and somewhat vague, as the authors know they need to add more detail but are not given specific guidance on what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of experimental details,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for increased clarity in the experimental description to help readers judge the results. The comment further suggests that the authors should provide more detailed information, which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details is lacking in clarity, making it difficult for readers to judge the results. However, the comment does not provide specific examples or references to support this claim, such as pointing out particular aspects of the description that are unclear or suggesting how the clarity could be improved. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the experimental description, which is crucial for readers to understand and judge the results. It highlights the need for increased detail in the experimental setup, methodology, and results to enhance clarity. However, the comment lacks specific suggestions or examples of what aspects of the description could be improved, such as which details are missing or how they could be presented more clearly. While it points out a critical area for improvement, the feedback could be more actionable and helpful if it provided concrete guidance on how to enhance the clarity of the experimental description. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more explanation to clarify the concept of \"expected\" and mentions that the main contribution is the CBR, which should be discussed in terms of different optimization strategies and their results. It specifically asks about the implications of minimizing both inter and intra terms in Equation 3 or only the first term. While the comment identifies areas for improvement and provides a specific example of what needs to be discussed, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer the exact actions to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"expected\" and the main contribution of the paper, which is the CBR. It also specifies the need for a discussion on different optimization strategies and their results, particularly regarding the implications of minimizing both inter and intra terms in Equation 3 or only the first term. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the concept of \"expected\" and discusses the main contribution of the paper, which is the CBR. It raises a question about the implications of minimizing both inter and intra terms in Equation 3 or only the first term. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that more explanation is needed. The suggestion to discuss different optimization strategies and their results is 3, as it provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a need for more explanation regarding the concept of \"expected\" in the paper, which is crucial for understanding the context and significance of the work. It also highlights the main contribution of the paper, which is the CBR, and suggests that the authors should discuss different optimization strategies and their results. The comment further questions the implications of minimizing both inter and intra terms in Equation 3 or only the first term, providing a specific example of what needs to be clarified. This feedback is clear and actionable, offering the authors a concrete direction for improving the clarity and depth of their paper. However, it could be more helpful if it included additional suggestions or examples to fully guide the authors. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a formal or intuitive definition of treewidth, as it is central to all the proofs in the paper. This feedback is explicit, as it clearly states what the authors should do\u2014add a definition. However, it lacks concrete details on how to present this definition or where it should be placed in the paper. The authors know they need to include a definition, but they are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, making it weakly grounded. The comment is specific in its suggestion to include a definition, but without clear guidance on where to place it, the authors may struggle to determine the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this definition is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. This feedback is clear and actionable, as it identifies a key concept that should be clarified to enhance the paper\"s comprehensibility and rigor. By providing a specific suggestion for improvement, the comment empowers the authors to address a critical aspect of their work, potentially improving the clarity and robustness of their proofs. However, the comment could be more helpful if it offered additional guidance on how to present the definition or why it is particularly important. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima that Algorithm 1 converges to, specifically mentioning the approximation ratio of these local minima under certain assumptions. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to analyze the quality of the local minima or what assumptions to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of the local minima that Algorithm 1 converges to, particularly focusing on the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima that Algorithm 1 converges to, specifically mentioning the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should analyze the quality of the local minima that Algorithm 1 converges to, particularly focusing on the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and potentially improve the paper\"s contribution. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific assumptions to consider. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not selfcontained and suggests that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies specific areas that need clarification and provides a concrete action request for releasing source code, it does not explicitly instruct the authors to address the lack of selfcontainment in the main paper. The action is implicit but concrete, as the authors know exactly what needs to be done. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being selfcontained, suggesting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which sections or parts of the paper are affected by this lack of selfcontainment, making it weakly grounded. The authors can infer that it relates to the main paper and supplementary materials, but this inference is not direct. The comment is specific in suggesting the release of source code for reproducibility, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and suggests that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the release of the source code of the experiments. While the comment identifies a potential issue with the paper\"s comprehensibility, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for source code is a suggestion, not a claim, and thus does not fit the criteria for a claim. Therefore, the comment is 3, as it provides a general observation but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that it is not easily understandable given the NIPS format. It highlights the necessity of the supplementary material for understanding large parts of the main paper and for reproducibility. Additionally, the comment requests the authors to release the source code of their experiments to allow reproduction of their results. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it offered suggestions on how to enhance the paper\"s selfcontainment or detailed guidance on what aspects of the supplementary material are most critical. Overall, the comment is 4 as it directs the authors to important improvements that can be made to enhance the clarity and reproducibility of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the role of information redundancy in the Fill, Propagate, Decode algorithms and provides a reference to a specific sentence in the paper. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these questions or improve their understanding of the algorithms. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the role of information redundancy in the Fill, Propagate, Decode algorithms and references a specific sentence in the paper. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification about the role of information redundancy in the algorithms and the sentence it references. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and a reference to a specific sentence in the paper, which are factual statements. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the role of information redundancy in the Fill, Propagate, Decode algorithms and references a specific sentence in the paper. While it identifies an area for clarification, it lacks depth and does not provide actionable feedback or suggestions on how the authors might address these questions or improve their understanding. The comment is 3 as it prompts the authors to consider a specific aspect of their work, but it does not offer a comprehensive guide or detailed guidance on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the added complexity in the model due to the use of multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider whether one IN would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The action is implicit and vague, as it lacks concrete steps or details on how to determine the importance of the added complexity or how to simplify the model if necessary. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific feature of the model, the use of multiple INs at different speeds in the dynamics predictor, and questions the importance of this design choice. However, it does not explicitly mention which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and whether one IN would suffice, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of the added complexity introduced by using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider whether one IN would suffice. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it impacts the overall design of the model. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of the added complexity in the model due to the use of multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider whether one IN would suffice, prompting them to evaluate the necessity of the added complexity. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this question or what experiments or analyses could be conducted to determine the importance of the added complexity. The feedback is 3 as it prompts the authors to reconsider their design choice, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments do not surprise the authors because the opponent is not aiming to maximize the multiagent payoff. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this point or improve their draft based on this feedback. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, noting that the opponent\"s performance is not surprising because it does not aim to maximize the multiagent payoff, as evidenced by the experiments where the opponent maximizes classical SE and AE. This provides clear guidance on what aspect of the experiments needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments do not come as a complete surprise because the opponent is not aiming to maximize the multiagent payoff. The reviewer provides a specific example, mentioning that the opponent maximizes classical SE and AE, which supports the claim. This level of detail and specificity makes the claim 4, as it provides a clear rationale and example to substantiate the observation. However, it could be further strengthened by referencing specific results or data from the experiments. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that the opponent\"s performance is not surprising because it does not aim to maximize the multiagent payoff. The reviewer provides a clear example, stating that the opponent maximizes classical SE and AE, which helps the authors understand the context of the experiments. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or improve their draft. While it points out a potential area for clarification, it does not provide actionable feedback or guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a description of the choices made in their work, specifically asking for clarification on why the REINFORCE algorithm was used for training instead of something like PPO. The comment implies that the authors should explain the rationale behind their choice, but it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to provide more context or justification for their choice of algorithm. However, the comment lacks concrete guidance on how to address this issue, such as suggesting specific points to clarify or examples to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of the choices made in their work, specifically asking for clarification on why the REINFORCE algorithm was used for training instead of something like PPO. It implies that the authors should explain the rationale behind their choice, but it does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. However, the comment is specific in its request for clarification regarding the choice of algorithm. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a description of the choices made in their work, specifically asking for clarification on why the REINFORCE algorithm was used for training instead of something like PPO. The comment implies that the choice is related to the attention model paper the authors are iterating on, but it does not provide specific reasoning or examples to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors provide a clearer explanation of the choices made in their work, specifically asking for clarification on why the REINFORCE algorithm was used for training instead of something like PPO. This feedback is 3 as it identifies a gap in the paper\"s explanation and prompts the authors to clarify their methodology. However, the comment could be more actionable by offering specific suggestions on how to address the issue or by providing examples of how to improve the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO by providing a more conservative upper bound than the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this confusion or clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement in Theorem 5.1, indicating that it might indicate a disadvantage of MMD DRO by providing a more conservative upper bound than the variance regularized problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO by providing a more conservative upper bound than the variance regularized problem. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples, comparisons, or references to substantiate the assertion that MMD DRO is more conservative. As a result, the claim is not wellsupported, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a point of confusion regarding Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO by providing a more conservative upper bound than the variance regularized problem. However, the comment lacks specificity and does not provide detailed reasoning or suggestions for how the authors might address this confusion or improve the clarity of the statement. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently for each domain. It suggests that the paper lacks insight into this aspect, which is crucial for task domain adaptation. While the comment implies that the authors should provide more information or clarification on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of morphologic segmentation across different domains and questions whether it should be conducted differently for each domain or if it is invariant. However, it does not specify which part of the paper discusses morphologic segmentation or where these questions should be addressed. The authors cannot confidently determine which sections or aspects of the paper are being referred to, making the comment weakly grounded. It is specific in questioning the approach and assumptions regarding morphologic segmentation, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently for each domain. The reviewer questions the assumption that morphologic segmentation is invariant across any arbitrary domain. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises important questions about the use of morphologic segmentation across different domains and whether it should be conducted differently for each domain. It also questions the assumption that morphologic segmentation is invariant across any arbitrary domain, which is crucial for task domain adaptation. While the comment identifies a significant gap in the paper, it lacks specific suggestions or guidance on how the authors might address these questions or improve their approach. The feedback is 3 as it highlights areas for improvement, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include experimental results demonstrating the contribution of their proposed method when excluding the mixup technique. This is a clear and direct action for the authors to take, providing them with a specific task to perform. The comment is concrete because it specifies exactly what needs to be done, leaving no ambiguity about the authors\" responsibilities. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the contribution of the proposed method when excluding the mixup technique. This provides clear guidance on what additional information or results are needed to strengthen the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results demonstrating the contribution of their proposed method when excluding the mixup technique. This claim is 3 as it implies that the current results may not fully showcase the pure contribution of the proposed method. However, the comment lacks specific examples or detailed reasoning to support why excluding the mixup technique is necessary or how it would demonstrate the pure contribution. The authors would need to infer the necessity of these experiments, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include experimental results demonstrating the contribution of their proposed method when excluding the mixup technique. This is a clear and actionable suggestion that could enhance the paper\"s demonstration of the method\"s effectiveness and its pure contribution. By providing a concrete example of what additional experiments are needed, the comment offers valuable guidance for the authors to strengthen their work. However, it could be more helpful if it included specific details on how to conduct these experiments or what results to expect. Overall, the comment is 4 as it directs the authors toward a specific enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions about the object detection based attention mechanism, asking whether it is performed on the image or on a convolutional feature map and whether rescaling is done based on the receptive field. While the questions are explicit, they do not provide concrete guidance on how the authors should address these questions or what specific actions they should take to clarify the mechanism. The authors are left to infer that they need to provide more details on the attention mechanism and its relationship with the feature map, but without explicit instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detection based attention mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two questions: whether the attention is performed on the image or a convolutional feature map and whether rescaling is done based on the receptive field. These questions provide clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detection based attention mechanism. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely descriptive. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the object detection based attention mechanism. It asks whether the attention is performed on the image or on a convolutional feature map and whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. These questions are clear and actionable, as they prompt the authors to clarify and provide more detailed information about their methodology. By addressing these questions, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how others have addressed similar questions. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a discussion about the Set Transformer and other related works that use summary tokens. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion on these topics, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of a discussion about the Set Transformer and other related works that use summary tokens. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in identifying the need for a discussion on these topics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where to add this discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that use summary tokens. This feedback is 3 as it highlights a specific area that needs attention and suggests that the authors should include a discussion on these topics. However, the comment lacks depth and does not provide specific guidance on how to incorporate this discussion or what aspects of these works should be covered. While it prompts the authors to expand their discussion, it does not offer detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical support for the acceleration of NTK convergence by Fourier features, specifically in the highfrequency range. It implies that the authors should provide an analysis or explanation of this aspect, but it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to address this question, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for the acceleration of NTK convergence by Fourier features, specifically in the highfrequency range. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the theoretical support and the highfrequency range, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical support for the acceleration of NTK convergence by Fourier features, specifically in the highfrequency range. It does not present an opinion, claim, or suggestion that requires verification. It is a request for clarification or further explanation, which fits the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the theoretical support for the acceleration of NTK convergence by Fourier features, specifically in the highfrequency range. It highlights the importance of this theoretical support in understanding the merits of Fourier features. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or improve their analysis. While it identifies an area for potential improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a relevant area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the methodology used in the paper, specifically questioning the details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific details are missing or how the authors should address this issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the methodology used in the paper, specifically questioning the details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is covered, the comment lacks full grounding. It is specific in identifying the issue but not in providing detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the methodology used in the paper, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any claim, judgment, or suggestion that requires verification. It is purely a factual inquiry, making it a \"No\" label.", "helpfulness_rationale": "The review comment raises a specific concern about the methodology used in the paper, questioning the details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback highlights a potential gap in the explanation of the methodology, which could be crucial for understanding the approach taken by the authors. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically regarding data augmentation methods and learning rate. It also references a specific paper, BadNets, which might be relevant to the discussion. However, the comment does not provide explicit guidance on what the authors should do to address this question or how they should present their findings. The reference to BadNets is included, but it does not offer a clear action or suggestion for improvement. As a result, the comment is vague and lacks concrete details, making it difficult for the authors to know what specific changes are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the experiment setup, including details like data augmentation methods and learning rate. Additionally, it references a specific paper, BadNets, which provides context for the discussion. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests clarification on the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. It also references a specific paper, BadNets, which might be relevant to the discussion. However, the comment lacks depth and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it does not offer guidance on how to enhance the paper\"s presentation or analysis. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about potential errors in the initial calibration steps that might explain the observed speed disparities between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to investigate or correct the potential error. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about potential errors in the initial calibration steps that might explain the observed speed disparities between the RSPs and FDs. This provides clear guidance on what the authors need to investigate or address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about potential errors in the initial calibration steps that might explain the observed speed disparities between the RSPs and FDs. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed analysis to justify the suggestion, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about potential errors in the initial calibration steps that might explain the observed speed disparities between the RSPs and FDs. While it identifies a potential area for investigation, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps to take to verify the calibration process. The comment lacks actionable advice or detailed feedback, making it 3 as it prompts the authors to consider a potential source of error but does not fully support their understanding or improvement efforts. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the claim, as it points out the weight transport problem and the lack of resemblance to biological networks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment does not provide any specific feedback or suggestions on how the authors might address this issue or improve their draft. It lacks actionable guidance or constructive criticism, leaving the authors without a clear path for improvement. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the authors conducted any statistical significance tests when comparing the proposed method with baselines. While it implies that the authors should perform such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests and may not be entirely sure how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison between the proposed method and baselines, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it raises a question about whether statistical significance tests were conducted, which provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the authors conducted any statistical significance tests when comparing the proposed method with baselines. This is a valid concern, as it raises a potential issue with the robustness of the results. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the results are close and require statistical significance testing. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the closeness of the numbers when comparing the proposed method with baselines. It questions whether the authors conducted any statistical significance tests, which is a crucial aspect of ensuring the robustness and reliability of the results. While the comment identifies a potential weakness, it lacks specific guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of statistical tests or providing examples of how to conduct them. This limits the comment\"s usefulness, as it provides insight into a potential area for improvement but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a potential area for clarification, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to explain the impact of emission distributions on inference, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus of the paper on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the impact of emission distributions on inference tasks, particularly in the context of common inference tasks in discrete HMMs. The comment specifies what needs to be addressed, namely the computation of exact or approximate inference tasks with an NPSPECHMM. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. This is a request for clarification rather than a claim that requires verification. The comment does not contain subjective opinions, judgments, or suggestions that need evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. This feedback highlights a potential area for clarification in the paper, prompting the authors to provide more detailed information on how emission distributions affect inference. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a gap in the paper, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the analysis of experimental results is insufficient, specifically mentioning that the authors only report the performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to conduct further analysis or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide an analysis of the reasons behind the poor performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, clearly specifying what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only report the performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a specific gap in the analysis, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of experimental results, specifically noting that the authors only mention the performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons for this outcome. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more detailed analysis to strengthen their paper. By addressing this issue, the authors can enhance the comprehensiveness and depth of their experimental results, making the paper more robust and informative. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of datasets and suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment implies that the authors should consider these additional datasets, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reference 7,12, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why only 10 out of 120 datasets are considered and suggests comparing batch and greedy methods in the remaining 110 datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the selection of datasets, specifically mentioning that only 10 out of 120 datasets are considered. It suggests comparing batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the selection of datasets, specifically noting that only 10 out of 120 datasets are considered. It suggests comparing batch and greedy methods in the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address this issue or why it is important. The feedback is 3 as it prompts the authors to consider a broader comparison, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction regarding lowrank factorization is unnecessary since the main result pertains to polytopes. It also implies that if the result has implications for lowrank matrix factorization, the authors should explicitly discuss these. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate the discussion of lowrank matrix factorization into the paper. The authors are left to infer that they need to address this aspect, making the action implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the lowrank factorization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation in the introduction and suggests that the implications for lowrank matrix factorization should be explicitly discussed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction regarding lowrank factorization is unnecessary given that the main result pertains to polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment lacks specific examples or references to support the claim that the motivation is unnecessary or to illustrate the implications for lowrank matrix factorization. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically questioning the relevance of lowrank factorization given that the main result pertains to polytopes. It suggests that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. This feedback is 3 as it highlights a specific area for improvement and provides a clear direction for the authors to enhance the clarity and relevance of their work. However, the comment could be more helpful if it offered specific suggestions on how to integrate the discussion of lowrank matrix factorization into the paper. Overall, the comment provides valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning whether they are derived from the dataset itself or from other sources, such as caspealr1 and mugshot. This direct request for clarification provides a clear and actionable step for the authors to take, ensuring they address the issue. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of labels for each dataset, particularly questioning their origin for generated datasets versus caspealr1 and mugshot. This provides clear guidance on what information is missing and needs to be provided. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the labels of datasets in section 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the labels of datasets in section 4.1, particularly questioning their origin for generated datasets versus caspealr1 and mugshot. This feedback is clear and actionable, as it prompts the authors to clarify the sources of these labels, which is crucial for understanding the context and validity of their work. By addressing this issue, the authors can improve the clarity and transparency of their methodology, making the comment 5. However, the comment could be more helpful if it provided additional guidance on how to address the labels or suggested potential sources of confusion. Overall, the feedback is 4, as it effectively directs the authors toward a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment notes that the paper is incremental with respect to 31, specifically mentioning that the authors adapt the existing architecture for the multiperson case to produce identity/tag heatmaps using joint heatmaps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this incremental nature or improve upon it. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s incremental nature with respect to 31, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by mentioning the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. This provides clear guidance on what aspect of the paper is being critiqued. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to 31, specifically mentioning the adaptation of the existing architecture for the multiperson case to produce identity/tag heatmaps using joint heatmaps. However, the comment lacks specific details or references to support this claim, such as how the current work differs from 31 or what aspects of the architecture are being adapted. Without this additional information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient evidence or context to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the paper is incremental with respect to 31, specifically mentioning the adaptation of the existing architecture for the multiperson case to produce identity/tag heatmaps using joint heatmaps. While this observation highlights a potential area for improvement, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their work. Without actionable feedback or detailed critique, the authors are left without a clear path forward for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and questions the process of calculating \u03bb. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but do not fully understand the explanation. The comment provides specific references to other works, which could help the authors understand the context of their findings. However, it does not explicitly instruct the authors to address these issues or provide concrete guidance on how to improve their explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the \u03bb calculation process and the explanation of sample efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues raised, such as the sensitivity of performance and sample efficiency to \u03bb parameters and the lack of understanding about how \u03bb is computed. Additionally, it references external works to provide context, which further supports the claim. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the sensitivity of performance and sample efficiency to \u03bb parameters and questions the process of calculating \u03bb. It references specific sections of the paper, providing a clear context for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why \u03bb is critical or how it affects performance. The references to other works provide some context, but they do not directly address the claim. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification or examples.", "helpfulness_rationale": "The review comment identifies a critical issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a significant concern for the robustness of the results. It also questions the process of calculating \u03bb, providing a clear area for the authors to clarify and improve their explanation. Additionally, the comment references external works, which can help the authors understand the context and implications of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or improve the clarity of the explanation. Overall, the feedback is 4 as it highlights important areas for improvement and provides some context, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on which specific method is used to solve the minmin problem, as it is mentioned in a brief manner. This direct question provides a clear action for the authors to take, which is to identify and specify the method used. However, it does not provide any additional guidance or suggestions on how to address this issue beyond the initial request for clarification. Therefore, the comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve a minmin problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is the identification of the specific method used. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the method used to solve the minmin problem, as it is briefly mentioned in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the use of an alternating direction method to solve a minmin problem is briefly mentioned but not clarified. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the method used, which is crucial for understanding the methodology and reproducibility of the work. However, the comment could be more helpful if it suggested ways to improve the clarity or provided examples of similar methods. Despite this, the feedback is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double Qlearning, particularly in the context of MsPacman in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. Additionally, it points out that the algorithm could overestimate the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the concerns raised. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MsPacman of Figure2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the effectiveness of lower bound double Qlearning, noting the slight performance decrease in Clipped DDQN and the potential convergence to the same solutions in specific environments. Additionally, it highlights the overestimation of the true maximum value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double Qlearning, particularly in the context of MsPacman in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. Additionally, it points out that the algorithm could overestimate the true maximum value. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of concrete evidence or references to substantiate the claims makes the comment 3, as it provides a general direction but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double Qlearning, particularly in the context of MsPacman in Figure 2. It points out that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge to the same solutions in environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. Additionally, it highlights the potential overestimation of the true maximum value. While the comment identifies specific areas of concern, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their draft. The feedback provides some insight into potential weaknesses but does not offer detailed advice on how to enhance the paper\"s effectiveness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the approach are considered non novel. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment lacks specific references or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 1, as it does not provide enough information for the authors to address the concern effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach. This feedback is 3 as it highlights a concern that the authors might need to address to strengthen their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the novelty or differentiate their approach from existing methods. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA when lambda becomes small, specifically questioning why it becomes worse than vanilla DNN. The reviewer suggests that the authors should expect it to approach vanilla methods from above but from below. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make. The action is implicit and vague, as it leaves the authors to infer that they need to investigate or clarify the performance issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda is small, and it suggests an expectation about the performance trend. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA when lambda becomes small, specifically questioning why it becomes worse than vanilla DNN. The reviewer suggests that the authors should expect it to approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation or to explain why the performance might be worse. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance of DNN+MMA when lambda becomes small, questioning why it becomes worse than vanilla DNN. It suggests that the authors should expect it to approach vanilla methods from above but from below. This feedback is 3 as it identifies a potential issue with the experimental results and prompts the authors to reconsider their findings. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what specific aspects to investigate further. To be more helpful, the comment could provide more detailed reasoning or examples to support the claim. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with earlier research work from 2020, specifically mentioning the comparison with Taghipour and Ng (2016). However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be made. The comment implies that the authors should include these comparisons, but it lacks concrete instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with earlier research work from 2020, specifically mentioning the comparison with Taghipour and Ng (2016). However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in identifying the need for comparisons with earlier work, but it does not provide detailed guidance on how to incorporate these comparisons into the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, specifically mentioning the comparison with Taghipour and Ng (2016). However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of explicit examples or references to other works that should be compared with the current paper limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a lack of comparison with earlier research work from 2020, specifically mentioning the comparison with Taghipour and Ng (2016). While the authors have explained their reasons for not including these comparisons in the author response, the comment highlights an area where the paper could be strengthened by providing a more comprehensive comparison with existing work. However, the comment does not offer specific suggestions or guidance on how to incorporate these comparisons, leaving the authors with a general idea of what might be improved but without detailed direction. This makes the comment 3, as it identifies a potential weakness but lacks actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should consider using a paired test setting, such as the Wilcoxon signedrank test, instead of the current significance testing method. This feedback provides a clear and explicit action for the authors to take, specifying which test should be used and why. The suggestion is concrete, as it offers a specific alternative method that could improve the analysis. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"significance testing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the choice of test might be incorrect and recommends using a paired test setting, such as the Wilcoxon signedrank test, instead of the current method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the choice of significance test might be incorrect, specifically recommending the use of a paired test like the Wilcoxon signedrank test instead of the current method. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support why the current test might be incorrect or why a paired test would be more appropriate. This makes the claim 3, as the authors would need to further investigate and justify the recommendation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance testing method used in the paper. It suggests that the authors might have made an incorrect choice by not using a paired test setting, such as the Wilcoxon signedrank test, when comparing two samples generated from the same input. This feedback is clear and actionable, as it provides a specific alternative method that could enhance the analysis and provide more accurate results. By recommending a more appropriate statistical test, the comment offers valuable guidance for improving the robustness and validity of the authors\" findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on how to achieve this comprehensiveness or generalization. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its suggestion to expand the experiments, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these limitations are problematic or how they impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the argument. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that the experiments should be more comprehensive and general. It points out that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. This feedback is 3 as it highlights a clear need for expansion in the experimental design, which could enhance the paper\"s contribution and robustness. However, the comment lacks specific suggestions or guidance on how to achieve this comprehensiveness, such as recommending additional tasks or baselines to include. Therefore, while it provides some direction, the comment could be more actionable with detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors elaborate on the application of Hoeffding\"s bound in the context of stochastic algorithms. It implies that the authors should provide more detailed explanations or examples to clarify how the bound is used and why it is relevant. While the action is explicit, it lacks concrete details on how to elaborate on this point, such as suggesting specific aspects or examples to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (124125) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the application of Hoeffding\"s bound in the context of stochastic algorithms. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Hoeffding\"s bound holds true for any w as long as the samples are drawn independently, and that stochastic algorithms further guarantee the bound. The comment suggests that the authors elaborate on this, implying that the current explanation is insufficient. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the claim is 3, as it lacks sufficient evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific point in the paper, namely lines 124125, where the application of Hoeffding\"s bound is discussed. It highlights that the bound holds true under certain conditions, such as independent samples, and further elaborates on how stochastic algorithms impose additional conditions that guarantee the bound. The comment suggests that the authors elaborate on this aspect, which would provide a clearer understanding of the theoretical underpinnings of the work. However, the comment could be more helpful if it offered specific suggestions on how to elaborate on this point, such as providing examples or further explanations. Overall, the feedback is 3 as it points out an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table1. While the suggestion is explicit, it lacks concrete details on how to implement this optimization or what specific aspects of the approach should be integrated. The authors know that they need to add a metalearning approach, but the comment does not provide guidance on how to do so, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table1. However, it does not specify which part of Table1 the authors should consider for this addition, making it weakly grounded. The comment is specific in suggesting a particular approach to consider, but without clear guidance on where in the table this addition should be made, the authors may find it challenging to apply the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table1. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or necessary. The lack of detailed explanation or examples makes it difficult for the authors to understand the rationale behind the suggestion, rendering the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table1. This feedback is 3 as it identifies a potential area for improvement in the paper, suggesting a specific approach that could enhance the study. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. The authors are given a direction but without comprehensive instructions, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of an ablation study in the paper, specifically mentioning the choice of using fewshot examples for CoT. It suggests that this choice might be improved, implying that the authors should include an ablation study to explain the reasoning behind their choice. While the comment implies that an ablation study should be added, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that an ablation study should be included and understand the specific aspect of the choice that needs to be clarified. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study explaining the choice of using fewshot examples for CoT. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in suggesting that an ablation study should be included to address the choice of prompt, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining the choice of using fewshot examples for CoT. However, it does not provide any supporting evidence or reasoning to justify why this choice is critical or how it could impact performance. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of an ablation study in the paper. It suggests that the choice of using fewshot examples for CoT might be improved, implying that an ablation study could provide additional insights into the effectiveness of this choice. While the comment highlights a potential weakness, it does not provide detailed guidance or suggestions on how to conduct the ablation study or what specific aspects should be explored. This limits the comment\"s usefulness, as it offers a general direction for improvement but lacks actionable details. Therefore, the comment is 3, as it provides some insight but not comprehensive guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the use of the term \"causal mechanisms\" and notes that causality is different from temporal relationships. This provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is specific and actionable, as it gives precise guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect use of the term \"causal mechanisms\" and the distinction between causality and temporal relationships. The comment provides a clear direction for improvement by advising the authors to be careful with their terminology. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of the term \"causal mechanisms\" and the distinction between causality and temporal relationships. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it identifies a specific issue with the use of terminology in the paper. It points out that \"causal mechanisms\" is different from temporal relationships and suggests that the authors be careful with their terminology. This feedback is valuable as it helps the authors avoid confusion and ensures clarity in their communication. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested alternative terms. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim that replacing procedure steps of XAIFOILER with a random mechanism results in \"better than random\" performance. The reviewer expresses uncertainty about the strength of this demonstration. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve the demonstration. The action is implicit, as the authors need to infer that they should provide a more robust demonstration of capability, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the performance of replacing procedure steps of XAIFOILER with a random mechanism. It questions the strength of the demonstration that \"better than random\" performance is achieved. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique of the claim, but without explicit grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that \"replacing any of the procedure steps of XAIFOILER with a random mechanism dropped its performance\" and expresses uncertainty about the strength of the demonstration that \"better than random\" performance is achieved. However, the comment does not provide specific examples, reasoning, or references to support the claim or address the concern. This lack of detailed justification makes the claim 1, as the authors may find it challenging to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the claim that replacing procedure steps of XAIFOILER with a random mechanism results in \"better than random\" performance. It questions the strength of this demonstration, suggesting that the authors need to provide a more robust justification for their claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or improve their demonstration. The feedback is 3 as it prompts the authors to reconsider their claims, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide explicit guidance on how to incorporate this discussion or what specific aspects should be addressed. The action is implicit, as the authors can infer that they need to add a discussion, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting a particular area for discussion, but without clear guidance on where in the paper this should be addressed, the authors may find it challenging to act on the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for improvement in the paper, specifically in terms of discussing the relationship between the authors\" results and existing theoretical bounds. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this discussion or what aspects of the relationship should be explored. While it points out a relevant area for enhancement, the authors may still need to make significant efforts to address the feedback effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce the interaction count, suggesting that the authors should provide more justification for their choice. It also questions the assumptions made by PCA and provides a reference to a paper that discusses robust explanations for deep neural networks. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more justification and address the assumptions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and significance of using PCA to reduce the interaction count, suggesting that the paper\"s results are unclear. It provides a reference to a specific paper, which helps ground the comment by indicating a potential area for further exploration. However, the comment does not specify which part of the paper discusses the PCA application or the interaction count, making it weakly grounded. The suggestion to provide more justification for the assumptions made by PCA is specific, but the overall comment lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce the interaction count, suggesting that the paper\"s results are unclear. The reviewer provides a reference to a paper that discusses robust explanations for deep neural networks, which may be relevant to the discussion. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the novelty and significance. The reference to the paper is helpful but does not fully address the critique. Therefore, the comment is 3, as it provides some support but requires more detailed explanation or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce the interaction count, suggesting that the paper\"s results are unclear. It provides a reference to a paper that discusses robust explanations for deep neural networks, which may be relevant to the discussion. However, the comment lacks specific guidance or suggestions on how the authors could address these concerns or improve the clarity of their results. While it identifies an area for improvement, the feedback is 3 as it prompts the authors to consider additional justification and context for their approach. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of fewshot RC models in the paper, suggesting that they are not stateoftheart models. It also asks how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment identifies a potential issue with the choice of models, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to compare their models to stateoftheart models in fewshot settings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot RC models\" considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of these models and asking how their performance compares to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of fewshot RC models in the paper, suggesting that they are not stateoftheart models. It provides specific references to support this claim, such as \"https://aclanthology.org/2022.coling1.205.pdf\" and \"https://ieeexplore.ieee.org/abstract/document/10032649/\". These references help substantiate the claim by providing examples of stateoftheart models, making the comment 4. However, the comment could be strengthened by explaining how the performance of the fewshot RC models compares to these stateoftheart models in fewshot settings. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of fewshot RC models in the paper, suggesting that they are not stateoftheart models. It raises a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment highlights a concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to consider the relevance and performance of their models, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the results in section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or expand their results to include deeper networks or other types of networks. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, stating that the results in section 4 apply only to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how it impacts the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the results presented in section 4, specifically that they are applicable only to shallow fullyconnected ReLU networks. While this observation highlights a potential weakness in the paper, it does not provide any suggestions or guidance on how the authors might address this limitation or expand their findings to include deeper networks or other types of networks. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While the comment implies that these changes would enhance the paper\"s structure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add background information and reorder sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements in the organization of the paper, specifically mentioning the need for more background knowledge of the proposed method and moving the description of related literature forward. However, it does not specify which sections of the paper should be revised or how these changes should be implemented. The authors can infer that these changes pertain to the introduction or related work sections, but the comment lacks full grounding. It is specific in suggesting improvements but not fully grounded, as it does not provide explicit references to sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would be beneficial or how they would enhance the paper\"s organization. Without explicit guidance or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While it identifies areas for enhancement, the comment lacks specific guidance or examples on how to achieve these improvements. The authors are given a general direction but without detailed instructions, making the feedback 3. It provides some insight into potential areas for improvement but does not offer comprehensive guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include these models in their comparisons, but it lacks concrete instructions on how to implement this change or what specific aspects to focus on. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should include comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in identifying the need for additional comparisons but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not compare with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. This feedback is clear and actionable, as it directs the authors to include these models in their comparisons to strengthen their evaluation and provide a more comprehensive analysis. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or highlighted the potential benefits of doing so. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion of using sequential MCB vs a single MCT layers for the decision head was interesting but lacks results. It suggests that the authors should provide more details about what was observed. While the comment implies that the authors should include results, it does not specify how to present them or what specific results should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include results but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of results and suggests that the authors should provide more details about what was observed. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the absence of results in the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is significant or how it impacts the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks results, namely the discussion of using sequential MCB vs a single MCT layers for the decision head. It suggests that the authors should provide more details about what was observed, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered suggestions on how to present the results or what specific aspects should be highlighted. Overall, the comment is 3 as it points out a gap in the paper and encourages the authors to provide more detailed information, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to proofread the paper and fix all language problems, including specific instances such as \"we typically considers\" and \"two permutation.\" This provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be corrected. The explicit nature of the instructions and the specific examples given make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines or sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the language issues that need to be corrected, such as \"we typically considers\" and \"two permutation.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of minor comments on language usage and requests for proofreading, without making any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests proofreading to fix these problems. This feedback is clear and actionable, providing the authors with specific areas to improve the clarity and professionalism of their manuscript. However, the comment could be more helpful if it offered suggestions on how to correct these language issues or provided examples of better phrasing. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also inquires about the implications of selecting a limited number of distribution sets. While the comment highlights an area of uncertainty, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or control the number of distribution sets. The action is implicit and somewhat vague, as the authors need to infer that they should consider controlling the number of distribution sets and explore the implications of selecting a limited number. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of 20 distribution sets and questions whether the number of distribution sets for each class can be controlled. It also inquires about the implications of selecting a limited number of distribution sets. However, it does not specify which part of the paper discusses the choice of distribution sets, making it weakly grounded. The comment is specific in its questioning about the control and implications of the number of distribution sets, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also questions the implications of selecting a limited number of distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or what specific issues arise from controlling the number of distribution sets. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also inquires about the implications of selecting a limited number of distribution sets. While the comment identifies a potential area of confusion, it lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. The feedback is 3 as it prompts the authors to consider the implications of their choice, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the scope of the evaluative framework, noting that it is restricted to three QuestionAnswering tasks and two language models. It expresses reservations about the method\"s broader applicability and suggests that it might not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider additional tasks or models to enhance the framework\"s applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluative framework\"s limited scope, specifically mentioning the restriction to three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests considering other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. However, the comment does not explicitly mention which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the limitations and potential areas for expansion, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is somewhat limited in scope, as it is restricted to three QuestionAnswering tasks and two language models. The reviewer expresses reservations about the method\"s broader applicability and suggests that it might not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. While the comment identifies a limitation, it lacks specific examples or references to support the claim about the method\"s applicability. The reasoning is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to substantiate it fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability and suggests that it might not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the scope of their framework. The feedback is 3 as it prompts the authors to think about the generalizability of their method, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should showcase their approach using transformerbased language models instead of obsolete ngram HMM and RNN. This feedback provides a clear and explicit action for the authors to take, which is to replace the current perplexity experiments with those using transformerbased models. The comment also specifies the type of models that should be used, making it concrete. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and suggests using \"transformerbased (masked) language models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of transformerbased models instead of obsolete ngram HMM and RNN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the perplexity experiments are carried out on obsolete language models and recommends using transformerbased models instead. While the comment identifies a potential issue with the choice of models, it lacks specific reasoning or examples to support why transformerbased models are more appropriate or beneficial. The suggestion is based on current NLP trends, but without detailed justification or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the perplexity experiments, noting that they are based on obsolete language models (ngram HMM, RNN) that are rarely used today. It suggests that the authors should showcase their approach using transformerbased language models, which are more current in the field of NLP. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by aligning it with current trends. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or why transformerbased models are particularly beneficial. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests conducting more empirical or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. It also mentions citing a result from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiments are insufficient and recommends additional empirical or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. However, it does not specify which part of the paper these experiments should be conducted in or where the theoretical analysis is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact sections that need improvement. The comment is specific in suggesting additional experiments and citing a relevant work, but without grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests additional empirical or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. The comment provides a logical reasoning by suggesting that more experiments are needed to support the theoretical analysis. However, it lacks specific examples or references to existing studies that could guide the authors in conducting these additional experiments. This makes the claim 3, as it provides a general direction for improvement but lacks detailed evidence or references to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental validation of the paper, noting that the current experiments are insufficient. It suggests that additional empirical or toy experiments, particularly for the simplified selfattention model considered in the theoretical analysis, should be conducted to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. The comment also recommends citing a relevant work, Kaplan et al. 2020, to support the findings. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the robustness and comprehensiveness of their experimental results. However, it could be more helpful if it included suggestions on how to design these additional experiments or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their estimation method. Without specific suggestions or steps, the authors are left without a clear understanding of what needs to be done to resolve the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of misestimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the problem of misestimation, it lacks grounding as it does not provide clear guidance on where in the paper this issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors discuss the misestimation of mu, which is described as the proportion of missing observations. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it can be addressed. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and how to improve it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their estimation method. The comment lacks depth and actionable advice, leaving the authors without a clear path forward for enhancing their draft. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific approach to assess the sensitivity of the performance to initialization by varying the distance of the initial matrix M^0 from the groundtruth matrix M^*. It proposes a method where the authors vary the distance c from 0.01 to 0.1 in increments of 0.01, sample matrices M^0 such that the Frobenius norm of M^0  M^* is less than c, and report the performance accordingly. The comment provides a clear and concrete action for the authors to take, specifying exactly how they should conduct this analysis. This makes the comment 5, as it gives the authors a direct and detailed path to follow in improving their draft.", "grounding_specificity_rationale": "The comment suggests a specific approach to assess the sensitivity of the performance to initialization by varying the distance of the initial matrix M^0 from the groundtruth matrix M^*. It provides a clear and concrete suggestion for the authors to vary the distance c from 0.01 to 0.1 in increments of 0.01, sample matrices M^0 such that the Frobenius norm of M^0  M^* is less than c, and report the performance accordingly. This feedback is fully grounded as it explicitly mentions the part of the paper where the sensitivity to initialization is discussed, allowing the authors to accurately identify the relevant section. It is also specific because it provides a detailed method for conducting the analysis, including the range of c and the expected outcomes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific approach to assess the sensitivity of the performance to initialization by varying the distance of the initial matrix M^0 from the groundtruth matrix M^*. It proposes a method where the authors vary the distance c from 0.01 to 0.1 in increments of 0.01, sample matrices M^0 such that the Frobenius norm of M^0  M^* is less than c, and report the performance accordingly. The comment provides a logical reasoning for why this approach is valid, as it expects that the mean error and variance would increase as the quality of initialization decreases. However, it lacks specific references or examples to fully substantiate the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by addressing the sensitivity of the performance to initialization. It proposes a method to vary the distance of the initial matrix M^0 from the groundtruth matrix M^* and assess how this affects the performance. By suggesting a systematic approach to vary the distance c from 0.01 to 0.1 in increments of 0.01, the comment offers a clear and detailed way for the authors to conduct an analysis that could reveal insights into the robustness of their method. This feedback is 5 as it guides the authors on how to enhance their experimental design and provide a more comprehensive understanding of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a clear and explicit action for the authors to consider, as it directly points out a potential simplification in their draft. The comment provides a concrete suggestion for improvement, making it 5. The authors know exactly what change to make to address the issue, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, suggesting that it is unnecessary since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that real numbers do not require absolute values for their definition. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the validity of the claim, as it is based on a general understanding of real numbers. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a minor issue in the paper, specifically the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This is a clear and actionable suggestion that can help the authors improve their draft by simplifying the definition. By removing the absolute value, the authors can make their explanation more precise and avoid unnecessary complexity. This feedback is specific and provides a direct path for improvement, making it 4. However, it could be more helpful if it suggested alternative ways to present the concept or provided additional context. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide highprobability bounds instead of only bounds in expectation. It also recommends using ensemble methods, similar to those used in the experiments, to potentially improve the robustness of the results. Additionally, the comment proposes adding measures like error bars or standard deviation to the experiments, in addition to the mean error. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes. The actions are concrete and clear, but they are not directly stated, making the comment 4.", "grounding_specificity_rationale": "The comment suggests improvements to the paper by proposing the inclusion of highprobability bounds and robustness measures, such as error bars or standard deviation, in addition to the mean error. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments. The authors can infer that these improvements relate to the experimental results or analysis sections, but this inference is not direct. The comment is specific in its suggestions for improvement but lacks grounding as it does not explicitly mention the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper only provides bounds in expectation and recommends considering highprobability bounds, possibly through ensemble methods. It also proposes adding measures like error bars or standard deviation to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim of using ensemble methods or the effectiveness of error bars. This makes the claim 3, as the authors would need to further explore and justify these suggestions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by proposing the inclusion of highprobability bounds instead of only bounds in expectation. It also recommends adding measures like error bars or standard deviation to the experiments, in addition to the mean error, to assess robustness. These suggestions are actionable and provide clear guidance on how the authors can enhance the comprehensiveness and reliability of their results. However, the comment could be more helpful if it included examples of how to implement these suggestions or discussed the potential impact of these changes. Overall, the feedback is 4 as it directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the reviewer\"s lack of expertise in pruning but suggests that the motivation is good and the results seem less impressive. It also recommends evaluating the results from additional aspects, such as actual latency on the target device, memory consumption during inference, and the actual network size. While the comment provides specific areas for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these additional metrics for evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation and results of the paper, suggesting that the results seem less impressive and recommending additional aspects for evaluation, such as actual latency on the target device, memory consumption during inference, and the actual network size. However, it does not specify which part of the paper these evaluations should be included in, making it weakly grounded. The comment is specific in suggesting additional metrics for evaluation, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: a personal statement about the reviewer\"s lack of expertise in pruning and a critique of the results being less impressive. The second part suggests evaluating the results from additional aspects, such as actual latency, memory consumption, and network size. While the critique is 3, it lacks specific examples or references to support the claim that the results are less impressive. The suggestion to evaluate additional metrics is logical but could be more robust with specific examples or references. Therefore, the comment is 3, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the reviewer\"s lack of expertise in pruning but provides a constructive critique of the results, suggesting that they seem less impressive. It offers specific suggestions for improvement by recommending additional aspects to evaluate, such as actual latency on the target device, memory consumption during inference, and the actual network size. This feedback is clear and actionable, providing the authors with concrete directions for enhancing the comprehensiveness and impact of their results. However, the comment could be more helpful if it included examples or detailed guidance on how to implement these suggestions. Overall, the comment is 4 as it directs the authors to consider important aspects for evaluation, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a concern about the paper\"s emphasis on \"diversity\" but notes that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the model to enforce diversity or how they might address the reviewer\"s disappointment. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the paper\"s emphasis on \"diversity\" but notes that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this concern is based on, such as the introduction, methodology, or results sections. The authors might infer that it relates to the discussion of diversity in the title or the introduction, but this inference is not direct. The comment is specific in identifying the issue of not enforcing diversity explicitly, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the paper\"s emphasis on \"diversity\" but notes that the model does not enforce diversity explicitly. The reviewer provides a logical reasoning by stating that the authors were excited to see the diversity term in the model but were disappointed when it was not enforced. However, the comment lacks specific examples or references to support the claim that the model does not enforce diversity. This makes the claim 3, as it provides a general observation but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s emphasis on \"diversity,\" noting that the model does not enforce diversity explicitly despite the title and initial excitement. This feedback is clear and highlights a critical area for improvement, prompting the authors to reconsider their approach to incorporating diversity into their model. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might enforce diversity in their model. As it stands, the comment is 4, as it directs the authors\" attention to a critical issue but lacks detailed guidance on how to address it. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that certain experiments are missing, specifically mentioning \"contrastive learning and adversarial learning.\" This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is specific and gives concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment identifies a specific issue with the experiments, mentioning \"contrastive learning and adversarial learning.\" However, it does not specify which part of the paper these experiments are missing from, making it weakly grounded. The comment is specific in detailing what is missing, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that certain experiments are missing, specifically mentioning \"contrastive learning and adversarial learning.\" However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are missing or why they are important. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that certain experiments are missing, such as contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments in their draft to ensure comprehensiveness. However, the comment could be more helpful if it provided additional context or explanation on why these experiments are important or how they might impact the paper\"s conclusions. Despite this, the comment is 4 as it highlights a critical area for improvement, making it a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons, acknowledging the flaws associated with FIDs and the Inception network. The comment explicitly instructs the authors to use DinoV2 Frechet Distances, providing a clear and concrete action for improvement. This guidance is specific and actionable, allowing the authors to directly apply the suggested change to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons, acknowledging the flaws associated with FIDs and the Inception network. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where these comparisons are made. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the use of DinoV2 Frechet Distances, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that FIDs are still being widely used but have clear flaws, and suggests using DinoV2 Frechet Distances in addition to FID. The comment provides a reference to the Inception network, which is a common critique of FIDs. However, it lacks specific examples or detailed reasoning about the flaws of FIDs or the advantages of DinoV2 Frechet Distances. This makes the claim 3, as the authors would need to further explore the references and understand the specific issues with FIDs to fully grasp the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs for evaluation, acknowledging their flaws and referencing the Inception network. It suggests using DinoV2 Frechet Distances as an alternative, which could provide a more robust evaluation metric. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the rigor and reliability of the evaluation process. However, the comment could be more helpful if it provided additional context or explanation on why DinoV2 Frechet Distances are a better choice or how they differ from FIDs. Overall, the comment is 4 as it directs the authors to a potential improvement in their methodology."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the novelty of the paper, suggesting that it may be incremental compared to a specific reference. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the perceived novelty or how they could differentiate their work from the reference. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the paper, specifically comparing it to a reference. However, it does not specify which part of the paper this question pertains to, such as the introduction, methodology, or results sections. The authors might infer that it relates to the discussion of the paper\"s contribution, but this inference is not direct. The comment is specific in questioning the novelty and methodology, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of the paper by comparing it to a specific reference. However, it does not provide any detailed reasoning or evidence to support the claim that the paper is incremental or similar to the reference. The comment lacks specific examples, comparisons, or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it differs from a specific reference. This is a relevant point that could help the authors clarify the unique contributions of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might differentiate their work from the reference or what aspects of novelty they could emphasize. Without actionable feedback or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the results of the ablation studies in Table 2, specifically questioning why the complete loss function performed worse than those with some terms missing. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting further analysis, additional experiments, or potential explanations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, questioning why the complete loss function performed worse than those with some terms missing. This provides a clear direction for the authors to investigate and address the concern. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the results of the ablation studies in Table 2, specifically questioning why the complete loss function performed worse than those with some terms missing. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the results of the ablation studies in Table 2, specifically questioning why the complete loss function performed worse than those with some terms missing. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed explanations, the authors are left without a clear path forward for addressing the concern. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests including an experiment where the image is occluded, with half of the image randomly blacked out. It provides two reasons for this suggestion: (a) to simulate the irregularity often present in neural/behavioral data, such as keypoint detection failures for some mice in some frames, and (b) to inspect the longrange \"inference\" capacity of the model, as opposed to a nearlysupervised reconstruction task. The comment also notes that these experiments are reasonably easy to run and expects them to be included in the final version unless the authors can convince the reviewer otherwise. The explicit suggestion and detailed reasoning provide clear guidance on what the authors should do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the final part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides clear guidance on what experiments should be included, namely an occlusion experiment where half of the image is randomly blacked out. This suggestion is supported by logical reasoning, as it simulates irregularity in neural/behavioral data and allows for the inspection of the model\"s longrange inference capacity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to assess the model\"s longrange inference capacity. The comment provides logical reasoning by explaining how this experiment would simulate realworld scenarios and offer insights into the model\"s capabilities. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further develop the rationale to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by proposing an experiment where the image is occluded, with half of the image randomly blacked out. This suggestion is supported by logical reasoning, as it simulates the irregularity often present in neural/behavioral data and allows for the assessment of the model\"s longrange inference capacity. The comment also emphasizes the ease of running these experiments, making it a valuable piece of feedback that can help the authors enhance their draft. However, it could be more helpful if it included specific examples or further elaboration on how these experiments would be conducted. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the figure\"s visualization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, and suggests a solution by recommending the use of a second yaxis or another more physically accurate visualization. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 6C implies negative rates, which is not accurate. The reviewer recommends using a second yaxis or another visualization for more physical accuracy. While the comment identifies a specific issue with the figure, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for a second yaxis or another visualization is logical, but the comment does not provide enough evidence or explanation to fully support the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not accurate. The reviewer provides a clear suggestion for improvement by recommending the use of a second yaxis or another more physically accurate visualization. This feedback is actionable and offers a concrete way for the authors to enhance the clarity and accuracy of their figure. However, the comment could be more helpful if it included additional context or explanation about why the current visualization is problematic or how the suggested alternative would address the issue. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. While it suggests that the authors should consider testing these cases, it does not provide specific guidance on how to do so or which models to test. The action is implicit and somewhat vague, as the authors know they need to test additional cases but are not given detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. However, it does not specify which part of the paper this observation pertains to, such as specific sections or experiments where these models are discussed. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting a potential area for improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a significant observation or how it impacts the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that inverse triples could be used in other embedding models besides CP, which the authors did not test in their experiments. This feedback highlights a gap in the experimental design and provides a clear direction for the authors to consider additional cases. However, the comment lacks specific guidance on which models to test or how to incorporate these cases into the analysis, which limits its helpfulness. While it points out a potential improvement, it does not offer detailed instructions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the abstract statement is unclear and suggests that it should be more highlevel, as technical details are not necessary. While the comment identifies an issue with the abstract, it does not provide explicit guidance on how to clarify the statement or what specific changes should be made to improve its clarity. The action is implicit, as the authors can infer that they need to rephrase the abstract to make it more understandable, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract statement that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the statement, namely that it is unclear and suggests that the abstract should be more highlevel, omitting technical details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be more highlevel, omitting technical details. However, the comment does not provide any specific examples or reasoning to support why the statement is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that a statement is unclear and suggesting that it should be more highlevel, omitting technical details. This feedback is 3 as it highlights a potential area for improvement in the abstract\"s clarity. However, the comment lacks depth and does not provide specific suggestions on how to rephrase the statement or what aspects of the statement could be clarified. Without actionable guidance, the authors may struggle to effectively address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is still room to improve the complexity of Algorithm 2. However, it does not provide specific guidance on how to achieve this improvement or what aspects of the algorithm could be enhanced. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about the exact steps to take to address the issue. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that there is still room to improve the complexity of Algorithm 2, but it does not specify which part of the paper this relates to or provide details on what aspects of the algorithm could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithm\"s complexity could be enhanced. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is still room to improve the complexity of Algorithm 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is still room to improve the complexity of Algorithm 2, indicating a potential area for enhancement. However, the comment lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without detailed feedback or actionable advice, the authors are left without clear direction on how to address the issue. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include results from other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While the comment implies that the authors should consider adding results from other modalities, it does not explicitly instruct them to do so. Additionally, the suggestion to question the significance of expected test loss is somewhat vague, as it does not provide specific guidance on how to evaluate or interpret this aspect. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests including results from other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include results from other modalities and to question the significance of expected test loss, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors include results from other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. However, the comment does not provide specific examples or references to support the claim that expected test loss is not meaningful. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the suggestion without further explanation or context.", "helpfulness_rationale": "The review comment suggests that the authors include results from other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. This feedback is 3 as it identifies a potential area for improvement by suggesting additional experiments or analyses that could enhance the paper\"s comprehensiveness. However, the comment lacks depth and does not provide specific guidance on how to address these suggestions or what specific modalities or tasks should be considered. While it prompts the authors to expand their work, it does not offer actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified, specifically in the context of fewshot learning. It points out that while the paper defines and creates a fewshot situation for graph link prediction, it does not address how the proposed method effectively uses \"fewshot\" and how it guarantees generalization to new tasks with 0/few training steps. The comment implies that the authors should provide additional justification for their approach, but it does not specify how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the motivation and provide further justification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically in the context of fewshot learning. It highlights the need for justification regarding how the proposed method effectively uses \"fewshot\" and guarantees generalization to new tasks with 0/few training steps. However, the comment does not specify which part of the paper discusses the motivation or the proposed method, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation and justification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically in the context of fewshot learning. It highlights a gap in the paper by noting that while the paper defines and creates a fewshot situation for graph link prediction, it does not address how the proposed method effectively uses \"fewshot\" or guarantees generalization to new tasks with 0/few training steps. The comment provides a logical reasoning by pointing out the lack of justification for the proposed method\"s effectiveness in fewshot learning. However, it could be strengthened by providing specific examples or references to similar approaches in the literature. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation, specifically in the context of fewshot learning. It points out that while the paper defines and creates a fewshot situation for graph link prediction, it does not address how the proposed method effectively uses \"fewshot\" or guarantees generalization to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to provide further justification for their approach and its effectiveness in fewshot learning scenarios. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or examples of how similar approaches have been validated. Overall, the comment is 4, as it provides valuable insight into areas needing improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the use of Gaussian Processes (GP) is described as straightforward and naive, and notes that dynamical modeling has been widely investigated in the GP community since the Gaussian Process Dynamical Model was introduced in NIPS 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this perceived simplicity or improve their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the approach of using Gaussian Processes (GP) as being straightforward and naive, referencing the Gaussian Process Dynamical Model introduced in NIPS 2005. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides some context about the GP community and dynamical modeling, it lacks specificity regarding what aspects of the approach are considered naive or how they could be improved. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is described as straightforward and naive, and references the Gaussian Process Dynamical Model introduced in NIPS 2005. This provides a logical basis for the claim, as it situates the critique within the context of established work in the GP community. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as comparisons with other methods or evidence of the perceived naivety. While the reference to NIPS 2005 provides some support, the overall claim is 3 due to the need for more detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the approach of using Gaussian Processes (GP) as being straightforward and naive, referencing the Gaussian Process Dynamical Model introduced in NIPS 2005. However, the comment lacks specificity and does not provide detailed feedback or suggestions on how the authors might address this perceived simplicity or improve their approach. Without actionable guidance or examples, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for LM compared to the GAN model is not supported by the authors\" experience. It provides an example from Zaremba et al. (2014) to challenge the claim. The reviewer also asks whether dropout is applied to the hidden states, implying that this might be a factor in the regularization issue. While the comment highlights a potential issue and suggests a specific area for further investigation, it does not provide explicit instructions on how to address the claim or improve the draft. The action is implicit and somewhat vague, as the authors need to determine how to respond to the critique and potentially revise their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about smaller architectures being necessary for LM compared to the GAN model, providing an example from Zaremba et al. (2014) to challenge this claim. Additionally, the comment asks whether dropout is applied to the hidden states, which adds depth to the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4, suggesting that the statement about smaller architectures being necessary for LM compared to the GAN model is not supported by the authors\" experience. The reviewer provides an example from Zaremba et al. (2014) to challenge the claim, which is a strong form of evidence. However, the comment does not explicitly state that the claim is incorrect or provide a detailed analysis of why the example contradicts the statement. The mention of \"Are they also applied to the hidden states?\" adds a layer of inquiry but does not fully substantiate the claim. Therefore, the comment is 4, as it provides some evidence but lacks comprehensive justification or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific claim in the supplemental section D.4 that the authors find questionable, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It provides a counterexample from Zaremba et al. (2014) to challenge this claim, which is a valuable point for the authors to consider. Additionally, the comment asks whether dropout is applied to the hidden states, prompting the authors to explore potential factors contributing to the regularization issue. This feedback is clear and actionable, offering a specific area for the authors to investigate and potentially revise their claims. However, it could be more helpful if it provided additional guidance on how to address the issue or suggested alternative approaches. Overall, the comment is 4, as it effectively directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablation studies mentioned in previous sections are difficult to locate in the following content and suggests that the writing could be improved in this part. While the comment identifies an issue with the organization and accessibility of the content, it does not provide specific guidance on how to improve the writing or where the ablation studies are located. The action is implicit and somewhat vague, as the authors know they need to improve the organization but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions \"some of the ablations mentioned in previous sections\" and suggests that the writing could be improved in this part. However, it does not specify which sections or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement or how the ablation studies are difficult to locate. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some ablation studies mentioned in previous sections are difficult to locate in the following content and suggests that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of the ablation studies in question, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the organization and accessibility of the content, specifically mentioning that some ablation studies mentioned in previous sections are difficult to locate in the following sections. This feedback highlights a gap in the paper\"s structure and suggests that the authors should improve the writing in this part. However, the comment lacks specific guidance or suggestions on how to enhance the organization or accessibility of the content. While it points out a problem, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think it through more clearly. It also mentions that the online algorithm and robustness are interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. While the comment provides some guidance on what the authors might need to address, it lacks explicit instructions on how to improve the differential privacy application or integrate the experimental results into the main paper. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment provides a general critique of the differential privacy application being \"halfbaked\" and suggests that the authors should think it through more clearly. It also mentions the online algorithm and robustness as interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which parts of the paper are being referred to, making it weakly grounded. The authors can infer that it relates to the sections discussing differential privacy and experimental results, but this inference is not direct. The comment is specific in suggesting that the differential privacy application needs more clarity and that the experimental results should be included in the main paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and recommends the authors to think it through more clearly. It also mentions that the online algorithm and robustness are interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the differential privacy application is \"halfbaked.\" Without concrete evidence or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is 3, as it provides a general critique but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides a general critique of the differential privacy application, suggesting that it is \"halfbaked\" at the present time. It offers a constructive suggestion to the authors to think more clearly about this aspect. Additionally, it highlights the novelty and interest of the online algorithm and robustness, and suggests that the experimental results in the appendix would be more beneficial in the main paper. While the comment identifies a potential area for improvement and provides some guidance, it lacks specific details or actionable steps for the authors to take. Therefore, the feedback is 3, as it offers some direction but could be more comprehensive with detailed suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point makes a claim about the incremental nature of the multilingual chainofthought compared to the villa chainofthought. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this claim or what changes could be made to improve the paper. Without actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment makes a claim about the incremental nature of the multilingual chainofthought compared to the villa chainofthought. However, it does not specify which part of the paper this comparison is made in, nor does it provide any context or details about the specific aspects of the chains being compared. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the chains are considered incremental. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it impacts the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment makes a claim about the incremental nature of the multilingual chainofthought compared to the villa chainofthought. However, it lacks specificity and does not provide any context, reasoning, or suggestions for how this observation might impact the paper or what changes could be made to address it. Without additional information or guidance, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general could suffice. While the comment implies that the authors should clarify the specificity of their methodology, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the specificity of their methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general could suffice. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might have an idea of where the methodology is discussed, the comment lacks full grounding. It is specific in identifying the issue of specificity but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it might not be tailored to bimanual manipulation and could be more appropriately applied to general robotic manipulation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if general robotic manipulation could suffice. While the comment identifies a potential issue with the specificity of the methodology, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this concern. The feedback is 3 as it prompts the authors to clarify the specificity of their methodology, but it could be more comprehensive with additional insights or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide the METEOR results, which are also reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what information should be included in the paper. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests providing METEOR results, which are also reported in recent works. However, it does not specify which part of the paper should include these results, making it weakly grounded. The comment is specific in its request for METEOR results, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests providing METEOR results, which are also reported in recent works. However, it does not provide any specific references or examples of these recent works, nor does it explain why METEOR results are important or how they would benefit the paper. The lack of detailed justification or evidence makes the claim 1, as the authors may not have a clear understanding of why this suggestion is necessary or how it would impact their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests providing METEOR results, which are also reported in recent works. This is a specific and actionable suggestion that can help the authors enhance the comprehensiveness and credibility of their paper by aligning it with current standards. By including METEOR results, the authors can demonstrate the effectiveness of their approach in comparison to existing methods. However, the comment could be more helpful if it provided additional context or explanation on why METEOR results are particularly relevant or how they should be presented. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across different unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the comparability of their results or suggest specific methods to ensure consistency. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the concern regarding the comparability of Geffect values across different unlearning objectives and approaches. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of explicit evidence or examples makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the concern regarding the comparability of Geffect values across different unlearning objectives and approaches. It highlights that the current methodology of examining Geffects in isolation may not provide a fair comparison. However, the comment does not offer specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it points out a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider methods to ensure comparability, but the comment does not fully support this inference. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the consistency of the advantage of UNIFORM over other procedures, noting that the results are not always clear, especially in the 1shot setting. It suggests that the authors should provide a theory explaining why the method is not as effective in this setting. However, the comment does not offer specific guidance on how to address this issue or what aspects of the theory should be explored. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and provide a theoretical explanation for the observed results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the advantage of UNIFORM over other procedures, specifically noting that the results are not always clear, especially in the 1shot setting. It suggests that the authors should provide a theory explaining this inconsistency. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a theoretical explanation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the consistency of the advantage of UNIFORM over other procedures, noting that the results are not always clear, especially in the 1shot setting. The reviewer suggests that the authors should provide a theory explaining this inconsistency. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are inconsistent or to provide a basis for the theory. This makes the claim 3, as it provides a direction for further investigation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the consistency of the advantage of UNIFORM over other procedures, noting that the results are not always clear, especially in the 1shot setting. It suggests that the authors should provide a theory explaining this inconsistency. While the comment identifies a potential weakness in the paper, it does not offer specific guidance or suggestions on how to address this issue or what aspects of the theory should be explored. The feedback is 3 as it prompts the authors to consider a theoretical explanation, but it lacks actionable details that would make the comment more useful. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the reason behind the \"stronger predictor\" of information value for dialogue, specifically in the context of complementarity discussed on page 7 or page 8. It also implies that the authors should explore if there are existing linguistic theories that could explain this phenomenon and consider adding such information to strengthen the paper. While the comment provides a clear direction for the authors to consider, it does not specify which linguistic theories to explore or how to integrate them into the paper. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7 or discussion in page 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the reason behind the \"stronger predictor\" of information value for dialogue and proposes considering existing linguistic theories to explain this phenomenon. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason behind the \"stronger predictor\" of information value for dialogue and explore existing linguistic theories that could explain it. While the comment implies that this exploration would strengthen the paper, it does not provide specific examples or references to existing theories, making it 3. The authors would need to conduct further research to address the suggestion, but the comment lacks detailed guidance or evidence to fully substantiate the claim. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors explore the reason behind the \"stronger predictor\" of information value for dialogue, specifically in the context of complementarity discussed on page 7 or page 8. It further recommends considering existing linguistic theories that could explain this phenomenon, which could strengthen the paper. While the comment highlights a specific area for investigation, it does not provide detailed guidance or examples on how to conduct this exploration or which theories to consider. This limits the comment\"s helpfulness, as it offers a direction for improvement but lacks actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential reason for using AutoML approaches, which is extracting hints for future network architectures. However, it points out that the authors did not adequately comment on these aspects. The comment suggests that the authors should provide more insight into the key takeaways from the found architecture. While the action is implied, it is not explicitly stated, and the comment lacks concrete guidance on how to address this issue. The authors can infer that they need to expand their discussion on the benefits of AutoML beyond performance improvements, but the comment does not provide specific steps or examples for how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more insight into the benefits of using AutoML approaches beyond improving raw performances, specifically in extracting hints for future network architectures. However, it does not specify which part of the paper should be revised or how the authors should address this issue. The authors might infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in suggesting what needs to be addressed but lacks grounding as it does not pinpoint the exact section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more insight into the benefits of using AutoML approaches beyond improving raw performances, specifically in extracting hints for future network architectures. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the current draft does not adequately address these aspects. As a result, the claim is 3, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the authors should provide more insight into the benefits of using AutoML approaches beyond improving raw performances, specifically in extracting hints for future network architectures. It highlights a gap in the discussion by pointing out that the authors did not adequately comment on these aspects. However, the comment does not offer specific suggestions or examples on how the authors might address this issue, such as recommending additional analysis or discussion on the extracted hints. While it points out an area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. While the comment implies that the authors should aim for conciseness and include empirical results, it does not specify which parts need to be made more concise or how the inclusion of empirical results should be structured. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require conciseness and the exact nature of the empirical results to be included. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which sections or parts of the introduction need to be made more concise or how empirical results should be included. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide guidance on how to achieve conciseness or integrate empirical results effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the introduction part of the paper could be more concise and includes empirical results. However, it does not provide any specific examples, reasoning, or references to support why the introduction should be more concise or how empirical results should be integrated. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the introduction part of the paper could be more concise and that it should include empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve this. The comment does not offer actionable advice or examples of how to make the introduction more concise or integrate empirical results effectively. This limits the utility of the feedback for the authors, as it does not provide a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two specific questions regarding the empirical analysis in Figure 3. The first question asks for additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The second question seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment points out that Equations (9) and (10) have large spacing from the preceding text. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these points, but the feedback lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy, and why these adjustments are effective. Additionally, it points out that Equations (9) and (10) have large spacing from the preceding text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and explanation rather than making subjective claims or judgments. The first question asks for additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The second question seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. The comment also points out formatting issues with Equations (9) and (10). Since the comment is primarily seeking clarification and does not contain subjective claims or opinions, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas for clarification and improvement in the paper. It points out that the empirical analysis in Figure 3 is confusing and seeks additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The comment also asks for an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, it notes formatting issues with Equations (9) and (10). While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to clarify these points, but the feedback could be more actionable with detailed suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments should include a comparison with CoCoOp, a recent related work that is not currently being compared. The comment implies that this comparison is necessary, as CoCoOp is an official publication after the NeurIPS deadline but serves as an extended version. However, the comment does not provide explicit instructions on how to implement this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors know they need to include a comparison but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should include a comparison with CoCoOp, a recent related work, which is not currently being compared. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in suggesting the need for a comparison with CoCoOp, but it lacks detailed guidance on how to implement this comparison or what aspects should be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should include a comparison with CoCoOp, a recent related work, which is not currently being compared. The comment provides a logical reasoning by noting that CoCoOp is an official publication after the NeurIPS deadline but serves as an extended version, implying that it should be included in the experiments. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the rationale to fully understand the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the experiments should include a comparison with CoCoOp, a recent related work that is not currently being compared. This is a clear and actionable suggestion that could enhance the paper\"s experimental evaluation by providing a more comprehensive comparison with existing work. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what aspects of CoCoOp should be considered. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, making it a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, including specific elements such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. While the comment implies that the authors should enhance the figure to include these details, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides specific elements that should be included, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on how to improve the figure, suggesting that it should better illustrate the processing pipeline, including specific elements like prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including specific elements such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific elements are important or how they would enhance the figure. Without this additional information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve Figure 1, suggesting that it could be enhanced to better illustrate the processing pipeline. It lists specific elements that should be included, such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. This detailed guidance empowers the authors to make significant improvements to their draft, making the comment 5. However, the comment could be further improved by suggesting how these elements should be integrated into the figure or providing examples of how to present them effectively. Overall, the feedback is 4 as it offers clear direction for enhancing the figure."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and suggests that the ReBeL\"s performance on more complex problems, especially those with larger depths, is not adequately explored. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to improve the study. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments to include more complex scenarios. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the experimental setup, noting that the author only conducted experiments on two typical games and suggests that the ReBeL\"s performance on more complex problems, especially those with larger depths, is not adequately explored. This provides some level of specificity by identifying the need for more complex problem scenarios. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and suggests that the ReBeL\"s performance on more complex problems, especially those with larger depths, is not adequately explored. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the experiments are limited to two games or that more complex problems are not adequately addressed. This makes the claim 3, as the authors would need to infer the basis of the critique without explicit justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and suggests that the ReBeL\"s performance on more complex problems, especially those with larger depths, is not adequately explored. This feedback highlights a potential gap in the study\"s scope and suggests that the authors should consider expanding their experiments to include more complex scenarios. However, the comment lacks specific guidance or suggestions on how to address this issue or what additional experiments or analyses could be conducted to improve the study. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that abbreviations like \"MoCo\" should not appear in the section header, as a reader might not know what it means. This is a clear and direct action for the authors to take, providing them with a specific instruction on how to improve the draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section (136),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of abbreviations like \"MoCo\" in the section header, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not know what it means. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the section header, noting that \"MoCo\" might not be familiar to readers. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the clarity and accessibility of the paper. By addressing this issue, the authors can ensure that their work is more understandable to a broader audience. However, the comment could be more helpful if it offered additional guidance on how to effectively communicate abbreviations or alternative ways to present the information. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify the technical contribution or improve the analysis. The comment lacks actionable details, such as recommending specific methods or techniques that could be used to enhance the contribution. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper this claim pertains to, nor does it provide details on what aspects of the analysis are considered standard or how they could be improved. Without specific references or detailed feedback, the authors cannot confidently determine which sections or analyses need revision. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might clarify the technical contribution or improve their analysis. Without actionable feedback or detailed examples, the authors are left without a clear understanding of what needs to be addressed to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment criticizes the paper for its limited novelty and suggests that the improvements on different datasets are trivial. It implies that the paper lacks originality and that the contributions are incremental, similar to previous works. However, the comment does not provide any specific guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. There is no explicit or implicit action for the authors to take, and no concrete details on how to improve the paper. As a result, the comment is 1, as it does not help the authors know what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper and suggests that the improvements on different datasets are trivial. However, it does not specify which datasets or aspects of the paper are being discussed, nor does it provide details on what specific improvements are considered trivial or incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity and grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited. It suggests that the work is incremental, similar to previous studies on the same topic. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, suggesting that the improvements on different datasets are trivial and that the work is incremental compared to previous studies. While it identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The comment does not provide actionable feedback or detailed examples of what could be improved, making it 3. The authors may gain some insight into the need for more original contributions, but the comment could be more helpful with additional guidance or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific aspects of the theoretical guarantee should be discussed. The action is implicit, as the authors can infer that they need to include a discussion on this topic, but the comment does not offer concrete steps or suggestions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing, which is the theoretical guarantee discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by highlighting the lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy compared to the global optimal of the original QUBO. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific theoretical aspects should be considered. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of quantitative measures for evaluating the generated VCEs, suggesting that evaluation is primarily based on visual inspection. While it identifies a gap in the methodology, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to incorporate quantitative measures, but the comment does not specify which measures to use or how to implement them. This makes the action implicit and somewhat vague, as the authors need to deduce the necessary steps without clear direction. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a lack of quantitative measures for evaluating the generated VCEs, suggesting that evaluation is primarily based on visual inspection. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where quantitative measures are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the need for quantitative measures, but without grounding, it lacks clarity on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is generally lacking a quantitative measure to evaluate the generated VCEs, with evaluation primarily relying on visual inspection. This claim is 3 as it highlights a potential gap in the methodology, but it lacks specific examples or references to support the assertion. The comment does not provide detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative measures for evaluating the generated VCEs. It notes that the evaluation is primarily based on visual inspection, which is a common practice but may not be sufficient for a comprehensive assessment. This feedback is valuable as it highlights an area where the paper could be strengthened by providing more rigorous evaluation methods. However, the comment could be more helpful if it suggested specific quantitative measures or provided guidance on how to incorporate them into the analysis. Overall, the comment is 3 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights issues with the generated videos, noting significant artifacts and low action recognition performance compared to the stateoftheart on the UCF dataset. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their work. The comment raises questions but does not offer concrete steps or actions for the authors to take. As a result, the authors are left without clear direction on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the issue of significant artifacts in the generated videos and the low action recognition performance compared to the stateoftheart on the UCF dataset. However, it does not specify which part of the paper discusses the generated videos or the action recognition performance, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might infer that it relates to the results or discussion sections, the lack of explicit references makes the comment weakly grounded. The comment is specific in detailing the issues with the generated videos and the performance metrics, but without grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the stateoftheart on the UCF dataset. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the extent of the issues or how to address them. The absence of detailed evidence or comparisons to existing methods makes the claim 3, as the authors would need to make significant effort to substantiate the claims themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the generated videos, noting that they have substantial artifacts and that the action recognition performance is below the stateoftheart on the UCF dataset. This feedback highlights a critical area for improvement, as it points out the need for better video generation and recognition techniques. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it provides valuable insight into the weaknesses of the current approach, it does not offer actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. While it identifies a gap in the paper, it does not provide explicit guidance or suggestions on how to address this issue. The comment implies that the authors should explore methods to enhance diversity and representation, but it lacks concrete steps or examples for implementation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are covered, the comment lacks full grounding. It is specific in identifying the need for more diversity and representativeness but does not provide detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not provide any claims, opinions, or suggestions that require verification. It is purely a question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also questions the selection of representative images. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out a critical area for enhancement, but it does not provide actionable steps or detailed advice for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, specifically mentioning elements like MDPs, trajectories, and policy. It also advises providing a brief overview of the original DPO algorithm to clarify the context of the modifications proposed in the methods section. These instructions are clear and concrete, giving the authors a direct path to improve their draft by adding these sections. The comment provides specific guidance on what needs to be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors include a background section to introduce the basic RL framework, specifically mentioning elements like MDPs, trajectories, and policy. It also advises providing a brief overview of the original DPO algorithm to clarify the context of the modifications proposed in the methods section. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or background sections. The comment is specific in detailing what needs to be included, such as the elements of the MDP and the DPO algorithm. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements like MDPs, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to help readers understand the modifications proposed in the methods section. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of these sections themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a background section to introduce the basic RL framework, specifically mentioning elements like MDPs, trajectories, and policy. This would help readers understand the context being considered. Additionally, the comment advises providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are detailed and constructive, offering the authors a clear path to enhance the clarity and comprehensibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically the issue of limited model capacity when new languages are continuously added. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the method to handle such scenarios. There is no guidance on potential solutions, such as suggesting alternative approaches or modifications to the model architecture. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the proposed method, specifically the issue of limited model capacity when new languages are continuously added. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the limitation, it lacks grounding as it does not provide clear guidance on where this issue is addressed in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation if users continuously add new languages due to limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically the issue of limited model capacity when new languages are continuously added. This feedback is 3 as it highlights a critical area that the authors need to address to improve the robustness and scalability of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might overcome this limitation. While it points out an important consideration, it does not offer actionable steps or detailed advice, which limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). It does not provide explicit guidance or suggestions on how the authors should address this question or incorporate it into their draft. The comment lacks actionable details, leaving the authors uncertain about what specific changes or improvements are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This provides clear guidance on what aspect of the paper needs further clarification or discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their draft. The comment lacks depth and actionable advice, making it 2. Authors would need to infer that they should consider the relevance of \"interpretable\" program in their work, but without further guidance, the feedback remains limited in its usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might expand their experiments or what additional datasets or approaches could be considered. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, specifically mentioning that they are limited to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these experiments are described, the comment lacks full grounding. It is specific in identifying the limitation but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the paper\"s conclusions. Without additional context or explanation, the authors may find it challenging to understand the significance of this limitation and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. While this is a valid observation, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their experiments. Without actionable feedback or specific recommendations, the authors are left without a clear path forward for improving their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the S2D structure, specifically regarding the number of parameters not changing despite the kernel height/width remaining the same. The reviewer acknowledges that efficiency could be improved due to the FLOP being quadratic on the activation side length but questions the lack of detail in terms of parameters. While the comment implies that the authors should provide more details on parameter changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the parameter changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of parameters not changing despite the kernel height/width remaining the same, and it provides a rationale for why this might be the case. The comment also suggests that more details are expected regarding the parameters, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically regarding the number of parameters not changing despite the kernel height/width remaining the same. The reviewer acknowledges that efficiency could be improved due to the FLOP being quadratic on the activation side length but questions the lack of detail in terms of parameters. While the comment provides some logical reasoning, it lacks specific examples or references to support the claim that more details are expected. This makes the claim 3, as the authors would need to infer the need for more detailed explanations themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the S2D structure, particularly regarding the number of parameters not changing despite the kernel height/width remaining the same. It acknowledges that efficiency could be improved due to the FLOP being quadratic on the activation side length but questions the lack of detail in terms of parameters. This feedback is clear and actionable, as it prompts the authors to provide more detailed explanations or justifications for their design choices. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar structures that have been successful. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to elaborate on their design decisions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this observation or incorporate these ideas into their work. The comment implies that the authors should explore or discuss these aspects, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is made or where these suggestions should be addressed. The authors cannot confidently determine which sections or elements of the paper are being discussed, making the comment weakly grounded. Additionally, while the comment suggests a potential improvement, it lacks specificity in detailing what aspects of the method in 10 could be enhanced or how the authors might address the question posed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the similarity between the proposed method and the approach in 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. This observation prompts the authors to consider potential improvements or extensions to their work. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this observation or incorporate these ideas into their draft. While it highlights an area for potential enhancement, the feedback is vague and does not offer detailed suggestions for improvement, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might expand their analysis or suggest additional baselines to improve the interpretability of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the presentation of the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the interpretability of their results. While it highlights an area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what specific changes could be made to the model to incorporate such a constraint. The action is implicit and vague, as it does not specify how to implement the suggested improvement or what specific changes should be made. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proposed method\"s lack of a sparsity constraint in the number of factors used by subsequent tasks. It highlights a potential problem with the model\"s incentivization to use more factors as more tasks are added, leading to increased computation. However, the comment does not explicitly mention a specific section of the paper where this issue is discussed, making it weakly grounded. The comment is specific in detailing the issue with the sparsity constraint and its implications on the model\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation as more tasks are added. The comment provides a logical reasoning by explaining the potential issue with the model\"s incentivization to use more factors. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added, which is a significant concern. The comment provides a clear and actionable insight into a potential weakness in the model, suggesting that the authors should consider incorporating a sparsity constraint to address this issue. However, the comment could be more helpful if it offered specific suggestions on how to implement such a constraint or provided examples of how other models have addressed similar issues. Overall, the feedback is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the presentation of the simulation study is not effectively aiding the authors in understanding the performance of the GPC benchmark compared to their method, BPC. It suggests that the authors should clarify why the GPC is performing better, specifically mentioning that this is due to bandit feedback and not the form of the cost function. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of the simulation study, specifically pointing out that the authors do not adequately comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should clarify this difference, noting that it is due to bandit feedback and not the form of the cost function. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the explanation of the performance difference. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not effectively aiding the authors in understanding the performance difference between the GPC (benchmark) and BPC (their method). The reviewer suggests that this difference is due to bandit feedback and not the form of the cost function. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of concrete evidence or references to substantiate the claim makes it challenging for the authors to improve their draft based on this feedback. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area where the presentation of the simulation study could be improved. It points out that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method), suggesting that this difference is due to bandit feedback and not the form of the cost function. This feedback is valuable as it prompts the authors to clarify and elaborate on this aspect, which could enhance the clarity and understanding of their results. However, the comment could be more helpful if it provided specific suggestions on how to improve the explanation or examples of how to present this information effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors might benefit from quantifying and clarifying the claim that \"ReLU does not work very well in very deep or in convolutional networks.\" It provides a specific example by mentioning that ReLUs were used in the AlexNet paper, which was considered deep and used convolutional layers with pooling. This feedback is explicit and provides a concrete action for the authors to take, which is to quantify and clarify the claim. The suggestion is clear and actionable, giving the authors a specific direction to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors might benefit from quantifying and clarifying the claim that \"ReLU does not work very well in very deep or in convolutional networks.\" It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers with pooling. This feedback is specific as it provides a clear example of a relevant work and suggests a way to improve the paper by quantifying and clarifying the claim. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might benefit from quantifying and clarifying the claim that \"ReLU does not work very well in very deep or in convolutional networks.\" The comment provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers with pooling. This provides some context and a basis for the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might benefit from quantifying and clarifying the claim that \"ReLU does not work very well in very deep or in convolutional networks.\" It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers with pooling. This feedback is actionable and offers a concrete suggestion for the authors to improve their draft by providing a specific example and a clear direction for further exploration. However, the comment could be more helpful if it offered additional guidance on how to quantify or clarify the claim. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reported perplexity in Figure 1, noting that it appears unusually high given the better BLEU scores observed. The reviewer questions the calculation of perplexity and suggests that it might be incorrect. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to resolve the discrepancy. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate the calculation of perplexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the reported perplexity being unusually high and questions the calculation of perplexity, suggesting that it might be incorrect. The comment provides a clear direction for the authors to investigate the calculation of perplexity, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the reported perplexity in Figure 1, noting that it appears unusually high given the better BLEU scores observed. The reviewer questions the calculation of perplexity, suggesting that it might be incorrect. However, the comment lacks specific examples or references to support the claim that perplexity is unusually high or to provide a basis for questioning the calculation. Without detailed justification or evidence, the claim remains 3, as it requires further explanation or context to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the reported perplexity in Figure 1, noting that it appears unusually high given the better BLEU scores observed. The reviewer questions the calculation of perplexity, suggesting that it might be incorrect. This feedback is 3 as it identifies a potential inconsistency in the results and prompts the authors to investigate the calculation of perplexity. However, the comment could be more helpful if it provided specific guidance on how to verify the perplexity calculation or suggested alternative methods for assessing the model\"s performance. Overall, the comment offers a starting point for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. While the action is explicit, it lacks concrete details on how to implement these experiments or what specific aspects of the model should be tested. The authors know they need to conduct additional experiments, but the comment does not provide guidance on how to execute this suggestion effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or results that need to be addressed. This lack of grounding makes it difficult for the authors to pinpoint where these experiments should be added or what aspects need to be expanded. While the suggestion is specific in terms of what experiments should be conducted, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these specific experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what aspects of the model should be tested. The comment highlights a relevant area for enhancement but does not offer actionable steps for the authors to take, making it 3. The authors would gain some insight into what additional experiments could be conducted, but the comment could be more comprehensive and detailed to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should elaborate on why rooted patterns are important and how they choose the roots. It suggests that a brief discussion is expected, or if nonrooted patterns are sufficient, the discussion could be limited to the supplementary material. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of rooted patterns and the lack of elaboration on their importance and root selection. It also suggests a brief discussion or discussion in the supplementary material if nonrooted patterns are sufficient. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to discuss this in the supplementary material is a helpful suggestion, but without further elaboration, the claim remains 1. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing feedback on the lack of elaboration regarding the importance of rooted patterns and the method of choosing roots. It suggests that a brief discussion is expected or that the discussion could be limited to the supplementary material if nonrooted patterns are sufficient. This feedback is clear and actionable, offering the authors a concrete direction for enhancing the clarity and comprehensiveness of their work. However, it could be more helpful if it included examples or further guidance on how to address these issues. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more explanations on the consistency between training and inference, which is mentioned multiple times in the paper. The suggestion is explicit, as it clearly states that the authors should elaborate on this point. However, it does not provide specific guidance on how to improve the explanation or what aspects should be clarified. While the action is clear, the lack of detailed instructions on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (Line 9597 and Line 308310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is providing more explanations on the consistency between training and inference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanations on the consistency between training and inference, which is mentioned multiple times in the paper. However, the comment does not provide any specific reasoning or evidence to support why this explanation is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand the need for more detailed explanations. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more detailed explanations be provided on the consistency between training and inference. This is a clear and actionable piece of feedback, as it directs the authors to enhance the clarity and depth of their discussion on this topic. By addressing this suggestion, the authors can significantly improve the comprehensibility of their work, making it more valuable to readers. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on this point. Overall, the feedback is 4, as it effectively points out an area for improvement and encourages the authors to make their explanation more robust."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for finetuning two hyperparameters, k and \u03b7, and mentions that this depends on the availability of the environment or a good Offline Policy Evaluation (OPE) method. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The comment implies that the authors should consider the impact of these hyperparameters on their results, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the introduction of two hyperparameters, k and \u03b7, and mentions the need for finetuning them, which depends on the availability of the environment or a good Offline Policy Evaluation (OPE) method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning process is described, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of hyperparameter finetuning, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good Offline Policy Evaluation (OPE) method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency of this finetuning on the availability of the environment or a good Offline Policy Evaluation (OPE) method. While the comment points out a potential limitation in the methodology, it lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. The feedback is 3 as it directs the authors\" attention to a critical aspect of their work, but it does not provide detailed guidance on how to resolve the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should try to reproduce the main features of previous models, specifically mentioning the GLM presented by Pillow et al., which did not use cropping but instead used L1 regularization and a low rank approximation. However, the comment does not provide explicit instructions on how to implement this suggestion or what specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to make the comparison fair. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to apply regularization to both LN models and GLMs, allowing the authors to identify the specific part of the paper being addressed. It also provides specific guidance by suggesting that the authors should try to reproduce the main features of previous models, such as the GLM presented by Pillow et al., which did not use cropping but used L1 regularization and a low rank approximation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should try to reproduce the main features of previous models, specifically mentioning the GLM presented by Pillow et al. The reviewer provides a specific reference to the GLM, which allows the authors to understand the basis of the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why reproducing these features is important or how it would improve the comparison. While the reference to Pillow et al. provides some support, the claim is 3 due to the need for further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the application of regularization to both LN models and GLMs. It suggests that the authors should attempt to reproduce the main features of previous models, such as the GLM presented by Pillow et al., which did not use cropping but instead used L1 regularization and a low rank approximation. This feedback is 3 as it highlights a potential area for improvement and provides a specific direction for the authors to consider. However, the comment could be more helpful if it offered detailed guidance on how to implement this suggestion or provided examples of how to reproduce the features. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include some failure cases and related discussion in their paper. While the comment implies that the authors should add this information, it does not specify which failure cases to include or how to integrate them into the discussion. The action is implicit and somewhat vague, as the authors need to infer what specific aspects to address and how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this should be included in, making it weakly grounded. It also lacks specificity regarding what failure cases should be discussed or how they should be integrated into the discussion. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include some failure cases and related discussion. However, it does not provide any specific examples, reasoning, or evidence to support why this is necessary or how it would benefit the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include some failure cases and related discussion in their paper. While this feedback is 3 as it points out an area for improvement, it lacks specificity and does not provide detailed guidance on which failure cases to include or how to integrate them into the discussion. The authors are left with a general direction but without concrete steps to follow, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct an ablation study to determine the necessity of the base layer GNN encoding in their proposed method. While the action is explicit\u2014conducting an ablation study\u2014the comment does not provide specific guidance on how to design or execute this study. The authors are left to infer the exact steps needed to perform the ablation, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to determine the necessity of the base layer GNN encoding in the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the base layer GNN encoding is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an ablation study, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study is needed to determine the necessity of the base layer GNN encoding in the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would impact the results. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by questioning the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to determine the importance of this component, which is a clear and actionable recommendation for the authors. This feedback is valuable as it provides a specific direction for improving the paper by exploring the role of the base layer GNN encoding. However, the comment could be more helpful if it included suggestions on how to design or execute the ablation study. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the authors should explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers specific guidance on how to address the issue of computational complexity discussion.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on the computational complexity of counting homomorphisms and the suggestion to explicitly add upper bounds and elaborate on empirical runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms. It supports this claim by suggesting that the authors should explicitly add the upper bounds of counting and elaborate on empirical runtimes. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to infer the importance of computational complexity and the need for explicit discussion, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of discussion on the computational complexity of counting homomorphisms. It acknowledges the brief mention of efficient computation on large datasets but suggests that the paper should explicitly add the upper bounds of counting and elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the comprehensiveness and depth of their discussion. By addressing this feedback, the authors can significantly improve the clarity and utility of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific corrections to the text, such as changing \"f\" to \"g\" and removing an extra \".\" in line 115. These are explicit actions that the authors can directly implement to improve their draft. However, the comment also raises a question about the convergence of networks in the baseline MCL with deep learning, suggesting that the authors should explain how they ensured convergence. While this question implies an action, it is not explicitly stated, making it somewhat vague. Overall, the comment is 4 due to the explicit corrections and the suggestion to address the convergence issue, which provides a clear direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (line 108 and line 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the correction needed for the first \"f\" to \"g\" and the removal of an extra \".\" in line 115. Additionally, it raises a question about the convergence of networks in the baseline MCL with deep learning, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a correction to the text and a question about the convergence of networks in the baseline MCL with deep learning. The correction is factual and does not require verification. The question, however, is more of a request for clarification rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two minor errors in the text: a typo in line 108 and an extra punctuation mark in line 115. These corrections are straightforward and can be easily addressed by the authors. Additionally, the comment raises a question about the convergence of networks in the baseline MCL with deep learning, prompting the authors to explain how they ensured convergence. This question is valuable as it highlights a potential area for improvement in the methodology section. While the comment is 4, it could be more comprehensive if it provided additional guidance or suggestions on how to address the convergence issue. Therefore, it is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method and compare it to previous topdown and bottomup methods. While the comment implies that the authors should conduct this study, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for the authors to follow. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method and comparing it to previous topdown and bottomup methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the inference time is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a comparison with previous methods, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should study the inference time of their pose estimation method and compare it to previous topdown and bottomup methods. This claim is 3 as it provides a logical reasoning for why inference time is an important factor to consider. However, the comment lacks specific references or examples to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method and compare it to previous topdown and bottomup methods. This feedback is 3 as it identifies a potential area for improvement in terms of performance evaluation. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this study or what specific comparisons should be made. While it prompts the authors to consider an important aspect of their work, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the proof of Theorem A.3, questioning the indexing of the input x and the correctness of an equation. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the indexing and verify the equation, but without detailed instructions on how to do so, the actions are implicit and vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two distinct questions: one about the indexing of the input x and another about the correctness of an equation. These questions provide clear guidance on what needs to be clarified or corrected in the proof. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the proof of Theorem A.3, specifically regarding the indexing of the input x and the correctness of an equation. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, questioning the indexing of the input x and the correctness of an equation. By pointing out these potential errors, the comment provides the authors with clear and actionable feedback that can help them improve the accuracy and clarity of their proof. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of similar proofs for reference. Overall, the feedback is 4 as it directs the authors to areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the clarity and veracity of the results presented in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and points out a specific issue with the percentage of result lists containing the ground truth logical forms. The reviewer suggests that the authors should clarify how they ensure the correctness of the entities/relationships plugged in, especially when no ground truth is available. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these concerns or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the clarity and veracity of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the clarity and veracity of the results, particularly regarding the use of terms like \"somewhat\" and \"good generative ability,\" and questions the percentage of result lists containing the ground truth logical forms. The comment also inquires about the correctness of entities/relationships plugged in when no ground truth is available. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a concern about the clarity and veracity of the results presented in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and points out a specific issue with the percentage of result lists containing the ground truth logical forms. The reviewer suggests that the authors should clarify how they ensure the correctness of the entities/relationships plugged in, especially when no ground truth is available. While the comment raises a valid concern, it lacks specific examples or references to support the claim, making it 3. The authors would need to further develop their understanding of the issue to address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the clarity and veracity of the results presented in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and points out a potential issue with the percentage of result lists containing the ground truth logical forms. The reviewer also raises a critical question about how the entities and relationships are ensured to be correct when no ground truth is available. This feedback is clear and actionable, as it prompts the authors to clarify and improve the veracity of their results. However, the comment could be more helpful if it provided suggestions on how to address these concerns or examples of how to ensure the correctness of the entities and relationships. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it only increases the variance of lowvariance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not provide specific guidance on how to address these limitations or what aspects should be discussed. The action is implicit and somewhat vague, as the authors know they need to discuss these limitations but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it only increases the variance of lowvariance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion of dropout methods or the section discussing internal covariate shift, but this inference is not direct. The comment is specific in detailing the limitations of the claim, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it only increases the variance of lowvariance units. The reviewer supports this claim by comparing it to Batch Normalization, which standardizes variance and centers activation. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it only increases the variance of lowvariance units. It suggests that this limitation should be discussed explicitly, providing a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to address these limitations or provided examples of how to discuss them effectively. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the dependence of FedPCL on the selection of pretrained models and suggests that the authors have addressed the limitations by developing a lightweight federated learning framework. However, it does not provide explicit guidance on how to implement these improvements or offer concrete suggestions for the authors to follow. The comment implies that the authors should consider these aspects, but it lacks specific instructions or examples on how to achieve this. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the dependence of FedPCL on pretrained models and the sensitivity of model accuracy to these models. The comment further elaborates on the authors\" efforts to address these limitations by developing a lightweight framework and integrating pretrained models for federated aggregation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL is heavily dependent on the selection of pretrained models, which limits its applications. It supports this claim by referencing Table 4, which shows the sensitivity of model accuracy to pretrained models. The comment also acknowledges that the authors have addressed these limitations by developing a lightweight framework and integrating pretrained models for federated aggregation. This provides a logical and factual basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the framework reduces computation and communication costs. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the dependence of FedPCL on the selection of pretrained models, which limits its applications. It highlights this as a limitation and notes that the authors have addressed it by developing a lightweight federated learning framework and integrating pretrained models for federated aggregation. The comment provides a clear understanding of the issue and acknowledges the authors\" efforts to address it. However, it lacks specific suggestions or guidance on how to implement these improvements or further enhance the framework. While it offers some insight, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional information should be included. The comment is concrete, as it outlines the specific elements that need to be added to the figures, making it 5.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, implying that the authors should consider adding this information to their figures. However, it does not explicitly mention which figures or sections of the paper these figures are in, making it weakly grounded. The comment is specific in its suggestion to include additional attention maps, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. However, it does not provide any justification or reasoning for why this addition would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their paper by including additional information in their figures. By doing so, the authors can provide a more comprehensive analysis of their results, which could lead to a better understanding of the attention mechanisms involved. However, the comment could be more helpful if it included examples of how to present these maps or why they are important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to \"add more description about the contribution of this paper.\" This is a direct and clear action, providing the authors with a specific task to enhance their draft. The comment is concrete, as it clearly specifies what needs to be done\u2014adding more detailed description about the paper\"s contribution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this should be added to, nor does it provide any guidance on what aspects of the contribution should be elaborated upon. Without specific references or detailed suggestions, the authors may find it challenging to determine where and how to improve the description. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning or examples to support why this addition is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should add more description about the contribution of their paper. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the contribution should be elaborated upon. The comment is 3 as it points out a need for additional explanation, but it does not offer actionable advice or examples to help the authors achieve this. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as organizing the description of attention mechanisms into a separate section and referencing tricks like normalization or feature scaling in another section. These suggestions are concrete and provide clear guidance on how to improve the structure and organization of the paper. However, the comment does not include specific details on how to implement these actions, such as which sections should be reorganized or how to reference the tricks. While the actions are explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for organizing the paper, such as introducing two types of attention for deep VAEs and separating their description from the generative and inference models. It also mentions referencing tricks like normalization or feature scaling in a separate section. However, the comment does not explicitly mention which sections of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that these suggestions relate to sections discussing attention mechanisms and model descriptions, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as organizing the description of attention mechanisms and referencing tricks like normalization or feature scaling. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of suggestions for organizing the paper and referencing specific elements, such as attention mechanisms and tricks like normalization or feature scaling. These suggestions are based on logical reasoning about the structure and clarity of the paper. However, the comment does not provide specific examples or detailed reasoning to support why these changes are necessary or how they would improve the paper. As a result, the claims are 3, as they offer a general direction for improvement but lack detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for organizing the paper, such as introducing two types of attention for deep VAEs and separating their description from the generative and inference models. This feedback is clear and actionable, as it guides the authors on how to improve the structure and organization of their draft. Additionally, the comment suggests referencing tricks like normalization or feature scaling in a separate section, which is another valuable piece of guidance. However, the comment could be more helpful if it included specific examples or detailed instructions on how to implement these suggestions. Overall, the feedback is 4 as it offers clear directions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the authors either do not understand Figure 5 or that the labels are incorrect. However, it does not provide any explicit guidance or suggestions on how to address this issue. The comment lacks specificity and does not offer concrete steps for the authors to take to resolve the confusion or correct the labels. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. However, it lacks specificity because it does not provide details on what is unclear about Figure 5 or the nature of the label issue. The authors know that Figure 5 is problematic, but they are not given specific guidance on how to address the issue. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that either the authors do not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with Figure 5, either the authors not understanding it or the labels being incorrect. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without additional context or examples, the authors are left without actionable feedback on how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the experiments, suggesting that it would be reasonable to assume full annotation is available for datasets of scale ~100k images. It also mentions that even if full annotation isn\"t available, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these baselines and understand the reasoning behind it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of missing supervised baselines in the experiments, suggesting that it would be reasonable to assume full annotation is available for datasets of scale ~100k images. It also provides a rationale for including these baselines, even if full annotation isn\"t available, to compare selfsupervised methods to a fully supervised pretrained network. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these baselines should be included. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its suggestion to include these baselines, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a reasonable assumption for datasets of scale ~100k images, where full annotation might be available. It suggests that even if full annotation isn\"t available, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. The comment provides a logical reasoning based on the scale of the datasets and the potential availability of full annotation. However, it lacks specific examples or references to support the claim further, which could enhance the verifiability. Therefore, the comment is 4, as it provides a reasonable argument but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It suggests that, given the scale of the datasets (~100k images), it is reasonable to assume full annotation is available, and even if it isn\"t, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by including these baselines. However, the comment could be more helpful if it offered additional guidance on how to implement these comparisons or why they are particularly relevant. Overall, the comment is 4, as it effectively directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal, suggesting that the results may be influenced by random variation. It also points out that the benchmarks are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods and the selection of outdated benchmarks, providing a specific reference to a paper for further context. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. The comment is specific in detailing the issues with performance differences and outdated benchmarks, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, suggesting that the results may be influenced by random variation. It also notes that the benchmarks are outdated and likely saturated. The comment references a specific paper, \"LoRA Learns Less and Forgets Less,\" which provides a basis for the claim about the saturation of benchmarks. This reference adds credibility to the claim, as it supports the assertion with an external source. However, the comment could be strengthened by providing more detailed reasoning or examples of how the benchmarks are outdated or saturated. Overall, the claim is 4 due to the supporting reference, but it could be more robust with additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the performance differences between methods being minimal, suggesting that the results may be influenced by random variation. It also points out that the benchmarks used are outdated and likely saturated, which could impact the validity of the results. The comment references a specific paper, \"LoRA Learns Less and Forgets Less,\" which provides a basis for the claim about the saturation of benchmarks. This feedback is 3 as it highlights areas for improvement in the evaluation section, but it lacks detailed guidance or suggestions on how the authors might address these issues. The authors are given a starting point for improvement but would need to conduct further analysis to fully address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggests potential improvements. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it points out the absence of BEAR in the baselines and questions its relevance. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are implicit and somewhat vague, as the authors need to infer the actions to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and suggestions regarding the evaluation of the method on different domains. It specifically questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it points out the absence of BEAR in the baselines and questions its relevance. However, the comment does not explicitly mention which sections or parts of the paper these questions pertain to, making it weakly grounded. The questions are specific in nature, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on deterministic dynamics and suggests evaluating it on nondeterministic domains. It also questions the absence of BEAR in the baselines. While the comment highlights potential areas for improvement, it lacks specific evidence or references to support the claims about the method\"s effectiveness or the absence of BEAR in the baselines. The questions are more of a request for clarification rather than a claim that needs verification. Therefore, the comment is classified as \"2,\" as it provides some direction but lacks sufficient evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for improvement. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This feedback is valuable as it prompts the authors to consider a broader range of scenarios, potentially revealing the method\"s true capabilities. Additionally, the comment points out the absence of BEAR in the baselines and questions its relevance, which is a relevant observation that could guide the authors in refining their experimental setup. While the comment is clear and prompts the authors to consider additional evaluations, it could be more helpful if it provided specific examples or guidance on how to conduct these evaluations. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to consider broader implications of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide a theocratical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include such justification, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to present the justification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide a theocratical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for justification, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide a theocratical justification for why cotraining and weight averaging can improve results. However, the comment does not offer any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors provide a theocratical justification for why cotraining and weight averaging can improve results. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the need for a theoretical justification of the methods used. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or what kind of justification would be appropriate. The authors may gain some insight into the importance of theoretical justification but may struggle to fully understand and implement the suggested improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in section 4, \"X\" should be a multiset instead of a set, and provides a rationale for this change by explaining that it is necessary to include multiplicities of labels in the graph to accurately represent it. The comment explicitly states the action that the authors should take, which is to change \"X\" to a multiset and clarify the set of multisets of size n. This provides clear and concrete guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for the suggestion, explaining that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The comment further specifies the need to include multiplicities of labels in the graph. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning by explaining the necessity of including multiplicities of labels in the graph. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this change themselves, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential issue in section 4, where \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The comment offers a clear rationale for this change, explaining the necessity of including multiplicities of labels in the graph. This feedback is valuable as it guides the authors on how to enhance the accuracy and representation of their work. However, the comment could be more helpful if it included additional context or examples to fully illustrate the impact of this change. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional explanations or examples, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete guidance on what specific details should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that more details about the proposed method should be presented. It highlights the need for explaining how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered specific examples or guidance on how to present these details effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method in detecting hallucinations in openended responses, specifically mentioning an example where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the method. There is no guidance on potential solutions, such as refining the prompt or adjusting the detection mechanism. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and provides a specific example of a potential issue with detecting hallucinations in openended responses. It clearly specifies the problem by mentioning the example of a prompt that could lead to responses about different individuals, making it easy for the authors to identify the relevant part of the paper. However, the comment does not provide specific guidance on how to address this issue or improve the method. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, using the example of a prompt like \"introduce a sports celebrity to me.\" The comment provides a specific example to illustrate the potential issue, making it 3. However, it lacks detailed reasoning or evidence to fully substantiate the claim, such as examples of how the method fails or specific scenarios where it would struggle. This makes the claim 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method in detecting hallucinations in openended responses, using a specific example to illustrate the issue. It highlights the challenge of distinguishing between different individuals when the prompt is about introducing a sports celebrity. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve their method. While it points out a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. This is an explicit action, as it clearly instructs the authors to conduct additional experiments or analyses to validate their findings. The comment provides concrete guidance on what specific experiments to perform, making it 5. The authors know exactly what needs to be done to address the feedback, which aligns with the criteria for a score of 5.", "grounding_specificity_rationale": "The comment suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper discusses these theoretical findings, making it weakly grounded. The comment is specific in suggesting that the authors should verify their conclusions on specific datasets, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. However, it does not provide any supporting evidence, reasoning, or references to justify why this verification is necessary or how it would impact the findings. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of verification of the conclusion about label noise and model size on MNIST and CNN. It suggests that the authors should conduct additional experiments or analyses to validate their findings. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and reliability of their results. However, the comment could be more helpful if it offered suggestions on how to conduct these verifications or provided examples of similar studies. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks whether the selection criteria in section 4.2 is reasonable, specifically questioning why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not chosen. While the comment provides some specific suggestions for improvement, it lacks concrete guidance on how to implement these suggestions, such as how to create the table or what specific criteria should be considered. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s organization and writing quality, allowing the authors to accurately identify the parts being addressed. It also specifies the weaknesses by suggesting improvements, such as drawing a table to compare CoT prompting methods and questioning the assumption about the frequenterror cluster. Additionally, it asks for clarification on the selection criteria in section 4.2, which provides specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could be improved by drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks whether the selection criteria in section 4.2 is reasonable. While the comment provides some logical reasoning and questions, it lacks specific examples or references to support the claims about the table and the assumption. This makes the claims 3, as the authors would need to further develop the suggestions to fully address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s organization and writing quality, which is a positive aspect. However, it identifies specific areas for improvement, such as suggesting the addition of a table to compare CoT prompting methods across different dimensions. This is a clear and actionable suggestion that could enhance the paper\"s clarity and organization. Additionally, the comment questions the assumption about the frequenterror cluster and the selection criteria in section 4.2, prompting the authors to consider the rationale behind their choices. This feedback is valuable as it encourages the authors to critically evaluate and potentially improve their methodology. Overall, the comment provides constructive feedback that can help the authors enhance their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explicitly mention that the probability distribution p(y | H_f(t_n)) must be Gaussian for the application of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs. While the comment implies that this is an important point to clarify, it does not provide specific guidance on how to implement this suggestion or where in the paper this clarification should be made. The action is implicit and somewhat vague, as the authors need to infer where to add this information and how to execute the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should explicitly mention that the probability distribution p(y | H_f(t_n)) must be Gaussian for the application of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probability distribution p(y | H_f(t_n)) must be Gaussian for the application of Kalman Filtering and Smoothing and CVI. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is necessary or how it impacts the methodology. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the probability distribution p(y | H_f(t_n)) must be Gaussian for the application of Kalman Filtering and Smoothing and CVI. It also mentions that this assumption is already made in the ELBOs. While the comment highlights an important point that the authors should clarify, it lacks specific guidance on how to address this issue or where in the paper this clarification should be made. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay across all layers, suggesting that this could lead to suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider reporting cosine similarities for larger weight decay strengths or adjust their approach to avoid this problem. While the action is implicit, it is somewhat specific in suggesting that the authors should consider reporting cosine similarities for larger weight decay strengths. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of weight decay across all layers and the implications of this choice on cosine similarities. It provides specific details about the expected outcomes and the absence of reported cosine similarities for larger weight decay strengths. This level of detail allows the authors to clearly identify the part of the paper being addressed and understand the specific issue being raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying weight decay to all layers could lead to suboptimal cosine similarities for large weight decay parameters. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed explanation or references to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay across all layers, suggesting that this could lead to suboptimal cosine similarities for large weight decay parameters. It highlights a gap in the paper by noting that cosine similarities for such large weight decay strengths are not reported, and the plots end at a point where cosine similarities are still close to optimal. This feedback is 3 as it points out a specific area that needs attention and suggests that the authors should consider reporting cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue or how to improve the analysis. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant omission in the paper, noting that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a critical issue that could lead to misinterpretation by casual readers. The reviewer suggests that this omission must be fixed for publication, implying that it is a straightforward action to take. However, the comment does not provide specific guidance on how to address this issue, such as suggesting where to include the explanation or what specific information should be added. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation regarding the results being for unsupervised random forests. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The reviewer suggests that this is a critical issue that could lead to misinterpretation by casual readers. However, the comment lacks specific examples or references to support the claim that the omission is serious or how it affects the conclusions. Without detailed evidence or examples, the claim is 3, as it provides a general concern but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests. This is a significant issue that could lead to misinterpretation by casual readers, potentially affecting the conclusions drawn from the work. The reviewer acknowledges the importance of this omission and suggests that it must be addressed for publication, noting that it would be straightforward to fix. However, the comment could be more helpful by providing specific guidance on how to incorporate this information into the title, abstract, introduction, and discussion. Additionally, it could suggest ways to ensure that the results are clearly presented and understood by the broader audience. While the feedback is valuable, it could be more actionable with additional details, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as suggesting the use of illustrative experimental results to show that minimizing HSICcondi could perform better than minimizing HSIC_HOOD, possibly using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it suggests providing visualization results or schematic diagrams to aid in understanding. The comment is explicit and provides concrete details on how to implement the suggested improvements, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as suggesting the use of illustrative experimental results and a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it suggests providing visualization results or schematic diagrams to aid in understanding. This level of detail and specificity provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as suggesting the use of illustrative experimental results and a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it suggests providing visualization results or schematic diagrams to aid in understanding. While the comment provides some guidance, it lacks detailed examples or references to specific experiments or datasets that could be used to substantiate the claim. The suggestions are 3, as they offer a direction for improvement but do not fully support the initial claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as suggesting the use of illustrative experimental results and a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it suggests providing visualization results or schematic diagrams to aid in understanding. These suggestions are clear and actionable, offering the authors a clear path to enhance the comprehensiveness and impact of their work. However, the comment could be more helpful if it included examples of how to conduct these experiments or diagrams. Overall, the feedback is 4 as it guides the authors in making their work more robust and understandable."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It suggests that the authors should compare the computational complexity with other methods. While the comment implies that the authors should conduct a comparison, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for the authors to follow. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the description of an online version of the algorithm, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the computational complexity of the proposed method compared to other methods, providing a clear direction for the authors to address. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed method requires much more computation than other methods, suggesting that it should be compared to other methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods, which is a relevant concern in the context of large models and datasets. By prompting the authors to compare the computational complexity, the comment provides a clear and actionable suggestion for improvement. This feedback is valuable as it guides the authors to address a potential weakness in their work, potentially leading to a more comprehensive evaluation of their method. However, the comment could be more helpful if it included specific examples or references to other methods for comparison. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper where the authors discuss the differences between certain methods but do not provide significance testing to support their claims. It specifically mentions the need for proper testing, including checking the distribution and accounting for multiple comparisons. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to conduct the significance testing or what specific statistical methods to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (line 486) and provides a detailed example of the claims made in the paper. It specifies the issue by pointing out the lack of significance testing to support the claims about the differences between methods. The comment also provides specific examples, such as the comparison between \"zh>en ChatGPT\" and \"GPT4,\" and the scores for \"FeedME2\" and \"PPO.\" This level of detail allows the authors to clearly identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide significance testing to support their claims about the differences between certain methods. The reviewer provides specific examples, such as the comparison between \"zh>en ChatGPT\" and \"GPT4,\" and the scores for \"FeedME2\" and \"PPO,\" to illustrate the issue. However, the comment lacks detailed reasoning or references to justify why the absence of significance testing is a problem or how it affects the validity of the claims. While the examples are helpful, the overall claim is 3 due to the lack of comprehensive justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the lack of significance testing to support the claims about the differences between certain methods. It provides a specific example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT4, and highlights the minimal difference in scores between these methods. The reviewer emphasizes the need for proper testing, including checking the distribution and accounting for multiple comparisons, to determine if the observed differences are statistically significant. This feedback is clear and actionable, as it directs the authors to a specific area where they need to improve their analysis and provide a more rigorous evaluation of their results. However, the comment could be more helpful if it offered suggestions on how to conduct the significance testing or provided examples of appropriate statistical methods. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach description in section 3 is difficult to follow and suggests that the additional page of the cameraready version should be used to extend the approach description rather than adding more experiments. This provides a clear and direct action for the authors to take, specifying where the description is lacking and suggesting a specific way to improve it. The comment is concrete and provides detailed guidance on how to enhance the clarity of the approach description. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach description (\u00a7 3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be revised, namely that the approach description is difficult to follow and suggests using the additional page of the cameraready version to extend the description rather than adding more experiments. This provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in section 3 is difficult to follow and suggests that the additional page of the cameraready version should be used to extend the description rather than adding more experiments. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is difficult to follow or how extending it would improve clarity. Without such evidence or examples, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the approach description in section 3, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending that the additional page of the cameraready version be used to extend the approach description rather than adding more experiments. This feedback is actionable and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their approach description. However, the comment could be more helpful if it included specific suggestions on how to improve the description or examples of what could be included. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of interpretive insights in the experiments section regarding the proposed gyrostructures and suggests that the paper should include comparisons with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights the need for additional comparisons, it does not provide specific guidance on which methods to include or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors know they need to add comparisons but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it highlights the lack of interpretive insights regarding the proposed gyrostructures and suggests that the paper should include comparisons with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments lack interpretive insights and suggests that the proposed gyrostructures do not outperform existing methods. It also points out the absence of comparisons with other stateoftheart methods. While the comment identifies a gap in the analysis, it lacks specific examples or references to support the claim about the lack of interpretive insights or comparisons. This makes the claim 3, as the authors would need to further investigate and provide evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experiments section by pointing out the lack of interpretive insights regarding the proposed gyrostructures and their performance compared to existing methods. It also highlights the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could clarify the effectiveness of the proposed approach. This feedback is clear and actionable, as it directs the authors to enhance the interpretability of their experiments and expand the scope of comparisons. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what types of methods to include. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing these specific areas of concern."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential usecases of _LMGQS_ over other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more evidence or analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential usecases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its request for additional evidence or analysis, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential usecases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential usecases of _LMGQS_ over other QFS datasets. This feedback is 3 as it identifies a gap in the paper\"s evidence and encourages the authors to enhance the depth and clarity of their analysis. However, the comment lacks specific guidance on what kind of evidence or analysis would be beneficial, such as suggesting particular metrics or experiments to include. While it points out an area for improvement, it does not offer detailed instructions on how to address it, making the feedback 3 but incomplete."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented in it. It also notes that the authors only study CATER for Englishcentric datasets and suggests that the text generation APIs are typically for translation, which supports multiple languages. The comment implies that the authors should consider extending CATER to other languages in the future. While the action is implicit, it is concrete in terms of suggesting specific details to be added and a potential future extension. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more details about the two baselines presented in Figure 5 and consider extending CATER to other languages. This provides clear guidance on what needs to be addressed and improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in it. The reviewer also notes that the authors only study CATER for Englishcentric datasets and suggests that the text generation APIs are typically for translation, which supports multiple languages. While the comment provides some logical reasoning about the limitations of the current study, it lacks specific examples or references to support the claim that the baselines are not adequately described. This makes the claim 3, as the authors would need to further develop their understanding of the issue to address it effectively.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that the authors should provide more details about the two baselines presented in the figure. It also points out that the study only focuses on Englishcentric datasets, while text generation APIs are typically used for translation, which supports multiple languages. The comment suggests that the authors could extend their work to other languages in the future. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, it could be more helpful if it included suggestions on how to enhance the comprehensibility of Figure 5 or examples of how to extend the study to other languages. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review is unclear and needs improvement. It highlights the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the literature review section, indicating that it is unclear and needs improvement. It specifies the need for a clearer understanding of the main contribution of the proposed method and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, it does not explicitly mention which part of the literature review this issue is present in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing a more explicit and comparative analysis of related work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for a more detailed literature review themselves, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it is unclear and lacks depth in explaining the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a clear and actionable piece of feedback. This guidance empowers the authors to enhance the clarity and depth of their literature review, making the comment 4. However, it could be more helpful if it provided specific examples or suggestions on how to improve the analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. While the comment implies that the section should be removed, it does not explicitly instruct the authors to do so. The action is inferred and lacks concrete details on how to implement this change, such as whether the section should be completely removed or just revised. Therefore, the comment is 3, as it provides a general direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests eliminating section 3.2, implying that readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper section 3.2 refers to, making it weakly grounded. The comment is specific in suggesting that the section can be removed, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples or references to similar sections in the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. This feedback is 3 as it provides a specific suggestion for streamlining the paper and reducing redundancy. However, it lacks depth and does not offer alternative approaches or detailed reasoning for why the section should be removed. The authors are given a direction but not a comprehensive guide on how to improve the draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that the improvements in the teacher\"s performance are due to distillation rather than regularization effects. It suggests that the finetuning on GLUE without validation earlystopping usually has very high variances and that proper ablation studies are needed to verify the claim. While the comment implies that the authors should conduct ablation studies, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform these studies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the study of knowledge distillation, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it details the potential issue with the claim that improvements are due to distillation rather than regularization effects. The comment further specifies the need for proper ablation studies to verify the claim, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the claim that the improvements in the teacher\"s performance are due to distillation rather than regularization effects. It questions the validity of this claim by pointing out that the finetuning is performed for only 10 epochs without earlystopping, which is a common practice in machine learning that can lead to high variance. The comment suggests that proper ablation studies are needed to verify the claim. While the comment provides a logical reasoning based on common practices, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the critique but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim regarding the source of improvements in the teacher\"s performance. It suggests that the improvements might be due to regularization effects rather than distillation, given the limited finetuning epochs and the absence of earlystopping. The comment highlights the need for proper ablation studies to verify the claim, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to conduct these ablation studies or examples of relevant literature that could guide the authors. Overall, the comment is 4 as it points out a critical area for improvement and encourages the authors to conduct further analysis, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific suggestions for improving the experiments section. The first suggestion is to add performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility and robustness of the framework. The second suggestion is to include experiments with morphologically rich languages like Finnish, Hebrew, and lowresource languages, which is noted as a minor point. Both suggestions are explicit and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as adding performance metrics on word similarity and sentence translation tasks, and including experiments with morphologically rich and lowresource languages. This guidance helps the authors understand what additional elements to consider in their experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment suggests adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility and robustness of the framework. This suggestion is based on a logical reasoning that additional metrics can provide more evidence for the framework\"s effectiveness. The second comment suggests including experiments with morphologically rich languages like Finnish, Hebrew, and lowresource languages, which is noted as a minor point. While the first suggestion is wellsupported by logical reasoning, the second comment lacks specific justification or examples, making it 3. Overall, the comment is 4 due to the detailed reasoning in the first part and the minor point in the second part.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experimental section of the paper. First, it suggests adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility and robustness of the framework. This is a clear and actionable recommendation that can help the authors strengthen their experimental evidence. Second, the comment suggests including experiments with morphologically rich languages like Finnish, Hebrew, and lowresource languages, which is noted as a minor point. This feedback is valuable as it highlights areas where the authors could expand their experiments to provide a more comprehensive evaluation of their framework. Overall, the comment is 4 as it offers specific and actionable suggestions for improving the draft, but it could be more comprehensive with additional guidance on how to implement these suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it questions how node importance can be used in a 1shot scenario, and second, it notes the absence of a 1shot setting in the experiment part, despite the mention of related works like RALE that do have such a setting. While the comment highlights areas that need clarification, it does not provide explicit instructions or suggestions for the authors to address these issues. The actions are implicit and vague, as the authors are left to infer that they need to explain the use of node importance in a 1shot scenario and include a 1shot setting in their experiments. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two distinct points. First, it questions how node importance can be used in a 1shot scenario, which is a specific issue that could be addressed in the paper. Second, it notes the absence of a 1shot setting in the experiment part, despite the mention of related works like RALE that do have such a setting. However, the comment does not specify which part of the paper discusses the 1shot scenario or the experiment section, making it weakly grounded. The comment is specific in identifying the issues, but without explicit references to sections, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point consists of two separate questions: one about the use of node importance in a 1shot scenario and another about the absence of a 1shot setting in the experiment part. The first question is a request for clarification, not a claim, and the second question is a critique of the paper\"s experimental setup. Since the comment does not contain any subjective opinions, judgments, or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two important points. First, it questions how node importance can be used in a 1shot scenario, which is a critical aspect of the paper that needs clarification. Second, it notes the absence of a 1shot setting in the experiment part, despite the mention of related works like RALE that do have such a setting. This feedback is 3 as it identifies areas where the paper could be improved by providing more detailed explanations and including a 1shot setting in the experiments. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to incorporate the 1shot setting. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that the authors should expand their analysis, it does not provide specific guidance on what aspects of the problem to address or how to approach the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed explanations and analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more detailed discussions on the challenges and potential solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a critical issue or how it impacts the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these issues. This feedback is clear and actionable, as it provides a direction for the authors to enhance the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these challenges. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward expanding their discussion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of insight into why selfsupervised learning is necessary for the proposed approach on 360 video data with spatial audio. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects they should explore to provide more insight. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of insight into why selfsupervised learning is necessary for the proposed approach on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is discussed, the comment lacks full grounding. It is specific in identifying the need for more insight but does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of insight into why selfsupervised learning is necessary for the proposed approach on 360 video data with spatial audio. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the lack of insight into why selfsupervised learning is necessary for the proposed approach on 360 video data with spatial audio. It points out that while the experimental results suggest the value of the approach, there is no detailed explanation provided. This feedback highlights a gap in the paper that the authors need to address to improve the clarity and comprehensiveness of their work. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing additional analyses or providing more context on the importance of selfsupervised learning in this context. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, implying that the authors should consider revising the text to clarify this relationship. Second, it explicitly instructs the authors to include labels for subfigures in Figures 3 and 4, rather than just stating this information in the captions. Both actions are clear and provide concrete guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the link between IP and the terms/equations should be explained more explicitly and prominently, and it provides a concrete request to include labels for subfigures in these figures. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate suggestions: one about the explanation of the link between IP and terms/equations, and another about the inclusion of labels for subfigures in Figures 3 and 4. Neither of these suggestions is a claim that requires verification, as they are requests for clarification or improvement in the presentation of the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear and actionable recommendation. Second, it advises including labels for subfigures in Figures 3 and 4, rather than just stating this information in the captions. These suggestions are concrete and provide the authors with clear directions on how to enhance the clarity and presentation of their work. While the comment could be more comprehensive, it is 4 as it offers actionable feedback that can significantly improve the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to average the results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a concrete instruction on how to achieve this, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as specific experiments or results sections. Without explicit references to sections or figures, the authors may find it challenging to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding which results or experiments should be averaged or how this averaging would impact the conclusions. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that the results be averaged over multiple runs to determine statistical significance. This feedback is specific and directly addresses a potential weakness in the experimental setup, offering a concrete step for the authors to take in enhancing the reliability and robustness of their results. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why averaging is necessary in the context of the study. Despite this, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis of the SimCLR approach, specifically mentioning the lack of analysis on the projection head, which is considered important. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this gap or what kind of analysis is required. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis of the projection head. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SimCLR case\" and the \"projection head,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular aspect of the SimCLR approach that is not covered in the analysis, namely the projection head, which is considered important. The comment suggests that there should be an analysis of this component, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, the comment does not provide specific references to SimCLRv2 or other recent papers that discuss the importance of the projection head. Without these references, the claim lacks sufficient evidence or context to support the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific gap in the analysis of the paper, noting that while the SimCLR case is covered, there is no analysis on the projection head, which is considered important. This feedback is clear and actionable, as it highlights a critical area that needs further exploration. By pointing out this omission, the comment guides the authors to enhance the depth and comprehensiveness of their analysis, potentially leading to a more robust and complete understanding of the approach. However, the comment could be more helpful if it provided suggestions on how to analyze the projection head or what aspects of the projection head should be considered. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should highlight the observations and conclusions in the experimental section, which would be beneficial for understanding the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations and conclusions more prominent, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section contains these observations or conclusions, making it weakly grounded. The comment is specific in its suggestion to highlight these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why this is important or how it would benefit the paper. Without concrete evidence or examples, the claim is 3, as it highlights a potential area for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these elements would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s clarity and aiding the authors in organizing their findings more effectively. However, the comment could be more helpful if it offered additional guidance on how to highlight these elements or provided examples of what could be included. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide ablation experiments for the modifications mentioned in Section 3.4 to validate the model performance further. This is an explicit action, as it clearly states what the authors should do to improve their draft. The comment also provides a concrete suggestion on how to implement this action by specifying that ablation experiments should be conducted. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing ablation experiments to validate the model performance further, which clearly indicates what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments for the modifications mentioned in Section 3.4 to validate the model performance further. However, the comment does not provide any supporting evidence, reasoning, or references to justify why ablation experiments are necessary or how they would validate the model performance. This lack of detailed justification makes the claim 1, as the authors may not fully understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments for the modifications mentioned in Section 3.4 to further validate the model performance. This feedback is clear and actionable, as it provides a specific and concrete suggestion for the authors to enhance the robustness and reliability of their results. By recommending ablation experiments, the comment offers a direct way for the authors to improve the quality and credibility of their work. However, the comment could be more helpful if it included examples of how to conduct these experiments or why they are particularly important. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison of performance on datasets where the decision space is beyond binary, suggesting that the KDE might require more data in such cases. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their draft. The comment implies that the authors should consider including a comparison, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison of performance on datasets where the decision space is beyond binary, suggesting that the KDE might require more data in such cases. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparison of performance on datasets where the decision space is beyond binary, suggesting that the KDE might require more data in such cases. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the comparison of performance on datasets where the decision space is beyond binary, specifically mentioning the KDE and Zhang et. al.44. It highlights a potential issue with the KDE requiring more data in such cases, which is not a problem for other approaches. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it offers insight but lacks detailed guidance for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While these questions suggest that the authors should explore the relationship between model capacity and FID, and address unexpected artifacts in their method, they do not provide explicit instructions or concrete guidance on how to conduct this exploration or resolve the artifacts. The actions are implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions pertain to, such as specific sections or figures discussing the SR model or the proposed method. This lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. While the questions are specific, the absence of grounding information makes the comment weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These are questions seeking clarification rather than claims or opinions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While these questions point out areas that need further exploration or clarification, they do not provide specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it identifies potential areas for improvement, but it lacks depth and actionable advice, making it less useful for the authors to make significant improvements to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback provides a clear and direct action for the authors to take, specifying what additional experiments are needed. The comment is specific in its request for these types of experiments, making it 5. The authors know exactly what kind of experiments they need to include to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing what additional experiments are needed, providing clear guidance on what the authors should address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional experiments, specifically mentioning comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the paper. Without such details, the claim remains 1, as it lacks the necessary justification for the authors to understand the importance of the suggested experiments. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional experiments, specifically mentioning the need for comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides the authors with specific directions on what experiments to include to strengthen their work. By addressing these areas, the authors can enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered suggestions on how to design these experiments or why they are particularly important. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors might address these issues or improve the paper. The comment lacks actionable details, such as recommending ways to enhance the contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution or approach are considered limited or incremental. Without specific references or detailed feedback, the authors cannot confidently determine which parts of the paper need revision or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper appears somewhat limited and that the proposed model seems incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the limited contribution and incremental nature of the proposed model. While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address these issues. Without detailed guidance or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more careful analysis is needed, particularly for \"old\" benchmarks that the model might have indirectly seen through data curation. It also mentions that more details about the evaluation procedures would be helpful. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a more careful analysis is needed, particularly for \"old\" benchmarks that the model might have indirectly seen through data curation. It also mentions that more details about the evaluation procedures would be helpful. However, the comment does not specify which benchmarks are considered \"old\" or provide specific examples of these benchmarks. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper this comment addresses. The comment is specific in suggesting the need for a more detailed analysis and evaluation procedures, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks but suggests that a more careful analysis is needed, especially for \"old\" benchmarks that the model might have indirectly seen through data curation. The comment implies that the authors should provide more details about the evaluation procedures. However, the comment lacks specific examples or references to support the claim about the \"old\" benchmarks or the need for a more detailed analysis. This makes the claim 3, as the authors would need to infer the specific areas requiring attention. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on many benchmarks but suggests that a more careful analysis is needed, particularly for \"old\" benchmarks that the model might have indirectly seen through data curation. It also recommends providing more details about the evaluation procedures. This feedback is 3 as it highlights a potential area for improvement and suggests a specific aspect that could be explored further. However, the comment could be more actionable by offering concrete suggestions or examples of how to conduct a more detailed analysis or improve the evaluation procedures. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the experimental setup, noting that the different methods in the two sets of benchmarks are quite different in different OPE methods. The reviewer suggests that the authors provide comments on these differences. While the action is implicit, it is clear that the authors need to address the differences between the two sets of evaluation methods. However, the comment does not provide specific guidance on how to analyze or present these differences, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the differences in the evaluation methods between the two sets of benchmarks proposed in the article. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the consistency of the experimental setup, specifically regarding the differences in evaluation methods between two sets of benchmarks. However, it does not provide any supporting evidence, reasoning, or references to justify why this discrepancy is problematic or how it affects the validity of the experimental results. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically the differences in evaluation methods between two sets of benchmarks. It highlights that the methods in Figure 4 and Figure 5 are quite different, which could impact the validity of the experimental results. The comment suggests that the authors provide comments on these differences, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to address these differences or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the experimental setup, where the proposed method lacks an advantage compared to the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make the comparison fair. The action is implicit and somewhat vague, as the authors need to infer that they should consider the additional complexity and cost in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the comparison with the stateoftheart (SOTA), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method lacks an advantage without prior information and requires two representation models, which adds complexity and cost. The comment provides clear guidance on what needs to be addressed to make the comparison fair. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage compared to the stateoftheart (SOTA) without prior information, suggesting that the comparison is unfair. The reviewer supports this claim by explaining that the proposed method requires two representation models (e.g., VAE/GAN + CL), which adds complexity and cost. This reasoning provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, noting that the proposed method lacks an advantage compared to the stateoftheart (SOTA) without prior information. It highlights that the comparison is unfair because the proposed method requires two representation models, which adds complexity and cost. This feedback is clear and actionable, as it prompts the authors to reconsider the fairness of their comparison and address the additional complexity involved in their method. However, the comment could be more helpful if it provided specific suggestions on how to mitigate the added complexity or how to structure the comparison to make it fair. Overall, the comment is 4, as it provides valuable insight into a critical aspect of the experimental evaluation that the authors should consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the behavior of the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to implement this suggestion, such as which collaborative games to include or how to analyze the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should include collaborative games to evaluate the behavior of the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the behavior of the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the behavior of the methods in both collaborative and competitive settings. This feedback is 3 as it identifies a potential area for improvement in the experimental design, which could enhance the comprehensiveness and applicability of the study. However, the comment lacks specific guidance on which collaborative games to include or how to analyze the results, which would make it more actionable. Overall, the comment provides some insight but could be more detailed and comprehensive to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, which makes them hard to be convincing. This feedback provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is specific in its request, as it identifies the exact figures that are missing and highlights the importance of these details in making the figures convincing. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figures 1 to 9,\" which allows the authors to accurately identify the parts of the paper being addressed, making it fully grounded. It also specifies the issue, which is the absence of experimental settings, and explains why this is a problem (i.e., it makes the figures hard to be convincing). Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes them hard to be convincing. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the manuscript, specifically the absence of experimental settings for Figures 1 to 9. This is a critical oversight that could undermine the credibility and persuasiveness of the figures presented in the paper. By pointing out this missing information, the reviewer provides the authors with a clear and actionable suggestion to improve the quality and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to include or present the experimental settings effectively. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the rationale behind the work, specifically the ambiguity in clarifying how the proposed method avoids hindering the learning of new task knowledge. While it identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this ambiguity. The comment implies that the authors should clarify this point, but it lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically discussing the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids this issue. However, the comment does not specify which part of the paper discusses this rationale, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the proposed method\"s approach to avoiding hindrance in learning new task knowledge. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is ambiguous, specifically regarding how the proposed method avoids hindering the learning of new task knowledge. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids hindering the learning of new task knowledge. It points out that some parameter isolation methods are specifically tailored to leverage sparsity, which raises questions about the proposed method\"s approach. While the comment highlights a gap in the explanation, it does not provide specific suggestions or guidance on how the authors might address this ambiguity. The feedback is 3 as it directs the authors to a critical area that needs clarification, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears to be adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not provide explicit guidance on how to implement this suggestion or which statistics to consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics for regularization and consider why the mean and standard deviation were not used. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, suggesting that it is adhoc and lacks theoretical support. It provides specific examples, such as the use of the median as an alternative to the mean, which could be used in the regularization. However, the comment does not explicitly mention which part of the paper discusses the regularization term, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting alternative statistics for regularization, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide specific examples or references to support the claim that the current approach is adhoc or lacks theoretical support. The suggestion to use the median as an alternative is logical, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3, as it provides a basis for the claim but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, suggesting that it is adhoc and lacks theoretical support. It provides a specific example of an alternative statistic, the median, which could be used instead of the mean and standard deviation. This feedback is 3 as it highlights a potential weakness in the methodology and offers a concrete suggestion for improvement. However, the comment could be more helpful if it provided additional context or explanation on why the current approach is considered adhoc or if it explored other potential statistics that could be used. Overall, the comment offers some actionable insight but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear action by stating that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper. The comment also offers a concrete suggestion by specifying that this would provide tangible evidence of the proposed method\"s performance and position the framework within the existing FairML research landscape. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting comparisons with existing fairness algorithms and integrating benchmark comparisons against stateoftheart fairness algorithms. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section lacks comparisons with existing fairness algorithms and recommends integrating benchmark comparisons against stateoftheart fairness algorithms. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that such comparisons would enhance the paper\"s performance evidence and position the framework within the existing research landscape. However, the comment lacks specific references or examples of existing fairness algorithms, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section by pointing out the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper\"s performance evidence and effectively position the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental section. By addressing this suggestion, the authors can strengthen the validity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and suggests that they should also discuss the iteration cost of all related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed. The comment is specific and offers concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors discuss the iteration cost (computational budget) of their proposed method and recommend discussing the iteration cost of all related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for discussion on iteration costs, but without clear grounding, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and recommend discussing the iteration cost of all related methods, including baseline methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is important or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their draft by discussing the iteration cost (computational budget) of their proposed method. It further recommends that the authors also discuss the iteration cost of all related methods, including baseline methods. This feedback is specific and offers a concrete direction for enhancing the paper\"s analysis and discussion sections, helping the authors address a critical aspect of their work. However, the comment could be more helpful if it provided additional guidance on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests reporting average results over multiple runs, which is a clear and direct action. Additionally, it asks for a discussion on the decision boundaries in Section 3.1, which is another explicit action. Lastly, it requests clarification on the information presented in Figure 9, which is also a direct request for additional information. Each of these actions is concrete and provides specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts being addressed. It also provides specific suggestions for improvement, such as reporting average results over multiple runs and discussing the decision boundaries in Section 3.1. Additionally, it asks for clarification on the information presented in Figure 9. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several suggestions for improvement, such as reporting average results over multiple runs, discussing decision boundaries, and clarifying information in a figure. These are requests for additional information or analysis rather than subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the experimental section. It suggests reporting average results over multiple runs to better compare methods, which is a clear and direct recommendation. Additionally, it requests a discussion on the decision boundaries in Section 3.1, which could enhance the understanding of the results. Lastly, it asks for clarification on the information presented in Figure 9, which is a request for additional detail. These suggestions are constructive and provide the authors with concrete steps to improve their draft, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation of the new proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this limitation, such as suggesting alternative approaches, modifications to the model, or additional constraints. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the new proposed model, specifically mentioning the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this issue is discussed, the comment lacks full grounding. It is specific in identifying the limitation but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the new proposed model, specifically mentioning that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. While this observation highlights a potential constraint of the model, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the model\"s applicability. Without actionable feedback or constructive advice, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is rated as 2, as it points out a limitation but lacks depth and actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of supervised pretraining based on the prediction of the homolumo gap, suggesting that this approach may lead to negative transfer, particularly in downstream experiments on QM9. It notes that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the paper\"s claim of being a \"generalpurpose neural network model.\" However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their model. The action is implicit and vague, as it does not specify how to mitigate the negative transfer or enhance the model\"s generalpurpose capabilities. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"QM9 in downstream experiments\" and \"TransformerM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of negative transfer and provides an example of how this affects the performance of TransformerM on most tasks, contradicting the paper\"s claim of being a \"generalpurpose neural network model.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of the homolumo gap may lead to negative transfer, particularly in downstream experiments on QM9. The reviewer provides an example of TransformerM performing poorly on most tasks other than homo, lumo, and gap, which contradicts the paper\"s claim of being a \"generalpurpose neural network model.\" This claim is supported by specific examples and data from the QM9 dataset, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of the homolumo gap, suggesting that this approach may lead to negative transfer, particularly in downstream experiments on QM9. It provides a specific example of TransformerM performing poorly on most tasks other than homo, lumo, and gap, which contradicts the paper\"s claim of being a \"generalpurpose neural network model.\" This feedback is 3 as it highlights a critical concern that the authors should address, but it lacks detailed suggestions or guidance on how to mitigate this issue or improve the model\"s generalpurpose capabilities. Therefore, the comment provides some insight but does not offer comprehensive guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" statement regarding the center correlation not being insightful for discriminating model defenses, despite its use in Figure 4 A&B. The reviewer is seeking clarification on why this metric was found useful in the figure but not elsewhere, or what the authors meant by their statement. While the comment implies that the authors should clarify this point, it does not provide explicit guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the statement and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082 and Figure 4 A&B, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" statement about the center correlation not being insightful for discriminating model defenses, despite its use in the figure. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement regarding the center correlation not being insightful for discriminating model defenses, despite its use in Figure 4 A&B. The reviewer is seeking clarification on why this metric was found useful in the figure but not elsewhere. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the center correlation is not insightful. This lack of detailed justification makes the claim difficult for the authors to address effectively, rendering the comment 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" statement regarding the center correlation not being insightful for discriminating model defenses, despite its use in Figure 4 A&B. It seeks clarification on why this metric was found useful in the figure but not elsewhere, or what the authors meant by their statement. This feedback is 3 as it prompts the authors to clarify their reasoning and potentially improve the clarity of their explanation. However, it lacks specific guidance or suggestions on how to address the issue, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" might be too strong and provides a specific explanation of what the phenomenon represents. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to revise the term or what alternative terms to consider. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the naming of a phenomenon, suggesting that \"distributional generalization\" might be too strong. It provides a detailed explanation of what the phenomenon represents, which helps the authors understand the context of the feedback. However, the comment does not explicitly mention which part of the paper discusses this phenomenon, making it weakly grounded. The authors can infer that it relates to the discussion of the phenomenon, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe a phenomenon. It provides a detailed explanation of what the phenomenon represents, stating that it is the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero, which might not be the case. The comment is 4 as it offers a clear and logical explanation of the issue, but it could be strengthened by referencing specific examples or studies that support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the naming of a phenomenon, suggesting that \"distributional generalization\" might be too strong a term. It provides a detailed explanation of what the phenomenon represents, clarifying that it is the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero, which might not be the case. This feedback is clear and actionable, as it guides the authors to reconsider the terminology used in their paper. However, it could be more helpful if it suggested alternative terms or provided examples of similar phenomena. Overall, the comment is 4, as it offers valuable insight into a potential issue with the terminology, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a neutral stance, noting that the theoretical contribution is considered \"ok but not particularly strong\" and critiques it as a \"weak, unpractical bound.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might strengthen their theoretical contribution or address the concerns raised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical contribution of the paper, noting that it is considered \"ok but not particularly strong\" and critiques it as a \"weak, unpractical bound.\" However, it does not specify which part of the paper this critique pertains to, such as specific sections or results. The comment lacks detail on what aspects of the theoretical contribution are weak or unpractical, making it difficult for the authors to pinpoint the exact areas needing improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the theoretical contribution is \"ok but not particularly strong\" and critiques it as a \"weak, unpractical bound.\" The reviewer provides a logical reasoning by stating that the proof does not offer particular mathematical novelty. However, the comment lacks specific examples or references to existing results that support the claim, making it 3. The authors would need to further explore the existing literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a balanced perspective on the theoretical contribution of the paper, noting that it is considered \"ok but not particularly strong\" and critiques it as a \"weak, unpractical bound.\" While it identifies a potential weakness in the theoretical contribution, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The comment does not offer actionable feedback or detailed insights that would help the authors enhance their draft. As a result, the comment is 3, as it highlights an area for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the experimental evaluation, particularly in the ablation studies and the comparison on the CIFAR dataset. It explicitly states that the paper claims a distinction regarding the \"picking\" step, but this aspect is not ablated, and the comparison on CIFAR is not convincing. The reviewer also points out that the continual learning literature has extensive experiments on the CIFAR dataset and suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. While the comment provides clear guidance on what needs to be addressed, it lacks specific instructions on how to implement these changes, such as suggesting which aspects to ablate or how to replicate the setup from the DEN paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Experimental Evaluation 2.1. Ablations\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the claims regarding the \"picking\" step and the comparison on the CIFAR dataset, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the paper incorrectly states a distinction regarding the \"picking\" step, which is not ablated. It also criticizes the comparison on the CIFAR dataset, noting that it is not convincing and lacks a fair comparison to the DEN paper. The comment provides logical reasoning by pointing out the absence of ablation for the \"picking\" step and the lack of a fair comparison, which supports the claim. However, it could be more verifiable with specific references or examples from the literature to strengthen the argument. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two main areas: the experimental evaluation and the comparison on the CIFAR dataset. It points out that the paper claims a distinction regarding the \"picking\" step, but this aspect is not ablated, which is a critical oversight. Additionally, it critiques the comparison on the CIFAR dataset, noting that it is not convincing and lacks a fair comparison to the DEN paper. The comment suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. This feedback is clear and constructive, offering the authors specific areas to address and improve their experimental evaluation. However, it could be more helpful if it provided additional guidance on how to conduct the suggested comparisons or ablation studies. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a specific suggestion for improving the interpretation of a plot by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This is a clear and concrete action that the authors can take to enhance the clarity of their plot. The comment explicitly states the change, making it easy for the authors to understand and implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"above/below diagonal\" and \"45 degree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree\" to enhance the interpretability of the plot. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a nitpicking observation about the interpretation of a plot, suggesting that \"above/below diagonal\" is easier to understand than \"above/below 45 degree.\" The comment provides a specific suggestion for improvement but does not offer any supporting evidence, examples, or references to substantiate the claim. This makes the claim 3, as it lacks detailed justification or examples to fully substantiate the observation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the interpretation of a plot by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is clear and directly addresses a potential issue with the clarity of the plot\"s interpretation. By offering a concrete change, the comment empowers the authors to enhance the readability and understanding of their visualizations, making it 5 for improving the draft. Therefore, the comment deserves a score of 5, as it is detailed and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaning of the phrase \"is sufficient\" at lines L240 and L428. It suggests that the authors might want to clarify the intended meaning of this phrase, possibly indicating that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the phrase and provide a concrete suggestion on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, L240 and L428, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the meaning of the phrase \"is sufficient\" and suggesting that the authors might want to clarify it, possibly indicating that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the phrase \"is sufficient\" at specific lines in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"is sufficient\" at specific lines in the paper, suggesting that the authors might want to clarify its meaning. It implies that the phrase could be interpreted as indicating that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their text. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model offers any additional explanation for how nonlinear RNN models attain their solutions through optimization. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their explanation. The feedback is vague and lacks concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. The comment further questions the model\"s role as a prototype approximation to nonlinear RNN models and suggests that the work does not provide additional explanation for how these models attain their solutions through optimization. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model offers any additional explanation for how nonlinear RNN models attain their solutions through optimization. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the model does not provide further explanation. This lack of supporting evidence makes the claim 3, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model offers any additional explanation for how nonlinear RNN models attain their solutions through optimization. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and prompts the authors to clarify their claims. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between the PPG outputs and the offsets for keypoints in the upper part. It suggests that the network parts responsible for each part may not predict all the keypoints of the pose, which could be a concern. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their methodology. The action is implicit and vague, as it leaves the authors to infer that they need to clarify or address the relationship between the PPG outputs and the offsets for keypoints. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the PPG outputs and their relationship to the offsets for keypoints in the upper part. It explicitly mentions \"Eq.2 of the supplementary material,\" which provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment also specifies the issue by questioning how the network parts responsible for each part predict all the keypoints of the pose, given the relationship between the PPG outputs and the offsets. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between PPG outputs and the offsets for keypoints in the upper part. It questions how the network parts responsible for each part predict all the keypoints of the pose, given the relationship between the PPG outputs and the offsets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or address the issue. This makes the claim 1, as the authors are left without guidance on how to address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the relationship between PPG outputs and the offsets for keypoints in the upper part. It points out a potential issue with how the network parts responsible for each part predict all the keypoints of the pose, given the relationship between the PPG outputs and the offsets. This feedback is 3 as it identifies a potential area of confusion or inconsistency in the methodology. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include specific suggestions or examples of how to clarify or resolve the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as increasing the font size of legends and axis labels, and clarifying the numbering of propositions. It also suggests that captions and legend font should be larger in figures 2 and 3. These actions are concrete and direct, allowing the authors to know exactly what changes to make. The comment is 5 as it provides clear guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the legends and axis labels, and the numbering of propositions. It also specifies the issue with the font size in captions and legends for figures 2 and 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of factual observations and suggestions for improvement, such as the need for larger text in legends and axis labels, and the confusion between Proposition (1) and Equation 1. These are descriptive statements that do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It suggests that the font size of legends and axis labels should be larger, which is a clear and practical improvement that can enhance the readability of the paper. Additionally, it points out a potential confusion between Proposition (1) and Equation 1, which is a specific issue that the authors should address. The comment also mentions the need for larger captions and legend font in Figures 2 and 3, providing clear guidance on how to improve the visual presentation of the paper. This level of detail and specificity makes the comment 5, as it empowers the authors to make meaningful improvements to their draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison of their counterfactual experiments with Journey TRAK, specifically mentioning Figure 2 from 1 which demonstrates a larger effect of removing highscoring images. This feedback provides a clear and explicit action for the authors to take, which is to include this comparison in their draft. The comment also specifies what aspect of the comparison should be included, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the comparison of counterfactual experiments with Journey TRAK, particularly referencing Figure 2 from 1 to highlight the larger effect of removing highscoring images. This provides clear guidance on what aspect of the paper requires attention and improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a comparison of their counterfactual experiments with Journey TRAK, specifically referencing Figure 2 from 1. This claim is 3 as it provides a specific reference to a figure that demonstrates a larger effect of removing highscoring images according to Journey TRAK. However, the comment lacks detailed reasoning or explanation on why this comparison is necessary or how it would enhance the paper. The authors would need to infer the importance of this comparison themselves, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison of counterfactual experiments with Journey TRAK, particularly referencing Figure 2 from 1. This feedback is clear and offers a concrete way for the authors to enhance their work by incorporating a relevant comparison. By addressing this suggestion, the authors can provide a more comprehensive analysis and potentially strengthen their findings. However, the comment could be more helpful if it included additional context or explanation on why this comparison is important or how it would impact the results. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the placement of adaptive convolutions, noting that ACNNv3 performed worse than ACNNv2. It suggests that the placement of adaptive convolutions is important but lacks analysis or comments on this aspect. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific analysis or comments are needed. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further analysis on the placement of adaptive convolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the placement of adaptive convolutions, noting that ACNNv3 performed worse than ACNNv2. The comment suggests that there should be an analysis or comments on this aspect, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, as evidenced by the results in Table3 where ACNNv3 performed worse than ACNNv2. The claim is supported by specific data from the table, providing a clear basis for the assertion. However, the comment could be strengthened by offering a more detailed explanation of why the placement of adaptive convolutions is important and how it affects performance. Overall, the claim is 4 due to the supporting evidence in the table, but it could benefit from additional context or analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It highlights a discrepancy in the performance of ACNNv3 compared to ACNNv2, suggesting that the placement of adaptive convolutions is important. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it points out a gap in the analysis, it lacks actionable advice or detailed feedback, making it 3. The authors are given a direction to explore the importance of adaptive convolution placement but without clear steps on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tradeoff between computation time and information loss when using ancestral graphs instead of DAGs. It does not provide explicit instructions or suggestions for the authors to address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors uncertain about how to respond to the critique or what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the tradeoff between computation time and information loss when using ancestral graphs instead of DAGs, referencing a specific comparison with 10. However, it does not explicitly mention which part of the paper this comparison is made, making it weakly grounded. The comment is specific in detailing the tradeoff and questioning the information loss, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by using ancestral graphs, which results in less information compared to DAGs. The comment provides a logical reasoning by explaining the tradeoff between computation time and information loss. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the tradeoff between computation time and information loss when using ancestral graphs instead of DAGs. It raises a question about the information encoded in the ancestral graph compared to DAGs, which is a relevant point for understanding the limitations of the method. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important consideration, it does not provide specific steps or insights for the authors to enhance their work. Therefore, the comment is 3, as it offers some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, given confidence levels. However, it does not explicitly instruct the authors to include these results or provide specific guidance on how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should add these results and determine how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results for not returning NSF. However, it does not specify which part of the paper these theoretical discussions are in, making it weakly grounded. The comment is specific in suggesting the need for additional results related to sample complexity, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF. The reviewer provides a specific example, mentioning the expectation of such results given confidence levels. This reasoning is 3 as it offers a clear direction for improvement, but it lacks detailed justification or references to support the need for these additional results. The comment provides a logical basis for the suggestion but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the theoretical discussions of the paper, suggesting that it could benefit from additional results related to sample complexitytype outcomes for not returning NSF. The reviewer provides a specific example of what they might expect, such as sample complexitytype results given confidence levels, which offers a clear direction for the authors to enhance their theoretical framework. However, the comment could be more helpful if it included suggestions on how to incorporate these results or provided more detailed guidance on the potential benefits of doing so. Overall, the feedback is 3 as it points out a specific area for improvement and provides a clear example of what might be added, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the VAD ( voice activity detection) description in the paper, suggesting that the method simply discards TF bins with low magnitude, which could lead to division by zero. The reviewer questions whether this constitutes a VAD, as it seems more like a thresholding process. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their description. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their explanation of the VAD method. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the VAD description in the paper, specifically questioning the approach of discarding TF bins with a magnitude less than epsilon. It suggests that this action is more akin to a thresholding process rather than a VAD, which is typically used to detect speech presence over time, not frequency. The comment is fully grounded as it explicitly mentions the VAD description, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the VAD description and provides a rationale for why it might not be a VAD. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description in the paper is puzzling and suggests that the method simply discards TF bins with low magnitude, which could lead to division by zero. The reviewer argues that this approach is not a VAD but rather a thresholding process. The comment provides a logical reasoning by explaining the implications of discarding lowmagnitude bins and questioning the definition of VAD. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the VAD (voice activity detection) description in the paper. It points out that the method simply discards TF bins with low magnitude, which could lead to division by zero, and suggests that this is not a VAD but rather a thresholding process. The comment provides a clear and actionable critique, challenging the authors to reconsider their approach and clarify the definition of VAD. However, it could be more helpful if it offered suggestions on how to address this issue or alternative methods for VAD that avoid the division by zero problem. Overall, the comment is 4 as it prompts the authors to revisit and clarify their VAD description, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the discussion should include a brief discussion on the empirical motivation for a timevarying Q^t and S_t, as opposed to a fixed one. It also asks for an explanation of the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. While the comment provides a clear direction for the authors to include additional content, it does not specify exactly what should be included or how to present it. The action is explicit but somewhat vague, as it lacks detailed guidance on what specific aspects to address. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for a timevarying Q^t and S_t, as opposed to a fixed one, and asks for an explanation of the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. However, it does not specify which part of the discussion this should be included in, making it weakly grounded. The comment is specific in its request for additional content and analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a brief discussion on the empirical motivation for a timevarying Q^t and S_t, as opposed to a fixed one, and asks for an explanation of the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. While the comment provides a logical request for additional analysis, it lacks specific examples or references to support the claim that this discussion would be beneficial. The authors would need to infer the importance of this suggestion themselves, making the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q^t and S_t, as opposed to a fixed one, and asks for an explanation of the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. This feedback is clear and actionable, as it provides a specific area for the authors to expand upon in their discussion. By addressing this suggestion, the authors can enhance the depth and relevance of their analysis, making the paper more comprehensive and informative. However, the comment could be more helpful if it included examples or further guidance on how to present this discussion. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer also mentions that in RetinaNet, there is only a oneshot regression, and in ATSS, the regression methods do not significantly influence the results. The reviewer suggests that the method of directly regressing w, h to the center point is sufficient, while RepPoints regresses distance to the location of feature maps. The reviewer concludes that there is no obvious difference between the two methods and hopes the authors can clarify this issue. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how to address the issue or what specific changes should be made to clarify the definitions. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions in Table 1. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions, questioning the differences between anchorbased regression and the regression in RepPoints, and mentions the lack of a clear distinction between these methods. The reviewer also provides additional context by discussing the regression methods in RetinaNet and ATSS, which helps the authors understand the context of the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides some context by mentioning RetinaNet, which uses only oneshot regression, and notes that ATSS has shown that regression methods do not significantly influence results. The reviewer suggests that the method of directly regressing w, h to the center point is sufficient, while RepPoints regresses distance to feature maps. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that there is no obvious difference between the two methods. While the reviewer provides some context, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides context by mentioning RetinaNet, which uses only oneshot regression, and notes that ATSS has shown that regression methods do not significantly influence results. The reviewer suggests that the method of directly regressing w, h to the center point is sufficient, while RepPoints regresses distance to the location of feature maps. The reviewer concludes that there is no obvious difference between the two methods and hopes the authors can clarify this issue. While the comment highlights a potential area of confusion, it lacks specific suggestions or detailed guidance on how the authors might address this issue. The feedback is 3 as it points out a potential weakness in the paper, but it could be more actionable with additional guidance on how to clarify the definitions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not easy to follow and that the presentation lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to. However, the comment does not provide specific guidance on how to improve the clarity or intuition of the presentation or the experiments. Without explicit suggestions or concrete steps for enhancement, the authors are left without a clear understanding of what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the paper\"s difficulty in following and the lack of intuition in the presentation. However, it does not specify which sections or parts of the paper are difficult to follow or where the intuition is lacking. Without explicit references to specific sections, tables, or figures, the authors cannot confidently determine which parts need improvement. Additionally, the comment does not provide specific suggestions for how to enhance the clarity or intuition of the presentation. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not particularly easy to follow and that the presentation lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what is unclear or how the pieces fit together, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s presentation, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. This feedback highlights a critical area for improvement, as clarity is essential for readers to understand the paper\"s contributions and arguments. However, the comment does not provide specific suggestions or guidance on how to enhance the clarity or intuition of the presentation. While it points out a problem, it lacks actionable advice, making it 3. The authors would need to infer what changes to make, but the feedback is incomplete in terms of providing detailed guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the performance of the teacher network might be improved by training them simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics to assess the fairness of the comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include specific metrics and determine how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training of student and refinement networks simultaneously and its potential impact on the teacher network\"s performance. It raises a question about the fairness of the comparison and requests the inclusion of KID/FID metrics for the teacher network. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for KID/FID metrics, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously might improve the teacher network\"s performance. It requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the comparison might be unfair or how the inclusion of KID/FID metrics would address this concern. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously might improve the teacher network\"s performance. It requests the inclusion of KID/FID metrics for the teacher network to assess the fairness of the comparison. While the comment identifies a potential issue with the methodology and provides a specific request for additional metrics, it lacks detailed guidance on how to address the fairness concern or how to incorporate the KID/FID metrics effectively. The feedback is 3 as it points out a potential area for improvement and provides a clear direction for the authors to consider, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the refined region vector, suggesting that it scales the most important regions by a factor of two before global pooling. The reviewer questions whether having a scaling variable before the attention weight would be beneficial. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of scaling the vector. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effect of scaling the refined region vector and whether a scaling variable before the attention weight would be beneficial. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether scaling the vector by a factor of two before global pooling would be beneficial. The comment provides a logical reasoning by explaining the current method and suggesting a potential improvement. However, it lacks specific examples or references to support the claim that scaling the vector would be beneficial. This makes the claim 3, as the authors would need to further explore and justify the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific question regarding the refined region vector, suggesting that it scales the most important regions by a factor of two before global pooling. It also questions whether having a scaling variable before the attention weight would be beneficial. This feedback is actionable as it prompts the authors to consider an alternative approach to scaling the vector, potentially leading to improvements in the methodology. However, the comment could be more helpful if it provided additional context or suggested specific ways to explore this idea. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue related to goal misspecification, particularly in the context of the ALFRED benchmark. It points out that the LLM often fails to accurately recover the formal goal predicate, especially when dealing with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could follow to improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification, particularly in the context of the ALFRED benchmark. It highlights failures that occur due to the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not specify which part of the paper discusses the ALFRED benchmark or the goal misspecification, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and its impact on the ALFRED benchmark. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, specifically the LLM\"s inability to accurately recover the formal goal predicate, especially in ambiguous human language. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification, particularly in the context of the ALFRED benchmark. It highlights that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions. The authors are informed of a problem but are not provided with specific guidance on how to address it or what changes could be made to mitigate the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV compared to other baselines. This implies that the authors should conduct a specific analysis to determine why the effect is not significantly improved on IGEV. Second, the reviewer questions whether it is difficult for SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear action for the first concern\u2014analyzing disparities and comparing with baselines\u2014it does not explicitly instruct the authors to address the second concern. The second concern is more of a suggestion for further exploration rather than a direct action. Therefore, the comment is 4, as it provides a clear action for one part of the issue but leaves the second part somewhat vague.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with SOTA methods like IGEV, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by questioning the improvement over these methods and suggesting an analysis of disparities. Additionally, it raises a concern about the difficulty of significantly improving iterative frameworks similar to IGEV, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the improvement of the method over SOTA methods like IGEV being small, suggesting that there might not be a multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine the reason for the lack of significant improvement. However, the comment lacks specific examples or references to support the claim about the distribution problem or the suggestion to analyze disparities. This makes the claim 3, as it provides a direction for further investigation but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the improvement of the method over SOTA methods like IGEV, questioning whether the improvement is small and suggesting that there might not be a multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a specific suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine the reason for the lack of significant improvement. This feedback is clear and actionable, offering a concrete way for the authors to address the issue and potentially improve their draft. However, the comment could be more helpful if it included additional suggestions or considerations for further analysis. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should conduct a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a concrete example by mentioning the differences in false positive rates (FPR) between models with and without ReGuide, indicating that this information should be presented for a better comparison. The comment is explicit in its request for additional analysis and provides a specific example of what should be included. This level of detail gives the authors clear guidance on how to enhance their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on modelspecific insights and suggests a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example by mentioning the differences in false positive rates (FPR) between models with and without ReGuide, which helps the authors understand what aspect of the analysis needs further exploration. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the paper should conduct a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on differences in false positive rates (FPR). While the comment provides a specific example of what should be included, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion is based on logical reasoning but could be strengthened with more comprehensive analysis or references to support the need for this investigation. Therefore, the comment is 3, as it provides a direction for improvement but lacks full justification.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending a deeper investigation into how specific models behave differently when ReGuide is applied. It highlights the importance of examining differences in false positive rates (FPR) between models with and without ReGuide, which could add nuance to the conclusions. This feedback is clear and constructive, offering a concrete way for the authors to enhance the depth and relevance of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct this investigation or presented examples of how to analyze the data. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are represented as real or complex numbers. This is an explicit action, as it directly instructs the authors to provide a clarification. However, the comment does not specify how to implement this clarification, such as suggesting a particular way to present the information or examples to include. While the action is clear, the lack of detailed guidance on how to execute it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the topic of \"Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely whether these modes are represented as real or complex numbers. This provides clear guidance on what aspect of the paper requires further explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are represented as real or complex numbers. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment about the paper\"s content. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by asking the authors to clarify whether the Fourier modes are represented as real or complex numbers. This feedback is clear and directly addresses a potential ambiguity in the paper, helping the authors improve the clarity and precision of their work. However, the comment could be more helpful if it offered additional guidance on how to present this clarification or why it is important. Despite this, the feedback is 4 as it directs the authors toward a specific area for improvement, making it a 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. While the comment implies that additional comparisons or analyses are needed, it does not specify what additional comparisons should be made or how they should be conducted. The action is implicit and somewhat vague, as the authors can infer that more comparisons are needed but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this comparison is made, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in suggesting that more comparisons are needed, but without clear grounding, it is not fully actionable. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it could be improved. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what additional comparisons or analyses are needed. The comment highlights a gap in the paper but does not offer actionable steps for the authors to take to address this issue. As a result, the feedback is 3, as it points out a potential area for enhancement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a missing component in the results, specifically the lack of ablation studies to determine the performance gain from the task formulation versus pretrained language models. It suggests including results using the GCPG model without pretrained initializations as a way to address this issue. The comment provides a clear and direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the ablation studies to determine the performance gain from the task formulation versus pretrained language models, and suggests including results using the GCPG model without pretrained initializations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are unclear in terms of performance gain due to the task formulation versus pretrained language models. It suggests including ablation studies to address this issue. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the problem or how to address it. The suggestion to include results using the GCPG model without pretrained initializations is logical but lacks detailed justification or evidence. Therefore, the comment is 3, as it provides a direction for improvement but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the lack of ablation studies to determine the performance gain from the task formulation versus pretrained language models. It suggests including results using the GCPG model without pretrained initializations as a way to address this issue. This feedback is clear and actionable, providing the authors with a specific direction to enhance the comprehensiveness and clarity of their results. However, the comment could be more helpful if it included additional suggestions or examples of how to conduct these ablation studies. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. While it identifies a specific issue, it does not provide explicit guidance on how the authors should clarify this point. The action is implicit, as the authors can infer that they need to provide a clearer explanation of the axes, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding what the axes are for Figure 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This is a clear and actionable piece of feedback that can help the authors improve the clarity and interpretability of their figure. By addressing this issue, the authors can enhance the overall understanding of their results, making the paper more accessible to readers. However, the comment could be more helpful if it provided suggestions on how to clarify the axes or improve the figure\"s presentation. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results on ImageNet to make the proposed method more convincing. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which specific results should be included or how they would demonstrate the method\"s effectiveness. The authors know they need to add results on ImageNet, but the comment does not provide guidance on how to do so effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results on ImageNet to strengthen the proposed method\"s credibility. However, it does not specify which part of the paper should include these results or where in the paper the results are currently presented. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide guidance on how to present or analyze the results on ImageNet, further limiting its usefulness. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results on ImageNet could make the proposed method more convincing. However, it does not provide any specific reasoning, examples, or references to support why ImageNet results would be particularly convincing. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to incorporate these results or what specific aspects of the method should be demonstrated. The comment offers a general direction for enhancement but does not fully support the authors in making a concrete decision on how to improve their draft. Therefore, the comment is 3, as it provides a starting point for the authors to consider but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, suggesting that they should be included to demonstrate the efficiency of the proposed approach. The comment provides a clear and direct action for the authors to take, which is to conduct these comparisons. However, it does not specify how to perform the comparisons or what specific metrics should be used, leaving some detail missing. Therefore, the comment is 4, as it provides a clear direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment highlights the absence of direct runtime comparisons with existing methods, suggesting that these comparisons are necessary to demonstrate the efficiency of the proposed approach. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in its suggestion to include direct runtime comparisons, but without clear guidance on where to place these comparisons, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The comment provides a logical reasoning by explaining that implicit differentiation typically requires additional computational costs, making direct comparisons important. However, the comment lacks specific examples or references to existing methods that could be compared, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. This is crucial for demonstrating the efficiency and practicality of the proposed approach. The comment provides a clear and actionable suggestion for the authors to include these comparisons, which would help them substantiate their claims and enhance the paper\"s credibility. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what metrics to use. Overall, the feedback is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the proposed framework is a simple combination of metalearning and federated learning and claims that there are no technical contributions. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their framework. Without specific suggestions or actions, the authors are left without direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework as a simple combination of metalearning and federated learning and claims there are no technical contributions. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity regarding what aspects of the framework are lacking in terms of technical contribution. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning and that it lacks any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed framework, suggesting that it is a simple combination of metalearning and federated learning without any technical contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or enhance their framework. Without actionable feedback or detailed critique, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage such characteristics to improve model robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, implying that the authors should provide more insightful findings or possible solutions. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to address this issue or what specific insights or solutions are expected. The action is implicit and somewhat vague, as the authors need to infer that they should explore additional insights or solutions related to leveraging complementary characteristics for model robustness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the sufficiency of the contribution, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage such characteristics to improve model robustness. It suggests that the conclusion could be easily and intuitively obtained, implying that the authors should provide more insightful findings or possible solutions. However, the comment does not specify which part of the paper discusses the connection between complementary and robustness, making it weakly grounded. The comment is specific in its critique of the lack of further studies on leveraging complementary characteristics for model robustness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern that the contribution of the paper is insufficient, specifically noting that the authors studied the connection between complementary and model robustness but did not explore how to leverage such characteristics to improve model robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, implying that the authors should provide more insightful findings or possible solutions. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or that the conclusion is easily obtainable. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the sufficiency of the paper\"s contribution, specifically noting that while the authors explored the connection between complementary and model robustness, they did not delve into how to leverage such characteristics to improve model robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, implying that the authors should provide more insightful findings or possible solutions. This feedback is 3 as it highlights a critical area for improvement and encourages the authors to expand their analysis. However, it could be more helpful if it provided specific suggestions or examples on how to address this gap. Overall, the comment prompts the authors to enhance their work by exploring additional insights or solutions, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct the caption for Figure 7, specifying that it should be \"Edge Dynamics\" instead of \"Node Dynamics.\" This is a clear and direct action, providing the authors with a specific task to perform. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect caption for Figure 7, and provides a clear correction (\"Edge Dynamics\" instead of \"Node Dynamics\"). Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction regarding the caption of Figure 7, stating that it should be \"Edge Dynamics\" instead of \"Node Dynamics.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it clearly identifies an error in the caption of Figure 7, specifying that it should be \"Edge Dynamics\" instead of \"Node Dynamics.\" This feedback provides the authors with a direct and precise correction to make, which is essential for improving the accuracy and clarity of their manuscript. By addressing this issue, the authors can enhance the professionalism and correctness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include case studies and error studies to better highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the value of such studies. While the comment explicitly suggests the inclusion of case studies, it does not provide detailed guidance on how to conduct these studies or what specific aspects should be emphasized. The action is clear but somewhat vague, as it lacks concrete instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation,\" which helps the authors understand the specific aspect being addressed. However, the comment does not explicitly mention a specific section of the paper where these case studies should be included, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that including case studies and error studies would strengthen the paper by highlighting the effectiveness of each proposed component. The reviewer provides an example of a case study from \"Graph pretraining for AMR parsing and generation,\" which supports the suggestion. However, the comment lacks detailed reasoning or examples of how these case studies would specifically enhance the paper\"s effectiveness. While the example is helpful, the overall claim is 3 due to the need for more detailed justification or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a constructive suggestion by recommending the inclusion of case studies and error studies to better highlight the effectiveness of each proposed component. It acknowledges the mention of the Elementlevel Graph Pretraining but emphasizes the need for additional evidence to support the claims. The comment is specific in its suggestion and provides a concrete example of a case study, which can guide the authors in enhancing their draft. However, it could be more helpful if it offered additional guidance on how to design or execute these case studies. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already be considered explicitness (E) and size (S). It provides examples of how these factors might influence the evaluation of disentanglement (D) and proposes that the reviewer needs clarification on the motivation for considering these aspects as extra evaluation. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without clear direction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides specific examples, such as the need for a fixed capacity of probing and latent size, and discusses the entanglement between DCI and ES. However, it does not explicitly mention which part of the paper this discussion pertains to, making it weakly grounded. The comment is specific in detailing the issues with the traditional DCI framework and the need for clarification on the motivation for considering explicitness and size as extra evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that it may already be considered explicitness (E) and size (S). The reviewer provides examples of how these factors might influence the evaluation of disentanglement (D) and proposes that the latent size should also be fixed. The comment further discusses the entanglement between DCI and ES, suggesting that changes in probing capacity or latent size could affect DCI evaluation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore and clarify these points to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the traditional DCI framework, suggesting that it may already be considered explicitness (E) and size (S). It provides specific examples, such as the need for a fixed capacity of probing and latent size, and discusses the entanglement between DCI and ES. The comment highlights the need for clarification on the motivation for considering these aspects as extra evaluation. While the comment identifies a potential issue with the traditional DCI framework, it lacks actionable suggestions or detailed guidance on how the authors might address these concerns. The feedback is 3 as it points out a potential weakness but does not provide a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be addressed in the experimental section. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of not providing standard deviation after multiple experiments and suggests clarifying which effects are within the range of standard deviation fluctuations versus those improved by the SoRA method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement brought by SoRA compared to the baseline is limited due to random fluctuations. However, it does not provide specific data or examples to support this claim, such as standard deviation values or comparisons with baseline results. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the absence of standard deviation after multiple experiments. It also points out that the improvement attributed to SoRA compared to the baseline may be due to random fluctuations. The comment suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements brought by the SoRA method. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by ensuring clarity and precision in their experimental results. Therefore, the comment is 4, as it offers specific guidance for enhancing the clarity and robustness of the experimental findings."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the organization and layout of the paper, such as the font size of annotations in Figure 1 and Figure 2, the lack of explicit drawing of these figures, the incorrect placement of Table 2 within a paragraph, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to correct the font size, redraw the figures, adjust the placement of Table 2, and fix the formatting of the top lines. However, the comment lacks concrete guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure1\" and \"Figure2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the layout, such as the small font size of annotations, the lack of explicit drawing of the figures, the incorrect placement of Table 2, and the incorrect format of the top lines on page 6. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed. It provides specific examples of issues, such as the small font size of annotations in Figure1 and Figure2, the lack of explicit drawing of these figures, the incorrect placement of Table 2, and the incorrect format of the top lines on page 6. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar issues in other papers. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several issues with the organization and layout of the paper, such as the small font size of annotations in Figure1 and Figure2, the lack of explicit drawing of these figures, the incorrect placement of Table 2, and the incorrect format of the top lines on page 6. While the comment highlights these specific problems, it does not provide detailed guidance or suggestions on how to address them. The authors are left to infer that they need to make changes to improve the layout and organization, but without explicit instructions, the feedback is 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the types of interventions included in the paper, while reasonable computationally, should also be considered for their practicality and safety in realworld querying. However, it does not provide explicit guidance on how to evaluate or improve the practicality and safety of these interventions. The action is implicit, as the authors can infer that they need to assess the practicality and safety of the interventions, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the types of interventions included in the paper, suggesting that they should be considered for their practicality and safety in realworld querying. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to evaluate the practicality and safety of the interventions, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the types of interventions included in the paper, while reasonable computationally, should also be considered for their practicality and safety in realworld querying. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important point about the practicality and safety of the interventions included in the paper, despite their computational reasonableness. It suggests that the authors should consider whether these interventions are feasible and safe for realworld querying. However, the comment lacks specific guidance or suggestions on how to evaluate or improve the practicality and safety of the interventions. While it identifies a relevant area for improvement, it does not provide actionable feedback or detailed advice, making it 3. The authors would gain some insight into the importance of considering realworld applicability but may need further guidance to address the comment effectively."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the clarity and precision of the paper. It questions the meaning of \"upper faces\" of the convex hull and suggests that the dual subdivision and projection \u03c0 need to be better explained. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment implies that the authors should clarify these points to improve the paper\"s clarity and readability. While the actions are explicit, the comment lacks concrete guidance on how to address the undefined variable or how to better explain the concepts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several specific issues regarding the clarity and precision of the paper. It questions the meaning of \"upper faces\" of the convex hull and suggests that the dual subdivision and projection \u03c0 need to be better explained. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the sections discussing the convex hull and the use of \"p.\" The comment is specific in detailing what needs to be clarified or defined, making it weakly grounded but specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the clarity and precision of the paper. It questions the meaning of \"upper faces\" of the convex hull and suggests that the dual subdivision and projection \u03c0 need to be better explained. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. While the comment identifies specific areas of confusion, it lacks detailed reasoning or references to support these claims. The authors would need to infer the issues and address them, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved. It questions the clarity of the term \"upper faces\" of the convex hull and suggests that the dual subdivision and projection \u03c0 need to be better explained. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic given its extensive use throughout the paper. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is 3 as it directs the authors to areas needing clarification, but it could be more actionable with additional guidance on how to improve the explanations or definitions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a lack of conviction in the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the draft to align with the reviewer\"s perspective. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction in the idea that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, it does not specify which part of the paper this concern pertains to, such as a particular section, figure, or discussion. Without explicit references to the paper\"s content, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the treatment of images and their augmentations need to be reconsidered. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal opinion that the reviewer is not convinced of the idea that images and their augmentations should be treated separately. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the reviewer\"s belief that images and their augmentations should be treated separately, suggesting that they can be interchangeable. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. It does not offer actionable feedback or suggestions for the authors to address this concern, making it difficult for them to understand the basis of the reviewer\"s concern and how to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method on baseline detection or parsing techniques separately to better support the claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional evaluations. The comment also specifies what needs to be done, making it concrete. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: the generative shape model and the word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The suggestion to evaluate the proposed approach on baseline detection or parsing techniques separately is a specific recommendation for improvement. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method, consisting of two major components, does not clearly specify which component contributes to the performance gain. The reviewer suggests that evaluating the approach on baseline detection or parsing techniques separately would better support the claim. This reasoning is logical and provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that the authors should evaluate their approach on baseline detection or parsing techniques separately to better support their claim. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and robustness of their work. By addressing this suggestion, the authors can enhance the credibility and impact of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. While the comment implies that the authors should consider removing or reconsidering the manual disentangling, it does not provide explicit guidance on how to implement this change or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the manual disentangling process in the paper, particularly questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were entirely learned rather than manually performed. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in its critique of the manual disentangling process and suggests an alternative approach, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment lacks specific examples or detailed reasoning to support the claim that manual disentangling is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically the manual disentangling process. It questions the rationale behind choosing the semantic segmentation network as the first module in the pipeline and suggests that the paper would be more interesting if the disentangling were entirely learned. This feedback is 3 as it prompts the authors to reconsider their approach and potentially explore a more automated method. However, the comment could be more actionable by providing specific suggestions or examples of how to implement a learned disentangling process. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve the connection between the theoretical analysis and the method. The feedback is vague and lacks concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis of the proposed method, specifically questioning the connection between the PACBayesian bound for GNNs in the transductive setting and the proposed method. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in identifying the lack of a strong connection between the theoretical analysis and the proposed method, particularly regarding how the method enhances generalization for distant nodes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the connection between the theoretical analysis and the proposed method, specifically regarding how the proposed method enhances generalization for distant nodes. The reviewer provides a logical reasoning by pointing out that the method merely adopts the selfattention mechanism from transformers and applies it to graphs, without a clear explanation of its enhancement in generalization. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to further develop the explanation to fully understand the critique, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It highlights the lack of a clear connection between the theoretical analysis and the method, which is a critical area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the connection between the theoretical analysis and the proposed method. While it points out an important area for improvement, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or experiments to clarify the method\"s behavior. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in identifying the issue, it is 1 because it does not provide enough context or detail to guide the authors in addressing it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the understanding and reproducibility of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some pieces, such as equation (12), are using existing methods and that their presentation is vague, requiring the authors to check the original paper to understand them. While the comment identifies a specific issue with the presentation, it does not provide explicit guidance on how the authors should improve the clarity or presentation of these methods. The action is implicit, as the authors need to infer that they should clarify the presentation of these methods, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the presentation of these methods is vague and requires checking the original paper to understand them. This provides clear guidance on what needs to be addressed in terms of clarity and presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some pieces, such as equation (12), are using existing methods and that their presentation is vague, requiring the authors to check the original paper to understand them. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed justification or references to similar issues in the paper, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of certain pieces, such as equation (12), noting that they are using existing methods and that their presentation is vague, requiring the authors to check the original paper to understand them. This feedback is 3 as it highlights a potential area for improvement in the clarity and presentation of the paper. However, the comment could be more actionable by providing specific suggestions on how to clarify the presentation or improve the understanding of these methods. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind the design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input to SADTW. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The comment lacks actionable details, such as recommending specific analyses or clarifications, making it difficult for the authors to know what steps to take to improve their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the questions the authors need to address, namely, the rationale behind having a separate timbre encoder module and the input to SADTW. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind specific design choices in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input to SADTW. While it identifies areas that need clarification, it does not provide actionable feedback or suggestions on how the authors might address these questions or improve their draft. The comment lacks depth and guidance, making it 3 as it points out potential areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Table 4 is incomplete and suggests that it should include results for all four datasets. This provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the table. The comment is specific and concrete, leaving no ambiguity about how the authors should proceed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of results for all four datasets. This provides clear guidance on what needs to be addressed to improve the completeness of the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Table 4 is incomplete\" and suggests that it should include results for all four datasets. However, the comment does not provide any reasoning or evidence to support why Table 4 is incomplete or why it should include results for all four datasets. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the completeness of Table 4, noting that it should include results for all four datasets. This feedback is clear and actionable, as it provides a direct suggestion for improvement that the authors can easily implement. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their presentation. However, the comment could be more helpful if it offered additional guidance on how to present or analyze the results for the missing datasets. Despite this, the feedback is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the writing or presentation is \"jumbled\" at times, but it does not provide any specific guidance or suggestions on how to improve this. The comment lacks explicit instructions or concrete details on what aspects of the writing are jumbled or how the authors might address this issue. Without actionable advice, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the writing or presentation is \"jumbled\" at times, but it does not specify which parts of the paper this issue is present in. Without explicit references to sections, figures, or specific examples, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing are jumbled or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled\" at times. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the writing or presentation is \"jumbled\" at times, but it does not provide specific details or suggestions on how to improve this aspect. Without actionable feedback or guidance, the authors are left without a clear understanding of what needs to be revised or how to enhance the clarity of their writing. This lack of specificity and constructive advice makes the comment unhelpful for the authors, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also suggests considering the impact on power demand if the Woodbury flow is used on a mobile device. While the comment implies that the authors should address these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare computational complexity and consider power demand implications. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions, and suggests considering the impact on power demand if the Woodbury flow is used on a mobile device. However, it does not specify which part of the paper this question pertains to, such as specific sections or experiments where computational complexity is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about computational complexity and power demand, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions, and suggests considering the impact on power demand if the Woodbury flow is used on a mobile device. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the computational complexity is a concern or that it could cause significant power demand. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also suggests considering the impact on power demand if the Woodbury flow is used on a mobile device. While the comment identifies an area for improvement, it lacks specific guidance or suggestions on how the authors might address these concerns or what comparisons or analyses could be conducted to provide a more comprehensive understanding. The feedback is 3 as it prompts the authors to consider important aspects of their work, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific claim made by the authors regarding the base IOI circuit and highlights a discrepancy with Section 3 of Wang et al., 2023. It provides a clear and direct action for the authors to address, which is to correct the claim in their paper. The comment also specifies what the authors need to do, namely, to align their statement with the findings in Wang et al., 2023. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the base IOI circuit and the specific claim regarding the Induction, Duplicate Token, and Previous Token heads attending to the S2 token. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the incorrect claim and provides a reference to Wang et al., 2023, which helps the authors understand what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the base IOI circuit is incorrect, citing Section 3 of Wang et al., 2023. The comment provides a specific reference to Wang et al., 2023, which allows the authors to verify the claim and understand the basis of the critique. This level of detail and reference makes the claim 5, as it provides a clear and robust justification for the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the base IOI circuit and highlights a discrepancy with Section 3 of Wang et al., 2023. It points out that the heads are \"active\" at the S2 token but do not primarily attend to it, which contradicts the authors\" statement. This feedback is clear and actionable, as it directs the authors to correct their claim to align with the findings in Wang et al., 2023. By providing a specific reference and a clear explanation, the comment offers valuable guidance for improving the accuracy and consistency of the paper. Therefore, it is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment claims that the contribution of the work is incremental and that the proposed pipeline is not particularly novel or impressive, merely a collection of tricks to improve defense evaluation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique, such as suggesting ways to enhance the novelty or effectiveness of their approach. Without actionable advice or specific suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty and impact of the work, suggesting that the proposed pipeline is not particularly innovative or impressive. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need revision. The comment lacks specificity regarding what aspects of the pipeline could be improved or made more novel. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly novel or impressive, merely a collection of tricks to improve defense evaluation. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of why the pipeline is considered incremental or lacking in novelty, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the novelty and impact of the work, suggesting that the proposed pipeline is not particularly innovative or impressive, merely a collection of tricks to improve defense evaluation. While this feedback highlights a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the scalability of the method, suggesting that a distributed version might be necessary to handle large datasets typical of realworld scenarios. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the method to improve its scalability. The comment implies that the authors should consider developing a distributed version, but it lacks concrete steps or suggestions on how to implement this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it may not be feasible unless a distributed version is developed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of scalability and the potential need for a distributed version, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable unless a distributed version is developed, and it questions the feasibility of a single instance holding all the training data from realworld datasets. While the comment raises a valid concern about scalability, it lacks specific examples or references to support the claim. The authors would need to infer the basis of the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the scalability of the method, suggesting that it may not be feasible unless a distributed version is developed. This is a relevant and actionable observation that could guide the authors in considering the scalability of their method. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending potential distributed algorithms or strategies to improve scalability. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the reason for the noncentral chisquared distribution of the eta_ri term. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or clarify the reasoning behind the distribution choice. Without any guidance or actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the noncentral chisquared distribution of the eta_ri term, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this issue is discussed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the distribution of the eta_ri term, specifically questioning why it is a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this distribution is noncentral chisquared. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distribution of the eta_ri term, specifically questioning why it is a noncentral chisquared distribution. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the reasoning behind the distribution choice. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer constructive advice for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit guidance for the authors, specifying that the text at L15 is too vague and suggesting that certain RNNs are effective for specific natural language reasoning tasks, with references to relevant literature. This is a clear and direct action for the authors to take. Additionally, the comment highlights that the reinforcement learning/agent analogy is outofplace and suggests that generalization capabilities should be better illustrated by the examples provided later in the paper. This feedback is concrete and provides specific instructions on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) and provides context by referencing the literature on natural language inference and the SNLI leaderboard. It also specifies the issue with the reinforcement learning/agent analogy, suggesting that it is outofplace and should be better integrated with examples later in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the text at L15 is too vague and suggests that certain RNNs are effective for specific natural language reasoning tasks, referencing the literature on natural language inference and the SNLI leaderboard. This claim is supported by providing specific references, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples from the referenced literature to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the draft, identifying areas where the text is too vague and suggesting improvements. It points out that certain RNNs are effective for specific natural language reasoning tasks, referencing relevant literature and a leaderboard on natural language inference. This is a valuable suggestion that can help the authors enhance the clarity and relevance of their work. Additionally, the comment highlights the outofplace reinforcement learning/agent analogy and suggests that generalization capabilities should be better illustrated by the examples provided later in the paper. This feedback is clear, actionable, and constructive, offering the authors a clear path for improvement. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of discussion on the proposed sensitivelayer selection against randomized selection in Figure 5 and the absence of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the observation further and include theoretical justification, but without specific instructions or examples, the actions remain vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by pointing out the lack of discussion on the proposed sensitivelayer selection against randomized selection and the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and lacks further discussion. It also states that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas that need attention, it does not provide detailed reasoning or examples to support these claims. The absence of specific evidence or references makes it challenging for the authors to fully understand and address the issues. Therefore, the comment is 3, as it provides a general direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and the authors do not further discuss this observation. This feedback highlights a gap in the analysis and suggests that the authors should provide more discussion or justification for this aspect. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm.1, indicating that the authors need to include such justification to strengthen their work. While the comment identifies important areas for improvement, it could be more helpful by offering specific suggestions or examples of how to address these issues. Overall, the feedback is 3 as it directs the authors to areas needing attention but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the structure of triples denoted as $(e_1, r, e_2)$ by showing their tuplelike structure instead of sets. This is a direct and concrete action that the authors can take to improve their draft. The comment provides clear guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the structure of triples denoted as $(e_1, r, e_2)$ and suggests that they should be shown as tuplelike structures instead of sets. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific change in the representation of triples denoted as $(e_1, r, e_2)$, recommending that they be shown as tuplelike structures instead of sets. However, the comment does not provide any reasoning or justification for why this change is necessary or beneficial. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that triples denoted as $(e_1, r, e_2)$ should be clearly shown as tuplelike structures instead of sets. This feedback is clear and directly instructs the authors on how to enhance the presentation of their work, making it 5. The comment offers a concrete step that the authors can take to improve the readability and understanding of their work, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of speed analysis in the experiments, specifically mentioning that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The reviewer suggests that the improvement on inference speed would be more interesting than reducing FLOPs. This feedback provides a clear and explicit action for the authors to take, which is to include a speed analysis comparing the proposed network with prior work. The comment also offers a concrete suggestion on what aspect of speed analysis would be more impactful, making the action clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that the improvement on inference speed would be more interesting than reducing FLOPs. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing and what could be improved, providing clear guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments lack a speed analysis, specifically mentioning the absence of comparisons of inference speed between the proposed network and prior work. The reviewer suggests that focusing on inference speed improvement would be more interesting than reducing FLOPs. However, the comment does not provide specific examples or references to support the claim that the current analysis is lacking or that the proposed focus is more interesting. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of speed analysis. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The reviewer suggests that focusing on inference speed improvement would be more interesting than reducing FLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis by including a speed analysis. However, the comment could be more helpful if it offered suggestions on how to conduct the speed analysis or provided examples of how to present the results effectively. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also mentions that the paper aims to speed up variational inference (VI) through fast convergence, which is essential for big data and big model settings. The reviewer points out that quantization is a bottleneck, making the method lose its point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the scalability issue or improve the method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also mentions that the paper aims to speed up variational inference (VI) through fast convergence, which is essential for big data and big model settings. The comment highlights that quantization is a bottleneck, making the method lose its point. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the scalability issue and its impact on the method, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, specifically mentioning that it is costly in terms of both the number of data points (N) and the dimensionality (M). The reviewer supports this claim by noting that the paper aims to speed up variational inference (VI) through fast convergence, which is essential for big data and big model settings. However, the comment lacks specific examples or references to substantiate the claim about the cost of quantization in terms of N and M. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also points out that the paper aims to speed up variational inference (VI) through fast convergence, which is essential for big data and big model settings. The comment highlights that quantization is a bottleneck, making the method lose its point. However, the comment lacks specific suggestions or actionable advice on how the authors might address this scalability issue or improve the method. While it identifies a significant problem, it does not provide guidance on how to overcome it, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should compare its methodology against existing methods, specifically mentioning contrastive decoding 34. It also notes that the notations issues need to be addressed. While the comment implies that the authors should conduct these comparisons and address the notation issues, it does not provide explicit instructions on how to perform these comparisons or what specific aspects of the notation need attention. The action is implicit and somewhat vague, as the authors can infer the need for comparison and notation correction but may struggle to determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should compare its methodology against existing methods, specifically mentioning contrastive decoding 34. It also notes that the notations issues need to be addressed. However, the comment does not specify which part of the paper should include these comparisons or how the notations are currently presented, making it weakly grounded. The authors can infer that it relates to the methodology and results sections, but this inference is not direct. The comment is specific in suggesting comparisons with existing methods and addressing notations, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should compare its methodology against existing methods, specifically mentioning contrastive decoding 34. However, the comment lacks specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper\"s contribution. Additionally, it does not provide references to the existing methods being compared, making it difficult for the authors to understand the basis of the suggestion. The mention of \"notations issues\" is vague and does not provide a clear explanation of what specific notation problems exist. As a result, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper should compare its methodology against existing methods, specifically mentioning contrastive decoding 34, and highlights the need to address notations issues. While it identifies a potential area for improvement by suggesting a comparison with existing methods, the comment lacks specific guidance on how to conduct this comparison or what aspects of the notations need attention. The feedback is 3 as it points out a potential weakness in the paper\"s methodology and suggests a way to enhance its contribution, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the algorithm\"s effectiveness and its reliance on the entire training dataset. It suggests that the authors consider how the algorithm should function when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness and problem of the algorithm, specifically mentioning the need for access to the entire training dataset. It suggests considering how the algorithm should operate effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment also expects further elucidation of the technical contribution rather than the form of the attack. While the comment does not explicitly mention specific sections or experiments, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed, such as the comprehensiveness of validation experiments and the analysis of time complexity and efficiency. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and its reliance on the entire training dataset. It questions whether the algorithm should function effectively when the training dataset is not fully perceptible. The reviewer also points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. Additionally, the reviewer expects further elucidation of the technical contribution rather than the form of the attack. While the comment raises valid concerns, it lacks specific examples or references to support the claims about the comprehensiveness of the validation experiments or the analysis of time complexity and efficiency. This makes the claims 3, as the authors would need to provide more detailed evidence to address the feedback effectively.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the algorithm\"s effectiveness is dependent on access to the entire training dataset, suggesting that the authors consider how the algorithm should function when the training dataset is not fully perceptible. Additionally, it critiques the comprehensiveness of the related validation experiments and the lack of analysis on the time complexity and efficiency of the algorithm. The comment also expects further elucidation of the technical contribution rather than the form of the attack. While the feedback highlights important areas for improvement, it lacks specific suggestions or detailed guidance on how to address these issues. This makes the comment 3, as it provides some direction for improvement but could be more comprehensive with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement that every kernel can be described by a feature space parameterized by a neural network, noting that this is not trivially true. It provides a specific example with RBF kernels and their RKHS being infinitedimensional, suggesting that neural networks can only represent finitedimensional RKHSs in practice. The comment implies that the authors should clarify this limitation in their paper. However, it does not explicitly instruct the authors to make this clarification or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point and may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about kernels being described by neural networks, providing a concrete example with RBF kernels and their RKHS being infinitedimensional. The comment suggests that the authors should clarify this limitation, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not trivially true, providing a specific example with RBF kernels and their RKHS being infinitedimensional. The reviewer supports this claim by explaining that neural networks can only represent finitedimensional RKHSs in practice. This reasoning is logical and provides a clear example to substantiate the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that discuss the limitations of neural networks in representing RKHSs, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement that every kernel can be described by a feature space parameterized by a neural network. It provides a concrete example with RBF kernels, explaining that their RKHS is infinitedimensional, which cannot be represented by neural networks in practice. This feedback is clear and actionable, as it highlights a potential misunderstanding or misrepresentation in the paper and suggests that the authors should clarify this point. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how to clarify the statement. Overall, the comment is 4, as it effectively guides the authors toward a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method is not wellpositioned in the literature and recommends a thorough literature review to identify additional works that use the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs. The comment provides specific examples of related works, such as the original denoising score matching objective and \"scoreinterpolation,\" which can guide the authors in their literature review. However, it does not explicitly instruct the authors to conduct this review or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a literature review and use the examples provided as a starting point. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed method is not wellpositioned in the literature and recommends a thorough literature review. It provides specific examples of related works, such as the original denoising score matching objective and \"scoreinterpolation,\" which can guide the authors in identifying additional relevant literature. However, the comment does not explicitly mention which part of the paper should be revised or improved, making it weakly grounded. The authors can infer that it relates to the introduction or literature review sections, but this inference is not direct. The comment is specific in suggesting that the authors should conduct a thorough literature review, but it lacks grounding in terms of which part of the paper should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is a wellknown concept. The reviewer supports this claim by referencing specific examples, such as the original denoising score matching objective and \"scoreinterpolation,\" which are used in related works. This provides a logical basis for the claim, as it references existing literature that employs the same concept. However, the comment could be strengthened by providing more references or a broader context of its use in the literature. Overall, the claim is 4, as it is supported by logical reasoning and specific examples, but it could be more robust with additional references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 4 as it identifies a gap in the literature positioning of the proposed method and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is a wellknown concept. By referencing specific examples from related works, such as the original denoising score matching objective and \"scoreinterpolation,\" the comment provides the authors with a clear direction for conducting a thorough literature review. This feedback is actionable and constructive, as it guides the authors to enhance the context and positioning of their work within the existing literature. However, the comment could be more helpful if it offered specific suggestions on how to conduct the literature review or highlighted additional relevant works. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically concerning the generation phase. It questions whether the benefits for inference are still present when only limited tokens are used to generate the next token. While the comment implies that the authors should investigate this aspect, it does not provide explicit guidance or suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of limited tokens on inference benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a specific question about the handling of autoregressive decoding in the linear attention mechanism, particularly concerning the generation phase. It questions whether the benefits for inference are still present when only limited tokens are used to generate the next token. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in its inquiry about the handling of autoregressive decoding and its impact on inference benefits. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically concerning the generation phase. It questions whether the benefits for inference are still present when only limited tokens are used to generate the next token. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or address the issue. This makes the claim 1, as the authors are left to interpret the question without additional context or justification. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the handling of autoregressive decoding in the linear attention mechanism, particularly concerning the generation phase. It questions whether the benefits for inference are still present when only limited tokens are used to generate the next token. This feedback is 3 as it identifies a potential area of concern in the methodology or results sections. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their draft. The comment could be more helpful if it offered specific recommendations or examples of how to investigate or mitigate the concern. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a key component, the matching metric, specifically the Pearson correlation coefficient (PCC), and questions the assumption that it is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer suggests that the constraint strength of a loss function should be evaluated based on its gradient distribution, providing an example of how KL divergence and MSE loss are compared. The comment implies that the authors should provide a gradient comparison between KL and PCC to address the issue. While the action is implicit, it is concrete and provides a clear direction for the authors to take, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the assumption that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The comment further provides a rationale by discussing the constraint strength of loss functions and suggests providing a gradient comparison between KL and PCC. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point questions the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the constraint strength of loss functions, such as KL divergence and MSE loss, based on their gradient distributions. This comparison is supported by a clear example, making the claim 4. However, the comment could be strengthened by including more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a key component, the matching metric, specifically the Pearson correlation coefficient (PCC), and questions the assumption that it is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the constraint strength of loss functions, such as KL divergence and MSE loss, based on their gradient distributions. This comparison is supported by an example, which suggests that the authors should provide a gradient comparison between KL and PCC to address the issue. The feedback is clear, actionable, and constructive, offering a specific suggestion for improvement that could enhance the paper\"s understanding and rigor. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It asks whether GPI with noise added could reproduce the data similarly well and suggests considering other measures, such as behavioral trajectories or time to goal, to assess the fit of GPI with behavioral data. Additionally, it suggests that the approach is suitable for modeling pattern separation tasks with available behavioral data and recommends including a discussion on this. While the comment provides several specific questions and suggestions, it does not explicitly instruct the authors to address these points in their draft. The actions are implicit and somewhat vague, as the authors need to infer that they should address these questions and suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of data with GPI and noise, suggesting additional measures to consider, such as behavioral trajectories or time to goal. Additionally, it recommends discussing the suitability of the approach for modeling pattern separation tasks with available behavioral data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of data with GPI and noise, suggesting that additional measures, such as behavioral trajectories or time to goal, could be considered. It also recommends discussing the suitability of the approach for modeling pattern separation tasks with available behavioral data. While the comment provides a logical reasoning for questioning the reproducibility and suggesting additional measures, it lacks specific examples or references to support the claim that these measures would be more effective. This makes the claim 3, as the authors would need to further explore and substantiate the suggestions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper\"s analysis and discussion. It questions the reproducibility of data with GPI and noise, suggesting that additional measures, such as behavioral trajectories or time to goal, could be considered to assess the fit of GPI with behavioral data. This feedback is valuable as it prompts the authors to explore alternative methods for evaluating the model\"s fit, potentially leading to a more comprehensive analysis. Additionally, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks with available behavioral data, which could provide further insights into the paper\"s relevance and applicability. While the comment is clear and actionable, it could be more helpful if it provided specific examples or guidance on how to implement these suggestions. Overall, the feedback is 4 as it directs the authors to areas for improvement and encourages a deeper exploration of their findings."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their proposed approach with a \"small learning rate for attention parameters\" benchmark. While the action is explicit, it lacks concrete details on how to implement this comparison or what specific aspects should be considered. The authors know they need to conduct this comparison, but they are not provided with specific guidance on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in suggesting a comparison, but without clear guidance on where to place this comparison, the authors may struggle to identify the exact section that needs revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the results. The lack of detailed explanation or examples makes it difficult for the authors to understand the significance of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark, which could provide valuable insights into the performance and effectiveness of the proposed method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. While it identifies a potential area for improvement, the feedback is vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential area for enhancement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the paper\"s approach to resolving a debate, specifically questioning why the distribution might have changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment implies that the authors should consider additional experiments or provide more detailed explanations, but it lacks concrete steps or examples for how to implement these suggestions. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106\" and \"L29,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the paper\"s approach to resolving a debate and asking why the distribution might have changed, as well as whether experiments have been conducted to disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the paper\"s approach to resolving a debate, specifically questioning why the distribution might have changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the paper\"s approach to resolving a debate, specifically questioning why the distribution might have changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. This feedback highlights a potential gap in the paper\"s analysis and prompts the authors to consider additional experiments or explanations to address this concern. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what specific changes should be made to the analysis. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the comparison of methods, suggesting that the use of AdamW with cosine learning rate for training the proposed method should be considered in the comparison. It also recommends reproducing the results using the same setting as the paper, noting that most recent methods have their code released. While the comment implies that the authors should adjust their comparison to include the same training parameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should adjust their comparison and reproduce results with the same setting. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of AdamW with cosine learning rate for training the proposed method and suggests that comparing methods should use the same setting. It also recommends reproducing results using the same setting as the paper, noting that most recent methods have their code released. However, the comment does not specify which part of the paper discusses the training methods or the comparison section, making it weakly grounded. The comment is specific in detailing the issue with the comparison and suggesting a better approach, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison of methods is unfair because the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce their results using the same setting. This claim is 3 as it highlights a potential inconsistency in the comparison methodology. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, specifically noting that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that this comparison is unfair and recommends reproducing their results using the same setting as the paper, noting that most recent methods have their code released. This feedback is clear and actionable, as it provides a specific suggestion for improving the fairness and comparability of the results. However, it could be more helpful if it included examples of how to adjust the comparison or detailed guidance on reproducing the results. Overall, the comment is 4, as it offers valuable insights and actionable advice for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might explore this aspect or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear understanding of what to do next. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the performance are being questioned or what additional information would be helpful. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might explore this aspect or what improvements could be made. The comment lacks actionable content and does not offer any insight into potential weaknesses or areas for improvement in the paper. As a result, it does not provide the authors with any meaningful feedback that could help them enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are \"terrible\" and lists specific issues, such as being too small, color distinctions, poor labeling of axes, and visually similar labels. It also mentions that these plots are the main presentation of the experimental results and that the clarity is substandard. The reviewer provides clear and concrete actions for the authors to take, such as improving the size, color differentiation, labeling, and visual clarity of the plots. This level of detail and specificity makes the comment 5, as the authors know exactly what needs to be addressed and how to do it. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and provides specific details about the issues with the presentation, such as the size, color differentiation, and labeling. It also mentions that these plots are the main presentation of the experimental results, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it details the exact issues with the plots, such as the difficulty in distinguishing colors (e.g., pink vs red) and the confusion caused by visually similar labels (sdropout(tr) vs edropout(tr)). This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" and lists specific issues, such as being too small, color differentiation problems, poor labeling of axes, and visually similar labels. These claims are supported by detailed descriptions of the problems, providing a clear rationale for the critique. However, the comment could be strengthened by referencing specific examples or studies where similar issues have been addressed, which would further substantiate the claim. Overall, the comment is 4, as it provides a logical basis for the critique but could benefit from additional evidence or references.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the presentation of the experimental results. It identifies several issues with the plots, such as their size, color differentiation, and labeling, which are critical for clarity and understanding. By addressing these issues, the authors can significantly improve the clarity and effectiveness of their presentation. The comment also highlights the importance of these plots as the main presentation of the experimental results, emphasizing the need for clarity. This detailed feedback offers clear guidance on how to enhance the visual presentation of the data, making it highly beneficial for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance gains are not very high, with most metrics showing a small difference between the baseline and the best approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a specific observation about the performance gains, noting that they are not very high and that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not specify which part of the paper this observation pertains to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact location in the paper where this issue is discussed. While the comment is specific in its content, it lacks grounding because it does not provide enough context or reference to help the authors identify the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most metrics showing a small difference between the baseline and the best approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any data, analysis, or references to substantiate the assertion that the performance gains are minimal. Without this additional information, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the performance gains are not very high, with most metrics showing a small difference between the baseline and the best approach. This observation highlights a potential limitation in the study, suggesting that the improvements are modest. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed recommendations, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of certain information on the feedback network, specifically regarding the inclusion of incorrect phrase/(corrected phrase) and the type of mistake. It also asks for performance comparisons with and without these information types. While the comment poses a question, it does not provide explicit instructions or suggestions for the authors to address it. The action is implicit, as the authors can infer that they need to conduct experiments or analyses to determine the impact of these information types. However, the comment lacks concrete guidance on how to perform these analyses or what specific results to expect. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the impact of certain information on the feedback network, specifically regarding the inclusion of incorrect phrase/(corrected phrase) and the type of mistake. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in asking for performance comparisons with and without these information types, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the impact of certain information on the feedback network. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the feedback network, specifically regarding the inclusion of incorrect phrase/(corrected phrase) and the type of mistake. It also asks for performance comparisons with and without these information types. While the comment identifies an area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. The question prompts the authors to consider the importance of these information types but does not provide detailed feedback or examples to help them improve their draft. Therefore, the comment is 3, as it highlights a potential area for enhancement but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of standard deviations in Table 1 and suggests that the submission would be stronger if the experiments were more extensive. However, it does not provide specific guidance on how to address these issues or what additional experiments should be conducted. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and 1.", "grounding_specificity_rationale": "The comment mentions \"Table 1\" and suggests that the submission would be stronger if the experiments were more extensive. However, it does not specify which part of Table 1 lacks standard deviations or what specific aspects of the experiments could be improved. The authors can infer that the comment relates to Table 1, but the lack of detailed guidance on what needs to be addressed makes the comment weakly grounded. It is also not specific about the issues with the experiments or how they could be enhanced. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that Table 1 lacks standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment does not provide specific examples or references to support the claim about the absence of standard deviations or the need for more extensive experiments. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the critique without further explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting the absence of standard deviations. It suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks depth and does not provide specific guidance on how to address the issue of missing standard deviations or what additional experiments could be conducted to enhance the submission. While it points out a potential weakness, it does not offer actionable advice or detailed suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether the performance improvement is still present when using a better Unary baseline. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider this question, but it lacks concrete steps or actions to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance boost due to additional parameters, particularly questioning whether the performance improvement is still present when using a better Unary baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether the performance improvement is still present when using a better Unary baseline. The comment references specific tables (Tab 1,2,3) and a comparison with a different neural network used in 14. This provides a basis for the claim, as it highlights a potential inconsistency in the results. However, the comment could be strengthened by providing more detailed analysis or examples to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether the performance improvement is still present when using a better Unary baseline. It references specific tables and a comparison with a different neural network used in 14, which provides a basis for the claim. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, it does not provide enough detail to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several actions for improving the paper. It recommends restructuring the sections to follow a logical flow from introduction to method to experiments, which is a clear and explicit action. Additionally, it advises focusing more on the IEM in Figure 3, which is considered the main figure, and improving the visualization of Figures 7 and another unspecified figure. While the comment provides specific suggestions for restructuring and improving visualizations, it does not offer detailed guidance on how to implement these changes. Therefore, the actions are explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment suggests restructuring the paper to follow a logical flow from introduction to method to experiments, which is a specific suggestion for improving the paper\"s structure. It also recommends focusing more on the IEM in Figure 3, which is considered the main figure, and improving the visualization of Figures 7 and another unspecified figure. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the introduction, method, and results sections. The suggestion to improve the structure and focus on specific figures is specific but lacks detailed guidance on how to achieve these improvements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to follow and recommends restructuring the sections to improve readability. It also advises focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and another unspecified figure. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to support the claim that restructuring would significantly enhance readability. The suggestion to focus on specific figures is 3, as it provides a direction for improvement but lacks detailed justification. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper\"s structure and readability. It recommends restructuring the sections to follow a logical flow from introduction to method to experiments, which can help readers better understand the paper\"s content. Additionally, it highlights the importance of focusing on the IEM in Figure 3, which is considered the main figure, and suggests improving the visualization of Figures 7 and another unspecified figure. While the comment identifies areas for improvement, it could be more helpful by providing specific examples or guidance on how to enhance the structure or visualizations. Overall, the feedback is 4 as it offers actionable suggestions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not only by describing the related works but also by discussing the differences to the presented work. This feedback provides a clear and explicit action for the authors to take, which is to expand the discussion on related work. The comment also specifies what needs to be done\u2014discussing the differences to the presented work\u2014making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, specifically mentioning the need to not only describe related works but also discuss their differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a discussion of related work and differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, not only by describing the related works but also by discussing their differences to the presented work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it effectively. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of this suggestion without explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not only by describing the related works but also by discussing their differences to the presented work. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the depth and relevance of their discussion on related work. By addressing this suggestion, the authors can improve the comprehensiveness and impact of their paper. However, the comment could be more helpful if it included examples or specific areas where the related work discussion could be expanded. Overall, the comment is 4, as it offers a clear path for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include other architectures and classification tasks beyond the current scope of neural networks and image classification. While the comment implies that the authors should consider additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct further experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include other architectures and classification tasks beyond the current scope of neural networks and image classification. However, it does not specify which other architectures or tasks should be considered, nor does it provide guidance on how to implement this suggestion. The authors can infer that the comment relates to the experimental section, but they cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be expanded, but it lacks grounding as it does not pinpoint the exact section or task. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond the current scope of neural networks and image classification. However, the comment does not provide any specific reasoning, examples, or references to support why this expansion would be beneficial or necessary. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include other architectures and classification tasks beyond the current scope of neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement, indicating that the authors could consider a broader range of tasks to enhance the comprehensiveness of their study. However, the comment lacks specific guidance or examples on which other architectures or tasks should be included, making it less actionable. The authors are left with a general direction but without detailed instructions on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a concern about the authors\" claim that a transformer without locality bias is the best option. It questions the validity of this claim, suggesting that due to the limited speed of information propagation, local interactions between nodes are more significant than distant ones. The reviewer explicitly asks the authors to explain why the lack of locality in the transformer does not pose a concern. This request for clarification provides a clear and direct action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment raises a concern about the authors\" claim regarding the transformer being free of locality bias. It questions the validity of this claim, suggesting that due to the limited speed of information propagation, local interactions between nodes are more significant than distant ones. The comment implies that the authors should explain why the lack of locality in the transformer does not pose a concern. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its questioning of the authors\" claim, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim that a transformer without locality bias is the best option, suggesting that local interactions between nodes are more significant than distant ones due to the limited speed of information propagation. The reviewer expresses a lack of conviction in this claim and requests an explanation. While the comment raises a valid concern, it lacks specific examples or references to substantiate the claim fully. The request for explanation provides some direction, but the overall claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim regarding the transformer\"s lack of locality bias. It questions the validity of this claim, suggesting that local interactions between nodes are more significant than distant ones due to the limited speed of information propagation. The reviewer explicitly asks the authors to explain why the lack of locality in the transformer does not pose a concern, providing a clear and actionable suggestion for improvement. This feedback is 4 as it prompts the authors to address a critical aspect of their work, but it could be more comprehensive if it included additional guidance on how to substantiate their claims or provide evidence for their argument. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the algorithm\"s output depending on the order of data processing and suggests that this should be clarified. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to clarify this point or what specific aspects should be addressed. The action is implicit, as the authors can infer that they need to explain the dependency on data processing order, but the comment lacks concrete details on how to achieve this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a potential issue with the algorithm\"s output depending on the order of data processing, suggesting that this should be clarified. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the dependency on data processing order. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output depending on the order of data processing, suggesting that this should be clarified. While it points out a specific area that needs attention, it lacks detailed guidance or suggestions on how to address this issue or what aspects should be clarified. The feedback is 3 as it highlights a potential weakness in the paper, but it does not provide actionable steps for the authors to take to improve their draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential impact of mitigation strategies on the overall performance of the model. It suggests that while these strategies aim to reduce memorization, there might be a tradeoff with performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make. The action is implicit and vague, as it does not specify how to mitigate the potential negative impact on performance. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and their potential impact on the model\"s overall performance. However, it does not specify which part of the paper discusses these strategies, making it weakly grounded. The comment is specific in its critique of the tradeoff between reducing memorization and maintaining performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential impact of mitigation strategies on the model\"s performance, suggesting a tradeoff between reducing memorization and maintaining utility. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that these strategies might significantly impair performance. Without concrete evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the potential impact of mitigation strategies on the model\"s overall performance, suggesting a tradeoff between reducing memorization and maintaining utility. It highlights a potential issue that could deter the adoption of these strategies. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the draft. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of 6fold crossvalidation, questioning the reason for its application in the context of the paper. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should explain the necessity of 6fold crossvalidation, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper, questioning the reason for its application. However, it does not specify which part of the paper discusses the crossvalidation method, making it weakly grounded. The comment is specific in identifying the issue with the crossvalidation approach, but without clear guidance on how to address it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, citing the absence of this method in comparable papers. However, the comment lacks specific examples or references to other papers that did not use crossvalidation, making it difficult for the authors to understand the context and fully address the concern. The claim is 3 due to the lack of detailed justification or references, but it provides a starting point for the authors to explore the issue further.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology section, specifically questioning the necessity of using 6fold crossvalidation given that other comparable papers did not employ this method. This feedback is 3 as it prompts the authors to consider the rationale behind their choice of crossvalidation and whether it is appropriate for their problem. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. To be more helpful, the comment could include examples or references to other studies that used different crossvalidation methods, which would guide the authors in making an informed decision. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. The reviewer suggests that additional experiments or more indepth analysis are necessary to better justify the claims. This feedback provides clear and explicit guidance on what needs to be addressed to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Table 2 are insufficient to prove the benefits of the proposed methods, as they only outperform the baselines in one setup and show no consistent trend. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the results are insufficient. This makes the claim 3, as the authors would need to further develop their analysis to fully address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This feedback is clear and actionable, as it highlights a significant weakness in the paper\"s results and suggests that additional experiments or more indepth analysis are necessary to better justify the claims. By addressing this feedback, the authors can improve the robustness and reliability of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC and notes the inclusion of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide a clearer explanation of the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the impact of the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the inclusion of combinatorial and heuristic aspects and suggests clarifying the impact of these heuristic components. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the inclusion of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure. The reviewer suggests clarifying the impact of these heuristic components. However, the comment lacks specific examples or detailed reasoning to support the claim that the heuristic components are significant or how they impact the method. Without additional context or evidence, the claim remains 3, as it provides a general observation without detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but highlights the inclusion of combinatorial and heuristic aspects, particularly the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. This feedback is 3 as it identifies a specific area for improvement, prompting the authors to provide a clearer explanation of the heuristic components and their impact. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to clarify the impact. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses doubt about the proposed method\"s ability to be trained without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors can infer that they need to explore or clarify the method\"s reliance on camera information, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of the proposed method without camera information, particularly regarding the \"knowledge of CAD model correspondences\" and the origin of the ray. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the feasibility of the proposed method without camera information, specifically regarding the \"knowledge of CAD model correspondences\" and the origin of the ray. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the feasibility of the proposed method without camera information, specifically questioning the origin of the ray and the knowledge of CAD model correspondences. This feedback highlights a critical issue that the authors need to address, as it directly impacts the method\"s applicability and understanding. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their method. While it identifies a significant weakness, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not provide explicit guidance on how to conduct this comparison or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to include a more detailed comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the time complexity and competitiveness of prior art. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to include a detailed comparison, but without clear guidance on where to place this information, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness of prior art. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general direction for improvement but lacks the necessary depth to be fully actionable.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to enhance the paper\"s context and relevance. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects of prior work should be emphasized. Without more detailed suggestions, the authors may struggle to effectively incorporate this feedback into their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper, suggesting that the presented method does not clearly explain how it improves performance and computation speed compared to ODA. However, it does not provide explicit guidance on what specific changes should be made to address this concern. The comment implies that the authors should clarify the improvements, but it lacks concrete suggestions or actions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper does not clearly explain how the presented method improves performance and computation speed compared to ODA, one of the methods for solving the MOIP problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of the improvements over ODA. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presented method does not clearly explain how it improves performance and computation speed compared to ODA. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the method does not clearly suggest improvements. As a result, the claim is 1 due to the absence of supporting details or examples, making it difficult for the authors to address the feedback effectively.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that the presented method does not clearly explain how it improves performance and computation speed compared to ODA, one of the methods for solving the MOIP problem. This feedback highlights a gap in the paper\"s explanation, which is crucial for readers to understand the novelty and effectiveness of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional analysis or comparisons. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some figures, such as Figure 4, are not selfexplanatory because the lines for \"No adapt\" or \"Finetune\" are covered by other lines without additional explanation. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to add more explanation or context to make the figure selfexplanatory. The action is implicit and somewhat vague, as it lacks concrete instructions on how to improve the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the lines for \"No adapt\" or \"Finetune\" are covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where the lines for \"No adapt\" or \"Finetune\" are covered by other lines without additional explanation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, noting that some are not selfexplanatory. It provides an example, Figure 4, where the lines for \"No adapt\" or \"Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it highlights a particular area that needs improvement. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity of these figures or provided guidance on how to ensure that future figures are selfexplanatory. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the importance of the sampling method for obtaining different initializations x_0 and its impact on convergence to an optimum. However, it points out that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies a gap in the evaluation, it does not provide explicit guidance on how to address this issue or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors know they need to evaluate the sampling method but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the sampling method used to obtain different initializations x_0 and its impact on convergence to an optimum. It mentions that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for experimental evaluation of the sampling method, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to an optimum but notes that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. The comment provides a logical reasoning by highlighting the importance of the sampling method and the lack of experimental evaluation, which supports the claim. However, it could be strengthened by providing more detailed examples or references to specific aspects of the sampling method that could be evaluated. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies an important aspect of the paper, which is the sampling method used to obtain different initializations x_0 and its impact on convergence to an optimum. It points out that this aspect is not experimentally evaluated on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback highlights a potential gap in the experimental evaluation, which is crucial for understanding the robustness and reliability of the proposed method. However, the comment could be more helpful if it provided specific suggestions on how to address this gap, such as suggesting additional experiments or analyses that could be conducted. Overall, the comment is 3 as it identifies an important area for improvement but lacks detailed guidance for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the rationale behind the comparison of the proposed method with references 9 and 16, as well as the focus on computational cost. While it identifies areas of confusion and lack of clarity, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these issues or improve the clarity of their rationale. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises several questions about the rationale behind the comparison of the proposed method with references 9 and 16, as well as the focus on computational cost. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons are made, the comment lacks full grounding. It is specific in questioning the rationale and the focus on computational cost, but without clear guidance on how to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions and observations about the rationale and comparisons made in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the rationale and comparisons made in the paper, particularly regarding the proposed method and its comparison with references 9 and 16. It also questions the focus on computational cost and its relevance to the paper\"s contribution. While the comment identifies areas of confusion and lack of clarity, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the paper\"s presentation. The feedback is 3 as it highlights important areas for clarification but lacks depth and actionable advice, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to comprehensively evaluate the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the suggestion is explicit, it lacks specific guidance on which additional datasets to consider or how to conduct the experiments effectively. The action is clear but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets and encourages experiments on the full dataset instead of those in the lowresource regime. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or results that need to be expanded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting additional datasets and a different experimental approach, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to comprehensively evaluate the proposed method. While the suggestion is logical and based on the need for a more robust evaluation, it lacks specific examples or references to support the claim. The comment does not provide detailed reasoning or evidence to justify why more datasets are necessary or how they would improve the evaluation. As a result, the claim is 3, as it provides a general direction for improvement but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct experiments on more datasets to comprehensively evaluate their proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the robustness and comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it offered specific datasets or examples of how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a more thorough evaluation of their method."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this comparison but are not given specific guidance on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of the PL condition with the one proposed in the referenced work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. This is a valuable point for the authors to consider, as it could provide insights into the theoretical underpinnings of their work and potentially lead to improvements in the paper. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this comparison or incorporate the referenced work into their analysis. While it identifies an area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide an analysis of the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It also mentions that this analysis should be included for a fair comparison with the baseline 31, 33, *. The comment is clear and provides a direct action for the authors to take, which is to include this analysis. However, it does not specify how to conduct this analysis or what specific aspects should be examined, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to multistage training and multiple discriminators. The comment further suggests providing this analysis for a fair comparison with the baseline 31, 33, *. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a complete lack of discussion on the impact of adding additional parameters and computational effort due to multistage training and multiple discriminators. The reviewer suggests that the authors should provide this analysis for a fair comparison with the baseline 31, 33, *. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the analysis is missing. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of the missing analysis and its relevance to the paper\"s claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to multistage training and multiple discriminators. It suggests that the authors should provide an analysis for a fair comparison with the baseline 31, 33, *. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance the comprehensiveness and fairness of their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Despite this, the comment is 4 as it highlights an important area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of depth in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clearly explained across different model architectures and lacks theoretical evidence. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects to explore further. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis or provide theoretical justification for the observed correlation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, specifically noting that the trend is not clearly explained across different model architectures and lacks theoretical evidence. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional analysis and theoretical justification, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, as it does not clearly explain the trend across different model architectures and lacks theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend observed is not clearly explained across different model architectures and lacks theoretical justification. This feedback is valuable as it highlights a critical area where the paper could be strengthened by providing more comprehensive analysis and theoretical support. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how to conduct such analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential information leakage in the AutoAugment strategy due to the supervise training on ImageNet. It questions the authors\" conclusion regarding the pretraining dataset matching for linear classification and its implications for SSL algorithms. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their experimental setup. The feedback lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses Section 4.2, which is fully grounded as it explicitly mentions the section being discussed. It raises a concern about potential information leakage in the AutoAugment strategy due to supervise training on ImageNet. The comment also poses questions about the authors\" conclusion regarding the pretraining dataset matching for linear classification and its implications for SSL algorithms. This provides specific guidance on what the authors should consider and address in their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential information leakage in the AutoAugment strategy due to supervise training on ImageNet. It questions the authors\" conclusion regarding the pretraining dataset matching for linear classification and its implications for SSL algorithms. However, the comment lacks specific examples, references, or detailed reasoning to support the claim of information leakage or the impact on SSL algorithms. This makes the claim 3, as the authors would need to further explore and substantiate the points themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential information leakage in the AutoAugment strategy due to supervise training on ImageNet. It questions the authors\" conclusion regarding the pretraining dataset matching for linear classification and its implications for SSL algorithms. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their experimental setup. The feedback is 3 as it prompts the authors to consider the implications of their methodology, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider the use of tabular data as another form of multimodal data and would be interesting to see how the model works with this data. However, it does not provide explicit instructions or concrete details on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore the model\"s performance with tabular data. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests considering tabular data as another form of multimodal data and would be interesting to see how the model works with this data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis. The authors might infer that it relates to the discussion of multimodal data or the methodology section, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that tabular data could be another form of multimodal data and would be interesting to explore. However, the comment lacks specific reasoning or examples to support why this is an important consideration or how it could impact the model\"s performance. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests considering tabular data as another form of multimodal data and would be interesting to explore how the model works with this data. While it identifies a potential area for further exploration, the comment lacks specific guidance or suggestions on how to implement this exploration or what aspects of the model could be examined. This limits the comment\"s usefulness, as it provides a general idea but does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a more detailed analysis of the alignment of entity representations, particularly focusing on multilingual alignment. It also recommends including visualizations or case studies for different language types, such as language families, and inquiring about the alignment of entities from lowresource languages with highresource ones. These suggestions are concrete and provide clear guidance on how the authors can enhance their analysis and presentation. The comment is 5 as it offers specific actions and visualizations that the authors can implement to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more analysis on the multilingual alignment of entity representations and recommends including visualizations or case studies for different language types, such as language families. Additionally, it raises a question about the alignment of entities from lowresource languages with highresource ones. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the paper has weak analysis on the alignment of entity representations, particularly for languageagnostic characters. The reviewer suggests that the authors should provide more analysis on multilingual alignment and include visualizations or case studies for different language types, such as language families. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include visualizations or case studies could be more robust if it were supported by specific examples or references. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific area of weakness in the paper, namely the analysis of the alignment of entity representations, particularly for languageagnostic characters. It suggests that the authors should provide more detailed analysis on multilingual alignment and include visualizations or case studies for different language types, such as language families. Additionally, the comment raises an interesting question about the alignment of entities from lowresource languages with highresource ones. This feedback is clear and actionable, offering specific suggestions for improvement that could enhance the depth and comprehensiveness of the paper. However, it could be more helpful if it provided examples or detailed guidance on how to implement these suggestions. Overall, the comment is 4, as it effectively directs the authors toward meaningful enhancements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on the use of attention would be beneficial, possibly as an extra appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine how to incorporate this suggestion into their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details on the use of attention would be beneficial, possibly as an extra appendix. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more details on the use of attention, but it lacks grounding as it does not indicate where in the paper this information should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on the use of attention would be beneficial, possibly as an extra appendix. However, it does not provide any specific reasoning or examples to support why this would be beneficial or how it would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details on the use of attention would be beneficial, possibly as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate this suggestion into the paper. The comment is 3 as it points out a potential enhancement, but it does not offer detailed feedback or actionable steps for the authors to follow. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or years of many papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to correct these errors. The authors are left to infer that they need to remove duplicates and ensure the completeness of the publication information. However, the comment lacks concrete instructions on how to address these issues, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the references list, namely the presence of duplicates and missing publication venues and years. This provides clear guidance on what needs to be corrected. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies two specific issues with the references list: the presence of duplicates and the omission of publication venues and years for many papers. While it highlights these problems, it does not provide any suggestions or guidance on how the authors might address these issues, such as recommending specific actions or resources for completing the references. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable advice, making it less useful for the authors to make informed changes to their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it suggests that the authors need to analyze and compare the theoretical results to other comparable methods. This feedback provides a clear and direct action for the authors to take, which is to enhance the clarity and strength of their theoretical analysis by comparing it to other methods. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the unclear and weak theoretical analysis in Theorem 1 and the need to analyze and compare the theoretical results to other comparable methods. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically noting that the error bound is not wellexplained. The reviewer suggests that the authors should analyze and compare their theoretical results to other comparable methods. However, the comment lacks specific examples or references to other comparable methods or detailed explanations of how the error bound should be interpreted. This makes the claim 3, as it provides a general direction for improvement but lacks the detailed evidence or examples needed to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical analysis in Theorem 1, noting that it is unclear and weak. It specifically points out the lack of clarity regarding the error bound and suggests that the authors should analyze and compare their theoretical results to other comparable methods. This feedback is clear and actionable, providing the authors with a specific direction to enhance the clarity and strength of their theoretical analysis. By addressing this feedback, the authors can improve the comprehensibility and robustness of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and mentions the absence of the pseudocode for the proposed method. While the comment identifies a potential issue with the explicit methods and the missing pseudocode, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide a rationale for the performance difference and include the missing pseudocode. However, the comment lacks concrete instructions on how to improve the explicit methods or where to place the pseudocode. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the absence of the pseudocode for the proposed method. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the performance comparison is discussed. Additionally, the comment does not provide specific guidance on what aspects of the pseudocode are missing or how it should be included. This lack of grounding and specificity makes it difficult for the authors to identify the exact parts of the paper that need attention. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the absence of the pseudocode for the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why the explicit methods perform better or why the pseudocode is missing. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out the absence of the pseudocode for the proposed method. While it identifies a potential issue with the explicit methods, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The mention of the missing pseudocode is a minor point, and the comment lacks depth and actionable advice. Therefore, the feedback is 2, as it highlights a potential area for improvement but does not offer detailed guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs further finetunes the multilingual model and uses the method like R3F to maintain generalization ability. However, it also points out that the improvement of 0.8 in some lowresource language translations is insignificant in a practical sense. The comment explicitly suggests that the authors should address this issue, but it does not provide specific guidance on how to do so. The mention of a missing reference to Aghajanyan et al. (\"Better FineTuning by Reducing Representational Collapse\") indicates that the authors should include this reference in their work. While the comment provides some direction, it lacks concrete steps or detailed guidance on how to address the issue of insignificant improvements in lowresource language translations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs and the method like R3F to maintain the generalization ability of a multilingual model. It specifically mentions the improvement of 0.8 in some lowresource language translations and notes that it is insignificant in a practical sense. The comment also points out a missing reference to Aghajanyan et al. (\"Better FineTuning by Reducing Representational Collapse\"). However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of insignificant improvements and the need for a reference, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement of 0.8 in some lowresource language translations is insignificant in a practical sense. However, the comment does not provide specific examples or detailed reasoning to support this claim, nor does it reference any studies or data that could substantiate the claim. The mention of a missing reference to Aghajanyan et al. (\"Better FineTuning by Reducing Representational Collapse\") suggests that the authors might need to include this reference, but the comment itself does not provide enough information to verify the claim. As a result, the claim is considered 2, as it lacks sufficient evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs in the context of multilingual model finetuning. It points out that while the improvement of 0.8 is claimed, it may be insignificant in a practical sense. The comment also references a missing work by Aghajanyan et al. (\"Better FineTuning by Reducing Representational Collapse\"), suggesting that this reference should be included. While the comment highlights a potential weakness in the methodology and provides a reference for further exploration, it lacks specific guidance on how the authors might address the issue of insignificant improvements or how to incorporate the suggested reference effectively. This limits the comment\"s helpfulness, as it provides some insight but lacks actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why the authors only show results on images corrupted with Gaussian noise, despite mentioning that their model can work well for various image noise. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Without specific advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s claim about the model\"s versatility with various image noise types, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on Gaussian noisecorrupted images, prompting the authors to explain the rationale behind this choice. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reason for only showing results on Gaussian noisecorrupted images, despite mentioning the model\"s versatility with various image noise types. This is a logical question seeking clarification, which does not constitute a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the paper\"s claim regarding the model\"s versatility with various image noise types. It points out that the authors only provide results for images corrupted with Gaussian noise, despite mentioning the model\"s potential for handling different noise types. This feedback highlights a gap in the paper\"s presentation and suggests that the authors should provide more comprehensive results to support their claim. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional noise types to test or explaining the rationale behind the choice of Gaussian noise. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should visualize the effect of increasing data dimensionality on existing PU learning methods. This is an explicit action, as it clearly instructs the authors to include a visualization to support their claim. The comment also highlights the importance of this visualization in the context of the paper\"s research motivation, providing a clear and concrete action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of increasing data dimensionality on existing PU learning methods, which is relevant to the research motivation of the paper. However, it does not specify which part of the paper this visualization should be included in, making it weakly grounded. The comment is specific in its suggestion to visualize the effect, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that existing PU learning methods will decline in performance as data dimensionality increases. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s claim regarding the performance decline of existing PU learning methods as data dimensionality increases. It suggests that the authors should visualize this effect to better support their research motivation. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper\"s presentation and understanding of the research motivation. However, the comment could be more helpful if it offered additional guidance on how to create an effective visualization or discussed the implications of this visualization. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) could be appropriately placed in the supplementary materials. This is an explicit action, as it clearly indicates where the information should be located. However, it does not provide specific guidance on why this placement is beneficial or how it would enhance the paper. The action is concrete, as the authors know exactly where to place the information, but it lacks detailed reasoning or examples. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests placing the empirical version of the objective (3) in the supplementary materials. However, it does not specify which part of the paper this objective is discussed in, making it weakly grounded. The comment is specific in suggesting where to place the information, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) could be appropriately placed in the supplementary materials. However, it does not provide any reasoning or justification for why this placement is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the empirical version of the objective (3) could be appropriately placed in the supplementary materials. This feedback is 3 as it provides a specific suggestion for organizing the content, which could enhance the clarity and accessibility of the paper. However, the comment lacks depth and does not explain why this placement is beneficial or how it would improve the paper. It also does not offer alternative suggestions or guidance on how to effectively present the empirical version of the objective. Therefore, while the comment offers some actionable feedback, it could be more helpful with additional context and reasoning."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a need for simplifying the result descriptions and provides specific suggestions for improvement. It mentions a related study on speakerlistener communication from a teachability perspective and suggests checking the relevance of the differences in figures. The reviewer also provides references to support the suggestions, which adds concrete guidance for the authors. The explicit nature of the suggestions and the inclusion of references make the comment 5, as the authors can clearly understand what needs to be addressed and how to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific result descriptions that are needlessly convoluted, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as referencing a related study on speakerlistener communication from a teachability perspective and suggesting a check on the relevance of differences in figures. The inclusion of references further supports the suggestions, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and provides specific examples of this. It suggests that a related study on speakerlistener communication from a teachability perspective was studied in 1, and that the differences in figures seem too small but indicate something reasonable. The comment is 4 as it provides references to support the suggestions, allowing the authors to understand and address the issues. However, the comment could be strengthened by providing more detailed reasoning or examples of the convoluted descriptions. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a need for simplification in the result descriptions, noting that they are unnecessarily convoluted. It provides specific examples of this complexity, such as the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" The comment offers actionable suggestions for improvement, including referencing a related study on speakerlistener communication from a teachability perspective (1) and suggesting a check on the relevance of differences in figures. Additionally, it provides references to support the suggestions, which adds depth to the feedback. This level of detail and constructive feedback empowers the authors to make meaningful improvements to their draft, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of approximation error should be clarified by providing a mathematical characterization. While the comment implies that the authors should add a mathematical definition, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer that they should include a mathematical characterization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the definition of approximation error, which is a specific aspect of the paper. However, it does not explicitly mention which section or part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that a mathematical characterization would be better than the current definition, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the definition of approximation error is ambiguous and proposes that a mathematical characterization would be more precise. However, the comment does not provide specific examples or references to support why the current definition is ambiguous or how a mathematical characterization would improve clarity. This lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the definition of approximation error, suggesting that it is unclear without the context of the values in the table. It provides a constructive suggestion to offer a mathematical characterization, which would enhance clarity and precision in the paper. This feedback is clear and actionable, as it guides the authors on how to improve the clarity of their work. However, it could be more helpful if it included specific examples or further elaboration on how to implement the mathematical characterization. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific claim about Corollar 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this claim or what changes could be made to the paper to clarify or improve the argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is being addressed, namely the claim about Corollar 10 and its implications regarding uncertainty sampling and the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. The comment provides a logical reasoning by explaining the distinction between the expected 01 loss and the expected convex surrogate. However, it lacks specific examples or references to support the claim further, which could enhance the verifiability. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific claim about Corollar 10, noting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is 3 as it highlights a potential misunderstanding or misinterpretation in the paper, prompting the authors to reconsider their conclusions. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or clarify the implications of their findings. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the proposed model, noting that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n. This results in very slow dynamics. Additionally, it points out that the evolution model is simplistic, as it only changes edges with the average of 1 node changing cluster. However, the comment does not provide any explicit or implicit suggestions for improvement or how the authors might address these limitations. There is no guidance on how to enhance the model\"s dynamics or complexity, leaving the authors without a clear path for action. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, mentioning the reassignment probability and the simplicity of the evolution model. However, it does not specify which part of the paper discusses these points, making it weakly grounded. The comment is specific in detailing the limitations of the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in very slow dynamics. It also states that the evolution model is simplistic, as it only changes edges with the average of 1 node changing cluster. The comment provides logical reasoning based on the reassignment probability and the simplicity of the model, making the claim 4. However, it lacks specific examples or references to support the claim further, which could enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the proposed model, noting that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n. This results in very slow dynamics, which is a significant concern. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges with the average of 1 node changing cluster. While the comment highlights important weaknesses in the model\"s design, it lacks actionable suggestions or guidance on how the authors might address these limitations or improve the model\"s dynamics. Without specific recommendations or alternative approaches, the feedback provides some insight but does not fully support the authors in making meaningful improvements to their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division. It specifies that the division should not be random and suggests considering other factors. This provides clear and concrete guidance on what needs to be included in the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and test sets, including the numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014details about the division process, including whether it is random or based on other considerations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information regarding the division of the dataset into training and test sets. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks detail, namely the division of the dataset into training and test sets. It explicitly asks for the numbers involved and how the division was made, suggesting that it is not simply random. This feedback is clear and actionable, as it provides the authors with a concrete task to improve the transparency and reproducibility of their work. By addressing this issue, the authors can enhance the clarity and robustness of their methodology, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning. It also mentions the scalability issue with longtext input. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning. It also mentions the scalability issue with longtext input. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing methodology or experimental setups, but this inference is not direct. The comment is specific in detailing the issues with text descriptions and scalability, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning. It also mentions the scalability issue with longtext input. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the basis of these concerns, making the claims 3. The comment could be strengthened with more detailed explanations or references to support the claims, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning. It also mentions the scalability issue with longtext input, which could restrict the framework\"s applicability. While the comment identifies potential weaknesses in the methodology, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it highlights areas for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the performance improvement of the proposed methods, noting that the improvement in the bank dataset is minimal (approximately 0.02). It also suggests that using tables to directly show key improvements would be more intuitive and detailed. While the comment identifies a specific area of concern and provides a suggestion for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider using tables for better presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the minimal performance improvement in the bank dataset and suggests using tables to better illustrate key improvements. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, as evidenced by the minimal improvement in the bank dataset (approximately 0.02). The comment suggests that using tables to directly show key improvements would be more intuitive and detailed. While the claim is supported by the mention of the minimal improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use tables is logical but could be more robust with additional justification or examples. Therefore, the comment is 3, as it provides some support but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance improvement of the proposed methods, noting that the improvement in the bank dataset is minimal (approximately 0.02). It suggests that using tables to directly show key improvements would be more intuitive and detailed. This feedback is 3 as it highlights a specific area of concern and provides a suggestion for improvement. However, the comment could be more actionable by offering specific guidance on how to present the data in tables or suggesting alternative ways to visualize the results. Overall, the comment provides some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the experimental validation, such as the limited consideration of shallow networks (only 2 or 3 layers) and the lack of description on the optimization strategy, including the grid search for hyperparameters. It also points out a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The authors are left to infer that they need to expand their experimental setup and provide more detailed descriptions, but without concrete instructions, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the limited consideration of shallow networks (only 2 or 3 layers) and the lack of description on the optimization strategy, including the grid search for hyperparameters. It also points out a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding the experimental setup and providing more detailed descriptions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, citing the limited consideration of shallow networks (only 2 or 3 layers) and the lack of description on the optimization strategy, including the grid search for hyperparameters. The comment also mentions a minor issue regarding the positioning with respect to related works, specifically referencing a paper on network pruning. While the comment provides some context and a specific reference, it lacks detailed reasoning or examples to fully substantiate the claim about the experimental validation. The mention of layer redundancy in the context of network pruning is a relevant external reference, but the overall claim remains 3 due to the need for more detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the experimental validation section of the paper. It points out that only shallow networks (2 or 3 layers) are considered, which limits the scope of the evaluation. Additionally, it notes the lack of description on the optimization strategy, including the grid search for hyperparameters, which is crucial for understanding the methodology. The comment also highlights a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment provides some valuable insights into areas that need improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are left with a general idea of what needs to be expanded but without specific actionable steps. Therefore, the comment is 3, as it identifies areas for improvement but could be more comprehensive with detailed feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the use of a specific type of loss in a particular setting might be new, but it does not provide any guidance or suggestions on how the authors could address this issue or improve their work. The comment lacks explicit or implicit actions, leaving the authors without any clear direction on how to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the lack of new theoretical results in the paper, suggesting that the use of a specific type of loss in a particular setting might be new. However, it does not specify which part of the paper this critique pertains to, nor does it provide details on what theoretical results are missing or how they could be proven. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what theoretical results are missing or how they could be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results, despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential weakness in the paper, specifically the lack of new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve their work. It lacks actionable feedback, making it difficult for the authors to understand what steps they could take to enhance their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider a straightforward hypothesis about the two parts of their work, specifically regarding the characteristics of the trivial and impossible parts. It implies that the authors should provide evidence to either prove or disprove this hypothesis. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to gather or present this evidence. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to support or refute the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the characteristics of the trivial and impossible parts, specifically regarding the simplicity of the trivial part and the ambiguity of the impossible part. However, it does not specify which part of the paper this hypothesis is related to, making it weakly grounded. The comment does provide some specificity by suggesting that the authors should provide evidence to either prove or disprove this hypothesis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the characteristics of the trivial and impossible parts, specifically regarding their simplicity and ambiguity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this hypothesis. Without additional context or justification, the claim remains 1, as it lacks the necessary details to support the authors\" understanding of the hypothesis. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a hypothesis about the characteristics of the trivial and impossible parts, specifically regarding their simplicity and ambiguity. It implies that the authors should provide evidence to either prove or disprove this hypothesis, which could be a valuable direction for further exploration. However, the comment lacks specific guidance or suggestions on how to test or validate this hypothesis, making it 3. The authors are given a direction to consider, but the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the model on other tasks in the bAbI dataset, implying that the authors should consider testing the model on additional tasks. However, it does not provide explicit instructions or concrete guidance on how to address this issue, such as suggesting specific tasks to test or how to analyze the results. The action is implicit and somewhat vague, as the authors can infer that they need to expand their testing but lack detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1 of bAbI,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the testing of the model on other tasks in the bAbI dataset, prompting the authors to consider expanding their testing beyond the current scope. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the testing of the model on other tasks in the bAbI dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement.", "helpfulness_rationale": "The comment raises a question about the testing of the model on other tasks in the bAbI dataset, specifically noting that it was only tested on a single supporting fact dataset (Task 1). This feedback highlights a potential limitation in the experimental setup and prompts the authors to consider expanding their testing to other tasks. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how to address this issue or what other tasks might be relevant. The feedback is 3 as it points out a potential weakness in the experimental design, but it could be more actionable with additional context or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment indicates that it is challenging to follow Section 3.2 and suggests that the authors improve it by providing more illustrations and examples. While the comment implies that the authors should add more detailed explanations or examples to enhance clarity, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors are left to infer that they need to provide more illustrations and examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors improve the section by providing more illustrations and examples to enhance clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is challenging to follow Section 3.2 and suggests that the authors improve it by providing more illustrations and examples. However, the comment does not offer any specific reasoning or examples to support why it is difficult to follow this section or how the suggested improvements would address the issue. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific challenge in understanding Section 3.2, suggesting that the authors improve the clarity of this section by providing more illustrations and examples. This feedback is actionable and provides a clear direction for the authors to enhance the comprehensibility of their work. However, the comment could be more helpful if it offered specific suggestions on what kind of illustrations or examples would be most effective. Despite this, the feedback is 4 as it guides the authors toward improving the clarity of their presentation. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the technical contribution of the paper is limited, specifically noting the absence of significant technical contributions and extensions based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects they should focus on to improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant extensions based on a typical model for crossdomain recommendation. However, it does not specify which part of the paper this critique pertains to, such as specific sections, experiments, or results. Without explicit references to the paper\"s content, the authors cannot confidently determine which parts need attention or improvement. The comment is not specific about what aspects of the technical contribution are lacking, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited, specifically noting the absence of significant extensions based on a typical model for crossdomain recommendation. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation in the technical contribution of the paper, specifically noting the absence of substantial technical contributions and extensions based on a typical model for crossdomain recommendation. This feedback is clear and highlights a critical area for improvement, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provided examples of how to extend the model. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which baselines to include or how to present the results. The authors know that they need to add these baselines, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper Table 1 is located in, making it weakly grounded. The comment is specific in suggesting the addition of baselines to address a particular aspect of the analysis, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would clarify the gap. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their analysis by including additional baselines. By doing so, the authors can gain a deeper understanding of the performance differences between fully supervised and SSL approaches for small models. However, the comment could be more helpful if it included suggestions on how to present or interpret these baselines. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the computation of hypervolume in each step of LaMOO. It suggests that for problems with many objectives, this computation could be timeconsuming, potentially making LaMOO impractical. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors can infer that they need to consider the time complexity implications of their algorithm, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the time complexity of the proposed algorithm, particularly regarding the computation of hypervolume in each step of LaMOO. The comment further specifies the concern by mentioning that the computation could be timeconsuming, especially for problems with many objectives (e.g., >3), and questions whether this would make LaMOO impractical for those problems. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the computation of hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming, especially for problems with many objectives, potentially making LaMOO impractical for those cases. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim about the time complexity. The reasoning is 3, as it provides a logical basis for the concern but does not offer detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant question about the time complexity of the proposed algorithm, specifically focusing on the computation of hypervolume in each step of LaMOO. It highlights a potential issue with the algorithm\"s practicality for problems with many objectives, which could make it impractical for such cases. While the comment identifies a critical area for consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve the algorithm\"s efficiency. Providing more detailed feedback or actionable advice would enhance its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the use of small datasets in the experiments and suggests that results on medium or large datasets, such as ImageNet, would strengthen the paper. However, it does not provide explicit instructions or concrete steps for the authors to take to address this issue. The comment implies that the authors should consider including results on larger datasets, but it lacks specific guidance on how to implement this suggestion or what additional analysis might be necessary. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment acknowledges the use of small datasets in the experiments and suggests that results on medium or large datasets, such as ImageNet, would strengthen the paper. However, it does not specify which part of the paper discusses the experiments or datasets, making it weakly grounded. The comment is specific in suggesting the need for results on larger datasets, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is very small and suggests that results on medium or large datasets, such as ImageNet, would strengthen the paper. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the use of larger datasets would improve the paper\"s overall quality. The lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the suggestion without further explanation.", "helpfulness_rationale": "The review comment acknowledges the use of small datasets in the experiments and suggests that results on medium or large datasets, such as ImageNet, would strengthen the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what kind of results would be beneficial. The feedback is 3 as it highlights a minor issue that could enhance the paper\"s credibility, but it lacks depth and actionable advice, making it less valuable for the authors to use for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed discussion on the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being precise in being critical, questioning the title as being too generic and vague, and suggesting that the term \"brittle convergence properties\" should be clarified. Additionally, the reviewer suggests considering the adoption of DeepRL methods and the landscape over the past decade. While the comment provides several areas for improvement, it lacks explicit instructions on how to address each point, such as specific examples or detailed guidance on how to enhance the discussion. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed discussion on the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also questions the title, suggesting it is too generic and vague, and implies that the authors should be precise in being critical. Additionally, the comment raises questions about the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape over the past decade. However, the comment does not specify which part of the paper should be revised or improved, making it weakly grounded. The suggestions are specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed discussion on the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also questions the title, suggesting it is too generic and vague, and implies that the authors should be precise in being critical. The comment raises questions about the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape over the past decade. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it 3. The authors would need to infer the basis of these suggestions, which limits the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It suggests that the authors should offer a more detailed discussion on the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. This feedback is clear and prompts the authors to expand their discussion on these aspects. Additionally, the comment questions the title, suggesting it is too generic and vague, and implies that the authors should be precise in being critical. It also raises questions about the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape over the past decade. While the comment identifies areas for improvement, it could be more helpful by providing specific examples or guidance on how to address these issues. Overall, the feedback is 4 as it directs the authors toward enhancing the depth and precision of their discussion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the synthesis of the focal stack, the forward model of using a defocus map and an image, and the handling of edges with depth discontinuities. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or methods to address these questions. However, the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the synthesis of the focal stack, the forward model of using a defocus map and an image, and the handling of edges with depth discontinuities. However, it does not specify which part of the paper these questions pertain to, such as specific sections or figures. The authors can infer that these questions relate to the methodology or experimental setup, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks grounding as it does not pinpoint the exact sections of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper, specifically regarding the synthesis of the focal stack, the forward model of using a defocus map and an image, and the handling of edges with depth discontinuities. These are questions that require the authors to provide more detailed explanations or methods, but they do not contain subjective claims, opinions, or suggestions that need verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks clarity and provides specific questions about the methodology used in the paper. It asks about the synthesis of the focal stack, the forward model of using a defocus map and an image, and the handling of edges with depth discontinuities. While the comment highlights important aspects that need clarification, it does not offer suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or methods to address these questions, which limits the helpfulness of the comment. Therefore, the comment is 3, as it points out areas for improvement but lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical justification for their first contribution, which is the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include empirical evidence to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first claimed contribution of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the first contribution of the paper is not supported by empirical justification. The reviewer suggests that the authors should provide evidence to support their claim. However, the comment does not provide specific examples or references to substantiate the claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or examples renders the claim 2, as it highlights a potential gap in the paper but does not fully support the argument.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper regarding the first contribution, which is that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. The reviewer suggests that the authors should provide empirical justification for this claim, indicating a gap in the paper\"s support for this contribution. This feedback is clear and actionable, as it directs the authors to a specific area where they need to strengthen their argument with evidence. However, the comment could be more helpful if it provided examples of how to conduct such empirical justification or suggested methods for testing the claim. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the components of the approach are not novel, specifically mentioning the use of weak predictors like MLP, Regression Tree, or Random Forest, which have been used before in NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and exactly the same as in BRPNAS. The comment suggests that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor used (MLP, Regression Tree, or Random Forest) and the sampling strategy, which are compared to existing methods like epsilongreedy and BRPNAS. It also references specific results in Table 2 of the Appendix, providing clear guidance on what needs to be addressed. This level of detail allows the authors to accurately identify the parts of the paper being discussed and understand the specific issues raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the components of the approach are not novel, specifically mentioning the use of weak predictors like MLP, Regression Tree, or Random Forest, which have been used before in NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and exactly the same as in BRPNAS. The comment references specific works (2,3,7 for weak predictors and 5 for the sampling strategy) and provides a comparison with results from Table 2 in Appendix C. This level of detail and reference to existing literature supports the claim, making it 4. However, the comment could be strengthened by providing more context or a broader discussion of the implications of these observations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, specifically pointing out that the components of the approach are not novel. It highlights the use of weak predictors like MLP, Regression Tree, or Random Forest, which have been used before in NAS performance prediction, and notes that the sampling strategy is similar to epsilongreedy and exactly the same as in BRPNAS. The comment also references specific results in Table 2 of the Appendix, providing a concrete basis for the critique. While the comment effectively identifies areas of overlap and potential redundancy, it lacks detailed suggestions or actionable steps for the authors to address these issues. This limits its helpfulness, as the authors are left with a clear understanding of the problem but without a comprehensive guide on how to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed S1DBED algorithm is too similar to RMED, suggesting that the novelty of this part is limited. It explicitly states that the paper needs a sufficient discussion on the comparison with RMED. This feedback provides a clear and direct action for the authors to take, which is to include a detailed comparison with RMED in their paper. The comment is specific and actionable, giving the authors a concrete task to address the issue of novelty. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed S1DBED algorithm and suggests that it is too similar to RMED, indicating a need for a discussion on the comparison. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely a sufficient discussion on the comparison with RMED. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED, suggesting that the novelty of this part is limited. The reviewer provides a specific reference to Komiyama et al. 2015, which supports the claim by indicating that the comparison with RMED is necessary. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the similarity affects the novelty. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, noting its similarity to RMED. It suggests that the paper needs a sufficient discussion on the comparison with RMED to address this concern. This feedback is clear and actionable, as it provides a specific area for the authors to expand upon in their paper. By addressing this comparison, the authors can enhance the novelty and distinctiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively compare the two algorithms or what aspects of the comparison are most critical. Overall, the comment is 4, as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work are missing or how the authors should address this gap. The comment lacks explicit guidance or concrete suggestions on how to improve the discussion of previous work, leaving the authors uncertain about what specific changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion on previous work related to the topic. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what aspects of the previous work are missing or how they should be addressed. Without explicit references to sections or specific elements, the authors cannot confidently determine where the discussion is lacking or how to improve it. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not offer any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a significant gap in the paper by noting the absence of a comprehensive discussion of previous work on the topic. This is a valuable piece of feedback as it highlights an area where the authors could enhance the depth and context of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending specific studies or frameworks to include. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the OT sample selection process and the training steps. It asks whether the OT sample selection process runs once or iteratively, and whether the loss of equation (10) and the OT in equation (3) are optimized iteratively. The comment also suggests that adding more details and a flow chart would help readers understand the process. Additionally, it inquires about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment identifies specific areas for clarification and suggests improvements, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10)\" and \"equation (3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions and requests for clarification regarding the OT sample selection process, the training steps, and the runtime for solving the entropic regularized discrete OT problem. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the OT sample selection process and the training steps. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely factual. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and requests for clarification regarding the OT sample selection process and the training steps. It asks whether the OT sample selection process runs once or iteratively, and whether the loss of equation (10) and the OT in equation (3) are optimized iteratively. Additionally, it suggests that providing more details and a flow chart would help readers understand the process. The comment also inquires about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment identifies specific areas for improvement and provides a clear request for clarification, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out areas that need further explanation, but it could be more comprehensive with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the experimental section, noting that while the authors discuss how KG handles continuous tasks, there are no experiments conducted for continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in the experiments and asks how these methods compare empirically to ConBO. The comment implies that the authors should include experiments with continuous tasks and provide comparisons to ConBO, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and include comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental section, specifically mentioning the discussion of how KG handles continuous tasks and the lack of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in the experiments and asks about the empirical performance compared to ConBO. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental part of the paper, particularly Section 7. The comment is specific in detailing what is missing in the experiments and what comparisons should be made. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the absence of experiments with continuous tasks and the inclusion of entropy methods for conditional optimization in the experiments. It also asks about the empirical performance of these methods compared to ConBO. While the comment highlights a gap in the experimental section, it lacks specific examples or references to support the claim that the absence of experiments is a significant issue. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is categorized as 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a gap in the experimental section by pointing out that while the authors discuss how KG handles continuous tasks, there are no experiments conducted for continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in the experiments and asks about the empirical performance compared to ConBO. This feedback is 3 as it highlights areas where the authors could improve their experimental setup and provide a rationale for why these experiments are important. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to conduct the necessary experiments. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential to craft adversarial prompts and transfer them. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"other LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to include a comparison of the approach with other LLMs, particularly mentioning the potential to craft adversarial prompts and transfer them. Additionally, it highlights a minor point about the jailbreaking percentage being low for certain LLMs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential to craft adversarial prompts and transfer them. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim. The mention of a low jailbreaking percentage for certain LLMs is a minor point that does not require extensive justification. Overall, the comment is 3 due to the need for more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include a comparison of their approach with other LLMs, particularly in crafting adversarial prompts and transferring them. This feedback is actionable and offers a clear direction for enhancing the paper\"s relevance and impact. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to various POMDP formulations, including continuous or infinite spaces. While it poses a question, it does not explicitly instruct the authors to address these limitations or provide guidance on how to do so. The action is implicit, as the authors can infer that they need to explore or clarify the framework\"s limitations, but the comment lacks concrete details on how to implement this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to various POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to various POMDP formulations, including continuous or infinite spaces. However, it does not present a claim or opinion that requires verification. It is a request for clarification or further exploration, which fits the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework in terms of its applicability to various POMDP formulations, including continuous or infinite spaces. This question prompts the authors to consider whether the framework can handle a broader range of POMDP formulations, which is a relevant area for improvement. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation. While it identifies a potential area for enhancement, it does not offer detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the precision/recall/F1score was calculated for the 4class classification of breast density and whether AUC results should be provided for breast cancer detection. While the first question is explicit, the second part is more of a suggestion rather than a direct action. The authors are prompted to consider providing AUC results for comparisons, but the comment does not specify how to implement this suggestion or what specific AUC results should be included. The action is somewhat vague, as it lacks concrete guidance on how to apply the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two specific questions regarding the methodology and results of the paper. The first question asks about the calculation of precision/recall/F1score for a 4class classification of breast density, which is a specific aspect of the methodology. The second question suggests providing AUC results for breast cancer detection, which is a specific recommendation for improving the comparison of model performance. However, the comment does not explicitly mention which part of the paper these questions pertain to, making it weakly grounded. The questions are specific, as they clearly identify what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: questioning the methodology of calculating precision/recall/F1score for a 4class classification and suggesting the inclusion of AUC results for breast cancer detection. The first part is a request for clarification, which does not contain a claim. The second part suggests providing AUC results, which is a recommendation rather than a claim. Since the comment does not contain subjective opinions, judgments, or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions and suggestions for improvement. First, it questions the methodology used to calculate precision/recall/F1score for a 4class classification of breast density, prompting the authors to clarify their approach. Second, it suggests providing AUC results for breast cancer detection, noting that this would be more informative for comparing model performance. While the comment identifies areas for clarification and improvement, it lacks detailed guidance or examples on how to address these issues. The suggestions are 3 as they provide direction for enhancing the paper, but they could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the creation of the dataset as optional and suggests that the Kialo dataset, which is wellstudied and clean, could be used instead. However, it does not provide explicit guidance on how the authors should incorporate this dataset into their work or what specific improvements it could offer. The comment implies that the authors should consider using the Kialo dataset, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the creation of the dataset, suggesting that the Kialo dataset could be used instead of the one created by the authors. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting the use of an existing dataset, but without clear guidance on how to integrate it into the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional and suggests that the Kialo dataset, which is wellstudied and clean, could be used instead. The comment provides a logical reasoning by pointing out the advantages of using an existing dataset over the one created by the authors. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the Kialo dataset to understand its relevance and applicability to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset creation process, suggesting that the Kialo dataset, which is wellstudied and clean, could be used instead. This feedback is 3 as it provides a specific alternative dataset that could be considered, potentially improving the quality and relevance of the dataset used in the paper. However, the comment lacks detailed guidance on how the authors might integrate this dataset into their work or what specific benefits it could offer. While it points out a potential improvement, it does not fully support the authors in making a meaningful change to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of the transformer in the paper, noting that it is no longer novel in the field. It also mentions that the authors made a modification, such as crosslayer, but this does not provide significant insight into machine learning. Additionally, the comment points out that the selfcross attention in the ablation study (table4 and 5) only provides limited improvement (<1%), suggesting that the main improvements over other methods come from using a na\u00efve transformer instead of the proposed modification. While the comment highlights several issues, it does not provide explicit guidance on how the authors should address these concerns or suggest specific changes to improve their draft. The feedback is somewhat vague and lacks concrete actions for the authors to take, making it 3.", "grounding_specificity_rationale": "The comment critiques the use of the transformer in the paper, noting that it is no longer novel in the field. It specifically mentions the authors\" modification, such as crosslayer, and questions the significance of the selfcross attention in the ablation study (table4 and 5), which only provides limited improvement. The comment is fully grounded as it explicitly mentions the use of the transformer and the ablation study, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the transformer\"s novelty and the limited improvement from the selfcross attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the use of the transformer in the paper, noting that it is no longer novel in the field. It also mentions that the authors made a modification, such as crosslayer, but this does not provide significant insight into machine learning. The comment further questions the significance of the selfcross attention in the ablation study, noting that it only provides limited improvement (<1%). The reviewer suggests that the main improvements over other methods come from using a na\u00efve transformer instead of the proposed modification. While the comment provides some logical reasoning and specific examples, it lacks detailed references or further elaboration to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the critique but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment critiques the use of the transformer in the paper, noting that it is no longer novel in the field. It points out that the authors made a modification, such as crosslayer, but this does not provide significant insight into machine learning. The comment also questions the significance of the selfcross attention in the ablation study, noting that it only provides limited improvement (<1%). It suggests that the main improvements over other methods come from using a na\u00efve transformer instead of the proposed modification. While the comment identifies several weaknesses and areas for improvement, it lacks specific suggestions or actionable guidance on how the authors might address these issues. The feedback is 3 as it highlights important points for the authors to consider, but it could be more comprehensive with detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and present results in terms of tasks learned rather than epochs. The comment explicitly states the need for more tasks and provides a clear direction for the authors to address the issue. However, it does not specify how to implement this suggestion or what specific tasks should be included. While the action is clear, the lack of detailed guidance on how to achieve this makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the number of tasks in the experiments, suggesting that it is limited and recommending the inclusion of at least 10 tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include more tasks and present results in terms of tasks learned rather than epochs. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the limited number of tasks in the experiments, suggesting that the authors should include more tasks (at least 10) and present results in terms of tasks learned rather than epochs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a critical issue or how it impacts the paper\"s conclusions. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, specifically the limited number of tasks used in the experiments. It suggests that the authors should include more tasks (at least 10) and present results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction to enhance the comprehensiveness and robustness of their experiments. However, the comment could be more helpful if it included additional guidance on how to select or design these tasks or provided examples of what kind of results would be beneficial. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their experimental design."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include more types of sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This feedback provides a clear and direct action for the authors to take, specifying which additional tasks should be considered. The comment is specific and offers concrete guidance on how to enhance the scope of the experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted on sentence similarity tasks and open domain QA tasks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the experiments, namely the inclusion of additional sentence pair tasks like MNLI and RTE. The suggestion to conduct experiments on these tasks provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as MNLI and RTE. The comment provides specific examples of tasks that are common in the NLP field, which supports the claim by indicating the range of tasks that could be included. This level of detail provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or papers that have explored these tasks, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments conducted by the authors, specifically noting that they only evaluate on sentence similarity tasks and open domain QA tasks. It suggests that the authors should consider conducting experiments on additional sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding the scope of their experiments. By addressing this suggestion, the authors can enhance the comprehensiveness and applicability of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the inclusion of the prompt in the appendix or supplement, suggesting that it might be in a supplement that the reviewer cannot access. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should follow to ensure the prompt is included. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the inclusion of the prompt in the appendix or supplement, suggesting that it might be in a supplement that the reviewer cannot access. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the prompt\"s inclusion are problematic or how it should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the inclusion of the prompt in the appendix or supplement, suggesting that it might be in a supplement that the reviewer cannot access. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a critical issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the inclusion of the prompt in the appendix or supplement, suggesting that it might be in a supplement that the reviewer cannot access. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback lacks actionable advice and does not offer a clear path for the authors to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity might not appear in earlier layers. While the comment implies that the authors should provide a clearer explanation for their choice of analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain their reasoning for focusing on the last layer. However, the comment does not provide specific guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity might not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the motivation for the analysis choice, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity might not appear in earlier layers. However, it does not provide any supporting evidence, reasoning, or references to justify the claim or explain the potential implications of this choice. Without additional context or justification, the claim remains 1, as it lacks the necessary details to support the authors\" understanding of the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the motivation for analyzing only the last convolutional layer, specifically asking why numerosity might not appear in earlier layers. This question prompts the authors to clarify their reasoning and provide a more detailed explanation of their analysis choice. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it encourages the authors to clarify their methodology, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the problem of setting the parameter S, but it does not provide any explicit or implicit suggestions on how to address this issue. The comment lacks any guidance or actionable steps for the authors to take, leaving them uncertain about what changes or improvements are needed. Without specific advice or examples, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the problem of setting the parameter S, but it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of parameter S, but without clear guidance on how to address it, the authors may struggle to understand the exact area needing improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the problem of setting the parameter S, but it does not provide any claim, opinion, or suggestion that requires verification. It is purely a question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the problem of setting the parameter S, which is a common issue in many research papers. However, it does not provide any specific guidance, suggestions, or insights on how to address this problem or improve the paper. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to resolve this issue. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing due to the potential misleading nature of automatic evaluation metrics. However, it does not provide explicit guidance on how to implement this suggestion, such as recommending specific methods or tools for human evaluation. The action is implicit, as the authors can infer that they need to consider human evaluation, but it lacks concrete details on how to execute this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing due to the potential misleading nature of automatic evaluation metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the evaluation is discussed. Without explicit references, the authors may find it challenging to identify the exact part of the paper that needs attention. While the comment is specific in its suggestion, it lacks grounding as it does not provide clear guidance on where to apply the suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing due to the potential misleading nature of automatic evaluation metrics. However, the comment lacks specific examples or references to support the claim that automatic metrics can be misleading. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing, as it addresses a potential limitation of relying solely on automatic evaluation metrics. This feedback is 3 as it identifies a specific area for improvement and provides a rationale for why human evaluation might be more reliable. However, the comment could be more helpful if it offered suggestions on how to implement human evaluation or provided examples of how this could be done. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the introduction, noting that the claim about not requiring tuning a free parameter is technically true, but the choice of employing different constraints (convex, concave, increasing, decreasing) can be seen as a hyperparameter that needs tuning. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The feedback implies that the authors should consider the tuning aspect of these constraints, but it lacks concrete steps or examples for how to implement this change. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the introduction, specifically pointing out a claim about shape constraints not requiring tuning a free parameter. It highlights that the choice of employing convex or concave constraints, and increasing/decreasing constraints, can be seen as a hyperparameter that needs tuning. However, the comment does not specify which part of the introduction this claim is made in, making it weakly grounded. The comment is specific in detailing what the authors need to consider regarding the tuning of these constraints. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction incorrectly states that \"these shape constraints do not require tuning a free parameter.\" The reviewer argues that while technically true, the choice of employing convex or concave constraints, and increasing/decreasing constraints, can be seen as a hyperparameter that needs tuning. This claim is 3 as it provides a logical reasoning for the need to consider these constraints as hyperparameters, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction, specifically the claim that \"these shape constraints do not require tuning a free parameter.\" While technically accurate, the comment points out that the choice of employing convex or concave constraints, and increasing/decreasing constraints, can be seen as a hyperparameter that needs tuning. This feedback is 3 as it highlights a subtle but important aspect of the introduction that may impact the interpretation of the constraints. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or suggested ways to clarify the statement. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the theoretical proof for convergence appears trivial and lacks substantial novelty and rigor. It suggests that the proof could be trivially adapted with straightforward modifications based on the assumption that $X$ is i.i.d. and the modification in Appendix C. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific modifications to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof\"s rigor and possibly explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical proof for convergence, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof being trivial and suggests that it could be trivially adapted with modifications based on the assumption that $X$ is i.i.d. and the modification in Appendix C. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial and lacks substantial novelty and rigor. It supports this claim by noting that the paper claims $Z$ is noni.i.d., but Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$ as $A^\top A / np$. The comment suggests that following Modification 1 in Appendix C, previous theorems can be trivially adapted with straightforward modifications. This reasoning provides a logical basis for the claim, as it explains the potential triviality of the proof and offers a path for improvement. However, the comment could be strengthened by providing more detailed examples or references to specific theorems that could be adapted. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial and lacks substantial novelty and rigor. It provides a clear explanation of the problem, pointing out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which could be addressed with straightforward modifications. This feedback is actionable as it guides the authors to reconsider the rigor and novelty of their theoretical proof. However, the comment could be more helpful if it offered specific suggestions on how to enhance the proof\"s rigor or provided examples of how to adapt the theorems. Overall, the comment is 4, as it directs the authors toward a meaningful improvement but lacks detailed guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the experimental setup borrowed from 2 is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback provides a clear and direct action for the authors to take, which is to mention this detail in their paper. The comment is specific and gives a concrete direction on how to improve the transparency and clarity of the experimental setup. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from 2 is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is supported by a logical reasoning that explains the nature of the experimental setup. However, the comment does not provide specific examples or references to substantiate the claim further, which could enhance its verifiability. Overall, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it directs the authors to explicitly mention this detail in their paper. By addressing this point, the authors can improve the transparency and clarity of their experimental setup, which is crucial for the reproducibility and understanding of their work. Therefore, the comment is 5, as it provides a direct and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the limited scope of the datasets and models used in the study, specifically noting that bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to take. The authors are left to infer that they need to expand their dataset and model evaluations to include more biases and advanced models, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited datasets and models used in the study, specifically mentioning that bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these datasets and models, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, such as additional biases and advanced models, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is limited in scope due to the lack of bias benchmarks beyond gender, race, and religion, and the absence of assessments on stateoftheart generative models like GPT. This claim is 3 as it highlights specific areas where the study could be improved, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to further explore these points to understand the full extent of the limitations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study\"s scope, specifically noting that the bias benchmarks only assess gender, race, and religion, and are missing assessments on stateoftheart generative models like GPT. This feedback is clear and actionable, as it highlights areas where the study could be expanded to include more comprehensive evaluations. By addressing these limitations, the authors can enhance the robustness and comprehensiveness of their research. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these additional biases and models into the study. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential conflict between two statements regarding the performance of the multienv model compared to the singleenv model. It suggests that the authors clarify this conflict, which is a direct and explicit action. However, the comment does not provide specific guidance on how to resolve the conflict or what aspects need to be clarified. While the action is clear, the lack of detailed instructions on how to address the conflict makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two statements regarding the performance of the multienv model compared to the singleenv model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of conflicting statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a conflict between two statements regarding the performance of the multienv model compared to the singleenv model. The reviewer suggests clarifying this conflict, but the comment does not provide any supporting evidence, reasoning, or references to justify why these statements are conflicting or how they should be resolved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential conflict between two statements regarding the performance of the multienv model compared to the singleenv model. It highlights the inconsistency in the claims made about the performance loss and the benefits of knowledge sharing. While the comment points out a critical issue, it lacks specific guidance or suggestions on how the authors might address this conflict or clarify the statements. This limits the comment\"s usefulness, as it provides insight into a problem but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citation for the metrics. While the comment implies that the authors should include more details about the metrics, it does not specify which metrics are mentioned or how they should be explained. The action is explicit but somewhat vague, as the authors know they need to provide more information about the metrics but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citation for the metrics. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its request for more detailed explanations or citations regarding the metrics, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citation for the metrics. However, the comment does not provide specific examples or references to support the claim that the metrics are insufficiently described. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the critique without further information. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the description of the metrics used. It suggests that providing an explanation or citation for the metrics would enhance the clarity and comprehensiveness of the paper. This feedback is clear and actionable, as it directs the authors to a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to effectively explain or cite the metrics, or if it provided examples of what kind of explanation would be beneficial. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear, and the representation of communication modes on the left side is confusing. While the comment highlights areas that need improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the figure clearer. The authors are left to infer that they need to improve the clarity of the figure, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions, and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as a confusing representation of communication modes on the left side. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it difficult to understand the specific issues with the figure. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear, and the representation of communication modes on the left side is confusing. This feedback is clear and actionable, as it highlights areas where the figure could be improved to enhance understanding. However, the comment could be more helpful if it provided suggestions on how to clarify these elements or offered specific examples of how to improve the figure\"s representation. Overall, the comment is 4 as it directs the authors\" attention to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the unclear meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this point. The action is implicit, as the authors can infer that they need to explain the term \"learned MASK embedding\" in their paper, but the comment does not specify how to do so. Therefore, the comment is 3, as it highlights an area for improvement but lacks concrete instructions on execution.", "grounding_specificity_rationale": "The comment raises a question about the unclear meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the confusion about the term \"learned MASK embedding,\" but it lacks detail on how this confusion impacts the paper or what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the unclear meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to clarify the confusion or suggest how this term should be interpreted. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to assist the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the unclear meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This feedback highlights a potential gap in the paper\"s explanation, which could hinder the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might clarify this point or improve the explanation. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential issue but lacks detailed guidance for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the reported results appear to be partially derivative, as they extend results from hypernetworks to standard networks, which are already presented in the literature. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. It lacks concrete details on what specific changes are needed or how to differentiate the results from existing literature. As a result, the authors are left without a clear understanding of what actions to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend results from hypernetworks to standard networks, which are already presented in the literature. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the results are derivative or how they should be differentiated from existing literature. Without specific references or detailed guidance, the authors cannot confidently determine which sections or elements need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend results from hypernetworks to standard networks, which are already presented in the literature. However, the comment lacks specific references or examples to support this claim, making it difficult for the authors to understand the basis of the criticism or how to address it. The absence of detailed evidence or reasoning makes the claim 2, as it provides some indication of a potential issue but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment points out that the reported results appear to be partially derivative, as they extend results from hypernetworks to standard networks, which are already presented in the literature. This observation highlights a potential issue with the novelty of the results presented in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or differentiate their results from existing literature. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues with the paper: the lack of motivation for the applications of the algorithms and the use of static datasets in the empirical analysis. While it points out these areas, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to add motivation for the applications and consider using dynamic datasets. However, the comment lacks concrete suggestions on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s introduction, specifically pointing out the lack of motivation for the applications of the algorithms and the use of static datasets. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for motivation and the use of static datasets, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of the algorithms and uses static datasets, which could make it less useful. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence for the claim makes it challenging to verify, leading to a score of 2.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for the applications of the algorithms and the use of static datasets in the empirical analysis. While it points out these areas, it does not provide specific suggestions or guidance on how to address them. The comment highlights the need for better motivation and suggests considering dynamic datasets, but it lacks actionable advice on how to implement these changes. This limits the comment\"s usefulness, as it offers some insight but not enough direction for the authors to make meaningful improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of specificity in the study\"s scope, noting that the work focuses on injecting a CoTbased approach to smallscale Language Models. It suggests that additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3. The comment implies that the authors should include these baselines to provide a more comprehensive understanding of the study\"s scope. However, it does not explicitly instruct the authors to add these baselines or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific action of adding baselines and may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of additional relevant CoT baselines for incontext learning of Large Language Models, particularly for text003 and ChatGPT. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the study\"s scope is underspecified, suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. It further implies that additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3. However, the comment does not provide specific examples or references to support the claim about the missing baselines, making it difficult for the authors to understand and address the issue. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the missing information themselves.", "helpfulness_rationale": "The review comment identifies a lack of specificity in the study\"s scope, noting that the work focuses on injecting a CoTbased approach to smallscale Language Models. It suggests that additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3. This feedback is 3 as it highlights a potential gap in the study\"s scope and provides a specific area for improvement by suggesting the inclusion of additional baselines. However, the comment could be more helpful if it offered guidance on how to identify and include these baselines or provided examples of relevant studies or models that could be referenced. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that Figure 3 is difficult to read, but it does not specify what aspects of the figure are hard to read or how the authors can improve the readability. The comment lacks explicit guidance or concrete suggestions on how to enhance the figure\"s clarity. Without specific details or actionable steps, the authors are left without a clear understanding of what needs to be done to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states the issue, which is that the figure is difficult to read anything on it. This provides the authors with a clear understanding of what needs to be addressed in terms of improving the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issues with Figure 3 or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with Figure 3, noting that it is difficult to read anything on the figure. However, it lacks any additional context, explanation, or suggestions on how the authors might improve the readability of the figure. Without further guidance or examples, the authors are left without actionable feedback on how to address this issue. Therefore, the comment is 2, as it identifies a problem but does not provide sufficient detail or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function for symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or incorporate the recent findings into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function for symmetric (orthogonal) order4 tensors. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function for symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function for symmetric (orthogonal) order4 tensors. This is a relevant point that could help the authors better understand the context and implications of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this question or incorporate these findings into their analysis. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to have the GAT (Graph Attention Network) reviewed by an English native speaker and to rewrite some sentences to improve clarity. These actions are clear and direct, providing the authors with specific steps to take for enhancing their draft. The comment is 5 as it offers concrete guidance on how to address the issues mentioned. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"245,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the GAT is trained with the whole model and that it needs to be reviewed by an English native speaker and rewritten for clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a statement about the GAT being trained with the whole model and a request for a native English review and sentence rewriting to improve clarity. The first part is a factual statement, while the second part is a request for improvement. Neither part contains subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific feedback on the draft, noting that the GAT (Graph Attention Network) is trained with the whole model and suggesting that it needs to be reviewed by an English native speaker and rewritten for clarity. This feedback is actionable, as it identifies a specific area for improvement and offers a clear path for the authors to enhance their draft. However, the comment could be more helpful if it provided additional guidance on how to rewrite the sentences or what aspects of the GAT\"s training should be reviewed. Despite this, the comment is 4 as it directs the authors toward a concrete step to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to consider. First, it suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a clear and direct action. Second, it questions the justification behind using a SGD learning rate of ~0.1, unlike the Adam default value, and suggests that the authors should provide a justification for this choice. Both actions are concrete and provide specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (119121 and 164) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues by suggesting a replacement for an expression and questioning the justification for a specific learning rate choice. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims: one about replacing an expression with a parameter and another about the justification for a specific learning rate. The first claim is a suggestion for a change, which does not require verification. The second claim questions the justification for a specific learning rate choice, which is a subjective opinion. However, the comment does not provide any supporting evidence or reasoning to substantiate the claim about the learning rate choice. Therefore, the second part of the comment is considered 2, as it lacks sufficient justification. Overall, the comment is 3 due to the mixed nature of its claims.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a clear and actionable change that could enhance the paper\"s clarity and robustness. Second, it questions the justification for using a SGD learning rate of ~0.1, unlike the Adam default value, and suggests that the authors should provide a justification for this choice. This feedback is 4 as it identifies areas for improvement and prompts the authors to clarify and justify their choices, which can lead to a more robust and transparent presentation of their work. However, the comment could be more helpful if it provided additional context or reasoning for the suggested changes. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors conduct error analysis to evaluate model performance and identify potential issues. It also encourages the authors to provide detailed explanations of the model\"s performance under different scenarios, which will aid in guiding subsequent improvements and expansions of the ERC research. The comment is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting error analysis to evaluate model performance and identify potential issues, and it encourages the authors to provide detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper should include this error analysis or where the detailed explanations should be provided. The authors can infer that this feedback pertains to the methodology or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in its suggestion to conduct error analysis and provide detailed explanations, but without grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. While the comment highlights the importance of error analysis, it lacks specific examples or references to support the claim that it is crucial. The suggestion to provide detailed explanations is logical, but the lack of detailed reasoning or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides valuable feedback by emphasizing the importance of error analysis in evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and offers detailed explanations of the model\"s performance under different scenarios, which can guide subsequent improvements and expansions of the ERC research. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their paper. However, it could be more helpful if it included examples or specific scenarios where error analysis would be particularly beneficial. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors analyze the domain gap and provide discussions about the gap between datasets. It also mentions that some datasets are closer, which might not be a significant issue, and suggests that the method\"s ability to finetune a pretrained model on synthetic data would enhance its value. While the comment provides some guidance on what aspects to consider, it lacks explicit instructions on how to conduct the analysis or what specific details to include in the discussions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and provides specific suggestions about discussing the gap between datasets and the potential value of finetuning a pretrained model on synthetic data. However, it does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestions about what needs to be addressed, such as discussing the domain gap and the potential value of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and provides specific suggestions about discussing the gap between datasets and the potential value of finetuning a pretrained model on synthetic data. While the comment highlights potential areas for improvement, it lacks detailed reasoning or evidence to support why these suggestions are necessary or how they would enhance the paper. The lack of specific examples or references makes it challenging for the authors to fully understand and address the feedback. Therefore, the comment is 3, as it provides a general direction but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by suggesting the analysis of the domain gap and the discussion of the gap between datasets. It also highlights the potential value of the method if it can finetune a pretrained model on synthetic data. While the comment identifies areas for improvement, it lacks detailed guidance or examples on how to conduct the analysis or what specific aspects to focus on. This makes the feedback 3, as it offers a direction for enhancement but does not fully support the authors in executing the suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the performance as the maximum number of identities increases, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore methods to scale up the system without performance degradation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance degradation with an increase in the maximum number of identities and suggests that the capacity should be preset to a small number, such as 10. The comment further questions whether the authors have considered scaling up without compromising performance, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance degrades as the maximum number of identities increases, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered scaling up without compromising performance. The claim is supported by the reference to Table 3, which provides a basis for the observation. However, the comment could be strengthened by providing more detailed analysis or examples of how the performance degrades with increasing identities. Overall, the comment is 4, as it provides a logical basis for the claim but lacks comprehensive evidence or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a critical issue with scalability, specifically noting that the performance degrades as the maximum number of identities increases, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. This feedback is valuable as it highlights a potential limitation in the methodology and prompts the authors to explore scalability issues, which is crucial for improving the robustness and applicability of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address scalability. Overall, the comment is 4, as it directs the authors toward an important area of consideration, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include at least one NCEbased method for comparison, referencing a specific work (1) that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. While the comment implies that the authors should include this method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the referenced method and understand how to incorporate it into their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific work (1) that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, the comment does not specify which part of the paper this suggestion pertains to, such as a section or a figure, making it weakly grounded. The suggestion is specific in terms of recommending the inclusion of a particular method, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a specific work (1) that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to a specific work that supports the suggestion. However, the comment lacks detailed reasoning or explanation about why this method is relevant or how it would improve the comparison. The authors would need to further explore the reference to understand the rationale fully, making the claim 3.", "helpfulness_rationale": "The review comment suggests that the authors include at least one NCEbased method for comparison, referencing a specific work (1) that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of a relevant method. However, the comment lacks depth and does not provide specific guidance on how to incorporate this method or why it would be beneficial for the paper. The authors would need to make significant effort to understand and implement the suggestion, which limits the comment\"s usefulness. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with the most recent LLMs. While the comment provides specific actions\u2014conducting significance tests and comparing with recent LLMs\u2014the instructions do not explicitly instruct the authors to do so. The actions are concrete, as they specify exactly what needs to be done, but they are not phrased as direct commands. Therefore, the comment is 4, as it provides clear guidance on how to enhance the experiment section.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically recommending the inclusion of significance tests on human evaluation results and comparisons with the most recent LLMs. However, it does not specify which part of the experiment section these improvements should be applied to, such as specific subsections or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in suggesting what needs to be improved, but without clear grounding, it is challenging for the authors to implement the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim. The authors would need to infer the importance of these suggestions without explicit guidance, making the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the experiment section. It suggests conducting significance tests on the human evaluation results and comparing the proposed method with the most recent LLMs. These suggestions are clear and offer a clear path for enhancing the robustness and relevance of the experimental results. By addressing these points, the authors can significantly improve the quality and impact of their work. Therefore, the comment is 4, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to discuss their claim about the lack of research on the joint error for UDA and to directly illustrate the relationship between their work and a previously studied work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" from ICML2019. The comment provides a clear and concrete action for the authors to take, which is to include a discussion and comparison with the referenced work. This guidance is specific and actionable, giving the authors a clear direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim about the lack of research on the joint error for UDA and references a specific work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely discussing the relationship between the referenced work and the proposed method, and why the proposed method is better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no research focusing on the joint error for UDA, but it references a previous work that has studied a similar problem. The comment provides a specific reference to \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019, which supports the claim by indicating that the issue has been previously addressed. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing a more detailed explanation of how the referenced work relates to the proposed method and why the proposed method is an improvement. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the lack of research on the joint error for UDA and provides a clear reference to a previous work that has studied a similar problem. It suggests that the authors should discuss this work and directly illustrate the relationship between it and their proposed method, explaining why their approach is better. This feedback is actionable and provides a concrete direction for the authors to enhance their draft by incorporating relevant literature and clarifying the novelty of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, suggesting that the performance of the paper may be influenced by the use of a newly collected largescale dataset. The reviewer points out that existing methods, such as GEM, use smaller datasets, which could impact accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to ensure a fair comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to adjust their comparison to account for dataset scale differences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the fairness of the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected largescale dataset and comparing it to existing methods like GEM, which use smaller datasets. This provides some grounding as it relates to the comparison section of the paper. However, the comment does not specify which part of the paper discusses the comparison with SOTA methods, making it weakly grounded. The comment is specific in detailing the issue of dataset scale impact on accuracy, which helps the authors understand what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a newly collected largescale dataset, which could impact accuracy. The reviewer provides a specific example, mentioning that GEM uses only 20M unlabeled data, while the paper uses a larger dataset. This example helps to support the claim by illustrating the potential impact of dataset size on performance. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods, suggesting that the performance of the paper may be influenced by the use of a newly collected largescale dataset. The reviewer points out that existing methods, such as GEM, use smaller datasets, which could impact accuracy. This feedback is 3 as it identifies a potential weakness in the comparison and highlights the importance of dataset scale in performance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue, such as normalizing the dataset sizes or comparing against methods that use similar datasets. Overall, the comment offers some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that several curriculum learning methods have been discussed in Section 1 but does not justify the need for designing a new method for text graphs. It also highlights a research gap regarding why existing methods can\u2019t be applied. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the research gap need to be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify the necessity of a new method and discuss the research gap. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for justifying the design of a new curriculum learning method for text graphs and points out a research gap regarding why existing methods can\u2019t be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that several curriculum learning methods have been discussed in Section 1 but does not justify the need for designing a new method for text graphs. It also points out a research gap regarding why existing methods can\u2019t be applied. However, the comment lacks specific examples or detailed reasoning to support the claim that existing methods are insufficient for text graphs. Without concrete evidence or references, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that several curriculum learning methods have been discussed in Section 1, but there is no justification for designing a new method for text graphs. It also highlights a research gap regarding why existing methods can\u2019t be applied. This feedback is 3 as it directs the authors to address a critical issue in their work, suggesting that they need to justify the necessity of a new method and explore the limitations of existing approaches. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these gaps. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT or XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of relying on the simplest ngram features. This feedback provides a clear and explicit action for the authors to take, specifying which models to use and what comparison to make. The comment is concrete, as it offers specific guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT or XLNet as the base encoder for all methods and then comparing the efficacy of the transfer parts instead of relying on the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using powerful pretrained language models like BERT or XLNet can help overcome the domainshift problem in NLP. It suggests that the authors should use these models as the base encoder and compare the efficacy of the transfer parts instead of relying on simple ngram features. The claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors would need to further explore and substantiate this suggestion to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends using powerful pretrained language models like BERT or XLNet as the base encoder for all methods and then comparing the efficacy of the transfer parts instead of relying on simple ngram features. This feedback is specific and offers a concrete direction for enhancing the methodology and results sections of the paper. By following this suggestion, the authors can potentially improve the robustness and effectiveness of their approach. However, the comment could be more helpful if it included examples or further elaboration on how to implement this suggestion. Overall, the comment is 4, as it provides valuable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it includes several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or merely the increased number of parameters. The comment also points out that the current ablation study does not provide definitive answers to these questions. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to conduct a more detailed ablation study or to provide specific suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should enhance their analysis to clarify the source of performance gains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which includes several complicated modules and has more parameters than the baselines. It raises a concern about whether the main performance gain is due to a specific module or merely the increased number of parameters. The comment also mentions the current version of the ablation study, which does not provide definitive answers to these questions. However, the comment does not specify which part of the paper discusses the ablation study or the specific modules being compared, making it weakly grounded. The comment is specific in identifying the issue of unclear performance attribution and the lack of definitive answers in the ablation study. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the proposed method, noting that it includes several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or merely the increased number of parameters. The comment also mentions that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or detailed reasoning to support the claim that the performance gain is not due to the increased number of parameters. Without concrete evidence or references, the claim is 3, as it highlights a potential issue but does not provide sufficient justification for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it includes several complicated modules and has more parameters than the baselines. It raises a valid concern about whether the main performance gain is due to a specific module or merely the increased number of parameters. The comment also points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should conduct a more detailed analysis to clarify the source of performance gains. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more explanation regarding why the two quantities are different and how this captures the difference in learning settings. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The comment also mentions that the reviewer leans toward acceptance, implying that the authors should consider the feedback. While the action is implied, it is vague and lacks concrete guidance on how to address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the range \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for more explanation on why the two quantities are different and how this captures the difference in learning settings. Additionally, the reviewer expresses a leaning toward acceptance, suggesting that NIPS should have room for \"pure theory\" papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for more explanation regarding the difference between two quantities and its relevance to learning settings. It also includes a subjective statement about the reviewer\"s leaning toward acceptance, suggesting that NIPS should have room for \"pure theory\" papers. The first part of the comment is a request for clarification, which does not contain a claim. The second part expresses an opinion, which is subjective and not verifiable. Therefore, the comment is a mix of a request for clarification and a subjective opinion, making it 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper that requires more explanation, namely the difference between two quantities and its relevance to learning settings. This feedback is clear and actionable, as it directs the authors to provide additional context and justification for their claims. However, the comment also includes a subjective statement about the reviewer\"s leaning toward acceptance, which does not provide specific guidance on how to improve the paper. While the comment offers valuable feedback on a critical aspect of the paper, it could be more helpful if it included suggestions on how to address the issue or improve the explanation. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a direct and explicit request for the authors to provide additional analysis or discussion on this aspect of their work. The action is clear and concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional analysis, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional analysis, making it a normal statement.", "helpfulness_rationale": "The review comment requests a discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is specific and actionable, as it directs the authors to provide additional analysis or discussion on a critical aspect of their work. By addressing this point, the authors can enhance the comprehensiveness and depth of their paper, making it more robust and informative. However, the comment could be more helpful if it provided examples or guidance on how to conduct this analysis. Overall, the comment is 4, as it effectively identifies an area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two actions: first, to explore the applicability of the proposed framework with different policy gradient approaches, and second, to inquire about the number of random seeds used for learning the policies (DDPO and IPPG). The first action is explicit, as it clearly states what the authors should investigate. However, the second action is implicit, as it does not explicitly instruct the authors to provide information about the number of random seeds used. The comment is 3 because it provides a clear direction for one action but leaves the other action somewhat inferred, making it difficult for the authors to fully understand and execute both actions.", "grounding_specificity_rationale": "The comment suggests exploring the applicability of the proposed framework with different policy gradient approaches and inquires about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion relates to, such as specific sections or experiments. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for additional information about the number of random seeds used, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: a suggestion to explore the applicability of the proposed framework with different policy gradient approaches and a question about the number of random seeds used for learning the policies (DDPO and IPPG). The first part is a suggestion for further exploration, which does not contain a claim. The second part is a question seeking clarification, which also does not constitute a claim. Therefore, the comment is purely factual and descriptive, fitting the classification of \"No\".", "helpfulness_rationale": "The review comment suggests two potential areas for improvement. First, it proposes exploring the applicability of the proposed framework with different policy gradient approaches, which could provide valuable insights into the framework\"s versatility and robustness. Second, it questions the number of random seeds used for learning the policies (DDPO and IPPG), which is a critical factor in ensuring the reliability and reproducibility of the results. While the comment identifies specific areas for further investigation, it lacks detailed guidance or suggestions on how to conduct these explorations or analyze the results. Providing more specific advice or examples would enhance its helpfulness. Therefore, the comment is 3, as it offers some direction but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should evaluate its results on more datasets and tasks to strengthen the analysis and conclusions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper should evaluate its results on more datasets and tasks to strengthen the analysis and conclusions. However, it does not specify which datasets or tasks are currently being used, nor does it provide guidance on how to expand the analysis. The authors can infer that the paper is referring to the datasets and tasks mentioned in the paper, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific because it lacks detailed guidance on how to improve the analysis. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should evaluate its results on more datasets and tasks to strengthen the analysis and conclusions. However, the comment does not provide specific examples of additional datasets or tasks that could be used, nor does it offer any reasoning or evidence to support why this would be beneficial. Without detailed guidance or examples, the claim is 3, as it highlights a potential area for improvement but lacks the necessary details to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, noting that it only assesses results on a single dataset and task. This feedback is valuable as it highlights a potential weakness in the paper\"s scope and suggests a way to strengthen the analysis by expanding the evaluation to more datasets and tasks. However, the comment could be more helpful if it provided specific examples of additional datasets or tasks that could be considered, or if it offered guidance on how to conduct a more comprehensive evaluation. Overall, the comment is 3 as it points out an area for improvement but lacks detailed suggestions for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment indicates that the writing could be improved in some places, specifically mentioning two examples: the definition of \"relevant\" auxiliary model weights in Definition 2.1. The comment provides a specific area for improvement by asking for clarification on the definition, which gives the authors a clear and direct action to take. The suggestion is explicit and concrete, as it specifies what needs to be clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"relevant\" auxiliary model weights. This provides clear guidance on what the authors should do to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning two examples: the definition of \"relevant\" auxiliary model weights in Definition 2.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this specific part of the writing is difficult to interpret. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the writing, namely the definition of \"relevant\" auxiliary model weights in Definition 2.1. By pointing out that the current definition is difficult to interpret, the comment provides a clear and actionable suggestion for the authors to enhance the clarity of their writing. This feedback is valuable as it directs the authors to a specific part of their draft that needs refinement, helping them improve the overall quality and readability of their work. However, the comment could be more helpful if it offered additional guidance on how to clarify the definition or suggested alternative phrasing. Despite this, the feedback is 4 as it directs the authors toward a concrete area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA testing for privacy guarantees and recommends using ULiRA. However, it does not provide explicit guidance on how to address the issue of MIA testing robustness or how to implement the recommendation. The action is implicit, as the authors can infer that they need to investigate the robustness of their MIA testing and consider using ULiRA, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not sufficiently robust for privacy guarantees. It also recommends using ULiRA. However, the comment does not specify which part of the paper discusses MIA testing or where the authors should address the robustness issue. This makes it weakly grounded, as the authors cannot confidently determine which sections or aspects of the paper are being addressed. The comment is specific in detailing the issue with MIA testing and recommending ULiRA, but without grounding, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not sufficiently robust for privacy guarantees and recommends using ULiRA. However, the comment lacks specific reasoning or evidence to support why MIA testing is insufficient or how ULiRA would address this issue. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of MIA (Membership Inference Attack) testing as a metric for evaluating unlearning effectiveness, suggesting that its robustness for privacy guarantees is insufficient. It recommends using ULiRA as an alternative. While the comment highlights a specific concern and provides a suggestion for improvement, it lacks detailed guidance on how to address the issue or why MIA testing might be insufficient. The recommendation to use ULiRA is helpful, but the comment could be more actionable by providing further explanation or examples. Overall, the feedback is 3 as it points out a potential weakness and offers a suggestion for improvement, but it could be more comprehensive and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that it could also be presented in the context of kernel interpolation/smoothing. However, it does not provide explicit guidance or suggestions on how the authors should address this point or what specific changes should be made to the paper. The action is implicit and vague, as the authors are left to infer that they need to explore and possibly present these considerations in a different context. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting these considerations in the context of kernel interpolation/smoothing. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to consider kernel interpolation/smoothing, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting these considerations in the context of kernel interpolation/smoothing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that these considerations could also be presented in the context of kernel interpolation/smoothing. While the comment identifies a potential area for expansion or clarification, it lacks specific guidance or suggestions on how the authors might address this point. The feedback is 3 as it prompts the authors to consider a broader applicability of their work, but it does not provide actionable steps or detailed reasoning to support the suggestion. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations and procedures in the simulation or experimentbased evidence, as well as the confusion caused by unclear figures. It suggests that adding more details to the paper and/or supplementary information would help clarify what was done in each simulation. Additionally, it recommends including error bars and pvalues when statistical inferences are made. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific details to include or how to incorporate error bars and pvalues. The actions are somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the explanations, the lack of detailed procedures in simulations or experiments, and the confusion caused by unclear figures. The comment further specifies the need for more details in the paper and supplementary information to clarify what was done in each simulation, as well as the importance of including error bars and pvalues for statistical inferences. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are very qualitative and lack detailed procedures, particularly when simulation or experimentbased evidence is provided. It also points out that some figures are confusing, such as the unclear term \"sample count\" in Figure 2. The reviewer suggests that adding more details to the paper and supplementary information would help clarify the work done in each simulation. Additionally, the comment emphasizes the importance of including error bars and pvalues when statistical inferences are made. While the comment identifies specific issues, it lacks detailed examples or references to support the claim about the qualitative nature of the explanations or the confusion in figures. This makes the claim 3, as the authors would need to further investigate and address the issues themselves.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the need for more detailed explanations and procedures in the simulation or experimentbased evidence, as well as the lack of clarity in figures. It specifically points out the confusion caused by the term \"sample count\" in Figure 2 and suggests that adding more details to the paper and supplementary information would help clarify the work done in each simulation. Additionally, the comment emphasizes the importance of including error bars and pvalues when statistical inferences are made. This feedback is clear and actionable, providing the authors with specific suggestions for enhancing the clarity and comprehensiveness of their work. However, it could be more helpful if it included examples of how to incorporate these details or suggestions for improving the figures. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for claims that may be inspired from existing studies. It provides a specific example by mentioning Lines 5564 and the four critical factors identified in the paper. The comment is clear and concrete, as it specifies which parts of the paper need additional references and what those references should include. This provides the authors with a direct and actionable step to improve their draft by grounding the feedback in specific sections and requirements. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Lines 5564, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for supportive references for claims that may be inspired from existing studies. The comment provides an example of how this issue is addressed by mentioning the four critical factors identified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired from existing studies and suggests adding supportive references. The comment provides a specific example by mentioning Lines 5564 and the four critical factors identified in the paper. It references existing studies, which adds some support to the claim. However, the comment could be strengthened by providing more detailed references or examples of the existing studies mentioned. Overall, the claim is 4, as it is supported by logical reasoning and some evidence, but it could be more robust with additional references.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some claims may be inspired from existing studies. It suggests that the authors add supportive references to strengthen their claims. The comment is specific and provides a clear example of how this can be addressed by mentioning Lines 5564 and the four critical factors identified in the paper. By offering a concrete suggestion, the comment provides the authors with actionable feedback that can help improve the credibility and originality of their work. However, the comment could be more helpful if it included specific references to existing studies that the authors should consider. Overall, the feedback is 4 as it guides the authors toward a more robust and credible presentation of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and SEARN. This feedback provides a clear and explicit action for the authors to take, which is to include specific details about the algorithm settings. However, it does not offer concrete guidance on how to implement this suggestion, such as which settings to focus on or how to present them effectively. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and SEARN. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include details about the algorithm settings, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and SEARN. However, the comment lacks specific examples or detailed reasoning to support why this would be beneficial or how it would help the community. Without concrete evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and SEARN. This feedback is 3 as it identifies a specific area for improvement, which is the inclusion of detailed settings to provide a comprehensive review of the algorithm\"s advancements. However, the comment lacks depth and does not offer specific guidance on how to implement this suggestion or what aspects of the settings should be highlighted. While it points out a potential enhancement, it does not fully support the authors in making the necessary changes to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights an area of uncertainty regarding the generality of the specific examples presented in the paper. It points out that while the paper demonstrates specific examples of biases and prediction shifts, it does not clarify how general these situations are. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more context or analysis to clarify the generality of the examples, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular area of uncertainty regarding the generality of the examples presented, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generality of the examples presented in the paper, specifically regarding the bias of target statistics and the prediction shift of gradient values. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that these situations are not general. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty in the paper, namely the generality of the examples presented regarding biases of target statistics and prediction shifts of gradient values. It highlights that while the paper demonstrates specific examples, it does not clarify how general these situations are. This feedback is 3 as it points out a potential gap in the paper\"s analysis, prompting the authors to consider the broader applicability of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how to demonstrate the generality of the situations. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would benefit from including a few more datasets, particularly in the context of crosstask transferability. While the comment implies that additional datasets could enhance the study, it does not explicitly instruct the authors to include them or specify which datasets would be most beneficial. The action is implicit and somewhat vague, as the authors need to infer that adding more datasets is a recommended improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors would benefit from including additional datasets, particularly concerning crosstask transferability. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where these datasets could be relevant. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the need for more datasets, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors would benefit from including additional datasets, particularly concerning crosstask transferability. However, the comment does not provide any specific reasoning or evidence to support why these additional datasets would be beneficial or how they would enhance the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors would benefit from including additional datasets, particularly concerning crosstask transferability. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on which datasets would be most beneficial or how they could enhance the study. The feedback is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks presented are somewhat standard and recommends the inclusion of unique tasks to showcase the diversity of the dataset. It provides an example of a potential task, such as Question Answering from images, which could be considered. While the comment implies that the authors should add these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these tasks and may not be entirely sure how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks presented are somewhat standard and recommends the inclusion of unique tasks to showcase the diversity of the dataset. It provides an example of a potential task, such as Question Answering from images, which could be considered. However, the comment does not specify which part of the paper discusses the tasks, making it weakly grounded. The suggestion for unique tasks is specific, as it provides a clear example of what could be added. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks presented are somewhat standard and recommends the inclusion of unique tasks to showcase the diversity of the dataset. The reviewer provides an example of a potential task, such as Question Answering from images, which could be considered. This provides a specific suggestion for improvement, making the claim 3. However, the comment could be strengthened by providing more examples or references to similar tasks in the literature, which would enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the tasks presented, noting that they are somewhat standard, specifically mentioning figure captioning and matching figures/subfigures to appropriate captions. It suggests that the authors could enhance the novelty and diversity of their work by introducing unique tasks, such as interleaved imagetext tasks like Question Answering from images. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by expanding the scope of tasks and demonstrating the dataset\"s diversity. However, the comment could be more helpful if it offered additional examples or guidance on how to implement these unique tasks. Overall, the comment is 4 as it effectively guides the authors toward enhancing their work\"s originality and relevance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 3.1 on 3D Gaussian generation appears to follow the previous work, Luciddreamer, and suggests that the authors correct this claim. However, it does not specify whether the authors should provide additional details or evidence to support their assertion of novel effort. The action is implicit, as the authors need to infer that they should address the claim, but it is vague because it lacks concrete guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section appears to follow the previous work, \"Luciddreamer,\" and suggests that the authors correct this claim. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.1 on 3D Gaussian generation appears to follow the previous work, \"Luciddreamer,\" and suggests that the authors correct this claim. However, the comment does not provide any specific evidence, reasoning, or references to support this assertion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically noting that Section 3.1 on 3D Gaussian generation appears to follow the previous work, \"Luciddreamer.\" This observation prompts the authors to reconsider the novelty of their contribution in this section. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it highlights a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an action for the authors to consider: sparsifying the trained models on the lefthand side of Figure 3 to reduce the number of selected features and compare the accuracy to the proposed model. This is a clear and explicit action with concrete guidance on how to implement it. The authors know exactly what needs to be done to address the suggestion, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete action for the authors to take: sparsifying the trained models on the lefthand side of Figure 3 to reduce the number of selected features and compare accuracy to the proposed model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests an action for the authors to consider, specifically sparsifying the trained models on the lefthand side of Figure 3 to reduce the number of selected features and compare accuracy to the proposed model. However, the comment does not provide any justification or reasoning for why this action is necessary or beneficial. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to consider: sparsifying the trained models on the lefthand side of Figure 3 to reduce the number of selected features and compare accuracy to the proposed model. This feedback is clear and actionable, providing the authors with a concrete step to enhance their analysis and potentially improve the paper\"s contribution. However, the comment could be more helpful if it explained why this sparsification is important or how it might impact the results. Despite this, the suggestion is valuable and offers a clear path for improvement, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several areas where the paper lacks detail, making it difficult for readers to reproduce the results. It specifically points out the need for more information about the techniques used, particularly the sparsification process, which is crucial for extracting landmark features. The comment also raises questions about how to generate landmarks on the edge, decide the number of landmarks used, what kind of image features are considered, the fixed radius with different scales, and how to achieve shape invariance. These questions provide clear and explicit guidance for the authors to address the lack of detail in their work. The comment is 5 as it directly instructs the authors on what specific information is missing and how to improve the reproducibility of their results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail about the techniques and the sparsification process, which is crucial for extracting landmark features. It also provides specific questions about the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This level of detail allows the authors to accurately identify the parts of the paper that need improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detailed information about the techniques and makes it difficult to reproduce the results. It provides specific examples of areas where the paper is unclear, such as the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. These specific questions and examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support these claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of detailed information about the techniques used, which makes it difficult for readers to reproduce the results. It specifically highlights the importance of the sparsification process for extracting landmark features and raises several questions about the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. These questions provide clear and actionable feedback that can guide the authors in improving the clarity and reproducibility of their work. The comment is 4 as it offers specific areas for improvement and directs the authors\" attention to critical aspects of their methodology that need further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the Appendix H section should be reorganized, but it does not provide specific guidance on how to achieve this reorganization or what aspects of the section are difficult to follow. The action is implicit, as the authors can infer that they need to reorganize the section, but the lack of concrete details makes it vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Appendix H,\" providing full grounding as the authors can accurately identify the section being addressed. It also specifies the issue, which is that the section is difficult to follow and should be reorganized. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Appendix H should be reorganized,\" but it does not provide any reasoning or evidence to support this claim. There is no explanation of why the section is difficult to follow or what specific issues exist. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the Appendix H section is difficult to follow, suggesting that it should be reorganized. However, it lacks specific guidance on how to reorganize the section or what aspects are problematic. Without detailed suggestions or examples, the authors may struggle to understand what needs to be improved. While it identifies an area for improvement, the comment is vague and lacks actionable advice, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper\"s comprehensiveness, noting that while the pseudocode in the supplementary material provides some details, it is insufficient for reproducibility. The reviewer suggests that the paper should be written to provide an intuitive understanding but also include more technical details necessary for reproduction, such as specifics about the RNN implementation. However, the comment does not explicitly instruct the authors to add these details or provide a clear path for how to do so. The action is implicit and somewhat vague, as the authors know they need to include more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplementary material\" and the \"pseudocode,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detailed technical information necessary for reproducibility, such as details about the RNN implementation. The comment provides a clear request for additional details to be included in the paper or supplementary material. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient details for reproducibility, even with the provided pseudocode. The reviewer suggests that more technical details, such as specifics about the RNN implementation, are missing. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the missing details themselves, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s comprehensiveness, noting that while the pseudocode in the supplementary material provides some details, it is insufficient for reproducibility. The reviewer highlights the need for more technical details, such as specifics about the RNN implementation, to enable reproducibility. This feedback is clear and actionable, as it directs the authors to include additional details that are necessary for others to reproduce the work. However, the comment could be more helpful if it provided specific examples of the missing details or suggested where these details should be included. Overall, the comment is 4, as it effectively guides the authors in enhancing the reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and/or more random trials to potentially eliminate random fluctuations in the results. While the comment provides a clear direction for improvement, it does not specify how to implement these changes, such as which error bars to include or how many additional random trials are needed. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what could be improved: the inclusion of error bars and/or more random trials to potentially eliminate random fluctuations in the results. This level of detail helps the authors understand exactly what changes are needed to enhance the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger if it included error bars and/or more random trials to potentially eliminate random fluctuations in the results. While the comment provides a logical suggestion for improving the figure, it lacks specific examples or references to support the claim. The authors may find it challenging to understand the exact nature of the improvements needed without further elaboration. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving Figure 1 by suggesting the inclusion of error bars and/or more random trials. This feedback is clear and directly addresses a potential weakness in the presentation of the results, offering a concrete way to enhance the clarity and robustness of the figure. By providing these suggestions, the comment empowers the authors to make a meaningful improvement to their draft, making it 4. However, it could be more helpful if it included additional context or explanation on why these changes are necessary or how they might impact the interpretation of the results. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence of points in Figure 1. While the comment explicitly states the actions to be taken, it lacks specific guidance on how to introduce energy models or clarify the correspondence in the figure. The authors know they need to address these issues but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific request for improvement. It also points out that Figure 1 does not clarify which points correspond to different learning rates in the left graph and different steps in the right graph. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the Related Work section and Figure 1, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence of points in Figure 1. The suggestion is based on the need for clarity and context, which is a common request in academic writing. However, the comment lacks specific examples or references to support the claim that energy models are not adequately covered. While the authors might infer that energy models are relevant, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed justification or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. This is a clear and direct suggestion that can help improve the paper\"s context and understanding. Additionally, the comment points out a lack of clarity regarding the correspondence of points in Figure 1, which is a specific issue that the authors need to address. While the comment does not provide detailed guidance on how to clarify the figure, it effectively highlights areas for improvement that are crucial for the paper\"s comprehensibility. Therefore, the comment is 4, as it offers clear directions for enhancing the draft but could be more comprehensive with additional guidance on the figure clarification."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance, suggesting that relying solely on utility scores might introduce biases. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve their approach. The comment implies that the authors should consider alternative methods or additional criteria to mitigate the potential biases, but it lacks concrete steps or examples for implementation. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED for determining chunk significance, suggesting that relying solely on utility scores might introduce biases. However, it does not specify which part of the paper discusses this approach, making it weakly grounded. The comment is specific in identifying the potential issue with the utilitybased approach and suggests a possible bias, providing some guidance on what might need to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning that recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. The comment provides a logical reasoning by highlighting the potential for bias in the utilitybased approach. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern, thus aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It highlights a concern that relying solely on utility scores might introduce biases, particularly the risk of premature evictions of valuable chunks due to temporary high utility scores. This feedback is valuable as it points out a critical weakness in the methodology, suggesting that the authors need to consider alternative approaches or additional criteria to mitigate potential biases. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the first paragraph of the Introduction is focused on a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The reviewer suggests that this section is not central to the paper and provides little value to readers. However, the comment does not explicitly instruct the authors to remove or revise this section, nor does it provide specific guidance on how to integrate driftrelated content more effectively. The action is implicit and somewhat vague, as the authors can infer that they need to revise the introduction to better align with the paper\"s focus but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the introduction is focused on a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The comment provides a clear suggestion for improvement by indicating that the DNNrelated introduction is not central to the paper and offers little value to readers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is focused on a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The reviewer argues that this section is not central to the paper and provides little value to readers. However, the comment lacks specific examples or references to support the claim that the introduction is not relevant or valuable. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the Introduction section, noting that it is focused on a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. This feedback is clear and actionable, as it highlights a key area that needs revision to align the Introduction with the paper\"s core focus. However, the comment could be more helpful if it provided suggestions on how to integrate driftrelated content more effectively or offered guidance on how to revise the Introduction to better reflect the paper\"s focus. Despite this, the comment is 4 as it directs the authors\" attention to an important aspect of their draft that needs improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance and contribution of different parts of the framework from an experimental perspective. It suggests that the authors should include quantitative experiments and comparisons between algorithms or provide more detailed explanations to clarify the framework\"s performance. While the comment identifies a specific area for improvement, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework from an experimental perspective. It specifically mentions the result section, where the framework yields promising visual stimuli results, but lacks quantitative experiments and comparisons between algorithms or detailed explanations. The comment is fully grounded as it explicitly mentions the result section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in terms of experimental validation and detailed explanations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental results regarding the performance and contribution of different parts of the framework. It suggests that the result section lacks quantitative experiments and comparisons between algorithms or detailed explanations. The comment is 3 as it provides a logical reasoning for the issue, indicating that the authors need to include more detailed experimental evidence to clarify the framework\"s performance. However, it lacks specific examples or references to support the claim, which would make it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s experimental results, specifically regarding the clarity of how different parts of the framework contribute to the final result. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments and comparisons between algorithms or detailed explanations. This feedback is clear and actionable, as it directs the authors to include additional experimental evidence and detailed explanations to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on what kind of experiments or comparisons to include. Overall, the comment is 4, as it effectively guides the authors in improving their draft by addressing a critical area of clarity and detail."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses uncertainty about whether the model could generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they could take to clarify the potential of their model. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model could generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this concern pertains to, such as specific sections, experiments, or discussions. Without explicit references to sections or elements of the paper, the authors cannot confidently determine where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the model or data are unclear. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses uncertainty about whether the model could generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the novelty and testability of the model in generating knowledge or hypotheses regarding neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed examples, the authors are left without a clear understanding of what aspects of their work need improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors present a simplified version of Theorem 2 for the general audience, as it is currently difficult to understand on its own. This feedback is explicit, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to simplify Theorem 2 or what specific aspects should be made more accessible. The authors know they need to provide a simplified version, but they may not be entirely sure how to execute this task effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests presenting a simplified version of Theorem 2 for the general audience, implying that it is currently difficult to understand on its own. However, it does not specify which part of the paper this suggestion pertains to, such as the section where Theorem 2 is discussed. The authors might infer that it relates to the discussion or results section, but this inference is not direct. The comment is specific in suggesting a simplification, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult to understand on its own, implying that a simplified version for the general audience would be beneficial. However, the comment does not provide specific examples or reasoning to support why Theorem 2 is particularly challenging to comprehend. Without detailed justification or examples, the claim remains vague and lacks sufficient evidence to be 5. Therefore, the comment is categorized as 2, as it provides some insight but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand on its own. This feedback is actionable, as it provides a clear direction for the authors to enhance the accessibility and comprehensibility of their work. However, the comment could be more helpful if it offered specific guidance on how to simplify the theorem or what aspects of the theorem should be made more accessible. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting experiments with larger resolutions to evaluate performance, but it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit, as the authors can infer that they need to adjust their experiments, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests conducting experiments with larger resolutions, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure where the experiments are described. The authors can infer that it pertains to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not explicitly mention the section, but it is specific in its suggestion. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments with larger resolutions to evaluate performance, but it does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. The comment lacks specific examples or explanations that would help the authors understand the potential impact of this suggestion. As a result, the claim is 1, as it does not provide sufficient justification or context for the proposed change.", "helpfulness_rationale": "The review comment suggests conducting experiments with larger resolutions to evaluate performance, which is a relevant and actionable suggestion. It provides a clear direction for the authors to consider, potentially leading to improvements in the robustness and generalizability of their results. However, the comment could be more helpful if it included specific details on how to implement this suggestion or why larger resolutions might be beneficial. Overall, the feedback is 3 as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the keypoint mask averaged feature vector and suggests that it might be equivalent to simply multiplying each feature map elementwise by H_psi. However, it does not provide explicit guidance or suggestions on how the authors should address this observation or clarify it in their draft. The action is implicit, as the authors can infer that they need to explain or clarify this point, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide specific instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific question about the \"keypoint mask averaged feature vector,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the comment is asking about, namely whether the keypoint mask averaged feature vector is equivalent to simply multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the keypoint mask averaged feature vector and its equivalence to multiplying each feature map elementwise by H_psi. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the keypoint mask averaged feature vector and suggests that it might be equivalent to simply multiplying each feature map elementwise by H_psi. While this observation is intriguing, the comment does not provide any guidance or suggestions on how the authors might address this point or clarify it in their draft. It lacks actionable feedback or detailed insights that could help the authors improve their work. As a result, the comment is not particularly helpful and does not align with the criteria for a helpful review comment. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors make use of styles, such as dashed lines, or add color to differentiate between the different curves in Figure 2. This provides clear and concrete actions for the authors to take, ensuring they know exactly how to improve the figure. The suggestion is direct and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure, suggesting the use of styles (e.g., dashed lines) or adding color to differentiate between the curves. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that Figure 2 is difficult to distinguish between different curves and recommends using styles or color to differentiate them. While the suggestion is logical and provides a clear direction for improvement, it lacks specific examples or detailed reasoning on why the current figure is problematic or how the suggested changes would address the issue. The comment is 3 as it offers a reasonable suggestion but could be strengthened with more detailed justification or examples. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Figure 2, namely the difficulty in distinguishing between different curves. It provides a clear and actionable suggestion to improve the figure by using styles, such as dashed lines, or adding color. This feedback is valuable as it guides the authors on how to enhance the clarity and readability of their figure, which is crucial for effectively communicating their results. However, the comment could be more helpful if it included additional suggestions or examples of how to implement the proposed changes. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should tone down the introduction and not refer to the task as language learning, as it is more accurately described as a feedbackdriven question answering in the form of a dialog. This feedback provides a clear and explicit action for the authors to take, which is to revise the introduction to better reflect the nature of the task. The comment also offers a specific suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the claims made in the introduction, suggesting that they are inconsistent with the tasks and models described. It recommends toning down the introduction and not referring to the task as language learning, instead describing it as a feedbackdriven question answering in the form of a dialog. This feedback is specific in its critique of the claims and provides a clear direction for improvement. However, it does not explicitly mention which part of the introduction is problematic, making it weakly grounded. The authors can infer that it relates to the introduction, but the lack of explicit grounding reduces the score. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the claims in the introduction are inconsistent with the tasks and models described, suggesting that the task should be referred to as feedbackdriven question answering rather than language learning. The reviewer provides a logical reasoning by explaining the discrepancy between the labels and the evaluation method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are inconsistent with the tasks and models described. It suggests that the task should be referred to as feedbackdriven question answering rather than language learning. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their introduction. By addressing this critique, the authors can enhance the alignment between their claims and the actual content of their work, making the comment 5. However, the comment could be more helpful if it offered additional suggestions on how to revise the introduction or examples of how to present the claims more accurately. Overall, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the central contribution of the paper, specifically regarding the modeling of weight evolution using ordinary differential equations (ODEs). It suggests that the issue of neural ODEs exhibiting inaccuracy during activation recomputation was previously reported in another paper, and the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment implies that the authors should provide more evidence or reasoning to substantiate their contribution, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should strengthen their argument with additional evidence or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically regarding the modeling of weight evolution using ODEs. It mentions a previous paper that reported an issue with neural ODEs, and the current paper lacks convincing analytical or empirical evidence to support this claim. However, the comment does not specify which part of the paper discusses this issue or where the previous paper is referenced, making it weakly grounded. The comment is specific in detailing the issue with the modeling approach and the lack of evidence, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the central contribution of the paper, specifically regarding the modeling of weight evolution using ODEs. It suggests that the issue of neural ODEs exhibiting inaccuracy during activation recomputation was previously reported in another paper, and the current paper lacks a convincing analytical argument or empirical evidence to support this claim. The comment provides a logical reasoning by referencing a previous paper and the absence of evidence, which supports the claim. However, it could be strengthened by providing specific references or examples from the previous paper to substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment raises a valid concern about the central contribution of the paper, specifically regarding the modeling of weight evolution using ordinary differential equations (ODEs). It questions the novelty of the approach, suggesting that the issue of neural ODEs exhibiting inaccuracy during activation recomputation was previously reported in another paper. The reviewer expresses doubt about the current paper\"s contribution and lacks convincing evidence or analytical arguments to support the claim. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and prompts the authors to provide more evidence or reasoning to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this concern. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a certain period. This is an explicit action, as it clearly indicates what the authors should consider adding to their draft. However, it does not provide specific guidance on how to implement this suggestion, such as whether to mention the duration or the context in which this observation is relevant. While the action is clear, the lack of detailed instructions on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors might want to mention that the algorithms follow the sampled policy for a certain period. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a certain period. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it impacts the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the authors might want to mention that the algorithms follow the sampled policy for a certain period. This feedback is actionable and offers a clear direction for enhancing the clarity and completeness of the paper. However, it could be more helpful if it provided additional context or explanation on why this information is important or how it impacts the overall understanding of the paper. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that proving lower bounds for round complexity is a major part of work in batched ranking problems. However, it points out that the paper uses an easy reduction from collaborative ranking, making the lower bound results a corollary of these results. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to reconsider their approach or provide more detailed analysis to justify the lower bound results. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of proving lower bounds for round complexity in the context of batched ranking problems. It highlights that the paper uses an easy reduction from collaborative ranking, making the lower bound results a corollary of these results. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the issue of lower bounds and the potential ease of deriving them from collaborative ranking results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a major part of work in batched ranking problems, but the paper uses an easy reduction from collaborative ranking, making the lower bound results a corollary. This claim is 3 as it provides a logical reasoning for the assertion, explaining how the paper\"s approach leads to the lower bound results. However, the comment lacks specific examples or references to support the claim fully, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach, specifically noting that proving lower bounds for round complexity is a significant part of work in batched ranking problems. However, the paper claims that it uses an easy reduction from collaborative ranking, making the lower bound results a corollary of these results. This feedback highlights a gap in the paper\"s contribution and suggests that the authors might need to reconsider their approach or provide more detailed analysis to justify the lower bound results. While the comment points out a potential weakness, it lacks specific suggestions or guidance on how the authors could address this issue. Therefore, the comment is 3, as it provides insight into a potential area for improvement but does not offer detailed guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of large language models (LLMs). It implies that the authors should consider using more carefully curated prompts to improve the results of generating systematic reviews. While the comment suggests an action\u2014using better prompts\u2014the feedback does not provide specific guidance on how to implement this suggestion or what specific prompts should be used. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of large language models (LLMs). It implies that using more carefully curated prompts could yield better results. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use better prompts is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of large language models (LLMs). The reviewer suggests that carefully curated prompts could yield better results. However, the comment lacks specific examples or references to support the claim that the current prompts are basic or insufficient. Without detailed evidence or examples, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study, specifically the basic nature of the prompting technique used, which does not fully leverage the capabilities of large language models (LLMs). It suggests that using more carefully curated prompts could yield better results in generating systematic reviews. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the use of better prompts. However, the comment could be more helpful if it offered examples of what constitutes \"better\" prompts or how the authors might implement this suggestion. Overall, the comment is 4 as it highlights an area for enhancement and provides a constructive suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the performance of the models presented in Table 4, noting that the results are behind more recent models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements, additional experiments, or comparisons with the mentioned models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear comparison with more recent models, mentioning specific results from GLaMM and UNINEXT, which helps the authors understand the issue and how to address it. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on \"REC and RES\" is behind more recent models, providing specific examples of results from GLaMM and UNINEXT. This claim is supported by explicit references to specific models and their performance metrics, making it 5. The authors can easily understand and address the feedback by incorporating these references and results into their analysis.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models presented in Table 4, noting that the results are behind more recent models. It provides concrete examples of how other models, such as GLaMM and UNINEXT, perform on similar metrics, which can help the authors understand the context and potential areas for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or how to improve the performance of the models in question. Overall, the feedback is 3 as it highlights a clear area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"evidence\" used in the paper is too strong and recommends using a more precise term like \"Fig.\" However, the comment does not specify which part of the paper this feedback is related to, nor does it provide detailed guidance on how to revise the term or what alternative phrasing to use. The action is implicit and vague, as the authors are left to infer that they need to revise the term \"evidence\" to a more appropriate one, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the term \"evidence\" is too strong and recommends using a more precise term like \"Fig.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"evidence\" used in the paper is too strong and recommends using a more precise term like \"Fig.\" However, the comment does not provide any supporting evidence or reasoning to justify why \"evidence\" is too strong or what specific aspects of the paper should be revised. Without additional context or explanation, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"evidence\" in the paper, suggesting that it is too strong and recommending a more precise term like \"Fig.\" This feedback is 3 as it points out a specific area for improvement in the language used in the paper. However, it lacks depth and does not provide further guidance on how the authors might address this issue or what alternative phrasing could be used. The comment could be more helpful if it offered suggestions on how to revise the term or provided examples of more appropriate language. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, which is similar to the approach used in ConsiStory. The comment points out that the only notable difference is the use of CLIPseg and OTSU segmentation instead of crossattention. However, it does not provide any explicit or implicit suggestions for how the authors could address this limitation or enhance the novelty of their approach. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically noting that it primarily relies on framewise SDSA, which is similar to the approach used in ConsiStory. It highlights the only notable difference, which is the use of CLIPseg and OTSU segmentation instead of crossattention. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitations and differences in the approach, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, as it primarily relies on framewise SDSA, which is similar to the approach used in ConsiStory. The comment highlights the only notable difference, which is the use of CLIPseg and OTSU segmentation instead of crossattention. However, the comment lacks specific references or detailed comparisons to ConsiStory or other relevant works, making it 3. The authors would need to further explore the similarities and differences to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, which is similar to the approach used in ConsiStory. The comment highlights the only notable difference, which is the use of CLIPseg and OTSU segmentation instead of crossattention. While this feedback provides some insight into the potential lack of innovation, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their approach. As a result, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes. It recommends comparing the approach to previous ones in the context of fewshot classification on such a dataset. While the comment implies that the authors should conduct additional experiments or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes and recommends comparing it to previous approaches in the context of fewshot classification on such a dataset. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in suggesting a comparison to previous approaches, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes and recommends comparing it to previous approaches in the context of fewshot classification. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general direction for improvement but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, suggesting that its weakness would be more pronounced in images with multiple objects or cluttered scenes. It provides a specific suggestion for improvement by recommending a comparison of the approach to previous ones in the context of fewshot classification on such datasets. This feedback is clear and actionable, offering a concrete way for the authors to enhance their work by addressing the identified limitation. However, the comment could be more helpful if it included specific examples or datasets to consider, which would further guide the authors in their analysis. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed explanations of the bounds. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more explanation of the bounds, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide specific examples or detailed reasoning to support why this additional explanation would be beneficial. The lack of explicit justification or examples makes it difficult for the authors to understand the necessity of the suggested change. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment acknowledges the space limitations but suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. This feedback is 3 as it identifies a potential area for improvement and provides a direction for the authors to enhance their draft. However, the comment lacks depth and does not offer specific suggestions or examples on how to explain the bounds, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the kernels are implemented with OpenAI\"s Triton, not CUDA, and that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should consider this information, how it might impact their work, or what changes are needed. Without actionable advice or suggestions, the authors are left without a clear understanding of how to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the implementation of kernels with OpenAI\"s Triton, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that a fullpage explanation is unnecessary due to wellknown engineering improvements. This provides clear guidance on what the authors need to consider or address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the kernels are implemented with OpenAI\"s Triton, not CUDA, and that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a factual observation about the implementation of kernels using OpenAI\"s Triton instead of CUDA. It notes that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not offer any suggestions or guidance on how this information might impact the paper or what changes could be made to address it. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and suggestions regarding the zeroshot nature of the study and the transferability of the policy. It questions the claim that the transferability is limited by the difficulty of the source and target tasks, suggesting that the manipulation scenario might provide sufficient information for policy transfer. The reviewer implies that the authors should clarify these points in the paper to avoid misleading claims. While the comment does not explicitly instruct the authors to make these clarifications, it provides a clear direction for improvement. The action is implicit but concrete, as the authors know what needs to be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, such as the zeroshot nature of the study and the transferability of the policy. It questions the claim that the transferability is limited by the difficulty of the source and target tasks, suggesting that the manipulation scenario might provide sufficient information for policy transfer. The comment also implies that the authors should clarify these points in the paper to avoid misleading claims. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be clarified or addressed, making it weakly grounded but specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the zeroshot nature of the study and critiques the claim that the transferability is limited by the difficulty of the source and target tasks. The reviewer provides a logical reasoning by comparing the difficulty of the source task (Walkerrun) to the target task (Walkerwalk) and suggests that the policy transfer might be possible. Additionally, the reviewer points out the complexity of the manipulation scenario, which could make policy transfer difficult. While the comment provides some reasoning, it lacks specific examples or references to support the claim fully. Therefore, the claim is 3, as it requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the study and challenges the claim that the transferability is limited by the difficulty of the source and target tasks. It provides a logical reasoning by comparing the difficulty of the source task (Walkerrun) to the target task (Walkerwalk) and suggests that the policy transfer might be possible. Additionally, the comment highlights the complexity of the manipulation scenario, which could make policy transfer difficult. It suggests that the authors should clarify these points in the paper to avoid misleading claims. While the comment identifies a significant issue and provides a clear direction for improvement, it could be more helpful by offering specific suggestions on how to address these concerns. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed methods compared to existing baselines, suggesting that the gains are not very strong. It also questions whether the proposed method would still be effective on larger backbone models like SwinB or SwinL. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is somewhat vague and lacks concrete steps for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the improvement of the proposed methods across different frameworks and tasks, noting that the relative gains are not very strong. It specifically mentions the baseline ResNet50 and suggests that the proposed methods achieve only a small gain. The comment also questions whether the proposed method would still work well on larger backbone models like SwinB or SwinL. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where these comparisons are typically addressed. The comment is specific in detailing the issue of relative gains and the potential effectiveness on larger models. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed methods are not very strong, particularly for most baselines, which only achieve a small gain on a relatively small backbone ResNet50. The reviewer suggests that the proposed method, which introduces global pooling, might be more effective on larger backbones like SwinB or SwinL. However, the comment lacks specific examples or detailed reasoning to support the claim that the gains are not strong or that the proposed method would perform better on larger models. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a concern about the relative gains of the proposed methods compared to existing baselines, noting that the gains are not very strong. It specifically mentions that the proposed methods achieve only a small gain on a relatively small backbone ResNet50. The comment also questions whether the proposed method would still be effective on larger backbone models like SwinB or SwinL. This feedback is 3 as it highlights a potential limitation of the proposed method and prompts the authors to consider the scalability of their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored alternative strategies to enhance the method\"s performance. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the analysis of neural networks contributes less and suggests that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their analysis. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or improvements are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analysis of neural networks and specifically mentions the extension from linear models to wide fullyconnected neural networks, referencing Section 3.2 and 3.3. This provides full grounding as the authors can accurately identify the part of the paper being discussed. The comment is also specific, as it highlights the triviality of the extension due to the existing NTK theorem and points out that the work bypasses the core problem of overparametrized neural networks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less due to the existing NTK theorem, which allows for a trivial extension from linear models to wide fullyconnected neural networks. The comment references specific sections (3.2 and 3.3) to support this claim, providing a clear rationale for the assertion. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Overall, the comment is 4, as it provides a logical basis for the claim but lacks additional depth and examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks, limiting the scope of the analysis. While the comment highlights a critical weakness in the paper, it lacks specific suggestions or guidance on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors\" attention to a specific area that needs clarification, but it could be more actionable with additional guidance on how to enhance the analysis. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results, noting that while there is good performance on ImageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. However, it does not provide any explicit or implicit suggestions for how the authors should address this gap. There is no guidance on whether the authors should include results for larger models, why this is important, or how it might impact the paper\"s conclusions. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ImageNet classification\" and the models \"ResNet50/34/18\" and \"ResNet101/152,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing results with larger models like ResNet101/152, which the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is good performance on ImageNet classification with ResNet50/34/18 but lacks results with larger models like ResNet101/152. This claim is 3 as it highlights a specific gap in the results, but it does not provide detailed reasoning or examples to support why this gap is significant or how it affects the paper\"s conclusions. The authors would need to infer the importance of including results for larger models, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the results, noting that while there is good performance on ImageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This feedback highlights an area where the authors could enhance their paper by including results for larger models, which might provide additional insights or validate the scalability of their approach. However, the comment lacks specific suggestions or guidance on how to address this gap or why it is important. While it points out a potential improvement, it does not offer detailed advice on how to implement it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential inconsistency in terminology regarding the cost of evaluating quantities of interest, noting that the abstract mentions \"relatively inexpensive\" while the introduction states \"expensive to evaluate.\" This creates confusion for the reader. However, the comment does not provide explicit guidance on how the authors should address this inconsistency or suggest a resolution. The action is implicit and vague, as the authors are left to infer that they need to clarify the terminology in their paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities of interest, such as probabilities of threshold exceedance, and references a specific paper by Stroh et al. (2017). However, it does not explicitly mention which part of the paper this discussion pertains to, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the terminology used in the abstract and introduction, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a confusion in terminology regarding the cost of evaluating quantities of interest, noting that the abstract mentions \"relatively inexpensive\" while the introduction states \"expensive to evaluate.\" However, the comment does not provide specific examples or references to clarify this confusion or suggest how the terminology should be clarified. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in terminology regarding the cost of evaluating quantities of interest, noting that the abstract mentions \"relatively inexpensive\" while the introduction states \"expensive to evaluate.\" This observation highlights a potential confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this inconsistency or improve the clarity of their terminology. While it points out a potential issue, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it requires subtaskspecific rewards, similar to a dense reward signal. It also poses a question about whether other methods, such as Qmix, can solve sparsereward tasks if given the sum of lowlevel rewards as the global reward. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The actions are implicit and vague, as the authors are left to infer that they need to clarify these points in their paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems and suggests that it requires subtaskspecific rewards, similar to a dense reward signal. It also poses a question about whether other methods, such as Qmix, can solve sparsereward tasks if given the sum of lowlevel rewards as the global reward. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in its questioning of the method\"s approach to sparse reward problems, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it requires subtaskspecific rewards, similar to a dense reward signal. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method does not support well in practice. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it requires subtaskspecific rewards, similar to a dense reward signal. It also poses a question about whether other methods, such as Qmix, can solve sparsereward tasks if given the sum of lowlevel rewards as the global reward. While the comment identifies a potential issue with the method\"s approach to handling sparse rewards, it lacks specific guidance or suggestions on how the authors might address this concern or improve their draft. The feedback is 3 as it prompts the authors to consider and clarify their method\"s limitations, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the dataset\"s usage and fairness in comparison with other methods like HMR and SPIN. It explicitly questions whether the AH36M dataset is used for training and suggests that the authors should clarify this. However, it does not provide specific guidance on how to address this issue or what information should be included to make the comparison fair. The action is implicit and somewhat vague, as the authors know they need to clarify the dataset\"s usage but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific concern about the clarity of the dataset\"s usage and fairness in comparison with other methods like HMR and SPIN. It explicitly questions whether the AH36M dataset is used for training and suggests that the authors should clarify this. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the dataset\"s usage and fairness in comparison with other methods like HMR and SPIN. It does not make a subjective claim or suggestion but rather points out a potential issue that the authors should clarify. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the clarity of the dataset\"s usage and fairness in comparison with other methods like HMR and SPIN. It questions whether the AH36M dataset is used for training and suggests that the authors should clarify this to ensure a fair comparison. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern, such as recommending additional explanations or comparisons. This limits the comment\"s helpfulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work. However, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to correct the mistakes in the proof and conduct a more detailed comparison with previous work. While the action is implicit, the comment is 3 as it gives a general direction for improvement. However, it lacks concrete details on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment identifies two main issues: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work. However, it does not specify which part of the paper these issues are addressed in, making it weakly grounded. The comment is specific in detailing the issues, such as the presence of confusing mistakes and the lack of detailed discussion and comparison with previous work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper contains confusing mistakes in the proof of the main results and lacks detailed discussion and comparison with previous work. However, the comment does not provide specific examples of these mistakes or references to previous work for comparison, making it difficult for the authors to understand and address the issues. The lack of detailed justification or evidence weakens the verifiability of the claim, leading to a score of 2.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work. While it highlights these areas for improvement, the comment does not provide specific guidance or suggestions on how to address these issues. The authors are left to infer that they need to correct the mistakes and conduct a more detailed comparison with previous work, but without explicit instructions, the feedback remains 3. Therefore, the comment aligns with a score of 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. It also notes that the proposed model includes newlyadded components (CAT and GAN), which are larger than other models, and that even the pretrained model is compared with others. While the comment identifies areas of concern, it does not provide explicit guidance on how the authors should address these issues or what specific changes to make. The actions are implicit and vague, as the authors are left to infer what needs to be clarified or corrected. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. It also notes that the proposed model includes newlyadded components (CAT and GAN), which are larger than others, and that even the pretrained model is compared with others. However, the comment does not specify which part of the paper these issues pertain to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact areas needing revision. While the comment is specific about the issues, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network and the fairness of the experimental results comparison. It also notes that the proposed model includes newlyadded components (CAT and GAN), which are larger than others, and that even the pretrained model is compared with others. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left to infer the basis of these concerns, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the clarity of the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. It also notes that the proposed model includes newlyadded components (CAT and GAN), which are larger than others, and that even the pretrained model is compared with others. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas needing clarification, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results on the official COOC leader board using the blind test set, as opposed to the current comparison on some not official test set or dev set. It also provides specific references to other works that have achieved similar results and suggests that the paper should at least compare to these. This feedback is clear and provides concrete guidance on how to improve the paper by ensuring that the results are evaluated on a standardized and relevant benchmark. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment and the specific issue of comparing results to related work on the official COOC leader board using the blind test set. It provides a clear reference to the official COOC leader board and specific examples of works that have achieved similar results, such as 5,17. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand the specific issue that needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared to related work on the official COOC leader board using the blind test set. The comment provides specific references to works that have achieved similar results, such as 5,17, and mentions that several other approaches have been proposed since then and significantly improved. This level of detail and reference to external sources supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current comparison falls short of the suggested standard. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the captioning experiment, highlighting a critical issue with the comparison to related work. It suggests that the results should be evaluated on the official COOC leader board using the blind test set, which is a more stringent and relevant benchmark. The comment also references specific works that have achieved similar results and suggests that the paper should at least compare to these. This feedback is clear and constructive, offering a clear direction for improving the paper\"s evaluation and comparison framework. By addressing this feedback, the authors can enhance the credibility and robustness of their experimental results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results, particularly in Table 1, are unreliable due to the discrepancy between MSE and MAE. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative metrics, conducting additional experiments, or providing further analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting the discrepancy between MSE and MAE and questioning the validity of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE. This claim is 3 as it highlights a specific discrepancy in the results, which could be a point of concern. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this discrepancy raises concerns about the validity of the results. Providing more context or references would strengthen the claim, making it easier for the authors to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1. This observation raises concerns about the validity of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. Without actionable feedback or constructive advice, the authors are left without a clear path forward for improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the methodology lacks novelty and is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the methodology or suggest alternative approaches. Without actionable advice or specific suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and is a direct extension of existing methods. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered \"novel\" or how they could be improved. Without clear grounding and specificity, the authors may struggle to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and is a direct extension of existing methods. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons to existing methods, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a lack of novelty in the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. While this feedback highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or differentiate their approach from existing methods. Without actionable advice or detailed examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of adversarial loss, which is a measure used to ensure that perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific changes could be made to include adversarial loss. Without guidance on how to incorporate this concept or what aspects to focus on, the authors are left without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights the absence of adversarial loss, which is a specific aspect of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where adversarial loss is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of missing adversarial loss, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no adversarial loss to guarantee the perturbed data being similar to the authentic data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of adversarial loss, which is crucial for ensuring that perturbed data remains similar to authentic data. This is an important aspect that could enhance the robustness and reliability of the experimental results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss into their work. Without actionable feedback or specific recommendations, the authors are left without a clear path forward for improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of \"wrong\" in the context of the paper, suggesting that the authors clarify what is meant by \"good,\" \"bad,\" or \"wrong\" explanations before using these terms. While the comment implies that the authors should provide a clear definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these terms. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the meaning of \"wrong\" in the context of the paper. The comment also implies that the authors should clarify the terms \"good,\" \"bad,\" or \"wrong\" explanations before using them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" in a specific context, suggesting that the authors clarify what is meant by \"good,\" \"bad,\" or \"wrong\" explanations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the meaning of the term \"wrong\" in a particular context. It suggests that the authors clarify what is meant by \"good,\" \"bad,\" or \"wrong\" explanations before using these terms. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity that could affect the interpretation of their work. However, the comment could be more helpful if it provided additional context or examples of how these terms are used in the paper. Overall, the comment is 4 as it highlights an area for clarification that could enhance the clarity and precision of the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the limited comparison of the proposed method with other methods and the lack of analysis for inferior results, which contradicts the motivation of the paper. It suggests that the authors should provide analysis for these results and be open to changing their rating based on feedback. While the comment implies that the authors should conduct additional analysis, it does not specify how to perform this analysis or what specific aspects should be examined. The action is implicit and somewhat vague, as the authors know they need to address the issue but lack detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of limited comparison with other methods and the lack of analysis for inferior results, which contradicts the motivation of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need for analysis of inferior results and the potential willingness to change the rating, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of the proposed method is only compared with a few methods and that the results are not consistently better than other methods. The reviewer suggests that some analysis should be provided for the inferior results, as they contradict the motivation of the paper. However, the comment lacks specific examples or references to support the claim that the results are inconsistent or that the motivation is not met. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s performance comparison, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. This feedback highlights a critical weakness in the paper\"s evaluation, which could undermine its credibility and impact. The comment suggests that the authors should provide analysis for the inferior results, which aligns with the motivation of the paper. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects of the results should be examined. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this gap. The comment implies that the authors should include more information on these aspects, but it lacks concrete details on what specific activities should be discussed or how to present the information. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area of the paper that lacks coverage, namely the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more information on these aspects, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed justification or evidence makes the claim 2, as it provides some direction but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it highlights an area where the authors need to provide more detailed information or analysis. However, the comment could be more helpful if it offered suggestions on how to address this gap or provided examples of relevant activities. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". While the comment implies that the authors should change their notation, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to implement the change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location of the problem. Additionally, the comment lacks specificity regarding what notation should be used or how to implement the change. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". However, the comment does not provide any reasoning, examples, or references to support why this change is necessary or how it would improve clarity. Without additional context or justification, the claim remains 1, as it lacks sufficient evidence or explanation to guide the authors in making an informed decision. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically the use of the same notation \"D\" for both the dimensionality of points and the dilation factor. This is a clear and actionable suggestion that could help improve the clarity and readability of the paper. However, the comment does not provide further guidance on how to choose alternative notation or suggest specific alternatives, which would make the feedback more comprehensive. While the comment is 4, it could be more beneficial with additional details on notation choices. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a lack of clarity regarding the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" It also suggests that more elaboration is needed on this topic. The comment provides a clear and direct action for the authors to take, which is to clarify the concept of \"state\" and provide further explanation. This makes the comment 5, as it gives the authors a specific task to address the issue. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the concept of \"state\" and asks for clarification on whether \"elements\" are equivalent to \"states\" or \"actions.\" Additionally, it suggests that more elaboration is needed on this topic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" The comment suggests that more elaboration is needed on this topic. However, it does not provide specific examples or references to support the claim that the concept of \"state\" is unclear. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" It provides a clear and actionable suggestion for the authors to elaborate on this topic, which could enhance the understanding of the paper\"s methodology. By addressing this issue, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in expanding on this point. Overall, the feedback is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific action for the authors to take, which is to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, using a Jaccard index as an example. This feedback is explicit and provides a clear direction for the authors to enhance their analysis by including such a comparison. The suggestion is concrete, as it specifies the exact method (Jaccard index) to use for the comparison, making it easy for the authors to implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that of baseline methods, using a Jaccard index as an example. However, it does not specify which part of the paper this comparison should be made in, such as a specific section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a particular comparison and method, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a specific comparison between the proposed scheme and baseline methods using a Jaccard index. This claim is 3 as it provides a clear suggestion for comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to determine the relevance and significance of this comparison to fully understand its importance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific enhancement to the paper by proposing a comparison between the support of the solution obtained by the proposed scheme and that of baseline methods, using a Jaccard index as an example. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to include in their work, potentially enhancing the analysis and comparison of their proposed method. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or why it is particularly relevant. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out a missing aspect in the paper, specifically the explanation of why the proposed module prevents a generator from collapsing. It provides a clear action for the authors to take, which is to include this explanation in their submission. The comment is specific and provides a direct action, making it 5. The authors know exactly what they need to address to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the generator equipped with a standard RGCN as a discriminator collapsing after several iterations, and it requests an explanation of why the proposed module prevents this collapse. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed module prevents a generator from collapsing, which is an important aspect to highlight. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it impacts the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the proposed module prevents a generator from collapsing, while a standard RGCNbased discriminator tends to collapse. This observation is important for understanding the mechanism of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it 3. The authors would need to infer that they should include an explanation of this mechanism, but the comment does not fully support this inference. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises originality concerns by comparing the article\"s reasoning and writing logic to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve the originality of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises originality concerns by comparing the article\"s reasoning and writing logic to those found in a previous study. However, it does not specify which part of the paper this comparison is made, nor does it provide details on what aspects of the work might be novel or how they could be improved. The authors cannot confidently determine which sections or elements are being addressed, and the comment lacks specificity regarding what needs to be revised or clarified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises originality concerns by comparing the article\"s reasoning and writing logic to those found in a previous study. However, it does not provide specific examples or detailed reasoning to support the claim that the work is merely an extension of the previous study. The lack of explicit evidence or references makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises originality concerns by comparing the article\"s reasoning and writing logic to those found in a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While this feedback identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address these concerns or enhance the originality of their work. The comment lacks actionable advice or detailed feedback, making it 3 as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. The action is implicit, as the authors can infer that they need to improve the clarity of their theoretical comparisons, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarity in these comparisons, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific guidance or suggestions on how the authors might clarify these comparisons or improve the clarity of their theoretical framework. Without actionable feedback or detailed examples, the authors are left with a general understanding of the issue but without clear steps to address it. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that a yes response does not necessarily indicate the model comprehends the presence of the object in the image. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative methods could be considered. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate the model comprehends the object in the image. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this measurement is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the measurement method but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate the model comprehends the object in the image. The comment provides a logical reasoning by pointing out that the model might produce incorrect objects in other tasks even with a positive response. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through yes/no responses. It points out that a positive response does not necessarily indicate the model comprehends the presence of the object in the image, as the model might produce incorrect objects in other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and suggests that the authors should consider a more comprehensive approach to measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or alternative methods for assessing object hallucination. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task, while theoretically interesting, may not have significant practical relevance. It recommends improving the discussion by conducting experiments on more datasets and training baseline models with the correct forecast horizon to provide context for the results. While the comment provides a clear direction for improvement, it lacks specific guidance on which datasets to use or how to determine the correct forecast horizon. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the verylongterm forecasting task, suggesting that it may be of limited practical significance. It recommends improving the discussion by conducting experiments on more datasets and training baseline models with the correct forecast horizon to provide context for the results. However, the comment does not specify which part of the paper discusses the verylongterm forecasting task, making it weakly grounded. The suggestion to improve the discussion is specific, as it provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. It provides a specific suggestion to enhance the discussion by conducting experiments on more datasets and training baseline models with the correct forecast horizon. This reasoning is 3 as it offers a logical approach to improving the discussion, but it lacks detailed examples or references to specific datasets or forecast horizons. The authors would need to further explore these suggestions to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the practical significance of the verylongterm forecasting task and suggests ways to improve the discussion. It recommends conducting experiments on more datasets and training baseline models with the correct forecast horizon to provide context for the results. This feedback is actionable and provides a clear direction for enhancing the paper\"s discussion, helping the authors address a potential weakness and improve the overall presentation. However, the comment could be more helpful if it included specific datasets or forecast horizons to consider. Overall, the comment is 4 as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a gap in the experiments section, specifically mentioning the missing components related to the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. It also questions the necessity of these components, particularly in comparison to VideoChatGPT and other works. The comment provides a clear and direct action for the authors to take, which is to include experiments and explanations regarding these different queries. However, it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the experiments, namely the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment further questions the necessity of these components, particularly in comparison to VideoChatGPT and other works, and what would happen if only spatial, temporal, or summary queries were used. This provides clear guidance on what needs to be addressed in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments and explanation regarding the different queries used in spatiotemporal representation are missing. It suggests that these components are crucial for distinguishing the work from VideoChatGPT and other works. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing components or how they impact the comparison. The lack of detailed justification or evidence makes the claim 3, as it highlights a potential issue but lacks the necessary depth to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific gap in the experiments section, pointing out the absence of experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. It highlights the key difference between the work and VideoChatGPT and other works, questioning the necessity of these components. This feedback is clear and actionable, as it directs the authors to include additional experiments and explanations to address the identified gap. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical area of the experiments."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a simple combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on what aspects of the innovation should be elaborated upon or how the authors should enhance the description of the proposed method. The action is implicit and vague, as it does not specify which parts of the innovation need more detail or how the authors should present it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment refers to the proposed FRM, which is described as a simple combination of channel attention and spatial attention. However, it does not specify which part of the paper this comment is addressing, such as a particular section or paragraph where the FRM is discussed. This makes it difficult for the authors to pinpoint the exact location of the proposed FRM in the paper. Additionally, while the comment suggests that the innovative aspect should be detailed, it does not provide specific guidance on what aspects of the innovation need more detail. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspect should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed FRM is described as a simple combination of channel attention and spatial attention, and it suggests that the innovative aspect should be detailed. However, the comment lacks specificity and does not provide guidance on what aspects of the innovation need more detailed explanation or how the authors should enhance their description. Without actionable feedback or suggestions, the authors are left without clear direction on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method, even though they believe there is no negative social impact. While the comment implies that the authors should include these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\" belief about the potential negative social impact of their work and suggests that the authors could consider mentioning the social impact of increased automation or the risks from the dual use of their method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim that their work has no negative social impact, suggesting that the authors should consider the potential risks of increased automation or the dual use of their method. While the comment raises a valid concern, it lacks specific examples or references to substantiate the claim that the work could have negative social impacts. The suggestion to mention these aspects is logical but does not provide detailed evidence or reasoning to fully support the claim. Therefore, the comment is 3, as it provides a basis for consideration but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the potential negative social impact of the work, questioning the authors\" belief that there is no negative impact. It suggests that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. This feedback is 3 as it prompts the authors to address a potential oversight in their work regarding societal implications. However, the comment could be more actionable by providing specific examples or guidance on how to incorporate these considerations into the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that Section 3 and Section 4 are slightly redundant and offers a specific action for improvement: moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. This feedback provides a clear and concrete action for the authors to take, making it 5. The comment explicitly instructs the authors on how to reorganize the sections to reduce redundancy, which is a direct and detailed action. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. This guidance is actionable and provides a concrete step for the authors to take to enhance their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3 and Section 4 are slightly redundant and offers a specific suggestion for reorganizing the content. However, it does not provide any justification or reasoning for why the sections are redundant or how the suggested reorganization would address this issue. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the claim and how to improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a redundancy issue in Sections 3 and 4, suggesting a specific way to reorganize the content to improve clarity and reduce redundancy. By recommending moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3, the comment provides a clear and actionable suggestion for the authors to enhance their draft. This feedback is specific and offers a concrete step for the authors to take, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper, specifically regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify these connections, but it does not specify how to do so. The action is implicit and vague, leaving the authors uncertain about the exact steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the paper, specifically regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the areas of confusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity in the paper regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide specific examples, detailed explanations, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper, specifically regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" While it points out this issue, it does not provide specific suggestions or guidance on how the authors might address this lack of clarity. The comment is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical analyses or extensive experiments to explore why a simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not specify how to conduct these analyses or experiments, nor does it provide concrete guidance on what specific aspects should be examined. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical analyses or extensive experiments to explore the reasons behind the performance of their proposed method. However, it does not specify which part of the paper should include these analyses or experiments, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, namely the theoretical and experimental exploration of the reasons behind the performance of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical analyses or extensive experiments to explore the reasons behind the performance of their proposed method. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that such analyses are missing. This lack of specificity and evidence makes the claim 2, as the authors would need to infer the need for additional analysis on their own.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors should provide theoretical analyses or extensive experiments to explore the reasons behind the performance of their proposed method. It specifically questions why a simple greedy selection approach outperforms more principled acquisition functions in NAS and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is 3 as it highlights a gap in the paper and suggests a direction for further exploration. However, the comment could be more actionable by offering specific suggestions on how to conduct these analyses or experiments. Therefore, it aligns with a score of 3, indicating that the comment provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide a citation for the discussion of the kmax problem elsewhere, indicating that the authors should include a reference to where the kmax problem was previously discussed. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment asks for a citation regarding the discussion of the kmax problem elsewhere, indicating that the authors should provide a reference to where this problem was previously discussed. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in its request for a citation, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for a citation regarding the discussion of the kmax problem elsewhere. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment requests a citation for the discussion of the kmax problem elsewhere in the paper. This is a straightforward and actionable suggestion that could help the authors ensure the accuracy and completeness of their references. However, the comment does not provide any additional context or explanation on why this citation is necessary or how it might impact the paper. While it points out a potential issue, it lacks depth and does not offer specific guidance on how to address it. Therefore, the comment is 3, as it identifies a minor issue but does not fully support the authors in making a significant improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific information should be included. The action is implicit, as the authors can infer that they need to provide more details on the estimation process and model reliability, but the comment lacks concrete instructions on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it impacts the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. It highlights the lack of information that would help readers understand how the model was developed and its expected reliability. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for the completeness and credibility of their work. However, the comment could be more helpful if it suggested specific ways to address these issues or provided examples of how to improve the explanation. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the applicability of the methods to realworld problems, specifically due to strong assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might relax these assumptions or improve the applicability of their methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the strong assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper discusses these assumptions or where the authors should address the limitations. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of limited applicability due to assumptions, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods to realworld problems is limited due to strong assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. The comment provides a logical reasoning by pointing out the specific assumptions that restrict the methods\" applicability. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore these assumptions to fully understand the limitations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods to realworld problems, specifically due to strong assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback is 3 as it highlights a critical area that needs attention, prompting the authors to consider the practicality of their methods. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these limitations or improve the applicability of their methods. To be more helpful, the comment could include recommendations on how to relax these assumptions or suggest alternative approaches. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct a statement in the paper, specifically mentioning that \"thousands\" is not accurate and suggesting that \"on the subword level\" should be added. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006\" and the main text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement \"thousands\" and suggests a correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or correction regarding a specific statement in the paper. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a minor inaccuracy in the paper and suggests a correction. By recommending the addition of \"on the subword level\" to clarify the statement, the reviewer provides clear guidance on how the authors can improve the accuracy of their text. This feedback is valuable as it directly addresses a specific issue and offers a straightforward solution, making it 5 for the authors to enhance their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several concerns. First, it notes that certain hyperparameters, such as regularization, are not specified, which could be a source of confusion for readers. This is an explicit action for the authors to clarify, making it actionable. Second, the comment questions why the y value at x=0 is always 0 for all latent path figures, suggesting that it might be normalized. This is a specific question that the authors can address by providing further explanation or clarification. Lastly, the comment requests further analysis on the model, suggesting that the authors consider using interpolations themselves. This is a concrete and actionable suggestion for enhancing the paper. Overall, the comment provides multiple clear and actionable steps for the authors to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment addresses specific issues related to hyperparameters and the behavior of the y value at x=0 in the latent path figures. It explicitly mentions \"Fig 3,\" which provides full grounding, allowing the authors to accurately identify the part of the paper being addressed. The comment also suggests further analysis on the model, which is specific to the content of the paper. However, the suggestion to use interpolations themselves is somewhat vague, as it does not provide detailed guidance on how to incorporate this analysis. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point consists of multiple observations and requests for clarification. The first part notes that certain hyperparameters, such as regularization, are not specified, which is a factual observation. The second part questions the consistency of the y value at x=0 across all latent path figures, suggesting it might be normalized. This is a logical observation that could be supported by further explanation or evidence. The third part requests further analysis on the model, which is a request for additional information rather than a claim. Overall, the comment is factual and descriptive, without any subjective claims or verifiable assertions, making it \"No\".", "helpfulness_rationale": "The review comment provides several valuable insights and suggestions for improvement. It points out that certain hyperparameters, such as regularization, are not specified, which could be a source of confusion for readers. This is a clear and actionable feedback that the authors can address by providing more details on these parameters. Additionally, the comment questions the consistency of the y value at x=0 across all latent path figures, suggesting that it might be normalized. This is a specific and relevant observation that could help the authors clarify their methodology. Finally, the comment requests further analysis on the model, particularly using interpolations, which is a constructive suggestion for enhancing the paper. Overall, the feedback is detailed and actionable, providing the authors with clear guidance on how to improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies issues with forward referencing and lack of clarity in the Introduction regarding the exact contributions. It also points out that the material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights these areas for improvement, it does not provide specific guidance on how to address these issues or suggest particular changes to make the Introduction clearer or to better integrate the appendix content. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to improve the clarity and organization of the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with forward referencing and lack of clarity in the Introduction regarding the exact contributions. It also points out that the material supporting the main contributions is in the appendix rather than the main sections, specifically mentioning the \"deeprag algorithm\" and the \"discussion on the high concurrency.\" This provides clear guidance on what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which sections or parts of the paper are affected by the forward referencing or lack of clarity, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper and that material is introduced without proper explanation, which is clarified in later sections. It also suggests that the material supporting the main contributions is in the appendix rather than the main sections, such as the \"deeprag algorithm\" and the \"discussion on the high concurrency.\" While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the issues based on the information provided, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including forward referencing and lack of clarity in the Introduction regarding the exact contributions. It also points out that the material supporting the main contributions is in the appendix rather than the main sections, such as the \"deeprag algorithm\" and the \"discussion on the high concurrency.\" While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors\" attention to areas that need clarification and organization, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor. It asks whether there is an error bound in terms of epsilon, which suggests that the authors should clarify this aspect in their paper. While the comment implies that the authors should address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or justification regarding the error bound. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the rounding of core tensors to smaller ranks with a given accuracy. It questions the effect on the approximation error in the full tensor and asks about the existence of an error bound in terms of epsilon. However, the comment does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The authors can infer that it relates to the section discussing the core tensors and their approximation, but this inference is not direct. The comment is specific in its questioning about the error bound, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effect of rounding core tensors on the approximation error in the full tensor. It asks whether there is an error bound in terms of epsilon. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or address the question. This makes the claim 1, as the authors are left without guidance on how to address the issue or what information is needed to resolve it. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor. It specifically asks whether there is an error bound in terms of epsilon, which is a crucial aspect of understanding the impact of this rounding process. While the comment identifies a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this issue or what kind of analysis could be conducted to explore the error bound. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the test settings in visual dialog, specifically noting that while the discriminative setting is shown in Table 1, the generative setting is not addressed. The reviewer implies that the authors should provide results for the generative setting. However, the comment does not explicitly instruct the authors to do so or provide guidance on how to present the results. The action is implicit and somewhat vague, as the authors need to infer that they should include results for the generative setting. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the test settings in visual dialog, noting that the discriminative setting is shown in Table 1 while the generative setting is not addressed. The comment further specifies the concern by asking about the result on the generative setting, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a concern about the test settings in visual dialog, specifically noting that while the discriminative setting is shown in Table 1, the generative setting is not addressed. The reviewer implies that the authors should provide results for the generative setting. However, the comment lacks specific reasoning or evidence to support why the generative setting is important or how it would impact the results. Without additional context or references, the claim is 3, as it highlights a potential gap in the paper but does not provide a detailed explanation or justification for the need to address this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that while the discriminative setting is shown in Table 1, the generative setting is not addressed. This is a relevant observation, as the generative setting is often more applicable to realworld applications. The comment prompts the authors to consider presenting results for the generative setting, which could enhance the comprehensiveness and applicability of their work. However, the comment could be more helpful if it provided suggestions on how to present the results or discussed the implications of not addressing the generative setting. Overall, the feedback is 3 as it highlights an important area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what additional evidence or reasoning should be included or how the authors should present this information. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to address the feedback effectively. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that more evidence or reasoning should be provided to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is vague and lacks specific details on what kind of evidence or reasoning should be included. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that more evidence or reasoning should be provided to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment does not offer specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not offer any actionable suggestions or examples to address this issue. It merely points out a potential area for improvement without providing detailed guidance on how to enhance the draft. As a result, the feedback is 2, as it does not offer concrete steps for the authors to take to improve their work. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the unknown effectiveness of the proposed approach for other language families. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting additional experiments, comparisons, or analyses to determine the effectiveness across different language families. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the approach\"s effectiveness are unknown or how they could be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of information about the effectiveness of the proposed approach for other language families. This is a relevant point that could impact the credibility and generalizability of the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional experiments, comparisons, or analyses. Without actionable feedback or specific suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors do not analyze the security of their proposed framework, specifically mentioning the protection of privacy. This is a clear and direct action for the authors to take, as it identifies a specific area that needs attention. The comment provides a concrete suggestion for improvement, which is to include a security analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of analysis of the security aspect, specifically the protection of privacy, in the proposed framework. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in identifying the need for a security analysis, but without clear guidance on where to place this analysis, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not analyze the security of their proposed framework, specifically mentioning the protection of privacy. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the security aspect, specifically the protection of privacy, in the proposed framework. This is a critical area that the authors need to address to strengthen their work. However, the comment does not provide specific suggestions or guidance on how to conduct this analysis or what aspects of security should be considered. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors would need to infer the need for additional analysis on their own, which limits the utility of the comment. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the form of \"p\" should be described near line 135, as it is assumed to be a Gaussian distribution but not explicitly stated. This feedback provides a clear and explicit action for the authors to take, which is to include a description of \"p\" near the specified line. The comment also implies that the assumption about \"p\" being a Gaussian distribution might be incorrect, but it does not provide further guidance on how to verify or address this assumption. However, the explicit suggestion to describe \"p\" near line 135 makes the action clear and concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of \"p\" near line 135. The comment implies that \"p\" is assumed to be a Gaussian distribution but is not explicitly stated, providing a clear direction for improvement. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the form of \"p\" should be described near line 135, as it is assumed to be a Gaussian distribution but not explicitly stated. This claim is 3 as it points out a potential oversight in the paper\"s description, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this omission and understand why it is critical to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional information is needed, namely the description of \"p\" near line 135. It acknowledges the assumption that \"p\" is a Gaussian distribution but points out that this assumption is not explicitly stated. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of \"p\" to ensure clarity and completeness in their work. By addressing this omission, the authors can improve the transparency and comprehensibility of their methodology. Therefore, the comment is 4, as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to enhance the clarity. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the differences between related works but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which part of the related work section this comment is addressing, making it weakly grounded. The comment is specific in its suggestion to improve the description of differences between related works, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed justification or examples, the claim is considered 2, as it provides some direction but lacks the necessary details to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, noting that while some related works are mentioned, their differences are not adequately described. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and depth of their related work section. However, the comment could be more helpful if it offered suggestions on how to effectively describe the differences between the related works or provided examples of what constitutes a detailed comparison. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should explicitly explain what type of understanding one reaches by examining the PPP maps. While the comment implies that the authors need to provide a clearer explanation, it does not specify how to do so or what specific aspects of the PPP maps should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on their explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not provide detailed guidance on what the authors should explicitly explain regarding the PPP maps. It raises a question about the type of understanding one reaches by examining the PPP maps but does not offer specific suggestions or examples for how to address this. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point questions the authors\" claim that reliable PPP metrics are important for understanding PPP effects in different tasks. It suggests that the article does not explicitly explain this understanding, prompting the authors to provide a clearer explanation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the explanation is missing. This lack of detailed justification makes the claim 2, as the authors are left to infer the basis of the claim without clear guidance on how to address it.", "helpfulness_rationale": "The review comment identifies a gap in the paper by questioning the authors\" explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should explicitly explain what type of understanding one reaches by examining the PPP maps. This feedback is 3 as it prompts the authors to clarify and elaborate on their explanation, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this gap. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which could enhance the credibility of their work. However, it does not provide explicit guidance on how the authors should conduct these comparisons or suggest specific methods to include. The action is implicit, as the authors can infer that they need to add comparisons with stateoftheart methods, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which could enhance credibility. However, it does not specify which part of the paper this comparison should be made in, nor does it provide specific guidance on how to include these comparisons. The authors might infer that this feedback pertains to the results or discussion sections, but the lack of explicit references makes it weakly grounded. The comment is specific in suggesting the need for comparisons with stateoftheart methods, but without grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which could enhance credibility. However, the comment lacks specific examples or references to other stateoftheart methods, making it difficult for the authors to understand the exact nature of the comparison or how to address the issue. Without detailed justification or examples, the claim is 3, as it provides a general observation but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This feedback is valuable as it highlights an area where the authors could enhance the credibility and impact of their work by demonstrating how their methods compare to existing stateoftheart approaches. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or which methods to include. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs further exploration and justification."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the discussion on regret bounds, specifically questioning whether the authors mean that the prediction error over the entire horizon T cannot be sublinear. While the comment implies that the authors should clarify their statements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their discussion on regret bounds. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 32  37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\" claim about the regret bounds, asking whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim about the regret bounds, specifically asking whether the prediction error over the entire horizon T cannot be sublinear. This is a direct question seeking clarification, not an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the authors\" claim regarding the regret bounds, specifically questioning whether the prediction error over the entire horizon T cannot be sublinear. This feedback is 3 as it prompts the authors to clarify their discussion on regret bounds, which is a critical aspect of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic of the model. It also mentions that it was difficult to connect the text with the figure and equations. This feedback provides clear and concrete actions for the authors to take, including rewriting the figure and ensuring that the text aligns with the visual and mathematical content. The explicit nature of the suggestions and the detailed guidance make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation of the forwardprediction model, suggesting that Figure 2(b) should be redrawn to better represent the schematic. Additionally, it points out the difficulty in connecting the text with the figure and equations, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly noting that Figure 2(b) does not accurately represent the schematic of the model. The reviewer suggests that the figure should be redrawn and that it was difficult to connect the text with the figure and equations. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to redraw the figure provides some guidance, but more comprehensive evidence or references would be needed to fully verify the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of the forwardprediction model, noting that Figure 2(b) does not accurately represent the schematic of the model. It suggests that the figure should be redrawn to better illustrate the model. Additionally, the comment points out the difficulty in connecting the text with the figure and equations, which is a significant issue for understanding the model. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and accuracy of their presentation. However, it could be more helpful if it offered suggestions on how to effectively integrate the text with the visual and mathematical content. Overall, the comment is 4, as it effectively directs the authors\" attention to critical areas for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training of RBI, noting that it only trains on rewarded actions and potentially ignoring useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI over RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the training of RBI, specifically noting that it only trains on rewarded actions and potentially ignoring useful supervision from rewardless actions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying a potential issue with the training of RBI, it lacks grounding as it does not reference a specific section or figure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the training of RBI, suggesting that it only trains on rewarded actions and potentially ignores useful supervision from rewardless actions. The reviewer implies that this could be a significant factor in the effectiveness of FP + RBI over RBI alone. However, the comment lacks specific examples or references to substantiate this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence leaves the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the training of RBI, noting that it only trains on rewarded actions and potentially ignoring useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI over RBI alone. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors would need to infer that they should provide stronger baselines or additional experiments to address the concern, but the comment does not fully support this inference. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the multiscale statement might be misleading because the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the only benefit appears to be the reduction of the gradient path by the slow RNN. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their statement. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the multiscale statement, suggesting that it might be misleading because the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the only benefit appears to be the reduction of the gradient path by the slow RNN. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential misleading nature of the statement and the perceived benefit, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical reasoning by explaining that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific examples or references to substantiate the claim further, which could enhance its verifiability. Overall, the comment is 4, as it provides a reasonable argument but could benefit from additional evidence or examples to strengthen the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement, suggesting that it might be misleading because the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer points out that the only benefit appears to be the reduction of the gradient path by the slow RNN. This feedback is 3 as it highlights a potential misunderstanding or misrepresentation in the paper, prompting the authors to reconsider their statement. However, the comment could be more helpful if it provided suggestions on how to clarify or correct the statement. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the baseline methods, noting that they are weak and not stateoftheart. It also mentions the absence of a discussion on limitations and suggests that the authors should address the difference between their work and reinforcement learning. Additionally, it points out a potential direction for the conclusion, which is to discuss the similarity and difference and the generalizability of the results to RL settings. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to expand their discussion on limitations, differences from reinforcement learning, and generalizability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, noting that they are weak and not stateoftheart, and mentions the absence of a discussion on limitations. It also raises questions about the difference between the work and reinforcement learning and suggests discussing the similarity and difference, as well as the generalizability of the results to RL settings. However, the comment does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as discussing limitations and the difference from reinforcement learning. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests that there is no discussion of limitations. It also raises questions about the difference between the work and reinforcement learning and suggests discussing the similarity and difference, as well as the generalizability of the results to RL settings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that the baseline methods are weak or stateoftheart. The suggestion to discuss limitations and differences is 3, as it provides a direction for improvement but lacks specific examples or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not stateoftheart, which is a significant concern that needs addressing. The comment also highlights the absence of a discussion on limitations, which is crucial for understanding the scope and applicability of the work. Additionally, it raises questions about the difference between the work and reinforcement learning, suggesting that the authors should explore this aspect. The comment also provides a potential direction for the conclusion by suggesting a discussion on the similarity and difference, as well as the generalizability of the results to reinforcement learning settings. While the comment identifies important areas for improvement, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the feedback is 3 as it provides valuable insights but lacks detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between expected performance under observation noise and the actual objective function, which is a stochastic noisy function. It implies that the authors should make this distinction clearer upfront in their paper. While the comment does not explicitly instruct the authors to make this change, it provides a clear direction for improvement. The action is implicit but concrete, as it specifies what needs to be clarified. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the evaluation of expected performance under observation noise and the distinction between the objective function and the decisionmaking process. It suggests that the authors should clarify this distinction upfront. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the distinction, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of expected performance under observation noise is not representative because the decisionmaker is interested in the true objective function, which is a stochastic noisy function. The reviewer suggests that the distinction between these two should be clarified upfront. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current approach is misleading or not representative. This makes the claim 3, as the authors would need to further develop the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation methodology, specifically the use of expected performance under observation noise. It suggests that this approach may not be representative because the decisionmaker is interested in the true objective function, which is a stochastic noisy function. The comment provides a clear and actionable suggestion to clarify this distinction upfront, which could enhance the paper\"s clarity and relevance. By addressing this feedback, the authors can improve the transparency and accuracy of their evaluation, making the comment 4. However, it could be more helpful if it provided specific examples or guidance on how to make this distinction clearer. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions: whether the authors can run VGAE with a vamp prior to better match the doubly stochastic construction in the work, and whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. These questions provide clear and direct actions for the authors to take, such as experimenting with different priors and comparing the results. Additionally, the review point offers a minor suggestion regarding Figure 3, suggesting that the authors should optimize only the inference part of the model while keeping the generative model fixed. This provides a concrete action for the authors to consider. The comment is 4 as it provides explicit guidance on what experiments to conduct and what comparisons to make, but it could be more detailed. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also raises specific questions about the doubly stochastic construction and the benefits of using a vamp prior, as well as a suggestion to optimize only the inference part of the model. This provides clear guidance on what needs to be addressed and improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether running VGAE with a vamp prior would better match the doubly stochastic construction in the work. It suggests that this could help determine if the benefits are due to a better generative model or better inference. The comment also provides a minor suggestion regarding Figure 3, suggesting that the authors should optimize only the inference part of the model while keeping the generative model fixed. While the comment raises a relevant question, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion about Figure 3 is also vague and does not provide a clear path for improvement. Therefore, the comment is 3, as it provides some direction but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment raises an important question about whether running VGAE with a vamp prior would better match the doubly stochastic construction in the work. This question is relevant as it could help determine whether the benefits observed are due to a better generative model or better inference. The comment also provides a minor suggestion regarding Figure 3, suggesting that the authors should optimize only the inference part of the model while keeping the generative model fixed. This feedback is actionable and provides a specific direction for the authors to consider, which could lead to significant improvements in their draft. However, the comment could be more helpful if it included additional suggestions or examples to guide the authors further. Overall, the comment is 4 as it offers valuable insights and actionable feedback, but it could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the performance of the method, particularly in Table 2, but notes that the novelty and contribution of the method are somewhat incremental. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide explicit guidance or suggestions on how the authors should address the perceived lack of novelty or contribution. The feedback lacks actionable details, such as recommending specific ways to enhance the novelty or contribution of the method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the performance of the method, particularly in Table 2, and notes that the novelty/contribution of the method is somewhat incremental. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not specify which part of the paper this observation is based on, such as the introduction, methodology, or results sections. The authors can infer that it relates to the discussion of the method\"s contributions, but this inference is not direct. The comment is specific in detailing the perceived lack of novelty and contribution, but it is 1 as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty and contribution of the method are somewhat incremental, suggesting that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to prior work that the authors could compare their method to, making it difficult for the authors to understand the basis of the claim. The reasoning is not detailed enough to fully substantiate the claim, and without additional context or evidence, it remains 3. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges the performance of the method, particularly in Table 2, but points out that the novelty and contribution of the method are somewhat incremental. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a perceived limitation in the novelty of the method, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, making it less useful for the authors to make informed changes to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include a discussion on the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It points out that while the example in Table 3 shows some evidence, the authors are unsure if it is fully required. The comment implies that the authors should explore this aspect further, possibly by discussing the balance between longrange dependencies and locality in the graph structure. However, the comment does not provide specific guidance on how to incorporate this discussion or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a discussion and determine the exact content to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a discussion on the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment further suggests that the authors should explore the balance between longrange dependencies and locality in the graph structure, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that learning longrange dependencies is important for powerful predictors, particularly in the context of semantic segmentation. It supports this claim by referencing the visualizations in Table 3, indicating that the example shows the occurrence of longrange dependencies. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining how the visualizations demonstrate the necessity of longrange dependencies. This makes the claim 3, as it provides a starting point but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper\"s discussion regarding the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It points out that while the example in Table 3 suggests the occurrence of longrange dependencies, the authors are unsure if it is fully required. The comment suggests that the authors should explore this aspect further, possibly by discussing the balance between longrange dependencies and locality in the graph structure. This feedback is 3 as it highlights an area for improvement and encourages the authors to consider additional discussion on this topic. However, it could be more helpful if it provided specific suggestions or examples on how to address this issue. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the paper, including the definition of $e_l$ in Equation (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also mentions that the performance is more quickly getting worse than standard random features, which may indicate a weakness in the proposed approaches or theoretical results. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending specific changes or clarifications, making it difficult for the authors to know what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2, and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by discussing the definition of $e_l$, the exponential dependence on the diameter $M$, and the impact on the constant factor of the required feature size. Additionally, it highlights the performance issue shown in Figure 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims about the paper, including the definition of $e_l$ in Equation (3), the exponential dependence of results on the diameter $M$ of the data domain, and the impact on the constant factor of the required feature size. The comment also mentions that the performance is more quickly getting worse than standard random features, which may indicate a weakness in the proposed approaches or theoretical results. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The absence of detailed justification or evidence makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the definition of $e_l$ in Equation (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also points out that the performance is more quickly getting worse than standard random features, which may indicate a weakness in the proposed approaches or theoretical results. However, the comment lacks specific suggestions or actionable guidance on how the authors might address these issues or improve their draft. While it highlights important areas for improvement, the feedback could be more helpful if it provided detailed insights or constructive advice. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point discusses the poor longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients, and suggests that oversmoothing might also be a contributing factor. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve their model. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the poor longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients, and suggests that oversmoothing might also be a contributing factor. It references a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides context for the discussion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential causes of the poor performance, but without clear guidance on how to address these issues, it is underspecific. Therefore, this comment is weakly grounded and underspecific, aligning with category 2.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs is due to oversquashing and vanishing/exploding gradients, and suggests that oversmoothing might also be a contributing factor. The comment references a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides context for the discussion. This reference supports the claim by offering a source that discusses similar issues, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the poor longrange modelling ability of DGNs, and attributes it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing might be another contributing factor, referencing a specific paper for context. This feedback is clear and provides a basis for the authors to consider additional factors that might influence the performance of their model. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided guidance on how to improve the model. Overall, the comment is 4 as it highlights an important area for consideration and provides a reference for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the model collapses less than other methods, specifically in the context of gradients becoming zero. It also asks if this phenomenon is commonly encountered and if the authors observed it in their experiments. While the comment implies that the authors should provide evidence or results related to this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include such evidence or results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model collapses less than other methods and whether the phenomenon of gradients becoming zero is commonly encountered. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the model\"s behavior and experimental results. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the model\"s behavior, specifically whether it collapses less than other methods, particularly in the context of gradients becoming zero. It also asks if this phenomenon is commonly encountered and if the authors observed it in their experiments. While the comment identifies an area of interest, it lacks actionable feedback or suggestions on how the authors might address this issue or provide evidence for their claims. The comment is 3 as it prompts the authors to consider and clarify this aspect of their work, but it does not offer specific guidance on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the problem formulation or what specific aspects need to be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these examples are in. This lack of specific reference makes it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the problem formulation are unclear, such as whether it is the wording, the examples, or the overall clarity. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might clarify these sections. Without actionable feedback or detailed examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This feedback provides a clear and explicit action for the authors to take, which is to include experiments with specific models to demonstrate the method\"s applicability and generalizability across various LLM families. The comment is concrete, as it specifies which models should be tested and what the goal of these experiments is. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper should include these experiments, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, namely the lack of experiments on different LLM families. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that such experiments could provide valuable insights into the method\"s applicability and generalizability. However, the comment lacks specific examples or references to support the claim, which would make it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it guides the authors on what specific experiments to include to strengthen their work. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their study. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method appears to be limited to generative models that can be finetuned as in/outpainting models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the applicability of their method. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to follow to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method appears to be limited to generative models that can be finetuned as in/outpainting models. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s applicability are being questioned or how the authors might address this limitation. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method \"seems to only work for generative models that can be finetuned as an in/outpainting model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how it impacts the paper\"s validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the applicability of the method, suggesting that it is only effective for generative models that can be finetuned as in/outpainting models. While this observation highlights a potential weakness, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their method. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the connections between the curve finding (the first part) and FGE (the second part), suggesting that the relationship is weak. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the connection between these two parts. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the connections between the curve finding (the first part) and FGE (the second part), suggesting that the relationship is weak. However, it does not specify which parts of the paper these connections are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some context, it lacks full grounding as it does not explicitly mention the sections or parts of the paper being addressed. The comment is specific in its critique of the weak connection between the two parts, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concern about the weak connection between the curve finding (first part) and FGE (second part). The reviewer provides a specific example of their understanding of the first part, which is that it involves taking random weights, learning curves between weights, and finding nice weights to be mixed into the final ensemble. However, the reviewer notes that this understanding does not align with the actual content of the paper. While the comment highlights a potential issue, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the basis of the concern, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s connections between the curve finding (first part) and FGE (second part). It suggests that the relationship between these two parts is weak and provides a specific example of what the reviewer imagined the first part to be. However, the comment does not offer actionable feedback or suggestions on how the authors might address this issue or improve the connection between the two parts. While it highlights an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include results from the SOTA heuristicsolver, such as Concorde, for a better comparison, especially for the single objective TSP. It implies that the authors should add these results to their experimental results section. However, the comment does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to include these results, but the comment does not provide detailed guidance on how to present or integrate them into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the single objective TSP,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the results for linear scalarization + Concorde should be included for a better comparison, particularly for the single objective TSP. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers outperform the heuristicbased solvers, but suggests that including results from the SOTA heuristicsolver, such as Concorde, would provide a better comparison, especially for the single objective TSP. The comment is 3 as it provides a logical reasoning for the suggestion, explaining why the inclusion of Concorde\"s results would enhance the comparison. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of learningbased and heuristicbased solvers, suggesting that the results for linear scalarization + Concorde should be included for a better comparison, especially for the single objective TSP. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental results section. By recommending the inclusion of these results, the comment offers a concrete way for the authors to enhance the comprehensiveness and fairness of their comparison. However, the comment could be more helpful if it provided additional context or explanation on why this inclusion is necessary or how it would impact the overall analysis. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed method has some similarities with existing methods in terms of grounding in neuroscience and reasoning topologically. It suggests that the paper should discuss the proposed method in relation to these existing methods, such as those using the generalized Voronoi graph or semantic maps, or those involving loop closure in SLAM. While the comment implies that the authors should include a discussion of these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of these methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the grounding of the proposed method in neuroscience, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out that some general ideas are already present in other methods, such as reasoning topologically using generalized Voronoi graphs or semantic maps, and longterm storage through pose graphs in SLAM. The comment suggests that the paper should discuss the proposed method in relation to these existing methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method has similarities with existing methods in terms of grounding in neuroscience and reasoning topologically. It references specific methods, such as those using the generalized Voronoi graph or semantic maps, and mentions loop closure in SLAM. The comment provides a logical reasoning by identifying these existing methods and suggesting that the paper should discuss the proposed method in relation to them. However, the comment lacks specific examples or detailed references to these methods, which would enhance its verifiability. Overall, the claim is 4 as it provides a clear direction for the authors to address the issue, but it could be strengthened with more detailed references or examples.", "helpfulness_rationale": "The review comment identifies a potential overlap between the proposed method and existing methods in terms of grounding in neuroscience and reasoning topologically. It suggests that the paper should discuss the proposed method in relation to these existing methods, such as those using the generalized Voronoi graph or semantic maps, or those involving loop closure in SLAM. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by comparing their method to existing approaches. However, the comment could be more helpful if it included examples or detailed references to these existing methods, which would further support the authors\" understanding and execution of the suggested comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret. The reviewer provides a specific action by suggesting moving some of these details back into the main text and moving some background information from Section 2 to the appendix. This feedback is explicit and provides concrete guidance on how to reorganize the content for better clarity. The authors know exactly what needs to be done to improve the draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup, tasks, and other details\" and suggests moving some of these details back into the main text. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done\u2014moving certain details back and moving background information from Section 2 to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that moving certain details to the appendix makes it difficult to interpret the experimental setup and tasks. The reviewer provides a specific suggestion to move some details back into the main text and move background information from Section 2 to the appendix. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the current arrangement is problematic. While the suggestion is logical, the lack of specific evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the organization of the paper, specifically the placement of experimental setup, tasks, and other details in the appendix, which may make it difficult for readers to interpret the content. The reviewer provides a clear and actionable suggestion to move some of these details back into the main text and move background information from Section 2 to the appendix. This feedback is specific and offers a concrete way for the authors to improve the clarity and accessibility of their paper. However, the comment could be more helpful if it included additional suggestions or examples of how to effectively reorganize the content. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide glosses for Figure 2. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it does not specify which parts of the glosses are needed or how they should be presented, leaving some level of vagueness. Therefore, the comment is 4, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests providing glosses for Figure 2, which is a specific part of the paper. However, it does not explicitly mention which figure or section this refers to, making it weakly grounded. The comment is specific in its suggestion to provide glosses, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide glosses for Figure 2. However, it does not offer any justification or reasoning for why this is necessary or how it would improve the paper. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests providing glosses for Figure 2, which is a specific and actionable piece of feedback. This suggestion is clear and directly addresses a potential area for improvement in the paper, helping the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or explanation on why glosses are necessary or how they might benefit the paper. Despite this, the feedback is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that \"memb\" is considered the previous stateoftheart but does not mention any reference. This implies that the authors should include a reference to support the claim that \"memb\" is the previous stateoftheart. However, the comment does not provide specific guidance on which reference to include or how to present the information. The action is implicit and somewhat vague, as the authors know they need to add a reference but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that \"memb\" is considered the previous stateoftheart but does not mention any reference. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for a reference to support the claim that \"memb\" is the previous stateoftheart. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"memb\" is the previous stateoftheart but does not mention any reference to support this claim. This makes the comment 1, as it lacks evidence or references to substantiate the assertion. Without additional context or references, the authors may find it challenging to address the claim effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"memb\" is considered the previous stateoftheart but does not mention any reference to support this claim. This feedback is 3 as it highlights a potential gap in the paper\"s literature review or references section. However, it lacks depth and does not provide guidance on how the authors might address this issue or suggest a reference to include. The comment could be more helpful if it offered suggestions on where to find relevant references or how to integrate this information into the paper. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether finer grouping for quantization should be considered instead of the current approach of pertensor and perchannel. While the comment implies that the authors should explore this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider finer grouping for quantization. However, the comment does provide a clear direction for potential exploration, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the approach to quantization, specifically questioning whether finer grouping should be considered instead of the current pertensor and perchannel approach. However, it does not specify which part of the paper this question pertains to, such as a particular section or method discussion. The authors might infer that it relates to the quantization section, but this inference is not direct. The comment is specific in its inquiry about the choice of grouping for quantization, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the approach to quantization, specifically questioning whether finer grouping should be considered instead of the current pertensor and perchannel approach. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be beneficial or necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment raises a question about the approach to quantization, specifically questioning whether finer grouping should be considered instead of the current pertensor and perchannel approach. While it identifies a potential area for improvement, it lacks specificity and does not provide any suggestions or guidance on how the authors might explore this idea. The comment is 3 as it prompts the authors to consider a different approach, but it does not offer detailed feedback or actionable steps to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unseen classes and unlabeled examples. While the comment implies that the authors should conduct additional experiments or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes, specifically mentioning how performance varies with different ratios of unseen classes and unlabeled examples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this analysis could be conducted. The authors might infer that it relates to the experimental results or analysis sections, but this inference is not direct. The comment is specific in suggesting what needs to be studied, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unseen classes and unlabeled examples. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why this study would be beneficial or how it could impact the results. Without additional context or justification, the claim remains 1, as it lacks the necessary details to guide the authors in addressing the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unseen classes and unlabeled examples. This feedback is 3 as it identifies a potential area for further investigation that could enhance the comprehensiveness of the study. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. While it prompts the authors to consider an important aspect of their work, the suggestion is not as actionable as it could be. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or improve their draft based on the feedback. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or discussion. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the choice of architectures, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of using GRU and LSTM in the Pyramid and sequential parts, respectively. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While it identifies a potential area of interest, it does not provide specific feedback or suggestions on how the authors might address this question or improve their draft. The comment lacks actionable guidance, making it 3 as it prompts the authors to consider the rationale behind their architecture choices but does not offer detailed advice on how to enhance their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in line 135, which could be a source of confusion for the readers. While the comment implies that the authors should clarify this term, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a definition or explanation of \"active vertices.\" However, the comment does not offer specific guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of \"active vertices.\" This provides clear guidance on what the authors should clarify or explain in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the definition of \"active vertices\" in line 135. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in line 135, which could be a source of confusion for readers. While it identifies a potential area of ambiguity, it does not provide any suggestions or guidance on how the authors might clarify this term. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer constructive advice for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that the theoretical limitations are not clearly mentioned in the limitations section. It points out that the vagueness of unspecified structural assumptions, which are only provided in the appendix, makes this limitation difficult to identify. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific examples or additional sections to include. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s limitations and the use of graph neural networks, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the theoretical limitations not being clearly mentioned and suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical limitations of the paper are not adequately addressed, specifically noting the lack of mention of the theory\"s applicability to the used model and the vagueness of unspecified structural assumptions. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to elaborate on societal impacts is 3, as it provides a direction for improvement but does not include specific references or detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, pointing out that the theoretical limitations are not adequately addressed in the limitations section. It highlights the vagueness of unspecified structural assumptions, which are only mentioned in the appendix, making it difficult for readers to understand the theoretical limitations. The reviewer also suggests that the authors underestimate the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is clear and actionable, offering specific areas for improvement and providing guidance on how to enhance the paper\"s discussion. However, it could be more helpful if it included examples or suggestions on how to address the theoretical limitations or the societal impact. Overall, the comment is 4 as it provides valuable insights and directions for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically questioning whether it refers to epsilongreedy exploration on top of the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the term. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"epsilongreedy\" in the context of training, particularly whether it refers to epsilongreedy exploration on top of the proposed strategy. This provides clear guidance on what needs to be clarified or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically questioning whether it refers to epsilongreedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this point. The feedback is 3 as it highlights a specific area that needs clarification, but it lacks depth and actionable advice, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method is a direct combination of GCN and normalizing flow, with a modification to the transformed distribution from Gaussian to Gaussian mixture. However, it claims that there is no new technical content in the paper. While the comment implies that the authors should provide more detailed technical analysis or justification for the novelty of their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the technical aspects. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides a specific critique regarding the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with a modification to the transformed distribution from Gaussian to Gaussian mixture. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is being criticized, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with a modification to the transformed distribution from Gaussian to Gaussian mixture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with a modification to the transformed distribution from Gaussian to Gaussian mixture. However, the comment claims that there is no new technical content in the paper, which could be a valid critique. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or introduce new elements to their work. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific aspect of the paper, noting that only the projection head (CNN layers) are affected, but not the classification head (FCN layer). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes could be made to improve the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"projection head (CNN layers)\" and the \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of impact on the classification head. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the structure of the paper, noting that only the projection head (CNN layers) are affected, but not the classification head (FCN layer). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a factual observation about the structure of the paper, noting that only the projection head (CNN layers) are affected, but not the classification head (FCN layer). However, it does not provide any actionable feedback or suggestions for improvement. Without identifying specific areas for enhancement or offering guidance on how the authors might address this observation, the comment lacks value in terms of helping the authors improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the importance of certain parts of the framework in using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary but does not provide explicit guidance on which parts need clarification or how to address the issue. The comment implies that the authors should provide more detailed explanations or examples to differentiate their work from related literature, but it lacks concrete instructions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of certain parts of the framework in using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance on which parts need clarification or how to address the issue. The comment implies that the authors should provide more detailed explanations or examples to differentiate their work from related literature, but it does not specify which parts of the paper need improvement. The authors can infer that it relates to the discussion section, but the lack of explicit grounding and specificity makes it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point questions the importance of certain parts of the framework in using CLIP to guide weakly supervised learning and suggests that the discussion is necessary but lacks clarity. However, it does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique, rendering the comment 2. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a question about the importance of certain parts of the framework in using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance or examples to clarify this point. The comment implies that the authors should provide more detailed explanations or examples to differentiate their work from related literature, but it lacks actionable suggestions or detailed feedback. While it identifies an area for improvement, the comment is vague and does not offer concrete guidance, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a perceived weakness in the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It also mentions that the decomposition/integration steps in the paper do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve the analogy. The feedback lacks actionable details, leaving the authors uncertain about how to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analogy between HOI analysis and Harmonic analysis, specifically mentioning the weak link between the two. It also discusses the decomposition/integration steps and their connection to Fourier analysis. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in detailing the perceived weakness in the analogy and the lack of connection to Fourier analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, suggesting that the link is not as strong as initially perceived. The reviewer supports this claim by noting that the decomposition/integration steps in the paper do not have a close connection with Fourier analysis, as claimed. However, the comment lacks specific examples or detailed reasoning to substantiate the claim fully. While the authors might infer that the analogy is weak, the lack of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a perceived weakness in the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It also points out that the decomposition/integration steps in the paper do not have a close connection with Fourier analysis as claimed. While the comment highlights areas that need clarification, it lacks specific suggestions or guidance on how the authors might address these issues or improve the analogy. The feedback is 3 as it directs the authors\" attention to potential weaknesses, but it could be more actionable with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the proposed methodology to existing ML accelerators, which typically use bitparallel fixedpoint numbers. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their methodology. There is no guidance on potential solutions, alternative approaches, or specific actions the authors should take to address the concern. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of dynamic precision control during training to existing ML accelerators, which typically use bitparallel fixedpoint numbers. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying a potential limitation of the proposed methodology, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of dynamic precision control during training to existing ML accelerators, which typically use bitparallel fixedpoint numbers. The comment suggests that this might restrict the implications of the proposed methodology. However, it lacks specific examples or references to existing ML accelerators that use bitparallel fixedpoint numbers, making it difficult for the authors to fully understand and address the concern. The claim is 3 due to the lack of detailed evidence or references, but it provides a reasonable basis for consideration.", "helpfulness_rationale": "The review comment raises a concern about the applicability of dynamic precision control during training to existing ML accelerators, which typically use bitparallel fixedpoint numbers. This is a relevant point that could impact the implications of the proposed methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology in light of this limitation. While it identifies a potential weakness, it does not provide actionable feedback or detailed insights that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights an important consideration but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalization of the model\"s performance across different focusing distances, specifically asking whether the model generalizes well beyond the distances present in the training data. While the comment implies that the authors should consider additional focusing distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the model\"s performance on other focusing distances. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model\"s performance across different focusing distances, particularly those not present in the training data. This provides clear guidance on what aspect of the paper needs further exploration. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the generalization of the model across different focusing distances, specifically asking whether the model generalizes well beyond the distances present in the training data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the generalization of the model\"s performance across different focusing distances, specifically questioning whether the model generalizes well beyond the distances present in the training data. This feedback is valuable as it prompts the authors to consider the robustness and applicability of their model across a broader range of scenarios. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored potential limitations in the current experimental setup. While it identifies an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018) where style is instancespecific and content can be transferred among groups. It also questions the authors\" understanding of \"style\" in the context of a nonsequential model that does not capture temporal dynamics. While the comment provides a specific reference and suggests a direction for consideration, it does not offer concrete guidance on how to implement these changes or clarify the concept of \"style\" in this context. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It provides a specific example of style being instancespecific and content being transferable among groups. The comment also questions the authors\" understanding of \"style\" in the context of a nonsequential model that does not capture temporal dynamics. While the comment is specific in its suggestions, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, referencing Gabbay & Hosehn (2018) as an example. It questions the authors\" understanding of \"style\" in the context of a nonsequential model that does not capture temporal dynamics. The comment provides a specific reference to support the suggestion, making it 4. However, it could be strengthened by providing more detailed reasoning or examples of how this approach would benefit the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should consider defining content and style more broadly, referencing Gabbay & Hosehn (2018) as an example. It highlights the need to clarify the concept of \"style\" in the context of a nonsequential model that does not capture temporal dynamics. This feedback is valuable as it prompts the authors to expand their discussion and improve the clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of how to define content and style in this context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples and comparisons to highlight issues with the analysis of vit quantification. It suggests that the paper should offer a more detailed explanation of these points, which implies that the authors should expand their analysis to address these concerns. However, the comment does not explicitly instruct the authors on how to improve the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures, allowing the authors to accurately identify the parts of the paper being addressed. It provides detailed comparisons and examples, such as the variance difference in figures and the precision loss in MHSA quantization, which are relevant to the analysis of vit quantification. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification is not adequately explained, providing specific examples to support this assertion. It references the variance difference in figures and the precision loss in MHSA quantization, which are wellestablished in the field of transformer quantization. These references provide a solid foundation for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or additional references to further substantiate the claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, highlighting specific issues and offering comparisons to existing work in the field. It points out that the variance difference in figures and the precision loss in MHSA quantization are not adequately addressed, suggesting that the analysis could be improved. By referencing specific examples like QBERT and Q8BERT, the comment offers a clear direction for the authors to enhance their analysis. However, while the feedback is comprehensive, it could be more helpful by suggesting specific ways to address these issues or providing additional guidance on how to improve the analysis. Overall, the comment is 4 as it identifies key areas for improvement and provides a foundation for the authors to build upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness in the technical novelty of the work concerning spatial transformer networks (STN) and highlights the lack of comparison to similar works. It suggests that the proposed Xtransformation is similar to STN but applied locally, and points out existing works that have applied STN in a local pixel neighborhood, such as PointNet. The comment implies that the authors should provide a more detailed comparison to these existing works to strengthen the technical novelty claim. However, it does not specify how to conduct this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a main weakness in the technical novelty of the work concerning spatial transformer networks (STN) and highlights the lack of comparison to similar works. It specifically mentions the proposed Xtransformation and its similarity to STN, as well as existing works like PointNet that have applied STN in a local pixel neighborhood. This provides a clear direction for the authors to address the issue of technical novelty. However, the comment does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in detailing the issues with the technical novelty and the lack of comparison, but it lacks grounding as it does not specify the exact sections of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty concerning spatial transformer networks (STN) and highlights the absence of comparisons to similar works. The reviewer supports this claim by mentioning existing works, such as PointNet, that have applied STN in a local pixel neighborhood. This provides a logical basis for the claim, as it references specific examples of similar approaches. However, the comment could be strengthened by providing more detailed comparisons or specific references to the works being compared. Overall, the claim is 4, as it is supported by logical reasoning and references to existing literature, but it could be more robust with additional details. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the technical novelty of the work concerning spatial transformer networks (STN) and highlights the lack of comparison to similar works. It points out that the proposed Xtransformation is similar to STN but applied locally, and notes existing works like PointNet that have applied STN in a local pixel neighborhood. This feedback is valuable as it directs the authors to consider the limitations of their approach and the need for a more comprehensive comparison to existing methods. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations or included examples of how to conduct such comparisons. Overall, the comment is 4 as it provides a clear direction for improvement but lacks detailed guidance on execution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a confusion regarding Eq. 12, specifically questioning the origin of the reward at each trial and whether it is taken from Eq. 11. It also suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The comment provides clear and explicit guidance on what needs to be clarified and how to address the issue, making it 5. The authors know exactly what needs to be done to improve the clarity of their paper, which aligns with the criteria for a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with Eq. 12, questioning the origin of the reward at each trial and whether it is taken from Eq. 11. Additionally, the comment suggests that explaining the network model with equations would improve clarity, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Eq. 12 is confusing and questions the origin of the reward at each trial, suggesting that it might be taken from Eq. 11. The reviewer provides references to external works that discuss similar concepts, which can help the authors understand the context and improve the clarity of their explanation. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is 4, as it provides some support but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with Eq. 12, questioning the origin of the reward at each trial and suggesting that it might be taken from Eq. 11. It also recommends explaining the network model in Sec. 4.2 with equations to improve clarity. This feedback is clear and actionable, providing the authors with a direct way to enhance the clarity of their paper. However, the comment could be more helpful if it included specific suggestions on how to clarify the equations or model explanation. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their work, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions. First, it corrects a reference from \"Fig.7\" to \"Fig.12\" on Supp. Page 31, which is a clear and direct instruction for the authors to make this correction. Second, it suggests that each theorem and corollary in the main paper should be linked to its corresponding proof, offering a specific and actionable recommendation for improving the paper\"s readability and organization. Both actions are concrete and provide clear guidance on how to implement the changes, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7\" should be \"Fig.12,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the figure reference and suggests a specific improvement by linking each theorem and corollary to its corresponding proof. Additionally, the comment highlights the primary concerns of the paper, such as motivation, methodology soundness, and experiment persuasion, and expresses confidence in the paper\"s quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a correction to a figure reference and a suggestion to link theorems and corollaries to their proofs. The correction is factual and does not contain a claim, so it is labeled as \"No.\" The second part suggests a specific improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion is 3 as it provides a logical basis for the recommendation but lacks comprehensive evidence or references. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two aspects of the paper. First, it corrects a reference from \"Fig.7\" to \"Fig.12\" on Supp. Page 31, which is a clear and direct correction that the authors can easily implement. Second, it suggests that each theorem and corollary in the main paper should be linked to its corresponding proof, which would enhance the paper\"s readability and help readers follow the arguments more easily. Additionally, the comment acknowledges the paper\"s strengths, such as its motivation, methodology soundness, and empirical results, which adds context to the feedback. Overall, the comment is 4 as it provides clear and constructive suggestions for improvement, but it could be more comprehensive by offering additional guidance on how to effectively link theorems and corollaries to their proofs. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definitions and selection of action verbs and action frames. It explicitly asks for the specific 50 classes chosen and how they were selected, as well as whether the action verbs are explicitly tagged as action verbs by Levin. Additionally, it questions the definition of \"action frames\" and how they are chosen. While the comment identifies specific areas of confusion and provides clear questions for clarification, it does not offer explicit guidance on how to address these issues or suggest improvements. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to resolve the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and specific line numbers (248, 306ff), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the definitions and selection of action verbs and action frames, as well as the criteria for choosing the 50 classes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the definitions and selection of action verbs and action frames. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks to understand specific aspects of the paper, making it a normal statement.", "helpfulness_rationale": "The review comment raises several questions and requests for clarification regarding the definitions and selection of action verbs and action frames. It specifically asks for the 50 classes chosen, how they were selected, and whether the action verbs are explicitly tagged as action verbs by Levin. Additionally, it questions the definition of \"action frames\" and how they are chosen. While the comment identifies areas of confusion and prompts the authors to clarify their methodology, it lacks actionable suggestions or guidance on how to address these issues. The feedback is 3 as it highlights specific areas needing clarification, but it does not provide detailed advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a minor typographical error in the text, specifically the incorrect use of \"Empiically\" instead of \"Empirically.\" While the comment highlights the issue, it does not provide any guidance on how the authors should address this error or suggest any specific actions to take. The action is implicit and lacks concrete details, making it difficult for the authors to know what steps to follow to correct the error. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, \"Empiically\" should be \"Empirically,\" providing a clear and direct suggestion for correction. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor typographical error in the text, specifically the incorrect spelling of \"Empiically\" instead of \"Empirically.\" While this is a straightforward correction, it does not provide any additional context or suggestions on how this error might impact the paper or how it could be addressed. The comment lacks depth and does not offer actionable feedback that would help the authors improve their draft. As a result, it is 2, as it only points out an error without providing guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, as discussed in the appendix. While the comment implies that the authors should explore this area, it does not provide specific guidance on how to integrate representation learning into the feature selection process. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"Line 167174,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the feature selection could be further improved by considering representation learning, as discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection in Section 4.2 could be improved by considering representation learning, as discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed explanations of how representation learning could enhance the feature selection process. This makes the claim 3, as the authors would need to infer the specific aspects of representation learning that could be beneficial, but the comment does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection in Section 4.2 could be enhanced by considering representation learning, as discussed in the appendix. This feedback is 3 as it points out a specific aspect that could be expanded upon, potentially leading to a more comprehensive analysis. However, the comment lacks detailed guidance or suggestions on how to integrate representation learning into the feature selection process. While it provides a direction for improvement, it does not offer a complete picture or actionable steps for the authors to follow. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the lack of understanding about how to design the rewards. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific details are missing. The action is implicit, as the authors can infer that they need to clarify the design of the rewards, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of understanding about how to design the rewards, which suggests that the paper is missing detailed information on this aspect. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where the rewards are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing details about the reward design, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding about how to design the rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where details are missing, namely the understanding of how to design the rewards. This feedback is 3 as it highlights a gap in the paper that the authors need to address. However, the comment lacks depth and does not provide suggestions or guidance on how to improve the clarity or comprehensiveness of the section discussing the reward design. Without actionable advice or specific examples, the authors may struggle to effectively address the feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper regarding the generalization of the model to different numbers of entities, suggesting that the authors should clarify this issue. However, it does not provide explicit guidance on how to address this limitation or what specific changes should be made to the paper. The comment implies that the authors should discuss or demonstrate how their model can be generalized, but it lacks concrete steps or suggestions for implementation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on how to generalize the model to different numbers of entities. The comment provides a concrete example of the problem, making it easy for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of entities is fixed and does not clearly explain how to generalize the model to different numbers of entities, referencing figure 3 of INs. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. The absence of detailed justification or examples results in the comment being considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper regarding the generalization of the model to different numbers of entities. It highlights this issue by referencing figure 3 of INs, which presumably illustrates the problem. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation. While it points out a potential area for improvement, it does not offer specific steps or examples to help the authors enhance their work. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the incremental nature of the work, suggesting that it lacks novelty but requires significant engineering and execution effort. It mentions that the authors should provide a code release after revision. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the novelty or execution. The action is implicit and somewhat vague, as the authors need to infer that they should provide a code release and may not know exactly how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the incremental nature of the work, suggesting it lacks novelty but requires significant engineering and execution effort. It mentions that the authors should provide a code release after revision. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in detailing the perceived weakness and the need for a code release, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is an incremental improvement to a KNN based machine translation (MT) approach, characterized by little novelty but requiring significant engineering and execution effort. The reviewer supports this claim by mentioning the reliance on a good experimental design and the potential for the authors to execute the idea themselves. However, the comment lacks specific examples or references to substantiate the claim about the lack of novelty. Additionally, it does not provide detailed reasoning or evidence to fully support the assertion that the work is incremental. As a result, the claim is 3, as it provides some justification but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment critiques the incremental nature of the work, suggesting that it lacks novelty but requires significant engineering and execution effort. It highlights the reliance on a good experimental design and the potential for the authors to execute the idea themselves. The comment also mentions the need for a code release after revision, which is a relevant point for the authors to consider. However, the feedback could be more helpful if it provided specific suggestions on how to enhance the novelty or execution of the work. Overall, the comment offers some insight into potential weaknesses and areas for improvement, but it could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the computational efficiency of MLbased emulators, such as Prithvi WxC, should be discussed, given its large parameter count. It implies that the authors should consider the runtime as a limitation for applications that rely on these emulators. While the comment provides a clear action\u2014discussing the runtime\u2014 it lacks specific guidance on how to present this information or what aspects of the runtime should be highlighted. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment suggests discussing the computational efficiency of MLbased emulators, specifically mentioning the runtime of Prithvi WxC and its large parameter count. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to address the computational efficiency and runtime, providing clear guidance on what needs to be discussed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational efficiency of MLbased emulators, such as Prithvi WxC, should be discussed due to its large parameter count. The comment suggests that the runtime should be noted as a limitation. However, it lacks specific examples or references to support the claim about the computational efficiency or the impact of the large parameter count. Without detailed evidence or examples, the claim is 3, as it provides a general rationale but requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the computational efficiency of MLbased emulators like Prithvi WxC, given its large parameter count. It suggests that the runtime should be discussed as a limitation for applications relying on these emulators. This feedback is clear and actionable, as it provides a specific area for the authors to address, potentially improving the paper\"s discussion on the practicality and limitations of their approach. However, the comment could be more helpful if it offered suggestions on how to present or discuss the runtime effectively. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the idea is insufficient and notes that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the idea and points out that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the novelty are lacking or how the new metric and method are straightforward. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the claim is considered 1 due to the lack of supporting details or examples.", "helpfulness_rationale": "The review comment points out that the novelty of the idea is insufficient and critiques the new metric and method as being relatively straightforward. While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment highlights areas for enhancement but does not offer detailed guidance on how the authors might address these issues or what specific aspects could be improved. As a result, the feedback is 3, as it prompts the authors to reconsider the novelty and complexity of their work, but it does not fully support them in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper overstates the contribution of the method, making it less clear. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the framing need to be revised. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper overstates the contribution of the method, making it less clear. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspects of the framing need to be revised. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper overstates the contribution of the method, making it less clear. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the framing of the paper, suggesting that it overstates the contribution of the method, making it less clear. While this feedback highlights a concern, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. Without detailed suggestions or examples, the authors are left with a general idea of the problem but without clear direction on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps, which would enhance understanding. It also mentions that having too many symbols and a notation table could be better. While the comment provides some guidance on potential improvements, it does not explicitly instruct the authors to make these changes or specify how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the potential benefit of having a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors might infer that it relates to the model description, but this inference is not direct. The comment is specific in its suggestions but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and by having a notation table. However, the comment lacks specific examples or detailed reasoning to support why these changes would enhance understanding. The suggestion is somewhat vague and does not provide enough evidence or context to fully substantiate the claim. Therefore, the comment is categorized as 2, as it provides some direction but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests improvements to the model description, specifically recommending that the generative process be presented in separate steps for better understanding and that a notation table could be more effective. While the comment identifies areas for enhancement, it lacks specific guidance on how to implement these suggestions or provides examples of what might be improved. The feedback is 3 as it points out potential areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrased training data and its impact on the subsequent steps. It suggests that the authors should clarify how different the paraphrases are from the original sentences, as this is crucial for the model\"s reliance on the quality of the training data. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the paraphrasing process. The action is implicit and somewhat vague, as the authors need to infer that they should ensure the paraphrases are sufficiently different from the original sentences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for the training data, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the quality of the paraphrases and their impact on the subsequent steps, particularly the reliance on the quality of the training data. The comment provides a clear understanding of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrased training data and its impact on the model\"s reliance on the data. It suggests that the difference between the paraphrases and the original sentences is crucial, as it affects the quality of the final training data. However, the comment lacks specific examples or references to support the claim that the difference is not large enough, making it difficult for the authors to understand and address the issue effectively. The lack of detailed justification or evidence makes the claim 3, as it provides a general observation but requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical issue with the generation of paraphrased training data, specifically the lack of clarity on how different these paraphrases are from the original sentences. This is crucial because the model\"s reliance on the quality of the training data is significant, and poor paraphrasing could lead to lowquality training data and fewer pairs being added to the new training data. The comment provides a clear and actionable insight into the importance of the paraphrasing process and its impact on the model\"s performance. However, it could be more helpful if it offered suggestions on how to ensure the paraphrases are sufficiently different from the original sentences or provided examples of what constitutes a meaningful difference. Overall, the comment is 4 as it highlights a key area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on how to improve the clarity of the paper, specifically regarding the presentation of humanidentified rationales. It suggests that Figure 2 is cluttered and that the \"bold\" text is difficult to see, recommending the use of another color or a larger font to enhance readability. This feedback is clear and actionable, giving the authors specific steps to take to improve the presentation of their work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation of the rationales, suggesting that the \"bold\" text is hard to see and recommending the use of another color or a larger font. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales is not a simple problem, particularly for complex NLP tasks like machine translation. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It also suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, but it does not offer specific examples or references to support these observations. As a result, the claim is 1 due to the lack of detailed justification or evidence. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides specific feedback on the presentation of the paper, particularly regarding the clarity of Figure 2. It points out that the \"bold\" text is difficult to see, suggesting that using another color or a larger font could improve readability. This feedback is actionable and offers a clear way for the authors to enhance the visual presentation of their work, making it easier for readers to understand the humanidentified rationales. However, the comment could be more helpful if it included suggestions for other areas that might need similar attention. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the FlippedQA framework, which is described as general for various generative VideoQA models, should be tested on nonLLMbased models like HiTeA and InternVideo. The reviewer implies that the authors should conduct further verification to assess the framework\"s effectiveness and universality. While the action is implicit, it is concrete because it specifies the models to test and the purpose of the verification. The authors know exactly what needs to be done to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework, described as general for various generative VideoQA models, should be tested on nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper discusses the FlippedQA framework or where the authors have already applied it to LLMbased models. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the need to test the framework on additional models, it is 1 because it does not provide clear guidance on where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the FlippedQA framework is general for various generative VideoQA models but only applies it to LLMbased models. The reviewer suggests that further verification on nonLLMbased models like HiTeA and InternVideo would be beneficial. However, the comment lacks specific examples or references to support the claim that the framework is general or to demonstrate the potential benefits of testing it on nonLLMbased models. This makes the claim 3, as the authors would need to infer the reasoning and provide additional evidence to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, suggesting that the FlippedQA framework, described as general for various generative VideoQA models, is only applied to LLMbased models. The reviewer recommends further verification of the framework\"s effectiveness and universality when applied to nonLLMbased models like HiTeA and InternVideo. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by testing the framework on additional models. However, the comment could be more helpful if it included specific examples or suggested methods for testing the framework\"s universality. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the writing could be improved, but it does not provide specific guidance on how to enhance it. The reviewer mentions that it took effort to understand the main idea and theoretical analysis, but this feedback lacks actionable details. The authors are left without a clear understanding of what aspects of the writing need improvement or how to address the complexity of the content. As a result, the comment is 1 because it does not offer any specific steps or suggestions for improvement.", "grounding_specificity_rationale": "The comment indicates that the writing could be improved, but it does not specify which part of the paper this issue pertains to. It mentions that it took effort to understand the main idea and theoretical analysis, but without pointing to specific sections or examples, the authors cannot confidently determine which parts need revision. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, but it does not provide any specific examples or reasoning to support this claim. The comment lacks detailed feedback or suggestions on how the writing could be enhanced, making it difficult for the authors to understand the basis of the critique. Without specific examples or guidance, the claim is 1, as it does not provide enough information for the authors to address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment indicates that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it lacks specificity and does not provide actionable feedback or suggestions on how to enhance the writing. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. This makes the comment 2, as it identifies a general area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the use of existing methods and suggests that the proposed method lacks theoretical novelty. It implies that the authors should address these concerns to improve their score. However, it does not provide specific guidance on how to address the lack of theoretical novelty or how to enhance the method. The action is implicit and vague, as the authors are left to infer that they need to provide more theoretical justification or innovation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of existing methods, such as ClopperPearson intervals and Gaussian elimination, which allows the authors to identify the specific part of the paper being addressed. It also specifies the concern regarding the lack of theoretical novelty, providing a clear indication of what needs to be addressed. The mention of specific references (1 and 2) further supports the grounding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks theoretical novelty, as it primarily builds upon existing methods like ClopperPearson intervals and Gaussian elimination. The comment provides references to these methods, which adds some level of support to the claim. However, the comment does not offer detailed reasoning or examples to fully substantiate the claim about the lack of theoretical novelty. This makes the claim 3, as it provides some evidence but lacks comprehensive justification. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment acknowledges the use of existing methods and points out the lack of theoretical novelty in the proposed method. It suggests that the authors should address these concerns to improve their score. However, the comment does not provide specific guidance or suggestions on how to enhance the theoretical novelty or address the concerns. While it identifies a potential weakness, it lacks actionable feedback or detailed advice, making it 3. The authors are left with a general idea of what needs to be improved but without concrete steps to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input is concatenated by the four text elements of an object. While it implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify this point in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the concatenation of text input by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This makes it difficult for the authors to pinpoint the exact location in the paper where this clarification is needed. While the question is specific in nature, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text input by the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the concatenation of text input by the four text elements of an object. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the concept. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could improve by first motivating the \"Why\" aspect, i.e., explaining why the presented topic is important or relevant. However, it does not provide specific guidance on how to address this issue or what kind of motivation would be effective. The action is implicit and vague, as the authors are left to infer that they need to add a section or explanation to motivate the importance of their work. Without concrete suggestions or examples, the authors may struggle to understand how to implement this feedback effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper could improve by first motivating the \"Why\" aspect, i.e., explaining the importance or relevance of the presented topic. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to improve the motivation, but without clear grounding, the authors may find it challenging to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could improve by first motivating the \"Why\" aspect, i.e., explaining the importance or relevance of the presented topic. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could improve by first motivating the \"Why\" aspect, i.e., explaining the importance or relevance of the presented topic. This feedback is 3 as it identifies a potential area for improvement, prompting the authors to consider the necessity of providing a clear rationale for their work. However, the comment lacks specificity and does not offer detailed guidance on how to address this issue or what kind of motivation would be most effective. Without concrete suggestions or examples, the authors may struggle to understand how to implement this feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 of the abstract is cumbersome and can be made clearer. It provides a direct action for the authors to take, which is to rephrase the sentence to improve clarity. The comment is specific in its request for a clearer sentence, making it 5. The authors know exactly what needs to be done to improve the abstract, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and the specific lines (\"lines 1217\") where the issue is identified. This allows the authors to accurately pinpoint the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, making the sentence in lines 1217 clearer. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning or examples to support why the sentence is considered cumbersome or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that a particular sentence is cumbersome and suggests it can be made clearer. This feedback is actionable as it provides a clear direction for the authors to improve the clarity of their abstract. By rephrasing the sentence, the authors can enhance the readability and professionalism of their work. However, the comment could be more helpful if it offered specific suggestions on how to rephrase the sentence or provided examples of clearer phrasing. Overall, the comment is 4 as it directs the authors toward a concrete improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the experimental setup, where the domainspecific model and experiments are both conducted on Pix3D. The reviewer suggests that such comparisons to zeroshot singleimage 3D reconstruction models are unfair. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or actionable advice, leaving the authors uncertain about how to improve their draft. The feedback is vague and does not offer a clear path for action, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"domainspecific model\" and \"experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the comparisons to zeroshot singleimage 3D reconstruction models are unfair, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparisons to zeroshot singleimage 3D reconstruction models are unfair because the domainspecific model and experiments are both conducted on Pix3D. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed evidence or references to substantiate the assertion that these comparisons are unfair. As a result, the claim is considered 2, as it provides some reasoning but lacks sufficient detail or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically noting that the domainspecific model and experiments are both conducted on Pix3D. It suggests that comparisons to zeroshot singleimage 3D reconstruction models are unfair, which is a valid concern. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. The authors would gain some insight into the problem but may need to explore additional resources or guidance to fully address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance. It also mentions that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that by adjusting hyperparameters in Decouple Kang et al., the tail accuracy could be significantly improved while slightly decreasing the head accuracy. The comment provides a clear and specific action for the authors to take, which is to investigate and address the tradeoff between head and tail categories in the baselines. This feedback is concrete and actionable, giving the authors a clear direction for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proposed approach not outperforming or being worse than Decouple Kang et al., and it highlights the tradeoff between head and tail categories that has not been fully investigated. The comment also provides a suggestion for improvement by suggesting that adjusting hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance, as evidenced by the results shown in the paper. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that by adjusting hyperparameters in Decouple Kang et al., the tail accuracy could be significantly improved while slightly decreasing the head accuracy. This claim is supported by specific references to the results and the tradeoff analysis, providing a clear and logical basis for the critique. However, the comment could be strengthened by including more detailed examples or specific data points to fully substantiate the claim. Overall, the comment is 4, as it provides a solid foundation for the critique but could benefit from additional evidence.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting that the proposed approach does not outperform or is worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that by adjusting hyperparameters in Decouple Kang et al., the tail accuracy could be significantly improved while slightly decreasing the head accuracy. This feedback is clear and actionable, offering specific suggestions for improvement that could enhance the paper\"s performance and comprehensiveness. By addressing these points, the authors can significantly improve the quality and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (CrossView Deep Learning) approach. While the comment implies that these experiments should be conducted, it does not explicitly instruct the authors to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to support the C2D approach. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include more experiments, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, the comment does not provide any specific reasoning or evidence to justify why these experiments would be beneficial or how they would enhance the paper\"s support for C2D. Without detailed explanation or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (CrossView Deep Learning) approach. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the approach would benefit from such experiments. The feedback is 3 as it points out a potential enhancement to the paper, but it does not offer actionable steps or detailed suggestions for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation is limited, relying mostly on four OCR QA datasets, and suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. While the comment implies that the authors should consider expanding their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more datasets for a more comprehensive evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the reliance on four OCR QA datasets and suggesting the inclusion of more scenarios like the LLaVA benchmark. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in suggesting the need for additional scenarios, particularly for ablation studies, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark would be expected, especially in ablation studies. The comment provides a logical reasoning by pointing out the reliance on limited datasets and suggesting the need for additional benchmarks. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the rationale to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It suggests that the evaluation may be unreliable and recommends considering additional scenarios, such as the LLaVA benchmark, especially for ablation studies. This feedback is clear and actionable, as it provides a specific direction for improving the evaluation\"s comprehensiveness and reliability. However, it could be more helpful if it offered suggestions on how to incorporate these additional scenarios or provided examples of how they might enhance the evaluation. Overall, the comment is 4, as it guides the authors toward a more robust evaluation framework."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the abstract visual reasoning tasks, noting their unintuitiveness and difficulty. It questions the necessity of the current formulation and asks for proof that simpler tasks wouldn\"t suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as it lacks concrete steps or examples for the authors to follow. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the abstract visual reasoning tasks, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper these tasks are discussed in, making it weakly grounded. The comment raises concerns about the tasks being unintuitive and difficult, and questions the necessity of the current formulation. It also asks for proof that simpler tasks wouldn\"t suffice. While the comment is specific in its questioning, it lacks grounding as it does not point to a specific section or part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concern about the abstract visual reasoning tasks, noting their unintuitiveness and difficulty. The reviewer questions the necessity of the current formulation and asks for proof that simpler tasks wouldn\"t suffice. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the tasks are overly difficult or that simpler tasks would be more effective. This makes the claim 3, as it provides a general critique but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitiveness and difficulty. It questions the necessity of the current formulation and asks for proof that simpler tasks might be more effective. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it prompts the authors to reconsider the approach and provides a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that weak supervision could be better evaluated by assessing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it notes that the generation of authors is not realistic, as their embeddings are initialized by averaging the corresponding artificial tweets. While the comment provides some direction for improvement, it lacks explicit instructions or concrete steps on how to evaluate the realism of the tweets or address the issue with the initialization of embeddings. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It provides specific examples, such as the requirement for all structured elements for perspectives to be present in the generated tweets and the issue with the initialization of embeddings. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the realism of the tweets and the generation of authors. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the evaluation of weak supervision, specifically regarding the realism of the evaluated tweets and the generation of authors. It provides a logical reasoning by pointing out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it notes that the generation of authors is not realistic, as their embeddings are initialized by averaging the corresponding artificial tweets. This provides a clear rationale for the critique, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the realism of the generated tweets. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation of authors. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it notes that the generation of authors is not realistic, as their embeddings are initialized by averaging the corresponding artificial tweets. This feedback is 3 as it identifies potential issues with the evaluation process and provides a direction for improvement by suggesting a more realistic approach. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these concerns. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of essential visualization of intermediate processes and comparisons, but it does not provide any explicit or implicit actions for the authors to take. It does not specify what kind of visualizations are missing or how they should be incorporated into the paper. Without guidance on what needs to be added or how to improve the visualization, the authors are left without a clear understanding of what steps to follow to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where the visualization is missing or how it should be addressed. Additionally, the comment lacks specificity regarding what kind of visualizations are needed or how they could be incorporated into the paper. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where visualization is missing or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out the lack of essential visualization of intermediate processes and comparisons. This feedback is valuable as it directs the authors to a critical aspect of their work that could enhance the clarity and comprehensiveness of their findings. However, the comment does not provide specific suggestions on how to incorporate these visualizations or what types of visualizations would be most effective. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the importance of the result and provides a rationale by referencing a previous work (15) that suggests the decentralized algorithm with occasional noise is not surprising in terms of escaping saddle points. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve their draft. As a result, the comment lacks actionability, leaving the authors without any clear steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the importance of the result and provides a rationale by referencing a previous work (15) that suggests the decentralized algorithm with occasional noise is not surprising in terms of escaping saddle points. However, it does not specify which part of the paper this concern pertains to, such as specific sections or results. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its critique of the result\"s importance but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the importance of the result by referencing a previous work (15) that suggests the decentralized algorithm with occasional noise is not surprising in terms of escaping saddle points. The reviewer provides a logical reasoning by explaining that the iteration complexity is no longer dimensionfree, which supports the claim. However, the comment lacks specific examples or detailed references to fully substantiate the claim, making it 3. The authors would need to further explore the references and reasoning to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the importance of the result, referencing a previous work (15) that suggests the decentralized algorithm with occasional noise is not surprising in terms of escaping saddle points. The reviewer provides a logical reasoning by explaining that the iteration complexity is no longer dimensionfree, which adds depth to the critique. However, the comment lacks specific suggestions or actionable feedback on how the authors might address this concern or improve their draft. While it identifies a potential weakness, it does not provide detailed guidance on how to enhance the paper\"s contribution or significance. Therefore, the comment is 3, as it offers some insight but lacks comprehensive support for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a direct and clear action, providing the authors with a specific task to perform. The comment is concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that keypoint detection results should be included in the experiments section. However, it does not specify which part of the paper this section is located in, making it weakly grounded. The comment is specific in its request for inclusion, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with label 3.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that keypoint detection results should be included in the experiments section. This is a specific and actionable piece of feedback that can help the authors improve their draft by ensuring that all relevant results are presented in the correct section. However, the comment does not provide further guidance on how to present these results or why they are important, which could enhance its helpfulness. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their proposed model with existing models where answers are used as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This provides a clear and explicit action for the authors to take, which is to conduct a comparison with a specific existing model. The comment is concrete as it specifies which models to compare with and what aspect of the comparison is relevant. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models where answers are used as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This provides a clear reference to a specific existing model, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific in suggesting a particular comparison to make, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models where answers are used as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This claim is 3 as it provides a specific reference to an existing model for comparison, which can help the authors understand the context of the comparison. However, the comment could be strengthened by explaining why this comparison is relevant or how it would impact the evaluation of the proposed model. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a comparison with existing models where answers are used as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by comparing their model with a relevant baseline. By doing so, the authors can better understand how their proposed model stands in relation to existing approaches, potentially leading to more robust conclusions. However, the comment could be more helpful if it included additional context or rationale for why this comparison is important. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not provide any explicit or implicit suggestions for action. The comment lacks guidance on how the authors might address this question or what changes could be made to improve the draft. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the grid search is described. This makes it difficult for the authors to pinpoint the exact location of the issue. Additionally, the comment lacks specificity regarding what might be incorrect or missing in the grid search process. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking whether the grid search of the learning rate is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, making it a \"No\" label.", "helpfulness_rationale": "The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide any guidance or suggestions for the authors to address this question or improve their draft. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to enhance their work. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in the treebank and whether they are artifacts of colloquial language or if \"discourse\" was used for nondiscourse elements in other languages. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the table. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank and whether they are artifacts of colloquial language or if \"discourse\" was used for nondiscourse elements in other languages. This provides clear guidance on what the authors need to consider or clarify. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in the treebank and whether they are artifacts of colloquial language or if \"discourse\" was used for nondiscourse elements in other languages. However, it does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the number of discourse relations in the treebank and whether they are artifacts of colloquial language or if \"discourse\" was used for nondiscourse elements in other languages. This is a relevant and insightful observation that could help the authors understand potential issues with their dataset or methodology. However, the comment lacks actionable suggestions or guidance on how the authors might address this concern or improve their analysis. While it identifies a potential area for improvement, it does not provide specific steps or insights for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample, specifically regarding racial and economic diversity, and its implications for generalization to other groups, particularly marginalized ones. While it prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address the issue. The action is implicit, as the authors can infer that they need to explore and discuss diversity in their sample, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the diversity of the sample, particularly regarding racial and economic diversity, and its implications for generalization to other groups, especially marginalized ones. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample and its implications for generalization to other groups, particularly marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why this is an important consideration or how it might impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample, specifically regarding racial and economic diversity, and its implications for generalization to other groups, particularly marginalized ones. This feedback highlights a potential weakness in the paper\"s generalizability and encourages the authors to consider the diversity of their sample. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the analysis. While it prompts the authors to think about an important aspect of their work, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the issue of output quality being reasonable but not realistic, given the advancements in GAN works. It suggests that there is still room for improvement in the result quality. However, the comment does not provide specific guidance on how to enhance the output quality or what aspects of the output could be improved. The authors are left with a general idea of what needs to be addressed but without concrete steps or suggestions. The lack of explicit and detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but far from realistic, given the advancements in GAN works. It suggests that there is still room for improvement in the result quality. However, the comment does not specify which part of the paper discusses the output quality or where the authors should focus on improving it. This makes it weakly grounded, as the authors cannot confidently determine the exact sections or aspects being addressed. The comment is specific in its critique of the output quality and the potential for improvement, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but far from realistic, given the advancements in GAN works. The reviewer supports this claim by referencing the significant quality improvements in recent GAN works and the increased bar for result quality. However, the comment lacks specific examples or references to these advancements, making it 3. The authors would need to further explore the literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but far from realistic given the advancements in GAN works. It provides a logical reasoning by referencing the progress in GANs and the increased bar for result quality. However, the comment lacks specific suggestions or actionable steps for improving the output quality, such as recommending potential techniques or methods that could enhance the results. While it highlights a critical area for improvement, the feedback could be more helpful if it offered detailed guidance or examples. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of subpar hyperparameters and the unclear rationale behind the choice of hyperparameters, particularly in the context of soft labels and crossentropy loss. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their hyperparameter selection. The feedback lacks concrete steps or actionable advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the use of subpar hyperparameters and the unclear rationale behind the choice of hyperparameters, particularly in the context of soft labels and crossentropy loss. However, it does not specify which part of the paper these concerns pertain to, such as specific sections or figures where hyperparameters are discussed. The authors might infer that these concerns relate to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue with hyperparameter selection but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of subpar hyperparameters and the unclear rationale behind the choice of hyperparameters, particularly in the context of soft labels and crossentropy loss. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of explicit evidence or justification makes it difficult for the authors to understand and address the issues raised. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the use of subpar hyperparameters and the unclear rationale behind the choice of hyperparameters, particularly in the context of soft labels and crossentropy loss. It points out that the authors might be using suboptimal hyperparameters, which could impact the validity of their results. However, the comment does not provide specific suggestions or guidance on how the authors could address these issues or improve their hyperparameter selection. While it identifies a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include more evaluation on classifying unseen words, specifically mentioning the addition of translations to Figure 6 for nonChinese speakers. While the comment implies that the authors should expand their evaluation, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete suggestion for how to implement it by adding translations to the figure. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding translations to Figure 6 to aid in classifying unseen words, providing a clear direction for improvement. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and recommends additional evaluation on classifying unseen words. The comment implies that more evaluation is needed, but it does not provide specific examples or detailed reasoning to support why this additional evaluation is necessary. The suggestion to add translations to Figure 6 is a minor point, and the overall claim is 3 due to the lack of detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the value of the simple/traditional experiment for unseen characters but suggests that it is presented as an afterthought. It provides a specific suggestion for improvement by recommending additional evaluation on classifying unseen words, particularly by adding translations to Figure 6 for nonChinese speakers. This feedback is clear and actionable, offering a concrete way for the authors to enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it included further guidance on how to conduct this additional evaluation or why it is particularly important. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the number of images in the VioT dataset, suggesting that 20 images per category might be insufficient to validate the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the dataset size, what specific changes to make, or how to address the concern. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the number of images (20 per category) and suggests that this might be insufficient to validate the approach. The comment provides a clear indication of what needs to be addressed regarding the dataset size and its impact on the validity of the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the number of images in the VioT dataset, suggesting that 20 images per category might be insufficient to validate the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this number of images is considered small or why it might affect the validity of the approach. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the study, specifically noting that only 20 images are provided for each of the four categories. The reviewer expresses concern about whether this number of images is sufficient to validate the approach. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the dataset. Without actionable feedback or detailed reasoning, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an ablation study comparing the number of layers versus performance, which could be interesting. However, it does not provide explicit guidance on how to conduct this study or what specific aspects should be examined. The comment implies that the authors should consider this suggestion, but it lacks concrete details on how to implement it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests an ablation study comparing the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what kind of study would be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study comparing the number of layers versus performance, which is a specific suggestion for improvement. However, it does not provide any supporting evidence, reasoning, or examples to justify why this study would be beneficial or how it would enhance the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting idea for an ablation study comparing the number of layers versus performance, which could be a valuable addition to the paper. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this study or what specific aspects should be examined. While it identifies a potential area for improvement, the feedback is vague and does not offer actionable steps for the authors to follow. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including difficulty in following the content, the need for more intuitive explanations of mathematical derivations, and the lack of figure captions and legends. It explicitly suggests that the authors should provide additional explanations and legends for the figures, such as explaining the colors used in Figure 2. While the comment identifies specific areas that need improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The authors are left with a general idea of what needs to be done but without concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Fig. 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the paper, such as the need for more intuitive explanations of mathematical derivations, the lack of figure captions, and the requirement for additional explanations and legends, including color explanations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of figure captions and the need for additional explanations and legends, such as explaining the colors in Figure 2. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for more detailed explanations and legends, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the need for more intuitive explanations of mathematical derivations and the lack of figure captions and legends. It specifically mentions the need for additional explanations and legends, such as explaining the colors in Figure 2, and notes that Figures 1 and 2 did not contribute much to the understanding. This feedback is clear and actionable, providing the authors with specific suggestions for enhancing the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered examples of how to make the explanations more intuitive or detailed. Overall, the comment is 4 as it guides the authors toward improving the presentation and accessibility of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should investigate the robustness of their results, but it lacks concrete steps or specific actions to take. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. However, it does not specify which part of the paper this concern pertains to, making it weakly grounded. The comment is specific in identifying the need to address the sensitivity of results to hyperparameter choices, but without clear guidance on how to do so, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. The reviewer suggests that incorrect choices could potentially negate the benefits of the method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue effectively. The lack of detailed justification or evidence makes the claim 3, as it provides a general concern but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. This is an important point that the authors should address to ensure the robustness and reliability of their findings. However, the comment lacks specific suggestions or guidance on how the authors might investigate or mitigate this issue. While it identifies a significant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, given that it utilizes existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation or justification for the novelty and contribution, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. It implies that the authors need to further claim the novelty and contribution of their proposed method. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors need to clarify the novelty and contribution of their method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of novelty they could emphasize. The feedback is 3 as it prompts the authors to consider the novelty of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues: the text in table 1 being too small and hard to read, and the missing gradient symbol in line 4 of Algorithm 1. While the comment explicitly states these issues, it does not provide guidance on how to address them, such as suggesting ways to improve the readability of the table or recommending a solution for the missing gradient symbol. The authors are left with a clear understanding of the problems but without concrete steps to resolve them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"line 4 of Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the text being too small and hard to read, and the missing gradient symbol in Algorithm 1. Additionally, it provides references to specific works, which adds depth to the feedback. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations about the readability of text in Table 1 and the presence of a missing gradient symbol in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues: the text in Table 1 being too small and hard to read, and the missing gradient symbol in line 4 of Algorithm 1. These observations are clear and actionable, providing the authors with concrete feedback on areas that need improvement. However, the comment could be more helpful if it offered suggestions on how to address the readability issue or how to correct the missing gradient symbol. Despite this, the feedback is 4 as it directs the authors to specific areas requiring attention and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should render the text more naturally by using bracketed arguments as mentioned in Wright et al., 1934, and Figure 1. It also questions the compatibility of this approach with hyperref. While the comment provides a specific suggestion for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should use bracketed arguments and consider the hyperref compatibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and references \"Wright et al., 1934,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of bracketed arguments for rendering text more naturally and questions the compatibility with hyperref. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should use bracketed arguments as mentioned in Wright et al., 1934, to render text more naturally. However, the comment lacks specific examples or detailed reasoning to support why this approach would be more natural or beneficial. The mention of \"Figure 1\" and the reference to hyperref is also vague, as it does not provide clear guidance on how this might affect the document. Without explicit justification or examples, the claim is difficult for the authors to address effectively, making it 2.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the rendering of text by recommending the use of bracketed arguments as referenced in Wright et al., 1934. This is a clear and actionable piece of feedback that could enhance the clarity and professionalism of the paper. However, the comment does not address other potential areas for improvement, such as the use of hyperref or other aspects of the text that might need attention. While the suggestion is valuable, it could be more helpful if it included additional guidance or examples. Overall, the comment is 3 as it offers a specific suggestion but lacks comprehensive guidance for further improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the discussion of computational aspects, noting that the authors do not adequately address this topic beyond a brief mention in the appendix. It raises a concern about the practical usefulness of the proposed methods for highdimensional data, specifically mentioning the requirement of solving several linear programs (LPs) in high dimensions, each involving a parameter that is not easily calculable. The comment also points out that the experiments are conducted on very small scale datasets. While the comment identifies a gap in the discussion and raises concerns about the practicality of the methods, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to expand their discussion on computational aspects and consider the practicality of their methods for highdimensional data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, specifically mentioning the need for a more comprehensive exploration of this topic. It highlights the issue of the proposed methods\" practical usefulness for high dimensions, noting that the algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also points out that the experiments are performed on very small scale datasets. However, it does not specify which part of the paper should be expanded or revised to address these concerns, making it weakly grounded. The comment is specific in detailing the issues with computational aspects and the practicality of the methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss computational aspects, particularly in the context of highdimensional data. It highlights the requirement of solving several linear programs (LPs) in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are conducted on very small scale datasets. While the comment provides some logical reasoning about the computational challenges, it lacks specific examples or references to support the claim about the difficulty of calculating the parameter. This makes the claim 3, as the authors would need to further develop the argument to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of computational aspects, noting that the authors do not adequately address this topic beyond a brief mention in the appendix. It raises a critical concern about the practical usefulness of the proposed methods for highdimensional data, specifically mentioning the requirement of solving several linear programs (LPs) in high dimensions, each involving a parameter that is not easily calculable. The comment also points out that the experiments are conducted on very small scale datasets, which further highlights the issue. This feedback is clear and actionable, as it directs the authors to expand their discussion on computational aspects and consider the practicality of their methods for highdimensional data. However, it could be more helpful if it provided specific suggestions on how to address these issues or examples of how to improve the practicality of the methods. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific errors in the equations presented in the paper. It provides clear instructions for correcting the signs in the equations, such as changing a \"+\" sign to a \"\" sign and vice versa. Additionally, it specifies the exact lines where these corrections should be made, such as Line 502, Line 503, and Line 504. The comment also includes minor comments, indicating that the authors should consider these changes. Since the feedback is explicit and provides concrete instructions on how to correct the equations, the authors know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (Line 502, Line 503, and Line 504) where errors in the equations are identified. This allows the authors to accurately pinpoint the parts of the paper being addressed. The comment is also specific because it details the exact errors in the equations, such as the incorrect signs, and provides clear instructions on how to correct them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections to specific equations in the paper. It explicitly identifies the lines where errors occur and provides clear instructions on how to correct them. The comment is factual and descriptive, not making any subjective claims or judgments. Therefore, it does not contain any claims that require verification, and it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying errors in the equations presented in the paper. It clearly points out the incorrect signs in the equations and provides precise instructions on how to correct them. This level of detail is highly beneficial for the authors as it directly addresses potential issues that could affect the accuracy and correctness of their work. By correcting these errors, the authors can improve the quality and reliability of their paper. The comment is clear, concise, and offers a clear path for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a further interesting baseline could be compared to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between residual blocks and suggests a potential improvement by comparing to a deeper ResNet with parameter sharing. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a further interesting baseline could be compared to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment poses a question and suggests a potential improvement, it does not provide specific reasoning or evidence to support why this comparison would be beneficial or how it would enhance the paper. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a further interesting baseline could be compared to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for improvement and suggests a specific comparison that could enhance the paper\"s analysis. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the suggestion. Overall, the comment offers a clear direction for the authors to consider, but it could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of motivation for the crossencoder architecture, suggesting that it does not ignore crossentity comparisons and attends to all candidates simultaneously. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the motivation of their work. The feedback lacks actionable details, leaving the authors uncertain about how to enhance the motivation or address the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation of the crossencoder architecture, specifically questioning its ability to ignore crossentity comparisons and attend to all candidates simultaneously. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the crossencoder architecture, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture does not ignore crossentity comparisons and attends to all candidates simultaneously, which may result in less finegrained matching scores. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the motivation of the crossencoder architecture, suggesting that it does not ignore crossentity comparisons and attends to all candidates simultaneously, which may result in less finegrained matching scores. While the comment highlights a critical weakness in the paper\"s explanation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation of their work. The feedback is 3 as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a design choice in the paper, specifically the trimming of questions after the first 10, and suggests that this might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the design. The action is implicit and somewhat vague, as the authors are left to infer that they might need to reconsider the trimming process or provide reasoning for it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the design choice of trimming questions after the first 10 and questioning its oddness, especially since the question model is a bag of words, which is not expensive to encode longer sequences. This provides clear guidance on what aspect of the design choice needs to be reconsidered or clarified. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice given the nature of the question model as a bag of words. The comment provides a logical reasoning by pointing out that encoding longer sequences is not expensive, which supports the claim that the design choice is not as odd as it appears. However, the comment lacks specific examples or references to further substantiate the claim, making it 3. The authors would need to explore the reasoning themselves to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific design choice in the paper, namely the trimming of questions after the first 10, and questions its oddness given that the question model is a bag of words, which is not expensive to encode longer sequences. This feedback is 3 as it highlights a potential inconsistency in the design choice and prompts the authors to reconsider their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative design choices that might be more appropriate. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work uses an antiquated GNN model and method, which negatively impacts the framework\"s performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting the use of more modern models or methods. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an antiquated GNN model and method, suggesting that this impacts the performance of the framework. However, it does not specify which part of the paper discusses these models or methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the model or method are considered \"antiquated\" or how they impact performance. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an antiquated GNN model and method, which negatively impacts the framework\"s performance. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these antiquated models/methods are problematic. Without detailed justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which negatively impacts the framework\"s performance. This feedback is clear and highlights a critical weakness in the work. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending the use of more modern models or methods. While it points out a problem, the comment could be more helpful if it provided actionable advice or examples of how to improve the framework. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the explanation for \"mutagens containing the NO2 group.\" It suggests that additional analysis or postprocessing is needed to extract shared motifs, which the authors might find challenging. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or analysis to clarify the method\"s output. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the explanation of how the proposed method produces the explanation for \"mutagens containing the NO2 group,\" suggesting that additional analysis or postprocessing is needed. The comment provides a clear direction for improvement by indicating that the explanation is unclear and requires further elaboration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the proposed method produces the explanation for \"mutagens containing the NO2 group.\" It suggests that additional analysis or postprocessing is necessary to extract shared motifs, which the authors might find challenging. However, the comment lacks specific examples or references to support the claim that the explanation is unclear or that the proposed method simplifies this process. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanation provided by the proposed method regarding how it produces the explanation for \"mutagens containing the NO2 group.\" It highlights the need for additional analysis or postprocessing to extract shared motifs, which the authors might find challenging. While the comment points out a potential weakness in the explanation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. This limits the comment\"s usefulness, as it offers some insight but lacks actionable advice for the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the lack of true feature importance. It acknowledges the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which affects the trustworthiness of the experiment. The comment suggests that the experiment could be strengthened in two ways, but it does not specify what those ways are. While the authors know that they need to address the issue, the lack of concrete guidance on how to improve the experiment makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment related to estimating the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiment, explaining that it relies on pseudo feature importance due to the lack of true feature importance. The comment further specifies the potential ways to strengthen the experiment, such as considering the number of perturbations or other factors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment\"s reliance on pseudo feature importance is problematic due to the lack of true feature importance. It supports this claim by referencing Proposition 3.2 and the choice of a large enough perturbation value, which affects the trustworthiness of the experiment. The comment also suggests ways to strengthen the experiment, providing a logical basis for its critique. However, the explanation could be more detailed, such as providing specific examples or further elaboration on the implications of the pseudo feature importance. Overall, the comment is 4, as it provides a reasonable basis for the claim but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, namely the reliance on pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which affects the trustworthiness of the experiment. The comment suggests that the experiment could be strengthened by considering the number of perturbations or other factors. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it offered additional suggestions or examples on how to address the issue. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if Z has certain good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific properties of Z could be beneficial for the convergence of SGD. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182184, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if Z has certain good properties. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the nonconvexity of the function Z and suggests that it may not be a problem for the SGD to converge if Z has certain good properties. While this observation is relevant, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or what properties of Z could be beneficial for the convergence of SGD. Without actionable feedback or detailed insights, the authors are left with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific lines that should be moved to the Supplementary Material (SuppMat), namely lines 502, 507, and 509. It provides clear instructions on which lines need to be moved and to which sections they should be moved. This direct and specific guidance allows the authors to understand exactly what changes are needed to improve their draft. The comment is 5 as it provides concrete steps for the authors to follow, ensuring they know precisely how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L502, L507, and L509) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be done, namely moving certain lines to the Supplementary Material (SuppMat). This provides clear guidance on the necessary changes, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the placement of specific lines in the paper, specifying that they should be moved to the Supplementary Material (SuppMat). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback by identifying lines that should be moved to the Supplementary Material (SuppMat). It clearly specifies which lines need to be moved and to which sections they should be moved, such as lines 502, 507, and 509. This guidance helps the authors make a clear and precise adjustment to improve the organization and accessibility of their paper. The comment is detailed and provides a clear path for the authors to follow, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper, but it notes that this is not a strong negative point given the paper is short. However, the comment does not provide explicit guidance or suggestions on how to conduct this analysis or what specific aspects should be expanded. The action is implicit and vague, as the authors are left to infer that they need to enhance their analysis but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should be applied to. The authors cannot confidently determine which sections or aspects of the paper are being referred to, making it weakly grounded. Additionally, the comment lacks specificity regarding what kind of analysis would be more comprehensive or dataintensive, or what aspects of the current analysis are lacking. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the need for such an analysis, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1 due to the absence of supporting details or references.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper, but it notes that this is not a strong negative point given the paper is short. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects of the analysis would be most beneficial. The feedback is 3 as it highlights a direction for enhancement, but it does not provide actionable steps or detailed insights, making it 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of mention of experimental settings and the absence of code, both of which are critical for result reproducibility. It implies that the authors should provide the code to ensure reproducibility, which is a clear and explicit action. However, the comment does not specify which aspects of the experimental settings are missing or how the authors should address them. While the action is explicit, the lack of detailed guidance on what specific information is needed makes the comment 3. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of result reproducibility and mentions the absence of code, which are critical for ensuring the reproducibility of the experimental results. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned, making it weakly grounded. The comment is specific in identifying the need for proper mention of experimental settings and the absence of code, which are important for reproducibility. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that result reproducibility is critical using the provided information. It also mentions the absence of code. However, the comment lacks specific examples or detailed reasoning to support why the experimental settings are not mentioned properly or how the absence of code affects reproducibility. Without such details, the claim is not 5, as it does not provide enough information for the authors to understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings and result reproducibility, noting that they are not mentioned properly. It also points out the absence of code, which is essential for reproducibility. This feedback is clear and actionable, as it directs the authors to provide the necessary information to ensure the reproducibility of their results. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the experimental settings or how to include the code effectively. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the comparison of online learning approaches and the inclusion of retraining cost in the evaluation. It suggests that the authors should provide a proper comparison against online learning approaches and RL, and it questions the reasons for the exclusion of retraining cost. However, the comment does not explicitly instruct the authors to make these comparisons or provide specific guidance on how to address the challenges mentioned. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons and address the challenges, but without concrete steps, the action remains unclear. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss the online learning formulation and its comparison with other approaches. This allows the authors to accurately identify the sections being addressed. The comment is also specific as it raises several questions about the comparison against online learning approaches and RL, and it questions the reasons for excluding retraining cost and the challenges of including it in the evaluation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the comparison of online learning approaches and the inclusion of retraining cost in the evaluation. It questions the reasons for excluding retraining cost and the challenges of including it. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The questions are more of a request for clarification rather than a claim that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the comparison of online learning approaches and the inclusion of retraining cost in the evaluation. It points out that the authors should provide a proper comparison against online learning approaches and RL, and questions the reasons for excluding retraining cost. This feedback is valuable as it highlights potential gaps in the paper\"s evaluation and prompts the authors to address these issues. However, the comment could be more helpful if it provided specific suggestions or guidance on how to incorporate these comparisons or address the challenges mentioned. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning, particularly those that do not directly target continual learning but could be relevant. It also recommends that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work, as it appears to be an application to continual learning. While the comment provides a clear direction for citation and linking, it does not specify which specific works should be cited or how to integrate them into the paper. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the paper should cite works related to metalearning, particularly those that do not directly target continual learning but could be relevant. It also recommends that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work, as it appears to be an application to continual learning. However, the comment does not specify which parts of the paper should be revised or how the authors should integrate these suggestions. The authors can infer that it relates to the sections discussing related work or applications, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not explicitly mention specific sections, but it is specific in its suggestions for improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should cite works related to metalearning, particularly those that do not directly target continual learning but could be relevant. It also recommends that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work, as it appears to be an application to continual learning. While the comment provides a logical reasoning for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors would need to identify and reference relevant works themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should cite works related to metalearning, particularly those that do not directly target continual learning but could be relevant. It also recommends that the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to the current work, as it appears to be an application to continual learning. This feedback is clear and constructive, offering a clear direction for the authors to enhance their draft by incorporating relevant literature and improving the connection to related work. However, the comment could be more helpful if it provided specific examples of works that should be cited or a more detailed explanation of how to integrate these references. Overall, the comment is 4 as it guides the authors toward a more comprehensive and wellrounded paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lexical and syntactic diversity of teacher feedback, suggesting that the feedback might be autogenerated. It implies that the authors should consider turking the teacher feedback or generating a few different types of feedback to better reflect reallife situations. While the comment suggests an action\u2014specifically, considering turking or generating varied feedback\u2014it does not provide explicit guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore these options. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the lexical and syntactic diversity of teacher feedback, suggesting that the feedback might be autogenerated. It implies that the authors should consider turking the teacher feedback or generating a few different types of feedback to better reflect reallife situations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting actions to address the issue, such as turking feedback or generating varied feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lexical and syntactic diversity of teacher feedback, suggesting that the feedback might be autogenerated. The reviewer implies that the authors should consider turking the feedback or generating varied feedback to better reflect reallife situations. However, the comment lacks specific examples or references to support the claim that the feedback is autogenerated or to provide evidence of the need for diversity. This makes the claim 3, as it provides a logical basis but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the lexical and syntactic diversity of teacher feedback, suggesting that the feedback might be autogenerated. It implies that the authors should consider turking the feedback or generating a few different types of feedback to better reflect reallife situations. This feedback is 3 as it identifies a potential issue with the diversity of feedback and suggests a possible action to address it. However, it lacks specific guidance or examples on how to implement this suggestion, which would make it more actionable. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the main text regarding the additional experiments in the supplement and to summarize their results. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be addressed. The comment also poses a question, which can be seen as an implicit request for the authors to provide more detailed information. However, the explicit instruction regarding the main text and the summary of results makes the action clear and concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not specify which part of the paper this clarification should be made in, nor does it provide details on what specific results should be summarized. The authors might infer that this relates to the main text, but the lack of explicit grounding makes it challenging to pinpoint the exact section. The comment is specific in its request for clarity and summarization, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the main text clarify the presence of additional experiments in the supplement and summarize their results. This feedback is specific and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it included examples of how to summarize the results or suggested ways to integrate this information into the main text. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a comprehensive comparison with the works GFF1 and EfficientFCN2, which both aim to implement fast semantic segmentation methods in the encodedecoder architecture. The comment provides specific references and suggests that the authors should address this comparison. Additionally, it mentions that the societal impact is shown on the last page of the manuscript, which implies that the authors should ensure this information is included. The feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, GFF1 and EfficientFCN2, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Additionally, the comment mentions the societal impact, which is shown on the last page of the manuscript, further aiding the authors in understanding the context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF1 and EfficientFCN2. The reviewer provides specific references to these works, which are cited in the comment, making the claim 4. The inclusion of specific references to external works supports the claim, providing a clear basis for the authors to understand the issue and address it. However, the comment could be strengthened by explaining why these references are relevant or how they relate to the current work. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning GFF1 and EfficientFCN2, which are relevant to the work on fast semantic segmentation. The reviewer encourages the authors to include a comprehensive comparison with these works, which would enhance the paper\"s context and relevance. Additionally, the comment highlights the societal impact, which is mentioned on the last page of the manuscript. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it offered suggestions on how to conduct the comparison or what aspects of the comparison would be most beneficial. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement observed in the experimental results and the claim made in the paper regarding the effectiveness of the proposed prompts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this discrepancy or how to strengthen the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement in experimental results and the claim made in the paper regarding the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement in experimental results (ChatGPT vs. ChatGPT+DSP in Table 6 and Table 7) does not support the claim that the proposed prompts are effective across various language pairs and domains. However, the comment does not provide any detailed reasoning or evidence to substantiate this claim. It lacks specific examples, comparisons, or references to support the assertion that the improvement is insufficient to validate the effectiveness of the proposed prompts. As a result, the claim is 1 due to the absence of supporting evidence or justification.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement observed in the experimental results (ChatGPT vs. ChatGPT+DSP in Table 6 and Table 7) and the claim made in the paper regarding the effectiveness of the proposed prompts. This feedback highlights a potential issue with the paper\"s claim, as the results do not fully support the assertion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their claim. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the Cycle FC aligns features at different spatial locations to the same channel, but the analysis is insufficient. It suggests that there could be many different designs and provides examples, such as experiments or analysis with different sampling intervals and sample size. While the comment implies that the authors should consider these additional experiments or analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further experiments or analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the Cycle FC, which is a specific part of the paper, making it fully grounded. It specifies the issue with the analysis being insufficient and suggests considering different designs, such as experiments or analysis with different sampling intervals and sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis is insufficient, suggesting that there could be many different designs of the Cycle FC. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks sufficient evidence or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Cycle FC, noting that it aligns features at different spatial locations to the same channel, but the analysis is insufficient. It suggests that there could be many different designs and provides examples, such as experiments or analysis with different sampling intervals and sample size. This feedback is 3 as it highlights a potential area for improvement and provides a direction for the authors to consider additional experiments or analyses. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is truly the best or if other RF configurations have performances close to it. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or providing alternative measures. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviations and may not know exactly how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is truly the best or if other RF configurations have performances close to it. However, it does not specify which part of the paper this issue is addressed in, such as specific sections or figures where the results are presented. The authors might infer that it relates to the results section, but this inference is not direct. The comment is specific in identifying the issue of missing standard deviations, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the results makes it difficult to determine if the best method is truly the best or if other RF configurations have performances close to it. However, the comment does not provide any supporting evidence, such as examples or references, to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of standard deviations in the results, which makes it difficult to assess the performance of the best method relative to others. This feedback is clear and actionable, as it highlights a critical aspect of the results that the authors should address to provide a more comprehensive analysis. However, the comment could be more helpful if it suggested specific ways to include standard deviations or alternative measures to assess performance. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the current setting is specific and proposes extending the approach to more general settings. It implies that the authors should consider broadening their framework beyond the current specific requirements. However, the comment does not provide explicit guidance on how to achieve this extension or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific setting described in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the applicability of the current approach to more general settings, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that it should be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or examples to justify why the current setting is specific or how it should be extended. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the current setting, noting that it is very specific and suggesting that the approach should be extended to more general settings. This feedback is clear and actionable, as it provides a direction for the authors to consider broadening their framework. However, the comment could be more helpful if it offered specific examples or guidance on how to achieve this generalization. Despite this, the feedback is 4 as it directs the authors toward a meaningful enhancement of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on the feature extractor used for each region, given that the dimensionality is 512. This is a direct and specific request for information, providing the authors with a clear action to take. The comment is explicit and concrete, as it clearly identifies what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the information about which feature extractor is used for each region. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the feature extractor used for each region, given that the dimensionality is 512. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue in the paper, namely the lack of information about the feature extractor used for each region, given that the dimensionality is 512. This feedback is clear and actionable, as it directs the authors to provide additional context or clarification about the feature extractor, which is crucial for understanding the methodology and results. By addressing this point, the authors can improve the clarity and comprehensibility of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on what details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its suggestion to include details, but without clear guidance on where to place them, the authors may struggle to determine the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not offer any specific reasoning or examples to support why these details are necessary or how they would benefit the readers. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer detailed guidance on what kind of details should be included or how they might enhance the paper. The comment is 3 as it points out a relevant area for improvement, but it does not provide actionable advice or examples, making it incomplete in its guidance. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1. While it implies that the authors should explain their choice of this value, it does not provide explicit guidance or suggestions on how to address this issue. The action is implicit, as the authors can infer that they need to provide a rationale for their choice of p < 0.4, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the choice of p < 0.4, which is a clear and direct inquiry about the rationale behind this particular value. This provides the authors with a clear understanding of what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which could be a point of confusion for readers. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve the explanation. The comment lacks actionable feedback, making it 2. Authors would need to infer that they should explain the choice of p < 0.4 themselves, which limits the utility of the comment. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a lack of explanation and analysis for Figures 1, 2, and 3 in Section 5. It specifically points out the absence of clarification regarding the negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback provides a clear and direct action for the authors to take, which is to add explanations and analyses for these figures. The comment is specific and actionable, as it outlines exactly what needs to be addressed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and the figures (Figure 1, Figure 2, and Figure 3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for the figures, particularly the negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors fail to provide explanations or analysis for Figures 1, 2, and 3, and specifically mentions the absence of clarification regarding negative numbers in Figure 1 and the implications of Figures 2 and 3. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of these figures and the potential impact of their absence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of figures in Section 5, noting the absence of explanations or analysis for Figures 1, 2, and 3. It highlights the lack of clarity regarding the negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to provide additional context and analysis for the figures to enhance the understanding and interpretation of the results. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the motivation for applying Conditional Moment Displacement (CMD) in the context of federated learning. It suggests that the authors should provide a more explicit demonstration or explanation to clarify this aspect. While the comment implies that the authors should elaborate on the motivation, it does not specify how to demonstrate or explain it. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying Conditional Moment Displacement (CMD) in federated learning, indicating that it is unclear. However, it does not specify which part of the paper this issue pertains to, such as a particular section or paragraph where the motivation is discussed. This lack of specificity makes it difficult for the authors to pinpoint the exact area needing clarification. Additionally, the comment does not provide specific guidance on how to improve the explanation or demonstration of the motivation, further reducing its specificity. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation behind applying Conditional Moment Displacement (CMD) in federated learning is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the motivation for applying Conditional Moment Displacement (CMD) in the context of federated learning. It suggests that the authors should provide a more explicit demonstration or explanation to clarify this aspect. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to enhance the explanation or demonstration. This limits the comment\"s usefulness, as the authors are left with a general direction but without detailed steps to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. It also provides references to support the suggestion. While the comment explicitly states the need for additional analysis and comparison, it does not provide specific guidance on how to conduct this analysis or what specific aspects should be examined. The references are helpful, but the comment lacks concrete instructions on how to implement the suggested actions. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting additional comparisons and references to support the analysis, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other methods like EDA or LLMbased paraphrasing. The comment provides references to support the suggestion, such as 1 AllenZhu et al., Physics of language models: Part 3.1, knowledge storage and extraction, and 2 Ovadia et al., Finetuning or retrieval? comparing knowledge injection in llms. These references provide a basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples of how the analysis could be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. The comment also provides references to support the suggestion, which adds credibility to the feedback. This feedback is clear and actionable, offering a specific direction for the authors to enhance their analysis and provide a more comprehensive understanding of their method\"s effectiveness. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is 4, as it effectively directs the authors toward improving their draft by addressing a critical area of analysis."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an ablation study is necessary to evaluate the net effect of each component in the learning process using MMD. It provides specific examples of potential experiments, such as learning the proposed model with a knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is explicit and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that an ablation study is necessary to evaluate the net effect of each component in the learning process using MMD. It provides specific examples of potential experiments, such as learning the proposed model with a knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting the need for an ablation study and provides examples of potential experiments, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study is necessary to evaluate the net effect of each component in the learning process using MMD. It provides specific examples of potential experiments, such as learning the proposed model with a knowledge distillation loss or distilling a Hydra architecture with MMD loss. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more context or references to similar studies, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of an ablation study to evaluate the net effect of each component in the learning process using MMD. It provides a clear suggestion for improvement by proposing specific experiments, such as learning the proposed model with a knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers concrete guidance on how the authors can enhance their work by conducting additional experiments. However, the comment could be more helpful if it included more detailed reasoning or examples of how these experiments would contribute to the study. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should evaluate this scenario, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct this evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s performance should be evaluated or what conclusions should be drawn from this scenario. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for an evaluation of a specific scenario, which is a factual statement. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it identifies a potential area for evaluation, it does not provide any guidance or suggestions on how the authors might approach this evaluation or what specific aspects to consider. The comment lacks depth and actionable advice, leaving the authors with only a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the scaling of RLCD over RLAIF as the model size increases from 7B to 30B, as shown in Table 2. It raises a question about whether RLCD or RLCDRescore can scale to even larger models that might better differentiate responses near the decision boundary. While the comment highlights an area of interest, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the scalability of RLCD or RLCDRescore. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the advantage of RLCD over RLAIF and questioning its scalability to larger language models. This provides clear guidance on what aspect of the paper needs further exploration. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point discusses the scaling of RLCD over RLAIF as the model size increases from 7B to 30B, as shown in Table 2. It raises a question about whether RLCD or RLCDRescore can scale to larger models that might better differentiate responses near the decision boundary. While the comment highlights a potential limitation, it lacks specific evidence or detailed reasoning to support the claim that the advantage diminishes with larger models. The absence of supporting data or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment highlights a specific observation about the scaling of RLCD over RLAIF as the model size increases, as shown in Table 2. It raises a question about whether RLCD or RLCDRescore can scale to larger models that might better differentiate responses near the decision boundary. This feedback is 3 as it identifies a potential area of interest and suggests a direction for further exploration. However, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific aspects to focus on. The comment provides some insight but does not offer comprehensive advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the proposed NC measure, particularly in the context of large datasets like ImageNet. It questions how the method can be learned and applied to such datasets and suggests that addressing this scalability issue is crucial for the practical contribution of the paper. While the comment highlights a potential issue, it does not provide explicit guidance on how to address it or suggest specific solutions. The action is implicit and somewhat vague, as the authors need to infer that they should explore scalability solutions but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed NC measure and its applicability to largescale datasets, such as ImageNet. It raises a concern about the scalability issue and suggests that the practical contribution of the paper might be reduced if this issue is not addressed. However, the comment does not specify which part of the paper discusses the NC measure or where the scalability issue is discussed, making it weakly grounded. The comment is specific in identifying the concern about scalability and its impact on the paper\"s contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, particularly in the context of large datasets like ImageNet. The reviewer questions how the method can be learned and applied to such datasets and suggests that addressing this scalability issue is crucial for the practical contribution of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the scalability issue. While the concern is valid, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the scalability of the proposed NC measure, particularly in the context of large datasets like ImageNet. It questions how the method can be learned and applied to such datasets and suggests that addressing this scalability issue is crucial for the practical contribution of the paper. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how to address the scalability issue. This limits the comment\"s helpfulness, as the authors are left with a general idea of the problem but without actionable steps to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a lack of quantitative analysis on computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. This feedback provides a clear and concrete action for the authors to take, which is to include such quantitative data in their draft. The comment is 5 as it gives precise guidance on what needs to be added to support the claims made in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of specific measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks quantitative analysis on computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements. This claim is 3 as it provides a logical reasoning for the need for such measurements, but it lacks specific examples or references to support the claim fully. The authors would need to conduct further analysis to fully understand and address the issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It specifically mentions the need for measurements such as GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the rigor and evidence supporting their claims. By addressing this issue, the authors can strengthen the credibility and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the efficiency of the method for these scenes. However, it does not provide explicit instructions or concrete steps on how to incorporate this consideration into the analysis or comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to account for the time factor in their evaluation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the time for COLMAP and scenebyscene finetuning, suggesting that this should be considered when comparing the efficiency of the method for these scenes. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to consider time as a factor, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the efficiency of the method for these scenes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the method, specifically mentioning that the time for COLMAP and scenebyscene finetuning should be considered. This feedback is 3 as it highlights a critical aspect that could affect the efficiency assessment of the method. However, the comment lacks depth and does not provide specific guidance on how to incorporate this consideration into the analysis or comparison. The authors are left to infer that they need to account for the time factor, but without detailed suggestions, the feedback remains incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggests areas for further analysis regarding the \"filter manifold network\" (FMN). It asks whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger numbers of filter parameters. While the comment identifies specific areas for investigation, it does not provide explicit instructions or concrete steps for the authors to take. The questions are clear and specific, but they are phrased in a way that requires the authors to infer the actions they should take. Therefore, the comment is 3, as it provides a clear direction but lacks explicit guidance on how to implement the suggestions.", "grounding_specificity_rationale": "The comment addresses the lack of discussion and analysis on the \"filter manifold network\" (FMN), which is the main part of the technique. It raises several questions about the experimental setup, including whether other architectures were tested for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale well with larger numbers of filter parameters. However, the comment does not specify which part of the paper discusses FMN, making it weakly grounded. The questions are specific, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is the main part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger numbers of filter parameters. While the comment highlights potential gaps in the analysis, it does not provide specific examples or references to support these claims. The questions are based on logical reasoning but lack detailed evidence or references, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion or analysis on the \"filter manifold network\" (FMN), which is the main part of the technique. It raises several important questions, such as whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger numbers of filter parameters. These questions highlight areas where the authors could improve their draft by providing more comprehensive analysis and experimentation. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the feedback is 3 as it directs the authors to important aspects of their work that need further exploration and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially since UNets have shown strong performances on regular gridded domains. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed CoNO model and questions the source of the performance boost, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially since UNets have shown strong performances on regular gridded domains. However, the comment does not specify which part of the paper discusses the CoNO model or where the comparisons should be made, making it weakly grounded. The comment is specific in its questioning and suggestions, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the source of the performance boost in the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. The reviewer suggests that comparisons to UNets are inevitable, especially since UNets have shown strong performances on regular gridded domains. However, the comment lacks specific references or detailed reasoning to support the claim that comparisons to UNets are necessary. While the suggestion is logical, the lack of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the proposed CoNO model, specifically questioning the source of the performance boost. It suggests that the authors should provide comparisons to UNets, given that UNets have shown strong performances on regular gridded domains. This feedback is valuable as it prompts the authors to clarify and validate their claims, ensuring that the performance boost is not solely attributed to the fractional transform. However, the comment could be more helpful if it provided specific examples or references to studies that demonstrate the effectiveness of UNets, which would further strengthen the argument. Overall, the comment is 4 as it identifies a key area for clarification and validation, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the computational complexity of the proposed PSA method compared to baselines. It mentions that the PSA requires more computation and suggests that the comparison of computation complexity should be included in the experiment part. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors know they need to consider computational complexity but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational complexity of the proposed PSA method compared to baselines, specifically mentioning the calculation of all flipped previous layer outputs into the current layer. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or algorithm. The authors can infer that it relates to the methodology or algorithm description, but this inference is not direct. The comment is specific in detailing the issue of computational complexity, but it lacks grounding as it does not explicitly mention the section or algorithm being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of all flipped previous layer outputs into the current layer. However, the comment does not provide any supporting evidence, such as comparisons of computational complexity metrics or references to specific studies that have addressed this issue. Without additional context or justification, the claim remains 1, as it lacks the necessary details to substantiate the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed PSA method, specifically noting that it requires more computation than the baselines. It highlights a concern about the computational complexity and suggests that this aspect should be included in the experiment part. While the comment points out a potential weakness, it lacks specific guidance or suggestions on how the authors might address this issue or what specific changes could be made to improve the draft. The feedback is 3 as it directs the authors\" attention to an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should explore the contribution of each factor in the proposed model separately. It specifically mentions the need to assess the impact of the exponential moving average and the noise factor individually. The comment implies that the authors should compare the performance of the model when using a noisefree exponential moving average versus the current model. While the action is implicit, it is concrete as it provides a clear direction for the authors to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed model and the factors it benefits from, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the contribution of each factor individually, particularly the noise and the exponential moving average. The comment further specifies the need to assess the impact of a noisefree exponential moving average, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed model benefits from two factors: noise and an exponential moving average. It proposes that the authors should explore the contribution of each factor individually, particularly the noise factor, and assess the gain from using a noisefree exponential moving average. While the comment provides a logical suggestion for further analysis, it lacks specific examples or references to support the claim that the noise factor is insufficient. This makes the claim 3, as the authors would need to conduct additional research or experiments to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to explore the contribution of each factor in the proposed model separately. It highlights the need to assess the impact of the noise and exponential moving average factors individually, particularly the noise factor, and suggests comparing the performance of the model with a noisefree exponential moving average. This feedback is clear and constructive, offering a concrete direction for the authors to enhance their analysis and potentially improve the robustness of their model. However, the comment could be more helpful if it included specific examples or further guidance on how to implement this suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides several specific suggestions for improving the manuscript. It mentions that the fonts in figures 1 and 2 are too small and suggests increasing them. It also points out that the words in the grey box and the terms \"V_mem, Th_i, U_i^t\" are too small and suggests making them larger. Additionally, the comment highlights the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests presenting this information in a table format to better emphasize the data for readers. These suggestions are explicit and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 1,\" \"figure 2,\" and \"grey box,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with font sizes for \"V_mem, Th_i, U_i^t\" and the \"CTRL\" long form explanation, as well as the lack of details comparison with other stateoftheart Transformer designs. The suggestion to present this information in a table format is also specific, providing clear guidance on how to improve the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several observations and suggestions regarding the presentation of figures and the lack of details comparison with other stateoftheart Transformer designs. The claims about font sizes and the need for a table format are based on logical reasoning and common knowledge about the importance of clear and readable figures. However, the comment does not provide specific examples or references to support the claim about the lack of details comparison, which could be a minor gap in the justification. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the manuscript. It highlights issues with the font sizes in figures 1 and 2, suggesting that they be increased for better readability. It also points out that the words in the grey box and the terms \"V_mem, Th_i, U_i^t\" are too small and suggests making them larger. Additionally, the comment notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests presenting this information in a table format to better emphasize the data for readers. These suggestions are clear and constructive, offering the authors a clear path for enhancing the clarity and comprehensiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the reporting of results and suggests that the authors should consider including results from earlier stages of training, as these might provide insights into the behavior of the model during learning. It also questions the performance of the CNN with less data. While the comment implies that the authors should include these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional data points and consider the impact of data quantity on performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the results section, specifically mentioning the reporting of results after a significant amount of training. It raises a concern about the interest in how the agent behaves while learning, suggesting that early training stages might be more relevant. The comment also questions the performance of the CNN with less data, indicating a need for further exploration. However, the comment does not specify which part of the results section this issue pertains to, making it weakly grounded. The comment is specific in its suggestions for improvement, such as considering early training results and exploring the impact of data quantity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the reporting of results, suggesting that the authors should consider including results from earlier stages of training. It also questions the performance of the CNN with less data, implying that the model might not perform well with limited data. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it relies on general assumptions about the behavior of the model during training. Therefore, the comment is categorized as 2, as it provides some insight but lacks sufficient evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises a relevant concern about the reporting of results, suggesting that the authors should consider including results from earlier stages of training. This is particularly important in reinforcement learning (RL), where understanding the model\"s behavior during the learning process is crucial. The comment also questions the performance of the CNN with less data, prompting the authors to explore the impact of data quantity on model performance. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how to address these issues. Providing more detailed feedback or examples would enhance its helpfulness. Therefore, the comment is 3, as it highlights important aspects of the draft that need attention but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to rewrite a specific sentence that is unclear in meaning. The comment provides clear guidance on what needs to be done\u2014rewriting the sentence to clarify its meaning. However, it does not offer any suggestions on how to rewrite the sentence or what aspects of the sentence are unclear. While the action is explicit, the lack of detailed guidance on how to improve the sentence makes it 3. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"P. 5, p. 3, l.,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a rewrite of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps,\" which clearly indicates what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the meaning of a specific sentence in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence in the paper, asking for a rewrite to clarify its meaning. This feedback is actionable as it provides a clear direction for the authors to improve the clarity of their writing. However, the comment could be more helpful if it offered suggestions on how to rephrase the sentence or provided examples of clearer phrasing. While it effectively points out a need for improvement, it lacks depth and specificity in its guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two specific questions about the manuscript: whether the authors considered the documents as an entire sentence and how they handle concepts involving multiple entity mentions referring to the same entity. While the comment implies that these questions need to be addressed, it does not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to clarify these aspects in their manuscript, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide clear guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and the specific issue of how documents are treated as an entire sentence, as well as the handling of concepts involving multiple entity mentions referring to the same entity. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what information is missing from the manuscript, namely the consideration of documents as an entire sentence and the handling of multiple entity mentions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the manuscript\"s treatment of documents and entity mentions. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the manuscript: whether the authors considered the documents as an entire sentence and how they handle concepts involving multiple entity mentions referring to the same entity. These questions highlight potential gaps in the manuscript that need clarification. While the comment identifies areas for improvement, it lacks actionable suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out specific areas that require attention, but it does not provide detailed instructions or examples for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contribution of the paper appears marginal because all the methods used in different stages are welldesigned and demonstrated. It questions whether adding another stream for lowresolution would be a significant contribution for a toptier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the contribution. The feedback lacks actionable details, such as recommending specific changes or additional experiments that could enhance the contribution. As a result, the authors are left without clear direction on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the marginal contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated. It questions whether adding another stream for lowresolution would be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique is based on, such as specific sections or results. The authors might infer that it relates to the overall contribution or results sections, but this inference is not direct. The comment is specific in its critique of the contribution being marginal, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper appears marginal because all the methods used in different stages are welldesigned and demonstrated. It suggests that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to similar works or evidence that would help the authors understand why the contribution is considered marginal. As a result, the claim is 3, as it provides a general critique but lacks the necessary details to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the marginal contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific suggestions or actionable feedback on how the authors might address this issue or enhance their work. The feedback is 3 as it prompts the authors to reconsider the significance of their contribution, but it does not provide detailed guidance or examples to improve the draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution of the paper, suggesting that the performance gain is mostly attributed to PBSD. It questions the motivation behind the paper, which is primarily focused on supervised contrastive learning (DSCL). The reviewer implies that the authors should clarify the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide more motivation for PBSD and clarify the paper\"s contributions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the main contribution of the paper, suggesting that the performance gain is mostly attributed to PBSD. It questions the motivation behind the paper, which is primarily focused on supervised contrastive learning (DSCL). The comment implies that the authors should clarify the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the motivations and contributions of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the main contribution of the paper, suggesting that the performance gain is mostly attributed to PBSD. It implies that the paper is primarily motivated by supervised contrastive learning (DSCL). However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of explicit evidence or references to support the claim makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution of the paper, suggesting that the performance gain is mostly attributed to PBSD. It questions the motivation behind the paper, which is primarily focused on supervised contrastive learning (DSCL). The comment implies that the authors should clarify the motivations for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the paper\"s contributions. While it identifies a potential area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the potential (\u03f5, \u03b4)identity tester. It also inquires about how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5\u2080, but the distance d_K(\u03c0\u2080, \u03c0) is large. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the relationship between the testers and ensure that the tester can handle such cases. However, the comment lacks concrete details on how to implement this clarification, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relationship between the tester for the spread parameter and the potential (\u03f5, \u03b4)identity tester, and it inquires about how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5\u2080 but the distance d_K(\u03c0\u2080, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the potential (\u03f5, \u03b4)identity tester. It inquires about how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5\u2080, but the distance d_K(\u03c0\u2080, \u03c0) is large. While the comment highlights a potential issue, it does not provide any supporting evidence, reasoning, or references to justify the claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between the tester for the spread parameter and the potential (\u03f5, \u03b4)identity tester. It specifically inquires about how the tester handles (\u03c0, \u03d5) pairs where \u03d5 = \u03d5\u2080, but the distance d_K(\u03c0\u2080, \u03c0) is large. This feedback highlights a potential gap in the paper\"s explanation or analysis, prompting the authors to clarify the relationship between these testers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments described in it, such as the Brusselator. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could consider to improve their draft. Without actionable advice or suggestions, the authors are left without a clear understanding of what to do to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments described in it, such as the Brusselator. However, it does not specify which part of the paper the authors should focus on or provide specific guidance on how to address the issue of time constraints. The comment lacks grounding as it does not identify a specific section or experiment that needs attention, and it is also not specific in detailing what needs to be done to improve the draft. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the value of the comprehensive Appendix and mentions that the authors did not have time to read additional experiments described in it, such as the Brusselator. However, the comment does not provide any specific reasoning or evidence to support the claim that the authors should have read these experiments. It lacks detailed justification or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the value of the comprehensive Appendix and notes that the authors did not have time to read additional experiments described in it, such as the Brusselator. However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and does not offer guidance on what specific aspects of the paper could be enhanced or how the authors might prioritize their time more effectively. As a result, the comment is not particularly helpful in guiding the authors to improve their draft, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might clarify the distribution or what specific aspects need to be clarified. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the \"detailed distribution\" of the proposed dataset, which provides some level of specificity regarding what needs to be addressed. However, it does not explicitly mention which part of the paper discusses this distribution, making it weakly grounded. The authors can infer that it relates to the dataset description or analysis section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the detailed distribution of the proposed dataset. This is a clear and actionable piece of feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment does not provide further guidance or suggestions on how to address this issue, such as recommending specific ways to clarify the distribution or examples of how to present it more effectively. While it points out a critical area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a selfsupervised pretraining approach without annotations could be more appealing. While the comment implies that the authors should consider exploring a selfsupervised pretraining approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for exploring a selfsupervised approach and understand how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the necessity of annotated labels for learning semantic tokens, which limits the application of the proposed method to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the specific issue with annotated labels, making it weakly grounded. The suggestion to consider a selfsupervised pretraining approach is specific, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support the claim that a selfsupervised approach would be more beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a general suggestion without concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which is the requirement for annotated labels to learn semantic tokens, thereby restricting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it highlights a potential weakness in the method and provides a direction for improvement. However, the comment could be more actionable by offering specific suggestions on how to implement a selfsupervised pretraining approach or by discussing the advantages of such an approach. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should include more challenging DRL tasks with higher input dimensionality to demonstrate the scalability of LFF. It explicitly states that the current experiments are limited to simple and lowdimensional tasks, such as cartpole or mountain car, and recommends expanding the scope to include more complex tasks like locomotion of ants or humanoids. This feedback provides a clear and concrete action for the authors to take, specifying the type of tasks that should be included to enhance the demonstration of LFF\"s scalability. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include more challenging DRL tasks with higher input dimensionality to demonstrate the scalability of LFF. However, it does not specify which part of the paper should be revised or how these additional experiments should be integrated. The authors can infer that it relates to the experimental section, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper that needs improvement. The comment is specific in its suggestion to include more complex tasks, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the continuous control experiments are limited to simple and lowdimensional tasks, such as cartpole or mountain car, and recommends expanding the scope to include more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why the current scope is insufficient, suggesting that demonstrating scalability requires more complex tasks. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental scope, noting that most continuous control experiments are performed on simple and lowdimensional tasks. It suggests that to fully demonstrate the scalability of LFF, the authors should include more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for expanding the scope of the experiments to showcase the scalability of LFF. By addressing this suggestion, the authors can enhance the comprehensiveness and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides specific suggestions for improving the abstract by suggesting a more precise statement about expressivity and recommending the inclusion of learning curves for all experiments, at least in an appendix. The comment is explicit in its request for a more detailed and specific statement in the abstract and offers a concrete action for the authors to take by including learning curves. This provides clear guidance on how to enhance the paper, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as specifying the expressivity in terms of the change in linear regions in output space and recommending the inclusion of learning curves for all experiments, at least in an appendix. This provides the authors with clear guidance on what needs to be addressed in the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract should include a more precise statement about expressivity, specifically mentioning the change in linear regions in output space after a citation. It also recommends including learning curves for all experiments, at least in an appendix. While the comment provides a specific suggestion for improvement, it lacks detailed reasoning or references to support why these changes are necessary or how they would enhance the paper. The suggestion is 3 as it offers a clear direction for improvement but could be strengthened with more justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting a more precise statement about expressivity and recommending the inclusion of learning curves for all experiments, at least in an appendix. This feedback is clear and offers concrete suggestions for improvement, which can help the authors enhance the clarity and comprehensiveness of their paper. By addressing these points, the authors can significantly improve the presentation and understanding of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of motivation in the paper, specifically questioning the application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation in the paper, specifically questioning the application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. However, the comment does not specify which part of the paper lacks this motivation or where the examples should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections that need revision. The comment is specific in suggesting the need for additional examples to illustrate the application of the method, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation and application of the paper\"s proposed method, specifically regarding its relevance in domain adaptation. The reviewer suggests that the paper should demonstrate the methodology on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This claim is 3 as it provides a logical reasoning for the need for additional examples to illustrate the method\"s utility. However, the comment lacks specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation in the paper, specifically questioning the application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper\"s relevance and impact. However, the comment could be more helpful if it included examples or suggested ways to demonstrate the method\"s utility. Overall, the comment is 4, as it guides the authors toward a more comprehensive presentation of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point lists several papers that are relevant to the paper under review, specifically mentioning MISA, M2FNet, and MMDFN. It notes that the paper regards MULT as the only deep learningbased baseline considering crosssensory interaction but points out that MULT was proposed in 2019, making it somewhat outdated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address the perceived limitation of using an outdated baseline or how they might improve their work in this regard. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment lists specific papers, MISA, M2FNet, and MMDFN, which are relevant to the paper under review. It also mentions that the paper regards \"MULT\" as the only deep learningbased baseline considering crosssensor interaction but notes that MULT was proposed in 2019, making it somewhat outdated. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology or results sections. The authors can infer that it relates to the baseline section, but the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the critique about the baseline\"s age, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point lists specific papers, MISA, M2FNet, and MMDFN, which are relevant to the paper under review. It mentions that the paper regards \"MULT\" as the only deep learningbased baseline considering crosssensory interaction but notes that MULT was proposed in 2019, making it somewhat outdated. The comment provides a clear reference to specific works and a logical reasoning for why the baseline might be considered outdated. However, it lacks detailed explanations or comparisons that would further substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or context.", "helpfulness_rationale": "The review comment identifies specific papers that are relevant to the paper under review, namely MISA, M2FNet, and MMDFN. It notes that the paper under review regards \"MULT\" as the only deep learningbased baseline considering crosssensor interaction but points out that MULT was proposed in 2019, making it somewhat outdated. This feedback is 3 as it highlights a potential weakness in the paper\"s choice of baseline, which could be addressed by the authors. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their work in this regard. Therefore, the comment provides some insight but does not fully support the authors in making improvements, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the comparison against other models in the experiments and to ensure a fair comparison by omitting the value of the used ranks for all models. It also suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models while keeping the number of model parameters consistent. The comment provides clear and concrete actions for the authors to take, including specific steps to compute the number of model parameters and ensure a fair comparison. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it details the issue with the omission of the value of the used ranks for all models, which makes a fair comparison difficult. The comment further specifies the need to compare the tensor completion results for all models while ensuring the same number of model parameters, providing clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all models, which makes a fair comparison difficult. The reviewer suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models while keeping the number of model parameters consistent. This claim is supported by logical reasoning, as it highlights a specific issue with the experimental setup and provides a clear suggestion for improvement. However, the comment could be strengthened by referencing specific examples or providing more detailed guidance on how to implement the suggested changes. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity and fairness in comparing different models. It points out that the omission of the value of the used ranks for all models makes it difficult to establish a fair comparison. The comment provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models while ensuring the same number of model parameters. This guidance is detailed and constructive, offering a specific path for the authors to enhance the fairness and clarity of their experimental results. The feedback is 5 as it directs the authors toward a concrete step to improve their draft, making it a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include \"ATA\" in the comparison for the leave one out setting, as it was found to be better than \"FP\" in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to add \"ATA\" to the comparison in Table 2. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific setting \"leave one out,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of \"ATA\" in the comparison for the leave one out setting. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in the leave one out setting, as it was found to be better than \"FP\" in Table 1. This claim is 3 as it provides a logical reasoning based on the results in Table 1, suggesting that including \"ATA\" would strengthen the comparison. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that in Table 2, the proposed method is only compared to \"LFP\" under the leave one out setting. It suggests that including \"ATA\" in the comparison would be more convincing, as \"ATA\" was found to be better than \"FP\" in Table 1. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s analysis and results presentation. By addressing this point, the authors can improve the comprehensiveness and robustness of their comparison, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the normalization module, suggesting that it appears different in two versions but seems the same in text. It also mentions the need for standardization of pictograms in the figures. Additionally, it points out a minor issue with the text on page 4 after an equation. While the comment identifies specific areas that need attention, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to clarify the normalization module, standardize pictograms, and improve the text, but the lack of concrete steps makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the normalization module, suggesting that it appears different in two versions but seems the same in text. Additionally, it highlights the need for standardization of pictograms in the figures and points out a minor issue with the text on page 4 after an equation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the normalization module, suggesting that it appears different in two versions but seems the same in text. It also mentions the need for standardization of pictograms in the figures and points out a minor issue with the text on page 4 after an equation. While the comment identifies specific areas that need attention, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the issues themselves, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the normalization module, suggesting that it appears different in two versions but seems the same in text. It also highlights the need for standardization of pictograms in the figures, pointing out a specific issue with Figure 4 in the 0/50 latency range where symbols overlap. Additionally, it notes a minor problem with the text on page 4 after an equation. While the comment points out areas that need attention, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors to specific areas for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical part of the paper, specifically regarding the proposed algorithm and its ability to remove subdivision splines. It questions whether the algorithm would require additional computational costs for building the space partition. While the comment implies that the authors should provide more details on how the algorithm removes subdivision splines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more details in the theoretical part. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"author claim\" and the \"theoretical part,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it questions the details of the proposed algorithm regarding the removal of subdivision splines and the potential computational costs involved. This provides clear guidance on what needs to be addressed in the theoretical part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the utility of subdivision splines for decision boundaries and the goal of pruning. It does not express an opinion or suggestion but rather raises a question about the theoretical part of the paper. The comment is factual and does not contain subjective claims, making it a normal statement.", "helpfulness_rationale": "The review comment raises a question about the theoretical part of the paper, specifically regarding the proposed algorithm and its ability to remove subdivision splines. It questions whether the algorithm would require additional computational costs for building the space partition. While the comment identifies a potential gap in the theoretical explanation, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify their theoretical framework, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies that W1 and W2 are not defined in the paper, suggesting that they denote the Encoder and Decoder networks. It also points out that W and V are not defined in several equations. However, the comment does not provide explicit instructions on how the authors should define these variables or where they should be placed in the paper. The action is implicit, as the authors can infer that they need to define these variables, but the lack of concrete guidance on how to do so makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"p.3, A4, eq.3,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that W1, W2, W, and V are not defined, suggesting that they denote the Encoder and Decoder networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that W1, W2, W, and V are not defined in the paper, suggesting they denote the Encoder and Decoder networks. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific instances where variables are not defined in the paper, namely W1, W2, W, and V. It suggests that these variables denote the Encoder and Decoder networks, which is a crucial piece of information for understanding the context of the paper. However, the comment does not provide any suggestions or guidance on how the authors might define these variables or improve the clarity of their definitions. While it highlights an important area for clarification, the feedback lacks actionable advice, making it 3. The authors are given a starting point for improvement but are left without detailed guidance on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not provide specific guidance on how to achieve this. The action is implicit and vague, as the authors are left to infer that they need to adjust their comparison method. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, it does not specify which baselines are being compared or provide details on how the comparison could be improved. The authors cannot confidently determine which part of the paper this comment addresses, as it does not explicitly mention a section or figure. Additionally, the comment lacks specificity regarding what aspects of the comparison are unfair or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the unfairness or how to address it. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison to some baselines, specifically noting that these baselines lack prior knowledge of users or language embedding computation. This feedback is 3 as it highlights a critical area that needs attention, prompting the authors to reconsider their comparison methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or improve the comparison. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, the dimensionality after upsampling, and the lack of discussion on limitations and societal impact. While the comment identifies areas that need clarification or further explanation, it does not provide explicit instructions or concrete steps for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several specific issues, including the lack of benefit from outputside layers, unclear illustration of Figure 4, unclear details on the Pixelshuffle operation, and questions about the dimensionality after upsampling. It also mentions the absence of limitations and potential negative societal impact of the work. However, the comment does not explicitly mention which sections or figures are being addressed, making it weakly grounded. The specificity of the feedback is high as it clearly identifies the issues and areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of multiple questions and observations, primarily seeking clarification and additional information rather than making subjective claims. It does not contain any opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and concerns that could help the authors improve their draft. It questions the benefits of outputside layers, the clarity of Figure 4, and the details of the Pixelshuffle operation. Additionally, it points out the lack of discussion on limitations and potential negative societal impacts of the work. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is 3 as it highlights critical areas that need clarification, but it could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the negative chips are fixed after generation or updated during the training of the RPN. It also inquires whether alternating between generating negative chips and training the network could improve performance. While the comment poses questions, it does not provide explicit instructions or suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should consider the impact of negative chip generation and training order on performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips and their impact on performance, specifically in the context of a lightweight RPN. However, it does not explicitly mention which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the relationship between negative chip generation and training, and it suggests a potential improvement by alternating between generating negative chips and training the network. This provides a clear direction for the authors to consider, but without explicit grounding, the authors may still need to infer the relevant section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the process of generating negative chips and their impact on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips and their impact on performance, specifically in the context of a lightweight RPN. It inquires whether the negative chips are fixed after generation or updated during training and whether alternating between generating negative chips and training the network could improve performance. While the comment identifies a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their work. The feedback is 3 as it prompts the authors to consider an important aspect of their methodology, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of the proposed approach on new and old patients, suggesting that the authors should consider this aspect. While the comment implies that the authors should evaluate their approach on both new and old patients, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct separate evaluations for new and old patients. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the evaluation of the proposed approach on new and old patients, suggesting that the authors should consider this aspect. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting an evaluation on new and old patients, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the evaluation of the proposed approach on new and old patients. It does not make a claim or suggestion that requires verification, as it is merely a request for clarification or consideration. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the evaluation of the proposed approach on new and old patients, suggesting that the authors should consider this aspect. This feedback is 3 as it prompts the authors to think about a potential limitation or area for improvement in their evaluation process. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. While it highlights an important consideration, the lack of detailed feedback limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the same procedure is used for all experiments or just some, and suggests that this could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes should be made to clarify the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental setup and possibly provide more details on the use of the 300WLP dataset. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental methodology, specifically questioning the use of the 300WLP dataset. It highlights a potential issue where the same procedure is used for both the proposed method and the baselines, despite most baselines not using the 300WLP dataset. This makes the comment specific in its critique. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. The reviewer questions whether the same procedure is used for all experiments or just some, and suggests that this could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that most baselines do not use the 300WLP dataset. This makes the claim 3, as the authors would need to further investigate and clarify the methodology themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the same procedure is used for all experiments or just some, and suggests that this could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify their experimental setup and ensure that the methodology is transparent and fair. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how other baselines might have used the dataset. Overall, the comment is 4 as it highlights a significant concern that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some techniques behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting ways to enhance the novelty of their techniques or providing references to similar works. Without actionable advice or specific steps, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspects of these techniques are not novel or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed justification or evidence, the claim remains 1, as it does not provide a clear rationale for the authors to follow. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out that some techniques behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While this observation is relevant, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their techniques. Without actionable feedback or detailed examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the assumption that the observations are obtained by averaging over the corresponding support $v$. It suggests that the data might be aggregated by another procedure, such as simple summation or population weighted average, which is more common for disease incident data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to their draft. The action is implicit and vague, as the authors are left to infer that they need to consider alternative aggregation methods. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and references specific works, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the assumption that observations are obtained by averaging over the corresponding support $v$, and questions whether other procedures like simple summation or population weighted average might be more appropriate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the assumption made in the paper regarding the aggregation of observations, specifically questioning whether the data might be aggregated by another procedure such as simple summation or population weighted average. The reviewer provides a rationale by referencing the disease incident data being often available in count or rate per the number of residents. However, the comment lacks specific examples or references to support the claim that the current aggregation method is incorrect or that alternative methods are more appropriate. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption made in the paper regarding the aggregation of observations, specifically questioning whether the data might be aggregated by another procedure such as simple summation or population weighted average, which is more common for disease incident data. This feedback is valuable as it prompts the authors to reconsider their assumptions and potentially improve the accuracy of their model. However, the comment could be more helpful if it provided specific examples or references to support the claim that the current aggregation method is incorrect. Additionally, it could suggest alternative methods or considerations for the aggregation process. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide an indepth analysis of the training dynamics, specifically explaining why inverse scaling occurs over compute. This feedback is clear and provides a direct action for the authors to take, which is to include a detailed analysis. However, it does not specify how to conduct this analysis or what aspects to focus on, leaving some room for interpretation. Therefore, the comment is 4, as it gives a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis, specifically regarding the training dynamics and why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, but without clear grounding, the authors may struggle to identify the exact section where this analysis should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis, specifically regarding the training dynamics and why inverse scaling occurs over compute. The reviewer suggests that providing an analysis would strengthen the paper. However, the comment does not provide specific examples, references, or detailed reasoning to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of the analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of indepth analysis regarding the training dynamics, specifically the occurrence of inverse scaling over compute. It suggests that providing an analysis would strengthen the paper\"s solidness. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their draft by offering a detailed explanation of the training dynamics. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of mathematical definitions for architectural details, specifically mentioning multihead attention. It also questions the split arrow in Figure 2, asking about the inputs for the attention layer and whether the same vectors are used for keys and values. The reviewer suggests that a formal definition would aid readers in understanding the model. While the comment identifies specific areas needing clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include mathematical definitions and clarify the split arrow, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definitions for architectural details, such as multihead attention, and questions the split arrow in Figure 2, asking about the inputs for the attention layer and whether the same vectors are used for keys and values. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of mathematical definitions for architectural details, specifically mentioning multihead attention. It also questions the split arrow in Figure 2, asking about the inputs for the attention layer and whether the same vectors are used for keys and values. The comment suggests that a formal definition would aid readers in understanding the model. While the comment identifies specific areas of concern, it lacks detailed reasoning or references to support the claim that these details are missing or unclear. The authors would need to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of mathematical definitions for architectural details, such as multihead attention, which is crucial for understanding the model\"s structure. It also questions the split arrow in Figure 2, asking about the inputs for the attention layer and whether the same vectors are used for keys and values. This feedback is clear and actionable, as it points out areas where the paper could be improved by providing formal definitions and clarifications. By addressing these issues, the authors can enhance the clarity and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider more complex tasks that require a nonfixed policy, similar to those discussed in the last paragraph of the paper. It also implies that the authors should compare their results with a reinforcement learning algorithm baseline. While the comment provides a clear direction for potential improvements, it does not specify which tasks should be considered or how the comparison should be conducted. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests considering more complex tasks that require a nonfixed policy, similar to those discussed in the last paragraph of the paper. However, it does not specify which part of the paper this suggestion is related to, making it weakly grounded. The comment is specific in its suggestion to compare with a reinforcement learning algorithm baseline, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting, with a fixed policy, is a subset of reinforcement learning. It proposes that tasks could be more complex, requiring a nonfixed policy, similar to those discussed in the last paragraph of the paper. The comment implies that the authors should compare their results with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to the tasks mentioned in the last paragraph of the paper, making it difficult for the authors to understand and address the suggestion effectively. Therefore, the claim is 3, as it provides a general direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the current setting, with a fixed policy, is a subset of reinforcement learning. It proposes that tasks could be more complex, requiring a nonfixed policy, similar to those discussed in the last paragraph of the paper. The comment implies that the authors should consider comparing their results with a reinforcement learning algorithm baseline. While the comment identifies a potential area for improvement, it lacks specific guidance or examples on how to implement this suggestion or what specific tasks should be considered. The feedback is 3 as it points out a direction for enhancement but does not provide detailed instructions for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of comprehensive analysis of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It suggests that the authors should provide a more detailed analysis to address this concern. However, the comment does not specify how the authors should conduct this analysis or what specific aspects need to be explored. The action is implicit and somewhat vague, as the authors need to infer the need for a more detailed analysis but lack concrete guidance on how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of comprehensive analysis of the method and experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It suggests that the authors should provide a more detailed analysis to address this concern. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a more comprehensive analysis and the potential issue with the authors\" claim regarding their method\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analyses of the method and experimental outcomes are not comprehensive enough, particularly noting that the authors\" method underperforms the baseline in some instances. The comment suggests that the authors should provide a more detailed analysis to address this concern. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are insufficient. It does not provide references or detailed explanations of what aspects of the analysis are lacking, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than a comprehensive analysis of the method itself and its experimental outcomes. It points out that the authors\" method underperforms the baseline in some instances, which raises questions about the extent of performance improvement attributed to the method. The comment suggests that the authors should provide a more detailed analysis to address these concerns. While the feedback highlights a critical area for improvement, it lacks specific suggestions or guidance on how to conduct this analysis or what aspects to focus on. This makes the comment 3, as it provides insight into a potential weakness but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper primarily focuses on explaining multitask models, which limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might broaden the scope of their work or suggest alternative approaches to enhance applicability. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper\"s focus on explaining multitask models, which limits its applicability. However, it does not specify which part of the paper discusses this limitation, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper could be expanded to enhance applicability. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper primarily focuses on explaining multitask models, which limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s focus on explaining multitask models, which limits its applicability. However, it does not provide specific suggestions or guidance on how the authors might broaden the scope of their work or enhance the applicability of their findings. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the literature review, suggesting that it ignores relevant papers that could be relevant to the work. It mentions specific papers, 1 and 2, and notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate these papers into their literature review. The action is implicit and vague, as the authors are left to infer that they need to include these papers and possibly discuss their relevance. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the literature review ignores relevant papers, such as 1 and 2, which are relevant to the work. The comment further details what needs to be addressed by mentioning specific papers and their relevance to Assumption 2 and the comparison with QSGD. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores relevant papers, specifically mentioning 1 and 2. It provides a rationale by stating that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific references or detailed explanations of how these papers relate to the current work or why they should be included in the literature review. This makes the claim 3, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the literature review, suggesting that it overlooks relevant papers that could be relevant to the work. It specifically mentions two papers, 1 and 2, and notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide detailed guidance on how the authors should address this issue or incorporate these papers into their literature review. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it 3. The authors are given a direction but not a comprehensive roadmap for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how the authors might improve the clarity or organization of their work. Without explicit guidance or concrete examples, the authors are left without a clear understanding of what needs to be addressed to enhance the readability of their paper. As a result, the comment lacks actionability, as it does not offer any actionable steps for the authors to take. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where the presentation difficulties lie. Additionally, the comment lacks specificity regarding what aspects of the presentation are challenging or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is difficult to follow. However, it does not provide any specific examples, reasoning, or suggestions to support this claim. Without detailed information on what aspects of the presentation are challenging or how they could be improved, the authors may find it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how the authors might improve the clarity or organization of their work. Without actionable feedback or examples, the authors are left without guidance on how to enhance the readability of their paper. This lack of specificity and detail makes the comment unhelpful, as it does not assist the authors in making improvements. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses questions about the performance of the algorithm on additional datasets, specifically Clothing1M and WebVision, using DivideMix as the evaluation method. While it implies that the authors should consider these additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the performance of the algorithm on specific datasets, namely Clothing1M and WebVision, using DivideMix as the evaluation method. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the performance on these datasets, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the performance of the algorithm on specific datasets, namely Clothing1M and WebVision, using DivideMix as the evaluation method. This feedback is 3 as it prompts the authors to consider additional experiments and potentially improve the robustness of their results. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address these questions or what analyses might be relevant. While it identifies an area for improvement, it does not offer actionable steps for the authors to take, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct more experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. While the comment implies that these additional experiments are necessary, it does not explicitly instruct the authors to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted on T5, PaLM, and GPT series LLMs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for additional experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. However, the comment does not provide specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the study. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 2, as it provides a general suggestion without sufficient support.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental setup by suggesting that the authors should conduct more experiments on different famous LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. This feedback is 3 as it highlights an area for improvement, prompting the authors to consider expanding their experiments to include additional models. However, the comment could be more helpful if it provided specific reasons or examples for why these additional experiments are necessary or how they would enhance the study. Overall, the comment offers some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of description regarding the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation of defenses would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the lack of description regarding the hyperparameters used by each defense and how they are derived, suggesting a maximally charitable evaluation of defenses. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue effectively. The lack of detailed justification or evidence makes the claim 2, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of description regarding the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation of defenses would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by enhancing the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it included examples or further guidance on how to implement this suggestion. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results lack immediate practical implications and recommends that the authors provide more takeaway points for practitioners. It specifically mentions the observation about querying a cluster proportionally to the square root of its size and questions whether this is a novel finding. While the comment implies that the authors should include more practical insights, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more practical takeaways and clarify the novelty of their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the authors should provide more takeaway points for practitioners. It specifically mentions the observation about querying a cluster proportionally to the square root of its size and questions its novelty. However, the comment does not explicitly mention which part of the paper discusses these theoretical results, making it weakly grounded. The authors can infer that it relates to the theoretical results section, but this inference is not direct. The comment is specific in its suggestion to include more practical takeaway points and clarify the novelty of the findings. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. The reviewer suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation about querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or how it could be more practical. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and suggests that the theoretical results lack immediate practical implications. It provides a specific observation about querying a cluster proportionally to the square root of its size and questions whether this is a novel finding. The comment offers a constructive suggestion by recommending that the authors provide more takeaway points for practitioners, which could enhance the practical relevance of their work. However, the feedback could be more helpful if it included examples or guidance on how to make the theoretical results more applicable to practitioners. Overall, the comment is 3 as it identifies an area for improvement and provides a specific suggestion, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the introduction of separators in section 4, asking for clarification on their purpose beyond the typical T/I/O. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific information they need to include. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the purpose of introducing separators in that section, prompting the authors to clarify the additional information they provide beyond T/I/O. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of introducing separators in section 4, asking for clarification on their purpose beyond T/I/O. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the introduction of separators in section 4, specifically asking for clarification on their purpose beyond the typical T/I/O. This feedback is 3 as it prompts the authors to reconsider the role and necessity of separators in their work. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of mean pooling in the context of token pooling, suggesting that there could be other pooling strategies. While it implies that the authors should consider exploring alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other pooling strategies without specific guidance on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of mean pooling and suggesting the exploration of other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of mean pooling in token pooling, suggesting that there could be other pooling strategies. However, it does not provide any supporting evidence, reasoning, or references to justify why mean pooling might be the only option or to suggest alternative strategies. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the use of mean pooling in token pooling, suggesting that there could be other pooling strategies. This feedback is 3 as it prompts the authors to consider alternative pooling methods, which could potentially improve the robustness and generalizability of their approach. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to explore these alternative pooling strategies. While it encourages the authors to think beyond the current approach, it does not offer actionable steps or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison of the real search cost in terms of GPU days in Table 3, in addition to the number of queries. This feedback is explicit, as it clearly states what the authors should do to improve their draft. The action is concrete because it specifies exactly what additional information should be included in the table. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison of the real search cost in terms of GPU days. This provides clear guidance on what additional information should be included in the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a comparison of the real search cost in terms of GPU days in Table 3, in addition to the number of queries. This is a suggestion for improvement, not a claim that requires verification. The comment is factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by recommending that the authors include a comparison of the real search cost in terms of GPU days in Table 3, in addition to the number of queries. This feedback is clear and directly points out a potential enhancement to the presentation of data in the paper, which could help readers better understand the computational resources required for the experiments. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Despite this, the suggestion is clear and actionable, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include details about the training process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"training details,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a specific dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This inquiry is actionable as it prompts the authors to provide more information about the training process, which could enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested ways to address this issue or provided context on why this information is important. Overall, the feedback is 3 as it identifies a specific area for improvement but lacks depth and guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the work should include comparisons with other taskoriented recommendation systems, such as the work by Li et al. (2017) and He et al. (2015). It implies that these comparisons would help clarify the differences between the current work and other chatbox research works. However, the comment does not provide specific guidance on how to conduct these comparisons or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with specific works, such as Li, Xiujun, et al. (2017) and He, Ji, et al. (2015), to clarify the differences between the current work and other chatbox research works. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in suggesting the inclusion of these comparisons to highlight differences, but without explicit references to sections, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the work should include comparisons with specific works, such as Li, Xiujun, et al. (2017) and He, Ji, et al. (2015), to clarify the differences between the current work and other chatbox research works. The comment provides specific references to these works, which adds credibility to the suggestion. However, it lacks detailed reasoning or explanation on why these comparisons are necessary or how they would enhance the paper. While the references are relevant, the comment could be more 5 with additional context or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the work should include comparisons with specific works, such as Li, Xiujun, et al. (2017) and He, Ji, et al. (2015), to clarify the differences between the current work and other chatbox research works. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including these comparisons. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, particularly in MSVD, where performance shows minor improvements. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the genericity of their methods. There is no explicit or implicit action for the authors to take, and no concrete details on how to enhance the methods. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that these methods are not generic on some crossmodel retrieval tasks, particularly in MSVD, where performance shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, specifically noting that the performance in MSVD shows minor improvements. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, comparisons, or references to substantiate the assertion that the methods are not generic. Without such supporting information, the claim remains 1, as it is difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, particularly in MSVD, where performance shows minor improvements. This feedback is 3 as it highlights a potential limitation of the methods, prompting the authors to consider the generality of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the genericity of their methods. To be more helpful, the comment could include recommendations on how to enhance the methods or suggest alternative approaches. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the experimental strengths of the proposed approach, suggesting that the authors\" method of running a descent procedure for 40 different networks is not as effective as using vanilla Adam with 40 random initial points. The reviewer implies that the authors should consider a simpler approach, such as running vanilla Adam, to achieve the same goal. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the experimental setup. The action is implicit and somewhat vague, as the authors need to infer that they should consider a simpler approach and may not fully understand how to execute this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the need to run a descent procedure for 40 different networks. It suggests that a simpler approach, such as using vanilla Adam with 40 random initial points, could achieve the same goal. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the experimental approach, suggesting a more efficient method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the proposed approach, suggesting that a simpler method, such as using vanilla Adam with 40 random initial points, could achieve the same goal. The reviewer provides a logical reasoning by comparing the proposed method to a more straightforward approach, which is a commonsense argument. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to further explore and clarify the reasoning to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, suggesting that the method of running a descent procedure for 40 different networks is not as effective as using vanilla Adam with 40 random initial points. The reviewer points out that the goal of reaching the global minimum is not dependent on each initialization, but rather on at least one initialization achieving it. This feedback is 3 as it identifies a potential weakness in the experimental setup and suggests a simpler approach that could be more efficient. However, the comment could be more helpful if it provided specific guidance on how to implement this alternative method or discussed the implications of this suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study does not establish a relationship between the top selected patches and the disease, indicating that the study is incomplete. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might establish this relationship or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where in the paper this issue is addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is incomplete because it does not establish a relationship between the top selected patches and the disease. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. This feedback highlights a critical gap in the study that needs to be addressed to strengthen the paper. However, the comment lacks specific suggestions or guidance on how the authors might establish this relationship or what additional analyses or data could be included to address this issue. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to correct the quotation mark used in the phrase \"for \"inbetween\" uncertainty,\" specifying that the first quotation mark should be a forward mark rather than a backward mark. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be changed. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty\" and provides a specific instruction on correcting the quotation mark used. It clearly identifies the part of the paper being addressed, allowing the authors to accurately pinpoint the section that needs revision. The comment is also specific, as it details the exact issue with the quotation mark and provides a clear correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction regarding the use of quotation marks in a specific phrase. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for correcting a typographical error in the paper. It identifies an issue with the quotation mark used in the phrase \"for \"inbetween\" uncertainty,\" specifying that the first quotation mark should be a forward mark rather than a backward mark. This feedback is clear and directly addresses a minor but important detail that could affect the clarity and professionalism of the paper. By providing a precise correction, the comment empowers the authors to improve the accuracy and presentation of their work. Therefore, the comment is 4, as it offers a clear and actionable piece of feedback that can enhance the quality of the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance of FedSP in Table 1 and Table 2 on certain datasets. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements, additional experiments, or modifications to the analysis. Without actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the performance of FedSP on certain datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the performance of FedSP in Table 1 and Table 2 on certain datasets. While it identifies a potential weakness in the paper, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights an area for improvement, but it does not offer a comprehensive or detailed approach for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggests improvements regarding the clarity and specificity of the paper. It asks for an explanation of what Omega is, the link between OMD and its family of algorithms, and the specific theorem in 32 that supports the regret guarantee. While the comment implies that the authors should provide more detailed explanations and references, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for clarification on what Omega is, the link between OMD and its family of algorithms, and the specific theorem in 32 that supports the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the paper\"s content, such as what Omega is, the link between OMD and its family of algorithms, and the specific theorem in 32 that supports the regret guarantee. These are questions that require the authors to provide more detailed explanations and references, rather than making subjective claims. Since the comment is primarily seeking clarification and does not contain opinions or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and seeks clarification regarding the paper\"s content, specifically about the definition of Omega, the relationship between OMD and its family of algorithms, and the specific theorem in 32 that supports the regret guarantee. While the comment identifies areas where the paper could be improved in terms of clarity and specificity, it does not provide actionable suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it lacks depth and specificity that would guide the authors in making meaningful revisions. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a potential issue with the models being learned directly from pixels without a Markovian state. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what changes could be made to improve the models. Without specific suggestions or actions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue with the models being learned directly from pixels without a Markovian state. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the models or the learning process are problematic. Without clear grounding and specificity, the authors may struggle to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the models being learned directly from pixels without a Markovian state. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve their models. Without actionable feedback or detailed explanations, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific point of interest regarding the use of the Hamming distance as a scoring loss in the context of CRF. The reviewer suggests that this approach is unconventional and recommends pointing out some references to support this claim. While the comment implies that the authors should provide references to support their use of the Hamming distance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include references and are not given concrete guidance on which references to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular concern regarding the use of the Hamming distance as a scoring loss in the context of CRF, suggesting that this approach is unconventional and recommending that the authors point out some references to support their use of this method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the Hamming distance as a scoring loss in the context of CRF, suggesting that it is unconventional. The reviewer provides a specific example of a common practice, which is the nodewise Hamming loss, and requests references to support the use of the Hamming distance over entire parts of the sequence. This request for references provides a clear direction for the authors to address the concern, making the claim 3. However, the comment could be strengthened by providing specific references or examples to support the claim, which would make it 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the use of the Hamming distance as a scoring loss in the context of CRF, noting that it is unconventional and different from the commonly reported nodewise Hamming loss. The reviewer suggests that the authors provide references to support their use of this approach, which is a valuable and actionable piece of feedback. By prompting the authors to substantiate their claims with references, the comment encourages them to enhance the credibility and robustness of their methodology. However, the comment could be more helpful if it provided specific examples or suggested where such references might be found. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections, instead mentioning the metrics along with the datasets or in the captions of the tables. This feedback provides explicit guidance on how to reorganize the content, making it concrete and actionable. The authors know exactly what changes to make to improve their draft, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections, instead mentioning the metrics along with the datasets or in the captions of the tables. This feedback is specific in terms of what needs to be changed, such as renaming the element and suggesting where to mention the metrics. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the evaluation section, but the comment lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests renaming the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections, instead mentioning the metrics along with the datasets or in the captions of the tables. This claim is 3 as it provides a logical reasoning for the change, suggesting that \"evaluation\" may have a more general meaning and that metrics are wellknown and standard. However, the comment lacks specific examples or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting a change in terminology from \"Evaluation\" to \"Metrics\" to better align with the general meaning of the term. It also recommends restructuring the content by removing the corresponding sections and instead mentioning the metrics along with the datasets or in the captions of the tables. This guidance is clear and constructive, as it helps the authors improve the clarity and organization of their paper. However, the comment could be more helpful if it included examples of how to integrate the metrics into the captions or suggested specific sections to revise. Overall, the feedback is 4, as it offers valuable insights for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide specific guidance on how the authors should explore this dataset further or what aspects of the dataset should be emphasized. The action is implicit and lacks concrete details, leaving the authors uncertain about how to apply the suggested improvement. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where DRRI could be utilized. Additionally, the comment lacks specificity regarding what aspects of DRRI should be explored or how it could be integrated into the paper. Without explicit references or detailed guidance, the authors may find it challenging to determine the exact areas for improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or beneficial. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore this dataset further or what aspects of the dataset should be emphasized. Without detailed suggestions or examples, the authors are left without actionable feedback on how to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also provides a specific example of how the improvement might be difficult to characterize as remarkable due to the squished axes. This feedback is clear and provides concrete guidance on how to revise the text to be more objective and precise. The authors know exactly what changes to make to improve the draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reference 218, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of more objective terms instead of \"remarkable\" and provides a specific example of how the improvement might be difficult to characterize as remarkable due to the squished axes. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe an accuracy improvement. It provides a specific example of how the improvement might be difficult to characterize as remarkable due to the squished axes. This reasoning is logical and provides a clear basis for the suggestion, making the claim 4. However, it could be strengthened by referencing specific studies or examples where similar issues have been addressed. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also offers a concrete example of how the improvement might be difficult to characterize as remarkable due to the squished axes. This guidance is clear and helps the authors refine their language to be more precise and objective, which is valuable for improving the clarity and professionalism of their draft. However, the comment could be more helpful if it included additional suggestions on how to address the axes or improve the overall presentation. Overall, the feedback is 4 as it provides clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider using longer video sequences to address the issue of inconsistent motion, changing color, or object disappearance over time. It acknowledges the paper\"s interesting idea and extensive experiments but notes that the results are not perfect and could be improved. The comment implies that the authors should explore longer video sequences to enhance the evaluation. However, it does not provide specific guidance on how to implement this suggestion or what metrics to use for the longer sequences. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples like \"16 frames,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the synthesized results for UCF101, such as inconsistent motion, changing color, or object disappearance over time. The suggestion to consider videos with a longer duration is clear and provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are not perfect and could be improved by considering longer video sequences. It provides specific examples of issues observed in the synthesized results for UCF101, such as inconsistent motion, changing color, or object disappearance over time. The suggestion to use longer video sequences is logical and based on the observation of these issues. However, the comment lacks detailed reasoning or references to support why longer sequences would address these problems. While the claim is 3 due to the specific examples provided, it could be strengthened with more detailed justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the current experimental setup, noting that the results for UCF101 are inconsistent in terms of motion, color changes, or object disappearance over time. It suggests that using longer video sequences could potentially address these issues, implying that the authors might consider extending their experiments to longer sequences. The comment acknowledges the paper\"s interesting idea and extensive experiments but points out that the results are not yet perfect. It also highlights the quantitative and qualitative evaluation, which shows improved results over the previous stateoftheart. While the comment provides a clear direction for improvement by suggesting a potential enhancement to the experimental setup, it could be more helpful by offering specific examples or methods for implementing the longer video sequences. Overall, the feedback is 4 as it guides the authors toward a potential improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that it is not yet possible to realize efficiency gains on GPU, similar to most work on pruning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could consider to improve efficiency gains on GPU. Without any actionable advice or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, making it difficult for the authors to identify the exact section being discussed. It also lacks specificity because it does not provide details on what aspects of efficiency gains on GPU are being discussed or how they relate to the work on pruning. Without specific references or detailed feedback, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is not yet possible to realize efficiency gains on GPU, similar to most work on pruning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a common issue in the field, noting that it is not yet possible to realize efficiency gains on GPU, similar to most work on pruning. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this issue. It does not offer insights into potential solutions or areas for improvement, leaving the authors without a clear direction for enhancing their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the numerical evaluation is not fully convincing because the method is only tested on synthetic data. It also notes that the comparison with 5 is not fair, as 5 is designed for a more complex problem. While the comment identifies specific issues with the evaluation, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to expand their evaluation to include more realistic scenarios or provide a fairer comparison. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation section, specifically noting that it is only evaluated on synthetic data. It also critiques the comparison with 5, which is designed for a more complex problem. This provides some grounding as it refers to specific sections of the paper, but the authors may need to infer which parts are being discussed. The comment is specific in detailing the issues with the evaluation and the comparison, making it clear what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only tested on synthetic data. It also criticizes the comparison with 5, stating that it is not fair as 5 is designed for a more complex problem. The comment provides a logical reasoning for the critique, explaining why the comparison is not fair. However, it lacks specific examples or detailed references to support the claim about the fairness of the comparison. This makes the claim 3, as the authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only tested on synthetic data, which may limit its applicability and generalizability. It also critiques the comparison with 5, pointing out that 5 is designed for a more complex problem, specifically without knowledge of the camera pose parameters. This feedback is valuable as it highlights potential weaknesses in the evaluation and suggests areas for improvement. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations or examples of how to conduct a more comprehensive evaluation. Overall, the comment is 4 as it directs the authors\" attention to important aspects of their evaluation that need further exploration and justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the authors studied the impact of using a larger number of bits in the logits on the robustness against a more powerful PGD attack. It suggests that this experiment might be unnecessary but could strengthen the paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of using a larger number of bits in the logits on the robustness against a more powerful PGD attack. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting that the experiment might be unnecessary but could strengthen the paper, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of using a larger number of bits in the logits on the robustness against a PGD attack. It suggests that this experiment might be unnecessary but could strengthen the paper. However, the comment lacks specific reasoning or evidence to support the claim that a 32bit logit would improve robustness against a more powerful adversary. Without detailed justification or references, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a relevant question about the impact of using a larger number of bits in the logits on the robustness against a more powerful PGD attack. It suggests that this experiment might be unnecessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this question or what experiments could be conducted to explore this aspect. The feedback is 3 as it prompts the authors to consider an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the cost of insurance for men and women after applying the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question, such as suggesting additional analysis, data collection, or discussion. Without any actionable steps or suggestions, the authors are left without a clear understanding of what to do in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the cost of insurance for men and women after applying a method, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this question is relevant. Additionally, the comment lacks specificity regarding what aspect of the cost analysis is being questioned or how it should be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for information about the cost of insurance for men and women after applying a method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the cost of insurance for men and women after applying a method, but it does not provide any context or explanation for why this question is relevant or how it might impact the paper. It lacks specificity and does not offer any actionable feedback or suggestions for the authors to address this point. Without additional information or guidance, the authors are left without a clear understanding of how to respond to this comment. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not provide sufficient detail or direction for the authors to act on."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016, to support the suggestion. This feedback is clear and provides concrete guidance on how the authors should address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests clarification on the difference between meta solvers and centralized RL, providing a concrete example (Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016) to support the suggestion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers and suggests clarifying the difference between meta solvers and centralized RL. The comment provides a specific reference to Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016, which supports the suggestion by offering an example of a relevant work. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by explaining how the example relates to the current work or why it is relevant. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the meta solvers and their relationship to centralized reinforcement learning (RL). It suggests that the authors clarify the distinction between meta solvers and centralized RL, where agents share weights. The comment is clear and provides a concrete example (Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016) to support the suggestion, offering a specific reference that could help the authors understand the context better. This feedback is actionable and provides a clear direction for improvement, making it 5 for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the definition of M_T, which is defined over the probabilities of atomic events, is not clearly explained due to the notation used. The reviewer explicitly recommends providing examples to help clarify the concept. This feedback is explicit and concrete, as it clearly identifies the need for examples to aid understanding. The authors know exactly what action to take\u2014adding examples\u2014to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the definition of M_T, which is defined over the probabilities of atomic events, and suggests that examples should be provided to clarify the concept. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T, which is defined over the probabilities of atomic events, is not clearly explained due to the notation used. The reviewer recommends providing examples to aid understanding. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or detailed reasoning to support the claim that examples are necessary. This makes the claim 3, as the authors would need to infer the need for examples without explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events. It suggests that the notation used may not be making the concept clear and recommends providing examples to aid understanding. This feedback is clear and actionable, as it points out a potential area for improvement and offers a concrete suggestion for enhancing the clarity of the paper. By providing examples, the authors can help readers better grasp the concept, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide specific guidance on what aspects could be improved or how the authors might address this suggestion. The comment lacks explicit actions or concrete details, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying room for further refinement. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects could be improved or how the authors might address this suggestion. Without specific references or detailed feedback, the authors cannot confidently determine which sections or elements need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting room for further refinement. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this observation or how it impacts the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it lacks specificity and does not provide detailed feedback or suggestions on how the authors might address this observation or improve their work. Without actionable guidance or concrete examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide references for specific passages in Section 3.2 and to clarify the term \"MLP\" in Figure 2. These actions are clear and direct, allowing the authors to know exactly what needs to be done to improve their draft. The feedback is specific and provides concrete guidance on how to address the issues, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely Section 3.2, lines 230234 and 234235, and Figure 2. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it clearly specifies what needs to be addressed: providing references for two passages and clarifying the term \"MLP\" in Figure 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarification, which are factual and descriptive in nature. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting references for two passages in Section 3.2 and clarifying the term \"MLP\" in Figure 2. This guidance is clear and directly addresses potential gaps in the paper\"s references and terminology, which can help the authors improve the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to find appropriate references or provided examples of relevant literature. Overall, the feedback is 4 as it directs the authors to specific areas needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that they are not convincing enough to validate the effectiveness of the proposed method. It suggests that the performance is similar to IRM, which might be due to the problems mentioned above. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the results. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance their experimental results or provide a more detailed explanation of the performance comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, indicating that they are not convincing enough to validate the effectiveness of the proposed method. It also mentions that the performance is similar to IRM, which might be due to the problems mentioned above. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental results and the potential cause, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the results are not convincing or that the performance is similar to IRM. This makes the claim 3, as the authors would need to infer the basis of the critique without explicit justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a concern regarding the experimental results on the last two datasets, noting that they are not convincing enough to validate the effectiveness of the proposed method. It suggests that the performance is similar to IRM, which might be due to the problems mentioned above. However, the comment lacks specific guidance or suggestions on how the authors could address this issue or improve the results. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left to infer that they need to enhance their experimental results or provide a more detailed explanation of the performance comparison. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why both entities are detected in Figure 2 and what distinguishes this from just knowing the long one. While it implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete guidance on how to address the issue. The action is implicit and vague, as the authors are left to infer that they need to explain the rationale behind detecting both entities. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about why both entities are detected in the example and what distinguishes this from just knowing the long one. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind detecting both entities in Figure 2 and the difference between knowing the long one. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind detecting both entities in Figure 2 and the difference between knowing the long one. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is 2, as it only points out a potential area for improvement without offering detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks empirical validation and suggests that the authors should include experiments to validate the bounds. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the paper. The comment is specific and actionable, as it clearly identifies the missing component of empirical validation and provides a concrete suggestion for how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks empirical validation and requests experiments to validate the bounds. However, it does not specify which part of the paper should include these experiments or where the bounds are discussed, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of specific guidance on what experiments to conduct or how to validate the bounds makes the comment weakly grounded. Additionally, since it does not provide detailed suggestions on how to conduct these experiments, it is not specific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, specifically mentioning the need for experiments to validate the bounds. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. This feedback is valuable as it provides a specific direction for the authors to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to design these experiments or what specific aspects to focus on. Despite this, the comment is 4 as it directs the authors toward a critical area that needs attention, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks whether \"chunk\" is still considered sequential information. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"chunk\" in the context of nonsequential information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the phrase \"nonsequential information such as chunks,\" prompting the authors to clarify whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" and asks whether \"chunk\" is still considered sequential information. This is a specific and actionable question that could help the authors clarify their terminology and improve the clarity of their writing. However, the comment does not provide further guidance or suggestions on how to address this issue or what specific aspects of the term \"chunk\" might be causing confusion. While it points out a potential area for improvement, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are correctly represented as cropped parts of the input image or just masked versions. The reviewer suggests that if the output patches are indeed just masked versions, Figure 1 might be misleading. Additionally, the reviewer proposes that zooming on the region of interest using bilinear sampling could provide better results. This feedback provides a clear and explicit action for the authors to take, which is to verify the correctness of the representation in Figure 1 and consider using bilinear sampling for better results. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the discrepancy between the equation and the figure, questioning whether the output patches are correctly represented as cropped parts of the input image or just masked versions. The comment further suggests that using bilinear sampling for zooming on the region of interest could provide better results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are correctly represented as cropped parts of the input image or just masked versions. The reviewer suggests that if the output patches are indeed just masked versions, Figure 1 might be misleading. The comment also proposes that using bilinear sampling for zooming on the region of interest could provide better results. While the comment raises a valid point, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use bilinear sampling is logical but could be more robust with additional explanation or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are correctly represented as cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed just masked versions, Figure 1 might be misleading. The comment also proposes that using bilinear sampling for zooming on the region of interest could provide better results. This feedback is clear and actionable, as it points out a potential issue with the visual representation of the data and suggests a more accurate way to present it. By addressing this discrepancy, the authors can improve the clarity and accuracy of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically questioning the validity of the upper bound when a node has 0 neighbors. The reviewer implies that the authors should address this exception, but the comment does not provide explicit guidance on how to do so. The action is implicit, as the authors can infer that they need to explain or correct the issue, but the comment lacks concrete details on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the validity of the upper bound when a node has 0 neighbors, prompting the authors to explain this exception. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of Theorem 1 by presenting a scenario where a node with 0 neighbors results in an upper bound of 0, which is not true. The reviewer implies that this exception needs to be addressed but does not provide a detailed explanation or evidence to support the claim. The lack of specific reasoning or examples makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid question about the validity of Theorem 1, specifically questioning the upper bound when a node has 0 neighbors. This feedback is 3 as it prompts the authors to reconsider the assumptions or conditions under which Theorem 1 holds. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address the issue or improve the theorem. While it identifies a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of technical novelty in the paper, noting that the idea, coattention mechanism, and architecture are similar to previous works by Xing and Tsang (2022a, b). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might differentiate their work or improve its originality. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a lack of technical novelty and suggests comparing the paper with two mentioned works, Xing and Tsang (2022a, b). However, it does not specify which part of the paper this comparison should be made, nor does it provide detailed guidance on how to address the issue of limited novelty. The authors might infer that this feedback pertains to the methodology or results sections, but the lack of explicit grounding makes it difficult for them to pinpoint the exact areas needing improvement. The comment is specific in identifying the issue of limited novelty but lacks grounding, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, specifically noting similarities to previous works by Xing and Tsang (2022a, b). The comment provides a reference to these works, which partially supports the claim by indicating a potential area of overlap. However, the comment does not elaborate on how the current paper\"s approach differs from these previous works or provide specific examples of the similarities. This lack of detailed explanation or comparison makes the claim 3, as the authors would need to infer the extent of the overlap and how it affects the novelty of their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of technical novelty in the paper, noting that the idea, coattention mechanism, and architecture are similar to previous works by Xing and Tsang (2022a, b). While it highlights a potential issue with the originality of the paper, it does not provide specific suggestions or guidance on how the authors might differentiate their work or address the perceived overlap with previous studies. The comment lacks actionable advice or detailed feedback, making it 3 as it points out a critical area for improvement but does not offer a comprehensive path for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the training time reduction being less drastic than the parameter reduction. It suggests that this point should be revisited in the Discussion section, but the reviewer advises the authors to simply delete the mention of \"Discussion\" as it is not necessary. While the comment implies that the authors should reconsider the claim, it does not provide specific guidance on how to address the issue or what changes should be made. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the claim about the training time reduction being less drastic than the parameter reduction should be revisited in the Discussion section, which is not necessary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim regarding the training time reduction being less drastic than the parameter reduction. It points out that this point should be revisited in the Discussion section, which is not necessary, and suggests deleting the mention of \"Discussion.\" While the comment highlights a potential inconsistency in the paper\"s claims, it lacks depth and does not provide actionable feedback or suggestions for improvement. The authors are left with a vague indication of what needs to be addressed but without clear guidance on how to resolve the issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the problem to other downstream tasks or specifically to binding affinity prediction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to explore the broader applicability of their work. Without actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or specifically to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what the authors should consider or address in response to this question. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the applicability of the problem to other downstream tasks or specifically to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem to other downstream tasks or specifically to binding affinity prediction. This question prompts the authors to consider the broader relevance of their work, which could be valuable for understanding the scope and potential impact of their research. However, the comment does not provide any specific guidance or suggestions on how the authors might address this question or explore the broader applicability of their work. While it identifies an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the analysis of GPTgenerated rumors, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. It suggests that the authors should provide further analysis or solutions to address this issue. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about why GPTgenerated rumors are as difficult to detect as natural rumors, suggesting that the authors should provide further analysis or solutions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting GPTgenerated rumors compared to natural rumors, suggesting that the experimental results indicate that natural rumors are easier to detect. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or analysis, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the analysis of GPTgenerated rumors, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. It suggests that the authors should provide further analysis or solutions to address this issue. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what aspects should be explored. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution of the paper is limited, specifically noting that Section 4 focuses on heuristics rather than a formal and principled solution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific aspects need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically noting that Section 4 focuses on heuristics rather than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that Section 4 focuses on heuristics rather than a formal and principled solution. This feedback is 3 as it highlights an area where the paper could be strengthened by providing a more rigorous and systematic approach. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve the technical contribution. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the font size in Figure 6 is a little bit small. This provides a clear and direct action for the authors to take, which is to adjust the font size to improve readability. The comment is specific and concrete, as it identifies a specific element (font size) that needs attention and provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being too small. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a minor issue with the presentation of Figure 6, noting that the font size is too small. This feedback provides clear guidance for the authors to improve the readability of their figure. By addressing this issue, the authors can enhance the overall quality and clarity of their paper. However, the comment could be more helpful if it suggested specific ways to adjust the font size or provided additional context on why this issue is important. Despite this, the comment is 4 as it directs the authors to a clear area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) should be more thoroughly explored, particularly in the context of MixBoost where it is currently set to a quasiuniform distribution. The reviewer implies that considering various PMFs could add depth to the experimental setting, unless there is an obvious reason for the current choice. While the comment suggests an action\u2014exploring different PMFs\u2014 it does not provide specific guidance on how to implement this exploration or what specific PMFs to consider. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the use of the probability mass function (PMF) in the context of MixBoost, specifically mentioning that it is set to a quasiuniform distribution. It suggests that considering various PMFs could add depth to the experimental setting. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in suggesting that exploring different PMFs could enhance the experimental setting, but without clear guidance on which sections to focus on, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the probability mass function (PMF) is underexploited in the context of MixBoost, where it is currently set to a quasiuniform distribution. The reviewer argues that each learner class should be considered individually, even in the case of a BDT of different depths. The comment implies that exploring various PMFs could add depth to the experimental setting. However, the claim lacks specific examples or references to support the idea that the quasiuniform distribution is wellsuited, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the probability mass function (PMF) could be more thoroughly explored, particularly in the context of MixBoost where it is currently set to a quasiuniform distribution. The reviewer points out that each learner class should be considered individually, even in the case of a BDT of different depths, implying that exploring various PMFs could add depth to the experimental setting. While the comment highlights a potential area for enhancement, it lacks specific suggestions or examples of how to implement this exploration or what specific PMFs could be considered. This limits the comment\"s usefulness, as it provides a general direction for improvement but does not offer detailed guidance. Therefore, the comment is 3, as it offers insight but requires more detailed feedback to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is fair to compare the accuracies of ChatGPT with other models, given that ChatGPT shows a high percentage of abstention. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing accuracies between ChatGPT and other models, given that ChatGPT shows a high percentage of abstention. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how they might be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing accuracies between ChatGPT and other models, given that ChatGPT shows a high percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparing accuracies between ChatGPT and other models, given that ChatGPT shows a high percentage of abstention. This is a relevant point that could impact the validity of the experimental results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss connections with a specific reference, a, which is relevant to their topic. It provides a clear and concrete action by specifying which reference to include and what aspect of the connection should be discussed. This guidance is direct and provides specific instructions on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely discussing connections with reference a, which uses supervised learning in QBF solving and generalizes SMT. This provides clear guidance on what additional information or discussion is needed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks references, specifically mentioning a relevant work by Samulowitz, Horst, and Memisevic. The comment provides a specific reference and suggests discussing its connections with the current work. However, it does not provide detailed reasoning or explanation for why this reference is relevant or how it should be integrated into the paper. The lack of specific guidance or detailed justification makes the claim 3, as the authors would need to infer the importance of the reference and its relevance to the paper.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of relevant references. It points out a relevant work by Samulowitz, Horst, and Memisevic, which discusses QBF solving using supervised learning and generalizes SMT. The comment suggests that the authors should discuss these connections, providing a clear and actionable piece of feedback. By recommending the inclusion of this reference and its relevance to the paper, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it provided specific suggestions on how to integrate this reference into the discussion. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. However, the comment does not provide explicit guidance on how the authors should address this question or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore alternative relationships and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about whether the monotonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. It references a specific work, \"Learning the Pareto Front with Hypernetworks,\" which provides a basis for the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. The comment references a specific work, \"Learning the Pareto Front with Hypernetworks,\" which provides a basis for the suggestion. This reference adds credibility to the claim, as it supports the idea that exploring alternative relationships could be beneficial. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. It references a specific work, \"Learning the Pareto Front with Hypernetworks,\" which provides a basis for the suggestion. This feedback is 3 as it prompts the authors to consider alternative relationships and potentially expand their analysis. However, the comment could be more helpful if it provided specific suggestions or examples of alternative relationships that could be explored. Overall, the comment offers a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison in terms of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific aspects they should consider. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific analyses, the authors cannot confidently determine where this question is relevant. Additionally, the comment lacks specificity regarding what aspects of computation cost or running time need to be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the comparison in terms of computation cost or running time. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the experimental results. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of computation cost or running time should be considered. While it identifies an area for improvement, the lack of actionable feedback limits its usefulness. Therefore, the comment is 3, as it highlights a potential area for enhancement but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback provides a clear and explicit action for the authors to take, specifying the type of problems they should consider. The suggestion is concrete, as it offers a specific direction for the authors to improve their draft by focusing on different aspects of the problem. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the introduction section of the paper, specifically mentioning the goal of the paper and the examples chosen. It provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This makes the comment fully grounded, as it clearly identifies the part of the paper being addressed. Additionally, it is specific because it provides a clear direction for improvement by suggesting a different focus for the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the introduction do not effectively convey the importance of interprocess communication. The reviewer suggests that the examples, particularly those involving samplingbased Bayesian methods, are not relevant as they are already embarrassingly parallel. The comment provides a logical reasoning by pointing out the lack of convincing examples and offers a suggestion for improvement by focusing on different types of problems. However, the comment could be strengthened by providing specific examples or references to support the claim that the current examples are insufficient. Overall, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the introduction regarding the paper\"s goal, suggesting that the examples chosen do not effectively convey the importance of interprocess communication. It provides a specific suggestion for improvement by recommending the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their draft by addressing the weaknesses in the introduction. However, the comment could be more helpful if it included additional examples or explanations to fully support the suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning methods. It also questions whether privacy preservation is an issue for traffic signal control, suggesting that one traffic signal should not know the color of the next one. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their draft in response to these questions. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning methods and questions its relevance to traffic signal control. However, it does not specify which part of the paper discusses privacy preservation or traffic signal control, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in questioning the relevance of the approach to traffic signal control but does not provide detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning methods and questions its relevance to traffic signal control. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that privacy preservation is an issue for traffic signal control. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning methods and questions its relevance to traffic signal control. It suggests that one traffic signal should not know the color of the next one, implying a potential issue with privacy preservation. However, the comment does not provide specific feedback or suggestions on how the authors might address these concerns or improve their draft. While it identifies a potential weakness, it lacks actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should perform a fair comparison by including another pretrained model, such as ExpertBert, in their analysis. This feedback provides a clear and concrete action for the authors to take, specifying which model to include and why it is necessary for fairness. The comment is specific in its request for an additional comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and the specific lines (529534) where the comparison is made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely that PMEF lacks a pretraining module, and suggests a fairer comparison by recommending the inclusion of ExpertBert. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF is unfair because PMEF lacks a pretraining module. The reviewer suggests that a fair comparison should include another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s innovative pretraining module design. While the comment identifies a potential issue with the comparison, it lacks specific examples or references to substantiate the claim. The suggestion to include ExpertBert as a reference for comparison is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the fairness of the comparison in Figure 3, where the authors compare CPEF with PMEF. It points out that PMEF lacks a pretraining module, which undermines the fairness of the comparison. The comment suggests a constructive improvement by recommending that CPEF be compared with another pretrained model, such as ExpertBert, to better demonstrate the advantage of CPEF\"s innovative pretraining module design. This feedback is clear, actionable, and provides a specific suggestion for enhancing the fairness and clarity of the comparison, making it 5 for the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies an issue with the hyperlink for footnote 3 and 4, indicating that they do not seem to work. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete steps for the authors to take to resolve the problem, leaving them without a clear path forward. As a result, the action is implicit and vague, making it difficult for the authors to know what specific changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the hyperlink for these footnotes does not seem to work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the hyperlink for footnote 3 and 4 not working. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the hyperlink for footnote 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can easily address by ensuring the hyperlinks are functional. However, the comment does not provide further guidance or suggestions on how to resolve this issue, such as recommending a specific fix or explaining why the hyperlinks are important. While it points out a concrete problem, it lacks depth and could be more helpful if it offered additional context or suggestions. Therefore, the comment is 3, as it provides a clear area for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to make it clearer. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a correction regarding the Label Embeddings being external parameters rather than the output of the encoder. The comment is explicit in its suggestions and provides concrete details on how to improve the discussion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"modeling section\" and \"section 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be revised, such as the need for a better formalization of the architecture and a correction regarding the Label Embeddings being external parameters rather than the output of the encoder. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to clarify the architecture and Label Embeddings. The reviewer provides specific examples, such as the need for a better formalization of the architecture and a correction regarding the Label Embeddings being external parameters rather than the output of the encoder. This level of detail and specificity makes the comment 4, as it provides clear guidance on what needs to be addressed. However, it could be further strengthened by referencing specific sections or providing more detailed reasoning. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity and accuracy of the discussion, particularly in the modeling section. It suggests revising the discussion to better formalize the architecture and correct a potential misunderstanding regarding the Label Embeddings. By pointing out that the Label Embeddings are external parameters and clarifying the figure\"s misleading representation, the comment offers clear guidance on how to improve the draft. This level of detail and constructive feedback makes the comment 5, as it empowers the authors to make significant improvements to their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network in the section is hard to understand and recommends starting the section with the final paragraph that clarifies it. This feedback provides a clear and explicit action for the authors to take, which is to reorganize the section to begin with the final paragraph that explains the neural network. The comment is specific about what needs to be done and how to implement it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number (528) and the section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to start the section with the final paragraph that clarifies the description of the neural network. This guidance is actionable and provides a concrete step for the authors to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand, suggesting that the final paragraph of the section clarifies it. However, the comment does not provide specific examples or detailed reasoning to support why the initial description is unclear or how the final paragraph clarifies it. This lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to fully understand and address the issue without further clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network in the paper. It suggests that the final paragraph of the section, which clarifies the description, should be used to start the section. This feedback is clear and actionable, providing the authors with a concrete step to improve the readability and organization of their paper. By starting with the final paragraph, the authors can ensure that the description of the neural network is more accessible to readers. However, the comment could be more helpful if it included additional suggestions on how to enhance the clarity of the initial description or provided examples of how to rephrase it. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the model being limited to CTC loss and suggests exploring attentionbased encdec training. While the comment implies that the authors should consider this alternative training approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the model being limited to CTC loss and suggests exploring attentionbased encdec training. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the model is discussed. Without explicit references, the authors may find it challenging to identify the exact part of the paper being addressed. While the suggestion is specific, the lack of grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the model being limited to CTC loss and suggests exploring attentionbased encdec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this suggestion is necessary or beneficial. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim and how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the model being limited to CTC loss and suggests exploring attentionbased encdec training. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to implement this suggestion. The comment is 3 as it prompts the authors to consider a different training approach, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the division of tables into three types, suggesting that one type (the column header) should work. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider consolidating the column header into one type, but it lacks concrete steps or details on how to implement this change. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type (the column header) should work. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the division of tables into three types, specifically questioning whether one type (the column header) should work. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning whether one type (the column header) should work. While it identifies a potential issue with the organization of the tables, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, leaving the authors without clear direction on how to improve their draft. As a result, the comment is 2, as it only points out a potential area for improvement without offering any actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP could be considered. However, it does not provide explicit guidance on which specific attack methods should be used or how to implement this suggestion. The comment implies that the authors should explore additional attack methods, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the use of naive attack methods in the paper, specifically mentioning two methods: randomly adding tokens as suffixes and generating a universal adversarial suffix. It suggests that other classical attack methods in NLP could be considered, but it does not specify which other methods should be used or why they would be more appropriate. The comment lacks grounding as it does not explicitly mention a specific section or part of the paper where these attack methods are discussed. It also lacks specificity because it does not provide detailed guidance on how to address the issue or what other attack methods should be considered. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive, suggesting that other classical attack methods in NLP could be considered. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s approach by pointing out that the attack methods used are naive and suggests that other classical attack methods in NLP could be considered. This feedback is 3 as it highlights an area for improvement and encourages the authors to explore additional attack methods. However, the comment lacks specific guidance or examples of alternative attack methods that could be used, which would make it more actionable. The authors are left with a general direction but without detailed steps to follow, making the comment 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a concern about the impact of mitigation methods on the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the image quality. Without specific suggestions or steps, the authors are left without direction on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the impact of mitigation methods on the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the mitigation methods or image generation capabilities are problematic. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve the image quality. Without actionable feedback or detailed insights, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk of information leakage from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the fairness of their comparisons. The action is implicit and vague, as it does not specify how to mitigate the risk of information leakage or ensure fairness. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk of information leakage from the pretrained visual model and target dataset, which could skew results and lead to issues of unfairness. However, the comment does not specify which part of the paper discusses these comparisons or where the potential issues are detailed, making it weakly grounded. The comment is specific in identifying the concern about fairness and information leakage, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests a potential risk of information leakage from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to existing SSL methods or studies that have encountered similar issues. This makes the claim 3, as it provides a logical basis for the concern but lacks detailed evidence or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL (SelfSupervised Learning) methods due to the incorporation of prior knowledge. It highlights a potential risk of information leakage from the pretrained visual model and target dataset, which could skew results and lead to issues of unfairness. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparisons. The feedback is 3 as it points out a potential weakness in the methodology, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what changes could be made to the figure or the analysis. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, prompting the authors to consider why this might be the case. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks a basis for verification, making it difficult for the authors to understand the significance of the observation or how it might impact their work. Therefore, the claim is 1.", "helpfulness_rationale": "The comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which might be surprising to the reviewer. However, it does not provide any specific feedback or suggestions on how this observation could be addressed or improved in the paper. Without actionable guidance or a clear explanation of the implications of this observation, the authors are left without a clear path for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds should be used as a baseline, and instead, the minimal kmeans objective over multiple seeds is more reasonable. The reviewer provides references to support this suggestion, indicating that the current approach may not be the most effective. However, the comment does not explicitly instruct the authors to change their approach or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the minimal kmeans objective over multiple seeds and may need to explore the references provided to understand the rationale fully. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific change to the baseline used in the paper, recommending the use of the minimal kmeans objective over multiple seeds instead of the average. It provides references to support the suggestion, which adds depth to the feedback. However, the comment does not explicitly mention which part of the paper discusses the baseline, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds should be used as a baseline, and instead, the minimal kmeans objective over multiple seeds is more reasonable. The reviewer supports this claim by referencing two external works that discuss the use of minimal kmeans objectives. This provides a logical and evidencebased justification for the suggestion, making the claim 5. The references to specific studies on local maxima in Gaussian mixture models and the properties of kmeans on clustering benchmark datasets add depth to the argument, ensuring that the authors understand the rationale behind the suggestion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of the minimal kmeans objective over multiple seeds as a baseline, rather than the average. It supports this suggestion with references to relevant literature, which adds depth and credibility to the feedback. This guidance is clear and actionable, as it directs the authors to consider a more robust approach for their baseline comparisons. However, the comment could be more helpful if it included additional context or explanation on why this change is beneficial or how it might impact the results. Overall, the feedback is 4 as it offers a concrete and evidencebased suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task is more closely related to Argument Mining than to Summarization and recommends that the paper clarify the differences between the task and Argument Mining/Discussion Summarization. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the differences and determine how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the task is more closely related to Argument Mining than to Summarization and recommends clarifying the differences between the task and Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in its suggestion to clarify the differences, but without explicit grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task is more closely related to Argument Mining than to Summarization and recommends clarifying the differences between the task and Argument Mining/Discussion Summarization. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the task is more closely related to Argument Mining than to Summarization and recommends clarifying the differences between the task and Argument Mining/Discussion Summarization. This feedback is 3 as it points out a potential area for clarification that could enhance the paper\"s understanding. However, the comment lacks specific guidance on how to address the differences or what aspects of the task should be clarified. While it provides a direction for improvement, it does not offer detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions (2.a and 2.b) regarding the relationship between temperature calibration and uncertainty calibration, and the role of the regularization term H. The reviewer explicitly asks for clarification on the apparent contradiction between the training regularization term requiring temperature calibration and the application of temperature calibration after training. Additionally, the reviewer questions the motivation for calibrating the networks since they are already overconfident. These questions provide clear and direct actions for the authors to take, making the comment 5. The explicit nature of the questions and the specific guidance on what needs clarification make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 155160 and line 133136, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the relationship between temperature calibration and uncertainty calibration, and the role of the regularization term H. The comment further critiques the motivation for calibrating the networks, as they are already overconfident. This level of detail provides clear guidance on what needs to be clarified or addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the relationship between temperature calibration and uncertainty calibration, suggesting that they are independent but appears to be required for uncertainty calibration. The reviewer questions the training regularization term (H) and its role in temperature calibration, as well as the motivation for calibrating the networks since they are already overconfident. While the comment provides some logical reasoning, it lacks specific examples or references to support the claim that the regularization term H requires temperature calibration. This makes the claim 3, as the authors would need to further investigate and clarify the details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two specific questions regarding the relationship between temperature calibration and uncertainty calibration, and the role of the regularization term H. It points out a potential confusion in the paper, where the training regularization term requires temperature calibration, yet temperature calibration is applied after training. This raises a critical issue that the authors need to clarify. Additionally, the comment critiques the motivation for calibrating the networks, as they are already overconfident, which is a significant concern. The feedback is clear and actionable, providing the authors with specific areas to investigate and clarify, making it 5. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the calibration process. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista,\" placing it in an appropriate context. While the comment identifies a specific reference that is missing and suggests that the paper should address this topic, it does not provide explicit instructions on how to incorporate this discussion or what specific aspects of the comparison should be highlighted. The action is implicit and somewhat vague, as the authors know they need to include the reference and discuss the comparison but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific reference that is missing from the paper, namely \"Lista\" by Yann LeCun, which is relevant to the concept of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista,\" placing it in an appropriate context. However, the comment does not specify which part of the paper should address this topic, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically \"Lista\" by Yann LeCun, which is relevant to the concept of unrolling. The reviewer suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista,\" placing it in an appropriate context. However, the comment lacks specific examples or detailed reasoning to support why this reference is crucial or how it relates to the paper\"s content. The mention of \"http://yann.lecun.com/exdb/publis/pdf/gregoricml10.pdf\" provides a link, but without further elaboration, the claim remains somewhat vague. Therefore, the comment is categorized as 2, as it provides a reference but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a missing reference that is crucial to the paper\"s context, specifically mentioning \"Lista\" by Yann LeCun, which is relevant to the concept of unrolling. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista,\" which would help place the paper in an appropriate context. While the comment points out a specific area that needs attention, it lacks detailed guidance on how to incorporate this discussion or what aspects of the comparison should be emphasized. This makes the feedback 3, as it provides a clear direction for improvement but could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain the objective and constraints of the linear program in Theorem 3, which is a direct and clear action. The comment provides a specific request for clarification, making it concrete for the authors to follow. This feedback is actionable as it gives a precise direction on how to improve the draft by enhancing the explanation of a key component. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, explaining the objective and constraints of the linear program in Theorem 3. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 should be explained more intuitively, as it is a main theorem. The reviewer implies that the current explanation may not be sufficient for the reader to understand the objective and constraints. However, the comment does not provide specific examples or detailed reasoning to support why this explanation is necessary or how it would benefit the reader. Without additional context or evidence, the claim is 3, as it highlights a potential area for improvement but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the linear program in Theorem 3 should be explained more intuitively. It highlights the importance of understanding the objective and constraints of the linear program, which is crucial for readers to grasp the main theorem. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensibility of the paper. However, the comment could be more helpful if it offered additional guidance on how to effectively explain these components or provided examples of similar explanations in the literature. Despite this, the comment is 4 as it directs the authors\" attention to a key area that needs clarification, making it a strong suggestion for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined, which provides a clear and direct action for the authors to take. It suggests that the authors should define the FLOT cost matrix to improve the clarity and comprehensibility of their work. This feedback is specific and actionable, as it gives the authors a precise task to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed, making it fully grounded. It also specifies the issue by pointing out that the \"FLOT cost matrix\" is not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"FLOT cost matrix\" in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"FLOT cost matrix\" in Algorithm 1 is not defined. This is a clear and actionable piece of feedback that directs the authors to address a critical omission in their work. By specifying the exact location and the missing definition, the comment provides a clear path for improvement, helping the authors enhance the clarity and completeness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the convergence of the bound in Theorem 2, specifically Eq. (30), as T approaches infinity. It notes that the first term in Eq. (30) converges to 0, but it is unclear whether the second term also converges to 0. The reviewer suggests that the authors prove this, implying that they should address this issue. While the action is implicit, the comment provides a clear direction for the authors to take, which is to prove the convergence of the second term in Eq. (30). However, the comment does not provide specific guidance on how to approach this proof, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27) in Grunewalder et al, 2010,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the convergence of the bound in Eq. (30) as T approaches infinity, and it requests a proof of this convergence. The comment provides a clear direction for the authors to address a specific aspect of their work, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, specifically Eq. (30), as T approaches infinity. It references a similar result from Grunewalder et al, 2010, Eq. (27), which does converge to 0, and notes that while the first term in Eq. (30) converges to 0, it is not trivial to prove that the second term also converges to 0. The reviewer suggests that the authors prove this, implying that the claim is based on logical reasoning and comparison with a known result. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the convergence of the bound in Theorem 2, Eq. (30), as T approaches infinity. It references a similar result from Grunewalder et al, 2010, Eq. (27), which does converge to 0, and notes that while the first term in Eq. (30) converges to 0, it is not trivial to prove that the second term also converges to 0. The reviewer suggests that the authors prove this, providing a clear and actionable direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to approach the proof or provided examples of similar proofs in the literature. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention and offers a constructive suggestion for improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the algorithm\"s clarity and functionality, specifically regarding the possibility of updating one node based on multiple connected nodes and the use of the computed average. The reviewer also questions the definitions of \"j\"\" and \"i\"\"\" in Algorithm 2. While the comment identifies areas of confusion, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are informed that their response will be considered, but the comment itself does not offer actionable steps for improvement. Therefore, the comment is 3, as it highlights areas needing clarification but lacks detailed guidance on how to resolve them.", "grounding_specificity_rationale": "The comment raises questions about the algorithm\"s functionality and clarity, specifically regarding the possibility of updating one node based on multiple connected nodes and the use of the computed average. It also questions the definitions of \"j\"\" and \"i\"\"\" in Algorithm 2. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in nature, as they address the algorithm\"s functionality and clarity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and observations about the algorithm\"s functionality and clarity, rather than making subjective claims or judgments. It does not express an opinion, suggestion, or judgment that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the algorithm\"s functionality and clarity, specifically regarding the possibility of updating one node based on multiple connected nodes and the use of the computed average. It also questions the definitions of \"j\"\" and \"i\"\" in Algorithm 2. While the comment identifies areas of confusion, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights potential weaknesses in the algorithm\"s description, but it lacks actionable advice for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main issues: the unclear definition of the sparsity of the residual term and the lack of evidence supporting the sparsity assumption across various noisy cases. The reviewer suggests that the authors should clarify the definition of sparsity and provide evidence to support their assumptions. While the comment does not explicitly instruct the authors to make these changes, it provides clear guidance on what needs to be addressed. The action is explicit and concrete, as it specifies what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the specific issue of the unclear definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, it implies the need to demonstrate the advantages of the proposed method\"s assumptions compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the sparsity assumption is discussed. The comment is specific in detailing what needs to be clarified or supported, making it weakly grounded but specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a claim about the unclear definition of the sparsity of the residual term and the lack of evidence supporting the sparsity assumption across various noisy cases. The reviewer suggests that the authors should clarify the definition and provide evidence to support their assumptions. However, the comment does not provide specific examples or references to substantiate the claim, making it 3. The authors would need to infer the need for clarification and evidence, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies the need to demonstrate the advantages of the proposed method\"s assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify and substantiate their assumptions, which is crucial for the validity and robustness of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to clarify the term. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the term \"connectivity,\" suggesting that it is misleading because it does not refer to the structural connections between the brain and body. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is wrong with the term \"connectivity,\" but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, noting that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. This feedback is clear and actionable, as it highlights a potential source of confusion for readers. However, the comment could be more helpful if it provided suggestions on how to clarify or rephrase the term to better reflect its intended meaning. Overall, the comment is 3 as it points out a critical issue but lacks depth and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, or writing. However, it does not provide specific guidance on what aspects are missing or how the authors should address these issues. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what specific changes are needed to make the paper more polished and ready for publication. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is not polished and lacks details in related work, experiments, or writing. However, it does not specify which sections or parts of the paper are missing details, making it difficult for the authors to identify the exact areas needing improvement. The comment also lacks specificity regarding what particular details are missing or how they should be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, or writing. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand what aspects are missing or how to address them. The lack of detailed justification or examples renders the claim 1, as it does not offer a clear path for improvement. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, or writing. It directs the authors to a specific section, \"Clarity, Quality, Novelty And Reproducibility,\" which likely contains more detailed feedback. However, the comment does not provide specific suggestions or examples of what aspects are missing or how the authors might improve the paper. Without actionable guidance or detailed feedback, the authors are left with a general idea of what needs to be addressed but without clear direction on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the methodology, suggesting that the step involving the orthogonal matrix weight should be studied to validate its essentialness. It implies that the authors should explore this aspect, but it does not provide specific guidance on how to conduct this study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the issue but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific steps in the methodology, particularly steps 2 and 3, and suggests that the use of orthogonal matrix weights should be studied to validate their essentialness. It implies that the authors should explore this aspect, but it does not explicitly mention which part of the paper these steps are discussed in, making it weakly grounded. However, the comment is specific in detailing what needs to be addressed, namely the study of the orthogonal matrix weight\"s essentialness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of orthogonal matrix weights should be studied to validate their essentialness, implying that the current approach might be insufficient. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. It does not provide enough information for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered 2, as it requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically suggesting that the use of orthogonal matrix weights should be studied to validate their essentialness. It points out that the current approach might be insufficient and implies that the authors should explore this aspect. However, the comment lacks specific guidance or suggestions on how to conduct this study or what specific aspects to focus on. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5 after a certain order, specifically asking whether it is due to overfitting. While the comment implies that the authors should investigate this phenomenon, it does not provide explicit guidance on how to address it or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the cause of the accuracy drop and consider potential solutions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the accuracy drop after a certain order and asks whether it is due to overfitting. This provides clear guidance on what aspect of the figure needs further investigation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the accuracy drop in Figure 5, specifically questioning whether it is due to overfitting. It does not contain any subjective claims, opinions, or suggestions that require verification. The statement is factual and seeks clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically asking whether it is due to overfitting. This question prompts the authors to investigate and clarify the cause of the observed phenomenon. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve their analysis. The feedback is 3 as it highlights an area for further exploration, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the toylike nature of the models and datasets used in the paper. It suggests that the authors should consider using more challenging datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to better reflect the complexity of the tasks. Additionally, the comment questions the feasibility of experimenting on language tasks. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these concerns or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the toylike nature of the models and datasets used in the paper, suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also questions the feasibility of experimenting on language tasks. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the methodology or results sections where these datasets and models are discussed. The comment is specific in its suggestions for improvement, providing clear guidance on what additional experiments or datasets could enhance the paper\"s rigor. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the models and datasets used are too toylike, suggesting that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small should be considered. The reviewer questions the feasibility of experimenting on language tasks. While the comment provides a logical reasoning for the suggestion, it lacks specific references or examples to fully substantiate the claim. The mention of language tasks adds a layer of complexity, but without detailed justification or evidence, the claim remains 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the toylike nature of the models and datasets used in the paper. It suggests that the authors should consider using more challenging datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to better reflect the complexity of the tasks. Additionally, the comment raises a concern about the feasibility of experimenting on language tasks, prompting the authors to consider this aspect. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues, such as recommending specific datasets or providing examples of similar studies. This limits the comment\"s helpfulness, as the authors may need to infer the necessary steps to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of natural ablation studies, specifically mentioning the potential impact of scratchGAN if pretraining is not done. It suggests that this is a crucial baseline to include, especially for the central argument against pretraining. However, the comment does not provide explicit instructions on how to conduct these ablation studies or which specific aspects should be examined. The action is implicit and somewhat vague, as the authors know they need to include these studies but are not given detailed guidance on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of natural ablation studies, specifically mentioning \"scratchGAN\" as an example. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of ablation studies, particularly for the central argument against pretraining. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some natural ablation studies are missing, specifically mentioning \"scratchGAN\" as an example. However, the comment does not provide specific reasoning or evidence to support why these ablation studies are crucial or how they would impact the central argument against pretraining. The lack of detailed justification or references makes it difficult for the authors to understand the significance of the missing studies. Therefore, the claim is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of natural ablation studies, such as the impact of scratchGAN without pretraining. This is a crucial aspect that could strengthen the paper\"s argument against pretraining. However, the comment lacks depth and does not provide specific suggestions on how to conduct these ablation studies or what specific results should be highlighted. While it offers a clear direction for improvement, the feedback could be more helpful if it included detailed guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also mentions that the authors have already addressed this by padding shorter sequences with the last state and notes the lack of a normalization factor of 1/T, which could affect the comparison. The comment provides clear guidance on what needs to be clarified and even suggests that the authors have already made some of these improvements. This level of detail makes the comment 5, as it provides specific actions and reasoning for the authors to follow. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of how comparisons between episodes of different lengths are handled, including the method of padding shorter sequences and the lack of a normalization factor of 1/T. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should clarify how they handle comparisons between episodes of different lengths. It provides specific details about the method used in the code, which is padding the shorter sequence by replicating its last state. Additionally, it notes the lack of a normalization factor of 1/T, which could affect the comparison and favor longer trajectories. The comment is 4 as it provides logical reasoning and specific examples from the code, but it could be strengthened by referencing similar practices or providing more detailed explanation of the implications of the lack of normalization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue in the paper related to the comparison of episodes with different lengths. It provides clear guidance on how the authors should clarify this aspect, noting that the code pads shorter sequences by replicating their last state. Additionally, it highlights the lack of a normalization factor of 1/T, which could affect the comparison and favor longer trajectories. This feedback is actionable and constructive, as it directs the authors to improve the clarity and robustness of their methodology. By addressing these points, the authors can enhance the understanding and reproducibility of their work, making the comment highly valuable for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: first, it notes that the author did not consider Vision Transformer, an important SOTA model in image classification, and questions whether the pruning strategy would be different in self attention layers. While the comment identifies a potential area for improvement by suggesting the inclusion of Vision Transformer, it does not provide explicit guidance on how to incorporate it into the experiment or what specific aspects of the pruning strategy should be considered. The action is implicit and somewhat vague, as the authors are left to infer the need for additional analysis and the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiment section, specifically mentioning the consideration of Vision Transformer, an important SOTA model in image classification. It also questions whether the pruning strategy would be different in self attention layers for larger datasets like ImageNet. While the comment does not explicitly mention a specific part of the paper, the authors can infer that it relates to the experimental section. The comment is specific in identifying the need to consider Vision Transformer and questioning the applicability of the pruning strategy. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the consideration of Vision Transformer in the experiment, suggesting it is an important SOTA model in image classification. However, the comment lacks specific evidence or references to support the claim that Vision Transformer is not considered or that it is unclear for larger datasets like ImageNet. Additionally, the question about the pruning strategy in self attention layers is speculative and does not provide a clear basis for the claim. As a result, the comment is considered 2, as it provides some reasoning but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental section by pointing out that the author did not consider Vision Transformer, an important SOTA model in image classification. It also questions whether the pruning strategy would be different in self attention layers for larger datasets like ImageNet. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or incorporate Vision Transformer into their experiments. The feedback is 3 as it directs the authors to consider an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of comparison against baselines in the functionality similarity comparison study. It points out that the study only reports accuracy across optimization levels of binaries but does not consider baselines. The reviewer suggests that this is a widelyunderstood binary analysis application, with many papers reporting codesearch as a similar task. While the comment identifies a gap in the study, it does not provide explicit guidance on how to address this issue or suggest specific baselines to include. The action is implicit and somewhat vague, as the authors need to infer that they should include baselines and possibly codesearch comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison against baselines in the functionality similarity comparison study, specifically mentioning the absence of baselines in the report. It also notes that the study only reports accuracy across optimization levels of binaries. The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies what is missing\u2014comparison against baselines and mentions the need for codesearch comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the functionality similarity comparison study lacks comparison against baselines, specifically mentioning the absence of baselines in the report. It references the widelyunderstood nature of binary analysis and the common practice of reporting codesearch as a similar task. This provides a logical reasoning and reference to common practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples of baselines or codesearch comparisons that are commonly used, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries but does not consider baselines, which is a widelyunderstood binary analysis application. The comment suggests that many papers have developed architectureagnostic similarity comparison or codesearch, which are similar tasks. This feedback is clear and actionable, as it directs the authors to include baselines and possibly codesearch comparisons in their study to strengthen their analysis. However, the comment could be more helpful if it provided specific examples of baselines or codesearch comparisons that are commonly used in the field. Overall, the comment is 4, as it effectively guides the authors to improve their draft by addressing a critical gap in their analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention in SI 6.5 that, despite the preprocessing being identical to that in Mnih et al. 7, the evaluation is slightly different because no human starts are used. This is a clear and direct action for the authors to take, providing specific guidance on what needs to be included in the section. The comment is explicit and concrete, leaving no ambiguity about what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of the evaluation difference due to the absence of human starts, despite the preprocessing being identical to that in Mnih et al. 7. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the authors should mention a specific difference in the evaluation process, despite the preprocessing being identical to that in Mnih et al. 7. This claim is 3 as it provides a clear reason for the mention, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the evaluation difference, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement. It points out a potential oversight in the evaluation process, noting that despite the preprocessing being identical to that in Mnih et al. 7, the evaluation is slightly different because no human starts are used. This feedback is clear and directs the authors to a specific area where they need to make an adjustment to enhance the transparency and accuracy of their evaluation. By addressing this point, the authors can improve the clarity and robustness of their work. Therefore, the comment is 4, as it offers a clear and actionable piece of feedback that can significantly enhance the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the figures, including their difficulty in parsing, small text, lack of clear explanation of inputs and outputs for each task, and nonselfcontained captions that make it hard to link them to parts of the main text. While the comment identifies these problems, it does not provide explicit guidance on how to address them or suggest specific actions for the authors to take. The authors are left to infer that they need to improve the clarity and explanation of the figures, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the difficulty in parsing, small text, lack of clear explanation of inputs and outputs for each task, and nonselfcontained captions. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Fig.1 to Fig.3 are very difficult to parse,\" \"the texts in the figures are too small,\" and \"the inputs and outputs for each task are not clearly explained.\" These claims are supported by specific observations about the figures, such as the difficulty in parsing and the small text size. However, the comment does not provide further justification or examples of how these issues impact the understanding of the figures. While the claims are 3, they could be strengthened with additional context or references to support the assertions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the figures, including their difficulty in parsing, small text, lack of clear explanation of inputs and outputs for each task, and nonselfcontained captions. These observations are specific and actionable, providing the authors with clear feedback on areas that need improvement. By addressing these issues, the authors can enhance the clarity and comprehensibility of their figures, making them more effective in conveying the information. However, the comment could be more helpful if it offered suggestions on how to improve the figures, such as recommending specific design changes or clarifications. Overall, the feedback is 4 as it highlights critical areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the authors discuss the advantages of their proposed method in terms of efficiency but do not provide any metrics to support this claim. While it highlights a gap in the paper, it does not explicitly instruct the authors to include specific metrics or suggest which metrics to use. The action is implicit, as the authors can infer that they need to add metrics to demonstrate efficiency, but the comment lacks concrete guidance on which metrics to include or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of advantages over previous work in terms of efficiency, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of metrics that demonstrate the efficiency of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metrics showing the efficiency of the proposed method compared to previous work. However, it lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The comment is 3 as it identifies a gap in the paper, but it does not provide enough detail or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that while the authors discuss the advantages of their proposed method in terms of efficiency, there is no reported metric to demonstrate this efficiency. This feedback is clear and actionable, as it prompts the authors to include specific metrics or data to substantiate their claims about efficiency. By addressing this feedback, the authors can significantly improve the clarity and evidence supporting their claims, making the comment 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern that the contribution of the paper is not sufficient, specifically regarding the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the contribution or what specific improvements could be made. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s contribution, specifically mentioning the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of overfitting and the proposed differentiable augmentation, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the paper is insufficient, specifically regarding the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general critique but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a perceived weakness in the paper, specifically the lack of sufficient contribution regarding the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. While it highlights an important factor, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their contribution. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it less valuable for the authors to use effectively. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks for more details about the statespace, whether it is finite or continuous, the actions, and the space in which theta lies. This direct request provides clear guidance for the authors, specifying exactly what additional information is needed to improve the draft. The comment is specific and actionable, as it clearly identifies the areas where more detail is required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the details about the statespace (finite or continuous), actions, and the space in which theta lies. This provides clear guidance on what additional information is needed to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the statespace, actions, and the space in which theta lies. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback by asking for more details about the statespace, whether it is finite or continuous, the actions, and the space in which theta lies. This direct request for additional information helps the authors clarify and improve their draft by ensuring that the assumptions and details are welldefined. The comment is clear and constructive, offering a clear path for the authors to enhance their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the method\"s performance on general reasoning tasks. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique about the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this critique pertains to, such as specific sections, experiments, or results. Without explicit references to the paper\"s content, the authors cannot confidently determine where the issue lies or how to address it. Additionally, the comment lacks specificity regarding what aspects of the method\"s performance are being questioned or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation of the method, specifically its effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the method\"s performance. Without actionable feedback or detailed insights, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the inapplicability of results from Theorem 1 when normalizing the input. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their proof technique. The action is implicit and vague, as it does not specify what changes are needed or how to resolve the identified problem. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, and it acknowledges this by mentioning the inapplicability of results from Theorem 1 when normalizing the input. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity. It references Section 3, where the authors acknowledge the inapplicability of results from Theorem 1 when normalizing the input. This provides a logical basis for the claim, as it connects the proof technique to the discussion in Section 3. However, the comment could be strengthened by providing more detailed reasoning or examples of how this special case affects the proof. Overall, the claim is 4, as it is supported by logical reasoning and references to the paper, but it could benefit from additional evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also references Section 3, where the authors acknowledge the inapplicability of results from Theorem 1 when normalizing the input. This feedback is 3 as it highlights a potential weakness in the proof technique and directs the authors to a relevant discussion in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative approaches to improve the proof technique. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, specifically for conditional generation tasks. It acknowledges that GDSS does not explicitly present a conditional framework but mentions a recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. The comment provides a clear and explicit action for the authors to take, which is to include this baseline comparison in Table 3. Additionally, it offers concrete guidance on how to implement this suggestion by referencing a specific recent work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3 for conditional generation tasks. Additionally, it provides context by mentioning that GDSS does not explicitly present a conditional framework but references a recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3 for conditional generation tasks, despite not explicitly presenting a conditional framework. The comment references a recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. This provides a logical reasoning and a specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed explanation or examples of how GDSS could be adapted for conditional generation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that the continuous diffusion model (e.g., GDSS) be compared as a baseline in Table 3, specifically for conditional generation tasks. It acknowledges that GDSS does not explicitly present a conditional framework but references a recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. This feedback is valuable as it guides the authors to include a relevant baseline comparison, which can enhance the paper\"s comprehensiveness and provide a basis for comparison with other models. However, the comment could be more helpful if it provided additional context or explanation on why this comparison is important or how it would impact the paper\"s conclusions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. It also critiques the use of colorizationbased pretraining, arguing that it primarily learns semantics rather than accurate locations and poses, which are crucial for object detection tasks using metrics like IoU, as seen in benchmarks like KITTI and Waymo. While the comment provides some direction for improvement, it lacks explicit instructions on how to implement these changes or what specific aspects of the current approach should be revised. The authors are left to infer that they should consider these alternatives and improvements, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation instead of object detection as the downstream task. It also critiques the use of colorizationbased pretraining, arguing that it primarily learns semantics rather than accurate locations and poses, which are crucial for object detection tasks using metrics like IoU, as seen in benchmarks like KITTI and Waymo. However, the comment does not specify which part of the paper discusses these tasks or where the authors should make these changes. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the choice of tasks and the effectiveness of the pretraining approach, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice than object detection for the downstream task and critiques the use of colorizationbased pretraining, arguing that it primarily learns semantics rather than accurate locations and poses. The comment provides a logical reasoning for the choice of tasks and the effectiveness of pretraining, but it lacks specific references or examples to fully substantiate the claims. This makes the comment 3, as the authors would need to further explore and verify the reasoning themselves.", "helpfulness_rationale": "The review comment provides a thoughtful critique of the choice of downstream tasks and the effectiveness of the pretraining approach. It suggests that LiDARbased segmentation might be a better choice than object detection, which is a valuable insight for the authors to consider. Additionally, it critiques the use of colorizationbased pretraining, arguing that it primarily focuses on semantics rather than accurate locations and poses, which are crucial for object detection tasks using metrics like IoU, as seen in benchmarks like KITTI and Waymo. This feedback is clear and actionable, offering specific areas for improvement and providing a rationale for why these changes might be beneficial. However, the comment could be more helpful if it provided suggestions on how to implement these changes or further elaborated on the reasoning. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Eq (12) and the IPO (Institute of Pure and Applied Mathematics) theory. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this contradiction or what changes could be made to resolve it. Without specific suggestions or steps, the authors are left without a clear understanding of what actions to pursue to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Eq (12)\" and mentions the \"IPO\" theory, which suggests that it is addressing a specific part of the paper related to the theoretical framework or proofs. However, it does not explicitly mention which section or part of the paper this refers to, making it weakly grounded. The comment is specific in identifying a potential contradiction between the objective of Eq (12) and the IPO theory, providing a clear point for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a contradiction between the objective of Eq (12) and the IPO (Institute of Pure and Applied Mathematics) theory. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Eq (12) and the IPO (Institute of Pure and Applied Mathematics) theory. This observation highlights a gap in the theoretical framework that the authors need to address. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might resolve this contradiction or improve their theoretical framework. Without actionable advice or examples, the authors are left with a general idea of the issue but without a clear path to improvement. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also mentions that allowing \"t\" to be arbitrary does not add value. This feedback provides a clear and explicit action for the authors to take, specifying what change should be made to improve the clarity of the text. The suggestion is concrete, as it outlines exactly what needs to be done to enhance the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting replacing \"t\" with the size of T for clarity and noting that allowing \"t\" to be arbitrary does not add value. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a specific change to improve the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. This is a suggestion for improvement rather than a claim, as it does not express an opinion or judgment about the paper\"s content. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by recommending replacing \"t\" with the size of T. This feedback is actionable and offers a clear direction for enhancing the draft, making it 4. However, it could be more comprehensive if it included additional suggestions or explanations on why this change is beneficial. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. It acknowledges that DINO representations are observed to contain rich geometric information, which may alleviate concerns for geometrically distinctive concepts. However, it raises a question about the adaptation capacity for concepts where class labels correlate more with semantics rather than geometry. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore or validate the adaptation capacity for such concepts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. It provides a specific example of DINO representations, which are observed to contain rich geometric information, and raises a concern about concepts where class labels correlate more with semantics rather than geometry. This provides a clear and specific focus on the issue, allowing the authors to identify the part of the paper being addressed. However, the comment does not explicitly mention which section or figure this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the adaptation capacity for certain concepts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. The reviewer provides a rationale by noting that DINO representations are observed to contain rich geometric information, which may alleviate concerns for geometrically distinctive concepts. However, the comment does not provide specific examples or references to support the claim that DINO representations are effective for such concepts. This lack of detailed evidence or examples makes the claim 3, as the authors would need to further explore and substantiate the concern themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. It acknowledges that DINO representations are observed to contain rich geometric information, which may alleviate concerns for geometrically distinctive concepts. However, it raises a question about the adaptation capacity for concepts where class labels correlate more with semantics rather than geometry. This feedback is 3 as it identifies a potential limitation in the proposed method and prompts the authors to consider the robustness of their approach. However, it lacks specific suggestions or guidance on how the authors might address this concern or improve the adaptation capacity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison of their method against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is an explicit action, as it clearly states what the authors need to do to improve their draft. The comment also provides concrete details on which loss functions should be included, making it 5. The authors know exactly what needs to be added to their paper to address this feedback effectively.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, making it weakly grounded. The comment is specific in suggesting which loss functions to include, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides specific examples of loss functions that are relevant to the field of biometric verification. However, the comment lacks detailed reasoning or references to justify why these particular loss functions are important or how they would enhance the paper\"s contribution. The authors would need to further explore these loss functions to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by incorporating relevant comparisons. By addressing this suggestion, the authors can strengthen their paper\"s contribution and demonstrate its relevance to the field of biometric verification. However, the comment could be more helpful if it explained why these loss functions are particularly important or how they would impact the paper\"s results. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take, such as correcting technical terms, fixing word repetition, and ensuring consistency in numerical values. Each line mentioned in the comment specifies a clear and concrete action that the authors can perform to improve their draft. The comment also highlights potential issues with the formatting and consistency of the document, offering specific guidance on how to address them. This level of detail and specificity makes the comment 5, as it provides clear instructions on how to enhance the quality of the paper.", "grounding_specificity_rationale": "The comment provides specific line numbers and references to the paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as correcting technical terms, fixing word repetition, and ensuring consistency in numerical values. Additionally, it highlights potential formatting and consistency issues, such as the repetition of words and the same DOI number appearing in multiple places. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections and suggestions for improving the draft, such as correcting technical terms, fixing word repetition, and ensuring consistency in numerical values. These are factual observations and requests for clarification, not claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper, including correcting technical terms, fixing word repetition, and ensuring consistency in numerical values. It also highlights potential formatting and consistency issues, such as the repetition of words and the same DOI number appearing in multiple places. By addressing these points, the authors can significantly improve the clarity and professionalism of their draft. The detailed nature of the feedback makes it 5, as it offers clear guidance on how to enhance the quality of the paper. Therefore, the comment deserves a score of 5, indicating that it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests that the notation M and N should be defined, which is a clear and direct request for clarification. Additionally, it recommends spelling out F.L.T.R in Figure 4 and notes that the text in Figure 1 is too small to see, suggesting that it should be larger. The comment also advises crossreferencing notation and figures, which is another concrete suggestion for improvement. Each of these suggestions is specific and provides clear guidance on how the authors can enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses multiple issues related to the paper, including notation confusion, the size of text in Figure 1, and the need for crossreferencing notation and figures. It explicitly mentions \"M and N\" and \"Figure 4,\" providing full grounding by allowing the authors to identify the specific parts of the paper being addressed. The comment is also specific as it details what needs to be addressed, such as defining notation, improving the visibility of text, and crossreferencing elements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims regarding the clarity and presentation of the paper. The first claim is that the notation M and N is confusing, which is a subjective opinion. The second claim suggests that the text in Figure 1 is too small to see, which is a factual observation. The third claim recommends crossreferencing notation and figures, which is a suggestion for improvement. While the first claim is subjective, the other claims are factual and do not require verification. Therefore, the comment is categorized as \"2,\" as it contains a mix of claims and factual statements.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the clarity and presentation of the paper. It identifies that the notation M and N is confusing and suggests defining them, which is a clear and direct request for clarification. Additionally, it points out that the text in Figure 1 is too small to see, recommending that it be larger. The comment also advises crossreferencing notation and figures, which is another constructive suggestion for enhancing the draft. These specific and actionable feedback provides the authors with clear guidance on how to improve their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential confusion in the notation used in Algorithm1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the notation, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation used in Algorithm1, pointing out the potential confusion between the phase mixing probability and the dummy variable in the inner loop of Phase 2. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2 in Algorithm1 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in Algorithm1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This is a clear and actionable piece of feedback that can help the authors improve the clarity and readability of their work. By addressing this notation issue, the authors can enhance the understanding of their methodology, making the paper more accessible to readers. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or alternative notations that could be used. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several explicit actions for the authors to take. It suggests adding a more detailed mathematical formulation in the appendix to complement the highlevel description, which would help readers understand the approach better. Additionally, the comment highlights issues with the figure, suggesting that it is too abstract and could benefit from more text labels. It also recommends reworking the figure to depict the WiC task, which would align it better with the paper\"s main contribution. These suggestions are clear and provide concrete steps for the authors to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description,\" \"appendix,\" and \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be improved, such as adding a mathematical formulation in the appendix, suggesting more text labels for the figure, and reworking the figure to depict the WiC task. This level of detail provides clear guidance on how to enhance the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description provides an intuitive understanding of the approach but lacks a more detailed mathematical formulation, which could be beneficial. It also critiques the figure, noting that it is too abstract and could be improved with more text labels. Additionally, the reviewer questions the alignment of the figure with the main contribution of the paper, specifically the improvements on the WiC task, and suggests reworking the figure to better depict this task. While the comment provides some logical reasoning and suggestions for improvement, it lacks specific examples or references to support the claims about the figure\"s abstractness or misalignment with the task. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It highlights the need for a more detailed mathematical formulation in the appendix to complement the highlevel description, which would enhance the reader\"s understanding of the approach. Additionally, the comment critiques the figure, suggesting that it is too abstract and could be improved with more text labels. It also questions the alignment of the figure with the main contribution of the paper, specifically the improvements on the WiC task, and suggests reworking the figure to better depict this task. These suggestions are clear and provide the authors with specific directions for enhancing their draft, making the comment 5. However, the comment could be more helpful if it included examples of how to improve the figure or suggested specific ways to present the mathematical formulation. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include additional benchmarking tasks outside of AitW, implying that this would be beneficial. However, the comment does not specify which tasks should be included or how they should be integrated into the paper. The action is implicit, as the authors can infer that they need to add more benchmarking tasks, but it is vague because it lacks concrete details on what specific tasks to include or how to implement them. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include more benchmarking tasks, but without clear grounding, the authors may struggle to identify the exact section where this addition should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any specific reasoning or evidence to support why these tasks would be beneficial or how they would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which tasks should be included or how they might enhance the paper. The comment offers a general direction for improvement but does not offer actionable advice or examples, making it 3. The authors would gain some insight into the need for more benchmarking tasks but may struggle to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the experiments section. It asks for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iteration wise convergence, and whether there is a comparison to an explanation that can analyze the difference in performance between YOSO and linformer on downstream tasks like SST2. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions and requests for clarification, such as the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iteration wise convergence, and the need for a comparison to an explanation that can analyze the difference in performance between YOSO and linformer on downstream tasks like SST2. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the experiments section, specifically about the comparison between YOSO and linformer. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely descriptive. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved. It points out that the pretraining experiment part does not provide steps vs ppl of linformer with YOSO in Figure 4, which is a critical piece of information for understanding the comparison. Additionally, it questions the comparison result of YOSO with linformer on iteration wise convergence and asks for an explanation of the performance difference in downstream tasks like SST2. This feedback is clear and actionable, as it directs the authors to provide additional details and comparisons that would enhance the comprehensiveness and clarity of their experiments. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or what specific analyses might be useful. Overall, the comment is 4 as it effectively guides the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. The reviewer explicitly states that this is not true, as the authors clarify in the text. However, the comment does not provide any guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending a correction or explaining the impact of this discrepancy. As a result, the authors are left without a clear understanding of what steps to take to resolve this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, stating that the requirement of the proposal distribution to upper bound the target everywhere is not true, as the authors clarify in the text. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract incorrectly states that the proposal distribution must upper bound the target everywhere, which is not true as clarified in the text. However, the comment does not provide specific examples or references to the text where this discrepancy is mentioned, making it difficult for the authors to verify the claim. The lack of detailed evidence or references makes the claim 2, as it requires the authors to infer the specific parts of the text that need to be corrected. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. It points out that this statement in the abstract is not accurate, as clarified in the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the accuracy of their abstract. Without actionable feedback or specific advice, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion in the reference to \"PointNet\" in Figure 1, noting that the name does not appear in the paper and that another paper with the same name exists. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the reference, but without concrete instructions on how to do so, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet,\" pointing out that the name does not appear in the paper and that another paper with the same name exists. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to \"PointNet\" in Figure 1 is confusing because the name does not appear in the paper and another paper with the same name exists. The reviewer provides a specific reference to \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al., which supports the claim. This detailed reference justifies the critique, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear in the paper and that another paper with the same name exists. By providing a direct reference to the relevant paper, the comment offers a clear and actionable suggestion for clarification. This feedback is valuable as it helps the authors avoid confusion and ensure that their work is properly contextualized. However, the comment could be more helpful if it suggested how to address the issue beyond just clarifying the reference. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the policy gradient in Equation 6 solves the optimal problem and whether the optimal solution to Equation 5 is obtained after convergence. This question implies that the authors should clarify this aspect in their paper. Additionally, the comment points out a minor line number issue with \"on learning  on\" and corrects it to \"on learning\". While the first part of the comment suggests a specific action to clarify, the second part is a factual correction without any implied action. The comment is 3 as it provides a clear question for clarification but lacks concrete guidance on how to address the issue of the policy gradient solving the optimal problem.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 6\" and \"Line 78,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the policy gradient in Eq. 6 solves the optimal problem and whether the optimal solution to Eq. 5 is obtained after convergence. Additionally, it points out a minor line number issue with \"on learning  on\" and corrects it to \"on learning.\" This provides clear guidance on what needs to be clarified or corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a question about the policy gradient in Equation 6 and a minor line correction. The first part is a question seeking clarification, which does not contain a subjective claim or opinion. The second part is a factual correction, \"on learning  on,\" which is a straightforward observation. Since the comment does not contain any claims, opinions, or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Equation 6, specifically whether it solves the optimal problem and whether the optimal solution to Equation 5 is obtained after convergence. This question prompts the authors to clarify an important aspect of their methodology, which could significantly impact the interpretation of their results. Additionally, the comment points out a minor line number issue with \"on learning  on\" and corrects it to \"on learning,\" which is a straightforward correction. While the comment identifies a potential area for clarification, it could be more helpful by providing suggestions on how to address the question about the policy gradient. Overall, the comment is 3 as it provides some insight but lacks depth and actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the assumption of the general Gaussian distribution versus the isotropic Gaussian in the proposed algorithm. While it poses a question, it does not explicitly instruct the authors to make a change or provide guidance on how to address the issue. The action is implicit, as the authors can infer that they need to consider the implications of their assumption, but it lacks concrete details on how to implement this consideration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of the general Gaussian distribution versus the isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This makes it difficult for the authors to pinpoint the exact location in the paper where this issue is discussed. While the question is specific about the type of distribution assumption, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of the general Gaussian distribution versus the isotropic Gaussian in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of the general Gaussian distribution versus the isotropic Gaussian in the proposed algorithm. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the distribution assumption are important. The comment lacks actionable feedback, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the decision to freeze the partitioning in the first iteration is a risky choice and implies that it makes strong assumptions about the coverage of the initial data. It advises the authors to discuss the limitations of this choice. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to discuss the limitations or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the limitations of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the \"risky choice\" of freezing the partitioning in the first iteration and suggests discussing the limitations of this choice. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of freezing the partitioning in the first iteration, suggesting that it makes strong assumptions about the coverage of the initial data. However, the comment does not provide specific reasoning or examples to support why this choice is risky or what potential limitations it might have. Without detailed justification or references, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the choice of freezing the partitioning in the first iteration, questioning its riskiness and the assumptions it makes about the coverage of the initial data. It suggests that the authors discuss the limitations of this choice, which is a valuable piece of feedback. By pointing out this potential issue, the comment provides the authors with a clear direction for improving their draft, specifically by addressing the limitations of their approach. However, the comment could be more helpful if it offered additional guidance on how to discuss these limitations or provided examples of potential issues. Overall, the feedback is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration and clarification."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how it might impact their draft. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. However, it lacks specificity because it does not provide any details on what the intent of this section is or how it could be improved. The comment simply asks for clarification without offering guidance on what needs to be addressed. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment raises a question about the intent of Section 5.2, which could be a source of confusion for the authors. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the clarity of the section. Without actionable feedback or detailed insights, the comment lacks value and does not assist the authors in making improvements to their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that many aspects of the approach need clarification and questions the authors about the interaction between knowledge about objects and verbs in overcoming reporting bias. It also notes that the paper moves quickly into technical details without clearly explaining the overall approach or its benefits. However, the comment does not provide explicit guidance on what specific aspects need clarification or how the authors should address the questions raised. The feedback is somewhat vague and lacks concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on various aspects of the approach, including the interaction between knowledge about objects and verbs in overcoming reporting bias. It also notes that the paper moves quickly into highly technical details without clearly explaining the overall approach or its benefits. This provides the authors with a clear understanding of the specific areas that need attention. However, the comment lacks specificity regarding which particular aspects or details need clarification, such as specific sections or examples that are unclear. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the lack of explanation regarding how the method addresses reporting bias. It questions the authors\" understanding of the interaction between knowledge about objects and verbs. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims, making it difficult for the authors to address the feedback effectively. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the issues without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area of confusion regarding the approach, specifically the interaction between knowledge about objects and verbs in overcoming reporting bias. It highlights the need for clearer explanations and a more comprehensive overview of the overall approach, which is currently presented in a highly technical manner. While the comment points out a significant weakness in the paper\"s clarity, it lacks specific suggestions or guidance on how the authors might address these issues. This limits the comment\"s helpfulness, as it provides insight into a problem but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain the decision to use early stopping based on link prediction accuracy, suggesting that it should be compared with average type accuracy. This provides a clear and direct action for the authors to take, specifying what needs to be clarified in the paper. The comment is explicit and concrete, giving the authors a precise direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the decision to use early stopping based on link prediction accuracy and the suggestion to compare it with average type accuracy. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the decision to use early stopping based on link prediction accuracy should be explained, specifically mentioning the need to compare it with average type accuracy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the decision to use early stopping based on link prediction accuracy should be explained. It provides a clear rationale for this suggestion by asking why average type accuracy should not be considered instead. This feedback is actionable and prompts the authors to clarify an important aspect of their methodology, which could enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to explain the decision or provided examples of how to present the comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about how to set a reasonable classimbalanced task in the context of fewshot learning, where each class has only a few examples. It explicitly asks the authors to explain this with concrete details, providing a clear and direct action for them to take. The comment is specific in its request for detailed explanation, making it 5. The authors know exactly what they need to address and how to do so, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how to set a reasonable classimbalanced task in the context of fewshot learning, where each class has only a few examples. The comment further requests a concrete explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrasing \"sampling classimbalanced tasks\" and asks for an explanation of how to set a reasonable classimbalanced task in the context of fewshot learning. This is a request for clarification and does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrasing \"sampling classimbalanced tasks\" and seeks clarification on how to set a reasonable classimbalanced task in the context of fewshot learning, where each class has only a few examples. This feedback is 3 as it identifies a potential issue with the phrasing and prompts the authors to provide a more precise explanation. However, it lacks depth and does not offer specific suggestions or guidance on how to address the issue, which limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the ChatGPT baseline is rudimentary and that fewshot approaches are not tested. It also recommends including discourse relation information in the prompts, possibly using a ChainofThought style, which could enhance the paper\"s evaluation. However, the comment does not provide explicit guidance on how to implement these suggestions or which specific aspects of the evaluation should be expanded. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the ChatGPT baseline, suggesting that it is rudimentary and that fewshot approaches are not tested. It also recommends including discourse relation information in the prompts, possibly using a ChainofThought style, which could enhance the paper\"s evaluation. However, the comment does not specify which part of the paper discusses the ChatGPT baseline or where the evaluation is conducted, making it weakly grounded. The suggestion to include discourse relation information is specific, but the lack of grounding makes the comment 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the ChatGPT baseline is rudimentary and that fewshot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a ChainofThought style, could yield good results and enhance the paper\"s evaluation. However, the comment lacks specific examples or references to support the claim that the current approach is rudimentary or that the suggested method would yield good results. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a limitation in the ChatGPT baseline, noting that it is rudimentary and that fewshot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a ChainofThought style, could enhance the paper\"s evaluation. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to implement this suggestion. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with detailed instructions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of explanation regarding how the ground truth of sensitivity is achieved, specifically noting that lines 238239 only mention \"we first estimate a layer\"s sensitivity by pruning\" without detailing the actual pruning process. The reviewer implies that the authors should provide more information to clarify this aspect. While the action is implicit, it is concrete because it specifies what needs to be addressed\u2014providing details on the pruning process. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation on how the ground truth of sensitivity is achieved, particularly regarding the pruning process. The comment requests additional details on the pruning method used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically mentioning lines 238239 where only a general statement is made without detailed explanation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this lack of explanation is problematic or how it affects the paper\"s validity. Without additional context or examples, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the explanation of how the ground truth of sensitivity is achieved. It points out that lines 238239 only mention \"we first estimate a layer\"s sensitivity by pruning\" without providing details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more detailed information to enhance the clarity and comprehensibility of their methodology. However, the comment could be more helpful if it offered suggestions on how to present the pruning process or provided examples of similar methods. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides specific questions that the authors should address to improve the clarity of their text. It explicitly asks for an explanation of what a proper rotation matrix is, as mentioned in line 97, and what is meant in lines 105106 regarding the matrix being nonpositive semidefinite. These questions are clear and direct, giving the authors a clear understanding of what needs to be clarified or expanded upon. The feedback is explicit and provides concrete guidance on how to enhance the clarity of the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (97, 105106) in the paper, allowing the authors to accurately identify the parts of the text that need clarification. It is also specific because it clearly specifies what needs to be clarified: the definition of a proper rotation matrix and the meaning of the matrix being nonpositive semidefinite. This provides clear guidance on what aspects of the text require further explanation or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the text, such as the definition of a proper rotation matrix and the meaning of a matrix being nonpositive semidefinite. These are factual inquiries that do not contain subjective claims, opinions, or suggestions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be improved in terms of clarity and provides concrete questions to address these issues. By asking for an explicit explanation of what a proper rotation matrix is and what is meant by the matrix being nonpositive semidefinite, the comment provides clear and actionable feedback that can help the authors enhance the clarity and precision of their writing. This level of detail and specificity makes the comment 5, as it guides the authors in making significant improvements to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider replacing the activation function with a binary operator, similar to the approach taken by Cohen and Shashua in 2016. This feedback provides a specific action for the authors to consider, namely, changing the terminology or approach used in the paper. However, it does not provide detailed guidance on how to implement this change or what specific aspects of the current approach should be replaced. The action is explicit but somewhat vague, as it lacks concrete instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the activation function could be replaced with a binary operator, similar to the approach taken by Cohen and Shashua in 2016. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider replacing the activation function with a binary operator, similar to the approach taken by Cohen and Shashua in 2016. The comment references this work, providing a specific example of a similar approach, which supports the claim. However, the comment could be strengthened by explaining why this change is beneficial or how it aligns with the paper\"s objectives. Overall, the claim is 4 due to the reference to an external work, but it could be more robust with additional explanation or context.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors consider replacing the activation function with a binary operator, similar to the approach taken by Cohen and Shashua in 2016. This feedback is actionable and offers a concrete direction for enhancing the paper\"s methodology or analysis. By referencing a relevant work, the comment also provides context and justification for the suggestion, making it more valuable to the authors. However, the comment could be more helpful if it included additional reasoning or examples of how this change might impact the results or conclusions. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to consider shrinking the captions of Figure 1 and Figure 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their paper. The comment provides specific guidance on how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to consider shrinking the captions to leave more space for the methods or related work. This guidance is actionable and provides a concrete step for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Figure 1 and Figure 2 overlap with the content, and recommends shrinking the captions to provide more space for the methods or related work. While the comment identifies a potential issue with the layout, it does not provide specific examples or detailed reasoning to support why the overlap is problematic or how shrinking the captions would resolve the issue. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figure 1 and Figure 2, noting that they overlap with the content. It provides a clear and actionable suggestion to consider shrinking the captions to leave more space for the methods or related work. This feedback is valuable as it offers a straightforward way to improve the visual presentation of the paper, making it easier for readers to understand and follow the content. However, the comment could be more helpful if it included additional suggestions on how to effectively utilize the space or examples of how to rephrase the captions. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size variation. The reviewer questions why this dataset is not used as a potential benchmark for evaluating the role of context in detecting hate. While the comment implies that the authors should consider including this dataset, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the dataset and explain why it is relevant. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the work despite the size variation. The comment further questions why this dataset is not used as a potential benchmark for evaluating the role of context in detecting hate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the work despite the size variation. The comment implies that this dataset could be a potential benchmark for evaluating the role of context in detecting hate. However, the comment lacks specific reasoning or evidence to support why Vidgen et al., 2021, should or should not be included as a benchmark. Without detailed justification or references, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the work despite the size variation. The reviewer questions why this dataset is not used as a potential benchmark for evaluating the role of context in detecting hate. This feedback is 3 as it prompts the authors to consider the relevance and utility of including this dataset in their analysis. However, the comment could be more actionable by providing specific guidance on how to incorporate this dataset or explaining why it is not currently used. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs, preferably with errorbars. It also points out that the plotted curves are from single runs, which might lead to significant fluctuations, and notes that the models are small, making it unreasonable to not provide statistics. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers specific guidance on how to enhance the presentation of their results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the presentation of results as a mean over many runs with errorbars, and highlights the issue with the plotted curves being from single runs. The comment also emphasizes the importance of providing statistics due to the small size of the models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs with errorbars. The reviewer supports this claim by noting that the plotted curves are from single runs, which might lead to significant fluctuations. This reasoning is logical and provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the impact of single runs. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the presentation of results in the paper. It highlights the need to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs, preferably with errorbars. This is important because the current presentation is based on single runs, which might lead to significant fluctuations and misinterpretation of the results. The comment also emphasizes the importance of providing statistics due to the small size of the models, which is a valid concern. By addressing these points, the authors can significantly improve the clarity and reliability of their results. The feedback is clear, specific, and constructive, making it 5 for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM, implying that it still requires careful selection of basis functions and meshes, and assembling stiffness matrices. It also mentions that while current operator learning methods cannot yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not need to be adapted to specific PDEs. However, the comment does not provide explicit guidance or suggestions on how the authors could improve their approach or address these observations. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It mentions the reliance on basis functions, meshes, and assembling stiffness matrices, particularly in the context of FEniCS. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in its critique, it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. The reviewer mentions the reliance on basis functions, meshes, and assembling stiffness matrices, particularly in the context of FEniCS. The comment also notes that while current operator learning methods cannot yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not need to be adapted to specific PDEs. This critique is supported by logical reasoning and references to the nature of operator learning methods and their limitations compared to specialized numerical solvers. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of operator learning methods. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a critical perspective on the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the reliance on basis functions, meshes, and assembling stiffness matrices, particularly in the context of FEniCS. The comment also notes that while current operator learning methods cannot yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not need to be adapted to specific PDEs. This feedback is 3 as it identifies a potential limitation of the proposed approach and suggests areas for improvement. However, it lacks specific suggestions or actionable guidance on how the authors might address these concerns or enhance their work. Therefore, the comment provides some insight but does not fully support the authors in making significant improvements to their draft, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed description of the experimental environment, specifically mentioning the CUDA and PyTorch versions used. This direct request gives the authors a clear action to take, which is to include this information in their draft. The comment also explains the importance of this detail, as different versions can impact training and inference speeds. The action is concrete and explicit, providing the authors with a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed description of the experimental environment, specifically mentioning the CUDA and PyTorch versions used. This is a specific request for additional information that can enhance the clarity and reproducibility of the paper. However, the comment does not explicitly mention which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the experimental setup, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed description of the experimental environment, specifically mentioning the CUDA and PyTorch versions used. This claim is 3 as it highlights a potential area for improvement in the paper. However, the comment lacks specific examples or references to support why these details are important or how they might impact the results. The authors would need to infer the importance of this information themselves, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions used. This is important because different versions of the experimental environment can impact training and inference speeds, which are crucial factors in evaluating the performance of the model. By addressing this feedback, the authors can enhance the clarity and reproducibility of their results, making the paper more robust and transparent. The comment is specific and provides a direct path for improvement, making it 5 for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the difficulty of controlling multiple aspects of variation with precision using fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work in this regard. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the difficulty of controlling multiple aspects of variation with precision using fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, it does not specify which part of the paper this issue is discussed in, nor does it provide specific details on what aspects of variation are challenging to control. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the difficulty of controlling multiple aspects of variation with precision using fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, the comment does not provide any specific reasoning or evidence to support the claim that fully realistic datasets are challenging to control. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the difficulty of controlling multiple aspects of variation with precision using fully realistic datasets and agrees with the authors\" judgment regarding the lack of immediate societal impact. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback, leaving the authors without a clear path forward for enhancing their draft. Therefore, it is rated as 2, as it identifies a potential limitation but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paragraph is difficult to understand, despite the reviewer having some knowledge of the content. It suggests that the authors should clarify the paragraph by specifying which bandit algorithms are being discussed and provide a more detailed explanation of the figure. The comment also points out that the description of the dashed lines is vague. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes. The authors can infer that they need to clarify the paragraph and provide a more concrete explanation of the figure, but the lack of specific guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the range of lines (L156166) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph and the figure, indicating that the paragraph is difficult to understand and the figure is hard to interpret. The comment provides clear guidance on what needs to be clarified, such as specifying which bandit algorithms are being discussed and providing a more detailed explanation of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, despite the reviewer having some knowledge of the content. It suggests that the authors should clarify the paragraph by specifying which bandit algorithms are being discussed and provide a more detailed explanation of the figure. The comment also points out that the description of the dashed lines is vague. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the issues and make the necessary changes, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas of the paper that are difficult to understand, such as a paragraph and a figure. It provides actionable feedback by suggesting that the authors clarify the paragraph by specifying which bandit algorithms are being discussed and offer a more detailed explanation of the figure. The comment also points out that the description of the dashed lines is vague, which could be improved for better understanding. This feedback is clear and constructive, providing the authors with specific directions for enhancing the clarity and comprehensibility of their draft. However, it could be more helpful if it included examples or further elaboration on how to make the explanation more concrete. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation metric should be explicitly mentioned in the text to improve clarity and understanding of the scale of improvement. It also provides a specific example of how this could be done by referencing the expression used in a previous work. The comment is explicit in its request for clarification and provides a concrete example of how to implement the suggested change. This makes the action clear and actionable for the authors, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and Line 08), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to mention the evaluation metric for clarity and to better understand the scale of improvement. Additionally, it references a specific expression used in a previous work, providing context and a concrete example of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be explicitly mentioned to improve clarity and understanding of the scale of improvement. It provides a specific example by referencing the expression used in a previous work, which helps to substantiate the claim. However, the comment could be strengthened by explaining why this is important or how it impacts the results. Overall, the claim is 4, as it is supported by a logical suggestion and a specific example, but it could be more robust with additional explanation or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be explicitly mentioned in the text to improve clarity and understanding of the scale of improvement. It also references a specific expression used in a previous work, which helps the authors understand the context and importance of the metric. This feedback is clear and constructive, offering a direct way for the authors to enhance the clarity and comprehensibility of their results. However, the comment could be more helpful if it included additional suggestions on how to present the metric or why it is crucial for the results. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise, given that the standard deviation of the noise is stated as 3 but appears to be low based on the observations in the plot. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to implement the study or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"plot,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the stated noise level and the observed results, suggesting that the authors should study the model\"s behavior under higher noise. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the stated noise level in the simulation study is not very high, as evidenced by the observations in the plot compared to the true trajectories. The reviewer suggests studying the model\"s behavior under higher noise. This claim is 3 as it provides a logical reasoning based on the observed data, but it lacks specific examples or detailed analysis to fully substantiate the claim. The authors would need to further explore the data to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the stated noise level in the simulation study and the observed results, suggesting that the noise level is not as high as claimed. It provides a clear suggestion to study the model\"s behavior under higher noise, which could offer valuable insights into the model\"s robustness and performance. This feedback is actionable and constructive, as it guides the authors to explore an important aspect of their study that may not have been thoroughly examined. However, the comment could be more helpful if it included specific suggestions on how to conduct this additional study or what aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the approach due to the limitations imposed by the o(1) terms and the requirement for arbitrarily long inputs. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their approach. The comment lacks actionable details, such as recommending specific modifications or providing examples of how to overcome the limitations. As a result, the authors are left without a clear understanding of what steps to take to address the concern raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their applicability, specifically mentioning the o(1) terms and the requirement for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these bounds are discussed, the comment lacks full grounding. It is specific in identifying the issue with the bounds and their applicability, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds have o(1) terms and start improving over previously known results for arbitrarily long inputs. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how it impacts the paper\"s conclusions. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the approach due to the limitations imposed by the o(1) terms and the requirement for arbitrarily long inputs. While it identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their approach. The comment lacks actionable feedback, making it 3 as it highlights a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses an interesting question about the performance of DVP on video with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question, such as suggesting experiments, analyses, or comparisons. Without any actionable steps or suggestions, the authors are left without a clear understanding of what to do next. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses an interesting question about the performance of DVP on video with different lengths. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the performance should be explored or what conclusions could be drawn from this observation. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for an interesting observation about the performance of DVP on video with different lengths. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses an interesting question about the performance of DVP on video with different lengths. While it highlights a potential area of interest, it does not provide any specific guidance or suggestions on how the authors might explore this aspect further. The comment lacks actionable feedback or detailed insights that would help the authors improve their draft. As a result, it is 2, as it identifies a potential area for exploration but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a confusion about whether the paper targets singletoken or multitoken cloze queries, which is clarified in the conclusion. However, it does not provide explicit guidance or suggestions on how the authors should address this confusion in the paper. The comment implies that the authors should clarify this point earlier, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a confusion about whether the paper targets singletoken or multitoken cloze queries, which is clarified in the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue of confusion regarding the type of cloze queries, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, which is clarified in the conclusion. However, the comment does not provide any supporting evidence, reasoning, or references to justify this confusion. It lacks specific examples or detailed explanations, making it difficult for the authors to understand and address the issue. As a result, the claim is 1.", "helpfulness_rationale": "The comment identifies a specific confusion regarding whether the paper targets singletoken or multitoken cloze queries, which is clarified in the conclusion. However, it does not provide any actionable feedback or suggestions on how the authors might address this confusion in their draft. The comment lacks depth and does not offer guidance on improving clarity or organization, making it 2. The authors are left with a general understanding of the issue but without specific steps to resolve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. It also mentions that experiments should be conducted to support this evaluation. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done and how to implement it. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. The comment provides a clear direction for the authors to improve their draft by addressing this specific issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed training objective, specifically questioning the omission of the KLdivergence term in equation (3). The reviewer suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the omission of the KLdivergence term is problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that the KLdivergence term is omitted in equation (3). It suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is clear and actionable, providing the authors with a concrete direction to improve their draft by addressing the omission of a critical component in their training objective. However, the comment could be more helpful if it included additional guidance on how to conduct this evaluation or why it is important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 2 lacks a clear connection to the methodology section and that the theoretical analysis is somewhat simplistic, referencing a specific work. While it identifies areas for improvement, it does not provide explicit guidance on how to strengthen the connection between Section 2 and the methodology section or how to enhance the theoretical analysis. The comment lacks concrete suggestions or actions for the authors to take, leaving them with a general idea of what needs to be improved but without specific steps to follow. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited connection between Section 2 and the methodology section, as well as the simplicity of the theoretical analysis, referencing a specific work. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is somewhat simplistic, referencing a specific work. While the comment identifies a potential issue, it lacks detailed reasoning or examples to fully substantiate the claim. The reference to 1 provides some context, but the authors would still need to understand the specifics of that work to fully grasp the critique. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed explanation or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically noting that Section 2 lacks a clear connection to the methodology section and that the theoretical analysis is somewhat simplistic, referencing a specific work. This feedback is 3 as it highlights areas where the paper could be improved, particularly in terms of coherence and depth of analysis. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending ways to strengthen the connection between sections or enhancing the theoretical analysis. While it points out important areas for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further discuss or specify which situations the losses help in particular, such as for specular areas. While the comment implies that the authors should provide more detailed analysis or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on the topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing or specifying situations where losses help, particularly for specular areas. However, it does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss particular situations, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests discussing or specifying situations where losses help, particularly for specular areas. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it would benefit the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss or specify which situations the losses help in particular, such as for specular areas. This feedback is 3 as it points out a potential area for improvement in the paper, encouraging the authors to provide more detailed analysis or examples. However, the comment lacks specificity and does not offer detailed guidance on how to address this suggestion, such as which aspects of the losses should be discussed or how to identify the situations where they are particularly relevant. While it provides a direction for improvement, the feedback could be more actionable with additional details. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses doubt about the paper\"s strength for ICLR but does not provide any specific guidance or suggestions on how the authors might improve the paper to meet the standards expected for ICLR. The comment lacks actionable details, such as recommending specific enhancements, clarifications, or additional experiments that could strengthen the paper. Without explicit or implicit actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength for ICLR but does not specify which aspects of the paper are lacking or how they could be improved. It lacks both grounding and specificity, as it does not identify a specific section, table, figure, or unique element of the paper that needs attention. Without this information, the authors cannot determine what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a doubt about the paper\"s strength for ICLR but does not provide any specific reasoning, examples, or evidence to support this claim. It lacks detailed justification or references to substantiate the assertion that the paper is not strong enough for ICLR. Without such supporting information, the claim remains 1, as it does not offer a clear basis for the authors to address or improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength for ICLR but does not provide any specific feedback or suggestions on how the authors might improve the paper to meet the standards expected for ICLR. It lacks actionable guidance, such as recommending specific enhancements, clarifications, or additional experiments that could strengthen the paper. Without detailed and constructive feedback, the authors are left without a clear path to address the concerns raised. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the major contributions of the paper and criticizes the analysis of previous work as not constituting a contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors should clarify their contributions or how they might improve their analysis of previous work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the paper\"s major contributions and criticizes the analysis of previous work as not constituting a contribution. However, it does not specify which part of the paper this issue pertains to, such as the introduction, conclusion, or specific sections discussing contributions. Without explicit references to sections or elements of the paper, the authors cannot confidently determine where the issue lies. Additionally, the comment lacks specificity regarding what aspects of the analysis of previous work are problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions and criticizes the analysis of previous work as not constituting a contribution. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, which is the lack of clarity regarding its major contributions. It also critiques the analysis of previous work, suggesting that it does not constitute a contribution. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or clarify their contributions. Without actionable feedback or detailed examples, the authors are left with a general understanding of the problem but without a clear path to resolve it. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results and asks if the code will be publicly available. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what steps they should take to improve reproducibility. The action is implicit, as the authors need to infer that they should make the code publicly available to facilitate reproducibility. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results and asks if the code will be publicly available. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references to sections, figures, or tables, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of reproducibility or code availability need to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results and asks if the code will be publicly available. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or why the authors should consider making the code publicly available. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results and asks if the code will be publicly available. While it identifies a potential issue, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern. The comment is vague and does not offer guidance on improving reproducibility or accessibility of the code, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claims about the \"mixing time\" being better in practice are not sufficiently supported by the experiments, which limits the evidence available to practitioners. However, it does not provide specific guidance on how the authors should address this issue or what additional experiments or analyses could be conducted to strengthen the claims. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the claims about the \"mixing time\" being better in practice, but it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in identifying the lack of sufficient support for these claims through experiments, which provides clear guidance on what needs to be addressed. However, without explicit references to sections or experiments, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claims about \"in practice the mixing time is even better\" are not sufficiently supported by the experiments, which limits the evidence available to practitioners. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the claims made in the paper, noting that the assertion about \"in practice the mixing time is even better\" is not sufficiently supported by the experiments. This feedback highlights a critical gap in the evidence provided, which is essential for practitioners to understand the practical implications of the findings. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or strengthen their evidence. While it points out a significant weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, implying that A currently represents multiple attributes. This is an explicit suggestion for the authors to consider a specific action, which is to modify the feature representation. However, the comment does not provide detailed guidance on how to implement this extension or what aspects of the vector form should be considered. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, implying that A currently represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this extension could be applied. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an extension, but without clear grounding, it lacks specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, implying that A currently represents multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, implying that A currently represents multiple attributes. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically in how the protected feature is represented. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what aspects of the vector form should be considered. While it points out a potential enhancement, it does not fully support the authors in making a meaningful improvement to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors denote the vector representations of words in the equation and asks for clarification on whether these vectors are L2normalized. Additionally, it questions the method used for computing nearest neighbor examples, specifically whether cosine or dotproduct is used. These suggestions are clear and provide concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions regarding the vector representations of words, their normalization, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for clarification rather than making claims or opinions. It requests additional information about the vector representations, normalization, and the method used for computing nearest neighbor examples. Since it does not contain subjective opinions or assertions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a potential issue with the notation in the paper, suggesting that the vector representations of words should be denoted in some way. It also questions whether the vectors are L2normalized and asks about the method used for computing nearest neighbor examples, specifically whether cosine or dotproduct is used. These questions and suggestions are clear and provide the authors with concrete guidance on how to improve the clarity and precision of their work. By addressing these points, the authors can enhance the readability and technical accuracy of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that experiments should be run multiple times to address issues with reproducibility and the significance of improvements in deep reinforcement learning. It also mentions the need for a community effort towards reproducibility and highlights the importance of running multiple experiments and reporting statistics. The comment provides clear and concrete actions for the authors to take, such as conducting multiple runs and analyzing the results statistically. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments should be run multiple times,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of reproducibility and the need for a community effort towards reproducibility, suggesting that the authors should consider running multiple experiments and reporting statistics. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that experiments should be run multiple times due to issues with reproducibility and the significance of improvements in deep reinforcement learning. It references a suggestion from Henderson et al. (2018) regarding reproducibility. The comment provides a logical reasoning by linking the need for multiple experiments to address reproducibility issues, which is a common concern in the field. However, it lacks specific examples or detailed guidance on how to implement this suggestion, such as suggesting specific statistical measures or methods to improve reproducibility. This makes the claim 3, as it provides a general direction but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a critical issue with the experiments in the paper, specifically the lack of reproducibility and the significance of improvements in deep reinforcement learning. It suggests that the authors should run multiple experiments to address these issues, referencing a relevant paper by Henderson et al. (2018) that emphasizes the importance of reproducibility in deep RL. This feedback is clear and actionable, providing the authors with a specific direction to improve the robustness and reliability of their experiments. However, the comment could be more helpful if it offered additional guidance on how to conduct these multiple experiments or what specific statistical measures to report. Overall, the comment is 4 as it effectively directs the authors toward a significant aspect of their work that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the punctuation used in the equations. This provides clear and direct actions for the authors to take, making the comment 5. The authors know exactly what needs to be corrected and how to apply the action, as the instructions are specific and concrete.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" \"Line 433,\" and \"Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent punctuation in equations, providing a clear direction for the authors to follow. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding punctuation consistency in equations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with punctuation consistency in equations, which is a clear and actionable feedback. By pointing out the inconsistency in punctuation at Lines 433 and 468, the reviewer provides the authors with a clear direction to improve the accuracy and professionalism of their manuscript. This feedback is specific and actionable, making it 5 for the authors to address the issue effectively. Therefore, the comment deserves a score of 5, as it is fully helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might differentiate their work or improve the technical contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to the technical contribution of the paper, specifically mentioning \"$kNNECD$\" and \"$kNNMT$\". However, it does not specify which part of the paper this comparison is made in, such as a section or a particular discussion. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its claim that the technical contribution is limited due to the similarity between $kNNECD$ and $kNNMT$, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation in the technical contribution of the paper, suggesting that the similarity between $kNNECD$ and $kNNMT$ limits the originality of the work. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this issue. It does not offer guidance on how the authors might differentiate their work or improve the technical contribution. As a result, the comment is not helpful in guiding the authors to enhance their draft, making it a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks whether the figures in Figure 1 are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in these figures. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to evaluate the proposed method. The comment is specific and actionable, giving the authors a concrete task to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the origin of the figures (real experiments or artificial) and suggests conducting realworld experiments to support the phenomenon observed in the figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the origin of the figures in Figure 1, asking whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. This claim is 3 as it raises a valid concern about the credibility of the figures and suggests a potential improvement. However, it lacks specific examples or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment raises a valid concern about the credibility of the figures in Figure 1, questioning whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. This feedback is actionable and provides a clear direction for the authors to enhance the credibility and robustness of their findings. By addressing this issue, the authors can strengthen the evaluation of their proposed method. Therefore, the comment is 4, as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the numbers of parameters used in each approach are not clear in Section B.3. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this information. The action is implicit, as the authors can infer that they need to provide more details about the parameters used in each approach, but the comment lacks concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on the numbers of parameters used in each approach. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the numbers of parameters used in each approach, as mentioned in Section B.3. This is a clear and actionable piece of feedback that can help the authors improve the clarity and transparency of their work. However, the comment does not provide further guidance or suggestions on how to address this issue, such as recommending specific ways to present the information or how to ensure consistency across the paper. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an example and possibly a figure would be helpful in explaining the definition of uniform shattering. While the comment implies that the authors should include these elements, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to add an example and a figure, but it is not concrete because it does not specify where these elements should be placed or how they should be integrated into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this definition is discussed in, making it difficult for the authors to pinpoint the exact location where these elements should be added. While the suggestion is specific in terms of what is needed (an example and a figure), the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning or evidence to support why these elements are necessary or how they would improve the explanation. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not specify how these examples or figures should be integrated into the paper or what aspects of the definition they should address. While it points out a potential area for improvement, it does not offer detailed guidance on how to achieve that improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern that the proposed transductive method is not novel, suggesting it is similar to a common approach of incorporating unlabeled data in semisupervised methods, specifically selftraining methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the novelty of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed transductive method is not novel, as it is similar to a common approach of incorporating unlabeled data in semisupervised methods, specifically selftraining methods. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the method are considered noninnovative. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is similar to a common approach of incorporating unlabeled data in semisupervised methods, specifically selftraining methods. However, the comment lacks specific references or detailed reasoning to support this claim. Without explicit examples or citations to similar methods, the authors may find it challenging to understand and address the concern. The lack of detailed justification or evidence makes the claim 3, as it provides a general idea but requires more information for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential novelty issue with the proposed transductive method, suggesting that it is not novel as it resembles common approaches in semisupervised learning, specifically selftraining methods. While this feedback highlights a concern, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or enhance the novelty of their method. Without detailed suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve the manuscript. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the assumption among classes as not being practical and suggests that the formulation or definition in the manuscript is somewhat trivial. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the assumption or formulation are considered trivial or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains 1, as it does not provide a clear justification or evidence for the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the assumption among classes as not being practical and suggests that the formulation or definition in the manuscript is somewhat trivial. However, it does not provide specific examples or detailed feedback on how the authors might address this issue or improve the manuscript. The comment lacks actionable guidance or suggestions, leaving the authors without a clear path for improvement. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in table 1 are based on only three trials for each case, which is not statistically significant. It suggests that reporting deviations is not meaningful due to the lack of statistical significance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The authors are left to infer that they need to increase the number of trials or provide a rationale for the limited number of trials. Since the action is implicit and lacks concrete details, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that they are based on only three trials for each case, which is not statistically significant. The comment further explains why this is problematic and suggests that reporting deviations is not meaningful. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in table 1 are based on only three trials for each case, which is not statistically significant. The reviewer supports this claim by stating that reporting deviations is not meaningful due to the lack of statistical significance. However, the comment lacks specific examples or references to substantiate the claim about the number of trials or the implications of the limited sample size. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the evaluation results presented in table 1, noting that they are based on only three trials for each case. The reviewer points out that this is not statistically significant and suggests that reporting deviations is not meaningful. The comment also provides a specific example of a statement that does not make sense due to the lack of statistical significance, such as \"our performance is at least two standard deviation better than the next best baseline.\" This feedback is clear and actionable, as it highlights a significant limitation in the evaluation and provides a concrete example of a statement that should be revised. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited trials or how to improve the statistical significance of the results. Overall, the comment is 4, as it effectively guides the authors to improve the robustness and validity of their evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the comparison are lacking. The authors are left to infer that they need to include these two relevant papers in their comparison, but the comment does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the feature comparison, mentioning that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of two relevant papers, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison section, noting that it is shallow and mentions the absence of two relevant papers. This feedback is 3 as it highlights a potential weakness in the paper\"s analysis, prompting the authors to consider the inclusion of additional relevant work. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what aspects of the comparison could be improved. While it points out an area for enhancement, it does not offer actionable steps for the authors to take, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests a more cautious usage of the word \"equivalent,\" particularly if the equivalence is not verified. This provides a clear and direct action for the authors to take, specifying which lines need attention and what the reviewer is concerned about. The suggestion is concrete, as it outlines a specific change that can be made to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8, 56, 70, 93) where the usage of the word \"equivalent\" is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides a clear suggestion to use the word \"equivalent\" more cautiously, especially if the equivalence is not verified. This guidance is actionable and provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious usage of the word \"equivalent,\" particularly if the equivalence is not verified. However, the comment does not provide specific examples or reasoning to support why this caution is necessary or how it could be implemented. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and how to address it effectively. Therefore, the comment is considered 2, as it provides a general suggestion without sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that its usage should be more cautious, especially if the equivalence is not verified. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can help the authors enhance the clarity and accuracy of their writing. However, the comment could be more helpful if it included examples or further explanation of why the caution is necessary. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views beyond the paraphrase similarity view. It points out that while the paraphrase similarity view performs significantly better, there is no detailed analysis of how other views contribute to clustering. The reviewer suggests that without a more detailed analysis of the differences and similarities between the views, it is challenging to draw solid conclusions. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views beyond the paraphrase similarity view. It highlights that while the paraphrase similarity view performs significantly better, there is no detailed analysis of how other views contribute to clustering. The comment also mentions an empirical example of how different views help in clustering paraphrases of the word \"slip,\" but it lacks further analysis of how different clustering techniques differ. This feedback is specific in identifying the need for a more detailed analysis of the views and their contributions. However, it is weakly grounded as it does not explicitly mention a specific section or part of the paper where this analysis should be conducted. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views beyond the paraphrase similarity view. It provides a logical reasoning by noting that the paraphrase similarity view performs significantly better and lacks a detailed analysis of how other views contribute to clustering. However, the comment does not provide specific examples or references to support the claim that the other views are not useful. This makes the claim 3, as it provides a basis for questioning the approach but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views beyond the paraphrase similarity view. It points out that while the paraphrase similarity view performs significantly better, there is no detailed analysis of how other views contribute to clustering. The comment also highlights the lack of a more detailed analysis of the differences and similarities between the views, which is essential for drawing solid conclusions about their usefulness. This feedback is 3 as it identifies a gap in the analysis and suggests that the authors should conduct a more comprehensive evaluation of the views. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this analysis. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper, and the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to provide a clearer explanation of the architecture or include more details from Jiang et al. (2019). The action is implicit and somewhat vague, as it lacks concrete instructions on how to improve the clarity or selfcontainment of the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the architecture used for the experiments not being clearly explained in the paper, suggesting that the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. However, the comment does not specify which part of the paper discusses the architecture, making it weakly grounded. The comment is specific in identifying the lack of clarity and the need for a selfcontained explanation, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, suggesting that the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The comment provides a specific reference to Jiang et al. (2019), which adds some level of support to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of clarity affects the paper\"s comprehensibility. Therefore, the claim is 4, as it is supported by a reference but lacks additional detailed justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained. It points out that the authors refer to Jiang et al. (2019) for details, which makes the paper not selfcontained. This feedback is clear and actionable, as it highlights a critical area that needs improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the architecture or integrate the relevant details from Jiang et al. (2019). Despite this, the comment is 4 as it directs the authors\" attention to an important aspect of their work that needs clarification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that BertScore and BLEURT should be consistently typeset throughout the paper, either as \"Bertscore\" or \"Bleurt\". This is a clear and direct action for the authors to take, providing them with a specific and actionable step to improve the consistency of their paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the typesetting of BertScore and BLEURT, suggesting that they should be consistently typeset throughout the paper. However, it does not specify which sections of the paper are affected by this inconsistency, making it weakly grounded. The comment is specific in its suggestion to maintain consistency, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that they should be consistently typeset as \"Bertscore\" or \"Bleurt\". However, the comment does not provide any specific examples or references to support this claim, nor does it explain why consistency is important or how it affects the paper. Without detailed justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that they should be consistently typeset as \"Bertscore\" or \"Bleurt\". This feedback is clear and actionable, providing the authors with a direct suggestion to improve the consistency of their terminology, which is crucial for clarity and professionalism in academic writing. However, the comment could be more helpful if it offered additional guidance on how to implement this change or why consistency is important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on model size, given that increasing the model size can negatively impact performance. It references a recent paper by Ni et al., which supports the claim that scaling laws apply to dense retrieval models. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include detailed results and determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the preliminary experimental results on Wikipedia regarding model size, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide detailed results on model size, referencing a recent paper by Ni et al. to support the claim that increasing model size can negatively impact performance. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that increasing the model size can negatively impact performance, referencing a recent paper by Ni et al. that supports this claim by applying scaling laws to dense retrieval models. The comment is 4 as it provides a logical reasoning based on the referenced paper, which suggests that the authors should provide detailed results on model size. However, the comment could be strengthened by explicitly mentioning the specific results or experiments that should be included. Overall, the claim is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that the claim about increasing model size negatively impacting performance is not supported by evidence. It references a recent paper by Ni et al., which supports the idea that scaling laws apply to dense retrieval models, implying that the preliminary experimental results on model size should be detailed. This feedback is 3 as it points out a potential weakness in the paper and suggests a specific area for improvement by providing a reference for further exploration. However, the comment could be more helpful if it offered specific guidance on how to present these results or why they are important. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several aspects of the presentation quality that could be improved, such as the management of figures, tables, and the inclusion of a \"*\" in Table 1. However, it does not provide explicit guidance on how to address these issues or suggest specific changes to make. The feedback is somewhat vague, as it points out areas for improvement but lacks concrete instructions on how to implement them. Therefore, the comment is 3, as the authors can infer that they need to make changes to improve the presentation quality, but they are not given detailed guidance on how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figs 1&2) and tables, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the presentation quality, such as the management of figures, tables, and the inclusion of a \"*\" in Table 1. This provides clear guidance on what needs to be addressed to improve the presentation quality. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that certain aspects of the presentation quality are weaknesses for a highquality publication, such as the management of figures, tables, and the inclusion of a \"*\" in Table 1. The comment provides specific examples of these issues, such as the lack of informative \"Dataset\" columns in tables and the management of figures. However, the comment does not provide detailed reasoning or references to support why these aspects are problematic or how they impact the overall presentation quality. While the examples are clear, the lack of deeper justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several specific aspects of the presentation quality that could be improved, such as the management of figures, tables, and the inclusion of a \"*\" in Table 1. It provides clear examples of these issues, such as the lack of informative \"Dataset\" columns in tables and the management of figures. However, the comment does not offer detailed guidance or suggestions on how to address these issues or improve the presentation quality. While it highlights areas for improvement, the feedback could be more helpful if it included actionable advice or examples of how to enhance the presentation. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper uses excessive analysis to justify the use of the information axis as a tool, and it expresses curiosity about related experiments that this tool could help with. However, it does not provide explicit guidance on what specific experiments should be conducted or how they could demonstrate the tool\"s effectiveness. The action is implicit and somewhat vague, as the authors know they need to explore additional experiments but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper uses excessive analysis to justify the use of the information axis as a tool and expresses curiosity about related experiments that this tool could help with. However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in suggesting that related experiments should be conducted, but without clear grounding, the authors may struggle to identify the exact sections or aspects of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper uses excessive analysis to justify the use of the information axis as a tool, and it expresses curiosity about related experiments that this tool could help with. However, the comment does not provide specific examples or detailed reasoning to support the claim that the analysis is excessive or to explain why the information axis is a good tool. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the use of excessive analysis to justify the use of the information axis as a tool, which is a valid point of critique. It also expresses curiosity about related experiments that this tool could help with, suggesting that the authors might benefit from exploring additional applications or experiments to demonstrate the tool\"s effectiveness. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what specific experiments would be beneficial. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this interest or what specific aspects they should consider. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any details on what aspects of the pretraining setups are being questioned. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the multilingual pretraining setups are being questioned. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for additional information or clarification regarding the struggles of other multilingual pretraining setups with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for more information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific guidance or suggestions on how the authors might address this interest or what aspects of the pretraining setups should be considered. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear direction for improvement. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 is unclear and makes it difficult for readers to understand and evaluate the statement. It suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear. However, the comment does not provide specific guidance on how to clarify the statement or what changes should be made to improve the clarity. The action is implicit and vague, as the authors are left to infer that they need to rephrase or clarify the text. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the text in these lines is unclear and makes it difficult for readers to understand and evaluate the statement. The comment suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 is unclear and makes it difficult for readers to understand and evaluate the statement. However, the comment does not provide any specific reasoning or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand why the statement is unclear or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes the point difficult for readers to understand and evaluate. The comment suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear. While it highlights a potential area for improvement, it does not provide specific guidance or suggestions on how to clarify the statement or improve the overall clarity of the text. This limits the comment\"s usefulness, as the authors are left to infer the necessary changes without explicit direction. Therefore, the comment is 3, as it points out a weakness but lacks actionable feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on which realworld datasets to use or how to implement this change effectively. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting a change to improve the paper\"s relevance, but it lacks grounding as it does not clearly identify the section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or beneficial. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This is a relevant and actionable suggestion that could enhance the paper\"s applicability and relevance by aligning it with more realistic scenarios. However, the comment lacks specific guidance on which realworld datasets to use or how to implement this change effectively. While it provides a direction for improvement, it does not offer detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide explicit guidance on what needs to be clarified or how the authors should improve the explanation. The comment lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and provides line numbers (207210), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that some explanations are vague, particularly in the last paragraph of Section 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some explanations in the paper are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment lacks specificity and does not provide detailed feedback or suggestions on how the authors might clarify these explanations. Without actionable guidance or examples of what could be improved, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer substantial assistance in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the current study, which only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. While the comment implies that the authors should consider this extension, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this extension. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the study, which only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the study to multiple trucks and drones, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the limitation of the study, which only considers one truck and one drone, and suggests that extending the study to multiple trucks and drones would be more interesting and practical. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension would be beneficial or how it would enhance the study. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a relevant question about the limitation of the study, which only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones would be more interesting and practical. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to consider a more comprehensive and practical setting. However, the comment lacks specific guidance or suggestions on how to implement this extension or what aspects of the study could be enhanced by considering multiple trucks and drones. Therefore, the comment provides some insight but does not offer detailed, actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the proposed approach to pretraining is not novel, as it follows strategies similar to those used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address the lack of novelty or how they could differentiate their approach from ELECTRA. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, noting that it follows strategies similar to those used in ELECTRA. However, it does not specify which part of the paper discusses the proposed approach or where the comparison to ELECTRA is made, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach could be made more novel or how the authors might differentiate their work from ELECTRA. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining is not novel because it follows strategies similar to those used in ELECTRA. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the proposed approach to pretraining is not novel, as it follows strategies similar to those used in ELECTRA. However, it lacks specificity and does not provide any actionable feedback or suggestions for how the authors might differentiate their approach or enhance its novelty. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of motivation for the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer implies that experiments comparing the runtime of the Newton algorithm with a bisecting line search could help motivate the need for the analysis/algorithm. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for how to address the issue. The action is implicit but concrete, as it specifies what kind of experiments would be beneficial. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, suggesting that it is essentially a 1dimensional line search on a convex function. The comment further specifies what needs to be addressed by proposing experiments comparing the runtime of the Newton algorithm with a bisecting line search. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in section 4 is lacking, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer provides a logical reasoning by noting that even a basic bisecting line search would converge linearly, while the Newton algorithm offers quadratic convergence. However, the comment does not provide specific examples or references to support the claim that the runtime impact of the Newton algorithm is significant. This lack of detailed evidence or examples makes the claim 3, as the authors would need to further explore and substantiate the argument themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation for the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer provides a logical reasoning by noting that even a basic bisecting line search would converge linearly, while the Newton algorithm offers quadratic convergence. However, the comment does not specify how this difference in convergence impacts the algorithm\"s runtime or why it is necessary to analyze the algorithm. The reviewer suggests conducting experiments to compare the runtime of the Newton algorithm with a bisecting line search, which could help motivate the need for the analysis. While the comment provides a clear direction for improvement, it could be more helpful by offering specific suggestions or examples for the experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs random data is similar, implying that the results may not be idiomspecific. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The comment lacks actionable details, such as recommending specific analyses or modifications to make the results more idiomspecific. As a result, the authors are left without clear direction on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the proposed upweighing and KNN methods, specifically mentioning Figure 3 to support the claim that the impact on idiomatic vs random data is similar. This provides some grounding as the authors can infer that Figure 3 is relevant to the discussion. However, the comment lacks specificity in detailing what aspects of the methods are not idiomspecific or how the results could be improved to be more idiomspecific. The suggestion to \"better NMT systems are also better at idiomatic translations\" is a general observation without specific guidance on how to address it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not effectively distinguish between idiomatic and random data, as their impact is similar across different language and score combinations. The comment references Figure 3 to support this claim, providing a visual reference for the analysis. However, the comment lacks detailed explanation or specific examples from Figure 3 to fully substantiate the claim. This makes the claim 3, as it provides a basis for the assertion but requires more detailed evidence or analysis to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs random data is similar, implying that the results may not be idiomspecific. This observation is important as it questions the validity of the proposed methods in distinguishing between idiomatic and random data. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable feedback or detailed recommendations, the authors are left without a clear path forward to enhance their work. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the description of hyperparameters, specifically mentioning that the authors have C biases but only found one hyperparameter for the feedforward models in section 3.4. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this discrepancy or suggest any specific actions to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or correct the description of hyperparameters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the description of hyperparameters, particularly the confusion regarding the number of biases and the lack of clarity in the feedforward models. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the description of hyperparameters, specifically the number of biases and their relevance to the feedforward models. The reviewer points out that the authors have C biases but only found one hyperparameter for the feedforward models in section 3.4, which is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the description is unclear or incorrect. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of hyperparameters in the paper, particularly the confusion regarding the number of biases and their relevance to the feedforward models. It highlights a discrepancy between the description of hyperparameters and the actual implementation, which is an important point for clarity and consistency. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their description. While it points out a potential area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically the subtraction of a dynamic factor from dynamic information, which may lead to the loss of dynamic information. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider alternative approaches or modifications to mitigate the loss of dynamic information, but it lacks concrete steps or examples for implementation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential loss of dynamic information when subtracting a dynamic factor from dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential loss of dynamic information when subtracting a dynamic factor from dynamic information in Equation 8. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the concern.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically the subtraction of a dynamic factor from dynamic information, which may lead to the loss of dynamic information. This is a relevant observation that could impact the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the equation. While it highlights a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider alternative approaches or modifications to mitigate the loss of dynamic information, but the feedback could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these questions or what specific aspects they should investigate. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples and the network structure on performance. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the questions are specific in nature, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the impact of the number of Monte Carlo samples and network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the impact of the number of Monte Carlo samples and the network structure on performance. While it identifies areas of interest, it does not provide specific guidance or suggestions on how the authors might address these questions or what experiments could be conducted to explore these impacts. The comment lacks actionable advice and does not offer a clear path for improvement, making it 2. Authors would need to infer what needs to be done, which limits the utility of the feedback. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests showing the smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. This is a clear and direct action for the authors to take, providing specific guidance on which figures to include and what information should be presented. The suggestion is concrete, as it specifies which figures to focus on and what aspect of the reconstruction to highlight. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests showing the smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers understand the quality of the reconstruction. However, it does not specify which parts of the paper these figures are in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed\u2014showing the smoothed GT shapes. However, without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers understand the quality of the reconstruction. However, it does not provide any reasoning or evidence to support why this suggestion is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests showing the smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. This feedback is specific and actionable, as it provides a clear direction for improving the clarity and comprehensiveness of the paper. By suggesting the inclusion of these figures, the reviewer offers a concrete way for the authors to enhance the presentation of their results, making it easier for readers to grasp the quality of the reconstruction. However, the comment could be more helpful if it included additional context or explanation on why these figures are particularly important or how they would benefit the overall understanding of the paper. Despite this, the feedback is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the comparison between the proposed approach and the prior approach PRANC, specifically noting the absence of direct comparisons in both language and vision tasks. It mentions that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy, which is crucial for determining if the proposed approach is an improvement over the baseline it directly modifies. The comment implies that the authors should include a direct comparison of test accuracy to address this issue. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors know they need to include a direct comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the lack of direct comparisons with the prior approach PRANC in both language and vision tasks, and it highlights the absence of a direct comparison of test accuracy. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. The comment supports this claim by mentioning specific sections where comparisons are made, such as training loss in Section 3.4 and the rank of possible solutions in Section 3.5. However, it does not provide a direct comparison of test accuracy, which is crucial for determining if the proposed approach is an improvement over the baseline. The lack of a direct comparison of test accuracy makes the claim 3, as it highlights a gap in the evaluation that needs to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy, which is crucial for determining if the proposed approach is an improvement over the baseline it directly modifies. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and the coverage of 33 event types in the ACE data. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment implies that the authors should consider expanding their analysis to include more event types or provide a rationale for their selection, but it lacks concrete steps or details on how to implement this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and the coverage of 33 event types in the ACE data. However, it does not specify which part of the paper this concern is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the selection and coverage of event types. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and the coverage of 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and the coverage of 33 event types in the ACE data. This feedback is 3 as it identifies a potential weakness in the paper\"s scope and provides a specific area for the authors to consider. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this concern or improve the generalizability of their method. To be more helpful, the comment could include recommendations on how to expand the analysis or provide rationale for the selection of event types. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should include additional experiments on tasks like language modeling, machine translation, or text summarization to strengthen the paper\"s focus on the language modeling capability of pretrained models. This feedback provides a clear and concrete action for the authors to take, specifying which tasks should be included to better reflect the importance of language modeling. The comment is 5 as it offers specific guidance on how to improve the paper\"s presentation and relevance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, namely that they do not reflect the capability of language modeling, and suggests additional tasks that should be included to strengthen this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments conducted in the paper do not adequately reflect the importance of language modeling capability, as they focus on tasks like word similarity and SquAD, which are not as relevant to language modeling. The reviewer suggests including tasks like language modeling, machine translation, or text summarization to better align with the paper\"s main motivation. This claim is 3 as it provides a logical reasoning for why the current experiments are insufficient, but it lacks specific examples or references to support the suggestion of additional tasks. The authors would need to further develop their understanding to fully grasp the reasoning behind the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s experiments, noting that the current tasks (word similarity and SquAD) do not adequately reflect the importance of language modeling capability. It suggests that including additional tasks like language modeling, machine translation, or text summarization would better align with the paper\"s main motivation. This feedback is clear and actionable, providing the authors with specific suggestions for improving the relevance and comprehensiveness of their experiments. By addressing this feedback, the authors can enhance the paper\"s focus and strengthen its argument. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references in the revised manuscript. This feedback provides a clear and direct action for the authors to take, specifying what needs to be addressed. The comment is specific in its request for references and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and recommends citing and discussing these references in the revised manuscript. However, it does not specify which part of the paper should include these references or where they should be placed. The authors can infer that it relates to the introduction or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for references but lacks grounding because it does not pinpoint the exact sections of the paper that need revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which references are missing or how to address the issue. The lack of detailed justification or examples renders the claim 1, as it does not provide sufficient information for the authors to make informed decisions. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of important references for domain adaptation. It suggests that the authors should include and discuss these references in the revised manuscript. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by enhancing the literature review section. However, the comment could be more helpful if it offered suggestions on which specific references to include or how to integrate them effectively. Overall, the comment is 4 as it directs the authors toward a critical area of improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the SCNN model\"s performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions to take to improve the model or presentation. The suggestions are vague and lack concrete instructions, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the SCNN model\"s performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these issues might be discussed, the comment lacks full grounding. It is specific in identifying the concern about hyperparameter tuning and the distance to the next best model, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the SCNN model\"s performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. The reviewer questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a concern about the SCNN model\"s performance on domain pricing, suggesting that it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. While the comment identifies a potential issue with the model\"s performance, it lacks specific suggestions or guidance on how the authors might address this concern or improve their model. The presentation suggestions are vague and do not provide actionable steps for the authors to take. As a result, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance on how to achieve it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some aspects of the experimental setup, particularly regarding corpora and datasets, were unclear or poorly motivated. However, it does not provide specific guidance on what needs to be clarified or how the authors should improve the clarity or motivation of these aspects. The comment lacks explicit instructions or concrete suggestions for the authors to address the issue, leaving them uncertain about what steps to take to enhance the clarity or motivation of their experimental setup. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the clarity or motivation of certain aspects of the experimental setup, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the need for clarity or motivation regarding corpora and datasets, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically regarding corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. However, it lacks detailed guidance or suggestions on how the authors might improve the clarity or motivation of these aspects. While it highlights an important issue, the feedback is vague and does not provide actionable steps for the authors to address the problem. This limits its usefulness to the authors, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their results. The comment lacks actionable details, such as recommending specific experiments, comparisons, or additional analyses that could demonstrate the improvement. Without explicit instructions or concrete steps, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvement of the proposed method over existing RL methods is not impressive, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, figures, or specific results, the authors cannot confidently determine where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the improvement are considered unimpressive or how they could be enhanced. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the improvement of the proposed method over existing RL methods is not impressive. However, it lacks specificity and does not provide any detailed feedback or suggestions on how the authors might address this issue or enhance their results. Without actionable guidance or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the comparison of the model size to competing approaches, specifically in terms of depth or number of parameters. It points out that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model size, which is a clear and explicit action. However, it does not offer specific guidance on how to present this information or what details to include. Therefore, the comment is 3, as it identifies a missing piece of information but lacks concrete instructions on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the model size to competing approaches, specifically in terms of depth or number of parameters. It points out that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is specific in identifying a missing detail in the paper, but it is 1 as it does not explicitly mention a particular section or part of the paper where this information should be provided. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification on the model size, specifically the size of each hourglass module. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement.", "helpfulness_rationale": "The review comment raises a relevant question about the comparison of the model size to competing approaches, specifically in terms of depth or number of parameters. It points out that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it identifies a missing piece of information that could enhance the paper\"s comprehensiveness and allow readers to better understand the model\"s architecture. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that PACE addresses a gap by treating climate emulation as a diagnostictype prediction. It suggests that prior work, such as ClimateBench or ClimateSet, has already made similar claims. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify their contribution. The action is implicit, as the authors need to infer that they should provide a clearer explanation or differentiate their work from prior efforts. Additionally, the comment lacks concrete details on how to achieve this clarification, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the treatment of climate emulation as a diagnostictype prediction. It suggests that prior work, such as ClimateBench or ClimateSet, has already made similar claims, implying that the authors\" contribution is not as novel as they claim. However, the comment does not explicitly mention which part of the paper discusses this claim, making it weakly grounded. The comment is specific in identifying the issue with the claim and suggesting that prior work has already addressed similar claims. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s claim about PACE being a novel approach to climate emulation is misleading because prior work, such as ClimateBench or ClimateSet, has already addressed similar issues. However, the comment does not provide specific references or detailed examples of these prior works to substantiate the claim. This lack of detailed evidence or references makes the claim 2, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim regarding the novelty of PACE in addressing a specific gap. It points out that prior work, such as ClimateBench or ClimateSet, has already addressed similar issues, suggesting that the paper\"s contribution is not as novel as it claims. This feedback is 3 as it highlights a critical area for clarification, prompting the authors to reconsider their claims and differentiate their work from existing literature. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to differentiate PACE from prior work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the metric learning theory in the paper, suggesting that it is based on generalization theory of neural networks and does not provide better results compared to previous theoretical findings. However, it does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the metric learning theory or the analysis. The comment lacks actionable details, such as suggesting alternative approaches or providing examples of how to enhance the metric learning perspective. As a result, the authors are left without clear direction on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the metric learning theory in the paper, referencing the generalization theory of neural networks and comparing it to previous theoretical results. It also mentions that the metric perspective analysis does not yield better results and that the part of metric learning in the paper does not seem to work. However, the comment does not specify which sections or parts of the paper are being discussed, making it weakly grounded. The comment is specific in detailing the issue with the metric learning theory and the lack of better results compared to previous work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as referenced by Bartlett et al. (2017). It further suggests that the metric perspective analysis does not yield better results compared to previous theoretical findings. The comment provides a specific reference to support the claim, which is a form of verification. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the metric learning theory in the paper, suggesting that it is based on generalization theory of neural networks and does not provide better results compared to previous theoretical findings. It also points out that the metric perspective analysis does not seem to work within the existing content of the paper. While the comment highlights a concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the metric learning theory. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests moving some visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also advises condensing the existing three figures for the proposed network architecture to two, allowing space for additional visual results. This feedback provides explicit guidance on what the authors should do\u2014move and condense visual results\u2014to enhance the paper\"s presentation. The action is concrete, as it specifies exactly what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also advises condensing the existing three figures for the proposed network architecture to two, allowing space for additional visual results. This feedback is fully grounded as it explicitly mentions the main paper and the specific issue of missing visual results. It is also specific because it provides clear guidance on what needs to be done\u2014moving and condensing visual results\u2014to enhance the paper\"s presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also advises condensing the existing three figures for the proposed network architecture to two, allowing space for additional visual results. While the comment provides a logical suggestion for improving the presentation of the paper, it lacks specific examples or references to support the claim that visual results are essential for the main experiment. The suggestion is 3 as it offers a plausible reasoning but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors move some visual results from the supplementary material to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and advises condensing the existing three figures for the proposed network architecture to two, allowing space for additional visual results. This feedback is clear and constructive, as it guides the authors on how to enhance the presentation of their results in the main paper. By addressing this suggestion, the authors can improve the clarity and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the robustness of the methodology, specifically questioning whether the test examples are crucially different and whether the corpus residual value can detect this difference. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what steps they could follow to investigate it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the robustness of the methodology, specifically questioning whether the test examples are crucially different and whether the corpus residual value can detect this difference. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or example. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its questioning but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the robustness of the methodology, specifically questioning whether the test examples are crucially different and whether the corpus residual value can detect this difference. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the methodology, specifically questioning whether the test examples are crucially different and whether the corpus residual value can detect this difference. This feedback is valuable as it prompts the authors to consider the potential limitations of their approach and to explore the robustness of their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or what experiments or analyses could be conducted to verify the robustness. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests using the most popular WebQuestions benchmark set instead of WebQuestionsSP for the testbed. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. While the comment explicitly states the recommendation, it lacks specific guidance on how to implement this change or what aspects of the current setup need to be adjusted. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Choice of Dataset\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for suggesting the use of the \"most popular WebQuestions\" benchmark set instead of WebQuestionsSP, explaining the benefits of this choice in terms of weak supervision and direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using the \"most popular WebQuestions\" benchmark set instead of WebQuestionsSP for the testbed. The reviewer provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. This reasoning is logical and provides a clear justification for the recommendation. However, the comment could be strengthened by referencing specific studies or examples that have successfully used WebQuestions for similar tasks, which would further substantiate the claim. Overall, the comment is 4, as it provides a reasonable argument but could benefit from additional evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of the \"most popular WebQuestions\" benchmark set instead of WebQuestionsSP. It explains the rationale behind this choice, noting that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to enhance the relevance and comparability of their work, potentially leading to more impactful results. However, the comment could be more helpful if it included specific details on how the authors might integrate WebQuestions into their current framework or provided examples of similar studies that have successfully used this benchmark. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the claims made regarding the sparsity in training and its desirability. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the claims should be revised, removed, or if additional evidence is needed to support them. Without specific suggestions or actions, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the claims made regarding the sparsity in training and its desirability. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique of the claims, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the claims made regarding the sparsity in training and its desirability. The reviewer questions the assumption that sparsity is desirable and suggests that the benefits of sparsity, such as reduced memory requirements, may not be as significant as claimed. The comment provides a logical reasoning by questioning the assumption and suggesting that the benefits of sparsity may not be as impactful in the context of modern computational practices. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the critique to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the claims made regarding the sparsity in training and its desirability. It questions the assumption that sparsity is desirable and suggests that the benefits of sparsity, such as reduced memory requirements, may not be as impactful as claimed. The comment provides a logical reasoning by questioning the assumption and suggesting that the benefits of sparsity may not be as significant in the context of modern computational practices. However, the comment could be more helpful if it offered specific examples or suggestions for demonstrating the benefits of sparsity or for addressing the critique. Overall, the comment is 3 as it prompts the authors to reconsider their claims and provides a basis for further exploration, but it lacks detailed guidance on how to improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the novelty of the design is limited, as it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or suggest alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the novelty of the design, noting that it is not new due to the use of attention for motion learning, which has been widely used in video understanding. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the design could be improved or how the novelty could be enhanced. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. This claim is 3 as it references a common practice in the field, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to further explore the literature to understand the extent to which this approach is novel or how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a limitation in the novelty of the design, noting that it is not new due to the use of attention for motion learning, which has been widely used in video understanding. While this feedback highlights a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their design. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, such as ImageNet derivatives, to verify the effectiveness of the framework. It provides a clear action by recommending that these results be presented in the main paper. The comment is specific and concrete, as it identifies the missing elements and provides a direct path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, such as ImageNet derivatives, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the framework\"s effectiveness on ImageNet1k or ImageNet100, and suggests presenting these results in the main paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or results on other datasets, such as ImageNet derivatives, which are important for verifying the effectiveness of the framework. The comment suggests that presenting these results in the main paper would be beneficial. However, the comment does not provide specific examples or references to support the claim that ImageNet derivatives are crucial for verifying the framework\"s effectiveness. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these results themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks analysis or results on other datasets, such as ImageNet derivatives, which are important for verifying the effectiveness of the framework. It suggests that presenting these results in the main paper would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it offered additional guidance on how to present these results or why they are particularly important. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the model design, specifically mentioning that the model architecture and learning details are fragmented or missing. It suggests that the authors could provide a plot of model illustration, a pseudocode table, or a code repository to improve clarity. Additionally, it emphasizes the importance of demonstrating integrated details to facilitate reproducibility, given that Neurochaos Learning is not a wellknown method. The comment provides explicit actions for the authors to take, such as providing specific visual aids or code examples, and it also offers a clear rationale for why these actions are necessary. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of unclear model design, specifically mentioning the fragmentation or absence of model architecture and learning details. It suggests that the authors could provide a plot of model illustration, a pseudocode table, or a code repository to improve clarity. Additionally, it emphasizes the importance of demonstrating integrated details to facilitate reproducibility, given that Neurochaos Learning is not a wellknown method. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, such as providing visual aids or code examples. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details. It suggests that providing a plot of model illustration, a pseudocode table, or a code repository would improve clarity. The comment also emphasizes the importance of demonstrating integrated details to facilitate reproducibility, given that Neurochaos Learning is not a wellknown method. While the comment provides some logical reasoning by suggesting specific ways to improve clarity, it lacks detailed examples or references to support the claim fully. Therefore, the comment is 3, as it provides a general direction for improvement but requires more specific guidance to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, specifically noting that the model architecture and learning details are fragmented or missing. It provides actionable suggestions for improvement, such as providing a plot of model illustration, a pseudocode table, or a code repository. Additionally, it emphasizes the importance of demonstrating integrated details to facilitate reproducibility, given that Neurochaos Learning is not a wellknown method. This feedback is clear and constructive, offering the authors specific ways to enhance the clarity and reproducibility of their work. However, it could be more helpful if it included examples of what these visual aids or tables might look like. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between the use of BigFive and MBTI as models in the Abstract and Introduction sections and their use as datasets in the Experiments section. It suggests that the authors should either clarify why they are using these terms as models or reconsider their classification. The comment implies that the authors should provide an extended explanation or decide to treat them as datasets throughout the paper. While the action is implicit, it is concrete in terms of what needs to be addressed\u2014either an explanation or a reclassification. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract and Introduction sections\" and the \"Experiments\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the discrepancy between BigFive and MBTI being stated as models in the Abstract and Introduction but used as datasets in the Experiments. The comment suggests that it would be better to treat them as datasets throughout the paper unless the authors provide an extended explanation. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models in the Abstract and Introduction sections but are used as datasets in the Experiments section. The reviewer suggests that it would be better to treat them as datasets throughout the paper unless an extended explanation is provided. While the comment identifies a discrepancy, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide an extended explanation is vague and does not offer concrete guidance on how to address the issue. Therefore, the comment is 3, as it provides a general observation but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a discrepancy between the use of BigFive and MBTI as models in the Abstract and Introduction sections and their use as datasets in the Experiments section. It suggests that the authors should either provide an extended explanation for why they are using these terms as models or reconsider their classification as datasets throughout the paper. This feedback is clear and actionable, as it highlights a potential inconsistency in the paper\"s terminology and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to address the issue or provided examples of how to integrate the models more effectively. Overall, the comment is 4, as it effectively guides the authors toward a more consistent and coherent presentation of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the rejection rate is not shown in any experiments and questions whether misclassifications should be considered as rejections. It implies that the authors should include rejection rates or treat misclassifications as rejections in their results. While the action is implicit, it is concrete because it specifies what needs to be done\u2014either include rejection rates or treat misclassifications as rejections. The authors can infer that they need to provide more detailed information about the rejection process or clarify how misclassifications are treated. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the rejection rate is not shown in any experiments and questions whether misclassifications should be considered as rejections. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where the rejection rate is mentioned. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting that rejection rates should be included or treated as misclassifications, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the absence of rejection rates in the experiments and suggests that misclassifications could be considered as rejections. However, it does not provide any supporting evidence, reasoning, or references to justify why rejection rates are important or how misclassifications should be treated as rejections. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the manuscript, specifically the absence of rejection rates in the experiments. It suggests that misclassifications could be considered as rejections, implying that the authors should include rejection rates or clarify this aspect in their results. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to incorporate rejection rates or address the issue of misclassifications. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization to specific TSP instances, particularly focusing on the finetuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a clear direction for the authors to address the generalization issue and includes a suggestion for a comparison, it does not specify how to implement these changes or provide detailed guidance on what aspects to focus on. The action is explicit but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the generalization to specific TSP instances, particularly focusing on the finetuning step in DIMES. It suggests clarifying the generalization gaps and proposes a comparison with other methods on TSP100, both with and without metalearning. However, the comment does not specify which part of the paper discusses these generalization gaps or the finetuning step, making it weakly grounded. The authors can infer that it relates to sections discussing the methodology or results, but this inference is not direct. The comment is specific in suggesting improvements, such as clarifying the generalization gaps and comparing with other methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should clarify the generalization to specific TSP instances, particularly focusing on the finetuning step in DIMES. It acknowledges the advantages of DIMES in direct RL training for largescale problems and meta finetuning but emphasizes the need for a clearer explanation of these generalization gaps. Additionally, the comment suggests comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a logical reasoning for the need for clarification, it lacks specific examples or references to support the claim about the generalization gaps. The suggestion to compare with other methods is 3, as it implies a need for further analysis but does not provide detailed guidance. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by clarifying the generalization to specific TSP instances, particularly focusing on the finetuning step in DIMES. It acknowledges the advantages of DIMES in direct RL training for largescale problems and meta finetuning but emphasizes the need for a clearer explanation of these generalization gaps. Additionally, the comment suggests comparing DIMES with other methods on TSP100, both with and without metalearning, which could provide valuable insights into the performance of the method. While the comment identifies a specific area for improvement and offers a relevant comparison, it could be more helpful by providing detailed guidance on how to implement these suggestions or by suggesting specific metrics or analyses to include. Overall, the feedback is 4 as it directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions: \"What were the final thresholds that were used for the results?\" and \"It will also be good for reproducibility if the authors can share the full set of hyperparameters as well.\" These questions are explicit and direct, as they clearly instruct the authors to provide information about the thresholds and hyperparameters used in their experiments. The authors can directly infer that they need to include this information in their draft to ensure reproducibility and clarity. The action is concrete, as it specifies exactly what information is needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises two questions: \"What were the final thresholds that were used for the results?\" and \"It will also be good for reproducibility if the authors can share the full set of hyperparameters as well.\" These questions are specific and address the need for clarity and reproducibility in the paper. However, the comment does not explicitly mention which part of the paper these questions pertain to, such as a results section or a discussion on methodology. The authors can infer that these questions relate to the results and methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its request for additional information. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of two questions asking for clarification on the final thresholds used for the results and the full set of hyperparameters. These are factual inquiries seeking additional information, not opinions or claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two important points: the need for clarity regarding the final thresholds used for the results and the importance of sharing the full set of hyperparameters for reproducibility. These are actionable suggestions that can significantly enhance the transparency and reproducibility of the paper. By addressing these points, the authors can provide readers with a clearer understanding of their methodology and ensure that their work is replicable. The feedback is clear and constructive, offering specific guidance on what information should be included. However, it could be more helpful if it suggested specific ways to present this information or highlighted potential issues that arise from not sharing these details. Overall, the comment is 4 as it directs the authors to important areas for improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion depends on the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. It lacks concrete steps or actionable advice, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the dataset analysis, suggesting that the conclusion about the relationship between readability and question difficulty depends on the method or features used for answer detection. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing what the reviewer is questioning, namely the dependence on features like POS/dependency parse. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the dataset analysis suggests that the readability of RC datasets does not directly affect question difficulty. It provides a specific example, mentioning that the conclusion depends on the method or features used for answer detection, such as POS/dependency parse features. This reasoning is logical and provides a clear basis for challenging the original claim, making the comment 4. However, it could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper, suggesting that the conclusion about the relationship between readability and question difficulty may depend on the method or features used for answer detection. This feedback is 3 as it highlights a critical point that the authors need to reconsider, potentially prompting them to explore the impact of different features on their analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional analyses could be conducted to strengthen their findings. Therefore, while it provides some insight, it does not offer comprehensive support for improvement, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests optimizing Figure 1 to use less whitespace, which is a specific and concrete action. The authors know exactly what needs to be done\u2014reduce the whitespace in the figure. This feedback provides clear guidance on how to improve the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is optimizing the figure to use less whitespace. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace, but it does not provide any justification or reasoning for why this optimization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion to optimize Figure 1 by reducing the whitespace, which is a concrete and actionable piece of feedback. This guidance can help the authors improve the visual presentation of their results, making the paper more professional and easier to read. However, the comment could be more helpful if it provided additional context or explanation on why reducing whitespace is important or how it affects the overall presentation. Despite this, the feedback is clear and actionable, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to show that the morphological fitting results in a more meaningful space, not just better embeddings. While the comment implies that the authors should conduct additional analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further analysis or provide evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the vector space and the morphological variants, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaningfulness of the geometry of the space and suggests that the morphological fitting should result in a more meaningful space, not just better embeddings. The comment provides a clear request for evidence or analysis to support the claim, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to show that the morphological fitting results in a more meaningful space, not just better embeddings. The comment implies that the current approach might not be as effective as intended, but it lacks specific examples, references, or detailed reasoning to support this claim. The authors would need to infer the need for further analysis or evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to demonstrate that the morphological fitting results in a more meaningful space, not just better embeddings. This feedback is valuable as it prompts the authors to consider the practical implications of their findings and to substantiate the significance of their approach. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis. Overall, the comment is 4 as it identifies a key area for improvement and encourages the authors to enhance the interpretability of their results."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper could be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes to make. The authors are left to infer that they need to revise their explanations and expand their related work section, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general critique of the writing quality, suggesting that the authors spend the same space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, it does not specify which sections of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is 1 as it lacks specific references to sections or elements of the paper, and it is not specific because it does not detail what needs to be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing quality of the paper could be improved, specifically noting that the authors spend the same space on explaining basic memory networks and then the forward model. It also mentions that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to support the claim about the writing quality or the missing pieces in the related work. The absence of concrete evidence or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a need for improvement in the writing quality of the paper, specifically pointing out that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for enhancement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships with a recurrent model. While the suggestion is clear, it lacks specific guidance on how to identify or address these improvements. The authors know they need to explore additional properties, but the comment does not provide detailed steps or criteria for doing so. Therefore, the action is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships with a recurrent model. However, the comment does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where these improvements could be explored. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting areas for improvement, such as accuracy or specific properties, but without clear grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. The comment provides a logical reasoning by suggesting that exploring these areas could potentially offer insights into the model\"s performance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore these suggestions on their own, which limits the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider exploring improvements in accuracy or specific properties. It provides a specific example, such as the potential for easier modeling of sequential relationships with a recurrent model, which could be a valuable direction for further investigation. While the comment identifies a potential area for improvement, it lacks detailed guidance or suggestions on how to conduct this exploration or what specific properties to focus on. This makes the feedback 3, as it provides a direction for improvement but does not offer comprehensive guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should test this assumption, it does not provide explicit guidance on how to conduct the test or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should test the assumption but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption should be tested. However, it does not specify which part of the paper this assumption is made in, making it difficult for the authors to identify the exact section that needs attention. While the comment is specific in questioning the assumption, it lacks grounding as it does not provide clear guidance on where this assumption is discussed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it impacts the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the assumption made in the paper regarding the use of d_e as replacements for entity embeddings. It prompts the authors to consider whether this assumption has been tested, which is a relevant and important aspect of validating the methodology. However, the comment does not provide specific guidance or suggestions on how the authors might test this assumption or what kind of testing would be appropriate. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it highlights a critical area for consideration but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the authors arrived at the different components of the \"scoring function\" and the threshold values/ranges. While it points out a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or justifications for these components and thresholds, but it does not specify what those explanations should include. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the \"threshold values/ranges,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of unclear derivations of these components and threshold values/ranges. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is unclear how the authors arrived at the different components of the \"scoring function\" and the threshold values/ranges. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the methodology section, particularly the derivation of the \"scoring function\" and the threshold values/ranges. By pointing out the lack of clarity in these components, the comment highlights a critical gap in the paper that needs to be addressed. However, it does not provide specific suggestions or guidance on how the authors might clarify these aspects, such as recommending additional explanations or examples. While the feedback is 3 in pointing out a significant issue, it could be more actionable with more detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that making factors in a table does not help convey more messages than using pure text, implying that the table does not add any additional information. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the table or why it might be beneficial to include it. Without specific suggestions or actions, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that making factors in a table does not help convey more messages than using pure text, implying that the table does not add any additional information. However, it does not specify which part of the paper this issue is related to, such as a particular table or section. Without explicit references to specific sections or tables, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the table could be improved or how the authors might address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that making factors in a table does not help convey more messages than using pure text, suggesting that the table does not add any additional information. However, the comment lacks specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the presentation of factors in a table, suggesting that it does not effectively convey additional messages compared to using pure text. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might improve the presentation of their factors. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is 2, as it identifies a potential problem but does not offer a comprehensive solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be in one simulation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question, improve their work, or provide additional context. Without any actionable suggestions or instructions, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be in one simulation. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references to the paper\"s content, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what the authors need to address or clarify regarding the number of physical interactions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for clarification about the number of different kinds of physical interactions in a simulation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be in one simulation. While it identifies a potential area for clarification, it does not provide any actionable feedback or suggestions on how the authors might address this question or improve their work. The comment lacks depth and does not offer guidance on what the authors need to consider or how they might enhance their draft. As a result, it is 2, as it only points out a potential area for improvement without providing any actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a specific issue with the model comparison in the paper, noting that the selection of datasets is inadequate due to the lack of categorical features. It highlights that only one dataset has categorical features, while the others are numerical, which may impact the conclusions. Additionally, it points out that one hot encoding is not employed for the categorical dataset, which could negatively affect performance for some models. The comment provides clear and concrete actions for the authors to take, such as considering datasets with categorical features and employing one hot encoding. This level of detail makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"thorough comparison of models on a \"wide range\" of datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features, while the others are numerical. The comment further specifies the problem with one hot encoding not being employed for the categorical dataset, which could negatively affect performance. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the selection of datasets is inadequate due to the lack of categorical features, which are generally more challenging for deep learning models. The reviewer provides a specific example of one dataset with categorical features and notes the absence of one hot encoding, which could negatively impact performance. This claim is supported by logical reasoning and a clear example, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the model comparison in the paper, specifically the lack of datasets with categorical features. It points out that only one dataset has categorical features, while the others are numerical, which may affect the conclusions. The comment also notes the absence of one hot encoding for the categorical dataset, which could negatively impact performance for some models. This feedback is clear and actionable, providing the authors with specific areas to address in their draft. By highlighting these weaknesses, the comment empowers the authors to make significant improvements to their work, making it 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the choice of datasets in Section 4, noting that the two datasets selected are uncommon and potentially problematic for benchmarking. The reviewer suggests that the authors should consider using more relevant datasets, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. While the comment highlights the issue and provides a direction for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should replace the current datasets with more appropriate ones. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the choice of two uncommon IoT datasets, \"FlatCam Face 26\" and \"Headpose detection 11,\" and suggests that these choices are problematic. The comment further recommends better options for IoT benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two IoT datasets is problematic, suggesting that they are uncommon and not widely used. The reviewer provides specific examples of the datasets, such as \"FlatCam Face 26\" and \"Headpose detection 11,\" and notes that the latter was published in 2004 and no longer used recently. The comment also suggests that better options for IoT benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository, would be more appropriate. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be strengthened by referencing more relevant literature or providing a broader context on why these datasets are considered unsuitable. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of datasets in Section 4, noting that the two datasets selected are uncommon and potentially problematic for benchmarking. The reviewer provides logical reasoning by pointing out that \"FlatCam Face 26\" is relatively recent but not widely followed, and \"Headpose detection 11\" was published in 2004 and no longer used recently. This critique highlights a potential weakness in the authors\" choice of datasets, which could make their benchmarking results harder to interpret. The comment also suggests better options for IoT benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, offering specific suggestions for improvement that could enhance the relevance and usability of the datasets. Therefore, the comment is 5, as it provides valuable insights and constructive guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the use of pruning techniques, specifically mentioning that they primarily work with large networks trained in distributed settings. The reviewer suggests that the authors should consider mentioning the necessity of finding global top Q values of the metric over the average of gradients, as this could potentially break acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pruning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the use of pruning techniques, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is 3 as it highlights a potential issue with the use of pruning techniques, particularly in the context of distributed training. However, the comment lacks specific examples or references to substantiate the claim fully, making it 3. The authors would need to further explore and address this issue to fully understand the implications.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of pruning techniques, specifically noting that they primarily work with large networks trained in distributed settings. It suggests that the authors should consider mentioning the necessity of finding global top Q values of the metric over the average of gradients, as this could potentially break acceleration techniques like quantization and sparsification. This feedback is clear and actionable, as it highlights a specific area where the authors might need to address or clarify their methodology. However, the comment could be more helpful if it provided additional context or examples of how this issue might manifest in the paper. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires further exploration or clarification."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures for accuracy, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures and potentially correct any discrepancies. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, prompting the authors to check and verify the figures for accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking for clarification about potential errors in the figures. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment raises a question about potential errors in the figures, specifically asking if some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern. The feedback is vague and lacks actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the improvement in sensitivity provided by the dropout probe and its role in identifying causal relationships in syntactic representations. However, it raises a concern about the increased risk of false positives due to the use of this method. The reviewer suggests that this should be a substantial part of the discussion. While the comment implies that the authors should include this discussion, it does not provide specific guidance on how to integrate this point into the paper or what aspects of the discussion should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion to address this concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the dropout probe and its impact on sensitivity, suggesting that it improves the identification of causal roles in syntactic representations. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment does specify the concern about the increased risk of false positives and suggests that this should be a substantial part of the discussion, providing some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the improvement in sensitivity provided by the dropout probe and its role in identifying causal relationships in syntactic representations. However, it raises a concern about the increased risk of false positives due to the use of this method. The comment suggests that this should be a substantial part of the discussion. While the reviewer provides a logical reasoning for the concern, the comment lacks specific examples or references to support the claim about the increased risk of false positives. This makes the claim 3, as the authors would need to further develop the discussion to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the improvement in sensitivity provided by the dropout probe and its role in identifying causal relationships in syntactic representations. However, it raises a concern about the increased risk of false positives due to the use of this method. The comment suggests that this should be a substantial part of the discussion, indicating that the authors should address this concern in their paper. While the comment identifies a potential weakness in the methodology, it does not provide specific guidance on how to address this issue or suggest ways to mitigate the risk of false positives. The feedback is 3 as it prompts the authors to consider an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font and bottom page margins. It suggests that fixing the formatting would provide some space and allow the NLP experiments to be included in the main body of the paper. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the formatting issues, such as the abstract font size and bottom page margins, which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the formatting and suggests that fixing these issues would provide space for including NLP experiments in the main body of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font and bottom page margins. While the comment identifies specific problems, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include NLP experiments in the main body of the paper is a logical recommendation but does not provide further justification or evidence. Therefore, the comment is 3, as it provides some support but lacks comprehensive details.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that it does not follow the NeurIPS style. It points out particular problems, such as the abstract font being too large and the bottom page margins being altered. The comment suggests that fixing these formatting issues could provide more space and allow the inclusion of NLP experiments in the main body of the paper. This feedback is clear and actionable, offering a concrete step for the authors to take to improve their draft. However, it could be more helpful if it provided additional guidance on how to address the formatting issues or suggested specific changes. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks a discussion and comparison of various exploration methods in reinforcement learning (RL), such as countbased methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific methods should be discussed or compared. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a discussion of these methods, but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a concern about the paper\"s lack of discussion on exploration methods in reinforcement learning (RL), specifically mentioning countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper should include this discussion or comparison, making it weakly grounded. The comment is specific in identifying the need for a discussion on these exploration methods, but without explicit references to sections or specific elements, the authors may struggle to pinpoint where to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare exploration methods in reinforcement learning, such as countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand which methods are missing and how to address the issue. The absence of detailed justification or examples renders the claim 2, as it provides a general critique without sufficient support or guidance for improvement.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that it does not discuss and compare various exploration methods in reinforcement learning (RL), such as countbased methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive discussion of exploration strategies. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending which methods to include or how to structure the discussion. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to enlarge the annotations in Figure 4 for better visibility. This is a direct and concrete action that the authors can easily follow, as it provides a clear and specific instruction on how to improve the figure. The comment does not leave any ambiguity regarding what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done\u2014enlarging the annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 can be enlarged for better visibility. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the figure. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the visibility of annotations in Figure 4. By recommending that the annotations be enlarged, the comment offers a clear and direct way for the authors to enhance the clarity and readability of their figure. This feedback is valuable as it directly addresses a potential issue with the visual presentation of data, which is crucial for effectively communicating results. However, the comment could be more helpful if it included additional context or explanation on why enlarging the annotations is necessary or how it impacts the overall presentation. Despite this, the comment is 4 as it provides a clear and actionable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that multiple entities are typically present in both sentences and documents, even in relation classification, not just at the document level. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or incorporate it into their work. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that multiple entities are typically present in both sentences and documents, even in relation classification, not just at the document level. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that multiple entities are typically present in both sentences and documents, even in relation classification, not just at the document level. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the paper, specifically that multiple entities are typically present in both sentences and documents, even in relation classification, not just at the document level. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that on the color bar in Figure 4, one of the labels should be corrected to \"worse\" instead of the presumably incorrect label. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed. The comment is specific and leaves no ambiguity about the required correction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, stating that one of the labels on the color bar should be corrected to \"worse.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the content of Figure 4, specifically noting that one of the labels on the color bar should be corrected to \"worse.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a clear issue with Figure 4, where one of the labels on the color bar is incorrect. By pointing out the need for correction, the comment provides the authors with a direct and clear direction for improving the accuracy of their figure. This feedback is valuable as it helps the authors ensure that their visual representation aligns with the intended message, enhancing the clarity and correctness of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct a specific typo in the text, noting that \"training/validation/test\" should be \"training/validation/test sets\". This is a clear and direct action that the authors can easily follow, as it specifies exactly what needs to be changed. The comment provides concrete guidance on how to implement the correction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correction needed, which is changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a typo in the text, specifically mentioning that \"training/validation/test\" should be \"training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific typo in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable piece of feedback that directly points out an error in the manuscript. By correcting this typo, the authors can improve the clarity and professionalism of their draft. The comment is concise and provides a straightforward suggestion for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, such as the impact of inference speed and the coefficient of the p(L, E | X) term in line 307. It also notes that hyperparameter details are missing, which could affect the clarity of the writing and the understanding of the results. While the comment identifies areas for improvement, it does not provide explicit actions or suggestions on how to address these issues. The authors are left to infer that they need to clarify the impact of inference speed, provide the coefficient value, and improve the writing to enhance clarity. However, the lack of concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the paper\"s content, such as the impact of inference speed and the coefficient of the p(L, E | X) term in line 307. It also mentions the absence of hyperparameter details and the potential impact on the clarity of the writing. However, the comment does not explicitly mention which sections or parts of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as the coefficient value and the clarity of the writing. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, such as the impact of inference speed and the coefficient of the p(L, E | X) term in line 307. It also notes the absence of hyperparameter details, which could affect the clarity of the writing. While the comment identifies areas for improvement, it lacks specific evidence or references to support these claims. The authors are left to infer the significance of these observations, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could impact the understanding and evaluation of the paper. It questions the potential slowdown in inference and the lack of clarity in the writing, which are critical for the validity and comprehensibility of the research. The comment also points out the absence of hyperparameter details, which could affect the reproducibility and robustness of the results. While the comment identifies key areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Providing more detailed feedback or actionable steps would enhance its helpfulness. Therefore, the comment is 3, as it highlights important areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding an extra pair of brackets around the term \"1 | D | \u2211 ( X r , Y r ) \u2208 D 1 S ( X r , Y r ) \u2264 s\" to make the definition clearer. It also provides a concrete suggestion to define the bracketed term separately if space allows. These specific actions give the authors clear guidance on how to improve the clarity of their definition. The comment is explicit and provides detailed instructions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely adding an extra pair of brackets around the term \"1 | D | \u2211 ( X r , Y r ) \u2208 D 1 S ( X r , Y r ) \u2264 s\" to enhance clarity. This guidance is actionable and provides a concrete step for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of the quantile is confusing and suggests adding an extra pair of brackets to improve clarity. However, the comment does not provide any supporting evidence, examples, or references to justify why the current definition is confusing or how the suggested change would enhance clarity. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the definition of the quantile, noting that it is confusing. It provides a concrete suggestion for improvement by recommending the addition of an extra pair of brackets around the term to enhance clarity. This feedback is actionable and offers a clear path for the authors to improve the readability and understanding of their work. However, the comment could be more helpful if it included additional suggestions or examples of how the quantile definition could be further clarified. Overall, the comment is 4 as it provides a specific and actionable piece of feedback, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing the model by Dozat and Manning (2016) with a more current and higherperforming model. This feedback provides a clear and explicit action for the authors to take, specifying that they should replace the model with a more uptodate one. The suggestion is concrete, as it offers specific alternatives (\"very high performing model\" or similar), giving the authors a clear idea of what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a \"very high performing model.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the model by Dozat and Manning (2016) with a more current and highperforming model. However, the comment does not provide any justification or reasoning for why this model is no longer stateoftheart or how the proposed replacement would improve the paper. Without supporting evidence or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the replacement of the model by Dozat and Manning (2016) with a more current and highperforming model. This feedback is actionable and offers a clear direction for the authors to enhance the relevance and timeliness of their work. However, the comment could be more helpful if it provided additional context or explanation on why the original model is no longer stateoftheart or what specific aspects of the new model would be beneficial. Despite this, the suggestion is clear and actionable, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed compression method, specifically noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper this observation is made in, such as a particular section, table, or figure. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in detailing the issue, it is 1 because it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, suggesting this as a main weakness of the method. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed justification or comparison, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is an important observation that could impact the practicality and effectiveness of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including the use of subjective statements, the need for proofs and references to support claims, and the complexity of multiscale architecture design. It suggests that the authors provide a detailed explanation to verify these statements. While the comment highlights specific areas that need attention, it does not offer concrete guidance on how to address these issues or what specific changes should be made. The authors are left to infer the necessary actions, making the comment 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the use of subjective statements, the need for proofs and references, and the complexity of multiscale architecture design. However, it does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing proofs and references, and clarifying the complexity of multiscale architecture design. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the use of subjective statements, the need for proofs and references, and the complexity of multiscale architecture design. The reviewer provides specific examples, such as the mention of \"image recovery performance is sensitive to the choice of neural architecture\" and the task of \"fusing multiscale features,\" which adds some verifiability. However, the comment lacks detailed reasoning or references to support the claims about the laborintensive nature of seeking an effective architecture or the sensitivity of image recovery performance. While the reviewer provides some context, the lack of comprehensive evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the use of subjective statements, the need for proofs and references to support claims, and the complexity of multiscale architecture design. It provides specific examples, such as the sensitivity of image recovery performance to neural architecture choices and the task of fusing multiscale features. The comment suggests that the authors provide a detailed explanation to verify these statements, which is a constructive piece of feedback. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity and rigor of the paper. Overall, the comment is 4 as it highlights areas for improvement and encourages the authors to enhance the quality of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific comparisons should be made or how the authors might address this question. Without any actionable suggestions or detailed instructions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method compares with prior art, but it does not specify which part of the paper this comparison should be made in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this comparison should be addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison should be considered or how it should be structured. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for a comparison of the proposed method with prior art. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art, which is a relevant and important aspect for evaluating the novelty and impact of the work. However, the comment does not provide any specific guidance or suggestions on how the authors might address this comparison, such as recommending specific prior works to consider or outlining a framework for comparison. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of 20 different language/nationality types. It implies that the authors should explore biases towards different languages/nationalities and consider making interesting observations by comparing them. While the comment provides a general direction for improvement, it lacks specific guidance on which aspects to focus on or how to conduct the analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"language/nationality\" and the specific data types included, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring biases towards different languages/nationalities and making interesting observations by comparing them. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the analysis could be more detailed by exploring biases towards different languages/nationalities. It provides an example of the data types included, such as Japanese, Chinese, English, Arabic, and German, and mentions the potential for interesting observations by comparing them. This claim is 3 as it provides a specific example of a potential area for further analysis, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the need for more detailed analysis based on this feedback, making it 3.", "helpfulness_rationale": "The review comment suggests that the analysis could be more detailed by exploring biases towards different languages/nationalities. It provides a specific example of the data types included, such as Japanese, Chinese, English, Arabic, and German, and suggests that comparing these could lead to interesting observations. This feedback is 3 as it identifies a potential area for improvement and provides a direction for further analysis. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what specific comparisons might be insightful. Overall, the comment provides some actionable insight but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using additional properties of features beyond the norm, which could be beneficial for their approach design. While the comment implies that the authors should explore other feature properties, it does not explicitly instruct them to do so or provide specific guidance on which properties to consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore other feature properties but may not know exactly which ones to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional properties of features beyond the norm, which could be beneficial for the approach design. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore other feature properties, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that besides the norm, there might be other properties of features that could be used, which could be beneficial for the approach design. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it could be implemented. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that besides the norm, there might be other properties of features that could be used, which could be beneficial for the approach design. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on which properties to consider or how they could be integrated into the approach. This limits the utility of the feedback for the authors, as it does not offer actionable steps or examples to enhance their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of two SIRENs for f and d, suggesting that d should be a simpler network. While the comment implies that the authors should consider simplifying the network for d, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the network and may not be entirely sure how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of two SIRENs for f and d, suggesting that d should be a simpler network. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of two SIRENs for f and d, suggesting that d should be a simpler network. However, it does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it could be addressed. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the methodology section, specifically questioning the use of two SIRENs for both f and d. It suggests that d should be a simpler network, which could be a valuable insight for the authors to consider. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out an area for potential improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the RQ1 mentioned in the paper is redundant and does not add extra information for the audience. It suggests that the authors should consider analyzing how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and how this relates to RQ2 and RQ3. The comment also provides a reference for further reading. While the comment identifies a redundancy issue and suggests an interesting area for analysis, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the redundancy of RQ1 in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis regarding the relationship between the percentage of explicit hate information in the dataset and implicit hate speech detection performance, as well as its effect on RQ2 and RQ3. The comment provides a reference for further reading, which adds context to the suggestion. However, the comment does not specify which part of the paper discusses RQ1, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not add extra information for the audience. It suggests that the authors should consider analyzing the relationship between the percentage of explicit hate information in the dataset and implicit hate speech detection performance, as well as its effect on RQ2 and RQ3. The comment provides a reference for further reading, which adds some support to the claim. However, the reasoning is somewhat vague and lacks specific examples or detailed explanations of why this analysis would be beneficial. Therefore, the comment is 3, as it provides some justification but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a redundancy in the RQ1 mentioned in the paper, suggesting that it does not add extra information for the audience. It provides a specific suggestion for improvement by proposing an interesting point for analysis regarding the relationship between the percentage of explicit hate information in the dataset and implicit hate speech detection performance, as well as its effect on RQ2 and RQ3. The comment also references a specific paper for further reading, which adds context to the suggestion. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft by exploring additional analytical aspects. However, it could be more helpful if it provided more detailed guidance on how to conduct this analysis or what specific insights to seek. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where PE (Probabilistic Embedding) is important. However, it does not provide any explicit guidance or suggestions on how to achieve this, nor does it specify which tasks should be included or how they should be integrated into the paper. The action is implicit and vague, as the authors are left to infer that they need to expand the scope of tasks where PE is important but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where Probabilistic Embedding (PE) is important. However, it does not specify which tasks should be included or how they should be integrated into the paper, nor does it provide any guidance on how to achieve this. The authors cannot confidently determine which part of the paper this comment is addressing, as it does not explicitly mention a section or task. Therefore, the comment is 1 and lacks specificity, making it 1 at all.", "verifiability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where Probabilistic Embedding (PE) is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where Probabilistic Embedding (PE) is important. However, it lacks specificity and does not provide any guidance on which tasks should be included or how they should be integrated into the paper. Without additional context or suggestions, the authors are left with a vague idea of what needs to be expanded, making the comment 3. It points out a potential area for improvement but does not offer detailed feedback or actionable steps for the authors to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should elaborate on the differences between their work and other works that focus on semantic face editing, such as 1. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine how to effectively highlight the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should elaborate on the differences between their work and other works focusing on semantic face editing, such as 1. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in its request for elaboration on the differences, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should elaborate on the differences between their work and other works focusing on semantic face editing, such as 1. However, the comment does not provide specific examples or detailed reasoning to support why this comparison is necessary or how it would benefit the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 2, as it provides a general suggestion without sufficient evidence or detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should elaborate on the differences between their work and other works focusing on semantic face editing, such as 1. This feedback is 3 as it identifies a potential area for improvement, prompting the authors to provide more context and comparison. However, the comment lacks specificity and does not offer detailed guidance on how to address this issue or what aspects of the comparison should be highlighted. To be more helpful, the comment could include examples or specific questions to guide the authors in their response. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that footnotes are used excessively and distracting, recommending that important content be moved into the main body of the paper. It also provides a specific example, such as moving details around parameter settings into the appendix, to illustrate the proposed changes. This feedback is clear and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes\" and provides a specific suggestion to move important content into the main body of the paper, such as details around parameter settings. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue with the excessive use of footnotes and provides a concrete suggestion for improvement by moving details to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively and distracting, suggesting that important content should be moved into the main body of the paper. The comment provides a specific example, such as moving details around parameter settings into the appendix, to illustrate the proposed changes. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more examples or references to similar practices in the field. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the excessive use of footnotes in the paper, which can be distracting and detract from the clarity of the content. It provides a clear and actionable suggestion to move important content into the main body of the paper, such as details around parameter settings, which can be moved to the appendix to save space. This feedback is specific and offers a concrete way for the authors to improve the readability and structure of their paper. By addressing this issue, the authors can enhance the overall quality and professionalism of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also implies that a discussion about this topic would be beneficial. Additionally, the reviewer questions the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity about the capabilities of the LLM in this setting. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific aspects should be discussed. The actions are implicit and somewhat vague, as the authors need to infer what needs to be done and how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a set of fewshot demonstrations and a discussion about them, implying that this would be beneficial. It also questions the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity about the capabilities of the LLM in this setting. However, the comment does not specify which part of the paper should include these discussions or demonstrations, making it weakly grounded. The suggestion to include a discussion about fewshot demonstrations is specific, but the overall comment lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results might be strange and questions its relevance. However, it does not provide specific reasoning or examples to support why zeroshot generation results might be considered strange or how they could be integrated into the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the inclusion of zeroshot generation results might be strange and questions its relevance. It implies that a discussion about fewshot demonstrations could be beneficial, but it does not provide specific guidance or suggestions on how to incorporate these elements into the paper. While it identifies a potential area for improvement, the comment lacks actionable feedback and detailed advice, making it 3. The authors are given a hint about a possible enhancement but are not provided with clear steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that \"OAA\" is never referenced in the body text and suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific issue with Figure 3, it does not provide explicit guidance on how to address the problem. The authors are left to infer that they need to reference \"OAA\" in the body text or ensure that the caption is accurate and uptodate. The action is implicit and somewhat vague, as the authors need to determine the exact steps to take to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the reference \"OAA\" not being mentioned in the body text and suggests that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the reference \"OAA\" not being mentioned in the body text of Figure 3. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. However, the comment does not provide specific examples or detailed reasoning to support the claim that \"OAA\" is missing or that the caption is outdated. Without further elaboration or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment highlights a potential gap in the paper\"s presentation, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a critical oversight, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the introduction by specifying that the proposed solution is a \"fix\" of 12, rather than a new PIC approach. It provides a clear action by mentioning the specific lines where the authors should make this clarification, namely lines 2930. The comment also suggests that the authors mention the previously proposed framework by 12. This level of detail provides concrete guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and specific lines (2930) where the authors should clarify their claim. It specifies the issue by pointing out that the proposed solution is described as a \"fix\" of 12, rather than a new PIC approach, and suggests that the authors mention the previously proposed framework by 12. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed solution is a \"fix\" of 12, rather than a new PIC approach. The comment provides a specific reference to lines 2930, where the authors describe their framework as a \"fix\" of 12. This direct reference to a specific part of the paper and the mention of a previously proposed framework by 12 provide sufficient justification for the claim, making it 5. The authors can easily understand and address the issue by incorporating this information into their draft.", "helpfulness_rationale": "The review comment is 5 as it provides clear and actionable feedback by identifying a specific area of the paper that needs clarification. It explicitly instructs the authors to clarify the introduction by specifying that the proposed solution is a \"fix\" of 12, rather than a new PIC approach. The comment also directs the authors to mention the previously proposed framework by 12, which is referenced in lines 2930. This guidance helps the authors improve the clarity and accuracy of their paper, ensuring that readers understand the novelty and context of their proposed solution. The detailed and constructive nature of the feedback makes it 5 for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved by using the GS module, referencing a specific source 2. While it implies that the authors should investigate this aspect, it does not provide explicit instructions or concrete guidance on how to conduct this investigation. The action is implicit and somewhat vague, as the authors need to infer that they should explore the effective receptive field and its changes after applying the GS module. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and the \"effective receptive field,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the question regarding the improvement of the effective receptive field and its changes after applying the GS module, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the improvement of the effective receptive field when using the GS module, referencing a specific source 2. However, it does not provide any detailed reasoning or evidence to support the claim that the effective receptive field is improved. The reference to 2 is not provided, making it difficult for the authors to understand the context or relevance of the claim. As a result, the comment is considered 1 due to the lack of supporting evidence or detailed explanation.", "helpfulness_rationale": "The review comment raises a question about the improvement of the effective receptive field when using the GS module, referencing a specific source 2. This question prompts the authors to investigate and potentially address this aspect, which could enhance the understanding of how the GS module impacts the model\"s receptive field. However, the comment does not provide specific guidance or suggestions on how to conduct this investigation or what aspects to focus on. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific suggestion for the LSTM part, indicating that the objective for pretraining and finetuning should be the same, involving the probabilities of the actions. It also suggests that in the finetuning stage, the authors may add another head to the network to compute the value functions for the states. This feedback is explicit and provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment provides a specific suggestion regarding the LSTM part, indicating that the objective for pretraining and finetuning should be the same, involving the probabilities of the actions. It also suggests adding another head to the network for computing value functions in the finetuning stage. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides a specific suggestion regarding the LSTM part, indicating that the objective for pretraining and finetuning should be the same, involving the probabilities of the actions. It also suggests adding another head to the network for computing value functions in the finetuning stage. However, the comment lacks detailed reasoning or examples to support why this approach is beneficial or necessary. Without further explanation or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the LSTM part of the paper. It suggests that the objective for pretraining and finetuning should be the same, involving the probabilities of the actions, and proposes adding another head to the network for computing value functions in the finetuning stage. This feedback is clear and actionable, offering a concrete way for the authors to enhance their methodology. By addressing this suggestion, the authors can potentially improve the consistency and effectiveness of their approach. However, the comment could be more helpful if it included additional context or explanation on why this change is beneficial. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide a rationale for this combination, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to explain the rationale, but it lacks concrete guidance on how to address this question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the rationale and requirements, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC (i.e., HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This is a relevant and specific inquiry that could help the authors clarify the motivations and underlying principles of their methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning a long line of work that uses supervised, multilingual systems. While the comment implies that the authors should include these older works, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these older works but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning a long line of work that uses supervised, multilingual systems. However, the comment does not provide any specific examples or references to support this suggestion, nor does it explain why acknowledging these older works would be beneficial. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning a long line of work that uses supervised, multilingual systems. This feedback is 3 as it points out a potential area for improvement, encouraging the authors to broaden their literature review and include a wider range of relevant works. However, the comment lacks depth and does not provide specific examples or guidance on how to incorporate these older works into the paper. While it offers a direction for improvement, it does not fully support the authors in making those changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, suggesting that the linear/exponentialdecay sampling appears to underperform compared to uniform sampling. The reviewer implies that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The action is implicit and somewhat vague, as the authors need to infer that they should consider adjusting the sampling strategy or provide additional analysis to clarify the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results in Table 2, questioning why linear/exponentialdecay sampling appears to underperform compared to uniform sampling. The comment further provides a logical reasoning by suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why linear/exponentialdecay sampling appears to underperform compared to uniform sampling. The reviewer provides a logical reasoning by suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. This reasoning is based on the assumption that the performance of architectures in the good subregion is close, which is a reasonable argument. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore and substantiate this reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically questioning why linear/exponentialdecay sampling appears to underperform compared to uniform sampling. It provides a logical reasoning by suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. This feedback is 3 as it identifies a potential issue with the results and offers a plausible explanation for it. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this issue or further investigate the performance differences. Overall, the comment offers some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The feedback lacks actionable details, such as recommending specific optimizations or alternative approaches to reduce time complexity. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity is high due to the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment identifies specific issues, it lacks detailed reasoning or references to substantiate these claims. The authors would need to infer the basis of these claims, making the comment 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies several potential issues with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While it highlights these areas, the comment lacks actionable suggestions or guidance on how the authors might address these concerns or improve the efficiency of their method. Without specific recommendations or alternative approaches, the feedback provides limited value to the authors in terms of improving their draft. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to address them."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mentioned \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This feedback provides a clear and explicit action for the authors to take, which is to label the figures with the specific terms mentioned. The comment is specific and gives a direct instruction on how to improve the clarity of the figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures would be clearer if they explicitly mentioned \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not specify which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to clarify the figures, but without clear grounding, the authors may struggle to identify which figures need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they explicitly mentioned \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the clarity of the figures. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the figures by suggesting that they would be clearer if they explicitly mentioned \"pretrained solution encoders & solution decoders,\" given the variety of autoencoders present. This feedback is actionable and provides a clear direction for enhancing the clarity and understanding of the figures. However, it could be more helpful if it offered additional suggestions or examples of how to effectively incorporate these terms into the figures. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also recommends a comparison with occlusion experiments, but the comment does not specify whether this is relevant or how it should be conducted. The mention of the occlusion experiment is noted as minor, but the authors are left to infer that it might not be relevant. The action is explicit regarding the comparisons with NeRFbased methods but is vague regarding the occlusion experiment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" and recommends a comparison with occlusion experiments. However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, but without clear guidance on where to place them, the authors may struggle to identify the exact sections to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" and recommends including these comparisons. However, the comment does not provide specific reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. Additionally, the mention of the occlusion experiment is noted as minor, but without further elaboration, it is difficult for the authors to understand the relevance or importance of this aspect. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of these comparisons and experiments themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper lacks comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" and recommends including these comparisons. It also notes that the occlusion experiment does not seem relevant to the method\"s proposal, which is a minor point. While the comment identifies a specific area for improvement by suggesting additional comparisons, it does not provide detailed guidance on how to conduct these comparisons or what aspects of the method should be highlighted. The feedback is 3 as it points out a potential weakness in the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that a brief explanation of \"multiaspect\" would be helpful, which provides a clear action for the authors to take. Additionally, it questions the subscripts in Figure 1, suggesting they should be 1 and 2. This feedback is concrete and specific, as it clearly indicates what needs to be addressed and how to do so. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (Line 14, 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed: a brief explanation of \"multiaspect\" and questioning the subscripts in Figure 1. This provides clear guidance on what changes are needed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. Neither part contains subjective claims or opinions that require verification. The first part is a request for clarification, and the second part is a question seeking additional information. Both are factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that a brief explanation of \"multiaspect\" would be helpful, which can enhance the clarity of the paper. Additionally, it questions the subscripts in Figure 1, suggesting they should be 1 and 2. This feedback is clear and directly points out areas for improvement, offering the authors a clear path to enhance the comprehensibility and accuracy of their work. However, the comment could be more helpful if it provided additional context or explanation on why the subscripts are important or how they should be interpreted. Overall, the comment is 4 as it effectively guides the authors in making necessary improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the extraction of parts of sentences and documents, specifically asking how these are extracted and whether the extraction rules affect the experiment. It also expresses a desire for a more detailed analysis. While the comment implies that the authors should provide more information on the extraction process and its impact on the experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a detailed analysis of the extraction process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the extraction of parts of sentences and documents, and whether the extraction rules affect the experiment. The comment further requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the extraction of parts of sentences and documents, and whether the extraction rules affect the experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how these are extracted and whether the extraction rules impact the experiment. It also expresses a desire for a more detailed analysis. While the comment identifies a potential area for clarification, it lacks specific suggestions or guidance on how the authors might address these questions or improve their analysis. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for information about the computational requirements of the experiments, specifically asking how long the experiments took and on what kind of hardware they were conducted. This is a direct and explicit request for additional details that the authors should include in their paper. The comment provides clear guidance on what information is needed, making it 5. The authors know exactly what additional data they need to provide to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment asks for information about the computational requirements of the experiments, specifically asking how long the experiments took and on what kind of hardware they were conducted. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its request for additional details, but without clear grounding, the authors may struggle to determine where to incorporate this information. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements of the experiments, specifically asking for the time taken and the hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computational requirements of the experiments, specifically asking for the time taken and the hardware used. This feedback is clear and actionable, as it directs the authors to provide specific details that could enhance the transparency and reproducibility of their work. By addressing this request, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it suggested ways to present this information or highlighted the importance of this data in the context of the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. While the comment implies that the authors should provide more discussion on this aspect, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to expand their discussion on the application of the meta sampler. However, the comment lacks concrete guidance on how to address this issue, such as suggesting specific points to discuss or examples to include. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the application of the meta sampler and the timing of its use, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification on the application of the meta sampler. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. This is a relevant and actionable question that could help the authors clarify their methodology and improve the transparency of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional discussion or examples. While it identifies a potential area for improvement, the feedback could be more helpful if it offered more detailed guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to use related fairnessaware metrics like Equality odds (EO) and to conduct more experiments on specific datasets such as COMPAS and Drug Consumption. It also directs the authors to follow a cited AAAI paper for guidance. These instructions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment suggests using related fairnessaware metrics like Equality odds (EO) and recommends conducting experiments on specific datasets like COMPAS and Drug Consumption. It also references a cited AAAI paper for guidance. However, the comment does not specify which part of the paper discusses the current metrics or where the authors should incorporate these suggestions. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper need revision. Despite this, the comment is specific in its suggestions for improvement, such as using Equality odds and conducting experiments on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use related fairnessaware metrics like Equality odds (EO) and conduct experiments on specific datasets like COMPAS and Drug Consumption. It references a cited AAAI paper for guidance, which provides a basis for the suggestion. However, the comment lacks detailed reasoning or examples of how these metrics or datasets would improve the paper or what specific aspects of the current work could be enhanced by their inclusion. This makes the claim 3, as it provides a general direction for improvement but lacks specific guidance or evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of related fairnessaware metrics, such as Equality odds (EO), and recommending additional experiments on specific datasets like COMPAS and Drug Consumption. It also directs the authors to a cited AAAI paper for guidance, which can help them understand the context and importance of these metrics. This feedback is clear and constructive, offering a clear path for the authors to enhance their work by incorporating fairness considerations and expanding their experimental scope. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to address the speculative or opinionated nature of the content in lines 107114. It suggests that this should be stated as a remark, included in a Discussion section, or removed. This provides clear and direct guidance on how to improve the draft, making the comment 5. The authors know exactly what action to take to address the issue, which aligns with the criteria for a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the speculative or opinionated nature of the content in those lines, and suggests that it should be stated as a remark, included in a Discussion section, or removed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the content in lines 107114 is speculative or overly opinionated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as speculative or overly opinionated, suggesting that it should be presented as a remark, included in a Discussion section, or removed. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and appropriateness of their content. By addressing this issue, the authors can enhance the quality and coherence of their paper. However, the comment could be more helpful if it offered additional guidance on how to rephrase the speculative content or provided examples of how to integrate it into a discussion section. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines like Rope and Alibi relative positional embeddings to verify the performance improvement from the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines like Rope and Alibi relative positional embeddings to verify performance improvements. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result where these baselines should be considered. This lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the suggestion is specific in terms of what could be added, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests considering baselines like Rope and Alibi relative positional embeddings to verify performance improvements. However, it does not provide any specific reasoning or evidence to support why these baselines are relevant or how they would impact the evaluation. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests considering baselines like Rope and Alibi relative positional embeddings to verify the performance improvement from the changes suggested in the paper. This feedback is 3 as it provides a specific direction for the authors to enhance their evaluation by comparing their results against established baselines. However, the comment could be more helpful if it offered additional guidance on how to implement these baselines or why they are particularly relevant. Overall, the comment offers some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two key areas for improvement: the value of the neighborhood size h and the analysis of its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. While the comment explicitly states the need for analysis and provides a clear direction for the authors to take, it does not offer specific guidance on how to conduct this analysis or what aspects to focus on. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the missing value of the neighborhood size h and the analysis of its influence on the model\"s performance. It also mentions the use of different hyperparameter sets per dataset, which is not ideal. The comment is fully grounded as it explicitly mentions the need for analysis and provides clear guidance on what needs to be addressed. It is also specific because it details the importance of the neighborhood size h and the potential issues with varying hyperparameters across datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing an analysis of the neighborhood size h and its influence on the model\"s performance. It also notes that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of these elements themselves, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two critical areas for improvement in the paper: the analysis of the neighborhood size h and its influence on the model\"s performance, as well as the inconsistency in using different hyperparameter sets per dataset. It provides a clear and actionable suggestion for the authors to conduct a comprehensive analysis of the neighborhood size h, which is essential for understanding the key parameter of the proposed strategy. Additionally, the comment highlights the need for robustness testing with varying neighborhood sizes and suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is 4 as it directs the authors to specific areas for improvement and offers a clear path for enhancing the paper\"s rigor and comprehensiveness. However, it could be more helpful if it included specific examples or guidance on how to conduct the analysis. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the SST dataset, suggesting that the authors should show statistics on how negation or intensity words affect the dataset. However, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit, as the authors can infer that they need to include such statistics, but the comment lacks detailed guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely showing statistics on how negation or intensity words affect the dataset, specifically mentioning the word \"nothing\" and its impact on polarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or recommendations that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the SST dataset, specifically asking for statistics on how negation or intensity words affect the dataset. It suggests showing how many times words like \"nothing\" appear and how they change the polarity of the context. This feedback is 3 as it identifies a potential area for improvement in the analysis of the dataset. However, it lacks depth and does not provide specific guidance or suggestions on how to address the issue, such as recommending particular statistical measures or methods to include. Therefore, the comment offers some insight but is incomplete, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the authors\" work, specifically the lack of verification of the stability of the OGEAug model on OOD benchmarks like DrugOOD, where SPE is validated. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should conduct additional stability checks, but it does not specify which aspects of the model or benchmarks need to be examined or how to implement these checks. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the authors\" work, namely the lack of verification of the stability of the OGEAug model on OOD benchmarks like DrugOOD. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where the stability of OGEAug is discussed. The mention of \"SPE 2\" suggests that the authors might be referring to a specific section or figure, but without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue but weakly grounded due to the lack of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of the OGEAug model on OOD benchmarks like DrugOOD, where SPE is validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" work, noting that they do not verify the stability of the OGEAug model on OOD benchmarks like DrugOOD, where SPE is validated. This feedback highlights a potential gap in the experimental validation process, which is crucial for ensuring the reliability and robustness of the model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to assess stability. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider additional approaches, such as freezing some layers of the model or using parameterefficient methods like LoRA, in addition to applying SVD to the BERT embedding. While the comment implies that these methods should be explored, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include these methods in their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional approaches, such as freezing some layers of the model or using parameterefficient methods like LoRA, in addition to applying SVD to the BERT embedding. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or method discussed in the draft. The authors might infer that it relates to the experimental methods or results section, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering additional approaches, such as freezing some layers of the model or using parameterefficient methods like LoRA, in addition to applying SVD to the BERT embedding. While the comment provides a logical suggestion for expanding the experimental methods, it lacks specific examples or references to support why these methods are relevant or beneficial. The claim is 3 as it offers a plausible direction for improvement but requires more detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests considering additional approaches, such as freezing some layers of the model or using parameterefficient methods like LoRA, in addition to applying SVD to the BERT embedding. This feedback is valuable as it provides a clear direction for the authors to explore alternative methods that could enhance the efficiency and effectiveness of their experiments. By suggesting these methods, the comment offers a constructive way for the authors to improve their draft, potentially leading to more comprehensive and impactful results. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these methods. Overall, the feedback is 4 as it directs the authors toward meaningful improvements in their experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests expanding the related work section by comparing it to strong baselines that use coordinates. While the action is explicit, it lacks concrete details on how to implement this comparison or which specific baselines should be considered. The authors know they need to expand the section, but they are not provided with specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the related work section by comparing it to strong baselines that use coordinates. However, it does not specify which part of the related work section needs to be expanded or how the comparison should be structured. The authors might infer that it refers to the introduction or literature review sections, but this inference is not direct. The comment is specific in suggesting a comparison to strong baselines, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing it to strong baselines that use coordinates. However, it does not provide any specific examples or references to these baselines, making it difficult for the authors to understand which baselines should be considered or how to effectively incorporate them into the related work section. The lack of detailed justification or evidence makes the claim 2, as the authors would need to make an educated guess about the content of the comment. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests expanding the related work section by comparing it to strong baselines that use coordinates. This feedback is 3 as it identifies a potential area for improvement, which is the inclusion of relevant baselines in the related work section. However, the comment lacks specificity and does not provide detailed guidance on which baselines should be considered or how to effectively incorporate them into the section. Without more detailed suggestions, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include multiple seed runs to better assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. While the comment implies that multiple seed experiments should be conducted, it does not explicitly instruct the authors to do so. However, the suggestion is concrete, as it provides a clear action for the authors to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments being limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. However, it does not specify which part of the paper discusses the experiments or where the single seed experiments are mentioned, making it weakly grounded. The comment is specific in suggesting that multiple seed experiments would provide a more robust evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests that multiple seed experiments would provide a more robust evaluation. However, the comment lacks specific examples or references to support the claim about the limitations of single seed experiments. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental design, specifically the use of a single seed for training, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it provides a specific suggestion for improving the robustness and reliability of the experimental results. However, the comment could be more helpful if it included additional guidance on how to implement multiple seed experiments or why this approach is beneficial. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it implies that the authors should provide a clearer explanation or motivation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain the motivation for their choice of distributions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these distributions are discussed. This makes it difficult for the authors to pinpoint the exact location in the paper that needs clarification. While the comment is specific in questioning the motivation, it lacks grounding as it does not provide clear guidance on where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any supporting evidence, reasoning, or references to justify why these distributions are chosen or why their use is questioned. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions for addressing this issue. The comment lacks depth and actionable advice, making it 2. The authors are left with a general inquiry but no clear path to improve their draft. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation of the proposed method, stating that an entire multiGPU setup is required for optimizations, making it inaccessible to many potential users. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggest alternatives that might make the method more accessible. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, stating that an entire multiGPU setup is required for optimizations, making it inaccessible to many potential users. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that an entire multiGPU setup is required for the optimizations in the proposed method, making it inaccessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, specifically that it requires an entire multiGPU setup for optimizations, which may make it inaccessible to many potential users. This feedback is 3 as it highlights a potential barrier to accessibility, prompting the authors to consider whether the method\"s requirements are too restrictive. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or make the method more accessible. Therefore, the feedback is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that there is a missing citation for the public skipgram data set in L425. This is a clear and direct action for the authors to take, as they need to add the appropriate citation to properly acknowledge the source of the data set. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing citation for the public skipgram data set. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement about the absence of a citation for the public skipgram data set in L425. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable piece of feedback that directs the authors to address a potential oversight in their work. By providing a direct suggestion for improvement, the comment empowers the authors to enhance the accuracy and completeness of their references, which is crucial for the credibility and proper acknowledgment of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics, using Ref2 as a strong baseline. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects should be focused on. The action is implicit and vague, as it lacks concrete details on how to implement the suggested comparison or what specific performance metrics should be evaluated. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, using Ref2 as a baseline. However, it does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to conduct the comparison or what aspects should be considered. The authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity regarding the details of the comparison. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, using Ref2 as a baseline. However, the comment lacks specific details or examples to support this claim, such as what aspects of the systems should be compared or how Ref2 can be used as a baseline. Without this information, the authors may find it challenging to understand and implement the suggested comparison. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics, using Ref2 as a strong baseline. While the comment identifies a potential area for improvement by suggesting a comparison with another system, it lacks specific guidance on how to conduct this comparison or what aspects should be focused on. The suggestion is 3 as it provides a direction for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of how quantitative results are obtained, specifically questioning what data is used for training, validating, and testing. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the data sources used in their experiments, but the comment lacks concrete details on how to implement this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how quantitative results are obtained, specifically questioning what data is used for training, validating, and testing. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the data sources used in the experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of how quantitative results are obtained, specifically asking what data is used for training, validating, and testing. This is a request for clarification rather than a subjective claim or opinion. It does not make any assertions that require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the quantitative results, asking for clarification on what data is used for training, validating, and testing. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology, which is crucial for understanding and replicating their results. However, the comment could be more helpful if it suggested ways to improve the clarity of the description or provided examples of how to present the data sources effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspects of the model\"s performance are unclear or what specific issues need to be addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their model. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to enhance their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the utility of the SE framework and requests clarification on how it can improve the work. It also suggests that the authors should provide more detailed explanations of their methods, similar to a previous comment. The reviewer provides a reference to support the request for clarification, which gives the authors a concrete example of how to improve their draft. The comment is explicit in its request for additional information and provides a specific reference for further guidance, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the utility of the SE framework and requests clarification on how it can improve the work. It also suggests that the authors should provide more detailed explanations of their methods, similar to a previous comment. The reference to a specific paper by Luo et al. provides a concrete example of how to improve the draft. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the utility of the SE framework and requests clarification on how it can improve the work. It also suggests that the authors should provide more detailed explanations of their methods, similar to a previous comment. The comment does not contain any subjective claims or opinions but rather requests additional information and clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the utility of the SE framework and requests clarification on how it can improve the work. It also suggests that the authors should provide more detailed explanations of their methods, similar to a previous comment. The inclusion of a reference to a specific paper by Luo et al. provides a concrete example of how to improve the draft, offering a clear direction for the authors to enhance their work. This feedback is 4 as it guides the authors to provide more comprehensive explanations and justifications for their methodology, which can significantly improve the clarity and impact of their paper. However, it could be more helpful if it included specific suggestions on how to address the questions or improve the explanations. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views, suggesting that it should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the approach. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views, suggesting that it should generalize to more views. However, it does not specify which part of the paper this question pertains to, such as a particular section, method, or results. Without explicit references to sections or elements, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the approach could be generalized to more views. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to only two views, suggesting that it should generalize to more views. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to only two views, suggesting that it should be able to generalize to more views without much difficulty. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this concern or improve their approach. The comment lacks depth and actionable advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it identifies a potential issue but does not offer actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the metrics used for evaluating continual learning, specifically mentioning that they are suitable for datasets with known task boundaries but not applicable in scenarios where task boundaries are unknown or not identifiable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggest alternative metrics. As a result, the comment lacks actionability, leaving the authors without any clear steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of metrics for evaluating continual learning, specifically mentioning the metrics used for loss after switch and recovery time after switch. However, it does not specify which part of the paper these metrics are discussed in, making it weakly grounded. The comment is specific in detailing the limitation of these metrics in scenarios where task boundaries are unknown or not identifiable. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning are suitable for datasets with known task boundaries but not applicable in scenarios where task boundaries are unknown or not identifiable. This claim is 3 as it highlights a limitation of the metrics, but it lacks specific examples or references to support the claim. The authors would need to further explore and justify why these metrics are not applicable in the mentioned scenarios, which could enhance the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically noting that they are suitable for datasets with known task boundaries but not applicable in scenarios where task boundaries are unknown or not identifiable. This feedback is 3 as it highlights a potential weakness in the evaluation approach, prompting the authors to consider alternative metrics or methods that could be more broadly applicable. However, the comment could be more helpful if it provided suggestions on how to address this limitation or alternative metrics that could be used. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind the use of information from the agent decoder at time step t, specifically questioning why only the information up to time step t is used and not from all time steps. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the rationale and provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind the use of information from the agent decoder at time step t, specifically questioning why only the information up to time step t is used and not from all time steps. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the rationale but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind the use of information from the agent decoder at time step t, specifically questioning why only the information up to time step t is used and not from all time steps. This is a request for clarification rather than a claim that requires verification. The comment does not express an opinion, judgment, or suggestion that needs evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind the use of information from the agent decoder at time step t, specifically questioning why only the information up to time step t is used and not from all time steps. This is a relevant and actionable feedback that prompts the authors to clarify their methodology and provide a more detailed explanation of their approach. By addressing this question, the authors can improve the clarity and comprehensiveness of their paper, making it easier for readers to understand the rationale behind their choices. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the question. Overall, the feedback is 3 as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a discussion on the arbitrary hyperparameter \u03b3, including how it is set in practice for a given graph and its sensitivity. This feedback provides a clear and direct action for the authors to take, which is to include this discussion in their draft. The comment is specific and concrete, as it outlines exactly what is missing and how the authors should address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the absence of a discussion on the arbitrary hyperparameter \u03b3, specifically mentioning how it should be set in practice for a given graph and analyzing its sensitivity. This provides clear guidance on what is missing in the paper. However, the comment does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which could hinder researchers from following the paper. However, the comment does not provide specific examples or detailed reasoning to support why this omission is problematic or how it affects the understanding of the paper. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the discussion of the arbitrary hyperparameter \u03b3. It highlights the importance of including information on how this hyperparameter is set in practice for a given graph and its sensitivity, which is crucial for researchers to follow the paper effectively. By pointing out this omission, the comment provides clear and actionable feedback that can guide the authors in enhancing the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of how to set the hyperparameter. Overall, the feedback is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when abating induction heads versus FV heads could be due to the \"location\" of the heads within the model. It proposes that a controlled baseline should be implemented to ablate heads at different locations in the model. While the comment implies that the authors should consider adding such a baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a controlled baseline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of head \"location\" contributing to differences in ICL performance when abating induction heads versus FV heads. It suggests that a controlled baseline should be implemented to ablate heads at different locations in the model. However, the comment does not specify which part of the paper discusses the ICL performance or the ablation of heads, making it weakly grounded. The comment is specific in suggesting the need for a controlled baseline, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the difference in ICL performance when abating induction heads versus FV heads could be due to the \"location\" of the heads within the model. The reviewer suggests that a controlled baseline should be implemented to ablate heads at different locations in the model. However, the comment lacks specific examples or references to support the claim about the impact of head location on performance. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the model\"s performance, specifically the \"location\" of induction heads and FV heads within the model. It suggests that this factor could contribute to differences in ICL performance when abating these heads. The comment proposes a controlled baseline to address this issue, providing a clear and actionable suggestion for the authors to consider. However, the comment could be more helpful if it included specific examples or further elaboration on how to implement the controlled baseline. Overall, the feedback is 4 as it directs the authors\" attention to a critical aspect of their work and offers a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a missing section in the paper, specifically mentioning the absence of a section on synonym identification under similarity measurement. This provides a clear and direct action for the authors to take, which is to include this section. The comment is specific about what is missing and where it should be placed, making it 5. The authors know exactly what needs to be added to improve their draft.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of a section on synonym identification under similarity measurement, providing full grounding as it clearly identifies the part of the paper being addressed. It also specifies the issue by stating that this section is missing, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is important or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of the missing section. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This is a clear and actionable piece of feedback that highlights a critical area where the paper is incomplete. By pointing out this missing section, the reviewer provides the authors with a direct and constructive suggestion for improving their draft. However, the comment could be more helpful if it offered additional guidance on how to approach the synonym identification task or why it is important. Despite this, the feedback is 4 as it directs the authors to a specific area that needs attention, making it a valuable piece of advice. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model would help the reader understand the entire work. While the comment implies that the authors should include such an overview, it does not specify where in the paper this information should be placed or how it should be structured. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would help the reader understand the entire work. However, it does not specify which part of the paper this overview should be included in, making it weakly grounded. The comment is specific in its suggestion to include an overview, but without clear guidance on where to place it, the authors may struggle to determine the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would help the reader understand the entire work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would benefit the reader. The lack of detailed justification or evidence makes the claim 1, as the authors may not be able to determine the validity of the suggestion without further information. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would help the reader understand the entire work. While this feedback is 3, it lacks specificity and does not provide detailed guidance on how to create such an overview or where it should be placed in the paper. The authors are left with a general idea of what is needed but without concrete steps to follow. To be more helpful, the comment could include examples of what an effective overview might include or suggest ways to integrate it into the existing structure. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A, which cannot be accurately computed without significant computational effort. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or propose solutions. The feedback highlights a potential issue but lacks actionable steps or concrete advice for the authors to resolve it. As a result, the comment is vague and does not offer clear direction for improvement, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A, which cannot be accurately computed without significant computational effort. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses the sketch or the ridge regression problem, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references makes the comment weakly grounded. The comment is specific in identifying the issue with debiasing the sketch, but without grounding, it is not fully actionable. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A, which cannot be accurately computed without significant computational effort. The reviewer suggests that this might defeat the purpose of the approach. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the issue is significant or that the approach is ineffective. Without these elements, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach of debiasing the sketch, specifically the need to know the statistical dimension d_lambda of the design matrix A, which cannot be accurately computed without significant computational effort. This could potentially defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While the comment highlights a critical concern, it lacks specific suggestions or guidance on how the authors might address these issues or improve the approach. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, stating that the expected quantities are scalars but are currently shown as vectors. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, leaving no ambiguity about the required changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the expected quantities are scalars but are currently shown as vectors. This provides clear guidance on what correction is needed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or correction regarding the presentation of figure3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 3. It points out that the expected quantities are scalars but are currently shown as vectors, which is a clear issue that needs correction. By requesting the authors to redefine the figure accordingly, the comment offers a direct path for improvement. This feedback is valuable as it guides the authors on how to enhance the accuracy and clarity of their visual representation. However, the comment could be more helpful if it included additional context or explanation about why this correction is important or how it impacts the overall understanding of the paper. Despite this, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concern about the ablation experiments, suggesting that they need a better setup. However, it does not provide specific guidance on what aspects of the experiment setup could be improved or how the authors should address the questions raised. The feedback lacks explicit instructions or concrete details on how to enhance the experiment setup, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and does not provide actionable steps for improvement, making it barely actionable.", "grounding_specificity_rationale": "The comment expresses concern about the ablation experiments, suggesting that they need a better setup. However, it does not specify which part of the paper discusses the ablation experiments or provide details on what aspects of the setup could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the setup could be enhanced. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concern about the ablation experiments, suggesting that they need a better setup. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses concern about the ablation experiments, suggesting that they need a better setup. However, it lacks specificity and does not provide any detailed guidance or suggestions on how to improve the experiment setup or address the questions raised. Without actionable feedback or concrete examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer a comprehensive or actionable response."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to test the hypothesis regarding the usefulness of their proposed models for learning representations of lowfrequency words. It also notes that the explanation of improvements is lacking, as the word similarity data sets contain frequent word pairs. While the comment implies that the authors should conduct further analysis or provide more detailed explanations, it does not specify how to test the hypothesis or what specific improvements should be explained. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the usefulness of the proposed models for learning representations of lowfrequency words. It suggests that the authors should provide empirical evidence to test the hypothesis, which is a clear and specific request for improvement. However, the comment does not explicitly mention which part of the paper this aspect is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of the models or their applications, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations of lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should provide evidence to test the hypothesis, which is a reasonable request. However, the comment does not offer specific examples or references to substantiate the claim, making it 3. The authors would need to infer the lack of evidence and understand the need for further testing, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be strengthened by providing empirical evidence to support the claim that the proposed models are particularly useful for learning representations of lowfrequency words. It suggests that the authors should look deeper into this aspect, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to conduct this empirical evaluation or what kind of evidence would be most convincing. Additionally, the comment notes that the explanation of improvements is lacking, as the word similarity data sets contain frequent word pairs, which could be a point for further exploration. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on how to address them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the resolution of 3D voxel features and their impact on computational and memory costs. It suggests that the authors should study the importance of global features by comparing different resolutions of voxel features, particularly noting the case when the resolution is reduced to 1x1x1, which corresponds to using a single global feature. The comment provides a clear and explicit action for the authors to take, which is to conduct a comparative study of global features at different resolutions. This guidance is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the resolution of 3D voxel features and their impact on computational and memory costs, suggesting a comparison with different resolutions of voxel features to study the importance of global features. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the necessity of using voxellike features due to their high computational and memory costs. It suggests that the resolution of 3D voxel features and their impact on the network should be studied. The comment provides a logical reasoning by pointing out the potential overhead of using highresolution voxel features and suggests a comparison with different resolutions to study the importance of global features. However, it lacks specific examples or references to support the claim about the impact of resolution on computational costs. While the reasoning is sound, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant question about the computational and memory costs associated with using 3D voxellike features, particularly in the context of global features. It suggests that the authors should study the importance of global features by comparing different resolutions of voxel features, noting that a resolution of 1x1x1 corresponds to using a single global feature. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of the impact of feature resolution on computational efficiency. By addressing this suggestion, the authors can improve the comprehensiveness and depth of their study. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing and suggests that it should be included to allow other researchers to continue on this task. The comment provides a clear action for the authors to take, which is to add the error analysis. However, it does not specify how to conduct the error analysis or what specific cases should be considered. While the action is explicit, the lack of detailed guidance on execution makes it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is the error analysis, and suggests that it should be included to allow other researchers to continue on this task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of error analysis on the movie dataset. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing a concrete area for further analysis. By addressing this omission, the authors can enhance the comprehensiveness and utility of their work for other researchers. However, the comment could be more helpful if it suggested specific aspects of the error analysis that should be included or provided guidance on how to conduct it. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that it is difficult to discern trends in Table 3, specifically noting that PM+CL behaves differently than PM or CL alone. It suggests that the authors would benefit from exploring development set trends with respect to these hyperparameters. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this exploration or what specific trends should be examined. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the difficulty in discerning trends in the table and suggests exploring development set trends with respect to hyperparameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, specifically noting that PM+CL behaves differently than PM or CL alone. The comment implies that exploring development set trends with respect to hyperparameters would be beneficial. However, the comment lacks specific examples or detailed reasoning to support why this exploration would be valuable or how it would enhance the understanding of the trends. Without concrete evidence or examples, the claim is 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends due to the behavior of PM+CL being different from PM or CL alone. It suggests exploring development set trends with respect to hyperparameters, which could provide valuable insights. This feedback is clear and actionable, as it highlights a particular area for improvement and offers a specific suggestion for enhancing the analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct this exploration or what specific trends to look for. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in understanding Figure 5 due to overlapping lines and suggests that the authors could report additional metrics, such as FLOPS or model size, to make the information more concrete. While the comment implies that the authors should include these additional metrics, it does not explicitly instruct them to do so. The action is clear but inferred, and the suggestion is concrete, providing a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overlapping lines in the figure and suggests that the authors could report additional metrics, such as FLOPS or model size, to make the information more concrete. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to overlapping lines and suggests that the authors could report additional metrics like FLOPS or model size to make the information more concrete. While the comment identifies a specific issue with the figure, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include additional metrics is logical, but without specific guidance or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to overlapping lines. It suggests that the authors could report additional metrics, such as FLOPS or model size, to make the information more concrete. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it included specific examples or guidance on how to report these additional metrics. Overall, the comment is 4 as it directs the authors to a concrete area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide explicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks concrete instructions or suggestions for improvement, leaving the authors uncertain about what steps to take to enhance their draft. Since the action is implicit and vague, the comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or where in the paper these details should be addressed. The authors cannot confidently determine which part of the paper is being referred to, as the comment does not provide specific references or sections. Additionally, the comment lacks specificity regarding what details are missing or how they should be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand what exactly is missing or how to address it. The lack of detailed justification or examples renders the claim 1, as it does not provide sufficient information for the authors to make informed improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific examples or suggestions for what those missing details might be or how they could be addressed. Without detailed guidance or examples, the authors are left without actionable feedback on how to improve their draft. This lack of specificity and actionable advice makes the comment 2, as it only highlights an area for improvement without providing a clear path for the authors to follow. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is too dense and difficult to follow, suggesting that simplifying the description and explaining the architecture and computations would help. It specifically recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. While the comment provides a clear direction for simplification, it does not offer specific guidance on how to achieve this simplification or what aspects should be simplified. The action is explicit but somewhat vague, as the authors know they need to simplify the description and computations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8,\" and \"lines 3964,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by recommending simplification of the description and explanation of the architecture and computations. Additionally, it suggests reducing the content of these sections to gain more space. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and explaining the architecture and computations better. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is too dense or lacks clarity. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, noting that it is too dense and difficult to follow. It suggests that simplifying the description and explaining the architecture and computations would help the authors convey their contribution more effectively. Additionally, it recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. This feedback is clear and actionable, providing the authors with specific areas to improve the clarity and accessibility of their work. However, it could be more helpful if it offered additional suggestions on how to simplify the content or examples of how to rephrase the text. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and readability of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate the performance of EIGNN in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with other variants like GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to implement the evaluation or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on oversmoothing, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it suggests evaluating the performance of EIGNN under standard settings on realworld datasets, particularly in comparison with other variants like GCNII. This provides clear guidance on what needs to be addressed in the evaluation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests evaluating the performance of EIGNN in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with other variants like GCNII. However, the comment does not provide specific examples, detailed reasoning, or references to support why this evaluation is important or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 2, as it provides a general idea but lacks the necessary details to be fully substantiated.", "helpfulness_rationale": "The review comment suggests evaluating the performance of EIGNN in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with other variants like GCNII. This feedback is 3 as it identifies a specific area for improvement\u2014evaluating the model\"s performance under oversmoothing conditions. However, the comment lacks detailed guidance or suggestions on how to conduct this evaluation or what specific aspects to focus on. While it points out an important aspect of the evaluation, it does not provide actionable steps for the authors to follow, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of a separate part or subsection in the paper that introduces the inference strategy, specifically mentioning the use of multiple prompts in the test stage. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or suggest ways to incorporate the inference strategy into the paper. The action is implicit, as the authors can infer that they need to add a subsection or section to explain the inference strategy, but the comment does not offer concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of a separate part or subsection introducing the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks clarity, namely the introduction of the inference strategy, particularly how multiple prompts are used in the test stage. This feedback is clear and actionable, as it points out a missing element that could enhance the paper\"s comprehensiveness and clarity. By addressing this issue, the authors can improve the organization and presentation of their work. However, the comment could be more helpful if it provided suggestions on how to incorporate this information or examples of how to structure the inference strategy. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 4 is confusing because it is not clear what the columns mean, despite being explained in the text or caption. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should clarify the figure. The action is implicit, as the authors can infer that they need to add a legend or explanation for the columns, but the comment does not specify how to do so. Therefore, the comment is 3, as it highlights the issue but lacks concrete instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for the columns in Figure 4. The comment provides a clear indication of what needs to be addressed, namely the explanation of the columns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, despite being explained in the text or caption. However, the comment does not provide any additional context, reasoning, or examples to support this claim. Without further explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and lacks clarity regarding what the columns mean. While it points out a clear area for improvement, it does not provide any suggestions or guidance on how the authors might clarify the figure. The comment is 3 as it highlights a critical issue, but it lacks actionable advice or detailed feedback that would guide the authors in making the necessary improvements. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results should be discussed more, specifically questioning whether MaxGapTop2UCB is better than other algorithms based on the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clearly explained, particularly in the context of sorting or ranking. The comment implies that the authors should provide more detailed analysis and discussion of their results and applications. However, it does not specify how to conduct this analysis or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results should be discussed more, specifically questioning whether MaxGapTop2UCB is better than other algorithms based on the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, particularly in the context of sorting or ranking. The comment is fully grounded as it explicitly mentions the Streetview experiment and the potential application to sorting/ranking, allowing the authors to identify the specific parts of the paper being addressed. However, the comment lacks specificity regarding what aspects of the results or applications need further discussion or clarification. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the experiment results should be discussed more and questions the conclusion that MaxGapTop2UCB is better than other algorithms based on the Streetview experiment. It also raises concerns about the clarity of realworld applications, particularly in the context of sorting or ranking, and the computational complexity implications. However, the comment lacks specific examples, detailed reasoning, or references to support these claims, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or detail to be 5.", "helpfulness_rationale": "The review comment suggests that the experiment results should be discussed more, specifically questioning whether MaxGapTop2UCB is better than other algorithms based on the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clearly explained, particularly in the context of sorting or ranking. The comment highlights a potential gap in the discussion of the results and applications, which could be addressed by providing more detailed analysis and examples. However, the comment lacks specific suggestions or guidance on how to improve the discussion or clarify the applications, making it 3. The authors are given a direction to enhance their draft, but the feedback could be more comprehensive and actionable to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results when using only ML in the ablation experiments and suggests that the results are even lower than some simple early methods. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more explanations, but it lacks concrete steps or details on what specific aspects need clarification or improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the results of the ablation experiments, specifically questioning why the results are so low when using only ML. It also mentions that the results are even lower than some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not specify which part of the paper this question pertains to, such as the results section or the ablation experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the results and suggesting the need for more explanations, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the results being low when using only ML in the ablation experiments, suggesting that they are even lower than some simple early methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results being low when using only ML in the ablation experiments, suggesting that they are even lower than some simple early methods. This feedback highlights a potential issue with the experimental setup or the performance of the model, prompting the authors to provide more detailed explanations or justifications for their results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a gap in the results, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to include ablation analysis. The comment implies that the authors should consider adding ablation analysis, but it lacks concrete instructions on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors might infer that it pertains to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of missing ablation analysis but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. This is a valuable observation that highlights a critical gap in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific types of ablation analysis or where to include it. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that \"2 shows that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels,\" and the authors use Th. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do with this information or how it relates to their draft. Without specific instructions or suggestions, the authors are left without a clear understanding of how to address this point. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment mentions \"2,\" which provides some level of grounding as it allows the authors to identify the specific part of the paper being addressed. However, the comment lacks specificity because it does not explain what aspect of the results or analysis is being discussed, such as the implications of the noise rate comparison or how it relates to the overall findings. Without further details, the authors may struggle to understand the exact issue that needs attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"2 shows that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels,\" and the authors use Th. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific observation about the results presented in the paper, noting that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not offer any suggestions or guidance on how the authors might address this observation or incorporate it into their work. Without actionable feedback or constructive advice, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a gap in the experimental verification of the hypothesis, suggesting that the comparison between models trained on the original dataset and those trained on a mixture of original and adversarial examples would strengthen the argument. It implies that this comparison is crucial for highlighting the impact of the augmented adversarial examples. While the comment suggests a specific action\u2014comparing models on different datasets\u2014the instruction does not explicitly instruct the authors to perform this comparison. However, the action is concrete and provides a clear direction for improvement. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental verification of the hypothesis, suggesting a better comparison between models trained on the original dataset and those trained on a mixture of original and adversarial examples. This provides clear guidance on what needs to be addressed to strengthen the argument. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not well verified by the designed experiment, suggesting that the comparison between models trained on the original dataset and those trained on a mixture of original and adversarial examples would strengthen the argument. The comment provides a logical reasoning by pointing out the discrepancy in the training sets used in conventional methods and the base model. It suggests a specific comparison that could enhance the motivation of the work. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have successfully addressed this issue. Overall, the claim is 4, as it is supported by logical reasoning but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental verification of the hypothesis, suggesting that the comparison between models trained on the original dataset and those trained on a mixture of original and adversarial examples would strengthen the argument. It highlights the importance of this comparison in making the motivation of the work more convincing. The comment provides a clear and actionable suggestion for improving the draft by recommending a specific comparison that could enhance the experimental validation. However, it could be more helpful if it offered additional guidance on how to conduct this comparison or why it is particularly important. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing but does not provide any specific details or suggestions on how the authors might improve or clarify these experiments. The comment lacks explicit guidance or concrete steps for the authors to take to address the issue. Without additional information or actionable advice, the authors are left without a clear understanding of what needs to be done to enhance the credibility of their experiments. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the CNN experiments are not fully convincing, but it does not specify which part of the paper this refers to, making it weakly grounded. The comment lacks specificity as it does not detail what aspects of the experiments are lacking or how they could be improved. Without explicit references or detailed feedback, the authors cannot confidently determine which sections need attention or what specific issues require clarification. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it lacks specificity and does not provide any detailed feedback or suggestions on how the authors might improve or clarify these experiments. Without additional context or guidance, the authors are left without actionable information to enhance their draft. This makes the comment unhelpful, as it does not offer a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the results for model (3) (Chung et al. 2016) for CsEn were computed by themselves, as they are not reported in the paper. This provides a clear and direct action for the authors to take, ensuring they are aware of the discrepancy and need to address it. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and the specific results for model (3) (Chung et al. 2016) for CsEn, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of how the results were computed by the authors themselves. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the papers, implying that the authors computed them themselves. However, the comment does not provide any supporting evidence, such as references to the original papers or specific details about the computations. This lack of detailed justification makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn are not reported in the papers, implying that the authors computed them themselves. The comment provides a clear and actionable suggestion for the authors to mention this in their draft, which would help clarify the source of the results. This feedback is specific and constructive, offering a direct way for the authors to improve the transparency and accuracy of their presentation. However, it could be more helpful if it included additional guidance on how to present the results or why this clarification is important. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should place more emphasis on prompt design, as it is crucial for addressing issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. While the comment implies that the authors should include a section or discussion on prompt design, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the paper should place more emphasis on prompt design, specifically mentioning the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. However, the comment does not specify which part of the paper should be revised or expanded to address this issue, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit grounding, the authors may find it challenging to pinpoint the exact sections that require attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should place more emphasis on prompt design, as it is crucial for addressing issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. However, the comment lacks specific examples or references to support the claim that prompt design is underemphasized or that certain prompts are more effective than others. This makes the claim 3, as it provides a general rationale but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should place more emphasis on prompt design. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. This feedback is clear and actionable, as it provides a direction for the authors to enhance their draft by addressing the design of prompts. However, the comment could be more helpful if it offered specific examples or guidance on how to implement this suggestion. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that could significantly improve its quality."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could compare their results with SoTA (StateoftheArt) approaches, specifically mentioning the HateXplain models as an example. While the suggestion is explicit, it lacks concrete guidance on how to implement this comparison or what specific aspects of the comparison should be emphasized. The authors know that they need to include a comparison with existing models, but the comment does not provide detailed instructions on how to execute this task. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the results with SoTA approaches, specifically mentioning the HateXplain models as an example. However, it does not specify which part of the paper this comparison should be made in, such as in the results section or a discussion of the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a comparison with existing models, but without clear guidance on where to implement this suggestion, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with SoTA approaches, specifically mentioning the HateXplain models as an example. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why this comparison is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with SoTA (StateoftheArt) approaches, specifically mentioning the HateXplain models as an example. This feedback is 3 as it provides a specific direction for the authors to enhance their work by including a comparison with existing models. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what aspects of the comparison should be emphasized. While it points out a potential area for improvement, it does not fully support the authors in making a comprehensive revision. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of freezing in the MLS selection process, suggesting that if the adaptive method is effective, it might be better to use it instead. While the comment implies that the authors should consider using the adaptive method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the use of the adaptive method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of freezing in the MLS selection process, suggesting that if the adaptive method is effective, it might be better to use it instead. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the use of freezing is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the rationale behind using freezing, but without clear grounding, it lacks specificity. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point questions the use of freezing in the MLS selection process, suggesting that if the adaptive method is effective, it might be better to use it instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why freezing is used or why the adaptive method might be preferable. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in the MLS selection process, suggesting that if the adaptive method is effective, it might be better to use it instead. This feedback is 3 as it prompts the authors to reconsider their methodology and potentially improve the efficiency or effectiveness of their approach. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address the issue or what aspects of the adaptive method could be explored. While it identifies a potential area for improvement, it does not fully support the authors in making actionable changes to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is clear and direct, giving the authors a specific action to take in their future work. The comment is concrete, as it specifies what needs to be done\u2014developing a detailed plan to address the limitations. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which part of the paper discusses these limitations, making it weakly grounded. The comment is specific in its request for a detailed plan, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes the claim 1, as the authors may not understand the basis of the suggestion or how to address it. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the authors have mentioned limitations in the paper but have not provided a detailed plan on how they plan to address these drawbacks in their future work. This feedback is clear and actionable, as it directs the authors to a concrete step they can take to enhance the comprehensiveness and futureforwarding of their work. However, the comment could be more helpful if it offered suggestions on how to develop this plan or provided examples of strategies that could be employed. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors perform an analysis on their proposed knowledgeCLIP model, which combines image, text, and knowledge graphs (KGs), similar to existing work that adds negation or changes entities in text to test robustness. The comment implies that the authors should conduct such an analysis to validate their model. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors perform an analysis on their proposed knowledgeCLIP model, similar to existing work that combines text and KGs. It references a specific paper (https://arxiv.org/abs/2104.06378) as an example of such analysis. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. The suggestion is specific in terms of what the authors should do\u2014perform a similar analysis on their proposed model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should perform an analysis similar to existing work that combines text and KGs, such as adding negation or changing entities in text to test robustness. The comment references a specific paper (https://arxiv.org/abs/2104.06378) as an example of such analysis. This provides a clear reference and logical reasoning for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed guidance on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors perform an analysis on their proposed knowledgeCLIP model, similar to existing work that combines text and KGs. It references a specific paper (https://arxiv.org/abs/2104.06378) as an example of such analysis, providing a clear reference for the authors to follow. This feedback is actionable as it offers a concrete suggestion for the authors to enhance their work by conducting a similar analysis, which could improve the robustness and reliability of their model. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed instructions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main issues. First, it questions the use of p m in the numerator and p c in the denominator in Eq. 3, asking for clarification on the reason for this inconsistency. Second, it suggests that the authors consider adding variance for further improvement in Algorithm 2, where only the mean \u03bc f is used for the fusion prototype. Additionally, the reviewer recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. 3. While the comment provides specific questions and suggestions for improvement, it does not explicitly instruct the authors to address these points. The actions are implicit but concrete, as the authors can infer the need to clarify the use of p m and p c, consider adding variance, and use \u03bc g instead of \u03bc f. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Algorithm 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the use of p m and p c in Eq. 3, suggests considering the addition of variance for further improvement in Algorithm 2, and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. 3. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the use of p m and p c in Eq. 3 and suggests considering the addition of variance for further improvement in Algorithm 2. It also recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. 3. While the comment identifies specific areas of confusion and suggests potential improvements, it lacks detailed reasoning or references to support the claims. The authors would need to infer the rationale behind the suggestions, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two main points of confusion and suggests potential improvements. First, it questions the inconsistency in the use of p m in the numerator and p c in the denominator in Equation 3, asking for clarification on the reason for this inconsistency. Second, it suggests considering the addition of variance for further improvement in Algorithm 2, where only the mean \u03bc f is used for the fusion prototype. Additionally, the reviewer recommends using \u03bc g instead of \u03bc f, which is consistent with Equation 3. While the comment identifies specific areas of confusion and provides a suggestion for improvement, it lacks detailed guidance or examples on how to address these issues. The feedback is 3 as it points out areas for clarification and improvement, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the computational cost of the proposed approach, suggesting that the paper should provide a more comprehensive discussion on computational complexity. It also questions whether the approach might become prohibitive in certain settings. While the comment identifies areas for improvement, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to discuss computational complexity or potential limitations. The action is implicit and somewhat vague, as the authors need to infer that they should expand on computational complexity and consider potential limitations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational cost aspect of the paper, specifically questioning why the additional cost did not lead to significant delays in computation. It suggests that the paper deserves a more comprehensive discussion on the computational complexity of the proposed approach and questions whether the approach might become prohibitive in some settings. However, the comment does not specify which part of the paper discusses computational cost or where the authors should provide this additional discussion. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper need revision. The comment is specific in its request for a more detailed discussion on computational complexity and potential limitations, but without clear grounding, it is rated as 3.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach, questioning why the additional cost did not lead to significant delays in computation. The reviewer suggests that the paper deserves a more comprehensive discussion on computational complexity and questions whether the approach might become prohibitive in some settings. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the computational cost is a significant issue. Without these elements, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It questions why the additional cost did not lead to significant delays in computation and suggests that the paper deserves a more comprehensive discussion on computational complexity. Additionally, the reviewer raises a concern about whether the proposed approach might become prohibitive in certain settings. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out areas for further discussion but does not provide detailed instructions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a clearer explanation of how novel values in the test set are handled. This is an explicit action, as it directly instructs the authors to add more detail to their explanation. However, the comment does not specify exactly what aspects of the handling of novel values need to be clarified, leaving some room for interpretation. While the action is clear, the lack of specific guidance on what exactly needs to be explained makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for a clearer explanation of how novel values in the test set are handled. This provides the authors with a clear direction for improvement. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests that the authors should provide a clearer explanation of how novel values in the test set are handled. However, it does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by recommending that the authors clarify how novel values in the test set are handled. This feedback is clear and directly points out an area where the paper could be improved, offering the authors a concrete step to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included additional guidance on how to effectively explain this aspect or provided examples of how to do so. Despite this, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that similar methods have already been proposed for multitask learning but does not specify whether these methods are relevant to the current paper or if they should be discussed. The comment lacks explicit guidance on what the authors should do regarding these methods, such as whether they should be included, discussed, or compared. The action is implicit and vague, as the authors are left to infer that they need to address the mention of these methods but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"similar methods have already been proposed for multitask learning\" but does not specify which part of the paper this relates to, such as a specific section or method discussed. It also lacks specificity regarding what needs to be addressed or how the authors should respond to this observation. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning but does not provide any supporting evidence or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim or how it relates to the paper\"s content. This lack of detailed justification makes the claim 1, as it does not provide enough information for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that similar methods have already been proposed for multitask learning but does not discuss whether these methods are relevant to the current paper or if they should be addressed. While it identifies a potential gap in the literature review, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue. Without clear suggestions or examples, the authors are left with a vague understanding of what needs to be improved. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the computation amount of FedMITR is compared to other methods. While it implies that the authors should perform a comparison, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to include a comparison, but it lacks concrete guidance on how to conduct it or what specific aspects to focus on. Therefore, the comment is 3, as it provides a general direction but lacks detailed instructions.", "grounding_specificity_rationale": "The comment raises a question about the computation amount of FedMITR compared to other methods. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the computation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a comparison, but without clear grounding, it lacks specificity. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point raises a question about the computation amount of FedMITR compared to other methods. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which fits the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the computation amount of FedMITR compared to other methods, suggesting that the authors should perform a comparison. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to conduct the comparison or what aspects to focus on. The comment is 3 as it prompts the authors to consider an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should avoid using specific knowledge bases (1 and 2) by using a generic external knowledge base, as demonstrated in Figure 3. However, it also points out that the writing is confusing, making it unclear whether the suggestion is valid. While the comment provides an explicit action regarding the use of a generic external knowledge base, it lacks concrete guidance on how to implement this suggestion or address the confusion in the writing. The authors are left with a general idea of what to do but without detailed steps or examples, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1) and 2)\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the writing is too confusing and that the suggestion to use a generic external knowledge base is unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"1) and 2) can be avoided by using a generic external knowledge base (as shown in figure 3).\" However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Additionally, the comment notes that the writing is confusing, but it does not offer a clear explanation of why this is the case or how it could be improved. As a result, the claim is 3, as it lacks sufficient evidence or detailed justification to fully substantiate the authors\" concerns.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the writing, specifically mentioning that the suggestion to avoid using specific knowledge bases (1 and 2) can be clarified by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment does not provide specific guidance on how to improve the writing or clarify the suggestion, leaving the authors with a general idea of what might be improved but without actionable steps. While it highlights an area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for the authors to consider, such as the choice of 0.6 for glove embedding similarity, whether kcrossvalidation was performed, and the potential impact of using other influential loss functions like replacing the min with a mean or NDCG. While the comment provides specific questions and suggestions, it does not explicitly instruct the authors to make these changes or provide concrete guidance on how to address them. The actions are implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and suggestions regarding the selection of parameters and loss functions, but it does not specify which part of the paper these questions pertain to. The authors cannot confidently determine which sections or elements of the paper are being addressed, making it difficult to pinpoint the exact areas needing revision. While the questions are specific about the parameters and loss functions, the lack of grounding in the paper limits the comment\"s effectiveness. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of questions and suggestions for the authors to consider, such as the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other loss functions like min, mean, or NDCG. These are questions seeking clarification and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and suggestions for the authors to consider, such as the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other loss functions like min, mean, or NDCG. These questions and suggestions provide the authors with specific areas to explore and improve their work, offering actionable feedback that can enhance the quality and robustness of their research. However, the comment could be more helpful if it provided more detailed guidance or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of indepth analysis on the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct a more detailed analysis, but without specific suggestions on what aspects to focus on or how to approach the analysis, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the specific issue of \"why the improvements of models are limited on the offense detection dataset and are significant on the coarse stereotype set.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the lack of indepth analysis on the experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of indepth analysis on the experimental results, specifically questioning why the improvements are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of indepth analysis on the experimental results. It specifically questions why the improvements of the models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is valuable as it highlights an area where the authors need to provide more detailed analysis to strengthen their findings. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 3 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several specific actions for the authors to consider, such as using a new method of training on labeled data, incorporating input mask explanation annotations for a limited number of examples, and using modern backbone baselines like Resnet50 or DenseNet121 for feature extraction. These suggestions are explicit and provide concrete guidance on how the authors might improve their draft. However, the comment also expresses skepticism about the effectiveness of these interventions, which is an opinion rather than an action. The explicit actions provided make the comment 4, as the authors know what changes to make, but the skepticism adds a subjective element that does not provide actionable guidance. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific suggestions for improvement, such as using a new method of training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear guidance on what changes could be made to improve the draft, including the use of specific examples and baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed method, suggesting that it might not work due to the use of a small number of conv layers in the feature extraction layer. The reviewer expresses skepticism, citing that many robustness and domain invariance interventions have failed in the past. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the concern. The lack of detailed justification or evidence makes the claim 3, as it provides a general critique but lacks the necessary details to fully substantiate the argument.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the methodology section of the paper. It suggests using a new method of training on labeled data and incorporating input mask explanation annotations for a limited number of examples, which could enhance the robustness and generalizability of the approach. Additionally, the comment recommends using modern backbone baselines like Resnet50 or DenseNet121 for feature extraction, noting that a small number of conv layers might be insufficient for nonsynthetic tasks. This feedback is clear and constructive, offering the authors concrete steps to potentially improve their draft. However, the comment also expresses personal skepticism about the effectiveness of these interventions, which adds a subjective element but does not detract from the overall helpfulness. Overall, the comment is 4 as it provides actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should ensure a fair comparison by fully tuning the baseline with the same resources as the proposed method. While the comment implies that the authors should conduct a more thorough hyperparameter search, it does not provide specific guidance on how to achieve this or what specific hyperparameters should be adjusted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of hyperparameter tuning in the paper, specifically mentioning the extensive search for hyperparameters such as temperature, penalty, and threshold. However, it does not specify which part of the paper discusses these hyperparameters or where the baseline is mentioned, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources to ensure a fair comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper introduces multiple hyperparameters and conducted an extensive search, suggesting that the baseline should be fully tuned with similar resources for a fair comparison. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim 2, as it provides a general observation without concrete support.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach to hyperparameter tuning, suggesting that the baseline should be fully tuned with similar resources to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the fairness and validity of the experimental results. However, the comment could be more helpful if it offered suggestions on how to conduct the hyperparameter search or what specific resources should be allocated to the baseline. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a misunderstanding in the definition of perplexity and crossentropy, as well as the incorrect labeling of Eq1. The reviewer provides clear guidance by pointing out the inaccuracies in the text and suggesting that the authors clarify these definitions. This feedback is explicit and concrete, as it directly instructs the authors on what needs to be corrected. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the incorrect definitions of perplexity and crossentropy, as well as the incorrect labeling of Eq1. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity in the paper is incorrect, specifically stating that it is not the probability that the model generates the current sentence. The reviewer further argues that Eq1 does not represent perplexity but rather crossentropy. This claim is supported by logical reasoning, as perplexity is a measure of how well a probability model predicts a sample, and crossentropy is a different concept. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the definitions to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a critical misunderstanding in the paper regarding the definition of perplexity and crossentropy. It points out that the text incorrectly describes perplexity as the probability of generating the current sentence, which is not accurate. It also notes that Eq1 does not represent perplexity but rather crossentropy. This feedback is 5 as it provides clear and actionable guidance for the authors to correct the inaccuracies in their paper. By addressing these misunderstandings, the authors can improve the accuracy and clarity of their work, which is essential for the validity of their research. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning to their graph classification task, specifically mentioning MVGRL4 and gptgnn5 as missing. It also recommends testing these additional baselines on common datasets. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and suggests adding more baselines of graph contrastive learning, specifically mentioning MVGRL4 and gptgnn5 as missing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the current baselines and suggests adding more baselines for testing on common datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the compared baseline in the graph classification task is insufficient, specifically mentioning MVGRL4 and gptgnn5 as missing. The reviewer suggests adding more baselines of graph contrastive learning and testing them on common datasets. However, the comment lacks specific reasoning or evidence to support why these particular baselines are missing or why adding more would be beneficial. Without detailed justification or references, the claim remains 3, as it provides a general suggestion without concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the graph classification task, noting that the compared baseline is insufficient and explicitly mentions MVGRL4 and gptgnn5 as missing. It provides a clear suggestion to add more baselines of graph contrastive learning and test them on common datasets. This feedback is actionable and offers a concrete direction for the authors to enhance their work by expanding the scope of their experiments. However, the comment could be more helpful if it provided additional context or rationale for why these specific baselines are important or how they would benefit the study. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge mapbased defense strategies could cause structural damage to the edge map. The reviewer emphasizes the need to evaluate the defense against an adversarial attack that crafts adversarial examples to cause minimal structural alterations to the edge map while misleading the model predictions. However, the comment does not provide explicit guidance or concrete steps on how the authors should conduct this evaluation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of the proposed strategies, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern regarding the evaluation of the defense strategies, particularly the method of purifying the input image and the potential structural damage caused by an adaptive attack. The comment further specifies the need to evaluate the defense against an adversarial attack that crafts adversarial examples with minimal structural alterations but still misleads the model predictions. This provides clear guidance on what needs to be addressed in the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge mapbased defense strategies could cause structural damage to the edge map. The reviewer emphasizes the need to evaluate the defense against an adversarial attack that crafts adversarial examples with minimal structural alterations but still misleads the model predictions. However, the comment lacks specific examples or references to support the claim that such an attack would be effective. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It highlights the potential structural damage caused by an adaptive attack against the edge mapbased defense strategies. The comment suggests that the authors should evaluate their defense against an adversarial attack that crafts adversarial examples with minimal structural alterations but still misleads the model predictions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation process. However, it could be more helpful if it included suggestions on how to conduct this evaluation or examples of such attacks. Overall, the comment is 4, as it guides the authors toward a more comprehensive evaluation of their defense mechanisms."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the legends in Table 1, 2, and 3, specifying whether the numbers represent percentage errors or percentage correct. This is a direct and concrete action, as it provides clear guidance on what needs to be done to improve the clarity of the table. The authors know exactly what changes are required to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely clarifying the legends to indicate whether the numbers represent percentage errors or percentage correct, particularly for MNIST and CIFAR datasets. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the legends in Table 1, 2, and 3 should be clarified to specify whether the numbers represent percentage errors or percentage correct. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the legends in Tables 1, 2, and 3. It suggests that the numbers should be clarified to indicate whether they represent percentage errors or percentage correct, particularly for the MNIST and CIFAR datasets. This feedback is clear and actionable, as it provides a direct way for the authors to improve the clarity and interpretability of their results. By addressing this feedback, the authors can enhance the understanding of their findings for readers. However, the comment could be more helpful if it included suggestions on how to present the data more effectively or examples of how to clarify the legends. Overall, the comment is 4 as it points out a specific area for improvement and provides a clear direction for action."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to include standard deviations in their results, but the comment does not specify how to do so or what additional information would be helpful. The action is implicit and somewhat vague, as the authors need to determine the exact steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of standard deviations in the experimental results, making it difficult to judge the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect of the results that the authors need to address. By providing a straightforward suggestion to include standard deviations, the comment empowers the authors to improve the clarity and interpretability of their findings. However, the comment could be more helpful if it offered additional guidance on how to present or analyze the results with standard deviations. Overall, the feedback is 4, as it directs the authors toward a specific area for improvement that is crucial for the validity of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis is somewhat weak due to the lack of information on the existence and smoothness of the solution of SDE (2a)(2d), as well as any guarantees of the discretization in time and space. While the comment identifies specific areas where the analysis is lacking, it does not provide explicit guidance on how to address these issues or what specific changes should be made to strengthen the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should include these details in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis and the specific references to the theoretical work on sampling and particlebased optimization methods. It also specifies the issue by pointing out the lack of information regarding the existence and smoothness of the solution of SDE (2a)(2d), as well as any guarantees of the discretization in time and space. This provides clear guidance on what aspects of the analysis need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is weak due to the lack of information on the existence and smoothness of the solution of SDE (2a)(2d), as well as any guarantees of the discretization in time and space. The comment provides a specific example of what is missing, which helps to substantiate the claim. However, it could be more verifiable if it included references to relevant literature or further explanation on why these aspects are important. Overall, the comment is 4, as it provides a clear basis for the claim but could benefit from additional support.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis by pointing out the lack of information on the existence and smoothness of the solution of SDE (2a)(2d), as well as any guarantees of the discretization in time and space. This feedback is clear and actionable, as it directs the authors to address these missing elements in their analysis. By providing a specific example of what is missing, the comment helps the authors understand where their work could be improved and offers a concrete direction for enhancing the robustness and completeness of their analysis. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the quality of generated images produced by the proposed method, specifically noting that while continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the realism of the generated images. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images produced by the proposed method, specifically noting that while continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper discusses the generated images or where the issue is most apparent. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the issue with the quality of generated images, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion about the realism of the generated results. Without such details, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of generated images produced by the proposed method, noting that while continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights a critical area for improvement, prompting the authors to consider enhancing the realism of their generated images. However, the comment lacks detailed suggestions or guidance on how to achieve this improvement, such as recommending specific techniques or methods to increase image realism. While it points out a problem, it does not provide actionable steps for the authors to address it, making the feedback 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how the graph G is built using the human skeleton in Section 3.3. It also suggests adding the dimensions of G, X, and W to provide a clearer understanding of what DGCN is doing. These instructions are direct and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified: the construction of G using the human skeleton and the addition of dimensions for G, X, and W to better understand the operations of DGCN. This level of detail provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for clarification, rather than making subjective claims or opinions. It does not contain any claims that require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking for clarification on how the graph G is constructed using the human skeleton in Section 3.3. It also suggests adding the dimensions of G, X, and W to enhance the understanding of what DGCN is doing. This feedback is clear and constructive, guiding the authors to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples on how to present this information effectively. Overall, the comment is 4 as it directs the authors toward specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific claim in the paper that is not entirely accurate, suggesting that the Cycle Consistency loss involves iterating between two phases of reconstructions (ABA and BAB) with separate backpropagation processes. However, the comment does not provide explicit guidance or suggestions on how the authors should address this claim or improve their draft. It lacks concrete instructions or examples of how to revise the text to reflect the correct understanding of the Cycle Consistency loss. As a result, the authors are left without a clear action to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (559560) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the claim, namely that the Cycle Consistency loss involves iterating between two phases of reconstructions (ABA and BAB) with separate backpropagation processes. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely accurate, suggesting that the Cycle Consistency loss involves iterating between two phases of reconstructions (ABA and BAB) with separate backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper that is not entirely accurate, pointing out that the Cycle Consistency loss involves iterating between two phases of reconstructions (ABA and BAB) with separate backpropagation processes. This feedback is 3 as it highlights a potential inaccuracy in the paper, prompting the authors to reconsider their description of the Cycle Consistency loss. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might correct or clarify this claim. To be more helpful, the comment could include examples or references to support the claim, making it easier for the authors to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential confusion in terminology, specifically the use of \"hyperspectral\" instead of \"hyperspectral.\" It provides a clear definition of hyperspectral imaging, which can help the authors clarify the terminology in their paper. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to address the confusion. The action is implicit and somewhat vague, as the authors need to infer that they should correct the terminology and provide a rationale for their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with terminology, \"hyperspectral,\" and provides a clear definition of hyperspectral imaging. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is wrong with the terminology, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is defined as \"hyperspectral imaging.\" However, the comment does not provide any additional context, reasoning, or examples to support why this confusion might be problematic or how it affects the paper. Without further explanation or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in terminology, specifically the use of \"hyperspectral\" instead of \"hyperspectral.\" It provides a clear definition of hyperspectral imaging, which can help the authors clarify the terminology in their paper. However, the comment lacks depth and does not offer suggestions on how this confusion might impact the paper or how the authors could address it. While it points out a specific issue, it does not provide actionable guidance or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests refreshing the concept of energy in Section 5.2, where it is used multiple times, and provides a specific hint on how to interpret it: a high energy on a character would indicate that the current morpheme should be split at that point. Additionally, it points out that the concept of peak (in Figure 5) is not described. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: refreshing the concept of energy in Section 5.2, providing hints on how to interpret it, and describing the concept of peak in Figure 5. This level of detail ensures that the authors know exactly what needs to be improved. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and provides an explanation at that point. However, it recommends refreshing the concept in Section 5.2, where it is used multiple times, and provides a specific hint on how to interpret it. The comment also points out that the concept of peak (in Figure 5) is not described. While the comment provides some guidance, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s draft. It highlights the mention of the concept of energy for the first time in Section 3.1 and suggests refreshing this concept in Section 5.2, where it is used multiple times. The comment offers a clear hint on how to interpret the concept of energy, suggesting that a high energy on a character might indicate a split point. Additionally, it points out that the concept of peak (in Figure 5) is not described, which is a significant oversight. This feedback is detailed and constructive, providing the authors with clear guidance on how to enhance the clarity and comprehensiveness of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detailed explanations on how each component contributes to performance improvements, specifically mentioning the combination of the Linformer and window attention in Big Bird. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to deduce the exact steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2), and 3)\" above, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the authors should provide more detailed explanations on how each component contributes to performance improvements, particularly focusing on the combination of the Linformer and window attention in Big Bird. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed explanations on how each component contributes to performance improvements, specifically mentioning the combination of the Linformer and window attention in Big Bird. However, the comment does not provide specific examples or references to support this suggestion, making it difficult for the authors to understand and address the issue effectively. The lack of detailed justification or examples results in the comment being considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while ablation studies are mentioned in Sections 3 and 4, there is a lack of detailed explanations on how each component contributes to performance improvements. The comment provides a specific example of how this could be addressed, suggesting that the authors should explain the contribution of combining the Linformer and window attention in Big Bird. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper\"s comprehensiveness and clarity. However, it could be more helpful if it included additional examples or guidance on how to effectively present these contributions. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that certain details about the models are missing, specifically mentioning the grammar over kernels and the probabilities associated with it. It questions how this approach is applied in practice and how inference is performed. While the comment identifies specific areas where more information is needed, it does not provide explicit instructions on what specific details should be added or how to address the questions about inference. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but they may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the models, particularly the grammar over kernels and the probabilities associated with it. It questions the application of the approach in practice and the process of inference. However, it does not explicitly mention which part of the paper these details are discussed in, making it weakly grounded. The comment is specific in detailing what is missing and what needs to be addressed, providing clear guidance on what information is needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that certain details about the models are missing, specifically mentioning the grammar over kernels and the probabilities associated with it. The reviewer questions the application of the approach in practice and the process of inference. However, the comment lacks specific examples or references to support the claim that these details are missing or how they impact the understanding of the approach. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that certain details about the models are missing, particularly the grammar over kernels and the probabilities associated with it. It questions how this approach is applied in practice and how inference is performed, which are crucial aspects for understanding the methodology. While the comment highlights important areas that need clarification, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors to areas requiring further explanation, but it could be more actionable with additional guidance on what specific details should be included. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the unknown role of visual information, the lack of explicit verification in the ablation study, and the questionable nature of the experimental results due to the limited sample size. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The feedback identifies areas for improvement but lacks actionable steps or concrete details on how to implement the changes. As a result, the comment is vague and lacks direction, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper\"s content, including the unknown role of visual information, the lack of explicit verification in the ablation study, and the questionable nature of the experimental results. It mentions Table 10, which provides specific details about the performance of the model with and without the perception module. However, the comment does not explicitly mention which sections or parts of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the unknown role of visual information and the need for explicit verification in the ablation study. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the paper\"s experimental results, including the unknown role of visual information, the lack of explicit verification in the ablation study, and the questionable nature of the results due to the limited sample size. The comment provides logical reasoning by explaining the implications of these issues and suggesting that the experimental results may not be reliable. However, it lacks specific references or detailed examples to fully substantiate these claims, making it 3. The authors would need to further explore these points to fully understand and address the concerns raised.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the unknown role of visual information, the lack of explicit verification in the ablation study, and the questionable nature of the experimental results due to the limited sample size. It provides specific examples, such as the performance of the model with and without the perception module, which highlights the need for further exploration. However, the comment could be more helpful by offering suggestions on how to address these issues, such as proposing additional experiments or providing more detailed analysis. While it points out important areas for improvement, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening, but previous works on Lasso screening are not cited or compared. The reviewer suggests that these previous works should be cited or compared to provide a more comprehensive analysis. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add citations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of citation or comparison to previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 29923006. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests that previous works on Lasso screening, such as Ren et al., should be cited or compared. However, without specific references or detailed reasoning, the claim remains 1. The authors would need to conduct further research or provide more context to address this feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare previous works on Lasso screening. The reviewer suggests that these previous works should be cited or compared to provide a more comprehensive analysis. This feedback is clear and actionable, as it directs the authors to include relevant references and comparisons, which can enhance the depth and rigor of their work. However, the comment could be more helpful if it provided specific examples of previous works or detailed guidance on how to incorporate these references. Overall, the comment is 4, as it effectively points out an area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the model has many components with hyperparameters that are not fully provided, suggesting that someone might have to trace them in the source code. While the comment identifies a potential issue, it does not explicitly instruct the authors to provide these hyperparameters or suggest how to address the lack of information. The action is implicit and somewhat vague, as the authors need to infer that they should provide the hyperparameters and determine the best way to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the model, mentioning that it has many components with hyperparameters not fully provided. However, it does not specify which components or sections of the paper are affected, making it weakly grounded. The comment is specific in identifying the need for full hyperparameter information, but without clear grounding, the authors may struggle to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters not fully provided, suggesting that someone might have to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters not fully provided, which could lead to confusion or require additional effort to trace in the source code. While the comment highlights a potential weakness, it lacks actionable guidance or suggestions on how the authors might address this issue. It does not provide specific advice on what information should be included or how to improve the clarity of the model description. As a result, the comment offers limited value to the authors in terms of improving their draft, making it 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the notation used for results, specifically questioning the meaning of the percentage value mentioned in the paper. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to clarify or correct it. The authors are left to infer that they need to make the notation clearer, but without concrete steps on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the notation used for results, noting that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides a clear point of confusion and suggests that the authors need to clarify the notation. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation for results is unclear, specifically questioning the meaning of the percentage value \"%p\" mentioned in the paper. However, the comment does not provide any supporting evidence, examples, or references to clarify the issue or suggest how the notation could be improved. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation in the paper, pointing out that the percentage value \"%p\" is not clearly defined. This feedback is clear and actionable, as it directs the authors to clarify the notation, which is crucial for the reproducibility and understanding of the results. However, the comment could be more helpful if it provided suggestions on how to improve the notation or examples of clearer ways to present the information. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include qualitative results, possibly with zoomedin views, for cases where previous methods failed but are acceptable with the proposed method. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to present these results or what specific aspects should be highlighted. The authors know they need to include these elements, but the comment does not offer detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but are acceptable with the proposed method. It also recommends showing failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these results should be included in, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of qualitative results and analysis of limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results and analyzing the limitations of the proposed method. However, it does not provide specific examples or detailed reasoning to support why these additions would be beneficial or how they would enhance the paper. The comment lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomedin views, for cases where previous methods have failed but are acceptable with the proposed method. It also suggests showing failure cases and analyzing the limitations. This feedback is clear and actionable, as it guides the authors on what additional elements to include in their work to enhance its comprehensiveness and impact. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to present these results effectively. Overall, the comment is 4, as it offers valuable insights for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that the focus is on machine comprehension of text rather than human reading comprehension. This feedback is explicit, as it directly instructs the authors to make a change to the title to avoid confusion. The action is concrete because it specifies exactly what needs to be done\u2014clarify the title. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, recommending that it be clarified to avoid confusion between machine comprehension of text and human reading comprehension. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous, specifically mentioning that it should clarify the focus on machine comprehension of text rather than human reading comprehension. This claim is 3 as it provides a clear rationale for the suggestion, indicating that the title could be misleading. However, it lacks specific examples or references to support the claim fully, which could enhance the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it should clarify the focus on machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity of the title. By addressing this issue, the authors can enhance the precision and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to revise the title or suggested alternative phrasing. Overall, the comment is 4 as it directs the authors toward a specific improvement that could enhance the clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific claim made in the paper that is incorrect, providing a clear action for the authors to address. It highlights the inaccuracies in the statement regarding the Central Limit Theorem (CLT) and suggests that the authors should correct this claim. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim made about the Central Limit Theorem (CLT) and provides a detailed critique of the statement, explaining why it is inaccurate. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors incorrectly apply the Central Limit Theorem (CLT) by stating that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer provides a detailed critique, explaining that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and supported by a clear explanation of the inaccuracies in the authors\" claim, making the comment 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific and incorrect claim made in the paper regarding the Central Limit Theorem (CLT). It provides a detailed critique, explaining that the authors\" statement is inaccurate because the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it directs the authors to correct a significant error in their paper. However, the comment could be more helpful if it offered suggestions on how to revise the claim or provided examples of correct applications of the CLT. Overall, the comment is 4 as it effectively highlights a critical issue that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action, providing the authors with a specific task to perform. The comment is concrete, as it specifies exactly what needs to be done, leaving no ambiguity about the authors\" responsibilities. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is analyzing the time complexity of the proposed policies. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point is a request for analysis, not a claim or opinion. It does not make any subjective judgments or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a request for the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a straightforward and actionable suggestion that provides the authors with a clear direction for improving their draft. By addressing this feedback, the authors can enhance the comprehensiveness and depth of their analysis, making the paper more robust and informative. However, the comment could be more helpful if it provided additional guidance on how to conduct the time complexity analysis or what specific aspects should be considered. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of an automatic metric (TSS) in human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes to make. The comment implies that the authors should consider using a human metric, but it lacks concrete steps or suggestions on how to implement this change. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the use of an automatic metric (TSS) in human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned, making it weakly grounded. The comment is specific in identifying the issue with the use of an automatic metric, but without clear grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of an automatic metric (TSS) in human evaluation, suggesting that a human metric would be more convincing. However, the comment lacks specific reasoning or examples to support why the use of an automatic metric weakens the convincingness of human evaluation. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the use of an automatic metric (TSS) in human evaluation, suggesting that a human metric would be more convincing. This feedback is 3 as it identifies a potential weakness in the evaluation methodology, prompting the authors to consider the appropriateness of their choice. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative metrics or explaining the rationale behind their current choice. While it points out an area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning \"those in TDMPC 2.\" This feedback is explicit, as it clearly states what the authors should do to strengthen their paper. The action is concrete because it provides a specific direction for improvement, namely adding experiments across diverse domains. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning \"those in TDMPC 2.\" This provides a clear direction for improvement, but it does not specify which part of the paper currently contains the experiments or where the authors should add these additional experiments. The authors can infer that it relates to the experimental section, but the comment lacks full grounding. It is specific in suggesting the need for more diverse experiments, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include more diverse domains, specifically mentioning \"those in TDMPC 2.\" This claim is 3 as it provides a specific direction for improvement, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would need to explore and justify why these additional experiments would strengthen the paper, which could be a challenge without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning \"those in TDMPC 2.\" This feedback is 3 as it identifies a potential area for improvement, indicating that the experiments could be more comprehensive. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what additional experiments would be beneficial. While it prompts the authors to consider a broader scope of experiments, it does not offer detailed advice or examples, which limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of confidence intervals for the results and the limited evaluation to only two datasets. It also provides references to relevant works in the RNP community. While the comment identifies specific areas for improvement, it does not offer explicit guidance on how to address these issues or suggest specific actions for the authors to take. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets, but without concrete steps, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for the results and the limited evaluation to only two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also provides references to relevant works in the RNP community, which adds specificity to the feedback. The comment specifies what needs to be addressed, such as including confidence intervals and expanding the evaluation to more datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to two datasets, which are standard in the RNP community. The comment references specific works in the RNP community, such as \"DiversitySensitive Conditional Generative Adversarial Networks\" (ICLR 2019) and others, which provides a basis for the claim. However, the comment could be strengthened by explaining how these references relate to the current work or why the lack of confidence intervals and dataset evaluation is problematic. Overall, the claim is 4 due to the references provided, but it could be more robust with additional explanation or examples.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for the results and the limited evaluation to only two datasets, which are standard in the RNP community. It also provides references to relevant works in the RNP community, which can help the authors understand the context and significance of their findings. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to incorporate confidence intervals or expand the evaluation to more datasets. Overall, the feedback is 3 as it points out critical weaknesses but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks specificity and actionable details, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where to address this concern. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks evaluation, namely the magnitude of the interpretability tax associated with the method. This is a clear and actionable piece of feedback that highlights a potential gap in the paper\"s analysis. By pointing out this omission, the comment provides the authors with a concrete direction for improvement, encouraging them to conduct a more comprehensive evaluation of their method\"s interpretability. However, the comment could be more helpful if it offered suggestions on how to conduct this evaluation or provided examples of how to measure interpretability tax. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the paper for its lack of originality, suggesting that the main contribution is demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel methods. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might enhance the originality of their work or what specific changes could be made to achieve a more novel contribution. As a result, the comment is 1, as it does not offer any actionable steps for the authors to improve their draft.", "grounding_specificity_rationale": "The comment critiques the paper for its lack of originality, suggesting that the main contribution is demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel methods. However, it does not specify which part of the paper this critique is based on, nor does it provide specific details on what aspects of the paper could be improved. The authors cannot confidently determine which sections or elements are being addressed, and the comment lacks specificity regarding what needs to be revised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks originality, suggesting that the main contribution is demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel methods. The reviewer supports this claim by noting that the approaches in Section 5 are standard and have been explored in previous literature. However, the comment does not provide specific examples or references to support the assertion that the techniques are standard or have been explored before. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for its lack of originality, suggesting that the main contribution is demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel methods. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might enhance the originality of their work or address this critique. The feedback lacks actionable advice or detailed examples, making it 3 but incomplete. The authors would need to infer what changes could be made to improve the paper, which limits the utility of the comment. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should provide some training losses. While the question implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should provide some training losses. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the training process is discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its request for training losses, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question and a suggestion for the authors to provide some training losses. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should provide some training losses. While this feedback identifies a potential issue with the methodology, it lacks specificity and does not offer actionable guidance on how the authors might address this concern. The comment is 3 as it points out a potential area for improvement, but it does not provide detailed suggestions or examples to help the authors enhance their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, it does not provide explicit guidance or suggestions on how the authors should address this overclaiming. The comment lacks actionable details, such as recommending specific changes or clarifications to improve the paper\"s presentation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis section of the paper, specifically mentioning the BC loss and its properties, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability. However, it does not specify which part of the paper these elements are discussed in, making it weakly grounded. The comment is specific in identifying the overclaiming nature of the paper\"s analysis and suggesting that these properties are essentially the same concept from different viewpoints. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. The comment provides a logical reasoning by stating that these properties are not distinct but rather different expressions of the same idea. However, it lacks specific examples or references to substantiate this claim, making it 3. The authors would need to further explore and clarify these points to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential overclaiming in the paper\"s theoretical analysis, specifically regarding the BC loss. It points out that the concepts of geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same idea expressed from different viewpoints. This feedback is 3 as it highlights a critical area for clarification, prompting the authors to reconsider their theoretical analysis and ensure that their claims are wellsupported and distinct. However, the comment could be more helpful if it provided specific suggestions or examples to address the overclaiming aspect. Overall, the comment provides a useful insight but lacks detailed guidance, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which results in a slower running speed compared to other methods. The reviewer suggests that this could lead to an unfair comparison. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to adjust their comparison or provide additional context to make the comparison fair. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and the issue of \"2x samples per iteration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the problem with the training speed and suggests that the comparison with other methods may be unfair due to the increased sample processing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup processes 2x samples per iteration, leading to a slower running speed and potentially unfair comparisons with other methods. The comment provides a logical reasoning by stating that this could result in slower performance and unfair comparisons. However, it lacks specific examples or references to other methods that might be affected by this issue, making it 3. The authors would need to further explore and substantiate the claim to fully understand the implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which results in a slower running speed compared to other methods. The reviewer points out that this could lead to unfair comparisons with other methods. While the comment highlights a specific concern, it lacks detailed suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. The feedback is 3 as it directs the authors\" attention to a potential weakness, but it could be more actionable with additional guidance or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks, specifically in the context of IoU regression. It points out that while focal loss is effective for classification due to its property of lower gradients on easy samples, it may not be suitable for regression tasks where lower weight for easy samples could lead to inaccuracies. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of focal loss for regression tasks. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks, specifically in the context of IoU regression. It points out that while focal loss is effective for classification due to its property of lower gradients on easy samples, it may not be suitable for regression tasks where lower weight for easy samples could lead to inaccuracies. However, the comment does not specify which part of the paper discusses the use of focal loss or the IoU regression, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where focal loss is discussed, the comment lacks full grounding. It is specific in identifying the issue with the use of focal loss in regression tasks but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of focal loss in regression tasks, specifically in the context of IoU regression. It explains that while focal loss is effective for classification due to its property of lower gradients on easy samples, it may not be suitable for regression tasks where lower weight for easy samples could lead to inaccuracies. The comment provides a logical reasoning based on the known properties of focal loss and its applicability to classification versus regression tasks. However, it lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks. This makes the claim 3, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the use of focal loss in regression tasks, specifically in the context of IoU regression. It points out that while focal loss is effective for classification due to its property of lower gradients on easy samples, it may not be suitable for regression tasks where lower weight for easy samples could lead to inaccuracies. This insight is valuable as it challenges the authors to reconsider their choice of loss function for regression tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it prompts the authors to think critically about their methodology, it does not provide actionable steps for improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in making improvements. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. While it highlights an area of interest, it does not provide explicit guidance or suggestions on how the authors should address this question. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references, the authors may find it challenging to determine where to address this question. Additionally, the comment lacks specificity regarding what aspects of scalability need to be explored or how the authors might approach this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the scalability of the method as the corpus size or hidden dimension size increases. This is a relevant and pertinent inquiry that could guide the authors in exploring the robustness and applicability of their method under varying conditions. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or what experiments or analyses could be conducted to explore scalability. While it identifies a potential area for improvement, the feedback is incomplete and could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should verify the statistical significance of the improvements made by the proposed model over the RL without feedback model. While the comment implies that the authors should conduct a statistical test to confirm the significance of the improvements, it does not provide specific guidance on which statistical test to use or how to interpret the results. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of statistical significance in the improvements of the proposed model over the RL without feedback model, particularly noting that the improvements are not as high as expected for BLEU1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not as high as expected, specifically noting that the improvements are worse for BLEU1. The reviewer suggests that the authors should verify the statistical significance of these improvements. However, the comment lacks specific evidence or references to support the claim about the lack of significance. Without detailed reasoning or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides a general observation but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed model\"s improvements over the RL without feedback model. It points out that the improvements are not as high as expected, particularly noting a worse performance for BLEU1. The reviewer suggests that the authors should verify the statistical significance of these improvements, which is a valuable and actionable piece of feedback. This feedback encourages the authors to conduct a more rigorous statistical analysis to substantiate their claims, thereby enhancing the credibility and robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct the statistical analysis or suggested specific statistical tests to use. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear suggestion for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider relaxing the requirement of visiting all ballaction pairs with each iteration, asking what minimal assumptions are needed to achieve this. It also poses a question about the potential consequences of partially covering these pairs. While the comment implies that the authors should explore these possibilities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate these assumptions and explore the implications of partial coverage. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it refers to a continuation of a previous remark, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies what the authors need to consider: relaxing the requirement of visiting all ballaction pairs with each iteration and exploring the implications of partially covering them. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and exploration of the implications of relaxing certain assumptions. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the possibility of relaxing the requirement of visiting all ballaction pairs with each iteration, asking what minimal assumptions are needed and what would happen if only a partial coverage is used. This feedback is 3 as it prompts the authors to consider alternative approaches and explore the implications of their assumptions. However, it lacks specific guidance or suggestions on how to implement these changes or what specific aspects to focus on. The comment provides a direction for improvement but does not offer detailed instructions, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider whether an improvement in performance could be observed by using a better encoder, such as RoBERTabase, instead of BERT. While the comment implies that the authors should explore this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should test with a different encoder and determine if it leads to an improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering whether an improvement in performance could be observed by using a better encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where the encoder choice is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the suggestion is specific in terms of recommending a different encoder, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an improvement in performance could be observed by using a better encoder, such as RoBERTabase, instead of BERT. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests considering whether an improvement in performance could be observed by using a better encoder, such as RoBERTabase, instead of BERT. This is a relevant and actionable suggestion that could guide the authors in exploring alternative models or configurations that might yield better results. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what aspects of the model should be examined. While it points out a potential area for improvement, it does not fully support the authors in making a comprehensive response. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalization of the proposed technique to tasks with varying levels of reasoning requirements. While the comment implies that the authors should add these datasets, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalization of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in its suggestion to include additional datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalization of the proposed technique. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific datasets are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalization of the proposed technique to tasks with varying levels of reasoning requirements. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically in terms of dataset diversity and generalization capability. However, the comment lacks specificity and does not provide detailed guidance on how to select or incorporate these datasets, nor does it explain why these particular tasks are important for the study. While it points out a relevant area for enhancement, the authors may need to make significant efforts to address the feedback effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It recommends comparing against existing methods like RefNeRF and MipNerf, which are noted for their appearance decomposition capabilities. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to make these comparisons or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improving the choice of baseline methods, particularly for evaluating the appearance decomposition part. It specifically recommends comparing against existing methods like RefNeRF and MipNerf, which are noted for their appearance decomposition capabilities. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting particular baselines to consider, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It recommends comparing against existing methods like RefNeRF and MipNerf, which are noted for their appearance decomposition capabilities. This claim is 3 as it provides specific examples of potential baselines, which can help the authors understand the rationale behind the suggestion. However, the comment could be strengthened by providing more detailed reasoning or references to why these specific methods are relevant. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the choice of baseline methods could be improved, particularly for evaluating the appearance decomposition part. It recommends comparing against existing methods like RefNeRF and MipNerf, which are noted for their appearance decomposition capabilities. This feedback is clear and actionable, as it provides specific examples of potential baselines that could enhance the evaluation of the appearance decomposition part. However, the comment could be more helpful if it included additional reasoning or suggestions on why these specific methods are relevant or how they might improve the evaluation. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can be used to achieve fair policy learning without significantly damaging the performance of the predictive model. While the comment implies that the authors should include a demonstration or example, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to implement this demonstration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its request for a demonstration, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly damaging the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this demonstration is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly damaging the performance of the predictive model. This feedback is 3 as it identifies a specific area for improvement, prompting the authors to provide a demonstration or example. However, the comment lacks depth and does not offer specific guidance on how to implement this demonstration or what aspects of the method should be highlighted. While it provides a direction for improvement, it does not fully support the authors in making a comprehensive revision. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of implementation details for the proposed methods, suggesting that they should be included in the implementation details section, specifically in Section 4.1. While the comment explicitly states the need for more detailed implementation information, it does not provide specific guidance on what details should be included or how to present them. The action is clear but lacks concrete instructions, making it 3.", "grounding_specificity_rationale": "The comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. This provides full grounding as the authors can accurately identify the section being addressed. The comment is also specific, as it clearly specifies what is missing\u2014implementation details\u2014and what should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a concern about the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the implementation details are missing or why they are important. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, which is the lack of implementation details for the proposed methods. It suggests that these details should be included in the implementation details section, specifically in Section 4.1. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how to present them effectively. Overall, the comment is 4 as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evaluation and comparison with other methods, as well as the lack of discussion on the practical value of the contribution. It suggests that even a theoretical paper should argue for its significance, which is not the case here. While the comment identifies several areas for improvement, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include empirical evaluation, comparisons, and a discussion of practical value, but without concrete steps on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, as well as the absence of discussion on the practical value of the contribution. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what is missing in the paper, namely empirical evaluation, comparisons with other methods, and a discussion of the practical value of the contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, and it questions the practical value of the contribution. The comment suggests that even theoretical papers should argue for their significance, which is not the case here. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of empirical evaluation and comparison with other methods, as well as the absence of a discussion on the practical value of the contribution. It suggests that even theoretical papers should argue for the significance of their contributions, which is not the case here. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to better align with the expectations of a NeurIPS publication. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of how to include the necessary comparisons and discussions. Overall, the comment is 4, as it effectively highlights the weaknesses and provides a direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential source of confusion in the manuscript, specifically regarding the use of \"P\" to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the notation to avoid confusion, but it lacks concrete steps or examples of how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the manuscript, noting that \"P\" is used to represent both a probability and a cumulative distribution function in different parts of the paper. This provides full grounding as it clearly specifies the part of the paper being addressed, allowing the authors to accurately identify the relevant sections. The comment is also specific, as it highlights the confusion caused by the dual use of \"P\" and suggests that clarification is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"P\" is used ambiguously to represent both a probability and a cumulative distribution function, leading to confusion. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed explanation or references to clarify the confusion, making it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that the symbol \"P\" is used ambiguously to represent both a probability and a cumulative distribution function in different parts of the paper. This observation highlights a potential source of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or clarifications. While it points out a problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method discussed in the paper, which can be applied in general MDPs, is limited in navigation problems. It references a previous discussion on combining RL and planning in PRMRL~1 and questions whether such algorithms can be applied in more general tasks. While the comment implies that the authors should explore broader applications, it does not provide specific guidance on how to achieve this or suggest particular tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the direction of improvement but lack concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it can be applied in general MDPs but is limited in navigation problems. It references a previous discussion on combining RL and planning in PRMRL~1 and questions whether such algorithms can be applied in more general tasks. However, the comment does not specify which part of the paper discusses the method or navigation problems, making it weakly grounded. The comment is specific in suggesting that the authors explore broader applications, but without explicit references to sections or specific issues, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper, which can be applied in general MDPs, is limited in navigation problems. It references a previous discussion on combining RL and planning in PRMRL~1 and questions whether such algorithms can be applied in more general tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is limited to navigation problems. The reference to PRMRL~1 is mentioned but not elaborated upon, leaving the authors with insufficient information to fully understand and address the issue. As a result, the claim is 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method discussed can be applied in general MDPs but is limited in navigation problems. It references a previous discussion on combining RL and planning in PRMRL~1 and questions whether such algorithms can be applied in more general tasks. This feedback is 3 as it highlights a potential area for expansion and suggests a direction for further exploration. However, the comment could be more actionable by providing specific suggestions or examples of how the authors might address this limitation. Overall, the comment offers some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also provides a suggestion to standardize feature dimensions to avoid this issue. While the comment implies that the authors should consider the suitability of their feature spaces and possibly standardize them, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the suitability of feature spaces for 1NN and provides a suggestion to standardize feature dimensions to avoid performance issues. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and provides a rationale for why standardizing feature dimensions might be necessary. It explains that if a feature space is not close to a spherical Gaussian, it may perform poorly, and suggests standardizing feature dimensions to avoid this issue. This reasoning is logical and provides a clear explanation of the potential problem and a solution, making the comment 4. However, it could be strengthened by providing specific examples or references to support the claim about feature space suitability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about the suitability of feature spaces for 1NN and provides a rationale for why standardizing feature dimensions might be necessary. It highlights a potential issue with the feature space and suggests a solution by standardizing feature dimensions to avoid performance issues. This feedback is clear and actionable, as it guides the authors to consider the suitability of their feature spaces and provides a specific suggestion for improvement. However, the comment could be more helpful if it included examples or further elaboration on the potential impact of not standardizing feature dimensions. Overall, the comment is 4, as it provides valuable insight and actionable advice for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the definition of the proposed \"contrastive gap,\" which is central to the work. It suggests that while an intuitive example on the \"idealized\" dataset was provided, the setting of this example is less convincing, and a clear, formal definition is still lacking. The comment implies that the authors should provide a more precise and formal definition of the contrastive gap. However, it does not explicitly instruct the authors to do so, leaving the action somewhat vague. The authors can infer that they need to address this issue, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the contrastive gap, noting that it has never been defined clearly and that the example provided is less convincing. The comment provides a clear direction for improvement by suggesting the need for a clear, formal definition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" has not been defined clearly, which is a subjective opinion. The reviewer provides some reasoning by mentioning that an intuitive example on the \"idealized\" dataset was given, but the setting of this example is less convincing. However, the comment lacks specific examples or references to support the claim that the definition is unclear or that the example is less convincing. This makes the claim 3, as it provides a general idea but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition of the proposed \"contrastive gap.\" It acknowledges the intuitive example provided on the \"idealized\" dataset but points out that the setting of this example is less convincing. The comment suggests that a clear, formal definition is still lacking, which is a significant area for improvement. By highlighting this issue, the comment provides the authors with a specific direction to enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to define the contrastive gap or provided examples of how others have addressed similar issues. Overall, the feedback is 4 as it directs the authors\" attention to a crucial aspect of their work that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on two lines in the paper, suggesting that the description of the state changes and environment giving a reward is not accurate in standard MDP formulations. It also points out that the description of each action being a single feature or the power set is unclear. The comment explicitly instructs the authors to clarify these points, providing clear and concrete actions for improvement. The authors know exactly what needs to be addressed and how to do so, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the description of the state changes and environment giving a reward, and the ambiguity regarding whether each action is a single feature or the power set. The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the state changes and environment giving a reward is not accurate in standard MDP formulations. The reviewer provides a specific example of a line in the paper (\"Then the state changes and environment gives a reward\") and suggests that this is not consistent with standard MDP formulations. However, the comment lacks detailed reasoning or references to support the claim that this is not true. The suggestion to clarify the description of each action being a single feature or the power set is also vague and lacks specific guidance. As a result, the claim is 3, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the argument.", "helpfulness_rationale": "The review comment provides specific feedback on two lines in the paper, pointing out inaccuracies in the description of the state changes and environment giving a reward, which is not consistent with standard MDP formulations. It also highlights ambiguity in the description of each action being a single feature or the power set. The comment offers clear and actionable suggestions for improvement, such as clarifying these points to align with standard MDP formulations. This feedback is 4 as it guides the authors on how to enhance the clarity and accuracy of their description, but it could be more comprehensive if it included additional suggestions or examples. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those discussed in related work 29, 5, 6, to provide a more comprehensive comparison. It also mentions that the authors have addressed their weaknesses in their response and that the reviewer raised their score as a result. The comment implies that the authors should consider adding these baselines to the final version of the paper. However, it does not provide specific guidance on how to implement this suggestion or which baselines to include. The action is implicit and somewhat vague, as the authors know they need to add baselines but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those discussed in related work 29, 5, 6, to provide a more comprehensive comparison. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment also raises questions about testing beforehand, but it does not provide specific guidance on how to address these questions. While the suggestion is specific in terms of including baselines, the lack of grounding makes it difficult for the authors to pinpoint where to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include other baselines, such as those discussed in related work 29, 5, 6, to provide a more comprehensive comparison. However, the comment does not provide specific reasoning or examples to support why these baselines are necessary or how they would improve the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some suggestion but lacks sufficient evidence or explanation to be 5.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those discussed in related work 29, 5, 6, to provide a more comprehensive comparison. This feedback is 3 as it points out a potential area for improvement in the paper. However, the comment lacks specific guidance on which baselines to include or how to integrate them into the paper. Additionally, the comment raises questions about testing beforehand, which could be a valuable area for the authors to explore. While the feedback identifies a relevant area for improvement, it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a grammatical issue in the paper, specifically the use of \"to meet\" in the phrase \"a response candidate can meet each utterance.\" However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on how to correct the phrasing or improve the clarity of the sentence. As a result, the authors are left without a clear understanding of what changes are needed to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a grammatical issue with the use of \"to meet\" in the phrase \"a response candidate can meet each utterance.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"to meet\" in the phrase \"a response candidate can meet each utterance\" is grammatically incorrect and difficult to understand. However, the comment does not provide any explanation or reasoning to support this claim, nor does it offer examples or references to clarify the issue. Without additional context or justification, the authors may find it challenging to understand and address the problem. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a grammatical issue in the paper, specifically the use of \"to meet\" in the phrase \"a response candidate can meet each utterance.\" This is a clear and actionable observation that can help the authors improve the clarity and readability of their draft. However, the comment does not provide any suggestions or guidance on how to correct the phrasing or improve the sentence. While it highlights a specific area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a discrepancy between the notation used in the text and the figure, specifically mentioning that the task loss is referred to as L_task in the text but L_class in Figure 1. This is a clear and explicit action for the authors to correct the notation consistency in their paper. The comment provides a direct instruction on what needs to be changed, making it 5. The authors know exactly what needs to be addressed and how to implement the correction, ensuring that the feedback is actionable and specific.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy in the notation used for the task loss, referring to it as L_task in the text but L_class in Figure 1. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistency in notation used in the text and figure. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the notation used in the paper, noting that the task loss is referred to as L_task in the text but L_class in Figure 1. This is a clear and actionable piece of feedback that the authors can easily address by correcting the notation consistency. By making this correction, the authors can improve the clarity and professionalism of their paper, ensuring that the notation used is consistent throughout. The comment is specific and provides a direct path for improvement, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the limitations of the method, specifically asking about other limitations in the graph case and questioning whether the network being shallow is a concern here. While the comment implies that the authors should consider additional limitations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore other limitations and consider the depth of the network. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the limitations of the method, specifically in the context of the graph case, where the network is described as \"pretty shallow.\" However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in asking about other limitations and the depth of the network, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely descriptive. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the limitations of the method, specifically in the context of the graph case, where the network is described as \"pretty shallow.\" This inquiry prompts the authors to consider additional limitations and the depth of the network, which could be crucial for understanding the scope and applicability of their method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address these limitations or improve their analysis. While it identifies an area for improvement, the feedback is vague and lacks depth, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method should be evaluated in machine translation, which is considered a more convincing approach due to the lower uncertainties per word. While the comment implies that the authors should include machine translation as part of their evaluation, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete suggestion for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is considered a more convincing approach due to lower uncertainties per word. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting an additional evaluation method, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation would be more convincing due to lower uncertainties per word. This claim is 3 as it provides a logical reasoning for why machine translation is a more convincing evaluation method. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation could provide a more convincing assessment due to lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation framework. However, it could be more helpful if it offered additional guidance on how to implement this suggestion or why machine translation is particularly beneficial for this evaluation. Overall, the comment is 4 as it directs the authors to a potential enhancement in their evaluation approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implementation of the dropout method, specifically asking about the dropping rate and the number of masks generated. While the question is clear and specific, it does not provide explicit instructions on how the authors should address it. The authors can infer that they need to clarify these details in their draft, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout\" method and the \"reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the dropping rate and the number of masks generated. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the implementation of the dropout method, specifically regarding the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of the dropout method, specifically asking for clarification on the dropping rate and the number of masks generated. This is a relevant and specific inquiry that could help the authors clarify their methodology, which is crucial for the reproducibility and understanding of their work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies an area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should provide further justifications for the effectiveness of their twostage optimization approach. It highlights the need to show a performance drop on fusion models and emphasizes the importance of comparisons with other singlestage attacks to demonstrate effectiveness. Additionally, it points out the necessity of benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. The comment provides clear and concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"effectiveness of the proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks against stateoftheart (SOTA) algorithms. This level of detail provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that merely showing a performance drop on fusion models is insufficient and emphasizes the need for comparisons with other singlestage attacks and stateoftheart (SOTA) algorithms to demonstrate effectiveness. The comment provides logical reasoning by highlighting the importance of benchmarking and comparisons to substantiate the claims. However, it lacks specific examples or references to other works that could support the claim further. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical area for improvement in the paper, specifically the need for further justifications regarding the effectiveness of the proposed twostage optimization approach. It provides clear and actionable feedback by suggesting that the authors should demonstrate the performance drop on fusion models and compare their approach with other singlestage attacks. Additionally, it emphasizes the importance of benchmarks and comparisons with stateoftheart (SOTA) algorithms to substantiate the technical contributions. This detailed guidance empowers the authors to significantly enhance the clarity and impact of their work, making the comment highly valuable for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not provide information about the type of GPUs used and the inference time during testing. However, it does not offer any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific types of GPUs or suggesting how to measure and report inference time. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information is missing from, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these details are typically discussed, the comment lacks full grounding. It is specific in identifying the missing information but not in terms of where it should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of information about the type of GPUs used and the inference time during testing. This feedback is 3 as it highlights a gap in the paper that the authors need to address. However, it lacks depth and does not provide suggestions on how to improve the draft or what specific details should be included. The authors are left with a clear indication of a problem but without guidance on how to resolve it, making the comment 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate comments. The first comment questions the monotonic increase of performance with respect to \u03bb values and suggests exploring smaller \u03bb values. This is an implicit action, as the authors are prompted to consider further analysis, but it lacks concrete guidance on how to conduct this exploration. The second comment points out missing elements in the text, specifically mentioning the omission of \u03c4 and \u03b7 in the bracket on page 3, line 2, and the omission of s\" in the paragraph on D4PG. This is a clear and explicit action, providing specific details on what needs to be corrected. Overall, the comment is 4 due to the explicit nature of the second part and the implicit nature of the first part, which could be more detailed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear details on what needs to be addressed: questioning the monotonic increase of performance with respect to \u03bb values and suggesting further analysis, as well as pointing out missing elements in the text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment questions the monotonic increase of performance with respect to \u03bb values and suggests exploring smaller \u03bb values. This is a subjective claim that requires further justification or evidence to support the suggestion. The second comment points out missing elements in the text, specifically mentioning the omission of \u03c4 and \u03b7 in the bracket on page 3, line 2, and the omission of s\" in the paragraph on D4PG. This is a factual observation without any claim or suggestion, making it a normal statement. Therefore, the comment is partially verifiable due to the first part, which lacks sufficient justification, and the second part is factual. Overall, the comment is 3.", "helpfulness_rationale": "The review comment provides two separate pieces of feedback. The first comment questions the monotonic increase of performance with respect to \u03bb values and suggests exploring smaller \u03bb values, which is a relevant and actionable suggestion for the authors to consider. However, it lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. The second comment points out missing elements in the text, specifically mentioning the omission of \u03c4 and \u03b7 in the bracket on page 3, line 2, and the omission of s\" in the paragraph on D4PG. This is a clear and actionable suggestion that can be easily addressed by the authors. Overall, the comment provides some useful insights but could be more comprehensive and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be corrected in the figure. The comment is specific and actionable, as it gives a direct instruction on how to improve the figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the connection between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This provides clear guidance on what aspect of the figure needs correction. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any reasoning, examples, or references to support why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 2. It points out a potential issue with the Perceptual Metric, indicating that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and directly instructs the authors on how to enhance the figure, making it 4. However, it could be more helpful if it included additional context or explanation on why this change is necessary or how it would improve the figure. Therefore, the comment is rated as 4, consistent with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors reread it and the subsequent sentences to understand it. While the comment implies that the authors should reexamine the sentence, it does not provide explicit guidance on how to clarify it or what specific changes should be made. The action is implicit and somewhat vague, as the authors know they need to reexamine the sentence but are not given concrete steps on how to improve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, namely that it is confusing and not immediately clear in its meaning. The comment suggests that rereading the sentence and subsequent sentences would help the authors understand it, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and not immediately clear in its meaning. The reviewer suggests that rereading the sentence and subsequent sentences would help clarify it. However, the comment does not provide any additional context, examples, or references to support the claim that the sentence is confusing. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with a sentence in the paper, noting that it is confusing and not immediately clear in its meaning. The reviewer suggests that the authors reread the sentence and subsequent sentences to understand it better. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how to clarify the sentence or what changes could be made to enhance its clarity. This limits the comment\"s usefulness, as it provides some insight but does not offer actionable feedback for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies specific lines in the paper where citations or evidence are missing, such as lines 7879, 129130, 156158, and 217218. It provides clear actions for the authors to take, including adding citations and evidence where necessary. The feedback is concrete and direct, giving the authors precise guidance on what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (7879, 129130, 156158, and 217218) where citations or evidence are missing. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed in each of these lines, such as adding citations or evidence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims regarding the performance of diffusion models compared to generative adversarial networks, the limitations of previous work, and the benefits of diffusion models in terms of reliability and efficiency. Each claim is supported by a request for evidence or a citation, which provides a clear rationale for why these claims are important. However, the comment does not provide specific examples or references to substantiate the claims, which could enhance the verifiability. Overall, the claims are 4 as they are supported by logical reasoning and a request for evidence, but they could be strengthened with more detailed references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific lines in the paper where citations or evidence are missing, providing clear and actionable feedback for the authors. It highlights areas where the paper claims need to be supported with references or evidence, such as the performance of diffusion models compared to generative adversarial networks, the limitations of previous work, and the benefits of diffusion models in terms of reliability and efficiency. By pinpointing these specific areas, the comment offers a structured approach for the authors to improve the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided examples of relevant citations or evidence. Overall, the feedback is 4, as it guides the authors toward making significant improvements to their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, specifically noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should clarify the differences between the two figures. However, it does not provide explicit instructions on how to make the figures consistent or suggest specific changes to achieve this consistency. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy but are not given concrete guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency between the two figures regarding the encoderdecoder setup for multiple tasks. The comment provides a clear explanation of the discrepancy, making it easy for the authors to understand and address the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2, specifically noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This claim is supported by a clear and direct observation of the figures, making it easy for the authors to understand and address the issue. The comment provides a straightforward explanation of the discrepancy, which is sufficient for the authors to make the necessary adjustments. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This feedback is clear and actionable, as it highlights a discrepancy that the authors need to address to improve the clarity and consistency of their figures. By pointing out this issue, the comment provides the authors with a concrete direction for enhancing the accuracy and readability of their paper. However, it could be more helpful if it suggested specific ways to resolve the inconsistency or provided examples of how to present the information more effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of equation 2 and the mention of neighboring nodes. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or clarification on this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2\" and the description of \"N_l^(s),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the question of whether each node can attend to its own lowerlevel representation, based on the description of neighboring nodes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the description of equation 2 and the mention of neighboring nodes. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the description of equation 2 and the mention of neighboring nodes, specifically questioning whether each node can attend to its own lowerlevel representation. This feedback is 3 as it identifies a potential area of confusion in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. The comment could be more helpful if it offered constructive feedback or suggestions for improvement, making it more actionable for the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It suggests that the authors should explain the role of Lemma 7 in deriving the inequality, which provides a clear and direct action for the authors to take. The comment is specific and gives a concrete direction on how to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the explanation of how the inequality after line 433 follows from Lemma 7. The comment requests a clarification on the role of Lemma 7 in deriving the inequality, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the derivation of an inequality from Lemma 7. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of the paper that requires clarification, namely, the derivation of an inequality from Lemma 7. By asking for an explanation of how Lemma 7 contributes to the inequality, the reviewer provides a clear and actionable suggestion for improving the clarity and comprehensibility of the paper. However, the comment could be more helpful if it offered additional guidance on how to present this explanation effectively or suggested ways to enhance the overall understanding of the material. Despite this, the feedback is still valuable and provides a solid foundation for the authors to improve their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity regarding the main contribution, the overstated claims about the proposed method\"s properties, and the unclear explanation of how the automation is achieved. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, the proposed method\"s novel properties, and the automation process. However, it does not specify which sections or parts of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the claims and the lack of clarity regarding the method\"s capabilities and automation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, as the proposed method is described as having 8 novel properties, but these claims are either overstated or not wellsupported. The reviewer also notes that the main idea of how the proposed method copes with dynamic largescale multitasking and the automation process are not clear. While the comment identifies specific areas of confusion, it lacks detailed reasoning or examples to fully substantiate these claims. The authors would need to make significant effort to understand and address the issues raised, making the claim 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of clarity regarding the main contribution, the overstated claims about the proposed method\"s properties, and the unclear explanation of how the automation is achieved. This feedback is valuable as it highlights areas where the paper needs significant improvement to better articulate its contributions and findings. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is 3 as it points out important weaknesses but lacks detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the results of the bottomup method 9 on the crowdpose dataset in the tables, as it outperforms all methods in Table 4. It also recommends evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (non occluded) settings. While the comment provides specific actions for inclusion and evaluation, it does not offer detailed guidance on how to implement these suggestions, such as which aspects of the results to focus on or how to present the findings. The actions are explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"crowdpose dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the inclusion of the bottomup method 9 and recommending an evaluation on the standard MS COCO dataset, particularly in easy (non occluded) settings. This provides clear guidance on what needs to be addressed and improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the results of the bottomup method 9 on the crowdpose dataset in the tables, as it outperforms all methods in Table 4. It also recommends evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (non occluded) settings. While the comment provides a logical suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the bottomup method 9 is helpful, but the comment could be more robust with additional context or evidence. Therefore, the comment is 3, as it provides a reasonable suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper\"s evaluation and results presentation. It suggests including the results of the bottomup method 9 on the crowdpose dataset, as it outperforms all methods in Table 4. Additionally, it recommends evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (non occluded) settings. These suggestions are actionable and provide clear guidance on how the authors can enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it offered further details on how to implement these suggestions or why these evaluations are particularly important. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and suggests that the paper only considers label name, label description, and fewshot examples, while in reality, annotation guidelines in the IE domain are complex and curated by linguists. It provides an example from TACRED slot filling to illustrate the complexity of annotation guidelines. However, the comment does not explicitly instruct the authors to revise their claims or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and possibly provide more detailed justification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example from TACRED slot filling to illustrate the complexity of annotation guidelines. It also specifies the issue by questioning the depth of guideline understanding and suggesting that the prompts proposed by the paper might not fully capture this complexity. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and provides a specific example from TACRED slot filling to illustrate the complexity of annotation guidelines. It references a document that details the rules for annotators, such as the use of \"GPEs below the city level\" as an example rule. This external reference supports the claim by demonstrating the depth of annotation guidelines, which the paper may not fully capture. However, the comment could be strengthened by providing more detailed examples or a broader discussion of annotation guidelines in the IE domain. Overall, the claim is 4 due to the inclusion of a specific reference, but it could be more robust with additional examples or explanations.", "helpfulness_rationale": "The review comment challenges the claim of using \"annotation guideline\" by questioning its overstatement. It provides a specific example from TACRED slot filling, where annotation guidelines are complex and curated by linguists, to illustrate the depth of annotation guidelines. The comment highlights that the paper only considers label name, label description, and fewshot examples, suggesting that the prompts proposed might not fully capture the complexity of guideline understanding. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and possibly provide more detailed justification or examples to support their assertion. However, it could be more helpful if it offered suggestions on how to address the issue or integrate the complexity of annotation guidelines into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the experiment comparison is weak and recommends that the authors compare their method to token pruning and token combination baselines. This feedback provides a clear and direct action for the authors to take, specifying which baselines should be included in the comparison. The comment is specific and offers concrete guidance on how to enhance the experimental evaluation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiment comparison is weak and recommends comparing the method to token pruning and token combination baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in suggesting additional comparisons, but it lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak, specifically mentioning that the author only compares their method to the BERTbaseline. The reviewer suggests that the author should include comparisons to token pruning and token combination baselines. However, the comment does not provide any supporting evidence or reasoning to justify why these additional comparisons are necessary or how they would enhance the study. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental comparison, noting that it is weak and only compares the method to the BERTbaseline. It suggests that the authors should include comparisons to token pruning and token combination baselines to strengthen the evaluation. This feedback is clear and actionable, providing the authors with a concrete direction for improving their experimental design. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or why these specific baselines are important. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison with coordinateaware methods like TFN or SchNet. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it does not provide specific guidance on how to implement this comparison or what aspects of the comparison should be emphasized. The action is concrete but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section should include a comparison with coordinateaware methods like TFN or SchNet. However, it does not specify which part of the experimental section this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a type of comparison that should be included, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison with coordinateaware methods like TFN or SchNet. However, it does not provide specific reasoning or evidence to support why these methods are more appropriate or beneficial to include. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section by suggesting that it should include a comparison with coordinateaware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental section. By recommending a comparison with these methods, the comment offers a clear direction for the authors to expand their analysis and potentially strengthen their results. However, the comment could be more helpful if it provided additional context or rationale for why these methods are particularly relevant or beneficial to include. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not demonstrate the possible weaknesses of the proposed model. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions for the authors to take, such as suggesting potential weaknesses or providing examples of how to evaluate them. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of demonstration of the possible weaknesses of the proposed model. However, it does not specify which part of the paper this issue is related to, such as a particular section or analysis where the weaknesses should be addressed. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific in identifying the need for demonstrating weaknesses, it lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not demonstrate the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, specifically the lack of demonstration of the possible weaknesses of the proposed model. This feedback is valuable as it highlights an area where the authors need to provide more comprehensive analysis or evidence to strengthen their work. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending potential weaknesses or methods to evaluate them. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the novelty and effectiveness of the proposed idea in the context of long document summarization. It suggests that the authors should compare their approach with other extractthengenerate methodologies and explore the system\"s advantages over these methods. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with existing methodologies and discuss the system\"s advantages. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the novelty and effectiveness of the proposed idea in the context of long document summarization. It suggests comparing the system with other extractthengenerate methodologies and discusses the system\"s advantages over these methods. However, the comment does not specify which part of the paper should include this comparison or discussion, making it weakly grounded. The authors can infer that it relates to the Related Work section or the discussion of methodologies, but this inference is not direct. The comment is specific in its questions about the system\"s advantages and the lack of a Related Work section, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the novelty and effectiveness of the proposed idea in the context of long document summarization. It suggests that the authors should compare their approach with other extractthengenerate methodologies and discuss the system\"s advantages over these methods. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the proposed idea is novel or effective. This lack of detailed justification makes the claim 3, as the authors would need to conduct further research or provide more evidence to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant question about the novelty and effectiveness of the proposed idea in the context of long document summarization. It suggests that the authors should compare their approach with other extractthengenerate methodologies and discuss the system\"s advantages over these methods. This feedback is 3 as it prompts the authors to consider the broader context of their work and potentially identify gaps in their contribution. However, the comment could be more helpful if it provided specific examples or references to related work, which would guide the authors in addressing the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of training 3040 models for burnin testing and suggests alternative approaches, such as using unlabelled data or applying constraints. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the practicality of training 3040 models for burnin testing and suggests alternative approaches, such as using unlabelled data or applying constraints. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting alternative approaches, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of training 3040 models for burnin testing and suggests alternative approaches, such as using unlabelled data or applying constraints. However, the comment does not provide specific reasoning or evidence to support why this approach is not appealing or why the suggested alternatives are more effective. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a concern about the practicality of training 3040 models for burnin testing, suggesting that this approach may not be appealing. It offers an alternative direction for dealing with churn by proposing the use of unlabelled data or applying constraints. This feedback is 3 as it identifies a potential weakness in the methodology and suggests a more feasible approach for addressing the issue. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these alternative methods. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the introduction of related work is insufficient and suggests that more work on GLN should be included to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. While the comment implies that the authors should expand their related work section, it does not provide explicit guidance on how to incorporate this additional information or what specific aspects of GLN should be highlighted. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on GLN and understand the specific differences to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, indicating that it is insufficient and suggesting that more work on GLN should be included to reflect the advantages or differences of the proposed method. However, it does not specify which part of the introduction is lacking or how it should be expanded. The authors might infer that it relates to the introduction section, but this inference is not direct. The comment is specific in suggesting that more work on GLN should be included, but it lacks grounding as it does not pinpoint the exact part of the paper that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment does not provide specific examples, references, or detailed reasoning to support why GLN should be given more attention or how it would better reflect the proposed method\"s advantages. This lack of detailed justification makes the claim 2, as the authors may find it challenging to understand the basis of the critique and address it effectively.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the introduction of related work, noting that it is insufficient and suggesting that more work on GLN should be included to reflect the advantages or differences of the proposed method. It provides a clear direction for the authors to enhance their related work section by highlighting the need to include more information on GLN. However, the comment could be more helpful if it offered specific examples or guidance on how to incorporate this additional information. Overall, the feedback is 3 as it points out a clear area for improvement but lacks detailed suggestions for execution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout involves inputoutput and recurrent dropout parameters. This comment implies that the authors should consider the differences in the use of hyperparameters between the two approaches. However, it does not provide explicit guidance on how to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the differences in hyperparameter usage and potentially adjust their methodology accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used while Variational dropout involves inputoutput and recurrent dropout parameters. This question is specific and relates to the methodology section of the paper, allowing the authors to identify the relevant part of the paper being addressed. However, it does not provide detailed guidance on what needs to be addressed or how to improve the approach. Therefore, the comment is weakly grounded because it does not explicitly mention the section, but it is specific in its inquiry. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of a question asking for clarification on the use of hyperparameters in Moon\"s approach, specifically regarding the dropout rates used. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of hyperparameters in Moon\"s approach, particularly focusing on the dropout rates used. It highlights a discrepancy between the use of a single dropout rate and the more complex inputoutput and recurrent dropout parameters used in Variational dropout. This feedback is 3 as it identifies a potential inconsistency in the methodology and prompts the authors to consider the implications of this discrepancy. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the impact of this choice on the model\"s performance. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct largerscale experiments, specifically mentioning the inclusion of gridworlds with walls and other nontrivial tiles. It also provides an example of using simple videogame domains for experiments, noting that these naturally have lowcardinality discrete state and actionspaces. The comment implies that the authors should perform these experiments to better assess the scalability of their method. While the action is explicit, it lacks concrete details on how to implement these experiments or what specific aspects to focus on. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests conducting largerscale experiments, specifically mentioning the inclusion of gridworlds with walls and other nontrivial tiles. It also provides an example of using simple videogame domains for experiments, noting that these naturally have lowcardinality discrete state and actionspaces. This provides a clear direction for the authors to address the issue of scalability. However, the comment does not explicitly mention a specific section of the paper where these experiments should be included, making it weakly grounded. The suggestion is specific in terms of what experiments should be conducted, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls. The reviewer questions whether the difficulty in conducting these experiments is due to a lack of time or scalability issues. The comment provides a logical reasoning by suggesting that using simple videogame domains could be a convincing alternative, as they naturally have lowcardinality discrete state and actionspaces. However, the comment lacks specific examples or references to similar experiments, which would strengthen the argument. Therefore, the claim is 3, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by suggesting that largerscale experiments, particularly those involving gridworlds with walls and other nontrivial dynamics, would provide valuable insights into the scalability and effectiveness of the method. It questions whether the difficulty in conducting these experiments is due to a lack of time or scalability issues. The comment is 4 as it provides a clear direction for the authors to enhance their experimental design, offering a specific example of a domain (simple videogame domains) that could be used to test the method. However, it could be more helpful if it included suggestions on how to implement these experiments or provided more detailed guidance on the potential challenges. Overall, the feedback is actionable and constructive, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement regarding the extent of occupation bias relative to real distributions in society. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include such measurements, but it lacks concrete instructions on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement regarding occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for quantitative measurements, but without clear grounding, the authors may struggle to determine where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement regarding the extent of occupation bias relative to real distributions in society. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that the authors did not propose any quantitative measurement regarding the extent of occupation bias relative to real distributions in society. This feedback is clear and highlights a critical area for improvement, as it points out a lack of empirical evidence or data to support the claims made in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular metrics or methods for measuring occupation bias. While it effectively points out a significant area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of Stochastic Gradient Descent (SGD) and its potential impact on the findings. It specifically asks whether such a method might amplify updates for weights associated with hard features, such as x2. While the comment poses a question, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors can infer that they need to consider the implications of using adaptive gradient methods, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of Stochastic Gradient Descent (SGD) and its potential impact on the findings. It specifically asks whether such a method might amplify updates for weights associated with hard features, such as x2. However, it does not explicitly mention which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential impact of adaptive gradient methods on the findings, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of Stochastic Gradient Descent (SGD) on the findings. It specifically asks whether such a method might amplify updates for weights associated with hard features, such as x2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that adaptive gradient methods could affect the findings. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the potential impact of using adaptive gradient methods instead of Stochastic Gradient Descent (SGD) on the findings. It specifically asks whether such a method might amplify updates for weights associated with hard features, such as x2. This question prompts the authors to consider the implications of their choice of optimization method on their results, which is a valuable area for exploration. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what aspects of their work could be affected. While it identifies an important consideration, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest improvements. The comment implies that the authors should consider expanding the range of teacher architectures or comparing with more recent methods, but it lacks concrete steps or specific suggestions on how to do so. As a result, the authors are left without clear direction on how to enhance their draft, making the comment 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of sufficient experiments and the limited types of teacher architectures. It also mentions that most compared methods were proposed before 2019, referencing a table. This provides some grounding as the authors can infer that the comment pertains to the experimental section and the table. However, the comment does not explicitly mention which parts of the table or experiments are insufficient, making it weakly grounded. The comment is specific in detailing the issues with the experiments and the types of teacher architectures, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. The comment references a table, which provides some context, but it does not elaborate on why these limitations are problematic or how they impact the study. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issues. Therefore, the claim is 3, as it provides some basis but requires more detailed explanation or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas where the experiments could be improved: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. This feedback is 3 as it highlights potential weaknesses in the experimental design and suggests that the authors should consider expanding their scope to include more diverse teacher architectures and recent methods. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as recommending specific types of teacher architectures or methods to include. While it points out areas for improvement, it does not provide actionable steps for the authors to take, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of missing information or why the method is considered effective. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of missing information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of information and the simplicity of the method, but it lacks grounding as it does not reference a particular section or figure. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the assertion that the method is simple or why the lack of 2hop neighbor information is a problem. This makes the claim 3, as the authors would need to infer the basis of the critique without explicit support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that no information from 2hop neighbors is included and questioning the effectiveness of the method. While it highlights a potential weakness in the approach, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their method. The comment is 3 as it points out a critical area for improvement, but it does not offer a comprehensive or detailed response that would guide the authors in making significant changes to their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using real DICOM images instead of PNG images for the experiment and recommends using the FastMRI challenge dataset. It also suggests comparing inference speed between different methods. While the comment provides specific actions and a recommendation, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are concrete, but the comment could be more actionable if it included stepbystep instructions or examples. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests using real DICOM images instead of PNG images for the experiment and recommends using the FastMRI challenge dataset. It also suggests comparing inference speed between different methods. While the comment provides specific suggestions, it does not explicitly mention which part of the paper these suggestions pertain to, such as the experimental setup or results sections. The authors can infer that these suggestions relate to the experimental methodology or results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what needs to be addressed. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests using real DICOM images instead of PNG images for the experiment and recommends using the FastMRI challenge dataset. It also suggests comparing inference speed between different methods. While the comment provides specific recommendations, it lacks detailed reasoning or evidence to support why these choices are beneficial or necessary. The suggestion to compare inference speed between methods is logical but could be more robust with additional justification or examples. Therefore, the comment is 3, as it provides some guidance but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of real DICOM images instead of PNG images for the experiment, recommending the FastMRI challenge dataset, and suggesting a comparison of inference speed between different methods. These suggestions are clear and offer a clear path for improvement, helping the authors enhance the quality and relevance of their work. However, the comment could be more helpful if it included additional context or explanation on why these changes are beneficial or how they might impact the results. Overall, the feedback is 4 as it guides the authors toward making meaningful improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that ProtPainter provides only an empirical confirmation for binder design and implies that further optimization and validation are needed. While the comment implies that the authors should perform additional optimization and validation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct further optimization and validation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the binder design aspect, which provides some level of grounding as it specifies a particular area of the paper. However, it does not explicitly mention which part of the binder design is being discussed, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that ProtPainter only provides an empirical confirmation for binder design and suggests that further optimization and validation are required. However, the comment does not provide specific examples or references to support this claim, nor does it explain why further optimization and validation are necessary. This lack of detailed justification makes the claim 2, as the authors may find it challenging to understand the basis of the critique without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the binder design aspect. It points out that ProtPainter only provides an empirical confirmation and suggests that further optimization and validation are necessary. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their analysis in this area. However, the comment could be more helpful if it provided specific suggestions on how to achieve this optimization or validation, such as recommending particular methods or techniques to consider. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on how the model in Figure 7 was trained, specifically regarding the stimulus used and the duration of the cycle. It also poses a question about how the time scale of adaptation might change if the cycle duration is altered. This feedback provides clear and direct actions for the authors to take, ensuring they know exactly what information needs to be clarified or explored. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the training of the model in Figure 7, including the type of stimulus used and the potential impact of changing the cycle duration. The comment also references a specific study, Smirnakis et al. Nature 1997, which provides additional context and supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the training of the model in Figure 7. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment \"No\".", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of confusion regarding the training of the model in Figure 7. It asks for clarification on the type of stimulus used and the duration of the cycle, which are crucial details for understanding the experimental setup. Additionally, it poses a question about the potential impact of changing the cycle duration on the time scale of adaptation, referencing a relevant study for context. This feedback provides clear and actionable guidance for the authors to improve the clarity and comprehensiveness of their paper. However, it could be more helpful if it offered suggestions on how to address these questions or provide additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the implications of having a CAD model already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or incorporate it into their work. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model already associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or discussion. Without explicit references to the paper\"s content, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what the authors should consider or address in response to this question. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the implications of having a CAD model already associated with spatiallyvarying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of having a CAD model already associated with spatiallyvarying (SV) BRDF maps. While it identifies a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this issue or incorporate it into their work. The comment lacks actionable feedback, making it unhelpful in its current form. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on the CIFAR10 dataset in both full label and lower label scenarios. While the comment implies that additional evaluation is needed, it does not explicitly instruct the authors to conduct this evaluation or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should perform more evaluations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, specifically mentioning the CIFAR10 dataset in both full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be conducted on, making it weakly grounded. The comment is specific in suggesting additional evaluation, but without clear guidance on where to place this evaluation, the authors may struggle to identify the exact sections that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, particularly on the CIFAR10 dataset in both full label and lower label scenarios. However, the comment does not provide any specific reasoning or evidence to support why this additional evaluation is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on the CIFAR10 dataset in both full label and lower label scenarios. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how the authors might conduct this additional evaluation or what aspects of the evaluation would be most beneficial. This limits the utility of the feedback, as it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the comparisons in Table 2, specifically questioning whether they are applestoapples in terms of data usage. The reviewer points out that certain comparisons use less data than others, which could affect the validity of the results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It implies that the authors should ensure that comparisons are made with the same amount of data, but it does not specify how to implement this change. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the comparisons in Table 2, questioning whether they are applestoapples in terms of data usage. The comment provides specific examples of comparisons that use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This level of detail provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the comparisons in Table 2, specifically regarding the use of the same amount of data. The reviewer provides examples of comparisons that use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or references that have addressed similar issues, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons in Table 2, specifically questioning whether they are applestoapples in terms of data usage. The reviewer provides specific examples of comparisons that use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is clear and actionable, as it highlights a specific area where the authors need to ensure consistency in their data usage for accurate comparisons. However, the comment could be more helpful if it suggested ways to address this issue or provided guidance on how to ensure applestoapples comparisons. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two separate issues. First, it questions the counterintuitive placement of a suggestion at the end of the paper, asking for clarification on whether the authors apply Algorithm 1 with one or two iterations and what happens for larger iterations. This part is 3 as it prompts the authors to clarify their reasoning, but it lacks specific guidance on how to address the concern. Second, the comment points out the absence of a reference to Laplacian eigenmaps in the introduction and notes that it was not cited in the introduction. This part is explicit, as it clearly instructs the authors to include a reference to Laplacian eigenmaps in the introduction. Overall, the comment provides a mix of implicit and explicit actions, making it 3.", "grounding_specificity_rationale": "The comment addresses two separate issues. First, it questions the counterintuitive placement of a suggestion at the end of the paper, prompting the authors to clarify their reasoning. This part is weakly grounded as it does not specify which part of the paper is being addressed, and it is not specific about what needs to be clarified. Second, the comment points out the absence of a reference to Laplacian eigenmaps in the introduction and notes that it was not cited in the introduction. This part is fully grounded as it explicitly mentions \"Line 224\" and \"the introduction,\" allowing the authors to accurately identify the sections being addressed. However, the comment does not specify what is missing or how it should be addressed, making it underspecific. Therefore, the comment is weakly grounded and underspecific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two separate claims. The first claim questions the counterintuitive placement of a suggestion at the end of the paper, prompting the authors to clarify their reasoning. This claim is 3 as it raises a logical concern but lacks specific examples or references to support the claim. The second part of the comment points out the absence of a reference to Laplacian eigenmaps in the introduction and notes that it was not cited in the introduction. This claim is 3 as it identifies a factual omission, but it could be strengthened with references to relevant literature. Overall, the comment is 3 due to the lack of detailed justification for the first claim and the need for more context for the second claim.", "helpfulness_rationale": "The review comment raises two separate issues. First, it questions the counterintuitive placement of a suggestion at the end of the paper, prompting the authors to clarify their reasoning. This is 3 as it encourages the authors to provide more context or justification for their suggestion. Second, the comment points out the absence of a reference to Laplacian eigenmaps in the introduction and notes that it was not cited in the introduction. This is a clear and actionable suggestion that can help improve the paper\"s clarity and completeness. However, the comment could be more helpful if it provided specific guidance on how to incorporate the reference or suggested alternative references. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the inclusion of Section 2.1, suggesting that the description of the proposed methodology appears independent of the choice of model. It also implies that the time spent on describing the ResNet architecture could be better utilized to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment highlights areas for improvement, it does not explicitly instruct the authors to remove Section 2.1 or to reorganize the content. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the inclusion of Section 2.1 and possibly reorganize the content. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the inclusion of Section 2.1, questioning its relevance given the generality of Batch Normalization and Conditional Batch Normalization (CBN). It also suggests that the description of the ResNet architecture could be better utilized to provide motivation and intuition for the proposed CBN approach. While the comment does not explicitly mention a specific part of the paper, the authors can infer that it relates to Section 2.1 and the discussion of methodology. The comment is specific in its critique of the inclusion of Section 2.1 and the potential misalignment of the ResNet architecture description. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that the description of the proposed methodology appears independent of the choice of model. It also implies that the time spent on describing the ResNet architecture could be better utilized to provide greater motivation and intuition for the proposed CBN approach. While the comment raises a valid concern about the relevance of the section, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the basis of the critique, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the inclusion of Section 2.1, questioning its relevance given the generality of Batch Normalization and Conditional Batch Normalization (CBN). It suggests that the description of the ResNet architecture could be better utilized to provide greater motivation and intuition for the proposed CBN approach. This feedback is 3 as it identifies a potential area for improvement in the paper\"s structure and content. However, the comment could be more actionable by offering specific suggestions on how to reorganize the content or provide additional motivation for the CBN approach. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption made in the paper regarding the sparsity of the resulting matrix after multiplying by a dense projection matrix. It questions the validity of this assumption and suggests that the resulting matrix might not be sparse, as the multiplication is intended to ensure density. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes could be made to clarify the assumption. The action is implicit and vague, as the authors are left to infer that they need to reconsider or clarify their assumptions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption about the sparsity of the resulting matrix after multiplying by a dense projection matrix. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplying by a dense projection matrix. It suggests that the multiplication might not result in a sparse matrix, as the intention is to ensure density. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the assumption made in the paper regarding the sparsity of the resulting matrix after multiplying by a dense projection matrix. It questions the validity of this assumption and suggests that the resulting matrix might not be sparse, as the multiplication is intended to ensure density. This feedback is 3 as it identifies a potential issue with the assumptions in the paper, prompting the authors to reconsider their approach or clarify their assumptions. However, the comment lacks specific suggestions or guidance on how the authors might address this concern, such as proposing alternative methods or providing more detailed reasoning. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a gap in the paper, noting that the evidence of the motivation is not direct. It suggests that the authors should provide a figure demonstrating the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to provide evidence of the motivation by plotting a figure showing the decline in accuracy of a predictor over time (search steps) in different settings. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the directness of the evidence for the motivation and suggests that the authors should provide a figure demonstrating the decline in accuracy of a predictor over time in different settings. This claim is 3 as it provides a logical suggestion for improvement, but it lacks specific examples or references to support the need for such a figure. The authors would need to infer the importance of this suggestion, making it 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s motivation by pointing out that the evidence is not direct. It suggests that the authors should provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the paper\"s clarity and evidence base. However, the comment could be more helpful if it provided additional guidance on how to design or interpret the figure, or if it discussed the potential impact of such a visualization. Overall, the comment is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk and its calculation. It asks the authors to explain how excessive risk is defined in line 103 and how it is practically calculated, particularly in terms of expectation. The reviewer also questions the nature of the optimal solution \u03b8 \u2217 and its relation to the loss function, noting that it can be negative values. Additionally, the reviewer points out that all excessive risk values in Figures 3 and 7 are positive and asks whether these values are comparable across different groups. Finally, the reviewer inquires about the validity of excessive risk as a representation for fairness. While the comment raises several questions, it does not provide explicit instructions or concrete steps for the authors to address these issues. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (line 103) and figures (Figures 3 and 7), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking for an explanation of the definition of excessive risk, how it is calculated, and its relevance to fairness. The comment further questions the nature of the optimal solution \u03b8 \u2217 and its relation to the loss function, as well as the comparability of excessive risk values across different groups. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the definition and calculation of excessive risk. It questions the nature of the optimal solution \u03b8 \u2217 and its relation to the loss function, as well as the comparability of excessive risk values across different groups. While the comment highlights areas of confusion, it does not provide any claims or opinions that require verification. It is a request for clarification and does not contain subjective opinions or suggestions that need justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and requests for clarification regarding the definition and calculation of excessive risk, as well as its relevance to fairness. It points out that the optimal solution \u03b8 \u2217 is not the optimal solution for the loss function with respect to data from group A, which can be negative values, but the excessive risk values in the figures are positive. This raises a question about the comparability of excessive risk values across different groups. The comment also inquires about the validity of excessive risk as a representation for fairness. While the comment identifies specific areas of confusion and prompts the authors to clarify these points, it lacks detailed suggestions or actionable steps for improvement. The feedback is 3 as it highlights important aspects that need further exploration, but it could be more comprehensive with additional guidance on how to address these issues. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement about initialization should be more carefully stated, implying that the authors need to revise this part of their paper. However, it does not provide specific guidance on how to improve the statement or what aspects should be clarified. The action is implicit and vague, as the authors are left to infer that they need to make the statement more precise without knowing exactly what changes are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Initialization\" and \"NGD is a discretization of NGF,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated and provides a reference to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"Initialization plays a role in NGD, as it is a discretization of NGF, and solving NGF is an initial value problem (IVP) in this setting.\" The comment suggests that the statement about initialization should be more carefully stated. However, it does not provide specific examples, detailed reasoning, or references to support the claim that initialization is crucial in this context. The lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to fully understand and address the issue without additional context or explanation.", "helpfulness_rationale": "The review comment identifies a specific aspect of the paper that requires attention: the role of initialization in the context of Natural Gradient Descent (NGD) and its relationship to the discretization of Natural Gradient Flow (NGF). It suggests that the statement about initialization should be more carefully stated, implying that the authors need to clarify this aspect in their draft. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to address the issue or what aspects of the statement need clarification. This limits the comment\"s helpfulness, as it provides some insight but not actionable feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the lack of clarity on how named entities were extracted from the datasets and the suggestion that an Englishproofreading would improve the readability of the paper. While the first point is explicit, the second point is more of a suggestion without specific guidance on how to implement it. The authors can infer that they need to clarify the extraction process and improve the English proofreading, but the comment lacks concrete details on how to achieve these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the lack of clarity on how named entities were extracted from the datasets and the suggestion that an Englishproofreading would improve readability. However, it does not specify which part of the paper discusses the extraction of named entities, making it difficult for the authors to pinpoint the exact section that needs revision. The suggestion about Englishproofreading is more general and lacks specificity. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two parts: the lack of clarity on how named entities were extracted from the datasets and the suggestion that an Englishproofreading would improve readability. The first part is a statement of fact, while the second part is a suggestion for improvement. Neither part contains subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific areas for improvement. First, it points out that the extraction of named entities from the datasets is not clearly explained, which is a significant issue that could hinder the understanding and reproducibility of the paper. Second, it suggests that an Englishproofreading would improve the readability of the paper, which is a practical and actionable recommendation. While the comment highlights important areas for clarification and improvement, it could be more helpful if it provided specific suggestions on how to address the lack of clarity in the extraction process. Overall, the feedback is 4 as it directs the authors to specific areas that need attention and provides a clear suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the paper, such as questioning the assumption of a single optimistic parameter and suggesting an alternative approach for choosing T_0. These suggestions are explicit and concrete, as they clearly outline what changes the authors should make to address the issues raised. The feedback is actionable because it provides clear guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L200 and L303) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the assumption of a single optimistic parameter and suggesting an alternative approach for choosing T_0. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment questions the assumption of a single optimistic parameter, which is a logical reasoning that requires some explanation to be fully understood. The second comment suggests an alternative approach for choosing T_0, which is a specific suggestion that could be verified with further analysis. However, the comment lacks detailed justification or references to support the claims, making it 3. The authors would need to delve deeper into the reasoning to fully grasp the implications of the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct points. First, it questions the assumption of a single optimistic parameter, which is a critical aspect of the methodology. This suggests that the authors should reconsider their assumptions and possibly explore alternative approaches. Second, the comment offers a suggestion for choosing T_0, which could potentially improve the results by slightly enhancing the condition. These suggestions are clear and provide the authors with concrete directions for improving their draft. However, the comment could be more helpful if it included additional context or explanation on why these changes are important or how they might impact the overall results. Overall, the feedback is 4 as it guides the authors toward making significant improvements to their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to define L and E in the immediate vicinity, noting that they are sometimes italicized and sometimes not. This provides clear and concrete guidance on how to improve the draft by ensuring consistency in the presentation of these elements. The comment is specific and actionable, leaving no ambiguity for the authors on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296\" and \"Line 302,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent italicization of \"L\" and \"E\" in different parts of the paper, and suggests that they should be defined in the immediate vicinity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual observations about the formatting of \"L\" and \"E\" in the paper, noting inconsistencies in their italicization. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out inconsistencies in the formatting of \"L\" and \"E\" in the paper. It explicitly mentions that these elements are sometimes italicized and sometimes not, and suggests that they should be defined in the immediate vicinity. This feedback is clear and directly addresses a potential issue with the paper\"s formatting, which is crucial for improving the clarity and professionalism of the manuscript. By highlighting these inconsistencies, the comment empowers the authors to make a concrete and meaningful revision to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the experimental section is weak and suggests that more experiments are needed. However, it does not provide specific guidance on what additional experiments should be conducted or how they could enhance the section. The action is implicit, as the authors can infer that they need to add more experiments, but the comment lacks concrete details on what those experiments should be or how they should be structured. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and recommends adding more experiments. However, it does not specify which part of the experimental section is weak or what specific experiments are needed to strengthen it. Without explicit references to sections or detailed suggestions, the authors cannot confidently determine which parts of the paper need improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support why the current experiments are insufficient or what additional experiments could be beneficial. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a perceived weakness in the experimental section, suggesting that more experiments are needed. However, it lacks specificity and does not provide detailed guidance on what additional experiments could be conducted or how they might enhance the section. Without actionable suggestions or examples, the authors are left with a general idea of what might be improved but without clear direction on how to proceed. This limits the comment\"s usefulness, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct additional comparisons, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on which models or techniques to include in the comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or results that need to be expanded. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting what additional comparisons should be made, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples of these models or techniques, nor does it offer a rationale for why these comparisons would be beneficial. Without detailed justification or references, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement, specifically in terms of comparative analysis. However, the comment lacks specificity and does not provide detailed guidance on which models or techniques should be included in the comparisons. Without more detailed suggestions, the authors may find it challenging to implement the recommended changes effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to correct grammatical errors in specific lines of the paper. Each line is clearly identified, and the corrections are straightforward, leaving no ambiguity about what needs to be done. The feedback is concrete and direct, allowing the authors to make precise changes to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific feedback on several lines of the paper, indicating exact lines where corrections are needed. It mentions line 2, line 56, line 158, and line 265, allowing the authors to accurately identify the parts of the paper being addressed. Each line has a specific issue, such as correcting grammatical errors or clarifying the meaning of a sentence. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of corrections to grammatical errors in specific lines of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying grammatical errors in lines 2, 56, and 158, and by clarifying the meaning of a sentence on line 265. These corrections are straightforward and would help improve the clarity and professionalism of the paper. However, the comment does not address other potential areas for improvement, such as the overall structure, presentation, or content of the paper. While it offers valuable guidance for specific issues, it lacks a broader scope of feedback, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This suggests that the authors should clarify or correct a mistake in their equations. However, the comment does not provide explicit guidance on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to correct the equations but may not be entirely sure of the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This provides some grounding as it refers to a specific part of the paper, \"W4,\" which likely corresponds to a section or equation. However, the comment does not specify which part of the equations or which specific equations are incorrect, making it difficult for the authors to pinpoint the exact issue. The lack of specificity in detailing what needs to be corrected or clarified makes the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify why this is a mistake or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination or the number of samples, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" This feedback highlights a potential issue with the equations, which could impact the accuracy and validity of the paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or correct the equations. Without detailed feedback or actionable advice, the authors are left without clear direction on how to improve their draft. Therefore, the comment is 2, as it identifies a potential problem but does not offer a comprehensive solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how the authors might address the perceived incrementality or enhance the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the model are considered \"straightforward\" or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model are considered incremental or how they could be enhanced. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"somewhat incremental\" and that the developed model is a \"fairly straightforward extension of the GAN for static images.\" However, the comment lacks any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. While it identifies a potential weakness in the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without actionable feedback or detailed critique, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method could perform better in pure combinational logic without registers, and it implies that comparing sequential design with combinational design would be interesting. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform a comparison but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with sequential design in terms of performance in pure combinational logic without registers. However, it does not specify which part of the paper this comparison should be made, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method might perform better in pure combinational logic without registers and proposes a comparison between sequential and combinational designs. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the proposed method might perform better in pure combinational logic without registers and proposes a comparison between sequential and combinational designs. This feedback is 3 as it identifies a potential area for further investigation and suggests a comparison that could provide additional insights into the method\"s performance. However, the comment lacks specific guidance or detailed suggestions on how to conduct this comparison or what aspects to focus on. While it prompts the authors to consider an important aspect of their work, it does not fully support them in making the necessary improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate the performance of their baseline, which combines LDA and LSTM, in terms of the topic switch percent metric. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to implement the evaluation or what results to expect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating the performance of the baseline, namely LDA+LSTM, in terms of the topic switch percent metric. This provides clear guidance on what needs to be addressed in the experiment section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim about the baseline combining LDA and LSTM, suggesting that it can capture both sequential information and topic assignments. The reviewer expresses curiosity about the performance of this baseline in terms of the topic switch percent metric. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the need for further evaluation. This lack of justification makes the claim 1, as the authors are left without a clear understanding of why this baseline is worth evaluating or how it might impact the results.", "helpfulness_rationale": "The review comment raises a question about the performance of the baseline, specifically the LDA+LSTM model, in terms of the topic switch percent metric. This is a relevant and actionable suggestion that could help the authors evaluate the effectiveness of their proposed baseline. By addressing this question, the authors can gain insights into how well their model captures topic transitions, which is an important aspect of evaluating the model\"s performance. However, the comment could be more helpful if it provided additional guidance on how to conduct this evaluation or what specific metrics to focus on. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed instructions for the authors to fully benefit from it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the motivation and potential applications of the work, particularly regarding amodal tracking. It suggests that the authors should clarify the importance of their task and explore downstream applications or benefits. Additionally, it implies that the authors should address how uncertainty in amodal predictions can be handled or utilized in subsequent tasks. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer the specific actions to clarify the motivation and explore applications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind the task, specifically questioning the clarity of the task\"s relevance when an object is totally occluded. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not specify which part of the paper discusses the motivation or the task, making it weakly grounded. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in its questions about the motivation and applications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation and relevance of the task, particularly when an object is totally occluded. It highlights the difficulty in predicting the object\"s state and the potential issues with annotation quality. The comment suggests that the authors should clarify the motivation and explore downstream applications or benefits of amodal tracking. However, it lacks specific examples or references to support the claim that the motivation is unclear or to provide a clear rationale for the need for clarification. This makes the claim 3, as the authors would need to infer the reasoning and provide their own justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the motivation and relevance of the task, particularly when an object is totally occluded. It points out the difficulty in predicting the object\"s state, including position, size, and motion, and questions the quality of annotation due to the uncertainty of the object\"s real states. The comment also prompts the authors to consider potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled or utilized in subsequent tasks. While the comment identifies a significant gap in the motivation and provides a clear direction for the authors to address, it lacks specific suggestions or examples on how to improve the motivation or applications. This makes the feedback 3, as it highlights areas for improvement but does not provide detailed guidance on how to achieve those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option compared to GPT4. This is an explicit action that the authors can take to enhance their draft by providing a more comprehensive evaluation of their proposed approach. The suggestion is concrete, as it specifies which experiments to include and why they are important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option compared to GPT4. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or results where these experiments should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a change to include GPT3.5 experiments, but without clear grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option compared to GPT4. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that using a more affordable model could offer a more comprehensive evaluation of the proposed approach. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, which is a more affordable option compared to GPT4. This is a clear and actionable suggestion that could enhance the comprehensiveness of the evaluation of the proposed approach. By providing a more affordable alternative, the authors can potentially offer a more accessible and practical comparison, which could be beneficial for the readers. However, the comment could be more helpful if it provided additional context or rationale for why GPT3.5 is a suitable choice or how it would impact the evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically mentioning that the best result for WMT17WIKT in terms of BLEU is already included in the baselines. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done: including bold numbers for the baselines of previous work, particularly noting that the best result for WMT17WIKT in terms of BLEU is already included in the baselines. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for a specific change in the presentation of data, asking to include bold numbers for the baselines of previous work. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or modification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of the paper. It explicitly asks the authors to include bold numbers for the baselines of previous work, particularly noting that the best result for WMT17WIKT in terms of BLEU is already included in the baselines. This feedback is clear and directly points out a specific area where the paper could be enhanced, offering the authors a clear path for improvement. By addressing this suggestion, the authors can improve the readability and clarity of their results presentation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors,\" providing a clear and direct action for the authors to take. It does not leave any ambiguity, as the authors know exactly what is being asked for. The comment is specific in its request, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for examples of \"unreliable neighbors,\" providing a direct request for clarification or additional information. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for examples of \"unreliable neighbors.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is a request for clarification, specifically asking for examples of \"unreliable neighbors.\" This is a straightforward and actionable suggestion that can help the authors improve their draft by providing more context or examples. However, it lacks depth and does not address other potential areas for improvement or provide guidance on how to address the issue beyond the initial request. While it is 3, it could be more comprehensive and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning that the main paper does not mention the TD3GA algorithm. It suggests that the study of combining DQD with TD3 is crucial for understanding these synergies. Additionally, the comment emphasizes that the comparison to TD3GA should be central to the paper, as it is more relevant to the central claim of using onpolicy RL better fitting the DQD framework. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues, such as suggesting specific analyses or comparisons to be included. The action is implicit and somewhat vague, as the authors need to infer the necessary changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper should be revised, leaving the authors to infer that it relates to the main paper or sections discussing these algorithms. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, specifically noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. The reviewer suggests that the comparison to TD3GA should be central to the paper. This claim is 3 as it provides a specific example (the absence of TD3GA) that could be used to support the argument. However, the comment lacks detailed reasoning or references to substantiate the claim fully, making it 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the claim about the synergies between DQD and PPO is insufficiently supported. It highlights the absence of the TD3GA algorithm in the main paper, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the paper, emphasizing its relevance to the central claim of using onpolicy RL better fitting the DQD framework. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or how to structure the comparison effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance. While it implies that the authors should explain this phenomenon, it does not provide explicit instructions or concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide an explanation but are not given specific steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, prompting the authors to explain this phenomenon. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the treesliced Wasserstein distance compared to the original optimal transport distance. It does not make a subjective claim or suggestion but rather poses a question seeking clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance. While it identifies an area of interest, it does not provide specific guidance or suggestions on how the authors might address this observation or improve their understanding of the results. The comment lacks actionable feedback, leaving the authors without clear direction on how to enhance their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"confident\" might be ambiguous and implies that it could refer to either model confidence or human interpretability. The reviewer suggests that a slight rephrasing would be beneficial. While the comment implies that the authors should clarify the term, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should rephrase the comment to avoid ambiguity. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"ceterus paribus convexity\" and the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the ambiguity of the term \"confident\" and suggests that a slight rephrasing would be beneficial. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"confident\" in the context of \"ceterus paribus convexity,\" suggesting that it might be ambiguous. However, the comment does not provide any supporting evidence, reasoning, or references to clarify the ambiguity or suggest an alternative phrasing. This lack of detailed justification makes the claim 2, as the authors may find it challenging to understand the basis of the critique without further explanation.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the use of the term \"confident\" in the context of \"ceterus paribus convexity.\" It suggests that the authors might be referring to model confidence or human interpretability, which could lead to confusion. The comment provides a clear and actionable suggestion for improvement by recommending a slight rephrasing to clarify the intended meaning. This feedback is specific and constructive, offering a clear path for the authors to enhance the clarity of their work. However, it could be more helpful if it provided additional context or examples of how to rephrase the comment effectively. Overall, the comment is 4 as it directs the authors\" attention to a potential issue and provides a clear suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the practicality of the paper, particularly regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or suggest alternative approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s proposal of using known causal relationships between features and raises concerns about the practicality of this approach, particularly noting that prior knowledge may not always be available or accurate for specific subpopulations. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the concern about the practicality of the work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s approach of using known causal relationships between features is not practical because prior knowledge may not always be available or accurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically due to this limitation. However, the comment lacks specific examples or references to support the claim about the practicality of the approach. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a concern about the practicality of the paper\"s approach, which involves using known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, which is a common reason why many researchers focus on automatically mining causal relationships from data. This feedback is 3 as it points out a potential limitation of the paper\"s approach and suggests that the authors might need to consider alternative methods or strategies to address this issue. However, the comment could be more helpful if it provided specific suggestions or examples of how to mitigate this concern. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the figures and empirical results, such as missing axis labels, randomly masked curves, and single seed experiments. It also mentions that the core findings are based on two small scale datasets and a single architecture type. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to polish the figures and ensure clarity and confidence in the empirical results. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the lack of polishing of figures and empirical results, specifically mentioning issues like missing axis labels, randomly masked curves, and single seed experiments. It also highlights that the core findings are based on two small scale datasets and a single architecture type. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the figures and results sections. The comment is specific in detailing what needs to be addressed, such as the missing axis labels and the nature of the experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks polishing of figures and empirical results, which hinders clarity and confidence in the findings. The reviewer provides specific examples of issues, such as missing axis labels, randomly masked curves, and single seed experiments, which support the claim. However, the comment does not provide additional context or references to substantiate these observations fully. While the examples are clear, the lack of broader context or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically in terms of the clarity and confidence in the empirical findings. It points out issues such as the lack of polishing of figures, missing axis labels, and the use of single seed experiments, which could hinder the interpretation of the results. Additionally, it notes that the core findings are based on two small scale datasets and a single architecture type, which may limit the generalizability of the results. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to enhance the clarity and robustness of their figures and empirical results, but the feedback could be more actionable with detailed suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but suggests that the findings are not as novel as they could be, given the expected nature of tighter confidence intervals (CIs) with finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the novelty of the work or suggest alternative approaches to increase its originality. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the work, suggesting that the findings are not as novel as they could be due to the expected nature of tighter confidence intervals (CIs) with finetuning. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides some context, it lacks full grounding as it does not reference specific sections or elements of the paper. The comment is specific in its critique of the novelty, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, suggesting that tighter confidence intervals (CIs) with finetuning are expected. The comment provides a logical reasoning by explaining that taskspecific finetuning typically increases confidence for a specific task but may reduce generalizability. However, the comment lacks specific examples or references to support the claim that the findings are not novel. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but suggests that the findings might not be as novel as they could be, given the expected nature of tighter confidence intervals (CIs) with finetuning. While it provides a logical reasoning for the critique, it does not offer specific suggestions or actionable steps for the authors to enhance the novelty of their work. The comment lacks depth and guidance, making it 3 as it highlights an area for improvement but does not fully support the authors in addressing the feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would strengthen its case by reporting numbers from a label noise experiment conducted on ImageNet with 1000 classes, particularly on nontail classes. This feedback implies that the authors should include these results to further test their conjecture. However, the comment does not provide specific guidance on how to implement this suggestion, such as which metrics to report or how to present the results. The action is implicit and somewhat vague, as the authors know they need to include additional data but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests reporting numbers from a label noise experiment on ImageNet with 1000 classes, which implies that it is related to the label noise experiment mentioned in the paper. However, it does not specify which part of the paper this suggestion is related to, making it weakly grounded. The comment is specific in suggesting that the authors should report additional numbers to further test their conjecture, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting numbers from a label noise experiment on ImageNet with 1000 classes would strengthen the paper\"s case. This claim is 3 as it provides a logical reasoning for why such reporting would be beneficial, suggesting that it would further test the conjecture. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would strengthen its case by reporting numbers from a label noise experiment conducted on ImageNet with 1000 classes, particularly on nontail classes. This feedback implies that the authors should include these results to further test their conjecture. While the comment provides a logical suggestion for improvement, it lacks specific guidance on how to implement this suggestion, such as which metrics to report or how to present the results. The comment is 3 as it points out a potential area for enhancement, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of metrics, specifically asking why the number of weight updates is considered a better metric than the number of network updates. It also suggests providing additional feedback to improve the paper. While the comment implies that the authors should address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional feedback on this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of metrics, specifically asking why the number of weight updates is considered a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this metric is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the choice of metrics, but without clear grounding, it lacks specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the choice of metrics, specifically asking why the number of weight updates is considered a better metric than the number of network updates. However, it does not provide any supporting evidence, reasoning, or references to justify why one metric might be better than the other. The comment lacks detailed explanation or justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of metrics, specifically asking why the number of weight updates is considered a better metric than the number of network updates. It also suggests providing additional feedback to improve the paper. While the comment identifies a potential area for clarification, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the rationale behind their choice of metrics, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the realworld scenarios where the proposed adversarial prediction accuracy is more relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relevance of the proposed adversarial prediction accuracy in realworld scenarios, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the proposed adversarial prediction accuracy should be compared to classical prediction accuracy or what realworld scenarios are being considered. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of the proposed adversarial prediction accuracy in realworld scenarios. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the relevance of the proposed adversarial prediction accuracy in realworld scenarios, contrasting it with classical prediction accuracy. This question prompts the authors to consider the practical implications of their method and how it might be applied in actual situations. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the method should be emphasized. While it highlights a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of InContext Examples. It also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps for the authors to address these issues. The authors are left to infer that they need to provide more detailed information about the experiment setup and explore additional aspects of the evaluation. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of InContext Examples. Additionally, it points out the reliance on a single dataset, which may limit the generalizability of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information on the number of different sets of incontent examples used and the lack of exploration of the effects of varying the number of InContext Examples. Additionally, it notes the reliance on a single dataset, which may limit the generalizability of the results. These specific examples and logical reasoning support the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several critical areas for improvement in the evaluation section of the paper. It points out the lack of transparency regarding the experiment setup, specifically mentioning the absence of information on the number of different sets of incontent examples used. Additionally, it highlights the lack of exploration of the effects of varying the number of InContext Examples, which is an important aspect that the authors should consider. The comment also notes the reliance on a single dataset, which may limit the generalizability of the results. This feedback is clear and actionable, providing the authors with specific areas to address in order to enhance the comprehensiveness and robustness of their evaluation. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the evaluation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes could be made to improve their draft. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the framework is being compared to SimCLR or how this observation impacts the paper\"s content. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which is a wellknown framework. However, it does not provide any context or explanation for why this observation is relevant or how it impacts the paper\"s contribution or findings. Without additional information or suggestions, the authors are left without guidance on how to address this point or improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the absence of comparative experiments with other nonlinear blocks, such as the bottleneck in ResNet or linear bottleneck in MobileNetV2, in Section 4.3. This feedback implies that the authors should include these experiments to provide a broader context for their proposed method. However, the comment does not explicitly instruct the authors to add these experiments or specify which ones to include. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and may not know exactly which ones to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely the lack of comparative experiments with other nonlinear blocks like the bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with other nonlinear blocks, such as the bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that including these experiments would provide a broader context for the proposed method. However, the comment does not provide specific examples or detailed reasoning to support why these additional experiments are necessary or how they would enhance the paper. The lack of explicit evidence or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparative experiments with other nonlinear blocks, such as the bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is valuable as it suggests that the authors should include these experiments to provide a broader context and showcase the unique advantages or potential shortcomings of their proposed method. However, the comment could be more helpful if it offered specific guidance on which experiments to include or how to structure them. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples like 1, 2, and 3. However, it does not provide explicit guidance on which aspects of related work should be addressed or how the authors should integrate these references into their paper. The action is implicit, as the authors can infer that they need to include more related work, but the lack of concrete details on how to do so makes the comment vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples like 1, 2, and 3. However, it does not specify which part of the paper should be revised or how these related works should be integrated. The authors can infer that the feedback pertains to the introduction or related work sections, but this inference is not direct. The comment lacks specificity regarding the exact aspects of related work that need attention, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples like 1, 2, and 3. However, the comment does not provide any specific reasoning or evidence to support why these related works are important or how they could enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples like 1, 2, and 3. However, the comment lacks specificity and does not provide detailed guidance on which aspects of related work should be addressed or how the authors might integrate these references into their paper. Without explicit suggestions or examples, the authors may find it challenging to understand the exact areas that need improvement. Therefore, the comment is 2, as it identifies a potential area for enhancement but does not offer actionable feedback. This aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, particularly mentioning that many have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include comparisons with existing text GANs and test SeqGAN with a pretrained version, but without specific instructions on how to do so. The action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, particularly mentioning that many have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or experiments where comparisons are discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific about the issue of comparison, it is 1 because it does not provide clear guidance on where to address these concerns. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, particularly mentioning that many have opensource implementations. It also notes that SeqGAN is mentioned but not tested with a pretrained version. While the comment identifies a potential gap in the paper, it lacks specific examples or references to existing text GANs that could be compared against. The mention of SeqGAN being tested with a pretrained version is also not elaborated upon, making the claim 3. The authors would need to further explore and clarify these points to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against existing text GANs, particularly noting that many have opensource implementations. It also mentions that SeqGAN is mentioned but not tested with a pretrained version. This feedback is valuable as it highlights areas where the paper could be strengthened by providing a comprehensive comparison and testing with a pretrained version. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects of the pretrained version should be tested. Overall, the comment is 3 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. However, it does not provide explicit guidance on how to incorporate these aspects into the paper or suggest specific algorithmic details that should be included. The comment implies that the authors should address this omission, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner. However, it does not specify which part of the paper should be revised or how the algorithmic aspects should be integrated. The authors cannot confidently determine which sections or elements need attention, as the comment lacks specific guidance. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner, which it suggests limits the novelty of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, given the proposed concept of Blackwell winner, which it claims limits the novelty of the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback highlights a critical aspect of the paper that could enhance its novelty and impact, but it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that Table 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a specific example of how to organize the tables, by separating the 8 SFII columns and the 8 SPDI columns. This feedback is explicit and provides concrete guidance on how to improve the readability of the tables. The authors know exactly what changes to make to enhance the clarity of their presentation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: splitting the tables into two each, with one table per measure, and suggests a specific example of how to organize the columns. This guidance helps the authors understand exactly what needs to be done to improve the readability of their tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 and 5 would be more readable if they were split into two tables each, with one table per measure. The comment provides a specific example of how to organize the columns, suggesting that separating the 8 SFII columns and the 8 SPDI columns would improve readability. This reasoning is logical and provides a clear example of how to implement the suggested change, making the claim 4. However, it could be further strengthened by referencing similar practices or studies that have successfully improved readability through table organization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Table 4 and 5. By recommending that these tables be split into two separate tables, each focusing on a specific measure (SFII and SPDI), the comment offers a clear way to enhance the clarity and organization of the data presented. This feedback is valuable as it directly addresses a potential issue with the presentation of data, allowing the authors to make a concrete improvement to their draft. The suggestion is detailed and provides a clear example of how to implement the change, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks for clarification on the figure, specifically requesting that the authors specify what distinguishes \"valid\" and \"orig\" in Fig. 5. This is a direct and clear instruction, providing the authors with a specific action to take. The comment is explicit and concrete, as it clearly identifies the need for clarification and specifies what needs to be clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the distinction between \"valid\" and \"orig\" in the figure. This provides clear guidance on what the authors should clarify or explain in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the figure, specifically asking for an explanation of the distinction between \"valid\" and \"orig.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it requests clarification on a particular aspect of the paper, specifically the distinction between \"valid\" and \"orig\" in Figure 5. This feedback is clear and provides the authors with a concrete direction for improving the clarity and comprehensibility of their work. By addressing this request, the authors can enhance the understanding of their results and ensure that their findings are accurately interpreted by readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons more systematic, specifically by comparing the best performance of each method. This feedback provides a clear and explicit action for the authors to take, which is to enhance the systematic nature of their comparisons. The comment is concrete, as it specifies what needs to be done\u2014comparing the best performance of each method. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and suggests that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the systematic comparison of the best performance of each method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed guidance or references to how the comparisons could be made more systematic, making it difficult for the authors to understand and address the suggestion effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could be enhanced by making comparisons more systematic, specifically by comparing the best performance of each method. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by organizing their comparisons more effectively. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of how to structure these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that including a comparison to a method mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not explicitly instruct the authors to make this comparison or provide specific guidance on which method to include. The comment implies that the authors should consider this type of comparison, but it lacks concrete details on how to implement it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests including a comparison to a method mentioned in the computer vision setting, which implies that it is relevant to the paper\"s context. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment does specify what the authors should consider, namely comparing to lossbased sampling, but it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to a method mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer provides a rationale by explaining that these methods are not always applicable and typically require a supervised setup, but some can be adapted to language tasks. However, the comment lacks specific references or examples to support the claim, making it 3. The authors would need to infer the relevance of the suggested comparison and the applicability of the methods, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to a method mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods are not always applicable and typically require a supervised setup, but notes that some can be adapted to language tasks. This feedback provides a specific and actionable suggestion for improving the paper by suggesting a more relevant comparison. However, the comment could be more helpful if it offered additional guidance on which methods to consider or how to adapt them for language tasks. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This is a clear and explicit action, as it provides a direct instruction for the authors to include a specific analysis. The comment also concretely specifies what needs to be done, which is to estimate the time complexity. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the time complexity is discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact location in the paper that needs revision. While the suggestion is specific in terms of what needs to be addressed, the absence of grounding makes it challenging for the authors to act on the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the scalability. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This feedback is clear and actionable, as it provides a direct suggestion for the authors to include a detailed analysis of the algorithm\"s time complexity. By addressing this, the authors can enhance the robustness and applicability of their work. However, the comment could be more helpful if it offered additional guidance on how to estimate the time complexity or provided examples of how to present this information effectively. Overall, the comment is 4 as it directs the authors toward a specific and important aspect of their work that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing a specific chapter in a book. While it implies that the authors should explore this connection, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate the relationship between universal kernels and the third point of definition one. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the connection to properties of universal kernels and referencing a specific chapter in a book, \"chapter 4 of Steinwart and Christmann,\" which provides a clear direction for the authors to explore. This provides detailed guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing a specific chapter in a book. This provides a logical basis for the question, as it draws on established knowledge about universal kernels. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the reference to understand the connection, but the initial suggestion is clear enough to be considered 3.", "helpfulness_rationale": "The review comment raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing a specific chapter in a book. This feedback is 3 as it prompts the authors to explore a potential link between their work and established concepts in kernel methods. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this connection or incorporate it into the paper. While it identifies an area for improvement, it does not offer actionable steps for the authors to take, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion around equation (10) is very terse and not clearly explained. While it identifies a specific area that needs improvement, it does not provide explicit guidance on how to enhance the explanation or discussion. The authors are left to infer that they need to expand on the discussion, but without concrete suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion around equation (10), indicating that it is very terse and not clearly explained. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is very terse and not clearly explained. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issues with the discussion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the discussion around equation (10) is very terse and not clearly explained. While it identifies a specific area that needs improvement, it lacks actionable guidance or suggestions on how the authors might enhance the clarity of the discussion. Without specific advice on what aspects of the discussion could be expanded or clarified, the authors are left with a general idea of what needs to be improved but without concrete steps to follow. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
