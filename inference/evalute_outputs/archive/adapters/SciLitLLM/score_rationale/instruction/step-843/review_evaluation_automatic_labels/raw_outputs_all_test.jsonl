{"generated_text": "{'actionability_rationale': \"The review comment acknowledges that the authors are dealing with a challenging min-max optimization problem, which is typically difficult to train and execute, especially for PDEs with advective terms. It notes that the methodology performs better than the baselines but expresses concern about the presentation and clarity of the steps. However, the comment does not provide specific guidance on how to improve the presentation or clarity, nor does it suggest particular areas that need revision. The feedback lacks actionable details, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology of the paper, specifically the min-max optimization approach and its application to PDEs with advective terms. It acknowledges that the methodology performs better than the baselines but expresses concern about the presentation and clarity of the steps. However, the comment does not specify which part of the paper is lacking clarity or where the revision should focus. While it provides some context, it does not explicitly mention a specific section or part of the paper being addressed, making it weakly grounded. The comment is specific in identifying the issue of clarity and the need for revision, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the methodology, which involves min-max optimization, is typically challenging to train and execute, especially for PDEs with advective terms. The reviewer acknowledges that the methodology performs better than the baselines but expresses concern about the presentation and clarity of the steps. However, the comment lacks specific examples, detailed reasoning, or references to support the claim about the difficulty of the optimization approach. This makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the challenge of min-max optimization, which is typically difficult to train and execute, especially for PDEs with advective terms. It notes that the methodology provided by the authors performs better than the baselines but expresses concern about the presentation and clarity of the steps. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how to improve the presentation or clarity. The feedback highlights an area for improvement but does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges the difficulty of min-max optimization, especially for PDEs with advective terms, and notes that the methodology performs better than the baselines. However, it expresses concern about the presentation and clarity of the steps, suggesting that the paper would benefit from a revision. While the comment identifies a potential issue, it lacks specific guidance or actionable steps for the authors to improve the presentation or clarity. Without detailed suggestions or examples, the authors may struggle to understand how to address the concerns effectively. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the methodology of the paper, specifically the min-max optimization approach and its application to PDEs with advective terms. It acknowledges that the methodology performs better than the baselines but expresses concern about the presentation and clarity of the steps. However, the comment does not specify which part of the paper is lacking clarity or where the revision should focus. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the challenge of min-max optimization, particularly for PDEs with advective terms, and notes that the methodology performs better than the baselines. However, it expresses concern about the presentation and clarity of the steps, suggesting that the paper would benefit from a revision. While the comment identifies a potential issue, it lacks specific examples, detailed reasoning, or references to support the claim about the difficulty of the optimization approach. This makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the challenge of min-max optimization, which is typically difficult to train and execute, especially for PDEs with advective terms. It notes that the methodology provided by the authors performs better than the baselines but expresses concern about the presentation and clarity of the steps. However"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical use of the modified TD learning algorithm defined in Definition 5.1, compared to the original proposal (Algorithm 1). While the comment implies that the authors should justify or explain the practical implications of using the modified algorithm, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the practical use of the modified algorithm. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the practical use of the modified TD learning algorithm compared to the original proposal. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the practical use of a modified TD learning algorithm compared to the original proposal. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the practical implications of using a modified TD learning algorithm compared to the original proposal. It challenges the authors to justify why the modified algorithm should be preferred in practice, which is a valuable point for consideration. However, the comment does not provide specific suggestions or guidance on how the authors might address this question or improve their draft. While it prompts the authors to think about the practical application of their work, it lacks actionable advice or detailed feedback. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a concern about the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It points out that the paper does not empirically validate this claim, which is a significant issue. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to validate the metric. While it identifies a critical area for improvement, it lacks concrete instructions on how to proceed, leaving the authors with a general direction but no clear path for action. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It highlights a concern that the paper does not empirically validate this claim, which is a significant issue given the emphasis on Task2Vec and model diversity. However, the comment does not specify which part of the paper discusses the diversity coefficient or where the validation should be included, making it weakly grounded. The comment is specific in identifying the issue of empirical validation but lacks grounding in terms of where the authors should focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It highlights a significant issue by pointing out that the paper does not empirically validate this claim, which is crucial given the emphasis on Task2Vec and model diversity. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it identifies a critical area for improvement, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the concern without additional support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant concern regarding the practical utility of the data quality metric proposed in the paper, specifically the diversity coefficient. It points out that the paper does not empirically validate this claim, which is crucial given the emphasis on Task2Vec and model diversity. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to empirically validate the metric or offered guidance on potential methods for doing so. Overall, the comment is mostly helpful as it directs the authors' attention to a key weakness in their draft, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. However, it does not explicitly instruct the authors to make this change or provide details on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adjusting resource allocation, but without concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or examples, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the resource allocation need to be adjusted or how to address the inefficiency. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that using canary clients is more inefficient compared to using canary examples, suggesting that more resource allocation might be needed. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or detailed explanations of why canary clients are inefficient or how resource allocation could be adjusted. This makes the claim somewhat verifiable, as the authors would need to further explore and verify the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a potential inefficiency in the use of canary clients compared to canary examples and suggests that more resource allocation might be needed. While it points out a potential issue, it lacks specific guidance or suggestions on how to address this inefficiency or what changes could be made to improve resource allocation. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM, referencing Equation (4) in a specific source. However, it does not provide explicit guidance on how the authors should address this concern or clarify the relevance of Carefl. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to improve their draft. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references Equation (6) as the only mention of Carefl in the method description and compares it to Equation (4) in a specific source. This provides some grounding by mentioning specific equations, but it does not explicitly identify the section where Carefl is discussed, making it weakly grounded. The comment is specific in its critique, as it questions the relevance of Carefl and provides a reference for comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer references Equation (4) in a specific source to support their claim, providing a logical basis for questioning the novelty or importance of Carefl. This reference to an external source adds credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced source to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a concern about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references a specific equation and source to support its claim, which provides a basis for questioning the novelty or importance of Carefl in the context of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the relevance of Carefl. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references a specific equation and source for comparison, which provides some context. However, the comment does not provide explicit guidance on how the authors should address this concern or clarify the relevance of Carefl. Without specific suggestions or actionable steps, the authors may find it challenging to determine how to improve their draft in response to this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references Equation (6) as the only mention of Carefl in the method description and compares it to Equation (4) in a specific source. This provides some grounding by mentioning specific equations, but it does not explicitly identify the section where Carefl is discussed, making it weakly grounded. The comment is specific in its critique, as it questions the relevance of Carefl and provides a reference for comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer references Equation (4) in a specific source to support their claim, providing a logical basis for questioning the novelty or importance of Carefl. This reference to an external source adds credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced source to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a concern about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references Equation (4) in a specific source to support its claim, which provides a basis for questioning the novelty or importance of Carefl in the context of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the relevance of Carefl. While it identifies a potential area for improvement"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the approach, specifically the compute-intensive nature of pretraining the GAA model and the assumption that it will be performant enough to provide meaningful prompts. It raises a concern about the speedup claim if the assumption doesn\\'t hold true. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the compute-intensive nature of the approach, particularly the requirement for pretraining the GAA model. It also raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could impact the speedup claim. However, the comment does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensive nature of the approach, specifically the requirement for pretraining the GAA model. It questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. The claim is somewhat verifiable as it logically connects the compute-intensive nature of the approach to potential issues with the speedup claim. However, it lacks specific examples or references to support the assertion about the GAA model\\'s performance, making it challenging for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the approach, specifically the requirement for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and question the speedup claim of the proposed approach. While the comment highlights a critical aspect that the authors need to consider, it lacks specific suggestions or guidance on how to address this issue or improve the approach. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the approach, specifically the requirement for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and question the speedup claim of the proposed approach. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the compute-intensive nature of the approach, particularly the requirement for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could impact the speedup claim. However, the comment does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the potential issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensive nature of the approach, specifically the requirement for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times and question the speedup claim of the proposed approach. The comment logically connects the compute-intensive nature of the approach to potential issues with the speedup claim, providing a clear rationale for the concern. However, it lacks specific examples or references to support the assertion about the GAA model\\'s performance, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, noting its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses the method or the server dataset, making it weakly grounded. The comment is specific in identifying the limitation and its impact on the method\\'s generality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights a critical area that the authors need to address to improve the applicability and impact of their work. However, the comment does not provide specific suggestions or guidance on how the authors might mitigate this limitation or enhance the generality of their method. While it points out a crucial issue, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the proposed method, noting its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the issue but lacks grounding because it does not refer to a particular section, table, or figure. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights a critical area that the authors need to address to improve the applicability and impact of their work. However, the comment does not provide specific suggestions or guidance on how the authors might mitigate this limitation or enhance the generality of their method. While it points out a crucial issue, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, noting its high dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include additional downstream search methods, such as BO and LS, in addition to the single method (EA) currently provided. This feedback implies a specific action for the authors to take, which is to expand the range of search methods used in their experiments. However, the comment does not provide detailed guidance on how to implement this change or why these specific methods were chosen. While the action is clear, the lack of concrete instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include additional downstream search methods, such as BO and LS, in addition to the single method (EA) currently provided. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the search methods are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional methods to consider, but without clear grounding, it aligns with a score of 2. Therefore, the comment is weakly grounded and not specific, aligning with label 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should include additional downstream search methods, such as BO and LS, in addition to the single method (EA) currently provided. However, the comment does not provide any reasoning or evidence to support why these additional methods would be beneficial or necessary. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that only a single downstream search method (EA) is provided, suggesting that additional methods like BO and LS should be considered. This feedback is clear and actionable, as it provides a specific suggestion for expanding the scope of the experiments. By including more search methods, the authors could enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it explained why these additional methods are relevant or how they might impact the findings. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. It explicitly suggests that a direct comparison with other sparse models is missing. This feedback provides a clear and explicit action for the authors to take, which is to include a direct comparison with other sparse models. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a direct comparison of FLOPs and FPS with other sparse models, which is a critical aspect in sparse network research. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. The comment suggests that a direct comparison with other sparse models is missing. While the comment identifies a potential gap in the paper, it lacks specific examples or references to other sparse models that should be compared. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by highlighting the comparison of FLOPs and FPS in sparse network research. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to include a comparison with other models, which would enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific models or methods for comparison. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the numbers in the result tables are unclear. It provides an example to illustrate the problem, showing how reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy of 97%. This feedback implies that the authors should clarify the metrics and their interpretation in the results. While the action is not explicitly stated, it is clear and concrete, as the authors can deduce that they need to provide a clearer explanation of the metrics and their implications. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and providing an example of how reversing the prediction could lead to an incorrect accuracy. This level of detail helps the authors understand what needs to be addressed to improve the clarity of the metrics and their interpretation in the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are difficult to understand, leading to confusion about their meaning in the result tables. The reviewer provides a specific example to illustrate the issue, mentioning that reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy of 97%. This example provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or providing more detailed examples from the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the numbers in the result tables are unclear. It provides a concrete example to illustrate the problem, showing how reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy of 97%. This feedback is clear and actionable, as it highlights a critical area where the authors need to clarify their metrics and their interpretation in the results. By addressing this issue, the authors can improve the clarity and credibility of their findings. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the numbers in the result tables are unclear. It provides an example to illustrate the problem, showing how reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy of 97%. This feedback implies that the authors should clarify the metrics and their interpretation in the results. While the action is not explicitly stated, it is clear and concrete, as the authors can deduce that they need to provide a clearer explanation of the metrics and their implications. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are difficult to understand and providing an example of how reversing the prediction could lead to an incorrect accuracy. This level of detail helps the authors understand what needs to be addressed to improve the clarity of the metrics and their interpretation in the results. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are difficult to understand, leading to confusion about their meaning in the result tables. The reviewer provides a specific example to illustrate the issue, showing how reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy of 97%. This example provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or providing more detailed examples from the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the numbers in the result tables are unclear. It provides a concrete example to illustrate the problem, showing how"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption and its implications for the analysis. It asks whether this assumption is typical in practice, whether it is always possible to compute the effective variance for non-gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions imply that the authors should consider these aspects, they do not provide explicit instructions or concrete steps on how to address them. The authors are left to infer that they need to explore these questions further, but without specific guidance, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its implications for the analysis. It asks whether this assumption is typical in practice, whether it is always possible to compute the effective variance for non-gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in terms of what the authors need to consider or clarify, but without explicit references to sections or parts of the paper, the authors may struggle to identify where these issues are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the Gaussian assumption and its implications. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the Gaussian assumption used in the analysis. It inquires whether this assumption is typical in practice, whether it is always possible to compute the effective variance for non-gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. These questions are relevant and could help the authors clarify and strengthen their analysis. However, the comment does not provide specific suggestions or guidance on how to address these questions or improve the draft. While it prompts the authors to consider important aspects of their work, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach to the math and science categories suggests an open vocabulary problem that is not clearly addressed. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the approach. The comment lacks concrete details on what changes or clarifications are needed, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable, making it difficult for the authors to know what steps to take to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the approach to these categories and the lack of clarity in addressing it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly addressed. However, the comment does not provide specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach to the math and science categories, suggesting that it presents an open vocabulary problem that is not clearly addressed. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left with only a vague understanding of the problem and no clear path to resolve it. Therefore, the comment is barely helpful, as it highlights an area of concern but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough discussion of the similarity between their work and stochastic routing, implying that the current discussion is insufficient. However, it does not explicitly instruct the authors to include this discussion or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion but are not given specific steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide a more thorough discussion of the similarity between the work and stochastic routing. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be discussed or how the discussion should be expanded. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should provide a more thorough discussion of the similarity between the work and stochastic routing. However, it does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should provide a more thorough discussion of the similarity between the work and stochastic routing. While it identifies a potential area for improvement, it lacks specificity and does not offer detailed guidance or examples on how the authors might enhance their discussion. The comment hints at the need for a deeper analysis but does not provide actionable steps or suggestions for the authors to follow. As a result, the feedback is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential nature of the loss. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific changes should be made to their draft. The action is implicit, as the authors need to infer that they should reconsider their approach to convergence, and it is vague because it lacks concrete details on how to implement this suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or discussion about convergence. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment lacks specificity as it does not provide details on why this suggestion is important or how it could be implemented. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, the comment lacks specific reasoning or evidence to support this claim. It does not explain why the CE loss cannot be minimized due to its exponential nature or how this affects the convergence in direction. Without detailed justification or references, the claim remains unverifiable, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, it lacks clarity and does not provide specific reasoning or guidance on why this perspective is important or how it could impact the paper. Without detailed explanation or actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim flexibility in their framework by stating that components can be replaced by other models, but they have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework. This feedback implies that the authors should conduct experiments or evaluations to test the robustness of their framework. However, the comment does not provide specific guidance on which components to replace or how to conduct these tests, leaving the authors with a general idea of what needs to be done but without detailed instructions. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement the suggested action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the flexibility of their framework, stating that components can be replaced by other models. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out that the authors have not attempted any changes or alternatives to demonstrate the robustness of their framework, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework, despite stating flexibility in their approach. This claim is somewhat verifiable as it highlights a gap in the experimental validation of the framework\\'s robustness. However, the comment lacks specific examples or references to support the claim, such as which components were considered for replacement or how the robustness could be tested. This makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim flexibility in their framework by stating that components can be replaced by other models, but they have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework. This feedback is clear and actionable, as it highlights a gap in the experimental validation of the framework\\'s robustness. By pointing out this omission, the comment provides the authors with a concrete area for improvement, encouraging them to conduct additional experiments or evaluations to substantiate their claims. However, the comment could be more helpful if it suggested specific components or approaches to test for robustness. Overall, the feedback is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of the number of disentangled factors in the Atari game experiments, specifically asking how it was determined to be 30. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question or justify their choice. The action is implicit, as the authors need to infer that they should provide an explanation or justification for their choice of factors. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of the number of disentangled factors being 30 and raises a general concern about specifying this number for an arbitrary domain. This provides clear guidance on what aspect of the paper needs clarification or justification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of the number of disentangled factors in the Atari game experiments. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of the number of disentangled factors in the Atari game experiments, asking how this number was determined. This is a relevant point that could impact the validity and generalizability of the findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or justify their choice of factors. While it highlights an area for improvement, it lacks actionable feedback or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the use of colloquial expressions in the paper, specifically mentioning the phrase \"By the way\" in the context of the training stage. This feedback provides a clear and direct action for the authors to take, which is to avoid using colloquial expressions that are considered unprofessional. The comment is specific and actionable, as it directly instructs the authors on what needs to be changed to improve the professionalism of their writing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific colloquial expression, \"By the way,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of colloquial expressions that are considered unprofessional. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"colloquial expressions are unprofessional\" and provides an example with the phrase \"By the way.\" However, the comment does not provide further explanation or justification for why this particular expression is considered unprofessional or how it affects the overall professionalism of the paper. Without additional context or reasoning, the claim remains vague and lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of colloquial expressions in the paper, such as the phrase \"By the way.\" This feedback is clear and actionable, as it directly points out a stylistic issue that can be easily addressed by the authors to improve the professionalism and clarity of their writing. However, the comment could be more helpful if it provided additional guidance on how to avoid such expressions or suggested alternative phrasing. Overall, the comment is mostly helpful as it provides a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies the issue of abbreviations not being defined, specifically mentioning \"LLH,\" \"OOD,\" and \"ECE.\" It highlights that these abbreviations are pivotal metrics in the work and have not been explained. This feedback provides a clear and direct action for the authors to take, which is to define these abbreviations in their paper. The comment is explicit and concrete, giving the authors a straightforward task to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific abbreviations, \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to define these abbreviations, which are pivotal metrics in the work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abbreviation \"LLH\" was never defined, and similarly, \"OOD\" and \"ECE\" were not defined, despite being pivotal metrics in the work. This claim is somewhat verifiable as it highlights a specific issue with the paper\\'s terminology. However, the comment does not provide examples or references to support why these abbreviations are pivotal or how their lack of definition impacts the paper. To fully substantiate the claim, the reviewer could include examples of how these abbreviations are used or why their definitions are crucial. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of definition for the abbreviations \"LLH,\" \"OOD,\" and \"ECE,\" which are pivotal metrics in the work. By pointing out that these abbreviations have not been defined, the comment highlights a critical gap in the paper that could affect the reader\\'s understanding. This feedback is clear and actionable, as it directly instructs the authors to define these abbreviations to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to define these abbreviations or examples of how they are typically used in the field. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic/random projection. It explicitly asks the authors to justify the stability of their method and questions what happens when more layers are stacked. While the comment identifies a specific issue and requests justification, it does not provide explicit guidance on how to address the concern or what specific analyses or experiments should be conducted to demonstrate stability. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the concern. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the stability of the proposed method when stacking multiple layers of WLS units. It raises a question about the probability of failure cases in stochastic/random projection and its impact on the proposed method\\'s ability to form deeper GNNs. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the stacking of layers is discussed. The comment is specific in detailing the concern and the need for justification regarding the method\\'s stability. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic/random projection. The reviewer provides a logical reasoning by explaining how the probability of failure increases with each layer, which could hinder the formation of deeper GNNs. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While the reasoning is somewhat sound, it requires more evidence or examples to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units. It highlights the potential issue of increased failure cases in stochastic/random projection, which could hinder the formation of deeper GNNs. The comment is specific in its inquiry about the stability of the method and the implications of stacking more layers. While it does not provide detailed suggestions for addressing the issue, it prompts the authors to justify the stability of their method and consider the consequences of stacking multiple layers. This feedback is somewhat helpful as it identifies a potential weakness and encourages the authors to further explore and justify their method's stability, but it could be more helpful with additional guidance or suggestions on how to address the concern. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic/random projection. It explicitly asks the authors to justify the stability of their method and questions what happens when more layers are stacked. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or what specific analyses or experiments should be conducted to demonstrate stability. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the concern. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic/random projection. It asks for justification on the method\\'s stability and questions what happens when more layers are stacked. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where stacking of layers is discussed. The comment is specific in detailing the concern and the need for justification, but it lacks explicit grounding in the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic/random projection. The reviewer provides a logical reasoning by explaining how the probability of failure increases with each layer, which could hinder the formation of deeper GNNs. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While the reasoning is somewhat sound, it requires more evidence or examples to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the stability"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific section of the paper, \"the computation of the Bottleneck Distance in Definition 4.1,\" as lacking clarity. However, it does not provide any guidance or suggestions on how the authors might improve the clarity of this section. The comment lacks explicit instructions or concrete details on what the authors should do to enhance clarity. As a result, the authors are left without a clear understanding of how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the computation of the Bottleneck Distance in Definition 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the computation of the Bottleneck Distance. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any further explanation or examples to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the specific issues with clarity or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks clarity, namely the computation of the Bottleneck Distance in Definition 4.1. This is a valuable piece of feedback as it points out a potential weakness in the manuscript that the authors can address to improve the clarity and understanding of their work. However, the comment does not provide detailed guidance or suggestions on how to enhance the clarity of this section, such as by offering examples or alternative explanations. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the visualization in Figure 5, suggesting that it is weaker compared to Balikas COLING16\\'s work. The reviewer implies that the authors should provide a longer exemplar and ensure that the color assignment is consistent with the topics listed in Figure 4. While the comment provides a clear direction for improvement, it lacks specific guidance on how to enhance the visualization or what exactly constitutes a longer exemplar. The action is explicit but somewhat vague, as the authors know they need to improve the visualization but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the visualization is weaker compared to Balikas COLING16\\'s work and suggests providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has a weaker visualization compared to Balikas COLING16\\'s work, which raises doubts about the segmenting and assigning results of the document. The reviewer suggests providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. While the comment identifies a potential issue with the visualization, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide a longer exemplar and ensure consistent color assignment is a step towards improvement, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visualization in Figure 5, noting that it is weaker compared to Balikas COLING16\\'s work. The reviewer suggests that providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4 could enhance the paper\\'s credibility. This feedback is clear and actionable, offering the authors a concrete way to improve their visualization and presentation of results. However, the comment could be more helpful if it provided additional guidance on how to achieve these improvements or examples of what constitutes a longer exemplar. Overall, the comment is mostly helpful as it directs the authors toward a specific area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of using a parameter-efficient training method with a small backbone model, P5-small. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. There is no guidance on whether the authors should reconsider their choice of model, explore alternative training methods, or provide additional justification for their current approach. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of P5-small as the backbone model and questions the necessity of using a parameter-efficient training method. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its critique of the parameter-efficient training method, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of using a parameter-efficient training method with a small backbone model, P5-small. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unnecessary. The comment lacks detailed explanation or examples that would help the authors understand the basis of the critique. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the concern effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the necessity of using a parameter-efficient training method with a small backbone model, P5-small. While it identifies a potential issue with the choice of model and training method, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. The comment highlights a potential weakness but does not offer actionable advice or examples for improvement, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors seem to be proposing a method for creating a challenging set, but the description provided is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more scalable or what specific changes should be made to the proposal. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors want to propose a method for creating a challenging set but notes that the description provided is specific and not scalable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by pointing out the lack of scalability in the proposed method, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors want to propose a method for creating a challenging set but notes that the description provided is specific and not scalable. However, the comment does not provide any supporting evidence, examples, or detailed reasoning to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it appears specific and not scalable. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The comment does not clarify what aspects of the method are considered specific or how scalability could be improved. Without detailed guidance or examples, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment points out that the authors seem to be proposing a method for creating a challenging set, but the description provided is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more scalable or what specific changes could be made to improve the proposal. As a result, the comment lacks actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors want to propose a method for creating a challenging set but notes that the description provided is specific and not scalable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment provides some specificity by pointing out the lack of scalability, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors want to propose a method for creating a challenging set but notes that the description provided is specific and not scalable. However, the comment lacks supporting evidence, detailed reasoning, or specific examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it appears specific and not scalable. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the issue or enhance their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment points out that the authors seem to be proposing a method for creating a challenging set, but the description provided is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more scalable or what specific changes should be made to the proposal. As a result, the comment lacks actionable steps for the authors to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors want to propose a method for creating a challenging set, but"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method relies heavily on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit suggestions for how the authors might address this reliance or improve their approach. There is no guidance on potential modifications, alternative methods, or additional analyses that could be conducted to mitigate this reliance. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of this reliance are problematic or how it could be addressed. Without clear grounding or specific guidance, the authors may struggle to understand and address the issue effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the reliance of the proposed method on the optimal value function corresponding to the reward function is a strong one. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this reliance is considered strong or problematic. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the proposed method, specifically the reliance on the optimal value function corresponding to the reward function. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this reliance or improve their approach. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, but it does not provide any actionable feedback or suggestions for improvement. It simply states that the derivative nature is acceptable if it works, without offering any guidance on how the authors might enhance or differentiate their work. The comment lacks specificity and actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but it does not specify which parts of the paper this observation is based on. It also lacks specificity regarding what aspects of the approach are considered derivative or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach is derivative, combining two existing approaches. However, it does not provide any specific examples or references to the existing approaches being combined, nor does it explain why this combination is considered derivative. The comment lacks detailed reasoning or evidence to support the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, but it does not express any concern or suggest that this is a negative aspect. Instead, it states that derivatives are acceptable if they work. This feedback lacks specificity and actionable guidance, as it does not identify any weaknesses or areas for improvement in the paper. Without providing constructive criticism or suggestions for enhancing the draft, the comment does not assist the authors in improving their work. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of comparisons against other baseline approaches in the evaluation and suggests that a simple photographic style transfer method might achieve similar or better results. While the comment implies that the authors should include comparisons with baseline approaches, it does not explicitly instruct them to do so. Additionally, it does not specify which baseline approaches should be considered or how to implement these comparisons. The action is implicit and somewhat vague, as the authors need to infer the need for comparisons and determine which baselines to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparisons against baseline approaches in the evaluation, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it suggests a potential baseline approach, namely a simple photographic style transfer method, which could achieve similar or better results. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons against other baseline approaches in the evaluation and suggests that a simple photographic style transfer method might achieve similar or better results. This claim is somewhat verifiable as it provides a logical reasoning by comparing the results with a potential baseline method. However, the comment lacks specific references or detailed examples to substantiate the claim fully. The authors would need to further explore the suggestion to determine its validity, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of comparisons against other baseline approaches in the evaluation. It suggests that a simple photographic style transfer method might achieve similar or better results, which provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on which baseline approaches to consider or how to incorporate these comparisons into the evaluation. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and provides a starting point for the authors to enhance their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, making it difficult to understand the proposed method's details. It explicitly points out the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, and questions the difference between S_i and calligraphic S_j. The reviewer suggests that the authors clarify these mappings and provide explanations for the computation of each node in Figure 2. This feedback is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable. The authors know exactly what changes are required to improve the clarity of their draft.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and specific symbols like \"C_0, C_1, etc.\" and \"S_i,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with mapping these symbols to the equations and questions the explanation of C_i, Q_i, R_i, and A_i, as well as the difference between S_i and calligraphic S_j. The comment provides clear guidance on what needs to be clarified or explained, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the difficulty in mapping symbols in Figure 2 to those in the equations, which affects the understanding of the proposed method. The reviewer provides specific examples, such as the lack of explanation for C_i, Q_i, R_i, and A_i, and questions the difference between S_i and calligraphic S_j. This detailed critique highlights areas where the paper lacks clarity, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these issues impact the reader's understanding. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the paper, particularly in mapping the symbols in Figure 2 to those in the equations. It highlights the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, which makes it difficult for readers to understand the proposed method. Additionally, it points out a potential inconsistency between S_i and calligraphic S_j, questioning how S_i is computed. This feedback is clear and actionable, as it provides specific areas where the authors can improve the clarity and comprehensibility of their work. By addressing these issues, the authors can significantly enhance the reader's understanding of their method. Therefore, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the number of backtracking steps and the acceptance rate, as well as how much tuning was required to achieve good results. While the comment implies that these aspects should be investigated, it does not explicitly instruct the authors to do so. Additionally, it lacks specific guidance on how to conduct these studies or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to explore these additional parameters but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, it does not specify which part of the paper these suggestions pertain to, such as a specific section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for additional analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional parameters are important or how they might impact the results. Without such support, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. This feedback is somewhat helpful as it identifies specific areas for further exploration that could enhance the understanding of the experimental setup and results. However, the comment lacks depth and does not provide detailed guidance or examples on how to conduct these studies or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to analyze these parameters or what insights might be gained from such an investigation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. While the comment implies that these aspects should be investigated, it does not provide explicit instructions or detailed guidance on how to conduct this analysis. The authors are left to infer the action but without clear steps on how to implement it. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks specificity in execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests studying additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its request for additional analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, the comment lacks any supporting evidence, reasoning, or references to justify why these additional parameters are important or how they might impact the results. Without such support, the claim remains unverifiable, as it does not provide a clear basis for the authors to understand the significance of the suggestion. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. This feedback is somewhat helpful as it identifies specific areas for further exploration that could enhance the understanding of the experimental setup and results. However, the comment lacks depth and does not provide detailed guidance or examples on how to conduct these studies or what insights might be gained from such an investigation. To be more helpful"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the objective function for GSdyn and FABOLAS, specifically asking for clarification on the accuracy mentioned in Section 5.1. It identifies a gap in the explanation regarding whether the accuracy is on the validation or test dataset. While the comment does not explicitly instruct the authors to provide this information, the questions imply that the authors should clarify this aspect in their draft. The action is implicit but concrete, as the authors can infer that they need to specify the accuracy dataset used. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the objective function for GSdyn and FABOLAS, and the accuracy mentioned in Section 5.1. The comment asks for clarification on whether the accuracy is on the validation or test dataset, providing clear guidance on what information is missing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the objective function for GSdyn and FABOLAS, as well as the accuracy mentioned in Section 5.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the objective function for GSdyn and FABOLAS, specifically asking for clarification on the accuracy mentioned in Section 5.1. It highlights a potential inconsistency in the paper regarding whether the accuracy is on the validation or test dataset. This feedback is valuable as it prompts the authors to clarify a critical aspect of their methodology, which could impact the interpretation and validation of their results. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered examples of how to present this information clearly. Overall, the comment is mostly helpful as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a rearrangement of sections within the paper, specifically recommending that section 3.1 be moved to the related work section and that section 3 be renamed as section 3.2 with the proposal. This feedback provides a clear and explicit action for the authors to take, specifying exactly what changes should be made to improve the organization of the paper. The suggestion is concrete, as it outlines the exact sections that need to be reorganized and renamed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggested rearrangement, suggesting that section 3.1 fits better in the related work section and proposing that section 3 be renamed as section 3.2 with the proposal. This provides clear guidance on what needs to be addressed and how to improve the organization of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a rearrangement of sections within the paper, specifically recommending that section 3.1 be moved to the related work section and that section 3 be renamed as section 3.2 with the proposal. However, the comment does not provide any justification or reasoning for why this rearrangement would improve the paper\\'s organization or clarity. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the organization of the paper by recommending that section 3.1 be moved to the related work section and that section 3 be renamed as section 3.2 with the proposal. This feedback is clear and actionable, offering a concrete way to enhance the logical flow and structure of the paper. By suggesting a rearrangement of sections, the reviewer helps the authors improve the coherence and clarity of their manuscript. However, the comment could be more helpful if it explained why this rearrangement is beneficial or provided additional guidance on how to integrate the sections effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed justification.', 'helpfulness_label': '4'}\""}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to efficiently obtain priors and requests examples. It also suggests that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. While the comment identifies a potential issue and asks for clarification, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should provide examples or a practical method for obtaining the priors. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a practical method for obtaining the required prior {$U_{k_n}$}. The comment provides a clear direction for improvement by asking for examples or a practical method, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and prompts the authors to provide more information or examples. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their approach. To be more helpful, the comment could include potential methods or references to similar approaches that might be applicable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a question about the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to provide examples or a practical method for obtaining the priors, but the comment does not offer specific steps or examples to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a practical method for obtaining the required prior {$U_{k_n}$}. The comment requests examples or a practical method, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations to justify the concern, making it difficult for the authors to understand the basis of the issue. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and prompts the authors to provide more information or examples. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their approach. To be more helpful, the comment could include potential methods or references to similar approaches that might be applicable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the efficiency of obtaining priors and requests examples, suggesting that the"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. This feedback provides a clear and explicit action for the authors to take, specifying the additional dataset and metrics to consider. The suggestion is concrete, as it outlines exactly what the authors need to do to enhance their evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. The comment provides a logical reasoning by pointing out that while the current evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets is good, it is limited to metrics like AUC and precision. This reasoning is clear and provides a rationale for the suggestion. However, the comment could be strengthened by referencing specific studies or works that have used these metrics or datasets, which would make the claim more verifiable. Therefore, the comment is categorized as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the proposed framework. It acknowledges the current evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets, which are known benchmarks that evaluate methods using metrics like AUC and precision. The reviewer suggests that the authors perform additional evaluation on the VOT dataset, which would allow for a comparison of methods in terms of different metrics such as Accuracy, Robustness, and EAO. This feedback is valuable as it guides the authors to expand their evaluation scope and consider alternative metrics, which could enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to how these metrics are typically used in the VOT dataset. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern that the proposed method is not compared to any state-of-the-art unsupervised semantic segmentation technique, despite claiming comparable performance to supervised semantic segmentation. The reviewer points out that the paper does not report the performance of any state-of-the-art methods, either supervised or unsupervised. This feedback implies that the authors should include comparisons with relevant state-of-the-art methods to substantiate their claims. While the action is implicit, it is clear and concrete, as it specifies the need for additional comparisons. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concern about the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It also specifies the issue by pointing out that the paper claims comparable performance to supervised semantic segmentation but does not report the performance of any state-of-the-art methods, either supervised or unsupervised. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. The reviewer notes that the paper claims comparable performance to supervised semantic segmentation but does not report the performance of any state-of-the-art methods, either supervised or unsupervised. This claim is somewhat verifiable as it highlights a gap in the evaluation process, but it lacks specific examples or references to state-of-the-art methods that could be included for comparison. The authors would need to identify and include these methods themselves, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It points out that while the paper claims comparable performance to supervised semantic segmentation, it does not report the performance of any state-of-the-art methods, either supervised or unsupervised. This feedback is clear and actionable, as it directs the authors to include comparisons with relevant state-of-the-art techniques to substantiate their claims. However, the comment could be more helpful if it suggested specific methods or sources to consider for comparison. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses uncertainty about the explanation of the first curve-finding part in relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling, suggesting that it may not guarantee weight changes along the curve described in the first part. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the explanation. The feedback lacks actionable details, such as recommending specific changes or providing examples of how to clarify the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first curve-finding part,\" allowing the authors to accurately identify the specific section being addressed. It also specifies the issue by questioning the explanation of why the FGE work is relevant and highlights the potential issue with the cyclical learning rate scheduling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation of the first curve-finding part in relation to the FGE work. It suggests that the cyclical learning rate scheduling may not guarantee weight changes along the curve described in the first part. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. The authors may find it challenging to understand and address the issue without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the clarity and validity of the explanation provided in the paper regarding the first curve-finding part and its relation to the FGE work. It points out a potential issue with the cyclical learning rate scheduling, suggesting that it may not guarantee weight changes along the curve described in the first part. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the explanation. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment expresses uncertainty about the explanation of the first curve-finding part in relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling, suggesting that it may not guarantee weight changes along the curve described in the first part. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify or improve this explanation. Without specific actions or detailed feedback, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first curve-finding part,\" allowing the authors to accurately identify the specific section being addressed. It also specifies the issue by questioning the explanation of why the FGE work is relevant and highlights the potential issue with the cyclical learning rate scheduling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation of the first curve-finding part in relation to the FGE work, suggesting that the cyclical learning rate scheduling may not guarantee weight changes along the curve described in the first part. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the point.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the clarity and validity of the explanation provided in the paper regarding the first curve-finding part and its relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling, suggesting that it may not guarantee weight changes along the curve described in the first part. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the explanation. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors present a case study, ideally with synthetic datasets, to demonstrate the effectiveness of a distillation strategy. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and asks if the authors have checked the reasons behind this. The comment also suggests that the authors should provide more reasoning or hypotheses based on the performance. While the action is explicit, it lacks concrete guidance on how to conduct the case study or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests presenting a case study with synthetic datasets to demonstrate the effectiveness of a distillation strategy. The comment provides specific examples, such as the performance of LFADS-Hard and LFADS-Soft, and questions the authors about the reasons behind these results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that presenting a case study with synthetic datasets could help demonstrate the effectiveness of a distillation strategy. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and questions the authors about the reasons behind this. While the comment offers a logical suggestion for improvement, it lacks explicit references or detailed reasoning to fully substantiate the claim. The authors are prompted to provide more reasoning or hypotheses, but the comment itself does not offer a comprehensive justification. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but requires further elaboration from the authors.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that presenting a case study, ideally with synthetic datasets, could help demonstrate the effectiveness of a distillation strategy. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and questions the authors about the reasons behind this. The comment also encourages the authors to provide more reasoning or hypotheses based on the performance. This feedback is clear and actionable, offering a concrete suggestion for improving the paper's depth and understanding of the results. However, it could be more helpful if it included specific guidance on how to conduct the case study or what aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should create cloze-style or question answering evaluation sets to focus on generating factual knowledge, rather than relying solely on LM loss evaluation. While the comment provides a clear direction for improvement, it does not specify how to implement these evaluation sets or what specific aspects should be considered. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of LM loss throughout the paper, suggesting that it is not sufficient for evaluating factual knowledge because only a few tokens in a sentence are related to facts. It proposes creating cloze-style or question answering evaluation sets to focus on factual knowledge. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement by recommending alternative evaluation methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that evaluating LM loss is not sufficient for assessing factual knowledge because only a few tokens in a sentence are related to facts. The reviewer suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that LM loss alone is insufficient. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the evaluation approach used in the paper, specifically focusing on the evaluation of LM loss. It suggests that while LM loss may be suitable for evaluating style and topics, it is not sufficient for assessing factual knowledge, as only a few tokens in a sentence are related to facts. The comment provides a clear and actionable suggestion by recommending the creation of cloze-style or question answering evaluation sets to focus on factual knowledge. This feedback is valuable as it offers a concrete direction for improving the evaluation methodology, which could enhance the paper\\'s contribution and rigor. However, the comment could be more helpful if it included specific examples or guidance on how to implement these evaluation sets. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the theoretical or topological basis for the sensitivity of the RTD score to clusters, suggesting that the authors should provide explanations for this sensitivity. It also raises a concern about the specificity of the RTD score, questioning why it is only applicable to network representations. While the comment implies that the authors should provide theoretical or topological explanations and clarify the applicability of the RTD score, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional explanations and clarifications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the key contribution of the paper, which is the sensitivity of the RTD score to clusters. It also mentions the experiments that verify this claim, allowing the authors to accurately identify the part of the paper being discussed. The comment is specific because it questions the theoretical or topological basis for the sensitivity of the RTD score and why it is specifically applicable to network representations. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the theoretical or topological basis for the sensitivity of the RTD score to clusters, suggesting that the authors should provide explanations for this sensitivity. It also questions why the RTD score is specifically applicable to network representations. While the comment raises valid points, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors may find it challenging to address these concerns without additional context or evidence. Therefore, the comment is somewhat verifiable, as it provides a basis for questioning but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a key contribution of the paper, which is the sensitivity of the RTD score to clusters, and questions the theoretical or topological basis for this sensitivity. It also raises a concern about the applicability of the RTD score to any vectors with the same size, specifically questioning why it is only applicable to network representations. This feedback is somewhat helpful as it prompts the authors to provide a theoretical or topological explanation for the sensitivity of the RTD score and to clarify its applicability to network representations. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these concerns. Overall, the feedback provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the theoretical or topological basis for the sensitivity of the RTD score to clusters and why it is specifically applicable to network representations. While it raises valid points, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment implies that the authors should provide additional explanations or clarifications, but it lacks concrete steps or examples for the authors to follow. As a result, the feedback is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the key contribution of the paper, which is the sensitivity of the RTD score to clusters. It also mentions the experiments that verify this claim, allowing the authors to accurately identify the part of the paper being discussed. The comment is specific because it questions the theoretical or topological basis for the sensitivity of the RTD score and why it is specifically applicable to network representations. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the theoretical or topological basis for the sensitivity of the RTD score to clusters, suggesting that the authors should provide explanations for this sensitivity. It also raises a concern about the applicability of the RTD score to any vectors with the same size, questioning why it is specifically applicable to network representations. While the comment raises valid points, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors may find it challenging to address these concerns without additional context or evidence. Therefore, the comment is somewhat verifiable, as it provides a basis for questioning but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a key contribution of the paper, which is the sensitivity of the RTD score to clusters, and questions the theoretical or topological basis for this sensitivity. It also raises a concern about the applicability of the RT"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that ROCK has similar complexity to the original model, suggesting that it adds multiple layers and requires inference timings to support this claim. It also identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. The reviewer suggests comparing the full model (DNS) with models where one task is dropped out (DS, NS, DN) to address this weakness. While the comment provides explicit actions\u2014providing inference timings and conducting ablation studies\u2014it lacks concrete details on how to implement these actions. The authors know they need to address these points but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 88-89, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that ROCK has similar complexity to the original model, noting the addition of multiple layers and suggesting that inference timings should be provided to support this claim. Additionally, it identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. The comment provides specific suggestions for improvement, such as comparing the full model with models where one task is dropped out. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that ROCK has similar complexity to the original model, suggesting that it adds multiple layers and requires inference timings to support this claim. The reviewer provides a logical reasoning by pointing out the additional layers and the need for inference timings. However, the comment lacks specific examples or references to support the claim that the complexity is significantly different. This makes the claim somewhat verifiable, as it provides a basis for questioning the claim but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses two main points. First, it questions the claim that ROCK has similar complexity to the original model, suggesting that the addition of multiple layers makes this unlikely. The reviewer provides a logical reasoning by pointing out the additional layers and the need for inference timings to support the claim. This feedback is clear and actionable, prompting the authors to provide evidence or justification for their claim. Second, the comment identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. It suggests conducting comparisons between the full model and models with dropped tasks to address this weakness. This feedback is clear and actionable, offering specific guidance on how to improve the experimental section. Overall, the comment is mostly helpful as it provides valuable insights and suggestions for enhancing the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the calculation of the joint probability P(y_1, y_2, ..., | y_{<i}, X) when it is not autoregressive. It suggests adding the equation to the paper for clarity. While the comment implies that the authors should include the equation, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added, but it is inferred rather than directly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the calculation of the joint probability P(y_1, y_2, ..., | y_{<i}, X) when it is not autoregressive and suggests adding the equation for clarity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and seeks clarification, while the suggestion is a request for additional information. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the calculation of the joint probability P(y_1, y_2, ..., | y_{<i}, X) when it is not autoregressive. It suggests adding the equation to the paper for clarity. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional information. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it explained why this clarification is important or how it relates to the overall understanding of the paper. Despite this, the feedback is mostly helpful as it provides a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to discuss these aspects, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as discussing the dataset diversity and quality and the model\\'s behavior on real-world datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need further exploration, it does not provide specific examples or references to support the claim. The reasoning is based on logical assumptions about the importance of dataset quality and real-world applicability, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also raises concerns about the model\\'s behavior on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it points out important aspects that the authors should consider to enhance the robustness and generalizability of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as recommending methods for assessing dataset quality or strategies for handling noisy data. Overall, the comment is somewhat helpful as it directs the authors to important areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks concrete steps or examples, leaving the authors to infer that they need to discuss these aspects but without clear direction on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as discussing dataset diversity and quality and the model\\'s behavior on real-world datasets. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also mentions the potential behavior of the model on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies important areas for consideration, it does not provide specific examples or references to support the claim. The reasoning is based on logical assumptions about the importance of dataset quality and real-world applicability, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the reproducibility of the results due to the lack of promised code for training and testing. It points out that the training details about data and hyperparameters do not guarantee reproducibility. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of code or specific steps to ensure reproducibility. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility in the context of the model\\'s components and training stages. It highlights the lack of promised code for training and testing, which affects the reproducibility of the results. However, the comment does not specify which part of the paper discusses the training details or hyperparameters, making it weakly grounded. The comment is specific in identifying the issue of reproducibility but lacks grounding in terms of where the authors should focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model\\'s components and training stages are multiple, and the lack of promised code for training and testing makes the results non-reproducible. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to standards or best practices in reproducibility or examples of similar cases where such issues have been resolved. This makes the claim somewhat verifiable, as it provides a general concern but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the reproducibility of the results due to the lack of promised code for training and testing. It highlights that the training details about data and hyperparameters do not guarantee reproducibility, which is a significant concern for the validity and impact of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or detailed documentation. While it points out a crucial problem, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the reproducibility of the results due to the lack of promised code for training and testing. It points out that the training details about data and hyperparameters do not guarantee reproducibility. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of code or specific steps to ensure reproducibility. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility in the context of the model\\'s components and training stages. It highlights the lack of promised code for training and testing, which affects the reproducibility of the results. However, the comment does not specify which part of the paper discusses the training details or hyperparameters, making it weakly grounded. The comment is specific in identifying the issue of reproducibility but lacks grounding in terms of where the authors should focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model\\'s components and training stages are multiple, and the lack of promised code for training and testing makes the results non-reproducible. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to standards or best practices in reproducibility or examples of similar cases where such issues have been resolved. This makes the claim somewhat verifiable, as it identifies a potential issue but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the reproducibility of the results due to the lack of promised code for training and testing. It highlights that the training details about data and hyperparameters do not guarantee reproducibility, which is a significant concern for the validity and impact of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or detailed documentation. While it points out a crucial problem, the feedback lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label':"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a missing piece of information in the paper, specifically the total number of agents available in Flow\u2019s default configuration. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of critical setup information, specifically the total number of agents available in Flow\u2019s default configuration. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying what information is missing, which is the total number of agents. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"critical setup information is missing,\" specifically mentioning the total number of agents available in Flow\u2019s default configuration. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is critical or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\u2019s default configuration. This feedback is clear and actionable, as it directly points out a missing piece of information that could significantly impact the understanding and evaluation of the experimental setup. By addressing this issue, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific works are being referred to or how the claim could be substantiated. Without explicit references or detailed feedback, the authors cannot effectively identify the areas needing revision or improvement. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point challenges the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to verify the claim. The lack of detailed evidence or examples results in the comment being classified as \"2: Borderline Verifiable,\" as it provides some reasoning but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment challenges the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. While it identifies a potential issue with the paper\\'s claim, it does not provide specific examples or references to the works mentioned, nor does it offer guidance on how the authors might address this critique. The comment lacks actionable feedback, making it difficult for the authors to improve their draft based on this comment alone. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. Without specific guidance or suggestions on how to substantiate or clarify the claim, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific works are being referred to or how the claim could be substantiated. Without explicit references or detailed feedback, the authors cannot effectively identify the areas needing revision or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point challenges the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to verify the claim. The lack of detailed evidence or examples results in the comment being classified as \"2: Borderline Verifiable,\" as it provides some reasoning but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment challenges the claim that the work is the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to these works, nor does it offer guidance on how the authors might address this critique or improve their claim. Without actionable feedback or detailed suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the claim that the work is"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the ablation study, noting that it does not address the effect of different numbers of projectors on distillation when feature dimensions are different. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to fill this gap. The action is implicit, as the authors need to infer that they should conduct additional experiments or analyses to explore the effect of different numbers of projectors on distillation. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of analysis on the effect of different numbers of projectors on distillation when feature dimensions are different. This provides clear guidance on what aspect of the ablation study needs further exploration. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when feature dimensions are different. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the ablation study, noting that it does not address the effect of different numbers of projectors on distillation when feature dimensions are different. This feedback is clear and actionable, as it points out a gap in the analysis that the authors can address to improve their study. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing further exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting additional experiments on diverse datasets to demonstrate the model\\'s generalization capabilities beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment provides a clear direction for additional experiments, it lacks specific guidance on which datasets or shapes to include or how to design these experiments. The actions are explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on diverse datasets to demonstrate the model\\'s generalization capabilities beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. However, the comment does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments. While the authors might infer that it relates to the experimental results or discussion sections, this inference is not direct. The comment is specific in its suggestions for additional experiments but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on diverse datasets would better demonstrate the model\\'s generalization capabilities. While the comment provides a logical reasoning for why more experiments are needed, it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable as it highlights a potential area for improvement, but it would benefit from more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on diverse datasets to demonstrate the model\\'s generalization capabilities beyond the three categories mentioned (chair, airplane, car). It also suggests evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. This feedback is valuable as it offers specific directions for enhancing the experimental validation of the model, which can significantly strengthen the paper. However, the comment could be more helpful if it included specific examples of datasets or shapes to consider. Overall, the comment is mostly helpful as it provides a clear path for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and suggests that low compute restrictions during test time may not be necessary due to the ability to train fewer models. This feedback provides a clear and direct action for the authors to take, which is to include a comparison against methods with longer training times. The suggestion is concrete, as it specifies the need for a comparison and the implications of low computational requirements. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. This provides a clear reference to the specific part of the paper that needs attention, making the comment fully grounded. The comment also specifies the need to understand the implications of low computational requirements and suggests that low compute restrictions during test time may not be necessary due to the ability to train fewer models. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. The comment provides a logical reasoning by highlighting the importance of understanding the implications of low computational requirements and the potential redundancy of low compute restrictions during test time. However, the comment lacks specific examples or references to other methods that require more training time, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable argument but could benefit from additional evidence or examples.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improvement by recommending a comparison against methods that require more training time. It highlights the importance of understanding the implications of low computational requirements, particularly in the context of the neural networks proposed by Park & Van Hentenryck (2023) and others. The comment also acknowledges the potential redundancy of low compute restrictions during test time and suggests that training fewer models may render such restrictions unnecessary. This feedback is specific and offers a concrete direction for the authors to enhance their work by considering a broader range of methods and their implications. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks in ResNet. It provides a specific action for the authors to take by recommending they provide more comparisons between DetNAS and other networks constructed by efficient blocks, such as the result of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is explicit and concrete, giving the authors clear guidance on how to improve their draft by addressing the fairness of their comparisons and providing additional results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between DetNAS and ResNet, noting that ShuffleNetv2 is more efficient than the Residual block in ResNet. The comment provides a concrete suggestion for improvement by recommending additional comparisons with other networks constructed by efficient blocks, such as the result of a 3.8G FLOPs ShuffleNetv2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks in ResNet. The reviewer suggests providing more comparisons with other networks constructed by efficient blocks, such as the result of a 3.8G FLOPs ShuffleNetv2 in Table 2. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for improvement. However, it lacks detailed evidence or references to support the claim about the efficiency difference between the blocks, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison between DetNAS and ResNet, noting that ShuffleNetv2 is more efficient than the Residual block in ResNet. It provides a clear and actionable suggestion for improvement by recommending that the authors provide more comparisons between DetNAS and other networks constructed by efficient blocks, such as the result of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is constructive and offers a concrete way for the authors to enhance the comprehensiveness and fairness of their comparisons, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the input and output spaces/representations, suggesting that they are restricted to specific representations. It compares this limitation to other works that can handle any finite-dimensional representation. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or improve the generality of their approach. The feedback lacks actionable details, such as recommending alternative representations or suggesting ways to expand the scope of the work. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the input and output spaces/representations, suggesting that they are restricted to certain representations. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation in the generality of the approach compared to other works mentioned, but it lacks detailed guidance on how to address this limitation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer compares this limitation to other works that can handle any finite-dimensional representation. However, the comment does not provide specific examples or references to the mentioned papers or detailed reasoning to support the claim that the current approach is less general. This lack of explicit evidence or detailed comparison makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the generality of the input and output spaces/representations, noting that they are restricted to specific representations such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It compares this limitation to other works that can handle any finite-dimensional representation, suggesting that the current approach is less general. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the generality of their approach. Without actionable feedback or detailed advice, the comment provides only a vague direction for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the generality of the input and output spaces/representations, noting that they are restricted to specific representations such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It compares this limitation to other works that can handle any finite-dimensional representation. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand the generality of their approach. Without specific recommendations or actionable steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the input and output spaces/representations, suggesting that they are restricted to certain representations. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation in generality compared to other works, but it lacks detailed guidance or suggestions for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer compares this limitation to other works that can handle any finite-dimensional representation, suggesting that the current approach is less general. However, the comment does not provide specific examples or references to the mentioned papers or detailed reasoning to support the claim that the current approach is less general. This lack of explicit evidence or detailed comparison makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the generality of the input and output spaces/representations, noting that they are restricted to specific representations such as the group itself under the regular or trivial representation,"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks concrete actions or detailed advice on how to improve the practical usability of the system. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention a specific section or part of the paper where this complexity is discussed, making it weakly grounded. The comment is specific in detailing the complexity and potential limitations of the system, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, the comment does not provide specific examples or references to support the claim that these complexities might restrict the practical usability of the system. The reasoning is somewhat vague, as it lacks detailed evidence or examples to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in practical applications of the proposed system, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This feedback highlights a potential limitation that could restrict the practical usability of the system for typical users. However, the comment does not provide specific suggestions or guidance on how the authors might address this complexity or simplify the process. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks actionable details, such as recommending alternative approaches or providing examples of how to make the system more user-friendly. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention a specific section or part of the paper where this complexity is discussed, making it weakly grounded. The comment is specific in detailing the complexity and potential limitations of the system, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, the comment lacks specific examples or references to support the claim that these complexities might restrict the practical usability of the system. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is categorized as somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in practical applications of the proposed system, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This highlights a potential limitation that could restrict the practical usability of the system for typical users. However, the comment does not provide specific suggestions or guidance on how the authors might address this complexity or simplify the process. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the contributions of the paper are not significant and that there is a lack of comparison with traditional classification or manifold learning literature. However, it does not provide any explicit or implicit suggestions on how the authors could address these issues or improve the significance of their contributions. Without specific guidance or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the significance of the paper's contributions and the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which parts of the paper should be revised or how the authors could address these issues. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the contributions of the paper are not significant and that there is a lack of comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without such evidence or justification, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. While it identifies a potential weakness in the paper's contributions, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the significance of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment points out that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, it does not provide any explicit or implicit suggestions on how the authors could address these issues or improve the significance of their contributions. Without specific guidance or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the significance of the paper's contributions and the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which parts of the paper these issues pertain to, nor does it provide detailed guidance on how to address them. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without such evidence or justification, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the significance of their contributions. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment points out that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, it does not provide any explicit or implicit suggestions on how the authors could address these issues or improve the significance of their contributions. Without specific guidance or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the significance of the paper's contributions and the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which parts of the paper these issues pertain to, nor does it provide specific guidance on how to"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale for this suggestion by explaining that larger datasets could provide more accurate estimates but would require more time to compute. Additionally, the reviewer references two external works, [1] and [2], which could provide further context or insights into the topic. While the comment clearly identifies the need for a discussion and provides some guidance by referencing relevant literature, it does not offer detailed instructions on how to structure or conduct this discussion. Therefore, the action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale for this suggestion by explaining the trade-off between accuracy and computation time. Additionally, it references two external works, [1] and [2], which could provide further context or insights into the topic. However, the comment does not specify which part of the paper should include this discussion, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to incorporate this discussion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary, providing a rationale for this claim by explaining the trade-off between accuracy and computation time. The comment also references two external works, [1] and [2], which could provide further context or insights into the topic. While the references are not directly cited in the comment, they offer a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explicitly referencing the specific aspects of the works that support the claim, such as how they relate to the impact of few-shot datasets on sparsity ratios. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a necessary discussion on the impact of the few-shot dataset for the sparsity ratio, providing a rationale for why this is important. It explains the trade-off between accuracy and computation time, which is a relevant consideration for the authors. Additionally, the comment references two external works that could provide further context or insights into the topic, offering a starting point for the authors to explore. While the comment does not provide detailed guidance on how to conduct this discussion, it clearly identifies an area for improvement and offers some direction by referencing relevant literature. This makes the feedback somewhat helpful, as it provides a basis for the authors to enhance their draft by addressing this important aspect. However, it could be more helpful with additional guidance on how to integrate the discussion into the paper. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not provided an explanation for why it is beneficial to keep representations in the same hidden space and that this has not been experimentally verified. While the comment identifies a gap in the paper, it does not explicitly instruct the authors on how to address this issue or provide specific guidance on what kind of explanation or verification is needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification and experimental verification, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of explanation and experimental verification regarding the benefit of keeping representations in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for an explanation and experimental verification, but without clear grounding, the authors may struggle to pinpoint where these additions are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not provided an explanation or experimental verification for keeping representations in the same hidden space. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the justification for keeping representations in the same hidden space and the lack of experimental verification of this practice. While it points out an area that needs clarification, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness in the paper but lacks actionable advice, making it somewhat helpful. The authors are informed of a gap but are not given clear steps to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a lack of sufficient novelty in the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or enhance the novelty of their work. The feedback lacks actionable details, such as recommending specific improvements or alternative approaches to achieve novelty. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). This provides full grounding as it clearly identifies the part of the paper being discussed. The comment also specifies the issue by pointing out that the approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks sufficient novelty in its methodologies, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). The comment suggests that this approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. While the comment provides a specific example of the methodology, it lacks detailed reasoning or evidence to fully substantiate the claim of limited novelty. The reference to existing works is a step towards verification, but the comment could be strengthened with more detailed analysis or comparisons to demonstrate the lack of advancement. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of sufficient novelty in the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. While the comment highlights a critical issue, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\u0394t fixed, such as S5, which computes the input-output via a parallel scan. However, it does not provide explicit guidance or suggestions on how the authors should incorporate this information into their work. The comment implies that the authors should consider these approaches, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific oversight in the paper regarding the consideration of various SSM-based approaches that address the issue of keeping \\\\u0394t fixed. It mentions a particular example, S5, which computes the input-output via a parallel scan. However, the comment does not specify which part of the paper this oversight is related to, such as a specific section or discussion where these approaches should be included. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the oversight but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\u0394t fixed, such as S5. However, the comment does not provide specific examples or references to these approaches, making it difficult for the authors to understand which approaches are being referred to or how they relate to the paper. The lack of detailed justification or examples results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient evidence or reasoning to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper regarding the consideration of various SSM-based approaches that address the issue of keeping \\\\u0394t fixed. It mentions a particular example, S5, which computes the input-output via a parallel scan, highlighting a potential gap in the literature review. However, the comment does not provide detailed guidance or suggestions on how the authors might incorporate this information into their work or why it is important. While it points out an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\u0394t fixed, such as S5, which computes the input-output via a parallel scan. However, it does not provide explicit guidance or suggestions on how the authors should incorporate this information into their work. The comment implies that the authors should consider these approaches, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific oversight in the paper regarding the consideration of various SSM-based approaches that address the issue of keeping \\\\u0394t fixed, such as S5. However, it does not specify which part of the paper this oversight pertains to, making it weakly grounded. The comment is specific in identifying the issue of overlooking these approaches but lacks detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\u0394t fixed, such as S5. However, it does not provide specific examples or references to these approaches, making it difficult for the authors to understand which approaches are being referred to or how they relate to the paper. The lack of detailed justification or examples results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient evidence or reasoning to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the paper regarding the consideration of various SSM-based approaches that address the issue of keeping \\\\u0394t fixed. It mentions a particular example, S5, which computes the input-output via a parallel scan, highlighting a potential gap in the literature review. However, the comment does not provide detailed guidance or suggestions on how the authors might incorporate this information into their work or why it is important. While it points out an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues: it questions whether the presentation of \"3\" as the underlying data generating mechanism is accurate, suggests that it would be more standard to discuss causal graphs in the context of the underlying system, and points out that Definition 4 is difficult to read due to unclear dependencies. The reviewer also mentions the proof of Theorem, but does not specify what needs to be improved or clarified. While the comment identifies areas for improvement, it lacks explicit instructions or concrete guidance on how to address these issues. The authors can infer that they need to revise their presentation and definitions, but the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3\" and \"Definition 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the presentation of \"3\" as the underlying data generating mechanism and the difficulty in reading Definition 4 due to unclear dependencies. Additionally, it suggests a more standard approach of discussing causal graphs for the underlying system. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the presentation and content of the paper. It questions the accuracy of presenting \"3\" as the underlying data generating mechanism and suggests that it would be more standard to discuss causal graphs for the underlying system. Additionally, it points out that Definition 4 is difficult to read due to unclear dependencies. While the comment provides some reasoning and suggestions for improvement, it lacks specific examples or references to support the claims fully. The lack of detailed justification or evidence makes it somewhat verifiable, as the authors would need to make a significant effort to understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the presentation of \"3\" as the underlying data generating mechanism, which the reviewer believes is inaccurate. It suggests that it would be more standard to discuss causal graphs in the context of the underlying system rather than for the label inference process. Additionally, the comment points out that Definition 4 is difficult to read due to unclear dependencies. While the comment highlights these issues, it lacks specific suggestions or guidance on how to address them, such as proposing alternative explanations or clarifications. This limits the comment\\'s usefulness to the authors, making it somewhat helpful as it provides some insight into areas needing improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. While the comment implies that the authors should provide more examples, it does not explicitly instruct them to do so or specify which examples would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include more examples but lack detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to sections discussing the gradient or the dual-free approach, but this is not explicitly stated. The comment is specific in its request for more examples to motivate the dual-free approach, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and suggestions for improvement, such as including more examples in machine learning to motivate the dual-free approach. It does not contain subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. While the comment identifies a potential area for improvement by questioning the feasibility of the approach, it lacks specific guidance or examples on how to address this issue. The suggestion to include more examples is somewhat helpful, as it points the authors toward a potential enhancement, but it could be more actionable with detailed examples or suggestions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of explanation regarding the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It explicitly asks the authors to provide an explanation for why they chose to select from the range [0, Pcj(0)]. This direct request for clarification gives the authors a clear action to take, which is to include an explanation in their draft. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of the Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for the selection of a probability for the appearance of an unobservable data point. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of explanation for the selection of a probability for the appearance of an unobservable data point in the data approximation technique. However, it does not provide any supporting evidence, reasoning, or references to justify why this lack of explanation is problematic or how it affects the paper\\'s validity. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors lack an explanation for their methodology. It points out that the selection of a probability for the appearance of an unobservable data point in the data approximation technique is not explained. This feedback is clear and actionable, as it directs the authors to provide a justification or explanation for their choice, which could enhance the clarity and transparency of their methodology. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how such explanations are typically included in similar works. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions, as these terms are referenced throughout the paper. While the comment implies that the authors should clarify these concepts, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to present this clarification or what specific aspects need to be addressed. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (128 and 168) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. However, it does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This feedback is actionable as it directs the authors to clarify a potentially confusing aspect of their work, which could enhance the reader\\'s understanding. However, the comment could be more helpful if it included examples or suggestions on how to present this clarification. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the AIG-generation task is not convincing and recommends providing more background for readers unfamiliar with logic synthesis. It also suggests benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to make the task more convincing. While the comment provides explicit actions\u2014adding background information and benchmarking the method\u2014it does not offer detailed guidance on how to implement these suggestions. The authors know they need to provide more background and benchmark their method, but the comment lacks specific instructions on what aspects to focus on or how to effectively present the additional information. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the AIG-generation task and suggests that it is not convincing, indicating a lack of clarity on its challenge and the need for more background information for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the task is discussed. The comment is specific in detailing what needs to be addressed, such as providing background and benchmarking, but lacks explicit grounding. Therefore, this comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the AIG-generation task's convincing nature, suggesting that it is not clear how challenging the task is and recommending more background information for readers unfamiliar with logic synthesis. The reviewer also proposes benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task's convincingness. While the comment provides a logical reasoning for the need for more background and benchmarking, it lacks specific examples or detailed references to support the claim fully. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires additional evidence or examples to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of clarity regarding the challenge of the AIG-generation task and suggests that more background information should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task's convincingness. This feedback is clear and actionable, offering specific suggestions for improving the paper's clarity and credibility. However, it could be more helpful if it provided additional guidance on how to effectively incorporate this background information or benchmarking into the paper. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements to their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a lack of clarity regarding the challenge of the AIG-generation task and suggests that more background information should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task's convincingness. While the comment provides explicit actions\u2014adding background information and benchmarking the method\u2014it does not offer detailed guidance on how to implement these suggestions. The authors know they need to provide more background and benchmark their method, but the comment lacks specific instructions on what aspects to focus on or how to effectively present the additional information. Therefore, the comment is rated as somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The review comment addresses the AIG-generation task and suggests that it is not convincing, indicating a lack of clarity on its challenge and the need for more background information for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task's convincingness. While the comment provides specific suggestions for improvement, it does not explicitly mention a particular section of the paper where these issues are discussed, making it weakly grounded. However, the comment is specific in detailing what needs to be addressed, such as providing background and benchmarking. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the AIG-generation task's convincingness, suggesting that it is not clear how challenging the task is and recommending more background information for readers unfamiliar with logic synthesis. It also proposes benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some statements in the paper lack detail and analysis. However, it does not specify which statements are lacking detail or provide guidance on how the authors should address this issue. The feedback is vague and does not offer explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the detail and analysis in their paper. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements or sections are being referred to. This makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the statements are lacking detail or analysis. Without specific examples or guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some statements in the paper lack detail and analysis. However, it does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand which statements are lacking detail or how they could improve them. Without detailed justification or examples, the claim is unverifiable, as it lacks the necessary evidence to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that some statements in the paper lack detail and analysis, which is a valid observation. However, it does not specify which statements are lacking detail or provide guidance on how the authors might address this issue. Without specific examples or actionable suggestions, the feedback is limited in its usefulness to the authors. As a result, the comment is barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their diffusion models with other generative models, such as VAE, and provide an analysis of how the unique features of diffusion models, like diffusion timesteps, affect feature learning. While the comment implies that the authors should conduct this comparison and analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison and analysis that would be beneficial. However, the comment is stated implicitly, as the authors need to infer the action from the suggestion. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the diffusion models with other generative models, such as VAE, and analyzing how the unique features of diffusion models, like diffusion timesteps, affect feature learning. However, it does not specify which part of the paper should include this comparison or analysis, making it weakly grounded. The comment is specific in suggesting what could be added to the paper to enhance its value, but without clear grounding, the authors may struggle to identify where these suggestions should be implemented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that comparing diffusion models with other generative models, such as VAE, could be more informative. It highlights the unique features of diffusion models, like diffusion timesteps, and argues that analyzing how these differences affect feature learning would add significant value. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as the authors would need to further develop the rationale themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by comparing diffusion models with other generative models, such as VAE, and analyzing how the unique features of diffusion models, like diffusion timesteps, affect feature learning. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper by highlighting a comparative aspect that could add significant value. However, the comment could be more helpful if it included specific examples or references to similar analyses or studies that have been conducted. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions the complementarity of the ICT and DaPI tasks in Table 4, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. Second, it points out the lack of experiments to demonstrate the influence of the number of negatives on performance, suggesting that the quality of negatives is more important than their quantity. While the comment identifies specific issues, it does not provide explicit guidance on how to address these concerns or improve the draft. The authors can infer that they need to provide more evidence or experiments to support their claims, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the combination of self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. Additionally, it points out the lack of experiments to demonstrate the influence of the number of negatives on performance, referencing the importance of quality over quantity of negatives as shown in TAS-B. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims. The first claim is that the combination of self-supervised tasks ICT and DaPI is not complementary, and the effectiveness of DaPI is not significant despite doubling GPU memory usage. This claim is somewhat verifiable as it provides a specific observation about the results in Table 4, but it lacks detailed reasoning or evidence to fully substantiate the claim. The second claim is that ICoL is proposed to mitigate memory issues but lacks experiments to show the influence of the number of negatives, referencing the importance of quality over quantity of negatives as shown in TAS-B. This claim is also somewhat verifiable, as it references a known concept but lacks specific examples or detailed reasoning to fully support the argument. Overall, the review point provides some support for its claims but lacks comprehensive justification, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it questions the complementarity of the ICT and DaPI tasks in Table 4, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. This observation prompts the authors to reconsider the choice of tasks and their impact on performance. Second, the comment points out the lack of experiments to demonstrate the influence of the number of negatives on performance, suggesting that the quality of negatives is more important than their quantity. This feedback is clear and actionable, as it directs the authors to provide additional experiments or analysis to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an issue with Figure 3, noting that it is unclear what the difference is between the three plots on the same row. The reviewer suggests that a caption should be added to emphasize the distinction between the plots. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the clarity of the figure. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the difference between the three plots on the same row and suggests adding a caption to emphasize this distinction. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 3 lacks clarity in distinguishing between the three plots on the same row and recommends adding a caption to emphasize the differences. While the comment identifies a potential issue with the figure, it does not provide specific reasoning or examples to support why the current presentation is unclear. The suggestion to add a caption is a logical step, but without further elaboration, the claim remains somewhat verifiable. The authors would need to infer the exact nature of the issue and how to address it, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is unclear what the difference is between the three plots on the same row. It suggests that a caption should be added to emphasize the distinction between the plots. This feedback is clear and actionable, providing the authors with a concrete step to improve the clarity and understanding of their figure. By addressing this issue, the authors can enhance the readability and effectiveness of their visual presentation. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should conduct a more thorough examination of computational complexity, it does not provide specific guidance on how to perform this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific details of the analysis required. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in its suggestion to address the computational complexity, but without clear grounding, the authors may struggle to identify where to incorporate this analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. However, the comment does not provide specific examples, references, or detailed reasoning to support why this analysis is necessary or how it would improve the paper. Without such supporting information, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. This feedback is actionable as it provides a clear direction for the authors to enhance their work by addressing the computational complexity aspect. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement and provides some guidance, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should conduct this analysis, it does not provide specific guidance on how to perform it or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis required. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in its suggestion to address computational complexity, but without clear grounding, the authors may struggle to identify where to incorporate this analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. However, the comment lacks specific examples, references, or detailed reasoning to support why this analysis is necessary or how it would improve the paper. Without such supporting information, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. This feedback is actionable as it provides a clear direction for the authors to enhance their work by addressing the computational complexity aspect. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement and provides some guidance, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the paper could benefit from a deeper analysis of GPSE's computational complexity, particularly in comparison to complex hand-crafted PSEs and other encoding strategies. However, it does not provide specific guidance on how to"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to report the results on the test-standard split instead of the test-dev split, as mentioned in the guidelines from the VQA dataset authors. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable because it offers specific and concrete guidance on how to address the issue, aligning with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and the \"VQA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with reporting results on the test-dev split instead of the test-standard split, as per the guidelines from the VQA dataset authors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset should be reported on the test-standard split instead of the test-dev split, as per the guidelines from the VQA dataset authors. This claim is supported by a reference to the guidelines, which provides a clear rationale for the recommendation. The reference to the guidelines adds credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by including specific examples or further details about the potential overfitting issue, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable piece of feedback regarding the reporting of results on the VQA dataset. It points out that the results should be reported on the test-standard split rather than the test-dev split, as mentioned in the guidelines from the VQA dataset authors. This guidance is clear and directly addresses a potential issue with the methodology, allowing the authors to make a straightforward improvement to their draft. The comment is highly helpful as it offers precise and constructive advice that can significantly enhance the accuracy and validity of the paper\\'s findings.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose the parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) to guarantee a certain decision-making loss level while optimizing the Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss could improve the impact of the theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to address this issue. The authors are left to infer that they need to find a way to control the term $T_i \\\\beta$, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging. However, the comment does not specify which part of the paper discusses these parameters or the trade-off, making it weakly grounded. The comment is specific in detailing the issue with controlling the term $T_i \\\\beta$, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging, which implies a potential issue with the methodology. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim or suggest how to address the issue. This lack of supporting evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging, which could impact the theoretical result\\'s impact. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue or what alternative approaches might be considered. The feedback is somewhat helpful as it points out a critical aspect of the methodology that needs further exploration, but it could be more beneficial with additional details or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging, implying that the authors need to address this issue to improve the impact of their theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to manage this trade-off or control the term $T_i \\\\beta$. The action is implicit and lacks detailed instructions, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging, which implies a potential issue with the methodology. However, the comment does not specify which part of the paper discusses these parameters or the trade-off, making it weakly grounded. The authors might infer that it relates to sections discussing methodology or results, but this is not explicitly stated. The comment is specific in detailing the issue with controlling the term $T_i \\\\beta$, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) in the context of optimizing Brier scores and managing the trade-off between prediction accuracy and decision-loss. It suggests that controlling the term $T_i \\\\beta$ is challenging, implying a potential issue with the methodology. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. It questions whether the methods presented are ready for extension to non-fully connected architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the applicability of their methods. The feedback lacks actionable details, such as recommending specific modifications or experiments to explore the applicability to non-fully connected architectures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the LBEN method to more structured layers like convolutions, specifically mentioning the comparison with MON. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique of the method\\'s applicability and the need for extension to non-fully connected architectures, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. The reviewer notes that the method\\'s performance trails that of MON, suggesting that the methods may not be ready for extension to non-fully connected architectures. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. It questions whether the methods presented are ready for extension to non-fully connected architectures, given the significant performance gap observed when compared to MON. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or explore the applicability of their methods to different architectures. This limits the comment\\'s usefulness to the authors, as it points out a concern but does not provide actionable feedback for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. It questions whether the methods presented are ready for extension to non-fully connected architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or explore the applicability of their methods to different architectures. Without specific recommendations or actionable steps, the authors are left without a clear understanding of what changes or experiments might be necessary. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. It questions whether the methods presented are ready for extension to non-fully connected architectures. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique of the method\\'s applicability and the need for extension, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the LBEN method to more structured layers like convolutions, despite its strength in being applicable to convnets without much modification. The reviewer notes that the method\\'s performance trails that of MON, suggesting that the methods may not be ready for extension to non-fully connected architectures. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. While the comment implies that the authors should explore these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested metrics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. However, the comment does not specify which part of the paper this evaluation is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting potential metrics for evaluation, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It does not present a claim or opinion but rather poses a question and provides suggestions for potential metrics. The comment does not make any subjective judgments or claims that require verification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark, offering a specific direction for improvement. However, the comment could be more helpful if it explained why these metrics are relevant or how they could be applied. Despite this, the feedback is mostly helpful as it highlights an area for enhancement and provides actionable suggestions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the Wiener deconvolution has already been proposed, implying that the main contribution of the paper is not significant. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this concern or improve the sufficiency of their contribution. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the main contribution is insufficient. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not significant because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed. This feedback highlights a potential issue with the novelty of the work, which is important for the authors to address. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might enhance the sufficiency of their contribution. Without detailed feedback or constructive advice, the authors are left with a general critique that does not offer a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the Wiener deconvolution has already been proposed, implying that the main contribution of the paper is not significant. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this issue or improve the sufficiency of their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the main contribution is insufficient. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not significant because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed, implying that the contribution is not significant. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular aspects of the contribution that are insufficient or offering guidance on how the authors might enhance their work, the comment does not assist the authors in improving their draft. Therefore, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed, implying that the contribution is not significant. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this issue or improve"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several weaknesses in the connection to spin glasses, specifically questioning how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. While the comment highlights specific areas that need clarification, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more detailed explanations or evidence to support their claims, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the connection to spin glasses and the issues with the regularization term, the effect on Parisi\\'s order parameter, and the role of temperature. This provides clear guidance on what aspects of the connection to spin glasses need further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the connection between spin glasses and the regularization term, specifically highlighting three areas where the connection appears weak. It does not provide any supporting evidence or references to substantiate these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or examples makes the claim unverifiable, as it does not offer sufficient justification for the authors to address the concerns effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper by questioning the connection between spin glasses and the regularization term, specifically highlighting three areas that need clarification. It points out the lack of explanation regarding how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. This feedback is valuable as it directs the authors to address significant gaps in their explanation, which could significantly improve the clarity and depth of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful, as it highlights important areas for improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or enhance the contribution. There is no guidance on how the authors might improve the self-training scheme or what specific aspects could be expanded upon. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme, indicating that it is a direct application with limited contribution. However, it does not specify which part of the paper discusses this scheme, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides some insight into the perceived limitation of the contribution, it lacks specificity and grounding. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application with limited contribution. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. While it identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might enhance the contribution or address the perceived limitation. Without actionable feedback or detailed advice, the comment provides only a vague indication of an issue without offering a path for improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or enhance the contribution. Without specific guidance or suggestions, the authors are left without direction on how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme but does not specify which part of the paper discusses this scheme, making it difficult for the authors to pinpoint the exact section that needs revision. While it acknowledges the exploration of this direction, it lacks specificity in terms of what aspects of the contribution are considered limited. This lack of detail and clarity makes the comment weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application with limited contribution. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. However, it does not provide any specific feedback or suggestions on how the authors might enhance the contribution or address the perceived limitation. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or enhance the contribution. Without specific guidance or suggestions, the authors are left without direction on how to improve their draft. As a result, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the exploration of a self-training scheme but suggests that its contribution is relatively limited. However, it does not specify which part of the paper discusses this scheme, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in terms of what aspects of the contribution are considered limited or how they could be improved. Without clear guidance or detailed feedback, the authors are left without a clear path for improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label':"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results shown in the paper are low-resolution and recommends including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This feedback provides a clear and explicit action for the authors to take, which is to include additional images to enhance the clarity and quality of the results. The suggestion is concrete, as it specifies exactly what should be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results shown in the paper. However, it does not specify which part of the paper these results are located in, making it weakly grounded. The comment is specific in its suggestion to include zoomed-in regions for inspection, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results shown in the paper are low-resolution and recommends including zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, the comment does not provide any specific examples or detailed reasoning to support why the results are considered low-resolution or how the inclusion of zoomed-in regions would improve the quality. Without such evidence or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that they are low-resolution. It provides a clear and actionable suggestion by recommending the inclusion of zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and impact of their results, making it highly helpful. However, the comment could be more helpful if it explained why the inclusion of these zoomed-in regions is important or how it would benefit the readers. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes, which may be a concern for real-world applications with limited computational resources, and the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The authors are left to infer that they might need to explore alternative methods or discuss these limitations in their paper. The action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns regarding the comparative inference method, including the increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. However, it does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about computational cost and applicability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. Additionally, it mentions that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method's applicability. While the comment provides logical reasoning about the potential issues with computational cost and data availability, it lacks specific examples or references to support these claims. This makes the comment somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the concerns.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two significant concerns regarding the comparative inference method: the increase in inference cost due to multiple forward passes, which may be a concern for real-world applications with limited computational resources, and the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks. These points highlight potential limitations of the method that the authors need to address. However, the comment does not provide specific suggestions or guidance on how the authors might mitigate these issues or improve the applicability of their method. While it points out important considerations, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes, which may be a concern for real-world applications with limited computational resources, and the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks. While the comment highlights potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The authors are left to infer that they might need to explore alternative methods or discuss these limitations in their paper. The action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns regarding the comparative inference method, including the increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. However, it does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about computational cost and applicability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. Additionally, it mentions that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method\\'s applicability. While the comment provides logical reasoning about the potential issues with computational cost and data availability, it lacks specific examples or references to support these claims. This makes the comment somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the concerns.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two significant concerns regarding the comparative inference method: the increase in inference cost due to multiple forward passes, which may be a concern for real-world applications with limited computational resources, and the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks. These points highlight potential limitations of the method"}
{"generated_text": "{'actionability_rationale': 'The review point suggests performing gradient clipping with a high value for the gradient norm to address the issue of exploding gradients, which could lead to NaNs appearing. The comment provides a clear and explicit action for the authors to take, which is to implement gradient clipping. However, it does not specify the exact value for the gradient norm or how to implement the gradient clipping, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential solution to the issue of exploding gradients by recommending gradient clipping with a high value for the gradient norm to avoid NaNs. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that gradient clipping with a high value for the gradient norm could be used to address the issue of exploding gradients, which could lead to NaNs appearing. The comment provides a logical reasoning for the suggestion, as gradient clipping is a common technique used to prevent such issues. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the suggestion themselves to fully understand and implement it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for addressing the issue of exploding gradients, which is a common problem in deep learning. It recommends performing gradient clipping with a high value for the gradient norm to avoid NaNs appearing, which is a more robust solution than simply reinitializing the model. This feedback is clear and actionable, offering the authors a concrete step to improve their approach. However, the comment could be more helpful if it included additional details on how to implement gradient clipping or provided examples of effective values for the gradient norm. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests a more detailed explanation of the term \"common pattern,\" indicating that the authors need to provide additional information to clarify its meaning. This direct request provides a clear action for the authors to take, ensuring they know exactly what needs to be addressed. The comment is specific and actionable, as it directly instructs the authors to provide a more detailed explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"common pattern,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the need for a more detailed explanation of the term \"common pattern.\" This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the term \"common pattern.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires clarification, namely the term \"common pattern.\" It requests a more detailed explanation of this term, which is a clear and actionable suggestion for the authors to improve the clarity and understanding of their work. By pinpointing this area for improvement, the comment provides the authors with a concrete direction to enhance their draft. However, it could be more helpful if it offered examples or suggestions on how to define or explain the term more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter or Facebook. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should test the model on other datasets, explore its generalizability, or provide additional analysis to address this concern. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter or Facebook. However, it does not specify which part of the paper this concern is related to, such as the experimental setup or results section. The authors can infer that it relates to the discussion on generalizability, but this inference is not direct. The comment is specific in identifying the issue of generalizability to other datasets, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter or Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanation to justify why the model might not generalize to other sources. As a result, the claim is considered unverifiable, as it does not provide sufficient information for the authors to address the concern effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model, noting that all five downstream datasets are related to Reddit. It raises a valid concern about whether the model can effectively generalize to datasets from other sources, such as Twitter or Facebook. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or test the model's generalizability. While it points out an important area for consideration, the feedback could be more helpful with additional insights or recommendations. Therefore, it is rated as somewhat helpful, as it provides some direction but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential limitation in the generalizability of the pre-trained model, noting that all five downstream datasets are related to Reddit. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or test the model\\'s generalizability to other sources like Twitter or Facebook. Without specific guidance or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter or Facebook. However, it does not specify which part of the paper this concern is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the issue of generalizability, it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter or Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanation to justify why the model might not generalize to other sources. As a result, the claim is unverifiable, making it difficult for the authors to address the concern effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model, noting that all five downstream datasets are related to Reddit. It raises a valid concern about whether the model can effectively generalize to datasets from other sources, such as Twitter or Facebook. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or test the model\\'s generalizability. While it points out an important area for consideration, the feedback could be more helpful with actionable advice or examples. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should implement a specific quality check process, how to conduct it, or what criteria to use. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion about dataset quality. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about quality checks but lacks grounding as it does not point to a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim about LLMs hallucinating. The comment lacks specific examples or detailed explanations to help the authors understand the issue or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to understand and address the concern. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential for LLMs to hallucinate, which is a common issue in natural language processing. It asks how the authors ensure the quality of the generated dataset, which is a relevant question for the authors to address. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might improve their dataset quality checks. While it highlights an important issue, it does not offer detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should implement a specific quality check process, how to conduct it, or what criteria to use. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about quality checks but lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim about LLMs hallucinating. The comment lacks specific examples or detailed explanations to help the authors understand the issue or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to understand and address the concern. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential for LLMs to hallucinate, which is a common issue in natural language processing. It asks how the authors ensure the quality of the generated dataset, which is a relevant question for the authors to address. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might improve their dataset quality checks. Without detailed feedback or constructive advice, the authors are left with a general question but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies an important issue but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the meaningfulness of the comparison across the four models, suggesting that the fine-tuned model might perform best due to its training process. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve the comparison. The comment lacks actionable details, such as recommending alternative models, training methods, or specific analyses that could be conducted to make the comparison more meaningful. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the comparison of models, specifically mentioning that only the wav2vec model is fine-tuned while the other three models are trained from scratch. This provides a clear indication of the part of the paper being discussed, making it fully grounded. The comment also specifies the issue, which is the potential lack of meaningful comparison due to the training differences between models. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the meaningfulness of the comparison across four models, suggesting that the fine-tuned model might perform best due to its training process. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or detailed explanations of why the comparison might be misleading or how the authors could address this issue. As a result, the claim is not well-supported, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the meaningfulness of the comparison across four models, specifically noting that only one model (wav2vec) is fine-tuned while the others are trained from scratch. This observation highlights a potential bias in the results, which could affect the interpretation of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of the models. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the meaningfulness of the comparison across four models, noting that only one model (wav2vec) is fine-tuned while the others are trained from scratch. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the comparability of the models. The comment lacks actionable details, such as recommending alternative models, training methods, or specific analyses that could be conducted to make the comparison more meaningful. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the comparison across four models, noting that only one model (wav2vec) is fine-tuned while the others are trained from scratch. This provides a clear indication of the part of the paper being discussed, making it fully grounded. The comment also specifies the issue, which is the potential lack of meaningful comparison due to the training differences between models. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the meaningfulness of the comparison across four models, noting that only one model (wav2vec) is fine-tuned while the others are trained from scratch. This observation highlights a potential bias in the results, as it is easy to guess that the fine-tuned model would perform best. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to similar issues in other studies. Without detailed justification or references, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison across four models, noting that only one model (wav2vec) is fine-tuned while the others are trained from scratch. This observation highlights a potential bias in the results, which could affect the interpretation of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of the models. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and recommends adding more examples, such as Figure 2, to help clarify the content. While the suggestion to include more examples is explicit, it lacks specific guidance on which parts of the paper are particularly dense or how the examples should be integrated. The authors are given a clear action to take\u2014adding more examples\u2014but without detailed instructions on how to implement this suggestion, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and recommends adding more examples, such as Figure 2, to help clarify the content. However, it does not specify which sections of the paper are particularly dense or where additional examples should be included. This lack of explicit reference to specific parts of the paper makes it weakly grounded. The comment is specific in suggesting the inclusion of more examples, but without clear guidance on where these should be added, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is dense, even compared to other pure-math ML papers, and suggests that more examples, such as Figure 2, would help clarify the content. However, the comment lacks specific reasoning or evidence to support why the paper is considered dense or how additional examples would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is well-written but notes that it is dense, even compared to other pure-math ML papers. It suggests that adding more examples, such as Figure 2, would help clarify the content. While the comment identifies a potential issue with the paper\\'s density and provides a specific suggestion for improvement, it lacks detailed guidance on how to address the density or what specific areas need more clarification. The feedback is somewhat helpful as it offers a direction for improvement, but it could be more comprehensive with additional insights or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that section 4.2 starts with high-level intuition, while section 4.1 does not. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors\\' work, such as suggesting that section 4.1 should also include high-level intuition or offering specific ways to enhance the intuition in both sections. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"4.2\" and \"4.1,\" allowing the authors to accurately identify the parts of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not detail what is meant by \"high-level intuition\" or how this intuition could be improved in sections 4.1 and 4.2. Without specific guidance or examples, the authors may struggle to understand what needs to be addressed or improved. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point makes a claim that \"4.2 starts by providing high-level intuition while 4.1 does not.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a discrepancy in the structure of the paper, noting that section 4.2 starts with high-level intuition, while section 4.1 does not. However, it does not provide any further explanation or suggestions on how this discrepancy might affect the paper\\'s clarity or coherence. Without additional context or guidance on how to address this issue, the authors are left with a general observation but no actionable feedback. Therefore, the comment is barely helpful, as it highlights a potential issue but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more discussions could be introduced regarding the permutation matrices shown in Figure 3, specifically mentioning Figure (e)(j)(o). While the comment implies that additional discussion is needed, it does not provide specific guidance on what aspects of the permutation matrices should be discussed or how the authors should expand on this topic. The action is implicit and somewhat vague, as the authors are left to infer the details of what needs to be added. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that more discussions could be introduced regarding the permutation matrices shown in Figure (e)(j)(o). This provides clear guidance on what the authors need to consider or expand upon. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more discussions could be introduced regarding the permutation matrices shown in Figure 3, specifically mentioning Figure (e)(j)(o). However, it does not provide any justification or reasoning for why these discussions are necessary or how they would improve the representation. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more discussions could be introduced regarding the permutation matrices shown in Figure 3, specifically mentioning Figure (e)(j)(o). While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the permutation matrices should be discussed or how they could be better represented. The comment is somewhat helpful as it points out a potential enhancement, but it does not offer actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While the comment highlights an area that requires clarification, it does not provide explicit instructions or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should provide this information, and it is somewhat vague because it lacks concrete guidance on how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the crowd workers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. This is a relevant and important aspect of the study that could impact the validity and reliability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential area for improvement, it lacks actionable feedback or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While it highlights an area that requires clarification, it does not provide explicit instructions or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should provide this information, and it is somewhat vague because it lacks concrete guidance on how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the crowd workers, specifically who they were, how they were recruited, and how they were trained. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the crowd workers used in the study, specifically asking who they were, how they were recruited, and how they were trained. This is an important aspect of the study that could impact the validity and reliability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential area for improvement, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While it highlights an area that requires clarification, it does not provide explicit guidance or suggestions for the authors on how to address this issue. The action is implicit, as the authors need to infer that they should provide this information, and it is somewhat vague because it lacks concrete steps or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It implies that the authors should consider the importance of human evaluations and the potential limitations of automatic metrics. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions, such as conducting additional human evaluations or revising the conclusions. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weakly correlated human evaluations, specifically mentioning the correlation between automatic metrics and human evaluations. It highlights the potential limitations of automatic metrics in capturing the quality of simplifications and suggests that human evaluations are more important. However, the comment does not specify which part of the paper discusses these evaluations, making it weakly grounded. The comment is specific in identifying the issue of weak correlation and the importance of human evaluations, but without explicit references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak correlation between automatic metrics and human evaluations suggests that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it provides a logical reasoning based on the observed correlation, which could indeed question the validity and robustness of the conclusions. However, the comment lacks specific examples or references to support the claim further, such as data or studies showing similar issues with automatic metrics. This makes it challenging for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of the models, specifically the weak correlation between automatic metrics and human evaluations. It suggests that this weak correlation may question the validity and robustness of the conclusions drawn from the automatic metrics. The comment highlights the importance of human evaluations in assessing the quality of the results, which is a valuable insight for the authors. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the evaluation process. While it points out a critical area for consideration, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It implies that the authors should consider the importance of human evaluations and the potential limitations of automatic metrics. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their evaluation process. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weakly correlated human evaluations, specifically mentioning the correlation between automatic metrics and human evaluations. It suggests that the automatic metrics may not fully capture the quality of the simplifications, raising questions about the validity and robustness of the conclusions. However, the comment does not specify which part of the paper discusses these evaluations, making it weakly grounded. The comment is specific in identifying the issue of weak correlation and the importance of human evaluations, but without explicit references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak correlation between automatic metrics and human evaluations suggests that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it provides a logical reasoning based on the observed correlation, which could indeed question the validity and robustness of the conclusions. However, the comment lacks specific examples or references to support the claim further, such as data or studies showing similar issues with automatic metrics. This makes it challenging for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of the models, specifically the weak correlation between automatic metrics and human evaluations. It suggests that the automatic metrics may not fully capture the quality of the simplifications, which could question the validity and robustness of the conclusions. The comment highlights the importance of human evaluations in assessing the quality of the results, which"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific in the \"Chain of Reasoning\" section, particularly regarding line 276. This provides a clear and direct action for the authors to take, as they know exactly what aspect of the section needs to be clarified. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and a specific line number (276), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more detail or specificity in the \"Chain of Reasoning\" section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more specificity in the \"Chain of Reasoning\" section, particularly regarding line 276. However, it does not provide any justification or reasoning for why this section needs to be more specific or what aspects are lacking. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific request for more detail in the \"Chain of Reasoning\" section, particularly regarding line 276. This feedback is actionable as it directs the authors to enhance the clarity and specificity of their reasoning, which is crucial for understanding the paper. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of what constitutes a more detailed chain of reasoning. Despite this, the comment is mostly helpful as it highlights a specific area for improvement and gives the authors a clear direction to enhance their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. It provides a specific example of how these metrics are typically computed, which gives the authors a clear understanding of what is expected. The comment is explicit in its request and provides concrete guidance on how to implement the suggested metric, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ability to perform \"hypothetical inference\" or planning, which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are necessary or how they would improve the analysis. The lack of explicit justification or evidence makes it difficult for the authors to understand the importance of including these metrics. Therefore, the claim is somewhat verifiable, as it provides a general suggestion but lacks detailed support or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a sample quality metric on the CARLA data. It references common metrics like minADE or minMSD, providing a clear direction for the authors to enhance their analysis. However, the comment could be more helpful if it offered additional context or examples on how to implement these metrics or why they are important for the study. Despite this, the feedback is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption of having every constraint and its corresponding discriminator. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern, a request for clarification, or a suggestion for improvement. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the assumption of having every constraint and its corresponding discriminator. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of this assumption is unclear or problematic. Without clear grounding or specific guidance, the authors may struggle to understand and address the issue effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption of having every constraint and its corresponding discriminator. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption of having every constraint and its corresponding discriminator. While it identifies a potential area of confusion or assumption in the paper, it does not provide any specific guidance or suggestions for improvement. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address the issue. As a result, the comment is barely helpful, as it points out a potential weakness but does not offer a constructive path for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss or even include Wasserstein GAN (WGAN) as a baseline method in their work, given that it is the first instance of using Optimal Transport (OT) in GANs. This feedback provides a clear and explicit action for the authors to take, which is to incorporate WGAN into their discussion or as a baseline. The suggestion is concrete, as it specifies the exact method to be added or discussed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing or including Wasserstein GAN (WGAN) as a baseline method, referencing the Wasserstein GAN paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion about methods. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of WGAN as a baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) and the Wasserstein Distance in GANs was first introduced in the Wasserstein GAN paper (WGAN). This claim is supported by a specific reference to the WGAN paper, which provides a clear and verifiable source for the authors to consider. The suggestion to discuss or include WGAN as a baseline method is also based on a well-established practice in the field. The inclusion of a specific reference and the logical reasoning behind the suggestion make the claim fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the discussion or inclusion of Wasserstein GAN (WGAN) as a baseline method. It references the original paper where this approach was first introduced, providing a clear rationale for why this addition would be beneficial. This feedback is clear and constructive, offering the authors a concrete step to enhance their work by situating their approach within the existing literature. However, the comment could be more helpful if it included additional context or guidance on how to integrate WGAN into the discussion or experiments. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors discuss or include Wasserstein GAN (WGAN) as a baseline method, given that it is the first instance of using Optimal Transport (OT) in GANs. This feedback provides a clear and explicit action for the authors to take, which is to incorporate WGAN into their discussion or as a baseline method. The suggestion is concrete, as it specifies the exact method to be added or discussed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing or including Wasserstein GAN (WGAN) as a baseline method, referencing the Wasserstein GAN paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion about methods. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to pinpoint the exact area needing attention. The suggestion is specific, as it clearly identifies WGAN as a relevant baseline, but the lack of grounding makes it less actionable. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) and the Wasserstein Distance in GANs was first introduced in the Wasserstein GAN paper (WGAN). This claim is supported by a specific reference to the WGAN paper, which provides a clear and verifiable source for the authors to consider. The suggestion to discuss or include WGAN as a baseline method is also based on a well-established practice in the field. The inclusion of a specific reference and the logical reasoning behind the suggestion make the claim fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion by recommending that the authors discuss or include Wasserstein GAN (WGAN) as a baseline method. It references the original paper where this approach was first introduced, which is a clear and verifiable source for the authors to consider. This feedback is beneficial as it directs the authors to sit"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights the absence of important related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It recommends discussing these methods and provides specific references to relevant papers. Additionally, the comment suggests that the paper's preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. While the comment provides explicit actions\u2014discussing related work and considering a workshop submission\u2014it lacks concrete guidance on how to address the issues with clarity and organization. The authors are given a clear direction on what to include but may need to infer how to improve the clarity and organization themselves. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the absence of related work on MCMC in discrete spaces and provides specific references to relevant papers, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of related work and the potential suitability of the paper for a workshop. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that important related work on MCMC in discrete spaces is absent and suggests that several methods have applied Langevin MCMC to sample discrete sequences. The reviewer supports this claim by referencing specific papers (Zhang et al. and Sun et al.) that discuss these methods. This provides a clear and specific reference to the missing related work, making the claim mostly verifiable. However, the comment could be further strengthened by providing more detailed analysis or examples of how these references relate to the paper's content. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's literature review by pointing out the absence of important related work on MCMC in discrete spaces. It suggests that several methods have applied Langevin MCMC to sample discrete sequences, which should be discussed. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by including relevant literature. Additionally, the comment acknowledges the paper's preliminary results and issues with clarity and organization, suggesting that it may be more suitable for a workshop. This provides a nuanced assessment of the paper's readiness for a conference publication. The inclusion of specific references further enhances the helpfulness of the comment. Overall, the feedback is mostly helpful as it offers clear guidance on how to improve the paper's content and presentation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, if there are specific aspects that should be clarified, or if it is merely a curiosity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. Additionally, the comment lacks specificity regarding what aspects of the methods are unclear or how they differ between DS-FedDRO and FedDRO. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$, suggesting that they employ different approaches. However, it does not provide any context, explanation, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance for the authors to enhance their draft. Without specific insights or recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a discussion about the difference between (6) in Nicekl Kiela and l. However, it does not provide any explicit guidance on what aspects of the difference should be discussed or how the authors should approach this discussion. The comment lacks specificity and does not offer concrete steps for the authors to follow, leaving them uncertain about how to address the feedback. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to a specific equation, \"(6) in Nicekl Kiela and l,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide details on what aspect of the difference between (6) and l should be discussed or how it impacts the paper. Without additional context or guidance, the authors may struggle to understand what needs to be addressed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that there should be a discussion about the difference between (6) in Nicekl Kiela and l. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be a discussion about the difference between (6) in Nicekl Kiela and l. However, it lacks specificity and does not provide any context or explanation about why this discussion is necessary or how it would benefit the paper. Without additional details or guidance, the authors are left without a clear understanding of what needs to be addressed or improved. As a result, the comment is not helpful in guiding the authors toward meaningful improvements in their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments were not conducted multiple times and highlights the absence of variance analysis for the results. While it identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting how many times the experiments should be repeated or what specific variance analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to conduct multiple experiments and analyze variance, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of variance analysis in the experiments and the absence of multiple runs. However, it does not specify which part of the paper discusses the experiments or where the variance analysis should be included, making it weakly grounded. The comment is specific in identifying the need for variance analysis and the lack of multiple runs, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is valuable as it highlights a potential weakness in the study that could affect the reliability and robustness of the findings. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending the number of runs or the type of variance analysis that should be conducted. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experiments were not conducted multiple times and highlights the absence of variance analysis for the results. While it identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting the number of runs or the type of variance analysis that should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to conduct multiple experiments and analyze variance, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the experiments, noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not specify which part of the paper discusses the experiments or where the variance analysis should be included, making it weakly grounded. The comment is specific in identifying the need for variance analysis and the absence of multiple runs, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is valuable as it highlights a potential weakness in the study that could affect the reliability and robustness of the findings. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending the number of runs or the type of variance analysis that should be conducted. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the experiments, noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. While it highlights a potential weakness in the"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, it does not provide explicit guidance or suggestions on how the authors should address these gaps or incorporate them into their experiments. The comment implies that the authors should consider these factors, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, it does not specify which part of the paper discusses these gaps, making it weakly grounded. The comment is specific in identifying the issue of gaps between AL experiments and real-world datasets, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, the comment does not provide specific examples or references to support the claim that these factors are not accounted for in the experiments. The lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support or evidence to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap between the experiments conducted in the paper and real-world datasets, specifically highlighting the lack of consideration for factors like differing dataset qualities and temporal drifts in data distributions. This is a crucial point that the authors need to address to ensure the relevance and applicability of their findings. However, the comment does not provide specific suggestions or guidance on how to incorporate these factors into the experiments or analysis. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, it does not provide explicit guidance or suggestions on how the authors should address these gaps or incorporate them into their experiments. The comment implies that the authors should consider these factors, but it lacks concrete instructions or examples, making the action implicit and vague. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, it does not specify which part of the paper discusses these gaps, making it weakly grounded. The comment is specific in identifying the issue of gaps between AL experiments and real-world datasets, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. However, the comment does not provide specific examples or references to support the claim that these factors are not accounted for in the experiments. The lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support or evidence to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. This is a crucial point that the authors need to address to ensure the relevance and applicability of their findings. However, the comment does not provide specific suggestions or guidance on how the authors might incorporate these factors into their experiments or analysis. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a gap between the experiments conducted in the paper and real-world datasets, specifically"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper, O(SAH^2) or O(MSAH^2), does not seem particularly low or noteworthy compared to other federated Q-learning algorithms that have demonstrated O(H) communication rounds. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue, such as suggesting ways to improve the communication cost or comparing it to other algorithms. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this information is located in, making it weakly grounded. The comment also lacks specificity as it does not detail why the communication cost is considered unremarkable or how it compares to other federated Q-learning algorithms. Without clear references or detailed feedback, the authors may struggle to understand what needs to be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper, O(SAH^2) or O(MSAH^2), is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds. The reviewer supports this claim by referencing other algorithms that have achieved lower communication costs. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the other algorithms mentioned, which would make the claim fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the communication cost presented in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Q-learning algorithms. It references other algorithms that have demonstrated lower communication costs, which provides a basis for the critique. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their communication cost analysis. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper, O(SAH^2) or O(MSAH^2), is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds. However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this information is located in, making it weakly grounded. The comment also lacks specificity as it does not provide detailed reasoning or suggestions for improvement. Without clear references or detailed feedback, the authors may struggle to understand what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper, O(SAH^2) or O(MSAH^2), is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds. The reviewer supports this claim by referencing other algorithms that have achieved lower communication costs. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the other algorithms mentioned, which would make the claim fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the communication cost presented in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Q-learning algorithms. It references other algorithms that have demonstrated lower communication costs, which provides a basis for the critique. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their communication cost analysis. Without actionable advice or"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve their work. There is no guidance on potential adaptations, alternative approaches, or specific changes that could be made to enhance the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the main idea of using an ensemble of neural networks and its commonality in machine learning literature. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the paper lacks specific adaptation to the homomorphic encryption domain. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is \"trivial and very common in machine learning literature\" and that the paper lacks specific adaptation to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. While it identifies a potential weakness in the paper, it does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their work. Without specific feedback or recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a concern but does not offer sufficient support or direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or analyses, but it does not specify what kind of information or analysis is needed. As a result, the action is implicit and vague, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a new model for detecting overlapping entities in text and improves upon the previous state-of-the-art, MH, in experiments on benchmark datasets. However, it states that it is not clear why and how the new model works better. This claim is somewhat verifiable as it highlights a gap in the explanation of the model\\'s effectiveness, but it lacks specific examples, detailed reasoning, or references to support the assertion that the new model is indeed better. The authors would need to further explore and clarify the reasoning themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical area of weakness in the paper, specifically the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. This is an important point that the authors need to address to strengthen their argument and provide a more comprehensive understanding of their model's improvements. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or comparisons. While it highlights a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or analyses, but it lacks specific instructions or examples. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a new model for detecting overlapping entities in text and improves upon the previous state-of-the-art, MH, in experiments on benchmark datasets. However, it states that it is not clear why and how the new model works better. While the comment highlights a gap in the explanation, it does not provide specific reasoning, examples, or references to support the claim that the new model is indeed better. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further explore and clarify the reasoning themselves. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical area of weakness in the paper, specifically the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. This is an important point that the authors need to address to strengthen their argument and provide a more comprehensive understanding of their model's improvements. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or comparisons. While it highlights a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a lack of clarity regarding why and how the"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the reasonableness of the formula used in the Adjective Projection part, suggesting an alternative method for estimating whether an object is large or small. It provides a specific suggestion to calculate the difference between the similarity of the object with \"large\" and \"small\" embeddings, rather than using the similarity with the difference between the embeddings. This feedback is explicit and provides a concrete action for the authors to consider, making it highly actionable. The authors know exactly what needs to be changed and how to implement the suggested approach.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the specific section being addressed. It is also specific because it provides a detailed critique of the formula used, suggesting an alternative method for estimating whether an object is large or small. The comment clearly specifies what needs to be addressed, offering a concrete suggestion for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasonableness of a formula used in the Adjective Projection part, suggesting an alternative method for estimating whether an object is large or small. The reviewer provides a logical reasoning by explaining that the current approach involves calculating the difference between the similarity of the object with \"large\" and \"small\" embeddings, rather than using the similarity with the difference between the embeddings. This explanation offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the alternative method, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the formula used in the Adjective Projection part, suggesting that the current approach may not be the most reasonable way to estimate whether an object is large or small. It provides a specific alternative method, which involves calculating the difference between the similarity of the object with 'large' and 'small' embeddings, rather than using the similarity with the difference between the embeddings. This feedback is clear and actionable, offering the authors a concrete suggestion for improving the logical basis of their method. By addressing this point, the authors could enhance the clarity and effectiveness of their approach. Therefore, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a potential issue with the formula used in the Adjective Projection part and suggests an alternative method for estimating whether an object is large or small. It provides a clear and specific suggestion to calculate the difference between the similarity of the object with \"large\" and \"small\" embeddings, rather than using the similarity with the difference between the embeddings. This feedback is explicit and offers concrete guidance on how to improve the draft, making it highly actionable. The authors know exactly what changes to make to enhance the logical basis of their approach.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the specific section being addressed. It is also specific because it provides a detailed critique of the formula used, suggesting an alternative method for estimating whether an object is large or small. The reviewer explains the current approach and proposes a different calculation method, offering clear guidance on how to improve the draft. This level of detail and clarity makes the comment fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasonableness of the formula used in the Adjective Projection part and suggests an alternative method for estimating whether an object is large or small. The reviewer provides a logical reasoning by explaining that the current approach involves calculating the difference between the similarity of the object with \"large\" and \"small\" embeddings, rather than using the similarity with the difference between the embeddings. This explanation offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the alternative method, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the formula used in the Adjective Projection part, suggesting that the current approach may not be the most reasonable way to estimate whether an object is large or small. It provides a specific alternative method, which involves calculating the difference between the similarity of the object with 'large' and 'small' embeddings, rather than using the similarity with the difference between the embeddings"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of the equation \\\\sigma_k = sigmoid(\\\\sigma_k) in line 121, noting that \\\\sigma_k appears on both sides. This suggests that the authors should clarify this equation. Additionally, the reviewer expresses interest in the proposed method\\'s ability to capture long-range context information and suggests that elaborating on the issues mentioned would be more informative. While the comment implies that the authors should clarify the equation and provide more information, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of the equation \\\\sigma_k = sigmoid(\\\\sigma_k) and suggesting that the authors elaborate on the issues mentioned. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual statement and a request for clarification regarding the meaning of an equation. It also expresses interest in the proposed method\\'s ability to capture long-range context information and suggests that elaboration on certain issues would be more informative. The comment does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text, questioning the meaning of the equation \\\\sigma_k = sigmoid(\\\\sigma_k) in line 121. This is a direct and actionable piece of feedback that prompts the authors to clarify the equation, which is crucial for understanding the methodology. Additionally, the comment expresses interest in the proposed method\\'s ability to capture long-range context information and suggests that elaborating on the issues mentioned would be more informative. While the comment provides valuable insights, it could be more helpful if it offered specific suggestions on how to elaborate on the issues or provided examples of what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and suggests a way to enhance the paper\\'s informative value.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works that specifically address any-resolution image generation. It provides specific references, [1] and [2], which are recent works in the field. This feedback is explicit and provides concrete guidance on how to improve the draft by including relevant comparisons. The authors know exactly what additional information to include and where to find it, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing and comparing the work to more recent works that specifically address any-resolution image generation, providing specific references. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as the related work section or the methodology section. The authors can infer that it relates to the discussion of the claim regarding any-resolution generation, but this inference is not direct. The comment is specific in suggesting comparisons to recent works, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should discuss and compare its work to more recent works on any-resolution image generation, providing specific references. This claim is somewhat verifiable as it references recent works in the field, which could provide a basis for comparison. However, the comment lacks detailed reasoning or analysis on why these specific works are relevant or how they would enhance the discussion. The authors would need to further explore these references to fully understand the suggestion, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improvement by recommending that the authors discuss and compare their work to more recent works that specifically address any-resolution image generation. It offers specific references, [1] and [2], which are recent works in the field. This feedback is valuable as it guides the authors to situate their work within the context of current research, potentially enhancing the paper's relevance and impact. However, the comment could be more helpful if it included additional guidance on how to effectively integrate these comparisons into the paper. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the potential for overfitting in the CT experiment due to the use of only one subject in the test set. It also suggests that Section 6 does not sufficiently describe the limitations of the work and recommends that the authors discuss limitations such as theoretical assumptions and implementation considerations. Additionally, it asks for a discussion on the relative improvement of ODER over RED alternatives and how training time might compare. While the comment provides explicit actions for the authors to take, such as discussing limitations and providing comparisons, it lacks concrete guidance on how to address these issues. The authors are given clear directions but may need to determine the specific details themselves. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"84: 1763\u2013 1780\" and \"https://doi.org/10.1002/mrm.28235,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue of overfitting due to the use of only one subject in the test set and suggests that Section 6 does not sufficiently describe the limitations of the work. The comment further provides specific areas for improvement, such as discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED alternatives. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the potential for overfitting in the CT experiment due to the use of only one subject in the test set. It also suggests that Section 6 does not sufficiently describe the limitations of the work. The reviewer provides specific examples, such as discussing theoretical assumptions and implementation considerations, and questions the relative improvement of ODER over RED alternatives. While the comment identifies areas for improvement, it lacks detailed evidence or references to support the claim of overfitting or the need for more comprehensive limitations discussion. The suggestion for discussing theoretical assumptions and implementation considerations is logical, but the comment could be strengthened with more explicit examples or references. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires additional detail to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with overfitting in the CT experiment due to the use of only one subject in the test set. It also points out that Section 6 does not sufficiently describe the limitations of the work, suggesting that the authors discuss theoretical assumptions, implementation considerations, and other relevant limitations. Additionally, the comment raises a question about the relative improvement of ODER over RED alternatives and how training time might compare. This feedback is clear and actionable, providing the authors with specific areas to address and questions to consider, which can help them improve the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered more detailed guidance on how to address these issues. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific error in the text, pointing out that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This feedback is explicit and provides a clear correction, allowing the authors to easily identify and address the error in their draft. The comment is highly actionable as it gives precise guidance on what needs to be changed, ensuring the authors know exactly how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line numbers \"216 and 217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the bound on the 2-Wasserstein, pointing out that it is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual correction regarding the statement about the bound on the 2-Wasserstein, which is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This is a straightforward observation and does not involve subjective claims or opinions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the text, pointing out that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This feedback is clear and actionable, as it allows the authors to correct a factual error in their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided additional context or explanation about the importance of this correction or its implications for the overall argument. Despite this, the comment is mostly helpful as it directs the authors to a specific area needing correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It also references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not provide explicit instructions or concrete steps on how to address this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison and possibly discuss the differences in their paper. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not specify which part of the paper should include this comparison or where these references should be integrated. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its request for a comparison but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not provide specific details or examples from the referenced works to support the claim or guide the authors on how to address the question. The lack of detailed justification or references makes it challenging for the authors to fully understand and respond to the critique. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to be fully actionable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a pertinent question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. This feedback is somewhat helpful as it prompts the authors to clarify the unique contributions of their method and differentiate it from related work. However, the comment could be more helpful if it provided specific guidance on how to highlight these differences or suggested ways to address the comparison. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not provide explicit instructions or concrete steps on how the authors should conduct this comparison or what specific aspects should be highlighted. The action is implicit and lacks detailed guidance, making it somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not specify which part of the paper should include this comparison or where these references should be integrated. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its request for a comparison but lacks grounding, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. However, the comment does not provide specific details or examples from the referenced works to support the claim or guide the authors on how to address the question. The lack of detailed justification or references makes it challenging for the authors to fully understand and respond to the critique. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a pertinent question about the differences between the proposed multi-scale hierarchical predictor and other methods like IEConv and CDConv. It references several external works, suggesting that the authors compare their method with these existing approaches. This feedback is somewhat helpful as it prompts the authors to clarify the unique contributions of their method and differentiate it from related work. However, the comment lacks specific guidance or suggestions on how the authors should conduct this comparison or what specific"}
{"generated_text": "{'actionability_rationale': 'The comment states that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide specific guidance on what aspects of the writing are problematic or how the authors can improve the readability. The feedback lacks explicit instructions or concrete details, leaving the authors uncertain about how to address the issue. As a result, the comment is vague and unactionable, making it difficult for the authors to know what specific changes to make to improve the readability of their paper.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment broadly states that the paper does not read well and suggests that more careful proofreading is needed. However, it does not specify which parts of the paper are problematic or provide any details on what aspects of the writing are unclear or poorly executed. Without specific references or examples, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper \"in general does not read well\" and suggests that more careful proofreading is needed. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear or poorly executed, the authors may find it challenging to address the issue effectively. As a result, the claim is considered unverifiable due to the absence of supporting information, making it difficult for the authors to understand and improve the draft. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the paper does not read well and suggests that more careful proofreading is needed. However, it lacks specificity and does not provide any guidance on which parts of the paper are problematic or how the authors might improve the readability. Without actionable feedback or detailed suggestions, the authors are left without a clear path to address the issue. This limits the usefulness of the comment, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests several areas for improvement, including an analysis of the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, the value and selection of the trade-off parameter (Theta), and a comparison of a baseline using attention from the previous question instead of soft attention. While the comment provides specific areas for analysis, it does not offer explicit instructions on how to conduct these analyses or what specific results should be expected. The actions are implicit and somewhat vague, as the authors need to infer the details of the analysis and the criteria for comparison. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as analyzing the distribution of addressing coefficients with and without bias towards sequential addressing, the value and selection of the trade-off parameter, and comparing a baseline using attention from the previous question. This provides clear guidance on what aspects of the paper need further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing is crucial for understanding the synthetic task. It also questions the value and selection of the trade-off parameter (Theta) and proposes a comparison with a baseline using attention from the previous question. While the comment identifies important areas for further analysis, it lacks specific examples or references to support the claim about the importance of these factors. The suggestion for a baseline comparison is also not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or evidence to be fully actionable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several actionable suggestions for improvement. It highlights the importance of analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, which is crucial for understanding the synthetic task. Additionally, it points out the lack of information about the trade-off parameter (Theta) and its selection, suggesting that this information is essential for a comprehensive analysis. The comment also questions the use of a soft attention mechanism and proposes a comparison with a baseline using attention from the previous question. These suggestions are clear and provide specific areas for the authors to explore, making the feedback mostly helpful. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these analyses or what specific insights to look for. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer also expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as removing the proposition or revising it to better align with the paper\\'s focus. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the necessity of Proposition 1, which is a standard regression problem. It questions the need for the mathematical presentation and suggests that it does not contribute to making NC a complexity measure in statistical learning sense. However, the comment does not explicitly mention which part of the paper this proposition is located in, making it weakly grounded. The comment is specific in its critique of the mathematical presentation and its relevance to the paper\\'s focus, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer also expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. However, the comment lacks specific examples or references to support the claim that the mathematical presentation is unnecessary or unhelpful. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. While the comment identifies a potential issue with the paper\\'s presentation, it lacks specific suggestions or guidance on how the authors might address this concern or improve the clarity of their work. The feedback is somewhat helpful as it prompts the authors to reconsider the inclusion of certain mathematical elements, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as removing the proposition or revising it to better align with the paper\\'s focus. The feedback lacks actionable steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. It also expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. However, the comment does not specify which part of the paper this proposition is located in, making it weakly grounded. The comment is specific in its critique of the mathematical presentation and its relevance to the paper\\'s focus, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. However, the comment lacks specific reasoning or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains somewhat vague, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer expresses a personal opinion that the mathematical decoration is unnecessary and does not contribute to making NC a complexity measure in statistical learning sense. While the comment identifies a potential issue"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of defense techniques, specifically mentioning that there are several defenses relying on input perturbation in backdooring classification. It suggests that evaluating these defenses on the proposed method is essential for a comprehensive understanding of the attacks. The reviewer provides references to relevant works, \"Doan et al. Lira: Learnable, imperceptible and robust backdoor attacks. ICCV 2021\" and \"Doan et al. Backdoor attack with imperceptible input and latent modification. NeurIPS 2021,\" which gives the authors a clear direction on what specific defenses to consider. The explicit mention of the defenses and the references provide concrete guidance on how to address the issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a limitation in the evaluation of defense techniques, specifically mentioning that there are several defenses relying on input perturbation in backdooring classification. It suggests that evaluating these defenses on the proposed method is essential for a comprehensive understanding of the attacks. The comment provides specific references to relevant works, which helps the authors identify the areas needing further evaluation. However, it does not explicitly mention which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the evaluation of defense techniques. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of defense techniques is limited, particularly in the context of backdooring classification. The reviewer supports this claim by referencing specific works, \"Doan et al. Lira: Learnable, imperceptible and robust backdoor attacks. ICCV 2021\" and \"Doan et al. Backdoor attack with imperceptible input and latent modification. NeurIPS 2021,\" which provide examples of defenses relying on input perturbation. This reference to external works offers a clear and specific basis for the claim, making it fully verifiable. The inclusion of relevant references provides the authors with a concrete understanding of the defenses to consider, thus justifying the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that evaluating the proposed method against known defenses, such as those relying on input perturbation, is essential for a comprehensive understanding of the attacks. The comment provides specific references to relevant works, which can guide the authors in expanding their evaluation. This feedback is clear and actionable, offering a concrete direction for improving the draft by addressing a significant gap in the evaluation section. However, it could be more helpful if it included specific suggestions on how to incorporate these defenses or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also mentions that the context and evidence-based methods are presented shallowly. While the comment provides explicit actions for the authors to take, it lacks concrete details on how to achieve these improvements. The authors are given a clear direction to enhance the related work section, but without specific guidance on what aspects to focus on or how to present the context and evidence-based methods more deeply, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the related work section, specifically mentioning the need for a more focused section that includes descriptions of similar datasets for non-English or underrepresented languages. It also notes that the context and evidence-based methods are presented shallowly. However, the comment does not specify which part of the related work section is being addressed, making it weakly grounded. The comment is specific in its suggestions for improvement, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could be more focused and includes a specific suggestion to describe similar datasets for non-English or underrepresented languages. Additionally, it critiques the presentation of context and evidence-based methods as shallow. While the comment provides a general direction for improvement, it lacks specific examples or references to support the claim that the related work section is too broad or shallow. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the related work section, suggesting that it should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. Additionally, it points out that the context and evidence-based methods are presented shallowly, offering a clear direction for improvement. While the comment identifies areas for enhancement, it could be more helpful by providing examples of relevant datasets or methods that could be included. Overall, the feedback is mostly helpful as it guides the authors on how to improve the related work section, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations. It highlights a discrepancy between the experimental results (Table 2) and the authors\\' claim about the folding of BN after ReLU. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their argument. The feedback lacks actionable details, such as recommending specific changes or additional experiments to support the claim. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' argument about folding Batch Normalization (BN) into convolution (Conv) operations, particularly regarding the folding of BN after ReLU. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations, specifically addressing the claim that BN after ReLU can be folded into the next Conv op. The comment highlights a discrepancy between the experimental results (Table 2) and the authors\\' claim, suggesting that the authors\\' argument may not be fully supported by the data. However, the comment does not provide specific examples or references to substantiate the claim or challenge the authors\\' reasoning. This makes the comment somewhat verifiable, as it raises a valid concern but lacks detailed evidence or references to fully support the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations. It points out a discrepancy between the experimental results (Table 2) and the authors\\' claim, questioning whether BN after ReLU can be folded into the next Conv op as suggested. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this discrepancy or clarify their argument. The feedback provides some insight into a potential weakness in the paper but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations, specifically questioning the claim that BN after ReLU can be folded into the next Conv op. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their argument. Without specific recommendations or actionable steps, the authors are left without a clear understanding of what changes or clarifications are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations, particularly regarding the folding of BN after ReLU. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations, specifically addressing the claim that BN after ReLU can be folded into the next Conv op. The comment highlights a discrepancy between the experimental results (Table 2) and the authors\\' claim, suggesting that the authors\\' argument may not be fully supported by the data. However, the comment does not provide specific examples or references to substantiate the critique or challenge the authors\\' reasoning. This lack of detailed evidence or justification makes the claim somewhat verifiable, as it raises a valid concern but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution (Conv) operations, specifically questioning the claim that BN after ReLU can be folded into the next Conv op. It highlights a discrepancy between the experimental"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments with larger networks to demonstrate a trend in the results from the small-scale experiments. This feedback provides a clear and direct action for the authors to take, specifying that they should include experiments with varying network sizes. The suggestion is concrete, as it outlines exactly what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and provides specific examples of the models used in the experiments, such as the \"80 hidden neurons for the MNIST experiments\" and \"a single convolutional layer with 40 channels for the SVHN experiments.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for experiments with larger networks to demonstrate a trend in the results. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are lacking in scale, specifically mentioning the small size of the networks used (80 hidden neurons for MNIST and a single convolutional layer with 40 channels for SVHN). The reviewer suggests that larger-scale experiments would be beneficial to demonstrate a trend in the results. While the comment provides a logical reasoning for the need for larger-scale experiments, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental setup, noting that the models used in the experiments are relatively small. It suggests that including experiments with larger networks would help demonstrate a trend in the results, indicating whether the findings from the small-scale experiments would generalize to larger-scale experiments. This feedback is clear and actionable, providing the authors with a concrete direction for expanding their experiments to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered specific guidance on how to design these larger-scale experiments or suggested potential outcomes to look for. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the problem when the matrix W is the identity matrix. It suggests that the results should be compared with prior work in the spherical case. However, it does not provide explicit instructions or guidance on how the authors should address this question or what specific comparisons should be made. The action is implicit and vague, as the authors need to infer that they should explore and compare their results with prior work in the spherical case. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of the problem when the matrix W is the identity matrix and suggests comparing the results with prior work in the spherical case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the comparison with prior work, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the behavior of the problem when the matrix W is the identity matrix. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the behavior of the problem when the matrix W is the identity matrix. It suggests that the results should be compared with prior work in the spherical case. While this question highlights a potential area for further exploration and comparison, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the comparison would be most relevant. The comment provides some insight into a potential weakness or area for improvement but does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a potential area for exploration but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be explored to broaden the application scope. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the work by pointing out that it primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment does provide some specificity by identifying the scope of the work as a limitation, but it lacks detailed guidance on how the authors might address this issue or expand their work to include general MILP or QUBO problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how it could be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This feedback highlights a potential area for improvement, as it suggests that the authors could broaden the applicability of their work by considering more general problem types. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their work to include general MILP or QUBO problems. While it points out an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment does provide some specificity by identifying the scope of the work as a limitation, but it lacks detailed guidance on how the authors might address this issue or expand their work to include general MILP or QUBO problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how it could be addressed. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This feedback highlights a potential area for improvement, as it suggests that the authors could broaden the applicability of their work by considering more general problem types. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their work to include general MILP or QUBO problems. While it points out an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points"}
{"generated_text": "{'actionability_rationale': \"The review point highlights that learning both low- and high-frequency information in balance is not novel and mentions several related works that have been previously explored. It suggests that the authors should analyze or compare their work to these related works. However, the comment does not provide specific guidance on how to conduct this analysis or comparison, leaving the authors with a general idea of what needs to be done but without concrete steps on how to implement it. The action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the novelty of learning both low- and high-frequency information in balance, suggesting that this approach is not novel and has been explored in previous works. It provides specific references to related works, such as [1] Stochastic Frequency Masking, [2] FSDR, [3] Spectrum Random Masking, and [4] MASKED FREQUENCY MODELING, which the authors should analyze or compare their work to. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed by comparing the work to these related studies. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that learning both low- and high-frequency information in balance is not novel and references several related works to support this claim. The comment provides specific references to external works, such as [1] Stochastic Frequency Masking, [2] FSDR, [3] Spectrum Random Masking, and [4] MASKED FREQUENCY MODELING, which the authors should analyze or compare their work to. This detailed reference to existing literature provides a robust foundation for the claim, making it fully verifiable. The authors can use these references to understand the context and relevance of their work, allowing them to address the critique effectively. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper's approach to learning both low- and high-frequency information in balance. It points out that this concept is not new and references several related works that have been previously explored. The comment provides specific examples of these related works, which the authors can analyze or compare their work to. This feedback is clear and actionable, as it directs the authors to consider the existing literature and potentially differentiate their work from these related studies. However, the comment could be more helpful if it offered suggestions on how to address the lack of novelty or how to position their work within the context of these related works. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks depth in its guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any additional guidance or explanation on how to conduct this comparison or what specific aspects should be considered. The action is implicit, as the authors need to infer that they should include a comparison of compression bandwidths, but it is vague because it lacks concrete details on how to implement this comparison. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, the comment lacks specificity as it does not detail what needs to be addressed or improved in Section 5 regarding the comparison of compression bandwidths. Without specific guidance or examples, the authors may struggle to understand what exactly is being recommended or how to implement the suggested comparison. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or reasoning on why this comparison is important or how it could enhance the paper. Without further elaboration or actionable advice, the authors may find it challenging to determine the exact steps needed to address this suggestion. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not offer sufficient detail to be fully actionable.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. This feedback provides a clear and explicit action for the authors to take, which is to change the model names to more descriptive ones. The suggestion is concrete, as it specifies the new names that could be used, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the model names T5-ind and T5-seq, suggesting that they are misleading and proposing alternative names like Desc-ind/seq, Eg-ind, and Demo-ind/seq. This provides a clear suggestion for improvement, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses these model names, leaving the authors to infer that it might be related to the methodology or results sections. While the authors can infer the relevant part, the comment could be more grounded if it explicitly pointed to the sections or figures where these names are used. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names like Desc-ind/seq, Eg-ind, and Demo-ind/seq. However, the comment does not provide any justification or reasoning for why the current names are misleading or how the proposed names would be more appropriate. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model names T5-ind and T5-seq, suggesting that they are misleading. It provides a constructive suggestion by proposing alternative names like Desc-ind/seq, Eg-ind, and Demo-ind/seq. This feedback is clear and actionable, as it directly addresses a potential confusion in the paper and offers a concrete solution to improve clarity. By implementing these suggestions, the authors can enhance the readability and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of acronym \"AR\" for \"artificial intelligence\" and notes that it is used again in line 055. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a mistake, a preference, or a standard practice that needs to be addressed. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"AR\" and its usage in line 055, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of acronym and its repetition, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the use of an acronym, \"AR,\" for \"artificial intelligence\" and its repetition in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a specific issue with the use of an acronym, \"AR,\" for \"artificial intelligence\" and its repetition in the paper. While it identifies a potential inconsistency or confusion, it does not provide any guidance or suggestions on how to address this issue or why it might be problematic. The comment lacks depth and actionable advice, making it difficult for the authors to understand the significance of this observation or how to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the motivation for the gating design in multi-task learning (MTL) is unclear and notes that the gating mechanism is not a novel concept. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve the clarity of their motivation. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. However, the comment does not specify which part of the paper discusses the gating mechanism or the motivation for it, making it weakly grounded. The comment is specific in pointing out the lack of clarity in the motivation and the novelty of the gating mechanism. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of clarity in the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. This feedback highlights a critical area for improvement, as understanding the motivation and novelty of the approach is essential for the paper's contribution. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or differentiate their work from existing approaches. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the motivation behind the gating design for multi-task learning (MTL) is unclear and notes that the gating mechanism is not a novel concept. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve the clarity of their motivation. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. However, the comment does not specify which part of the paper discusses the gating mechanism or the motivation for it, making it weakly grounded. The comment is specific in pointing out the lack of clarity in the motivation and the novelty of the gating mechanism, but without explicit references to sections or details, it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of clarity in the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a novel concept. This feedback highlights an important area for improvement, as understanding the motivation and novelty of the approach is crucial for the paper's contribution. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or differentiate their work from existing approaches. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) during training. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the practicality of their approach. There is no guidance on potential modifications, alternative assumptions, or additional experiments that could be conducted to mitigate the limitations. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical scenarios in which learning to defer is preferable and details how it is expected to behave. However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment does provide some specificity by highlighting the limitations imposed by strong assumptions, such as the availability of ground truth and DM decisions. However, it lacks detailed guidance on how to address these limitations or improve the practicality of the approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that these assumptions are overly restrictive. The reasoning is somewhat verifiable, as it identifies a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). While the comment highlights a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or mitigate the impact of these assumptions. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the practicality of their approach. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment does provide some specificity by highlighting the limitations imposed by these assumptions, but it lacks detailed guidance or suggestions for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that these assumptions are overly restrictive. The reasoning is somewhat verifiable, as it identifies a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM). While the comment highlights a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the practicality of their approach. Without actionable feedback or detailed insights, the comment provides only a general critique without offering a clear path for improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the experimental part is less convincing due to the use of weak baselines like LR and SVM compared to deep learning approaches. However, it does not provide specific guidance on how to improve the experimental setup or suggest alternative baselines that could be used. The feedback lacks explicit instructions or concrete details on how to strengthen the experimental part, leaving the authors uncertain about what steps to take to address the issue. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experimental part of the paper, specifically mentioning the use of LR and SVM as weak baselines compared to deep learning approaches. However, it does not specify which part of the experimental section this critique pertains to, such as specific experiments or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in its critique of the baselines used, it is weakly grounded because it does not direct the authors to the exact parts of the paper being addressed. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the use of weak baselines like LR and SVM compared to deep learning approaches. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these baselines are considered weak. Without detailed justification or evidence, the claim remains unverifiable, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental part of the paper, noting that the baselines used (LR and SVM) are considered weak compared to deep learning approaches. This feedback highlights a potential weakness in the experimental setup that could impact the credibility of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might strengthen their experimental design or choose more appropriate baselines. Without actionable advice, the authors are left with a general understanding of the issue but no clear path to address it. Therefore, the comment is somewhat helpful, as it points out a problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the experimental part of the paper, noting that the baselines used (LR and SVM) are considered weak compared to deep learning approaches. However, it does not provide specific guidance or suggestions on how the authors might improve their experimental setup or choose more appropriate baselines. The feedback lacks explicit instructions or concrete details, leaving the authors uncertain about how to address the issue. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experimental part of the paper, specifically mentioning the use of LR and SVM as weak baselines compared to deep learning approaches. However, it does not specify which part of the experimental section this critique pertains to, nor does it provide details on how the baselines are considered weak or how they could be improved. This lack of explicit reference and detailed guidance makes it difficult for the authors to identify and address the issue effectively. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the use of weak baselines like LR and SVM compared to deep learning approaches. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these baselines are considered weak. Without detailed justification or evidence, the claim remains unverifiable, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental part of the paper, noting that the baselines used (LR and SVM) are considered weak compared to deep learning approaches. This feedback highlights an area where the authors might need to strengthen their experimental setup to ensure the credibility of their results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the baselines or choose more appropriate ones. Without detailed advice, the authors are left with a general understanding of the issue but no clear path to address it. Therefore, the comment is somewhat helpful, as it points out a problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}{'actionability_r"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of discussion on the communication cost in both the theorem and the experiment, which is crucial to the motivation of the GLASU algorithm. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on communication cost, but the comment does not specify how to do so or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"GLASU algorithm\" and the \"communication cost,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of discussion on the communication cost in both the theorem and the experiment, which undermines the contribution of the paper. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion, but it lacks specific examples or references to support the assertion that the communication cost is not addressed. The authors would need to infer the importance of this omission and how it affects the paper\\'s contribution. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the communication cost of the GLASU algorithm, which is central to its motivation. By pointing out that neither the theorem nor the experiment discuss this aspect, the comment highlights a critical area that needs to be addressed to strengthen the paper\\'s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to quantify or analyze the communication cost. While it effectively identifies a weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a gap in the paper regarding the discussion of communication cost, which is central to the motivation of the GLASU algorithm. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the communication cost should be discussed. The feedback is implicit and lacks concrete suggestions, making it barely actionable. The authors are left to infer that they need to include a discussion on communication cost, but without clear direction on how to do so, the comment remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"GLASU algorithm\" and the \"communication cost,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of discussion on the communication cost in both the theorem and the experiment, which undermines the contribution of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This is a relevant observation that highlights a gap in the paper. However, the comment does not provide specific examples or references to support the claim that the communication cost is not addressed. The lack of detailed justification or evidence makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the discussion of communication cost, which is central to the motivation of the GLASU algorithm. By pointing out that neither the theorem nor the experiment address this aspect, the comment highlights a significant area that needs to be addressed to strengthen the paper\\'s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to quantify or analyze the communication cost. While it effectively identifies a weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a gap in the paper"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to state the contributions of the paper. This is a clear and direct action that the authors can take to improve their draft. However, it does not provide specific guidance on how to articulate these contributions or what aspects should be emphasized. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated. However, it does not specify which part of the paper this pertains to, such as the introduction, conclusion, or a specific section where contributions are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint where to make improvements. Additionally, the comment lacks specificity regarding what aspects of the contributions should be clarified or how they should be articulated. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, which is a clear and actionable piece of feedback. However, it lacks specificity and does not provide guidance on what aspects of the contributions should be highlighted or how they should be articulated. Without detailed suggestions or examples, the authors may find it challenging to determine which contributions need emphasis or how to present them effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, which is a clear and direct action for the authors to take. However, it does not provide specific guidance on how to articulate these contributions or what aspects should be emphasized. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this pertains to or provide details on what aspects of the contributions should be clarified. Without explicit references or specific guidance, the authors may find it challenging to determine where and how to address this feedback. As a result, the comment lacks both grounding and specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance or basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, which is a clear and actionable piece of feedback. However, it lacks specificity and does not provide guidance on what aspects of the contributions should be highlighted or how they should be articulated. Without detailed suggestions or examples, the authors may find it challenging to determine which contributions need emphasis or how to present them effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, which is a clear and direct action for the authors to take. However, it does not provide specific guidance on how to articulate these contributions or what aspects should be emphasized. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this pertains to or provide details on what aspects of the contributions should be clarified. Without explicit references or specific guidance, the authors may find it challenging to determine where and how to address this feedback. As a result, the comment lacks both grounding and specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifi"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the work is unclear and that the explanation is not convincing. It specifically mentions that the statement \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. This feedback provides a clear and explicit action for the authors to take, which is to provide experimental or theoretical justification for the mentioned statement. The comment is concrete in its request for justification, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work and the explanation provided in the paper, specifically mentioning the statement \"different densities directly will cause semantic conflicts.\" However, it does not explicitly mention which part of the paper this statement is located in, making it weakly grounded. The comment is specific in its request for justification of this statement experimentally or theoretically. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work is unclear and that the explanation is not convincing. It specifically critiques the statement \"different densities directly will cause semantic conflicts,\" suggesting that it should be justified experimentally or theoretically. While the comment identifies a specific issue with the explanation, it lacks detailed reasoning or examples to support the claim that the explanation is not convincing. The suggestion to justify the statement experimentally or theoretically provides some direction, but the comment could be strengthened with more detailed justification or references. Therefore, the claim is somewhat verifiable, as it provides a basis for improvement but requires additional information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation and explanation of the work. It points out that the statement \"different densities directly will cause semantic conflicts\" is not adequately justified, suggesting that it should be supported experimentally or theoretically. This feedback is clear and actionable, as it directs the authors to provide additional justification for their claims, which is crucial for enhancing the credibility and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on how to achieve this justification or examples of what kind of evidence would be convincing. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical weakness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues. First, it asks whether the three transformer modules are trained iteratively or in an end-to-end manner, which implies that the authors should clarify this aspect in their paper. Second, it questions the necessity of repeating the visualization in Figure 5, suggesting that it is not necessary unless it demonstrates new points. While the comment provides explicit questions, it does not offer concrete guidance on how to address these issues or what specific changes should be made. The authors are left to infer the necessary actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the three transformer modules are trained iteratively or in an end-to-end manner and suggesting that the repeated visualization in Figure 5 is unnecessary unless it demonstrates new points. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training method of the transformer modules and critiques the repetition of visualization in Figure 5. However, it does not provide any supporting evidence, reasoning, or references to justify why the training method is unclear or why the repetition of visualization is unnecessary. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two points. First, it questions whether the three transformer modules are trained iteratively or in an end-to-end manner, which is a relevant clarification for the authors to address. Second, it critiques the repetition of visualization in Figure 5, suggesting that it is unnecessary unless it demonstrates new points. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out potential weaknesses, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete guidance on how to improve the writing by suggesting greater precision and clarity. It specifically mentions the need to clarify the distinction between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, it advises the authors to explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. The comment provides clear actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it provides specific examples of areas where the writing could be improved, such as the distinction between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" It also suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, and it provides specific examples of areas where this could be improved. However, the comment does not offer detailed reasoning or evidence to support why these changes are necessary or how they would enhance the paper. The suggestion to clarify the unique contributions of ParamReL is also vague, lacking specific examples or comparisons to infoDiffusion. This makes the claim somewhat verifiable, as it provides some direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the precision and clarity of the writing. It highlights areas where the language could be more precise, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, the comment suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This feedback is clear and constructive, offering the authors concrete steps to enhance the clarity and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the clarity of the authors\\' focus on a specific situation where the gradient of the sum is not the sum of the individual gradients. It suggests that this point is not effectively communicated in the text and that the paragraph from lines 70-74 could be discussed in less space. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the focus and potentially reduce the space dedicated to it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 60-74 and the beginning of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of communication about the focus on a situation where the gradient of the sum is not the sum of the individual gradients. The comment suggests that this setting is shared in all ERM approaches and could be discussed in less space, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' focus on a situation where the gradient of the sum is not the sum of the individual gradients is not effectively communicated in the text. The reviewer suggests that this is a common setting in all ERM approaches and could be discussed in less space. However, the comment lacks specific examples or references to support the claim that this situation is rare or requires more space. The reasoning is somewhat verifiable, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of the authors' focus on a specific situation where the gradient of the sum is not the sum of the individual gradients. It suggests that this point is not effectively communicated in the text and provides a specific example from lines 70-74. The comment also notes that this setting is shared in all ERM approaches and could be discussed in less space, offering a constructive suggestion for improvement. However, the comment could be more helpful if it provided specific guidance on how to clarify this point or suggested ways to address the issue. Overall, the feedback is somewhat helpful as it highlights a potential weakness and provides some direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions due to the high percentage of invalid questions and unresolved coreference issues. The reviewer provides specific numbers, such as 23% of questions becoming invalid and 44% attributed to unresolved coreference. However, the comment does not offer explicit guidance or suggestions on how the authors might address these concerns or improve the strategy. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the question-rewrite strategy and references Table 4 in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the method's coverage, the high percentage of invalid questions, and the unresolved coreference issues. The comment provides specific numbers and examples, such as the 23% of questions becoming invalid and the 44% attributed to unresolved coreference, which helps the authors understand the issues and potential improvements needed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions due to the high percentage of invalid questions and unresolved coreference issues. The reviewer provides specific percentages and numbers to support their claim, such as 23% of questions becoming invalid and 44% attributed to unresolved coreference. Additionally, the comment references the proposed method's rewriting of 12% of questions for all models, which is said to have a negligible effect. This detailed analysis and quantification of the issues provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by providing more context or references to similar studies that have addressed similar issues, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant concern with the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions due to the high percentage of invalid questions and unresolved coreference issues. The reviewer provides specific percentages and numbers to support their claim, which helps the authors understand the scale of the problem. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the strategy. While it highlights a critical area for improvement, the feedback could be more helpful if it offered specific recommendations or examples of how to enhance the strategy's effectiveness. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions due to the high percentage of invalid questions and unresolved coreference issues. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the strategy. The comment lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. As a result, the feedback is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the question-rewrite strategy and references Table 4 in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the method's coverage, the high percentage of invalid questions, and the unresolved coreference issues. The comment provides specific numbers and examples, such as the 23% of questions becoming invalid and the 44% attributed to unresolved coreference, which helps the authors understand the issues and potential improvements needed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions due to the high percentage of invalid questions and unresolved coreference issues. The reviewer provides specific percentages and numbers to support their claim, such as 23% of questions becoming invalid and 44% attributed to unresolved coreference. Additionally, the comment references the proposed method's rewriting of 12% of questions for all models, which is said to have a negligible effect. This detailed analysis and quantification of the issues provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by providing more context or references to similar studies"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It asks for clarification on the benefit of using L2 distance. While the comment implies that the authors should justify or explain the choice of L2 distance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). The comment clearly specifies what needs to be addressed, namely the justification or benefit of using L2 distance in the context of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). The comment raises a valid point about the choice of distance metric but lacks specific reasoning or evidence to support why L2 distance might be less suitable or beneficial in the context of the paper. The suggestion is based on common knowledge in the field, but without further elaboration or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It raises a valid question about the benefit of using L2 distance in this context, prompting the authors to justify or clarify their choice. This feedback is clear and actionable, as it encourages the authors to provide a rationale for their methodological decision, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of how earth mover\\'s distance might be more appropriate. Overall, the comment is mostly helpful, as it directs the authors to a critical aspect of their work that requires further explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should provide a more comprehensive comparison, it does not explicitly instruct them to do so or specify which other offline RL algorithms should be included in the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their comparison but lack detailed guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. However, it does not specify which sections or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need attention. While the authors might have an idea of where the related work is discussed, the comment lacks full grounding. It is specific in its request for a broader comparison but does not provide detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the description of related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment identifies a potential issue with the organization of the related work section, it does not provide specific examples or references to support the claim that the discussion is insufficient. The lack of detailed justification or examples makes it difficult for the authors to understand the extent of the problem or how to address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the related work section, noting that it is scattered throughout the paper. It suggests that while some relevant papers are included, a broader discussion on how the algorithm compares to other offline RL algorithms would be beneficial. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s structure and encourages the authors to provide a more comprehensive comparison. However, the comment lacks detailed guidance on how to achieve this broader discussion or which specific offline RL algorithms should be considered. To be more helpful, the comment could include suggestions on which papers to include or how to structure the comparison. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should provide a more comprehensive comparison, it does not explicitly instruct them to do so or specify which other offline RL algorithms should be included in the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their comparison but lack detailed guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. However, it does not specify which sections or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment provides a general direction for improvement, it lacks specificity and detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the description of related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment identifies a potential issue with the organization of the related work section, it does not provide specific examples or references to support the claim that the discussion is insufficient. The lack of detailed justification or evidence makes it difficult for the authors to understand the extent of the problem or how to address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the related work section, noting that it is scattered throughout the paper. It suggests that while some relevant papers are included, a broader discussion on how the algorithm compares to other offline RL algorithms would be beneficial. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s structure and encourages the authors to provide a more comprehensive comparison. However, the"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution changes if all increments are available at the same time. While it implies that the authors should consider this scenario, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question or what aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the impact of having all increments available at the same time on the final solution. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the effect of a particular scenario on the final solution, but without clear grounding, the authors may struggle to identify where this question fits into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of a specific scenario on the final solution. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about how the final solution changes if all increments are available at the same time. While it raises an interesting point that could lead to further exploration or analysis, it lacks specificity and does not provide any guidance or suggestions for the authors to address this question. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, the comment is barely helpful, as it identifies a potential area of interest but does not provide sufficient direction for the authors to act upon. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the technique of using multiple different feature spaces, describing it as convoluted and potentially circular. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their approach. There is no guidance on alternative methods, alternative feature spaces, or how to simplify the technique. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned glove model. This provides a clear indication of the specific technique being addressed, making the comment fully grounded. The comment also specifies the issue, which is the potential for the technique to be convoluted and potentially circular. This level of detail helps the authors understand what aspect of the technique needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technique of using multiple different feature spaces is convoluted and potentially circular. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the technique used in the paper, specifically the use of multiple different feature spaces. It describes the technique as convoluted and potentially circular, which could be a significant concern for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left with only a general critique, making the comment somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and to include their FLOPs and parameter sizes in Table 7. It also questions why the results of OFA with progressive shrink are not used in the table. This feedback provides clear and specific actions for the authors to take, making it highly actionable. The authors know exactly what changes to make to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and questions why the results of OFA with progressive shrink are not used in the table. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 7 should include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and questions why the results of OFA with progressive shrink are not included. While the comment identifies a potential gap in the comparison, it does not provide specific examples or references to support the claim that these comparisons are necessary. The reasoning is somewhat verifiable, as it highlights a potential area for improvement, but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper, namely the inclusion of comparisons with other works that use the MobileNetV3 search space, such as AtomNAS. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their results by expanding the comparative analysis. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or why they are important. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is necessary, in addition to referencing existing work. While the comment implies that the authors should add this discussion, it does not explicitly instruct them to do so. The action is clear but stated implicitly, making the comment mostly actionable. The authors know they need to address the issue but may not be entirely sure of the exact steps to take, such as how to structure the discussion or what specific points to cover.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including a discussion on why fixing hallucinations is necessary, in addition to referencing existing work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the desirability of fixing hallucinations, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on why fixing hallucinations is necessary, in addition to referencing existing work. However, the comment does not provide any specific reasoning or examples to support why this discussion is important or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the necessity of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is necessary, in addition to referencing existing work. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a more comprehensive explanation of the importance of fixing hallucinations. However, the comment lacks specific guidance on how to structure this discussion or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could provide examples of why fixing hallucinations is important or suggest how the discussion could be integrated into the paper. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the clarity of the text, specifically mentioning that lines 50-54 introduce terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This implies that the authors should clarify the relationship between these terms and the null hypothesis. While the comment does not explicitly instruct the authors to make these clarifications, the action is clear and concrete, as it points out specific lines and terms that need attention. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 50-54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of introducing terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential issue with the clarity of the text, specifically mentioning that lines 50-54 introduce terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. However, the comment does not provide any supporting evidence or reasoning to justify why this is a problem or how it affects the understanding of the paper. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text, pointing out that terms like Type-1 error, Type-2 error, and false positive rate are introduced before the null hypothesis is clearly stated. This feedback is valuable as it highlights a potential confusion for readers who might not be familiar with these terms. However, the comment does not provide specific suggestions on how to improve the clarity or rephrase the text to better align with the null hypothesis. While it directs the authors to an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the text, noting that terms like Type-1 error, Type-2 error, and false positive rate are introduced before the null hypothesis is clearly stated. This implies that the authors should clarify the relationship between these terms and the null hypothesis. While the comment does not explicitly instruct the authors to make these clarifications, the action is clear and concrete. The authors can deduce that they need to rephrase or reorganize the text to ensure clarity. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 50-54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of introducing terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential issue with the clarity of the text, specifically mentioning that terms like Type-1 error, Type-2 error, and false positive rate are introduced before the null hypothesis is clearly stated. However, the comment does not provide any supporting evidence or reasoning to justify why this is a problem or how it affects the understanding of the paper. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text, pointing out that terms like Type-1 error, Type-2 error, and false positive rate are introduced before the null hypothesis is clearly stated. This feedback is valuable as it highlights a potential confusion for readers who might not be familiar with these terms. However, the comment does not provide specific suggestions on how to improve the clarity or rephrase the text to better align with the null hypothesis. While it directs the authors to an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how to resolve it. The authors are left to infer that they need to address the uncertainty, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors might infer that it relates to sections discussing the model's reliability or estimation process, but this is not explicitly stated. The comment is specific in detailing the issue of inherent uncertainty and the need for a solution, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue. While the comment identifies a potential problem, it lacks specific examples, references, or detailed reasoning to support the claim. The authors may find it challenging to understand the basis of the concern without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It raises a pertinent question about how the authors address this uncertainty, which is a valid concern for the reliability of the model. However, the comment lacks specific suggestions or guidance on how the authors might tackle this issue or improve their approach. While it points out an important area for consideration, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue, but it does not provide explicit guidance or suggestions on how to tackle the uncertainty. The authors are left to infer that they need to address this concern, but without concrete steps or examples, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue, which is a relevant point for the authors to consider. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors might infer that it relates to sections discussing the model's reliability or estimation process, but this is not explicitly stated. The comment is specific in detailing the issue of inherent uncertainty but lacks grounding, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue, which is a relevant point. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the inherent uncertainty. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It raises a pertinent question about how the authors address this uncertainty, which is a valid concern for the reliability of the model. However, the comment lacks specific suggestions or guidance on how the authors might tackle this issue or improve their approach. While it points out an important area for consideration, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It asks the authors to address how they solve this issue, but it does"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of the SFAM scorers, which are fundamental components of the LISA embedding, when correlating with human judgments on more linguistics-relevant styles. It suggests that this discrepancy might lead to the LISA being more content-focused rather than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the alignment between the LISA and human judgments. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This allows the authors to identify the specific part of the paper being addressed, providing full grounding. The comment is also specific as it details the issue with the SFAM scorers and suggests that this might lead to the LISA being more content-focused rather than style-focused. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This claim is supported by logical reasoning, as it highlights a discrepancy in the performance of the SFAM scorers across different styles. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This insight is valuable as it points out a potential limitation in the model\\'s ability to capture style-focused aspects. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve the alignment between the LISA and human judgments. While it offers a clear area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy in the performance of the SFAM scorers, which are fundamental components of the LISA embedding, when correlating with human judgments on more linguistics-relevant styles. It suggests that this discrepancy might lead to the LISA being more content-focused rather than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the alignment between the LISA and human judgments. Without actionable steps or concrete advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This allows the authors to identify the specific part of the paper being addressed, providing full grounding. The comment is also specific as it details the issue with the SFAM scorers and suggests that this might lead to the LISA being more content-focused rather than style-focused. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This claim is supported by logical reasoning, as it highlights a discrepancy in the performance of the SFAM scorers across different styles. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding."}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their experiments on additional real-world datasets, specifically mentioning DexYCB and recommending the use of more recent hand-object pose estimation pipelines to predict the initial hand-object poses. This feedback provides a clear and explicit action for the authors to take, as it specifies the datasets and methodologies to consider. The suggestion is concrete, as it outlines a specific direction for expanding the experimental evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB and recommending the use of more recent hand-object pose estimation pipelines. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to use additional datasets and methodologies, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be evaluated on additional real-world datasets like DexYCB, using more recent hand-object pose estimation pipelines to predict initial hand-object poses. While the comment provides a specific suggestion for improvement, it lacks detailed reasoning or evidence to support why these datasets or methodologies are necessary. The claim is somewhat verifiable, as it offers a direction for enhancement but requires further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the experimental evaluation by recommending the use of additional real-world datasets like DexYCB. It also suggests incorporating more recent hand-object pose estimation pipelines to predict the initial hand-object poses. This feedback is clear and actionable, offering the authors a concrete direction for expanding their experimental setup to enhance the robustness and applicability of their findings. By addressing this point, the authors can significantly improve the comprehensiveness and relevance of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. While it identifies specific areas that need clarification, it does not provide explicit instructions or concrete suggestions on how to address these gaps. The authors are left to infer that they need to provide more detailed explanations, but the comment does not specify what specific information should be included or how to structure this explanation. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. However, it does not specify which part of the paper these components are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these components are discussed, the comment lacks full grounding. It is specific about what needs to be addressed\u2014clarification on the design and update of the attention model\u2014but does not provide detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper, specifically the lack of explicit explanation regarding important components such as the design of sequential models and how the attention model is updated. This feedback highlights a significant area for improvement, as understanding these components is crucial for comprehending the rationale behind the proposed work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or examples to include. While it points out a clear weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. While it highlights a critical area for improvement, it does not provide specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific sections to include more detailed explanations or suggesting ways to enhance the clarity of the content. As a result, the authors are left to infer the necessary steps, making the comment somewhat actionable but vague in its guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a lack of explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. However, it does not specify which part of the paper these components are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about what needs to be addressed\u2014clarification on the design and update of the attention model\u2014it lacks full grounding because it does not provide explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation regarding important components, such as the design of sequential models and how the attention model is updated. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper, specifically the lack of explicit explanation regarding important components such as the design of sequential models and how the attention model is updated. This feedback highlights a significant area for improvement, as understanding these components is crucial for comprehending the rationale behind the proposed work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or examples to include. While it points out a clear weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should make the entire code accessible if the paper is accepted. This is an explicit and concrete action, as it clearly states what the authors should do to improve their draft. The comment provides a direct and actionable recommendation, ensuring that the authors know exactly what steps to take to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests making the entire code accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on why this would be beneficial or how it could be implemented. Without specific references or detailed guidance, the authors cannot confidently determine which sections or aspects of the paper need to be addressed. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that making the entire code accessible would be beneficial if the paper is accepted. However, it does not provide any justification or reasoning for why this would be helpful or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that making the entire code accessible would be beneficial if the paper is accepted. This feedback is clear and actionable, as it provides a specific recommendation that could enhance the transparency and reproducibility of the research. By offering this suggestion, the reviewer empowers the authors to improve their draft by ensuring that their work is more accessible and verifiable. However, the comment could be more helpful if it included additional details on how to implement this suggestion or why it is particularly important for the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a concrete suggestion by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is explicit and provides clear guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hybrid architecture\" and specific processes like \"spike-driven token selection\" and \"intra- and inter-stage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the explanations and the inclusion of pseudo-code or flow diagrams to enhance understanding. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a logical suggestion to include pseudo-code or flow diagrams to enhance understanding. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that these explanations are unclear. While the suggestion is reasonable, the absence of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the clarity of the explanations for specific processes such as spike-driven token selection and intra- and inter-stage feature fusion. It provides a clear and actionable suggestion by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is valuable as it offers a concrete way for the authors to improve the comprehensibility of their work, making it mostly helpful. However, it could be further improved by providing more detailed guidance on how to implement these suggestions or by offering examples of similar approaches used in other works. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is an incremental improvement over existing AutoAugment, with performance improvements that are not very significant when compared to recent methods. It specifically mentions that on ImageNet, resnet-50 is only 0.3 better than a referenced method, and notes that the standard deviation (std) is large, which raises doubts about generalizability. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their method. The feedback lacks actionable steps or suggestions for enhancing the draft, leaving the authors uncertain about how to respond to the critique. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method as an incremental improvement over AutoAugment and critiques its performance improvements compared to recent methods, specifically mentioning ImageNet and resnet-50. It also points out the large standard deviation, which raises doubts about generalizability. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issues with performance and generalizability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over AutoAugment, with performance improvements that are not significant when compared to recent methods. The reviewer provides a specific example by mentioning that on ImageNet, resnet-50 is only 0.3 better than a referenced method. Additionally, the comment highlights the large standard deviation, which raises doubts about generalizability. This claim is supported by specific data and a comparison to a known method, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to other recent methods for a more comprehensive evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a critical evaluation of the proposed method by comparing it to existing AutoAugment and recent methods. It highlights that the performance improvements are not significant when compared to recent methods, specifically mentioning that on ImageNet, resnet-50 is only 0.3 better than a referenced method. Additionally, the comment points out the large standard deviation, which raises doubts about the method's generalizability. While the comment identifies specific weaknesses and provides some context for comparison, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their method. The feedback is somewhat helpful as it provides insight into areas needing improvement but does not offer detailed advice on how to achieve them. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment provides a critical evaluation of the proposed method, noting that it is an incremental improvement over existing AutoAugment and that the performance improvements are not significant when compared to recent methods. It also highlights the large standard deviation, which raises doubts about the method\\'s generalizability. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their method. Without actionable advice or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a critical evaluation of the proposed method by comparing it to existing AutoAugment and recent methods. It mentions specific performance metrics, such as ImageNet and resnet-50, and highlights the large standard deviation, which raises doubts about generalizability. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing the issues with performance and generalizability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over existing AutoAugment, with performance improvements that are not significant when compared to recent methods. It provides a specific example by mentioning that on ImageNet, resnet-50 is only 0.3 better than a referenced method. Additionally, the comment highlights the large standard deviation, which raises doubts about generalizability. This claim is supported by specific data and a comparison to a known method, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to other recent methods for a more comprehensive"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison in the paper is weak due to the lack of references to existing prior arts, such as [1], and suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. While the comment implies that the authors should include references to prior arts and conduct a comparison with recent methods, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights a weakness in the comparison section of the paper, noting that it lacks references to existing prior arts and suggesting that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table where the comparison is presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by including references to prior arts and conducting a comparison with recent methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison in the paper is weak due to the lack of references to existing prior arts and suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific references to the prior arts or detailed examples of the latest methods being compared. This lack of explicit evidence or references makes it difficult for the authors to fully understand and address the critique. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of references to existing prior arts in the comparison section. It suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by recommending the inclusion of references to prior arts and conducting a comparison with recent methods. However, the comment could be more helpful if it provided specific examples of prior arts or methods to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a weakness in the paper by pointing out the lack of references to existing prior arts in the comparison section. It suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. While the comment implies that the authors should include references to prior arts and conduct a comparison with recent methods, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a weakness in the paper by pointing out the lack of references to existing prior arts in the comparison section. It suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table where the comparison is presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by including references to prior arts and conducting a comparison with recent methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison in the paper is weak due to the lack of references to existing prior arts and suggests that a simple search with respect to the 5 experiment datasets would reveal significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific references to prior arts or detailed examples of the latest methods being compared. This lack of explicit evidence or references makes it difficult for the authors to fully understand and address the critique. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of references"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a quantification of the diversity of the data gathered, even though they argue for its importance. It explicitly states that a simple statistic, such as a types vs. token count, would be useful. This feedback is explicit and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to include a quantification of data diversity using a specific statistic. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of quantification for the diversity of the data gathered, suggesting that even a simple statistic like types vs. token count would be useful. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include a quantification, but without clear grounding, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but fail to provide quantification, suggesting that even a simple statistic like types vs. token count would be beneficial. This claim is somewhat verifiable as it logically points out the lack of quantification and provides a specific suggestion for improvement. However, the comment could be strengthened by offering more detailed reasoning or examples of how quantification could enhance the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting that the authors argue for the diversity of the data gathered but fail to provide any quantification. It suggests that even a simple statistic, such as a types vs. token count, would be beneficial. This feedback is clear and actionable, as it directs the authors to include a quantification of data diversity, which could strengthen their argument. However, the comment could be more helpful if it provided additional guidance on how to implement this quantification or discussed the potential impact of such a statistic. Overall, the comment is mostly helpful as it highlights a clear area for improvement and offers a specific suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to have created a more diverse set of positive instance pairs but lacks sufficient evidence or comparison with earlier works. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue, such as suggesting specific measures of diversity or how to compare with earlier works. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence or comparisons, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the creation of a more diverse set of positive instance pairs. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of a suggested measure of diversity and the absence of a comparison with earlier works regarding diversity. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about creating a more diverse set of positive instance pairs is not sufficiently supported. The reviewer points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. This claim is somewhat verifiable as it highlights a gap in the paper\\'s evidence and reasoning, but it lacks specific examples or references to earlier works that could provide context or comparison. The authors would need to make a significant effort to address this feedback, as the claim is based on a logical expectation of evidence and comparison, but the lack of explicit references or detailed examples makes it somewhat challenging to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of evidence or comparison to support the claim of creating a more diverse set of positive instance pairs. It points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. This feedback is clear and actionable, as it directs the authors to provide additional evidence or comparisons to substantiate their claim. However, the comment could be more helpful if it offered suggestions on how to measure diversity or which earlier works to compare with. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of evidence or comparison to support the claim of creating a more diverse set of positive instance pairs. It points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific measures or comparisons to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence or comparisons, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the creation of a more diverse set of positive instance pairs. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of a suggested measure of diversity and the absence of a comparison with earlier works regarding diversity. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about creating a more diverse set of positive instance pairs is not sufficiently supported. It highlights the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. While the comment identifies a gap in the paper\\'s evidence and reasoning, it lacks specific examples or references to earlier works that could provide context or comparison. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of evidence or comparison to support the claim of creating a more diverse set of positive instance pairs. It points out the absence of a suggested measure of diversity and a comparison with earlier works regarding diversity. This feedback is clear and actionable, as it directs the authors to provide additional evidence or"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors\\' approach compares to or aligns with other inputs, such as structured information, and mentions that AUCROC appears high in other models in literature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern, what specific comparisons should be made, or how the authors should address this question. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the authors\\' approach compares to or aligns with other inputs, such as structured information, and mentions that AUCROC appears high in other models in literature. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where structured information is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the comparison with structured information and the high AUCROC, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for a comparison with other inputs, such as structured information, and mentions that AUCROC appears high in other models in literature. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how the authors\\' approach compares to or aligns with other inputs, such as structured information. It also mentions that AUCROC appears high in other models in literature. While the comment identifies a potential area for improvement by suggesting a comparison with structured information, it lacks specificity and actionable guidance. The authors are left with a general question and an observation about AUCROC, but without detailed suggestions or examples, they may struggle to address the feedback effectively. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not provide enough detail to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit and concrete actions for the authors to take. It suggests stating the objective function in experiments, which is a direct action. It also questions the inequality sign in Eq. 7 and the gap definition, prompting the authors to clarify these aspects. Additionally, it suggests that section 3, particularly section 3.2, is too technical and recommends leaving more space in section 4 to explain the training procedure. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 7\" and \"section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the objective function, the inequality sign in Eq. 7, and the technical nature of section 3, particularly section 3.2. The comment suggests clarifying the objective function and the inequality sign, and it recommends leaving more space in section 4 to explain the training procedure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a mix of factual statements and questions. The factual statements, such as \"It would be great to state the objective function in experiments,\" are descriptive and do not require verification. The questions, such as \"Should Eq. 7 have a reverse inequality sign because v is the expected loss?\" and \"I felt some parts of section 3 (mainly sec. 3.2) are pretty technical but didn\u2019t help me understand the main method in section 4,\" are requests for clarification or personal opinions. These do not constitute claims that require verification. Therefore, the overall comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It explicitly requests the authors to state the objective function in experiments, which is a clear and direct recommendation. Additionally, it questions the inequality sign in Eq. 7 and the gap definition, prompting the authors to clarify these aspects. The comment also identifies a technical section that may be too dense and suggests leaving more space in section 4 to explain the training procedure, which is a constructive suggestion for enhancing the paper\\'s clarity and accessibility. While the comment could be more detailed in explaining why the technical section is too dense, it still offers valuable guidance on how to improve the draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot) and requests an explanation. While the comment identifies a specific issue that needs clarification, it does not provide explicit instructions or suggestions on how to address it. The authors are left to infer that they should provide an explanation, but the comment lacks concrete guidance on what aspects to focus on or how to present the explanation. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3, top right plot,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid, indicating that an explanation is needed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot) and requests an explanation. This feedback is clear and actionable, as it directs the authors to provide a detailed explanation of this observation. By addressing this question, the authors can enhance the clarity and understanding of their results, which is valuable for improving the draft. However, the comment could be more helpful if it suggested potential reasons for the trend or how to present the explanation effectively. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and provides a clear direction for the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of key implementation details, specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. While the comment identifies a specific area that needs attention, it does not provide explicit instructions or suggestions on how to address this issue. The authors are left to infer that they should include this information, but without concrete guidance on how to present it or what specific details to include, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of key implementation details, specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where these details should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in identifying what information is missing, namely the resolutions at which images achieve adversarial effects. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"key implementation details are missing,\" specifically mentioning the absence of information on the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this information is crucial or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this detail or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks key implementation details, namely the resolutions at which images successfully achieve adversarial effects. This feedback is valuable as it highlights a critical aspect of the methodology that needs clarification or inclusion in the paper. However, the comment does not provide detailed guidance or suggestions on how to address this issue, such as recommending specific sections or providing examples of how to present this information. While it points out an important omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific area where the paper lacks key implementation details, namely the resolutions at which images successfully achieve adversarial effects. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should include this information, but it lacks concrete guidance on how to present it or what specific details to include. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the absence of key implementation details, particularly regarding the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in detailing what is missing, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"key implementation details are missing,\" specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this information is crucial or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this detail or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks key implementation details, namely the resolutions at which images successfully achieve adversarial effects. This feedback is valuable as it highlights an important aspect of the methodology that needs clarification or inclusion in the paper. However, the comment does not provide detailed guidance or suggestions on how to address this issue, such as recommending specific sections or providing examples of how to present this information. While it points out an important omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies the absence of key implementation details, specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, it does"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that while the approach of using DDIM Inversion to obtain motion guidance for training is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback provides a clear and explicit action for the authors to consider, namely, to explore improvements to the motion guidance strategy. However, it does not specify what kind of improvements should be explored or how to implement them. Therefore, the comment is mostly actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the approach using DDIM Inversion does not significantly simplify the overall complexity and suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the approach of using DDIM Inversion to obtain motion guidance for training is effective in reducing training time but does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the approach does not simplify complexity. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the data preprocessing section, where the use of DDIM Inversion is mentioned. It acknowledges the effectiveness of this approach in reducing training time but points out that it does not significantly simplify the overall complexity. The comment suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, providing the authors with a direction for refining their approach to data preprocessing. However, it could be more helpful if it offered specific suggestions or examples of how to improve the motion guidance strategy. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment acknowledges the effectiveness of using DDIM Inversion to obtain motion guidance for training, which reduces training time. However, it suggests that this approach does not significantly simplify the overall complexity and recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these improvements or what specific aspects of the motion guidance strategy should be explored. The authors are left with a general idea of what needs to be done but without detailed instructions on how to proceed. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the approach using DDIM Inversion does not significantly simplify the overall complexity and suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the approach of using DDIM Inversion to obtain motion guidance for training is effective in reducing training time but does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the approach does not simplify complexity. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the data preprocessing section, where the use of DDIM Inversion is mentioned. It acknowledges the effectiveness of this approach in reducing training time but points out that it does not significantly simplify the overall complexity. The comment suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, providing the authors with a direction for"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific analyses or changes to the methodology. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the statistics and potential issues with relation phrases, but without clear grounding, it is weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not provide any supporting evidence, examples, or references to substantiate these claims or questions. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the concerns or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases. It highlights concerns about the frequency of rarer relation phrases and the issue of heavy tail in relations, which could impact the effectiveness of the approach. While the comment identifies relevant areas for consideration, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their methodology. The feedback is somewhat helpful as it prompts the authors to consider these issues, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their work. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is somewhat specific in its inquiry about the statistics and potential issues with relation phrases, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in relations. However, it does not provide any supporting evidence, examples, or references to substantiate these claims or questions. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the concerns or how to address them. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases. It highlights concerns about the frequency of rarer relation phrases and the issue of heavy tail in relations, which could impact the effectiveness of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their methodology. While it identifies relevant areas for consideration, it does not provide actionable feedback, making it somewhat helpful. The authors are prompted to consider these issues but are left without clear direction on how to proceed. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises questions about the statistics of relation phrases and the potential disadvantages of chunking into relation phrases, such as the issue of heavy tail in"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides explicit suggestions for addressing the issue, it lacks detailed guidance on how to implement these solutions or what specific techniques to use. The authors are given clear actions to take but without concrete steps on how to execute them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for more robust approaches in dynamic regions, using the Bonn dataset as an example. The comment further provides specific suggestions for addressing the issue, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the robustness of the approach in dynamic regions, suggesting that the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements\" is generally true but requires more robust approaches in edge cases. The reviewer provides a specific example from the Bonn dataset, where moving objects can occupy over 50% of the image, and suggests potential solutions such as masking out dynamic regions or re-running relative pose estimation. This detailed explanation and example make the claim mostly verifiable, as it provides a clear rationale and specific scenario to support the need for robustness in dynamic regions. However, the comment could be further strengthened by referencing additional studies or examples to fully substantiate the claim. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the robustness of the approach in dynamic regions, providing a clear example from the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, offering the authors concrete steps to address the identified weakness. However, the comment could be more helpful if it provided additional details or examples of how to implement these solutions. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only compare the models proposed by the authors and lack comparisons with other methods. While it identifies a gap in the experimental design, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to include comparisons with other methods, but the comment lacks concrete suggestions on which methods to include or how to structure these comparisons. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting that they only compare the models proposed by the authors and lack comparisons with other methods. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in identifying the need for additional comparisons, but without clear grounding, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack comparisons with other methods, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments only compare the models proposed by the authors and lack comparisons with other methods. This feedback highlights an important area for improvement, as it suggests that the authors should include comparisons with existing methods to provide a more comprehensive evaluation of their models. However, the comment does not offer specific guidance on which methods to include or how to structure these comparisons, leaving the authors with a general direction but without detailed direction on how to implement the suggested improvement. Therefore, the comment is somewhat helpful, as it provides insight into an area needing enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor inconsistency in Table 3 and 4, where the models labeled as \"math specialists\" have an asterisk, but the MAVIS models themselves do not. The reviewer suggests that the MAVIS models should also be considered \"math specialists\" and should have an asterisk. This feedback provides a clear and explicit action for the authors to take, which is to ensure consistency in labeling the MAVIS models as \"math specialists\" with an asterisk. The comment is specific and actionable, giving the authors a direct task to address the inconsistency. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in labeling models as \"math specialists\" and suggests that the MAVIS models should also be considered \"math specialists\" and have an asterisk. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the labeling of models in Table 3 and 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual observation and a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor inconsistency in the labeling of models in Table 3 and 4, noting that models labeled as \"math specialists\" have an asterisk, while the MAVIS models themselves do not. The reviewer suggests that the MAVIS models should also be considered \"math specialists\" and have an asterisk. This feedback is clear and actionable, as it provides specific guidance on how to correct the labeling inconsistency. By addressing this minor issue, the authors can improve the consistency and clarity of their presentation. However, the comment could be more helpful if it explained why this inconsistency is important or how it might affect the interpretation of the results. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area needing attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their work. There is no guidance on potential improvements, alternative approaches, or additional insights that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical novelty of the work, specifically mentioning that KNN-based methods are widely studied in LM and MT. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the work lack novelty or how it could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited, specifically noting that KNN-based methods are widely studied in LM and MT. However, the comment lacks detailed reasoning or specific examples to support this claim. It does not provide evidence or references to demonstrate why the insights into the non-parametric method for text classification are limited. This makes the claim somewhat verifiable, as the authors would need to further explore the literature to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into a non-parametric method for text classification. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or address the limitations identified. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment notes that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their work. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to improve their draft. As a result, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical novelty of the work, noting that KNN-based methods are widely studied in LM and MT. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the work lack novelty or how it could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence to substantiate the claim, rendering it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into a non-parametric method for text classification. However, the comment lacks specific guidance or suggestions on how the authors might enhance the novelty or address the limitations identified. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an issue but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment notes that the technical novelty of the work is"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overstates the enhancement of the IM for most existing RL algorithms and lacks a comparison with the latest work, particularly non-pixel-based approaches. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons or updates should be made. The comment implies that the authors should update their literature review to include more recent work, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s emphasis on the enhancement of the IM for most existing RL algorithms and criticizes the lack of a comparison with the latest work, specifically mentioning SAC in 2018. It also points out the absence of a comparison with non-pixel-based approaches to data efficiency. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014recent work and comparisons with non-pixel-based approaches\u2014but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the enhancement of the IM for most existing RL algorithms and lacks a comparison with the latest work, specifically mentioning SAC in 2018. However, the comment does not provide specific examples or references to other recent work or non-pixel-based approaches that should be included. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential overstatement in the paper regarding the enhancement of the IM for most existing RL algorithms. It points out that the description of the mainstream RL algorithms in related work is outdated, specifically mentioning SAC in 2018, and suggests that the paper lacks a comparison with the latest work, especially non-pixel-based approaches to data efficiency. This feedback is somewhat helpful as it highlights a gap in the literature review and encourages the authors to update their work to include more recent and relevant studies. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these updates or which recent works should be considered. Overall, the comment provides some direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper overstates the enhancement of the IM for most existing RL algorithms and lacks a comparison with the latest work, specifically mentioning SAC in 2018. It also highlights the absence of a comparison with non-pixel-based approaches to data efficiency. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific comparisons or updates should be made. The feedback is implicit and lacks concrete suggestions, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s emphasis on the enhancement of the IM for most existing RL algorithms and criticizes the lack of a comparison with the latest work, specifically mentioning SAC in 2018. It also points out the absence of a comparison with non-pixel-based approaches to data efficiency. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014recent work and comparisons with non-pixel-based approaches\u2014but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the enhancement of the IM for most existing RL algorithms and lacks a comparison with the latest work, specifically mentioning SAC in 2018. However, the comment does not provide specific examples or references to other recent work or non-pixel-based approaches that should be included. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential overstatement in the paper regarding the enhancement of the IM for most existing RL algorithms and points"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests expanding the background discussion in Section 2 to include further background knowledge on adversarial examples and threat models. It also recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA). The comment provides a clear and concrete action for the authors to take, specifying the areas that need to be expanded and the type of information that should be included. This level of detail makes the comment highly actionable, as it gives the authors a direct path to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and \"related work,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be expanded, including the background discussion on adversarial examples and threat models, and suggests referencing relevant surveys to clarify the threat model and position at the state-of-the-art. This level of detail provides clear direction for the authors to enhance their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion in Section 2 and related work to include further background knowledge on adversarial examples and threat models. It recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA). While the comment provides a logical suggestion for improvement, it lacks specific examples or references to surveys that could be used. This makes the claim somewhat verifiable, as the authors would need to identify and incorporate relevant surveys themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the background discussion in Section 2 by including further background knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA). This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their discussion, making it highly helpful. However, it could be further improved by suggesting specific surveys or examples to consider. Overall, the comment offers a constructive direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take to address this confusion. There is no guidance on how the authors might clarify this aspect or what specific information should be included to make the setting clearer. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of the proposed multiple-span answer setting in real-world applications. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the multiple-span answer setting are unclear or how it could be better explained. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question about the importance of the proposed multiple-span answer setting in real-world applications. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the importance of the proposed multiple-span answer setting in real-world applications. While it identifies a potential area of confusion, it does not provide any specific suggestions or guidance on how the authors might clarify this aspect in their paper. The feedback lacks depth and actionable advice, making it difficult for the authors to address the concern effectively. Therefore, the comment is rated as barely helpful, as it points out an area of confusion but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide a clear explanation of why this would be beneficial or how it would improve the paper. The action is implicit, as the authors need to infer that they should consider this suggestion, and it is vague because it lacks concrete guidance on implementation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers, \"558\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors consider mixing train set examples with hypernyms and non-hypernyms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach to the current methodology by proposing to mix train set examples with hypernyms and non-hypernyms. However, the comment does not provide any justification or reasoning for why this approach would be beneficial or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an alternative approach to the current methodology by proposing to mix train set examples with hypernyms and non-hypernyms. This feedback is somewhat helpful as it identifies a potential area for improvement by offering a specific suggestion that could enhance the paper. However, the comment lacks depth and does not provide a clear rationale or explanation for why this approach might be beneficial. Additionally, it does not offer guidance on how to implement this suggestion or why it would lead to better results. To be more helpful, the comment could include a justification for the proposed change or discuss potential benefits. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests an alternative approach by proposing to mix train set examples with hypernyms and non-hypernyms. However, it does not provide explicit instructions or guidance on how to implement this suggestion or explain why it might be beneficial. The action is implicit and lacks concrete details, making it barely actionable. The authors may infer that they should consider this suggestion, but they are left without clear steps to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers, \"558\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a potential improvement by mixing train set examples with hypernyms and non-hypernyms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach by proposing to mix train set examples with hypernyms and non-hypernyms. However, it does not provide any justification or reasoning for why this approach would be beneficial or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an alternative approach by proposing to mix train set examples with hypernyms and non-hypernyms. This feedback is somewhat helpful as it identifies a potential area for improvement by offering a specific suggestion that could enhance the paper. However, the comment lacks depth and does not provide a clear rationale or explanation for why this approach might be beneficial or how it would improve the paper. Without additional context or guidance, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests an alternative approach by proposing to mix train set examples with hypernyms and non-hypernyms. However, it does not provide explicit instructions or guidance on how to implement this suggestion or explain why it might be beneficial. The action is implicit and lacks concrete details, making it barely actionable. The authors may infer that they should consider this suggestion, but they are left without clear steps to follow. Therefore, the comment aligns with a score of 2.', 'actionability_label': '2', 'grounding_specificity_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to provide results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results presented for AdpCLR_pre in Table 1. This is a clear and direct action, specifying exactly what the authors need to do to improve their draft. The comment is explicit and concrete, leaving no ambiguity about the necessary steps to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the provision of results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results provided for AdpCLR_pre. This provides clear guidance on what needs to be addressed or added to the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information regarding the results of the AdpCLR_full approach for the ResNet-50 architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area where the authors could provide additional information. By asking for results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results provided for AdpCLR_pre in Table 1, the reviewer is guiding the authors to enhance the completeness and comparability of their results. This feedback is clear and actionable, prompting the authors to include more data that could strengthen their analysis. However, the comment could be more helpful if it explained why this additional information is important or how it could impact the interpretation of the results. Overall, the comment provides valuable insight into improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether N trajectories are similar concepts to replay in the Dyna model. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this question is a concern, a suggestion for improvement, or a point that needs clarification. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or explanation about why this similarity is important or how it might impact the paper. Without clear grounding or specificity, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it raises an interesting point that could prompt the authors to clarify or address in their paper, it lacks depth and does not provide any actionable feedback or suggestions for improvement. The comment does not indicate whether this similarity is relevant to the paper\\'s findings or if it requires further exploration. Without additional context or guidance, the authors may find it challenging to determine the significance of this question or how to address it in their draft. Therefore, the comment is barely helpful, as it points out an area for potential clarification but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiment results are suspicious, specifically mentioning that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. While this observation highlights a potential issue, it does not provide explicit guidance on what the authors should do to address this concern. The comment lacks concrete suggestions, such as recommending a specific analysis or correction to verify the results. As a result, the authors are left without clear instructions on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a suspicious issue with the experiment results, particularly the sharing of the same result between the two tables when changing the 2-hop EG into 3-hop EG. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. This claim is somewhat verifiable as it highlights a potential issue with the consistency of the results. However, the comment lacks detailed reasoning or evidence to substantiate why this discrepancy is suspicious or how it impacts the validity of the findings. Without further explanation or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment results, noting that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. This observation highlights a potential inconsistency or error in the experimental setup or analysis. However, the comment does not provide any suggestions or guidance on how the authors might investigate or address this issue, such as verifying the results or conducting additional analyses. While it points out a problem, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a suspicious issue with the experiment results, specifically mentioning that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. However, it does not provide any guidance or suggestions on how the authors should address this issue or investigate the discrepancy. The comment lacks explicit instructions or concrete steps for the authors to take, making it unactionable. Without actionable feedback, the authors are left without a clear path to improve their draft based on this comment.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a suspicious issue with the experiment results, particularly the sharing of the same result between the two tables when changing the 2-hop EG into 3-hop EG. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. This observation highlights a potential issue with the consistency of the results. However, the comment lacks detailed reasoning or evidence to substantiate why this discrepancy is suspicious or how it impacts the validity of the findings. Without further explanation or examples, the authors may find it challenging to understand and address the concern. Therefore, the claim is somewhat verifiable, as it points out a potential issue but lacks sufficient justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment results, noting that Tables 16 and 17 share the same result, even when changing the 2-hop EG into 3-hop EG. This observation highlights a potential inconsistency or error in the experimental setup or analysis. However, the comment does not provide any suggestions or guidance on how the authors might investigate or address this issue, such as verifying the results or conducting additional analyses. While it points out a problem, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the experimental results show some advantages of the proposed algorithms but that these advantages are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of significance or improve the competitiveness of their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experimental results show some advantages of the proposed algorithms but that these advantages are not very significant. It also notes that the results are still competitive with state-of-the-art algorithms. However, the comment does not specify which part of the paper these results are discussed in, nor does it provide details on what aspects of the results are considered not significant or competitive. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but that these advantages are not very significant. It also states that the results are still competitive with state-of-the-art algorithms. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or comparisons, the authors may find it challenging to understand the basis of the reviewer\\'s assessment and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. Without identifying particular aspects of the results that need further exploration or clarification, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the overconfidence or improve the protocol. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the per-sentence assessment protocol and its potential issue with LLM (Language Learning Models) overconfidence. However, it does not specify which part of the paper this assessment protocol is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this protocol is mentioned, the comment lacks full grounding. It is specific about the issue of overconfidence but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or a clear explanation of how overconfidence might manifest in the protocol, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve the protocol. The feedback highlights a potential weakness but does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate overconfidence or improve the protocol. As a result, the authors are left without any actionable steps to follow, making the comment unactionable. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not specify which part of the paper discusses this protocol, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of overconfidence, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of how overconfidence might manifest in the protocol, the authors may find it challenging to understand and address the issue. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the protocol. The feedback identifies a potential weakness but lacks actionable advice, making it somewhat helpful. The authors are given some insight into a potential problem but are not directed on how to resolve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a concern about the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate overconfidence or improve the protocol. As a result,"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim that minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity modeling. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how the authors might investigate or clarify this point, or if there are specific aspects of the methodology that need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3\" and \"App. C,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning what makes the approach reflect only non-semantic diversity, which is a specific concern about the methodology. This provides clear guidance on what aspect of the paper needs further clarification or explanation. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the methodology described in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methodology described in the paper, specifically regarding the claim that minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity modeling. While it identifies a potential area of confusion or lack of clarity, it does not provide any suggestions or guidance on how the authors might address this issue or clarify their methodology. The comment highlights a point of interest but lacks actionable feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the experimental results, asking whether they are due to the method\\'s superiority or an accidental result from a specific kernel function and feature map. While the question implies that the authors should consider this aspect in their analysis, it does not provide explicit guidance or suggestions on how to address this concern. The action is implicit and lacks concrete details, leaving the authors to infer that they should explore the potential causes of the results. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the experimental results, specifically asking whether they are due to the method\\'s superiority or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the results section, but this inference is not direct. The comment is specific in its inquiry about the potential causes of the results but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experimental results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the experimental results, specifically asking whether they are due to the method\\'s superiority or an accidental result from a specific kernel function and feature map. This question prompts the authors to consider the robustness and generalizability of their findings, which is a valuable insight for improving the draft. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or what additional analyses could be conducted to clarify the results. While it identifies a critical area for exploration, the feedback lacks actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any explicit or implicit action for the authors to take. The comment simply points out the absence of information without suggesting how the authors should address this issue or where they should add this description. As a result, the authors are left without any guidance on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not specify where in the paper this issue is discussed, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the algorithm is described, the comment lacks full grounding. It is specific in pointing out the absence of a description, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential oversight in the paper, specifically the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. This is a relevant observation that could help the authors ensure completeness and clarity in their work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as where in the paper this information should be included or how it should be presented. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable steps or suggestions for improvement, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not specify where in the paper this issue is discussed, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in pointing out the absence of information, it lacks full grounding as it does not provide explicit references to sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper, specifically the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. This is a relevant observation that could help the authors ensure completeness and clarity in their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as where in the paper this information should be included or how it should be presented. While it points out an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or where in the paper this information should be included. Without specific suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, the comment is unaction"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should discuss the computational costs associated with training their proposed method, which involves complex components like modified Gromov-Hausdorff distances and hypergraph structures. While the comment implies that a discussion of these costs is necessary, it does not explicitly instruct the authors to include this discussion or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should address the computational costs but are not given specific steps on how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures. It also references Appendix B, which suggests that the authors have theoretically analyzed the time complexity of each component. However, the comment lacks specificity regarding what aspects of the computational costs associated with training should be discussed. While it provides some context, it does not clearly identify the exact parts of the paper that need revision or expansion. Therefore, the comment is weakly grounded because it does not specify the exact sections, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the proposed method is complex due to its reliance on modified Gromov-Hausdorff distances and hypergraph structures, which likely increase the time complexity. The reviewer acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment provides some reasoning by mentioning the complexity and the theoretical analysis, it lacks specific examples or detailed evidence to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper, specifically the complexity of the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is somewhat helpful as it points out an area for improvement and provides a clear direction for the authors to enhance their paper. However, it could be more helpful if it offered specific suggestions on how to address the computational costs or provided examples of similar discussions in other works. Overall, the comment provides valuable insight but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the authors should discuss the computational costs associated with training their proposed method, which involves complex components like modified Gromov-Hausdorff distances and hypergraph structures. While the comment implies that a discussion of these costs is necessary, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should address the computational costs but are not given clear steps on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. While it provides some context, it does not specify which part of the paper should include this discussion or how it should be integrated. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is also not specific in detailing what needs to be discussed regarding the computational costs. Therefore, this comment aligns with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the proposed method is complex due to its reliance on modified Gromov-Hausdorff distances and hypergraph structures, which likely increase the time complexity. The reviewer acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment provides some reasoning by mentioning the complexity and the theoretical analysis, it lacks specific examples or detailed evidence to fully substantiate the"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern that the proposed method may not be groundbreaking and lacks clear differentiation from existing contrastive decoding techniques. However, it does not provide explicit guidance on how the authors could address this issue or improve the distinction of their method. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance the novelty and clarity of their approach. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the novelty and differentiation of the proposed method within the context of existing contrastive decoding techniques. However, it does not specify which part of the paper discusses the method or where the lack of distinction is most apparent. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where the method is discussed, the comment lacks full grounding. It is specific about the issue of lack of novelty and differentiation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method may not be groundbreaking and lacks clear differentiation from existing contrastive decoding techniques. However, the comment does not provide specific examples or references to existing techniques that are similar to the proposed method, nor does it offer detailed reasoning or evidence to support the claim. This lack of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty and differentiation of the proposed method within the context of existing contrastive decoding techniques. It highlights that the paper may not present groundbreaking innovation, despite effectively building upon existing strategies. However, the comment lacks specific suggestions or guidance on how the authors could enhance the novelty or differentiate their approach from existing work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment highlights a concern about the novelty and differentiation of the proposed method from existing contrastive decoding techniques. However, it does not provide specific guidance or suggestions on how the authors could address this issue or enhance the novelty of their approach. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to improve their draft. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the novelty and differentiation of the proposed method within the context of existing contrastive decoding techniques. However, it does not specify which part of the paper discusses the method or where the lack of distinction is most apparent. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some insight into the issue, it lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with category 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the proposed method may not be groundbreaking and lacks clear differentiation from existing contrastive decoding techniques. However, the comment does not provide specific examples or references to existing techniques that are similar to the proposed method, nor does it offer detailed reasoning or evidence to support the claim. This lack of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty and differentiation of the proposed method from existing contrastive decoding techniques. It highlights that the paper may not present groundbreaking innovation, despite effectively building upon existing strategies. However, the comment lacks specific suggestions or guidance on how the authors could enhance the novelty or differentiate their approach from existing work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment highlights a concern about the novelty and differentiation of the proposed method from existing contrastive decoding techniques. However, it does not provide specific guidance or suggestions on how the authors could address this issue or enhance the novelty of their approach. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to improve their draft. As a result, the comment is unactionable.\", 'actionability_label':"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the tabular representation of node agent interactions in Figure 4 is not intuitive. However, it does not provide any explicit guidance or suggestions on how to improve the representation or make it more intuitive. The authors are left to infer that they need to revise the figure to enhance its clarity, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, it lacks specificity as it does not provide details on what makes the tabular representation of node agent interactions unintuitive or suggest how it could be improved. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that \"Figure 4\\'s tabular representation of node agent interactions is not intuitive.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is considered unintuitive. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. While it points out a potential problem, it lacks depth and does not provide suggestions or guidance on how to improve the figure\\'s clarity or intuitiveness. Without actionable feedback or specific recommendations, the authors are left with only a vague understanding of what needs to be addressed. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit guidance or suggestions on how to improve the figure\\'s clarity or intuitiveness. The authors are left to infer that they need to revise the figure, but without specific instructions, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, it lacks specificity as it does not provide details on what makes the tabular representation of node agent interactions unintuitive or suggest how it could be improved. Without specific guidance or examples, the authors may struggle to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that \"Figure 4\\'s tabular representation of node agent interactions is not intuitive.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is considered unintuitive. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. However, it lacks depth and does not provide any suggestions or guidance on how to improve the figure\\'s clarity or intuitiveness. Without actionable feedback or specific recommendations, the authors are left with only a vague understanding of what needs to be addressed. This limits the comment\\'s usefulness, making it barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit guidance or suggestions on how to improve the figure\\'s clarity or intuitiveness. The authors are left to infer that they need to revise the figure, but without specific instructions, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, it lacks specificity as it does not provide details on what makes the tabular representation of node agent interactions unintuitive or suggest how it could be improved. Without specific guidance or examples, the authors are left to infer the necessary changes, making the comment under-specific. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the appropriateness of other frameworks besides PU as baselines and the impact of the PU loss on calibration. While these questions imply that the authors should consider these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors are left to infer that they should explore alternative baselines and consider the impact of the PU loss on calibration, but without specific suggestions or examples, the actions remain vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two points: the appropriateness of other frameworks besides PU as baselines and the impact of the PU loss on calibration. However, it does not specify which part of the paper these points pertain to, making it weakly grounded. The comment is specific in suggesting that other frameworks besides PU might be appropriate and questioning the impact of the PU loss on calibration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the appropriateness of baselines and the impact of the PU loss on calibration. It suggests considering other frameworks besides PU and questions the impact on calibration. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims or suggestions. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions that could significantly impact the evaluation and interpretation of the paper. First, it questions whether other frameworks besides PU might be more appropriate as baselines, suggesting the consideration of noise-aware losses. This prompts the authors to broaden their perspective on potential baselines, which could lead to a more comprehensive evaluation of their method. Second, the comment questions how the use of the PU loss impacts calibration, which is crucial for downstream applications. This highlights a critical aspect of the paper that may need further exploration. While the comment identifies key areas for consideration, it lacks specific guidance or suggestions on how to address these questions, making it somewhat helpful. The authors are given valuable insights but are left to determine the best course of action themselves.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. However, it does not provide explicit guidance on how the authors should revise their characterization or what specific changes they should make to align with the reviewer\\'s understanding. The comment lacks actionable details, such as suggesting alternative terminology or providing examples of how to better describe the phenomena. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. However, it does not specify which part of the introduction this characterization is found, making it weakly grounded. The comment is specific in its critique of the characterization, providing a clear explanation of the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. The reviewer provides a logical explanation by contrasting TL with MTL and fine-tuning with a sequential approach. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from more detailed evidence or references to better understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. While it provides a clear distinction between TL and MTL, it does not offer specific suggestions or guidance on how the authors might improve their characterization or presentation of these concepts. The comment highlights a potential misunderstanding or mischaracterization but lacks actionable feedback or detailed advice on how to address it. As a result, the comment is somewhat helpful, as it identifies an area for clarification but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. However, it does not provide explicit guidance or suggestions on how the authors should revise their characterization or improve their understanding of these concepts. The comment lacks actionable details, leaving the authors without a clear path to address the feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. However, it does not specify which part of the introduction this characterization is found, making it weakly grounded. The comment is specific in its critique of the characterization, providing a clear explanation of the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. The reviewer provides a logical explanation by contrasting TL with MTL and fine-tuning with a sequential approach. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from more detailed evidence or references to better understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term and that fine-tuning is a sequential approach. While it provides a clear distinction between TL and MTL, it does not offer specific suggestions or guidance on how the authors might improve their characterization or presentation of these concepts. The comment highlights a potential misunderstanding or mischaracterization but lacks actionable feedback or detailed advice on how to address it. As a result, the comment is somewhat helpful,"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is considered important. This provides a clear and direct action for the authors to take, namely to include a Limitation section in their paper. The comment is specific and actionable, as it gives the authors a specific area to address and improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of a \"Limitation section,\" which is considered important. However, it does not specify where this section should be included or what specific limitations should be addressed. The authors can infer that it relates to the conclusion or discussion sections, but this inference is not direct. The comment is specific in identifying the missing section but lacks grounding as it does not specify where it should be added or what specific limitations should be discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation section,\" which is considered important. However, the comment does not provide any reasoning, examples, or references to support why this section is necessary or how its absence impacts the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of a \"Limitation section\" in the paper. This is a clear and actionable suggestion that can help the authors enhance the completeness and transparency of their work. By addressing this feedback, the authors can provide a more balanced and honest evaluation of their research, which is beneficial for both the paper and the field. However, the comment could be more helpful if it offered examples of what types of limitations should be included or how to structure the section. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their draft that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests that Section 2.1 needs more detailed explanations regarding the theory behind diffusion models. It also points out that Section 2.2 lacks explanations about CLIP guidance using global and local directional losses. Additionally, it mentions that the works of Choi et al. (2021) and Meng et al. (2021) are not explained in Section 3.2. Finally, it notes that the captions of figures are often not explanatory. Each of these points provides a clear and specific action for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 2.1,\" \"Section 2.2,\" and \"Section 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in each section, such as the need for more detailed explanations in Section 2.1 regarding the theory behind diffusion models, the explanation of CLIP guidance in Section 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it points out that the captions of figures are often not explanatory, providing specific examples. This level of detail makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the paper, including the need for more detailed explanations in Section 2.1 regarding the theory behind diffusion models, the explanation of CLIP guidance in Section 2.2, and the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it mentions that the captions of figures are often not explanatory. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it challenging for the authors to fully understand and address the issues raised. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying several areas where the paper could be improved. It highlights the need for more detailed explanations in Section 2.1 regarding the theory behind diffusion models, which is crucial for understanding the methodology. Additionally, it points out the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2, suggesting that these references should be better integrated into the discussion. The comment also notes that the captions of figures are often not explanatory, providing examples of figures where this issue occurs. This feedback is clear and constructive, offering the authors specific directions for enhancing the clarity and comprehensiveness of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the title of the paper should include the term \"tensor completion\" because this is the only application of the new model that is presented in the paper. This feedback provides a clear and direct action for the authors to take, which is to modify the title to include the specified term. The suggestion is concrete, as it specifies exactly what change is needed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title of the paper should include the term \"tensor completion\" because this is the only application of the new model presented in the paper. However, it does not specify which part of the paper discusses the tensor completion application, making it weakly grounded. The comment is specific in its suggestion to include the term \"tensor completion\" in the title, but without clear grounding, the authors may struggle to identify where this suggestion fits into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title should include the term \"tensor completion\" because this is the only application of the new model presented in the paper. However, the comment does not provide any supporting evidence or reasoning to justify why this term is crucial for the title. Without additional context or explanation, the authors may find it challenging to understand the importance of including this term. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the title of the paper should include the term \"tensor completion\" because this is the only application of the new model presented in the paper. This feedback is clear and actionable, as it provides a specific suggestion for improving the title to better reflect the content of the paper. By following this advice, the authors can enhance the accuracy and relevance of their title, making it more informative for readers. However, the comment could be more helpful if it explained why the term \"tensor completion\" is important or how it impacts the paper\\'s focus. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should compare their proposed method to other prior methods or implement a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison that could be made, but it is stated implicitly. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment addresses the lack of comparison to prior methods, specifically suggesting that the authors should implement a simple baseline like character frequencies to provide a more comprehensive empirical evaluation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or evaluation sections where comparisons are discussed. The suggestion is specific, as it provides a clear direction for improvement by recommending a particular type of baseline. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the authors' method is insufficiently evaluated, as they only show statistically significant linear regressions without comparing it to other prior methods. The reviewer suggests implementing a simple baseline, such as character frequencies, to make the paper more persuasive. While the comment provides a logical reasoning for the need for additional comparisons, it lacks specific examples or references to prior methods that could be compared to the proposed method. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation, noting that the authors have not compared their proposed method to other prior methods. It suggests that the authors should implement a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. This feedback is clear and actionable, offering a specific direction for the authors to enhance the persuasiveness and robustness of their work. By addressing this point, the authors can significantly improve the quality and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}{'actionability_rationale': \"The review comment suggests that the authors should compare their proposed method to other prior methods or implement a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The suggestion is concrete, as it specifies the type of comparison that could be made, but it is stated implicitly. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment identifies a specific issue with the paper's evaluation, noting the lack of comparison to prior methods or simple baselines like character frequencies. It suggests that implementing such comparisons would enhance the paper's persuasiveness. However, the comment does not explicitly mention a specific section of the paper where this comparison should be made, leaving the authors to infer that it relates to the results or evaluation sections. While the suggestion is specific, the lack of explicit grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the authors' evaluation is insufficient because they only show statistically significant linear regressions without comparing their method to other prior methods. The reviewer suggests implementing a simple baseline, such as character frequencies, to provide a more comprehensive evaluation. While the comment logically argues for additional comparisons, it lacks specific examples or references to prior methods that could be compared to the proposed method. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation, noting that the authors have not compared their proposed method to other prior methods. It suggests implementing a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. This feedback is clear and actionable, offering a specific direction for the authors to enhance the persuasiveness and robustness of their work. By addressing this point, the authors can significantly improve the quality and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}{'actionability_rationale': \"The review comment suggests that the authors should compare their proposed method"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a potential limitation in the proposed method's ability to reduce computational load in real applications. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer highlights that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or improve the method's practicality. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the practicality of the proposed method in reducing computational load. It highlights a potential limitation in the method\\'s ability to apply a uniform activation pattern across all tokens, which could impact its efficiency. The comment provides a detailed explanation of the issue, including the reliance on precomputed PPL and activation patterns that may not generalize well. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its implications, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the proposed method in reducing computational load, particularly in real applications. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer supports this claim by discussing the reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the proposed method's ability to reduce computational load in real applications. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer highlights that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. This feedback is valuable as it points out a critical issue that could impact the practicality and efficiency of the method. However, the comment could be more helpful if it provided suggestions on how to address this limitation or improve the method's practicality. Overall, the comment is somewhat helpful as it identifies a significant concern but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential limitation in the proposed method's ability to reduce computational load in real applications. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer highlights that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve the method's practicality. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the practicality of the proposed method in reducing computational load. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer highlights the reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its implications, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the proposed method in reducing computational load, particularly in real applications. It explains that different tokens activate different channels, making it challenging to apply a uniform activation pattern across all tokens. The reviewer supports this claim by discussing the reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens. However, the comment lacks specific examples or references to"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the core motivation of the paper, specifically noting that the abstract does not effectively convey the main problem to be solved. The reviewer points out that the statements in the abstract are stacked and do not clearly capture the main issue. However, the comment does not provide explicit guidance on how the authors should clarify the core motivation or what specific changes should be made to the abstract. The action is implicit and vague, as the authors are left to infer that they need to restructure the abstract to better articulate the core motivation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the core motivation of the paper, which is not clearly articulated in the abstract. It highlights the stacked statements in the abstract that do not effectively capture the main problem to be solved. However, the comment does not specify which part of the abstract or the paper should be revised to improve clarity. While the authors might infer that the abstract is being referred to, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue with the stacked statements and the need for clearer motivation. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, citing the stacked statements in the abstract as evidence. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues with the motivation. The lack of explicit examples or references to specific statements in the abstract renders the claim borderline verifiable, as it requires more detailed justification to be fully actionable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the paper\\'s core motivation, specifically noting that the abstract does not effectively convey the main problem to be solved. It highlights the stacked statements in the abstract, which make it difficult to grasp the core motivation. While the comment points out a significant weakness, it lacks specific suggestions or guidance on how the authors might clarify the motivation or restructure the abstract to better articulate their core problem. This limits the comment\\'s usefulness to the authors, as it provides only a general direction for improvement without detailed actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of clarity in the core motivation of the paper, specifically noting that the abstract does not effectively convey the main problem to be solved. However, it does not provide explicit guidance on how the authors should clarify this motivation or suggest specific changes to the abstract. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to address the issue. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the core motivation of the paper, specifically noting that the abstract does not effectively convey the main problem to be solved. It highlights the stacked statements in the abstract that make it difficult to understand the core motivation. However, the comment does not specify which part of the abstract or the paper should be revised to improve clarity. While the authors might infer that the abstract is being referred to, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue with the stacked statements but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, citing the stacked statements in the abstract as evidence. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without explicit examples or references to specific statements, the authors may find it challenging to understand the exact issues with the motivation. This lack of detailed justification makes the claim borderline verifiable, as it requires more information to be actionable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the paper\\'s core motivation, noting that the abstract does not effectively convey the main problem to be solved. It highlights the stacked statements in the abstract, which make it difficult to grasp the core motivation. However, the comment lacks specific suggestions or guidance on how the authors might clarify the motivation or restructure the abstract to better articulate their core problem. While it points out a significant area for improvement, the feedback is not detailed enough to be fully actionable. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used for filtering data and questions the nature of the data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is clear but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses concerns about the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the classifier is discussed. The suggestion to provide examples of the filtered data adds specificity to the comment. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used for filtering data, questioning the nature of the data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for examples provides a direction for improvement, but the initial claim remains somewhat vague. Therefore, the comment is categorized as somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It notes that the task of filtering data using the task description seems different from the original MNLI distribution and suggests that examples of the filtered data would be helpful. This feedback is somewhat helpful as it identifies a potential area of confusion and provides a clear suggestion for improvement by requesting examples. However, it could be more helpful if it offered specific guidance on how to address the issue or provided additional context about the expected outcomes. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used for filtering data, questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is clear but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses concerns about the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the classifier is discussed. The suggestion for examples adds specificity to the comment. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used for filtering data, questioning the nature of the data that passes this filter. The reviewer notes that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for examples provides a direction for improvement, but the initial claim remains somewhat vague. Therefore, the comment is categorized as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It notes that the task of filtering data using the task description is different from the original MNLI distribution and suggests that examples of the filtered data would be helpful to better understand the process. This feedback is somewhat helpful as it identifies a potential area of confusion and provides a clear suggestion for improvement by requesting examples. However,"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies several issues with the application experiments, including potential biases due to the reliance on a single model and a small dataset. It suggests that the authors need to conduct comprehensive experiments to validate the effectiveness of their proposed methods. Additionally, the comment points out specific issues with the paper's structure, argumentation, and language clarity, such as chaotic equation numbering and the lack of indentation in Algorithm 1. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to address these issues. The authors are given clear directions on what needs to be improved, but the lack of specific suggestions for each point makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the application experiments and provides specific details about the issues, such as the reliance on a single model (DALL-E) and a small dataset (30 famous paintings and 30 generated paintings). It also highlights the need for comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, it provides specific examples of structural issues, such as chaotic equation numbering and the lack of indentation in Algorithm 1. This level of detail allows the authors to clearly identify the parts of the paper that need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the application experiments may have biases due to the reliance on a single model and a small dataset. The reviewer supports this claim by explaining that the experiment results are difficult to be convincing without comprehensive experiments. The comment also highlights specific issues, such as chaotic equation numbering and the lack of indentation in Algorithm 1, which contribute to the overall critique. While the comment provides some reasoning and examples, it could be strengthened by referencing specific studies or methodologies that demonstrate the importance of diverse datasets and models in validating results. As it stands, the claim is mostly verifiable, as it provides a logical basis for the critique but lacks comprehensive evidence or references. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the application experiments, noting that the reliance on a single model (DALL-E) and a small dataset (30 famous paintings and 30 generated paintings) may introduce biases. This feedback is valuable as it highlights the need for more comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, the comment points out specific structural issues, such as chaotic equation numbering and the lack of indentation in Algorithm 1, which can affect the paper's clarity and professionalism. While the comment provides actionable suggestions for improving the paper's structure and language clarity, it could be more helpful by offering specific examples or guidance on how to address these issues. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider discussing the practical applications of their model in real-world tasks, given that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. While the comment implies that the authors should provide a discussion on the practical applications, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to approach this discussion or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on practical applications but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical applications of the model discussed in the paper, specifically mentioning the experiments conducted on datasets created by concatenating manipulated samples from standard benchmarks. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for the authors to comment on the practical applications of their model, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practical applications of the model, noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer suggests that there might be real tasks with available data that would benefit from such a model. However, the comment lacks specific examples or references to support the claim that the model could be applied to real-world tasks. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the practical applications of the model discussed in the paper. It points out that while the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks, there may be real-world tasks with available data that would benefit from such a model. The comment encourages the authors to consider and discuss the practical applications of their work, which is a valuable suggestion for expanding the context and relevance of the research. However, the comment could be more helpful if it provided specific examples or guidance on how to identify or address these practical applications. Overall, the feedback is somewhat helpful as it prompts the authors to think about the broader implications of their work, but it lacks detailed direction for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should discuss the practical applications of their model, given that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. While the comment implies that the authors should provide a discussion on the practical applications, it does not explicitly instruct them to do so. Additionally, it lacks specific guidance on how to approach this discussion or what aspects to focus on. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the practical applications of the model discussed in the paper, noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. It suggests that there might be real-world tasks with available data that would benefit from such a model and requests the authors to comment on this. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The suggestion is specific in its request for a discussion on practical applications, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practical applications of the model, noting that the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks. The reviewer suggests that there might be real-world tasks with available data that would benefit from such a model and requests the authors to comment on this. While the comment raises a valid point about the practical relevance of the model, it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises an important question about the practical applications of the model discussed in the paper. It points out that while the experiments are conducted on datasets created by concatenating manipulated samples from standard benchmarks, there may be real-world tasks with available data that would"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the CAL-MIR selection of m, asking whether it is done exhaustively over all loss minimizer subsets. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the selection process. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the CAL-MIR selection of m, specifically asking whether it is done exhaustively over all loss minimizer subsets. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the CAL-MIR selection of m, specifically whether it is done exhaustively over all loss minimizer subsets. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the CAL-MIR selection of m, specifically asking whether it is done exhaustively over all loss minimizer subsets. This question highlights a potential area of confusion or lack of clarity in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential weakness, it lacks actionable feedback or specific advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider other backdoor detection methods that are input data-free, such as those involving weight matrix statistics or matrix factorization, in their analysis of algorithm performance. While the comment explicitly states the need to include these methods, it does not provide specific guidance on how to integrate them into the analysis or what aspects of the existing methods should be compared. The action is clear but lacks detailed instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods, such as those involving weight matrix statistics or matrix factorization, which should be included in the analysis of algorithm performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods, such as those involving weight matrix statistics or matrix factorization. While the comment identifies specific methods that could be relevant, it does not provide detailed reasoning or evidence to support why these methods should be included or how they would enhance the analysis. The lack of explicit justification or references makes the claim somewhat verifiable, as the authors would need to further explore and verify the relevance of these methods themselves.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper's analysis by suggesting that the authors consider other backdoor detection methods that are input data-free. It provides a clear and actionable suggestion to include methods like weight matrix statistics or matrix factorization in the analysis of algorithm performance. This feedback is valuable as it guides the authors to expand their evaluation and potentially enhance the robustness of their findings. However, the comment could be more helpful if it offered additional context or examples of how these methods could be integrated into the analysis. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies two areas that need attention: the completeness of the relation works section and the need to describe the view of the knowledge graph in the problem definition methodology. The first part of the comment suggests that the relation works section is incomplete, but it does not specify what aspects are missing or how to address this issue. The second part of the comment is more actionable, as it explicitly instructs the authors to describe the view of the knowledge graph in the problem definition methodology. However, it lacks concrete guidance on how to categorize the views or what specific details should be included. Overall, the comment provides some direction but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section\" and the \"problem definition methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the completeness of the relation works section and the need to describe the view of the knowledge graph in the problem definition methodology. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works section\" is incomplete and that the authors need to describe the view of the knowledge graph in the problem definition methodology. However, the comment does not provide specific examples or detailed reasoning to support why these aspects are incomplete or how they should be addressed. The lack of explicit justification or references makes it difficult for the authors to understand the basis of the claim and how to improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires improvement, namely the completeness of the \"relation works section.\" It also points out a need for clarity in the problem definition methodology, specifically asking the authors to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies two specific areas for improvement: the completeness of the \"relation works section\" and the need to describe the view of the knowledge graph in the problem definition methodology. While the comment clearly states what needs to be addressed, it lacks detailed guidance on how to achieve these improvements. The authors are informed of the areas that require attention but are not provided with specific instructions on how to enhance them. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section\" and the \"problem definition methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the completeness of the relation works section and the need to describe the view of the knowledge graph in the problem definition methodology. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works section\" is incomplete and that the authors need to describe the view of the knowledge graph in the problem definition methodology. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide clear guidance on what aspects of the relation works section are incomplete or how the description of the knowledge graph view should be improved. This makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper: the completeness of the \"relation works section\" and the need to describe the view of the knowledge graph in the problem definition methodology. By pointing out these areas, the comment provides clear and actionable feedback that can help the authors enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the feedback is mostly helpful as"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines, as the optimization is a downstream task that is expected to be the same regardless of the regression mechanism. While the comment implies that the authors should add this comparison, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides concrete guidance on what aspect of the paper should be addressed. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the metric used, specifically mentioning the optimality gap and the contribution of the paper. It suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines. However, it does not specify which part of the paper this feedback pertains to, such as specific sections or experiments. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in suggesting what needs to be addressed but does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the relevance of the optimality gap as a metric for the paper's contribution, which is centered around regression for prediction. The reviewer suggests that the optimization task is a downstream process and should not be the focus of the contribution. However, the comment lacks specific examples or references to support the claim that the optimality gap is not a relevant metric for the paper's contribution. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential mismatch between the problem setup and the metric used, specifically questioning whether the optimality gap is the right metric for the contribution. It suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines, as the optimization is a downstream task that is expected to be the same regardless of the regression mechanism. This feedback is clear and actionable, providing a specific direction for the authors to enhance their draft by comparing their method's performance on the primary task. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or suggested specific baselines to consider. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines, as the optimization task is a downstream process that is expected to be the same regardless of the regression mechanism. While the comment implies that the authors should add this comparison, it does not explicitly instruct them to do so. The suggestion is clear but inferred, and the authors may need to infer the exact action to take. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the metric used, specifically questioning whether the optimality gap is the right metric for the contribution. It suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines. However, it does not specify which part of the paper this feedback pertains to, such as specific sections or experiments. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in suggesting what needs to be addressed but does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the relevance of the optimality gap as a metric for the paper's contribution, which is centered around regression for prediction. The reviewer suggests that the authors should include the accuracy of their method on the regression task compared to strong baselines. While the comment provides a logical reasoning for why the optimality gap might not be the right metric, it lacks specific examples or references to support this claim. The suggestion to compare accuracy with strong baselines is a reasonable point, but the comment could be strengthened by providing more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is somewhat verifiable, as it offers a logical reasoning but requires additional support to be fully convincing.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential mismatch between the problem setup and the metric used, specifically questioning whether the optimality gap is the right metric for"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It also points out that the update derivation for these parameters is not convincing. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes are needed to strengthen the theoretical support. The feedback is implicit and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"technical design\" and references specific equations (Eq.7-10), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of theoretical support for the design and the unconvincing nature of the update derivation for intrinsic reward parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the technical design lacks theoretical support, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references Sorg et al. (2010) as a source for the design, which provides some context. However, the comment does not provide detailed reasoning or specific examples to support the claim that the update derivation is unconvincing. While the reference to Sorg et al. is a step towards verification, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to further explore the reference to fully understand and address the critique.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the technical design, specifically the lack of theoretical support for the update of intrinsic reward parameters. It acknowledges the need for justification regarding the design but points out that the update derivation for these parameters is not convincing. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to strengthen the theoretical foundation of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending additional references or methods to support the theoretical framework. Overall, the comment is somewhat helpful as it directs the authors' attention to a crucial aspect of their work that requires further development, but it lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It also points out that the update derivation for these parameters is not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve the theoretical support. The feedback is implicit and lacks concrete steps, making it barely actionable. The authors are left uncertain about how to enhance the theoretical foundation of their work.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"the technical design\" and \"Eq.7-10,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of theoretical support for the design and the unconvincing nature of the update derivation for intrinsic reward parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references Sorg et al. (2010) as a source for the design, which provides some context. However, the comment does not provide detailed reasoning or specific examples to support the claim that the update derivation is unconvincing. While the reference to Sorg et al. is a step towards verification, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to further explore the reference to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the technical design, specifically the lack of theoretical support for the update of intrinsic reward parameters. It acknowledges the need for justification regarding the design but points out that the update derivation for these parameters is not convincing. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to strengthen the theoretical foundation of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending additional references or methods to support the theoretical"}
{"generated_text": "{'actionability_rationale': \"The review comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it is not adaptive as it relies on picking a 'small enough' beta parameter. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might modify their claims or approach to better align with adaptive methods like AdaGrad. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it relies on picking a \"small enough\" beta parameter, which is not adaptive. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where the adaptive variance reduction property is mentioned. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its critique of the adaptive property, it is weakly grounded because it does not provide clear guidance on where to make improvements. Therefore, this comment aligns with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point challenges the authors\\' claim of an \"adaptive variance reduction property\" by suggesting that it is essentially based on selecting a \"small enough\" beta parameter, which is not adaptive. The reviewer provides a counterpoint by referencing adaptive methods like AdaGrad, implying that the authors\\' claim does not align with typical adaptive methods. However, the comment lacks specific examples or references to AdaGrad or other adaptive methods to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a logical critique but requires more detailed evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the authors' claim of an adaptive variance reduction property, suggesting that it is essentially based on selecting a 'small enough' beta parameter, which is not adaptive. This feedback identifies a potential weakness in the authors' argument and provides a counterpoint by referencing adaptive methods like AdaGrad. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their claim. While it highlights an area for improvement, the feedback could be more helpful if it offered actionable advice or examples on how to strengthen the adaptive nature of the variance reduction property. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the authors' claim of an adaptive variance reduction property, suggesting that it is essentially based on selecting a 'small enough' beta parameter, which is not adaptive. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might modify their claim or approach to better align with adaptive methods like AdaGrad. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of an \"adaptive variance reduction property,\" suggesting that it is essentially based on selecting a \"small enough\" beta parameter, which is not adaptive. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides a specific critique of the adaptive property, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point challenges the authors\\' claim of an \"adaptive variance reduction property\" by suggesting that it is essentially based on selecting a \"small enough\" beta parameter, which is not adaptive. The reviewer provides a counterpoint by referencing adaptive methods like AdaGrad, implying that the authors\\' claim does not align with typical adaptive methods. However, the comment lacks specific examples or references to AdaGrad or other adaptive methods to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a logical critique but requires more detailed evidence or examples to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the authors' claim of an adaptive variance reduction property, suggesting that it is essentially based on selecting a 'small enough' beta parameter, which is not adaptive. This feedback identifies a potential weakness in the authors' argument and provides a counterpoint by referencing adaptive methods like AdaGrad. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the effectiveness of different augmentation techniques and suggests that DINOv2 performs best most of the time. It implies that the authors should investigate why DINOv2 is the best-performing model and how to further improve it. While the comment provides a general direction for improvement, it does not offer specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the unclear value of different augmentation techniques and mentions that DINOv2 seems to be the best-performing model most of the time. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the need for further investigation into why DINOv2 is the best-performing model and how to improve it, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and that DINOv2 performs best most of the time. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. The comment lacks specific details or references that would help the authors understand the basis of the claim or how to address it. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the effectiveness of different augmentation techniques and notes that DINOv2 seems to be the best-performing model most of the time. It suggests that further investigation into why DINOv2 is the best-performing model and how to improve it would be beneficial. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to conduct this investigation or what aspects to focus on. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed direction for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the effectiveness of different augmentation techniques and notes that DINOv2 seems to be the best-performing model most of the time. It suggests that further investigation into why DINOv2 is the best-performing model and how to improve it would be beneficial. However, the comment does not provide specific guidance or actionable steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer the need for further investigation and improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the unclear value of different augmentation techniques and mentions that DINOv2 seems to be the best-performing model most of the time. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some level of specificity by suggesting further investigation into why DINOv2 is the best-performing model and how to improve it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and that DINOv2 seems to be the best-performing model most of the time. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. The comment lacks specific details or references that would help the authors understand the basis of the claim or how to address it. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the effectiveness of different augmentation techniques and notes that DINOv2 seems to be the best-performing model most of the time. It suggests that further investigation into why DINOv2 is the best-performing model and how to improve it would be beneficial. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to conduct this investigation or what aspects to focus on. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed direction for improvement. Therefore, it"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL in literature, which stands for \"Follow the Leader.\" The reviewer implies that a change in the acronym might be necessary to avoid confusion. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they should consider changing the acronym to avoid ambiguity. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a change in the acronym for \"follow the top perturbed leader\" due to its similarity to the common usage of FTL in literature, which stands for \"Follow the Leader.\" However, it does not specify which part of the paper this acronym is used in, making it difficult for the authors to pinpoint the exact location that needs revision. While the authors might have an idea of where the acronym is used, the comment lacks full grounding. It is specific about the issue with the acronym but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL in literature, which stands for \"Follow the Leader.\" This claim is somewhat verifiable as it provides a logical reasoning for the issue, but it lacks specific references or examples from the literature to fully substantiate the claim. The authors would need to verify the common usage of FTL in literature themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym used in the paper, suggesting that it might be confusing due to its similarity to the common usage of FTL in literature, which stands for \"Follow the Leader.\" The comment provides a clear and actionable suggestion to consider changing the acronym to avoid ambiguity. This feedback is valuable as it helps the authors improve the clarity and precision of their terminology, which is crucial for effective communication in academic writing. However, the comment could be more helpful if it included suggestions for alternative acronyms or explained why the current one is problematic. Overall, the comment is mostly helpful, as it provides a specific and actionable piece of advice, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL in literature, which stands for \"Follow the Leader.\" The reviewer implies that a change in the acronym might be necessary to avoid confusion. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they should consider changing the acronym to improve clarity. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a change in the acronym for \"follow the top perturbed leader\" due to its similarity to the common usage of FTL in literature, which stands for \"Follow the Leader.\" However, it does not specify which part of the paper this acronym is used in, making it difficult for the authors to pinpoint the exact location that needs revision. While the authors might have an idea of where the acronym is used, the comment lacks full grounding. It is specific about the issue with the acronym but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL in literature, which stands for \"Follow the Leader.\" This claim is somewhat verifiable as it provides a logical reasoning for the issue, but it lacks specific references or examples from the literature to fully substantiate the claim. The authors would need to verify the common usage of FTL themselves to fully understand and address the suggestion. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym used in the paper, suggesting that it might be confusing due to its similarity to the common usage of FTL in literature, which stands for \"Follow the Leader.\" The comment provides a clear and actionable suggestion to consider changing the acronym to avoid ambiguity. This feedback is valuable as it helps the authors improve the clarity and precision of their terminology, which is crucial for effective communication in academic writing. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the selection of attacks in Table 1 is arbitrary and suggests that the authors should consider using state-of-the-art attacks, such as MIDIFGSM. It also recommends mentioning the number of iterations for these attacks and their hyper-parameters. The comment provides clear and concrete actions for the authors to take, including specific examples of attacks to consider and detailed information to include in the table. This level of detail ensures that the authors know exactly what changes to make to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the selection of attacks, suggesting that the current choices are arbitrary and recommending the use of state-of-the-art attacks like MIDIFGSM. Additionally, it specifies the need to mention the number of iterations and hyper-parameters for these attacks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that the authors should consider using state-of-the-art attacks like MIDIFGSM. The reviewer supports this claim by referencing an external source, the survey available at https://arxiv.org/pdf/2310.17534.pdf, which provides an extensive analysis of attacks. This reference offers a clear and specific example of a state-of-the-art attack, providing a robust basis for the claim. The suggestion to mention the number of iterations and hyper-parameters is also supported by logical reasoning, as it aligns with best practices in experimental design. Therefore, the comment is fully verifiable, as it provides both logical reasoning and external evidence to support the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the selection of attacks in Table 1. It points out that the chosen attacks are not state-of-the-art and suggests considering more recent and effective attacks like MIDIFGSM. The comment also recommends mentioning the number of iterations and hyper-parameters for these attacks, which is crucial for reproducibility and clarity in the experimental setup. This feedback is clear and constructive, offering the authors a concrete way to enhance the rigor and relevance of their experimental design. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the method's applicability to other pre-training methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the limitations and conclusion sections of the paper, indicating that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This provides some grounding as it mentions specific sections of the paper, but it does not specify which parts of the limitations or conclusion sections need attention. The comment is specific in identifying the issue with the method\\'s applicability to different pre-training methods. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it highlights a potential area for improvement or further exploration in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or adapt their method to other pre-training methods. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issue but no clear path for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might adapt their method to work with other pre-training methods or improve its applicability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the limitations and conclusion sections of the paper, indicating that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not specify which parts of the paper discuss these limitations or provide detailed guidance on how to address them. The authors can infer that it relates to the limitations and conclusion sections, but the lack of explicit references makes it weakly grounded. The comment is specific in identifying the issue with the method\\'s applicability to different pre-training methods, but it lacks detailed guidance on how to address this limitation. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment lacks supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, it is difficult for the authors to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback highlights an important area for consideration"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the qualitative analysis, specifically regarding the determination of input sentences, the fine-tuning process, and the attribution values in Figure 1. It explicitly asks for clarification on how the examples were chosen for qualitative analysis, whether they occurred during fine-tuning, and whether the attribution values were normalized. Additionally, it inquires about the performance of the attribution map for input examples that failed to be classified. These questions provide clear and explicit actions for the authors to take, such as providing additional details and clarifications in their draft. The feedback is concrete, as it specifies exactly what information is missing and how it should be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions about the qualitative analysis, including how the input sentences were determined, whether they occurred during fine-tuning, and whether the attribution values were normalized. Additionally, it inquires about the performance of the attribution map for input examples that failed to be classified. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the qualitative analysis, specifically regarding the determination of input sentences and the attribution values in Figure 1. It seeks clarification on whether the examples occurred during fine-tuning and whether the attribution values were normalized. These questions are based on logical reasoning and seek clarification on specific aspects of the analysis. However, the comment does not provide any supporting evidence or references to substantiate these questions, making it somewhat verifiable. The authors would need to address these questions to improve their draft, but the lack of detailed justification or examples makes it challenging to fully understand the basis of the inquiry. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires more detailed explanation, namely the qualitative analysis. It raises several questions about the determination of input sentences for qualitative analysis, the fine-tuning process, and the attribution values in Figure 1. The comment also inquires about the performance of the attribution map for input examples that failed to be classified. This feedback is clear and actionable, as it provides the authors with specific points to address and clarifications to include in their draft. By addressing these questions, the authors can enhance the clarity and comprehensiveness of their qualitative analysis section. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific suggestion to include examples of practical applications where specific types of tensors need to be equivariant and to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. By including examples and clarifying the validation process, the authors can effectively address the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or discussion where these examples should be included. While the authors might infer that it relates to the sections discussing tensor functions or applications, the comment lacks full grounding. It is specific in suggesting what needs to be addressed but does not provide detailed guidance on how to implement the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any specific examples or references to support the claim that these applications are necessary or how they would validate the advantages. Without concrete examples or detailed reasoning, the authors may find it challenging to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the inclusion of examples of practical applications where specific types of tensors need to be equivariant. It also suggests clarifying how these scenarios validate the advantages of using equivariant tensor functions. This feedback is clear and constructive, offering the authors a concrete way to enhance their draft by illustrating the practical relevance and benefits of their work. However, the comment could be more helpful if it provided additional guidance on how to select or present these examples effectively. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. It also notes that Section 3.2.3 does not fully align with the table. While the comment highlights the problems, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the methods and ensure alignment between the table and section, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the tables, noting that it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. Additionally, it points out that Section 3.2.3 does not fully align with the table. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically mentioning Table 2 and Section 3.2.3. It states that it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly, and that Section 3.2.3 does not fully align with the table. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claims. The authors may need to infer the exact issues and how to address them, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. It also notes that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it points out specific areas where the authors need to improve the clarity and accuracy of their presentation. By addressing these issues, the authors can enhance the readability and comprehensibility of their paper. However, the comment could be more helpful if it provided suggestions on how to properly reference these methods or align the table with the section. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. It also notes that Section 3.2.3 does not fully align with the table. While the comment highlights the problems, it does not provide explicit instructions on how to address these issues, such as suggesting ways to clarify the methods or align the table with the section. The feedback is somewhat actionable as it points out the areas needing improvement but lacks detailed guidance on how to implement the changes. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the tables, noting that it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. Additionally, it points out that Section 3.2.3 does not fully align with the table. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically mentioning Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. Additionally, it notes that Section 3.2.3 does not fully align with the table. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claims. The authors may need to infer the exact issues and how to address them, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two specific questions for the authors to address. The first question asks for more details on whether the model is suitable for sarcastic/non-sarcastic utterances, suggesting that the authors should provide additional analysis. The second question seeks clarification on why eye-movement data would be useful for sarcastic/non-sarcastic sentiment classification beyond textual features, again asking for more explanations. These questions are explicit and provide clear actions for the authors to take, making the comment highly actionable. The authors know exactly what additional information or analysis is needed to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as providing more details on the model\\'s suitability for sarcastic/non-sarcastic utterances and explaining why eye-movement data would be useful for sarcastic/non-sarcastic sentiment classification beyond textual features. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions asking for clarification and additional information. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek further explanation, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a positive assessment of the paper, noting that it is well-written and organized, and that the experiments are conducted carefully for comparison with previous work. However, it also offers specific and actionable feedback by identifying two areas for improvement. The first point questions the suitability of the model for sarcastic/non-sarcastic utterances and suggests that the authors provide more details for further analysis. The second point raises a question about the utility of eye-movement data for sarcastic/non-sarcastic sentiment classification beyond textual features and asks for more explanations. These specific questions guide the authors on how to enhance their draft by providing additional context and analysis. While the comment is mostly helpful, it could be more comprehensive by offering suggestions on how to address these points. Therefore, it is rated as mostly helpful, consistent with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are limited, as the paper only conducts experiments on two small-scale/resolution datasets. It also mentions that the tables are unprofessional, specifically noting that \"DDIM is a sampler method instead of a model.\" While the comment identifies issues with the experimental setup and presentation, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to expand their experimental results and improve the presentation of their tables, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the limited number of experimental results and the unprofessional nature of the tables, particularly regarding the incorrect labeling of \"DDIM\" as a sampler method instead of a model. However, it does not specify which parts of the paper these issues pertain to, such as the sections discussing the experimental setup or the tables themselves. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in detailing what is wrong with the experimental results and the tables, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are limited, as the paper only conducts experiments on two small-scale/resolution datasets. It also criticizes the tables, stating that \"DDIM is a sampler method instead of a model.\" However, the comment lacks specific examples or detailed reasoning to support these claims, such as explaining why the number of datasets or the labeling of \"DDIM\" is problematic. This makes the claim somewhat verifiable, as it provides some basis for the critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited number of experimental results and the unprofessional nature of the tables. It points out that the paper only conducts experiments on two small-scale/resolution datasets, which may not provide a comprehensive evaluation of the proposed method. Additionally, it notes that the tables are unprofessional, specifically mentioning that \"DDIM is a sampler method instead of a model.\" While the comment highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues, such as recommending additional datasets or providing tips on how to improve the presentation of the tables. This limits the comment\\'s usefulness to the authors, making it somewhat helpful as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two issues: the limited number of experimental results and the unprofessional nature of the tables, specifically mentioning that \"DDIM is a sampler method instead of a model.\" However, it does not provide explicit guidance or suggestions on how to address these issues. The authors can infer that they need to expand their experimental results and improve the presentation of their tables, but the comment lacks concrete steps or examples. Therefore, the feedback is somewhat actionable, as it points out areas for improvement but does not offer detailed guidance on how to implement those changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the limited number of experimental results and the unprofessional nature of the tables, particularly regarding the labeling of \"DDIM\" as a sampler method instead of a model. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or tables, making it weakly grounded. The comment is specific in detailing what is wrong with the experimental results and the tables, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are limited, as the paper only conducts experiments on two small-scale/resolution datasets. It also criticizes the tables, stating that \"DDIM is a sampler method instead of a model.\" However, the comment lacks specific examples or detailed reasoning to support these claims, such as explaining why the number of datasets is insufficient or why the labeling of \"DDIM\" is incorrect. This makes the claim somewhat verifiable, as it provides some basis for the critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited number of experimental results and the unprofessional nature of the tables. It points out that the paper only conducts experiments on two small"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to provide more clarification about why their proposed method is important. It mentions that the method is essentially adjusting the variance level of DPSGD, which should influence the utility, but it questions what is lost in terms of privacy. The comment implies that the authors should discuss the trade-offs between utility and privacy. While the action is not explicitly stated, it is clear and concrete, as it specifies the need for a discussion on the trade-offs. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that more clarification is needed regarding the importance of the proposed method, particularly in terms of its impact on utility and privacy. However, it does not specify which part of the paper this clarification should address, making it weakly grounded. The comment is specific in its request for clarification on the trade-offs between utility and privacy, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method is essentially adjusting the variance level of DPSGD, which should influence the utility but questions what is lost in terms of privacy. The comment implies that the authors should provide a clearer explanation of the trade-offs between utility and privacy. However, it lacks specific examples or references to support the claim that the method is merely adjusting the variance level. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for more clarification regarding the importance of the proposed method. It suggests that the method is essentially adjusting the variance level of DPSGD, which should influence the utility, but questions what is lost in terms of privacy. While the comment highlights an area that requires further explanation, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper but does not provide detailed direction for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. The reviewer specifies that this example could be presented in tabular form. While the comment provides a clear action to take\u2014conducting a bigger-scale experiment and presenting a longer-horizon example in tabular form\u2014it does not offer detailed guidance on how to implement these suggestions. The authors are given a general direction but lack specific instructions on how to execute the changes. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, it does not specify which part of the paper these results are discussed in, making it weakly grounded. The comment is specific in its suggestion for improvement, as it provides a clear direction for enhancing the empirical results by suggesting a bigger-scale experiment and a longer-horizon example. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, the comment lacks specific reasoning or evidence to support why a bigger-scale experiment or longer-horizon example would be beneficial. Without detailed justification or examples, the claim remains vague and difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the empirical results, describing them as illustrative rather than demonstrative. It suggests conducting a bigger-scale experiment, particularly with a longer-horizon example, which could be presented in tabular form. This feedback is clear and actionable, providing the authors with specific directions for enhancing their experimental setup and results. By suggesting a bigger-scale experiment and a longer-horizon example, the comment offers a concrete path for improvement, making it mostly helpful. However, it could be further improved by providing more detailed guidance on how to implement these suggestions or by explaining why these changes would be beneficial. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. It specifies that this example could be presented in tabular form. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to implement these suggestions, such as specific parameters or methodologies for the bigger-scale experiment. The authors are given a general idea of what needs to be done but are left without detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, it does not specify which part of the paper these results are discussed in, making it weakly grounded. The comment is specific in its suggestion for improvement, as it provides a clear direction for enhancing the empirical results by suggesting a bigger-scale experiment and a longer-horizon example. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, the comment lacks specific reasoning or evidence to support why a bigger-scale experiment or longer-horizon example would be beneficial. Without detailed justification or examples, the claim remains vague and difficult for the authors to fully understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the empirical results, describing them as illustrative rather than demonstrative. It suggests conducting a bigger-scale experiment, particularly with a longer-horizon example, which could be presented in tabular form. This feedback is clear and actionable, providing the authors with specific directions for enhancing their experimental setup and results. By suggesting a bigger-scale experiment and a longer-horizon example, the comment offers a concrete path for improvement, making it mostly helpful. However, it could be further improved by providing more detailed guidance on how to implement these suggestions or by explaining why these changes would be beneficial. Therefore, the comment aligns with a score"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Equation (13) does not have a closed-form solution in general and suggests that the authors provide details on how it is solved in the experiments and discuss the computational complexity. This feedback is clear and provides a direct action for the authors to take, specifying exactly what information is needed to improve the draft. The comment is concrete in its request for specific details, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the specific part of the paper being addressed, which provides full grounding. It also specifies the issue by pointing out that the equation does not have a closed-form solution in general and suggests that details on how it is solved in the experiments and the computational complexity would be helpful. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general and suggests that details on how it is solved in the experiments and the computational complexity would be helpful. This claim is somewhat verifiable as it highlights a potential issue with the equation but lacks specific examples or references to support the assertion that it does not have a closed-form solution. The suggestion for additional details is logical, but the claim itself is not fully substantiated with evidence or reasoning. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13), noting that it does not have a closed-form solution in general. It suggests that the authors provide details on how the equation is solved in the experiments and discuss the computational complexity. This feedback is clear and actionable, as it guides the authors to include additional information that could enhance the clarity and understanding of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to present this information or examples of similar equations that have been successfully addressed. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement and provides a general direction for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of discussion on the choice of \"proximity\" and the nature of the task, specifically noting that proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space but may not hold for certain tasks. It suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that don\\'t. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct this analysis or which tasks to focus on. The authors are given a general idea of what needs to be addressed but are left to determine the specifics on their own. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the choice of \"proximity\" and the nature of the task, specifically mentioning the correlation between proximity on the fingertip Cartesian positions and proximity in the solution space. It provides an example of a complicated maze where this correlation may not hold and suggests analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that don\\'t. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where proximity is discussed. The comment is specific in detailing what needs to be addressed regarding the choice of proximity and its implications for different tasks. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the choice of \"proximity\" and its relationship with the nature of the task, specifically noting that proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space but may not hold for certain tasks. The reviewer provides an example of a complicated maze to illustrate this point, suggesting that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that don\\'t. While the comment includes a logical reasoning and an example to support the claim, it lacks specific references or detailed evidence to fully substantiate the argument. Therefore, the claim is mostly verifiable, as it provides a reasonable basis for the critique but could benefit from additional support or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of discussion on the choice of \"proximity\" and its relationship with the nature of the task. It highlights a potential issue with the proposed tasks, where proximity on the fingertip Cartesian positions may not accurately reflect proximity in the solution space, especially in complex environments like mazes. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that don\\'t. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and discussion. However, it could be more helpful if it included specific examples or methodologies for analyzing proximity metrics. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of implementation details in the experiments, indicating that readers cannot fully understand or reproduce the results without these details. However, it does not specify which details are missing or how the authors should provide them. The mention of \"See Questions for details\" suggests that the authors should address this issue elsewhere, but without further guidance, the authors are left without a clear understanding of what specific details are needed. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, indicating that readers cannot fully understand or reproduce the results without these details. However, it does not specify which parts of the experiments are missing details or provide examples of what specific details are needed. This makes it difficult for the authors to identify the exact areas that need improvement. The mention of \"See Questions for details\" suggests that the authors should address this elsewhere, but without further guidance, the comment remains weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. However, the comment does not provide specific examples or details of what these missing implementation details are, nor does it reference any external sources or provide a logical reasoning for why these details are crucial. This lack of specificity and supporting evidence makes the claim unverifiable, as it does not guide the authors on how to address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper, noting that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. This is a critical point that could impact the credibility and reproducibility of the study. However, the comment does not provide specific examples of what details are missing or how they could be added, leaving the authors without actionable guidance on how to address this issue. While it identifies a clear area for improvement, the lack of specificity limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of the comparison between SSUL and the paper, noting that SSUL uses an off-the-shelf saliency-map detector while the paper uses a pretrained Mask2Former for region proposals. The reviewer suggests that this may introduce an unfair comparison due to differences in data and model size. They propose two potential solutions: SSUL adopting Mask2Former for detecting unseen classes or generating object proposals in an unsupervised manner without additional data or a heavy model. While the comment provides a clear direction for addressing the issue, it lacks specific guidance on how to implement these suggestions. The authors are given a general idea of what needs to be done but are left to determine the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the comparison between SSUL and the paper, noting the use of different saliency-map detectors and the potential unfairness introduced by this choice. It suggests alternative approaches, such as using Mask2Former or an unsupervised method for generating object proposals. However, the comment does not explicitly mention which part of the paper discusses these detectors or comparisons, making it weakly grounded. The comment is specific in detailing the issue and potential solutions, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between SSUL and the paper, noting the use of different saliency-map detectors and the potential impact on data and model size. The reviewer provides a logical reasoning by pointing out that Mask2Former, used in the paper, is trained on COCO and has larger parameters compared to the off-the-shelf detector used by SSUL. The suggestion to consider using Mask2Former for SSUL or an unsupervised method for generating object proposals is a constructive suggestion for improvement. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore these suggestions to fully address the concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between SSUL and the paper, noting the use of different saliency-map detectors and the impact on data and model size. It suggests alternative approaches, such as using Mask2Former for SSUL or generating object proposals in an unsupervised manner, which could help address the fairness concern. This feedback is clear and actionable, providing the authors with specific suggestions for improving the comparability and fairness of their results. However, the comment could be more helpful if it included additional details or examples on how to implement these suggestions. Overall, the comment is mostly helpful, as it effectively guides the authors toward addressing a critical aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies potential issues with the metrics used to validate the performance of the proposed approach, specifically mentioning the style accuracy based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. However, it does not provide explicit guidance or suggestions on how to address these issues or improve the validation process. The comment lacks concrete actions or detailed advice, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and the metrics used to validate the performance of the proposed approach. It provides specific examples, such as the style accuracy based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. However, it does not explicitly mention which part of the paper these issues pertain to, such as specific sections or experiments. The authors can infer that it relates to the experimental results or metrics section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the issues with the metrics. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used to validate the performance of the proposed approach may not be adequate, specifically mentioning the style accuracy based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. The comment provides some reasoning by highlighting potential limitations in the metrics, but it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the validation of the proposed approach, specifically noting that the style accuracy metric may not effectively capture the performance of the algorithm. It provides a specific example of the style accuracy being based on a style classifier, which could be accurate but not necessarily reflective of the algorithm\\'s performance. Additionally, it highlights a concern with verifying the transfer result when using a styled motion input. While the comment raises important points about the limitations of the current validation approach, it lacks specific suggestions or guidance on how to address these issues or improve the validation process. This limits the comment\\'s usefulness to the authors, making it somewhat helpful as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies potential issues with the validation of the proposed approach, specifically mentioning the style accuracy metric and the difficulty in verifying the transfer result with a styled motion input. However, it does not provide explicit guidance or suggestions on how to address these issues or improve the validation process. The comment lacks actionable steps or concrete details, leaving the authors uncertain about how to proceed. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and the metrics used to validate the performance of the proposed approach. It provides specific examples, such as the style accuracy based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. However, it does not explicitly mention which part of the paper these issues pertain to, such as specific sections or experiments. The authors can infer that it relates to the experimental results or metrics section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the issues with the metrics. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used to validate the performance of the proposed approach may not be adequate, specifically mentioning the style accuracy based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. The comment provides some reasoning by highlighting potential limitations in the metrics, but it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the validation of the proposed approach, specifically noting that the style accuracy metric may not effectively capture the performance of the algorithm. It provides specific examples, such as the style accuracy being based on a style classifier and the difficulty in verifying the transfer result with a styled motion input. This feedback"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how individual preferences are generated and interpreted in the context of the proposed method. It suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences or if it encompasses other aspects. While the comment identifies an area that needs clarification, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail on the generation and interpretation of preferences. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the argument about how the proposed method takes individual preferences into account when simulating agents. It raises a specific question about the generation and interpretation of these preferences, particularly regarding the differentiation between risk-averse and other agents. This allows the authors to pinpoint the exact part of the paper being discussed. The comment is also specific because it clearly identifies the issue of clarity regarding the generation and interpretation of preferences. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the paper regarding how individual preferences are generated and interpreted, specifically mentioning the issue of risk aversion among agents. The reviewer suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences, indicating a need for further explanation. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the explanation is unclear. This makes the claim somewhat verifiable, as the authors would need to provide more detailed information to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the paper\\'s argument about how individual preferences are taken into account when simulating agents. It highlights the lack of clarity on how these preferences are generated and interpreted, particularly in terms of risk aversion among agents. The comment suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences, providing a clear direction for the authors to address this issue. While the comment effectively points out a gap in the paper\\'s explanation, it could be more helpful by offering suggestions on how to present this information more clearly. Overall, the feedback is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a lack of clarity regarding how individual preferences are generated and interpreted in the context of the proposed method. It suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences or if it encompasses other aspects. While the comment highlights an area that needs clarification, it does not provide explicit instructions or concrete steps on how the authors should address this issue. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the argument about how the proposed method takes individual preferences into account when simulating agents. It raises a specific question about the generation and interpretation of these preferences, particularly regarding the differentiation between risk-averse and other agents. This allows the authors to pinpoint the exact part of the paper being discussed. The comment is also specific because it clearly identifies the issue of clarity regarding the generation and interpretation of preferences. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the paper regarding how individual preferences are generated and interpreted, specifically mentioning the issue of risk aversion among agents. The reviewer suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences, indicating a need for further explanation. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the explanation is unclear. This makes the claim somewhat verifiable, as the authors would need to provide more detailed information to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the paper\\'s argument about how individual preferences are taken into account when simulating agents. It highlights the lack of clarity on how these preferences are generated and interpreted, particularly in terms of risk aversion among agents. The comment suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences, providing a clear direction for the authors to address this issue. While the feedback effectively points out"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about Figure 4, specifically regarding the meaning of \"1-200 frames,\" how the values are computed, and why the precision and recall change with trajectory length. It also inquires about the term \"action repeat.\" While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to clarify these aspects in their draft, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions about the meaning of \"1-200 frames,\" how values are computed, and the context of \"action repeat.\" These questions clearly specify what needs to be clarified or addressed in the figure, providing clear guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the content and methodology presented in Figure 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion regarding Figure 4, particularly in understanding the meaning of \"1-200 frames,\" how values are computed, and why precision and recall change with trajectory length. It also raises a question about the term \"action repeat.\" By pinpointing these unclear aspects, the comment provides the authors with clear directions for improving the clarity and comprehensiveness of their draft. However, it could be more helpful if it offered suggestions on how to clarify these points or provided examples of how to address them. Overall, the comment is mostly helpful as it highlights critical areas needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment questions the arbitrariness of certain design decisions, specifically the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, particularly in light of the cost-effectiveness motivation. The reviewer implies that providing such justification would enhance the paper's soundness. While the comment does not explicitly instruct the authors to provide justification, the action is clear and concrete, as it specifies the type of information that would be beneficial. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses specific design decisions related to the number of initial ground truth examples and the number of labeled examples, which are mentioned as arbitrary. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The comment also mentions the comparison of LLaMAA vs. finetuning, providing a specific example of what could be explored to enhance the paper. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where these design decisions are discussed. The comment is specific in detailing what needs to be addressed regarding the design decisions and the comparison of LLaMAA vs. finetuning. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the arbitrariness of certain design decisions, specifically the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The reviewer proposes a comparison between LLaMAA and finetuning, assuming a similar cost for the additional samples from the LLM. While the comment provides a logical reasoning for the need for justification, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's design decisions, specifically questioning the arbitrariness of the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The comment provides a specific example of what could be explored, such as comparing LLaMAA with finetuning, assuming a similar cost for additional samples from the LLM. This feedback is clear and actionable, as it guides the authors to provide a rationale for their design choices, which could enhance the paper's soundness. However, the comment could be more helpful if it offered additional suggestions or examples of how to justify these decisions. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment questions the arbitrariness of certain design decisions, specifically the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The reviewer also proposes a comparison between LLaMAA and finetuning, assuming a similar cost for additional samples from the LLM. While the comment does not explicitly instruct the authors to provide justification or comparisons, the actions are clear and concrete. The authors can infer that they need to justify their design choices and consider the suggested comparison. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses specific design decisions related to the number of initial ground truth examples and the number of labeled examples, questioning their arbitrariness. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The comment also proposes a comparison between LLaMAA and finetuning, assuming a similar cost for additional samples from the LLM. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these design decisions are discussed. The suggestion for a comparison provides some specificity, but the comment could be more grounded if it explicitly referenced the sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the arbitrariness of certain design decisions, specifically the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, particularly in the context of cost-effectiveness. The reviewer proposes a comparison between LLaMAA and finetuning, assuming a similar cost for additional samples from the LLM. While the comment provides a logical reasoning for the need for justification, it lacks specific examples or references to support the claim. This makes"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the motivation for using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It questions the complexity of the approach, implying that the authors should clarify or justify their choice. However, the comment does not provide explicit guidance or suggestions on how the authors should address this confusion or improve their explanation. The action is implicit and vague, as the authors need to infer that they should provide more clarification but are not given specific steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation behind using a graph structured model to capture global dependencies in sentences, contrasting it with existing sequence models. It questions the complexity of the approach, suggesting that the encoder and decoder are based on Transformer, which can already handle global dependencies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the approach and the potential confusion it raises, but without clear grounding, the authors may struggle to identify the exact section needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using a graph structured model to capture global dependencies in sentences, suggesting that existing sequence models already handle this. The reviewer points out that the encoder and decoder are based on Transformer, which can draw global dependencies. This critique is somewhat verifiable as it logically questions the necessity of the proposed approach, but it lacks specific examples or references to support the claim that sequence models already handle global dependencies effectively. The comment highlights a potential confusion but does not provide detailed evidence or reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It points out that the encoder and decoder are based on Transformer, which can already draw global dependencies. This feedback highlights a potential confusion or lack of clarity in the paper regarding the novelty or necessity of the proposed approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It questions the complexity of the approach, implying that the authors should clarify or justify their choice. However, the comment does not provide explicit guidance or suggestions on how the authors should address this confusion or improve their explanation. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It questions the complexity of the approach, suggesting that the encoder and decoder are based on Transformer, which can already draw global dependencies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the approach and the potential confusion it raises, but without clear grounding, the authors may struggle to identify the exact section needing clarification. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It points out that the encoder and decoder are based on Transformer, which can already draw global dependencies. This critique is somewhat verifiable as it logically questions the necessity of the proposed approach, but it lacks specific examples or references to support the claim that sequence models already handle global dependencies effectively. The comment highlights a potential confusion but does not provide detailed evidence or reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models already handle this. It points out that the encoder and decoder are based on Transformer, which can"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide videos demonstrating different policies controlling cars on different tracks to enhance the understanding of how different methods work. This is an explicit and concrete suggestion, providing a clear action for the authors to take. Additionally, the comment highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. It specifies that the policy gradient approach is unclear, providing a clear action for the authors to address this issue. The combination of these explicit and concrete suggestions makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which is a specific suggestion for improving the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for videos to enhance understanding, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance understanding. However, it does not specify which policies or tracks are being referred to, nor does it provide examples or references to support this suggestion. The claim about the lack of implementation details for reproducibility is somewhat verifiable, as it highlights a gap in the paper that could affect reproducibility. However, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two actionable suggestions. First, it recommends that the authors include videos demonstrating different policies controlling cars on different tracks to enhance the understanding of how different methods work. This is a clear and specific recommendation that can help improve the paper\\'s clarity and impact. Second, the comment highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. It specifically points out the unclear policy gradient approach, providing a clear direction for the authors to address this issue. Both suggestions are constructive and offer concrete steps for improvement, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the approximation of Equation 11 and the lack of clarity in Figure 1 regarding the layer-specific impact of parameters. The first part of the comment implies that the authors should provide a justification for the approximation used in Equation 11, suggesting that it does not account for the order of layers with the same parameters. The second part of the comment explicitly instructs the authors to conduct more experiments and theoretical analyses to explore the layer-specific impact of parameters. While the comment provides clear guidance on what needs to be addressed, it does not offer specific steps or examples on how to conduct these experiments or analyses. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the approximation used in Equation 11, noting that it only considers the impact of parameters in each layer and does not account for the order of layers with the same parameters in the network. Additionally, it points out the lack of clarity in Figure 1 regarding the layer-specific impact of parameters. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approximation used in Equation 11, suggesting that it does not account for the order of layers with the same parameters in the network. The reviewer provides a logical reasoning by pointing out that the approximation only considers the impact of parameters in each layer, which may not fully capture the complexity of the network. Additionally, the comment highlights the lack of clarity in Figure 1 regarding the layer-specific impact of parameters. While the comment raises valid concerns, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the critique but could benefit from more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the approximation used in Equation 11, questioning its validity and suggesting that it does not account for the order of layers with the same parameters in the network. This is a significant concern that could impact the accuracy and applicability of the proposed method. The comment also points out a specific issue with Figure 1, noting that it does not clearly indicate which layer each color represents, which could hinder the interpretation of the training trajectories. The reviewer suggests that the authors conduct more experiments and theoretical analyses to explore this aspect, providing clear and actionable feedback. This guidance empowers the authors to address the identified weaknesses and improve the comprehensiveness and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review point raises a question about the approximation used in Equation 11 and suggests that it does not account for the order of layers with the same parameters in the network. It also points out a lack of clarity in Figure 1 regarding the layer-specific impact of parameters. While the comment identifies areas for improvement, it does not provide specific guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide a justification for the approximation and conduct more experiments or analyses, but without detailed instructions, the feedback is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the approximation used in Equation 11, noting that it only considers the impact of parameters in each layer and does not account for the order of layers with the same parameters in the network. Additionally, it points out the lack of clarity in Figure 1 regarding the layer-specific impact of parameters. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approximation used in Equation 11, suggesting that it does not account for the order of layers with the same parameters in the network. The reviewer provides a logical reasoning by pointing out that the approximation only considers the impact of parameters in each layer, which may not fully capture the complexity of the network. Additionally, the comment highlights the lack of clarity in Figure 1 regarding the layer-specific impact of parameters. While the comment raises valid concerns, it lacks specific references or detailed examples"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance or concrete steps for the authors to take to address this issue. The action is implicit and lacks detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not specify which part of the paper this observation is based on, nor does it provide specific guidance on how to address the issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. The comment suggests that implementing online fine-tuning on top of existing benchmarks is feasible. However, the claim lacks specific examples, references, or detailed reasoning to support the assertion that the approach is incremental. Without such evidence or justification, the claim remains vague and difficult for the authors to fully understand or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not identify particular weaknesses or areas where the approach could be enhanced, nor does it offer guidance on how to address the perceived incremental nature of the adaptation. As a result, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance or actionable steps for the authors to address this issue. It lacks specificity and does not offer suggestions on how to enhance the approach or differentiate it from existing methods. As a result, the comment is barely actionable, as it provides limited direction for the authors to improve their draft.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specificity and does not provide details on which part of the paper this observation is based on, nor does it offer suggestions for improvement. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. The comment suggests that implementing online fine-tuning on top of existing benchmarks is feasible. However, the claim lacks specific examples, references, or detailed reasoning to support the assertion that the approach is incremental. Without such evidence or justification, the claim remains vague and difficult for the authors to fully understand or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the approach to offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies specific issues with the evidence presented in Table 6, noting contradictions and suggesting that the results do not support the claim of emotion-awareness being useful for synthetic text detection. However, it does not provide explicit guidance on how the authors should address these issues or improve their analysis. The comment lacks actionable details, such as recommending specific changes to the analysis or suggesting ways to resolve the contradictions. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 6,' allowing the authors to accurately identify the part of the paper being addressed. It also provides specific examples of contradictions in the evidence, such as the comparison between AT and BERTsynth, and GAS achieving the lowest F1 score despite fine-tuning with emotion classification datasets. This specificity helps the authors understand what needs to be addressed in terms of the evidence presented in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that Table 6 provides contradicting evidence regarding the utility of emotion-awareness for synthetic text detection. The reviewer supports this claim by pointing out specific examples, such as AT achieving a worse F1 score than BERTsynth and GAS having the lowest F1 score despite fine-tuning with emotion classification datasets. These examples provide a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific aspects of the data or providing more detailed reasoning about why these results contradict the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the evidence presented in Table 6, specifically noting contradictions that undermine the claim of emotion-awareness being useful for synthetic text detection. It provides specific examples, such as AT and GAS, which achieve worse F1 scores despite fine-tuning with emotion classification data. This feedback is clear and actionable, as it directs the authors to reconsider their claims and possibly revise their analysis or provide additional explanations to support their conclusions. However, the comment could be more helpful if it offered suggestions on how to address these contradictions or improve the evidence presented. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some guidance, aligning with a score of 4.\", 'helpfulness_label': '4'}{'label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It explicitly recommends testing with various models, such as Vision Transformers (ViT), and includes references to specific works. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions. The comment provides clear and concrete actions for the authors to take, specifying the types of models and noise models to consider. This level of detail makes the feedback highly actionable, as it gives the authors a clear path forward for improving their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments to address the research question and demonstrates the method\\'s generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and includes references to specific works. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or the discussion of generalizability. The comment is specific in detailing what additional experiments and models should be considered. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It provides specific references to relevant works, such as \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" and \"Learning Transferable Visual Models From Natural Language Supervision,\" which support the claim that testing with various models, including Vision Transformers (ViT), would be beneficial. Additionally, the comment suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. This combination of logical reasoning and specific references makes the claim mostly verifiable, as it provides a clear direction for the authors to follow, but it could be strengthened with more detailed examples or further justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting additional experiments to address the research question and demonstrate the method\\'s generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and includes references to relevant works. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. This feedback is clear and constructive, offering specific directions for enhancing the experimental validation and generalizability of the method. However, it could be more helpful if it included more detailed guidance on how to implement these suggestions or what specific outcomes to expect from these additional experiments. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the number of human annotators mentioned in the D.2 appendix and the number reported in the author responses. It explicitly states that the number should be four, indicating that the authors need to correct this inconsistency. The action is clear and concrete, as it specifies exactly what needs to be changed and provides a direct reference to the appendix and author responses. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between the number of human annotators mentioned in the appendix and the number reported in the author responses. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the D.2 appendix mentions two human annotators, while the author responses indicate a number of four. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. It is a statement of a discrepancy that requires clarification, but it does not make a claim that needs evidence or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the number of human annotators mentioned in the D.2 appendix and the number reported in the author responses. By pointing out this inconsistency, the comment provides the authors with specific feedback that can help them correct an error in their draft. However, the comment does not offer suggestions on how to address this issue or why it is important, which limits its helpfulness. While it highlights a critical area for improvement, it could be more beneficial with additional guidance or context. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would aid in understanding the value of the proposed approach. However, it does not provide specific guidance on how to improve the motivation or what aspects should be emphasized. The action is implicit and vague, as the authors are left to infer that they need to enhance the motivation but without clear direction on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where the encoder and decoder structure are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs improvement. While the comment is specific in suggesting a need for better motivation, it is weakly grounded because it does not provide clear guidance on where to make improvements. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support why this motivation is necessary or how it would enhance understanding. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to enhance the motivation. The feedback is somewhat helpful as it points out a potential weakness, but it does not offer actionable steps or suggestions for improvement, leaving the authors with only a vague direction to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the limited novelty of the explored loss functions and the absence of black-box evaluation. It also suggests that the paper should consider extending the analysis to targeted attacks to showcase the strength of the proposed attack method. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The authors can infer that they need to justify the novelty of their approach and consider black-box evaluation and targeted attacks, but the lack of detailed guidance makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific concerns regarding the novelty of the explored loss functions, the absence of black-box evaluation, and the limited scope of the attacks considered (only untargeted attacks). It provides clear guidance on what needs to be addressed, such as justifying the novelty of the loss functions and extending the analysis to targeted attacks. However, the comment does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the novelty of the explored loss functions, suggesting that they are not new and are merely 'plug and play' additions. The reviewer supports this claim by mentioning that JS divergence, masked CE loss, and masked spherical loss have not been commonly used in the context of segmentation attacks. However, the comment lacks specific references or detailed examples to substantiate the claim fully. Additionally, the critique about the absence of black-box evaluation and the limited scope of attacks (only untargeted attacks) is also supported by logical reasoning but could benefit from more detailed evidence or examples. Overall, the comment is mostly verifiable, as it provides a reasonable basis for the claims but could be strengthened with additional evidence or references.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies several key concerns regarding the paper's novelty and scope. It points out that the explored loss functions are not new and suggests that the attacks are conducted in a white-box manner without considering black-box evaluation. Additionally, the comment highlights a limitation in the paper's focus on untargeted attacks and recommends extending the analysis to targeted attacks to showcase the strength of the proposed method. While the comment effectively identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues, such as proposing alternative loss functions or methods for black-box evaluation. This limits the comment's helpfulness, making it somewhat helpful as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the novelty of the explored loss functions and the limitations of the conducted attacks, specifically the absence of black-box evaluation and the focus on untargeted attacks. While it identifies areas for improvement, it does not provide explicit guidance or suggestions on how to address these concerns. The authors can infer that they need to justify the novelty of their approach and consider extending the analysis to targeted attacks and black-box evaluation, but the lack of detailed instructions makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The review comment raises concerns about the novelty of the explored loss functions and the limitations of the conducted attacks, specifically the absence of black-box evaluation and the focus on untargeted attacks. While it identifies specific areas for improvement, it does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. However, the comment is specific in detailing what needs to be addressed, such as justifying the novelty of the loss functions and extending the analysis to targeted attacks. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions and the limitations of the conducted attacks. It provides some support for its claims by mentioning that JS divergence, masked CE loss, and masked spherical loss have not been commonly used in the context of segmentation attacks. However, the comment lacks specific references or detailed examples to substantiate the claim fully. Additionally, the critique about the absence of black-box evaluation and the limited scope of attacks (only untargeted attacks) is based on logical reasoning but could benefit from more detailed evidence or examples. Overall, the comment is somewhat verifiable, as it provides a reasonable basis for the claims but could be strengthened with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several key concerns regarding the paper's novelty and scope. It points out that the explored loss functions are not new and suggests that the attacks are"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. While the comment implies that the authors should include these comparisons and results, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides concrete guidance on what needs to be added to improve the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the results for CIFAR10 and CIFAR100, providing specific feedback on the lack of impressiveness in the CIFAR10 results and the need for a direct comparison with other approaches. It also suggests including results for CIFAR100. However, the comment does not explicitly mention which part of the paper discusses these results, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the results and comparisons. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment lacks specific examples or references to support the claim that the results are not remarkable. Additionally, it does not provide detailed reasoning or evidence to substantiate why the results are not impressive or how they compare to other approaches. This makes the claim somewhat verifiable, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches. It suggests that a direct comparison with other methods is necessary and requests results for CIFAR100. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including additional comparisons and results. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward enhancing the comprehensiveness and impact of their results, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. While the comment implies that the authors should include these comparisons and results, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides concrete guidance on what needs to be added to improve the draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the results for CIFAR10 and CIFAR100, providing specific feedback on the lack of impressiveness in the CIFAR10 results and the need for a direct comparison with other approaches. It also suggests including results for CIFAR100. However, the comment does not explicitly mention which part of the paper discusses these results, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the results and comparisons, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment lacks specific examples or references to support the claim that the results are not remarkable. It also does not provide detailed reasoning or evidence to substantiate why the results are not impressive or how they compare to other approaches. This makes the claim somewhat verifiable, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches. It suggests that a direct comparison with other methods is necessary and requests results for CIFAR100. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional comparisons and results. By addressing this point, the authors can improve the comprehensiveness and impact of their"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while hyperbolic space is known to be well-suited for hierarchical datasets, the experiments in the paper do not clearly demonstrate this. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific experiments or analyses that could be conducted to better demonstrate the suitability of hyperbolic space for hierarchical datasets. The action is implicit, as the authors need to infer that they should conduct additional experiments or analyses, and it is vague because it lacks concrete details on how to implement these changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the experiments not clearly demonstrating the suitability of hyperbolic space for hierarchical datasets. However, it does not specify which experiments or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact parts that need attention. While the authors might have an idea of where hyperbolic space is discussed, the comment lacks full grounding. It is specific in pointing out the issue of demonstration but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"hyperbolic space is well suited for hierarchical datasets\" but notes that \"none of the experiments clearly demonstrate this.\" This statement is somewhat verifiable as it highlights a potential gap in the experimental evidence supporting the claim. However, it lacks specific examples or references to experiments that could have demonstrated this suitability, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the experimental evidence regarding the suitability of hyperbolic space for hierarchical datasets. It highlights that while hyperbolic space is known to be well-suited for such datasets, the experiments in the paper do not clearly demonstrate this. This feedback is somewhat helpful as it points out a specific area where the authors could improve their work by providing more evidence or demonstrating the effectiveness of hyperbolic space in their experiments. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as specific experiments or analyses that could be conducted to better support the claim. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential gap in the experimental evidence regarding the suitability of hyperbolic space for hierarchical datasets. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific experiments or analyses that could be conducted to better demonstrate the suitability of hyperbolic space. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to conduct additional experiments or analyses, but without clear direction, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the experiments not clearly demonstrating the suitability of hyperbolic space for hierarchical datasets. However, it does not specify which experiments or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact parts that need attention. While the authors might have an idea of where hyperbolic space is discussed, the comment lacks full grounding. It is specific in pointing out the issue of demonstration but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"hyperbolic space is well suited for hierarchical datasets\" but notes that \"none of the experiments clearly demonstrate this.\" This statement is somewhat verifiable as it highlights a potential gap in the experimental evidence supporting the claim. However, it lacks specific examples or references to experiments that could have demonstrated this suitability, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the experimental evidence regarding the suitability of hyperbolic space for hierarchical datasets. It points out that while hyperbolic space is known to be well-suited for such datasets, the experiments in the paper do not clearly demonstrate this. This feedback is somewhat helpful as it highlights an area where the authors could improve their work by providing more evidence or demonstrating the effectiveness of hyperbolic space in their experiments. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending particular experiments or analyses to conduct."}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment highlights areas of potential interest, it does not provide explicit guidance or suggestions on how the authors should address these questions. The authors are left to infer that they need to clarify these aspects in their paper, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the strengths of MixBoost, but without clear grounding, the authors may struggle to identify the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the strengths of MixBoost. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights an important aspect that the authors need to clarify, but it lacks actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the wording in the paper, specifically regarding the phrase \"Unlike previous works which use the test set for hyperparameter tuning.\" The reviewer agrees with the importance of proper hyperparameter tuning but finds the wording confusing. Additionally, the reviewer suggests that the \"smaller training set\" could be avoided by training the network with optimal parameters on the complete train+val. While the comment implies that the authors should reconsider the wording and potentially adjust their approach to hyperparameter tuning, it does not provide explicit instructions or detailed guidance on how to make these changes. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (243 and 245), allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the wording regarding the use of the test set for hyperparameter tuning and suggests an alternative approach to avoid the \"smaller training set\" by training with optimal parameters on the complete train+val. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the wording in the paper regarding the use of the test set for hyperparameter tuning, suggesting that it is surprising. The reviewer agrees with the importance of proper hyperparameter tuning but finds the wording confusing. Additionally, the comment suggests an alternative approach to avoid the \"smaller training set\" by training the network with optimal parameters on the complete train+val. While the comment provides some reasoning and suggestions, it lacks specific examples or references to support the claim about the surprising nature of the statement. The suggestion to avoid the \"smaller training set\" is somewhat verifiable, but the overall claim about the wording is not fully supported. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the paper, noting that the phrase \"Unlike previous works which use the test set for hyperparameter tuning\" is surprising. The reviewer agrees with the importance of proper hyperparameter tuning but finds the wording confusing. Additionally, the comment suggests an alternative approach to avoid the \"smaller training set\" by training the network with optimal parameters on the complete train+val. This feedback is clear and actionable, as it provides the authors with a specific area to clarify and improve the clarity of their writing. However, the comment could be more helpful if it offered additional guidance on how to rephrase the sentence or suggested alternative wording. Overall, the comment is mostly helpful, as it effectively directs the authors to improve the clarity and precision of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction is vague and lacks detail, and it provides a specific suggestion for improvement by asking the authors to elaborate on how they tokenize parameters and use DDPM to predict actual parameters. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. The suggestion is clear and actionable, giving the authors a specific direction to enhance the clarity and depth of their introduction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the writing quality of the paper, specifically mentioning the introduction as \"quite obscure and high-level,\" and suggests that it lacks detailed elaboration on the implementation. It provides a specific suggestion for improvement by asking the authors to hint at how they tokenize parameters and use DDPM to predict actual parameters. However, the comment does not explicitly mention which part of the introduction is unclear, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction is \"quite obscure and high-level,\" lacking detailed elaboration on the implementation. The reviewer suggests that the authors provide more insight into how they tokenize parameters and use DDPM to predict actual parameters. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing of the paper, noting that the introduction is vague and lacks detailed elaboration on the implementation. It provides a clear and actionable suggestion for improvement by asking the authors to provide more insight into how they tokenize parameters and use DDPM to predict actual parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their introduction, making it highly helpful. However, the comment could be more helpful if it offered additional guidance or examples on how to effectively incorporate this information into the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the introduction is vague and lacks detailed elaboration on the implementation. It provides a specific suggestion for improvement by asking the authors to provide more insight into how they tokenize parameters and use DDPM to predict actual parameters. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. The suggestion is clear and actionable, giving the authors a specific direction to enhance the clarity and depth of their introduction. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the writing of the paper, particularly the introduction, which is described as \"quite obscure and high-level.\" It suggests that the authors provide more detailed information on how they tokenize parameters and use DDPM to predict actual parameters. However, the comment does not specify which part of the introduction is unclear or lacks detail, making it weakly grounded. The suggestion for improvement is specific, as it provides a clear direction for enhancing the clarity and depth of the introduction. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction is \"quite obscure and high-level,\" lacking detailed elaboration on the implementation. It suggests that the authors provide more insight into how they tokenize parameters and use DDPM to predict actual parameters. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for improvement is somewhat verifiable, as it provides a direction for enhancement but requires more detailed justification or evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing of the paper, noting that the introduction is vague and lacks detailed elaboration on the implementation. It provides a clear and actionable suggestion for improvement by asking the authors to provide more insight into how they tokenize parameters and use DDPM to predict actual parameters. This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their introduction, making it highly helpful. However, the comment could be more helpful if it offered additional guidance or examples on how to effectively incorporate this information into the paper. Overall, the comment is mostly helpful, aligning with a score"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is not good but does not provide any specific details or examples of what aspects of the presentation are problematic. Without explicit guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to address the issue. The lack of actionable feedback makes it difficult for the authors to know what specific changes to make to improve the presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is vague and does not specify which parts of the presentation are problematic or what aspects need improvement. It lacks grounding as it does not refer to specific sections, figures, or elements of the paper. Additionally, it does not provide any specific guidance or examples of what is considered \"not good\" about the presentation. This makes it difficult for the authors to identify and address the issues effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the presentation is not good\" but does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors are left without guidance on how to improve the presentation. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment is vague and lacks specificity, making it unhelpful for the authors. It simply states that the presentation is not good without providing any details or examples of what aspects are problematic or how they could be improved. This lack of actionable feedback does not assist the authors in enhancing their draft, rendering the comment unhelpful. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors have overlooked mentioning the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback provides a clear and direct action for the authors to take, which is to include this work in their related work section. The comment is specific and actionable, as it identifies a specific omission and suggests a concrete step for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"correlation of topological complexity with generalization ability,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of the work by Rieck et al. [2] in the related work section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have overlooked mentioning the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It lacks specific details or examples that would help the authors understand why this omission is significant or how it impacts their work. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence for the authors to address the issue effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the related work section, noting that the authors have not mentioned the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it directs the authors to include this relevant work in their literature review. By addressing this omission, the authors can enhance the comprehensiveness and accuracy of their paper. However, the comment could be more helpful if it provided additional context or explanation about the significance of this work in the broader context of the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the usefulness of the exploration parameter gamma, given that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment provides a clear direction for improvement by suggesting a specific remark and questioning the applicability of the analysis, it lacks concrete guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be addressed but without detailed steps on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the usefulness of the exploration parameter gamma, given the provision of only upper-bounds on the pseudo-regret. The comment suggests a potential improvement by adding a remark on high-probability upper-bounds and the role of gamma, and it questions whether the analysis can be extended to high-probability bounds on the regret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the usefulness of the exploration parameter gamma, given that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. The comment also questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment raises valid points and suggests potential areas for improvement, it lacks specific examples or references to support the claim about the usefulness of gamma. The reasoning is somewhat verifiable, as it provides a logical basis for the critique but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the usefulness of the exploration parameter gamma, given that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. This feedback is clear and actionable, providing the authors with specific areas to consider and explore in their analysis. By addressing these points, the authors can significantly improve the depth and robustness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either restate the definition of the LCA relaxation from Wang et al. in the body of the paper or add a description to the appendix. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the draft. The comment is concrete and leaves no ambiguity about the necessary steps, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to define the LCA relaxation, either by restating the definition from Wang et al. in the body of the paper or adding a description to the appendix. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the LCA relaxation was referenced but not defined in the paper. It requests the addition of a restatement of the definition from Wang et al. or a description in the appendix. This claim is somewhat verifiable as it highlights a specific issue with the paper\\'s clarity regarding the definition of the LCA relaxation. However, it lacks detailed reasoning or examples from the paper to support the need for this addition, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the LCA relaxation was referenced but not defined in the body of the paper. It provides a clear and actionable suggestion by recommending that the authors either restate the definition from Wang et al. in the main text or include a description in the appendix. This feedback is valuable as it helps the authors improve the clarity and completeness of their work by addressing a potential gap in the explanation of key concepts. However, the comment could be more helpful if it explained why this clarification is important or how it might impact the reader\\'s understanding. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more information on how validation and test splits influence model training could enhance the reproducibility of the dataset. While the comment implies that additional details are needed, it does not explicitly instruct the authors to provide this information or specify what aspects should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more details about the validation and test splits. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could enhance the reproducibility of the dataset. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to provide more details on validation and test splits, but without clear grounding, the authors may struggle to identify where to add this information. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more information on how validation and test splits influence model training could enhance reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks explicit references or detailed explanations, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more information on how validation and test splits influence model training could enhance the reproducibility of the dataset. This feedback is actionable and provides a clear direction for the authors to improve their draft by including additional details that would help readers better understand the experimental setup and its implications. However, the comment could be more helpful if it offered specific examples or guidance on what kind of information should be included. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. The comment implies that the authors should explore the combination of ZeroLiers with these other techniques. While the action is not explicitly stated, it is clear and concrete, as it provides specific areas for the authors to consider and explore. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its inquiry about the combination of ZeroLiers with other regularization techniques, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other techniques like L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. The comment provides a logical reasoning by pointing out that in practice, multiple techniques are often used together. However, it lacks specific examples or references to support the claim that using a single technique is insufficient. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration or evidence to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. This feedback is valuable as it prompts the authors to broaden their exploration of regularization methods and consider their combined effects. However, the comment could be more helpful if it provided specific suggestions or examples of how these techniques might be integrated or tested. Overall, the comment is somewhat helpful as it identifies an area for further exploration but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises questions about the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. While the comment implies that the authors should explore the combination of ZeroLiers with these other techniques, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its inquiry about the combination of ZeroLiers with other regularization techniques, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' focus on dropout as a regularization technique to address overfitting. It suggests considering other techniques like L2 regularization, data augmentation, and adding noise, and questions the practicality of using a single regularization technique. While the comment raises valid points about the limitations of using a single technique, it lacks specific examples or references to support the claim that using multiple techniques is more effective. The suggestion to consider other techniques is logical, but the comment could be strengthened by providing more detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the authors\\' focus on dropout as a regularization technique"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the assumption of overlap is reasonable in a tabular setting but questions its generalization to the function approximation setting. It explicitly asks the authors to discuss this generalization, providing a clear action for them to take. The comment also references the section about consistency, indicating where this discussion could be included. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and the section about consistency, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the generalization of the assumption to the function approximation setting and suggests discussing this in the context of consistency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It acknowledges that the assumption is reasonable in a tabular setting but suggests that a discussion on its generalization to the function approximation setting would be beneficial. The comment provides a logical reasoning by highlighting the need for further discussion, but it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed justification or evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific assumption, \"Assumption A (overlap),\" and questions its generalization to the function approximation setting. It acknowledges that the assumption is reasonable in a tabular setting but suggests that a discussion on its generalization would be beneficial. This feedback is clear and actionable, as it prompts the authors to consider and discuss the implications of their assumption in a broader context. However, the comment could be more helpful if it provided additional guidance or examples on how to address this issue. Overall, the comment is mostly helpful as it directs the authors to an important area for further exploration and discussion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that Table 1 should be one column wide and recommends that figures 3, 5, and 6 should be two column wide to improve readability. Additionally, the comment advises that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. These suggestions are clear and provide specific guidance on how to enhance the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the width of these elements, suggesting that Table 1 should be one column wide and figures 3, 5, and 6 should be two column wide. Additionally, the comment provides a general critique that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. It also states that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. While the comment provides specific suggestions for formatting improvements, it lacks detailed reasoning or evidence to support why these changes would enhance readability or understanding. The claim about the difficulty of understanding the paper is not substantiated with specific examples or explanations, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the formatting of the paper, suggesting that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. This guidance is clear and directly addresses the presentation of data and figures, which can significantly improve the readability and clarity of the paper. Additionally, the comment notes that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. While it does not specify what aspects of the content need improvement, it provides a direction for the authors to enhance the overall clarity and organization of their work. This feedback is mostly helpful as it offers concrete suggestions for improvement, but it could be more comprehensive with additional guidance on how to straighten up the content. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests a specific action by recommending that the authors repeat the Text-DPO baseline with generated images used for additional image-question-answer triplets. It provides a clear and concrete suggestion on how to modify the experimental setup to test the authors' hypothesis that training with perturbed images is the source of the performance benefit. This explicit guidance gives the authors a clear path to follow, making the comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a specific action by recommending the repetition of the Text-DPO baseline with generated images used for additional image-question-answer triplets. It provides a clear rationale for this suggestion, questioning whether the perturbed images are the source of the performance benefit rather than the specific DPO objective. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as specific sections or experiments. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests a specific method for testing the authors' hypothesis that training with perturbed images is the source of the performance benefit. The reviewer provides a detailed rationale for their suspicion, explaining the proposed method of creating additional image-question-answer triplets with perturbed images. This detailed reasoning and suggestion make the claim mostly verifiable, as it offers a clear path for the authors to test their hypothesis. However, the comment could be strengthened by referencing specific studies or examples where similar approaches have been successful, which would provide even more robust evidence. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a specific suggestion for an experiment that could help clarify the contribution of the DPO objective versus the use of perturbed images in the authors' method. By proposing to repeat the Text-DPO baseline with generated images used for additional image-question-answer triplets, the reviewer offers a clear and actionable way to test the authors' hypothesis. This feedback is highly helpful as it guides the authors toward a more rigorous evaluation of their method's components, potentially leading to a clearer understanding of the results. However, the comment could be further improved by explaining why this specific approach is expected to yield insights or by suggesting additional experiments to explore the impact of perturbations. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential assumption in the paper that there is no difference in expertise between Alice and Bob, and suggests that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to incorporate this consideration into their work. The feedback is implicit and lacks concrete steps, leaving the authors uncertain about how to apply this information to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the potential for non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges a specific assumption in the paper, namely that there is no difference in expertise between Alice and Bob. The reviewer provides a logical reasoning by pointing out that real-world tasks in human-AI collaboration often involve varying levels of expertise, which could lead to non-linear interactions between success-rate and speed-up. This reasoning is based on common knowledge in the field, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the assertion about non-linear interactions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential assumption in the paper that there is no difference in expertise between Alice and Bob, which may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise. This feedback is valuable as it points out a limitation in the assumptions made in the paper, encouraging the authors to consider more realistic scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to incorporate this consideration into the analysis. Overall, the comment is somewhat helpful as it provides insight into a potential weakness but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate this consideration into their work. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft. Therefore, the comment is rated as barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the potential for non-linear interactions between success-rate and speed-up due to varying levels of expertise. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges a specific assumption in the paper, namely that there is no difference in expertise between Alice and Bob. The reviewer provides a logical reasoning by pointing out that real-world tasks in human-AI collaboration often involve varying levels of expertise, which could lead to non-linear interactions between success-rate and speed-up. This reasoning is based on common knowledge in the field, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the assertion about non-linear interactions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise. This feedback is valuable as it points out a limitation in the assumptions made in the paper, encouraging the"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the generalizability of the mitigation strategies, specifically mentioning the possibility of data leakage. It suggests that these strategies might be dataset-specific and not applicable more generally. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve the generalizability of their framework. The feedback lacks actionable details, such as recommending alternative strategies or providing examples of how to test generalizability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the mitigation strategies being dataset-specific and not generally applicable, which is a specific concern. However, it does not explicitly mention which part of the paper discusses these strategies, making it weakly grounded. The authors can infer that it relates to sections discussing the framework or its applicability, but this inference is not direct. The comment is specific in detailing the issue of generalizability and the potential limitations in applicability to other LLMs and datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the mitigation strategies are dataset-specific and may not be generally applicable, which could limit the framework's applicability to other LLMs and datasets. The comment provides a logical reasoning by suggesting that the strategies might be specific to the dataset used, which could affect their generalizability. However, the claim lacks specific examples or references to support the assertion that these strategies are indeed dataset-specific, making it somewhat verifiable. The authors would need to further explore and verify this claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the generalizability of the mitigation strategies proposed in the paper. It points out that these strategies might be dataset-specific and not applicable more generally, which could limit the framework's applicability to other LLMs and datasets. This feedback is somewhat helpful as it highlights a critical area for consideration and encourages the authors to explore the generalizability of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or test the generalizability of their framework. To be more helpful, the comment could provide examples of how to evaluate or adapt the strategies for different datasets or LLMs. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a concern about the generalizability of the mitigation strategies, noting that they might be dataset-specific and not applicable more generally. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve the generalizability of their framework. The comment lacks actionable details, such as recommending alternative strategies or providing examples of how to test generalizability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the mitigation strategies being dataset-specific and not generally applicable, which is a specific concern. However, it does not explicitly mention which part of the paper discusses these strategies, making it weakly grounded. The authors can infer that it relates to sections discussing the framework or its applicability, but this inference is not direct. The comment is specific in detailing the issue of generalizability and the potential limitations in applicability to other LLMs and datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the mitigation strategies are dataset-specific and may not be generally applicable, which could limit the framework's applicability to other LLMs and datasets. The comment provides a logical reasoning by suggesting that the strategies might be specific to the dataset used, which could affect their generalizability. However, the claim lacks specific examples or references to support the assertion that these strategies are indeed dataset-specific, making it somewhat verifiable. The authors would need to further explore and verify this claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the generalizability of the mitigation strategies proposed in the paper. It points out that these strategies might be dataset-specific and not applicable more generally, which could limit the framework's applicability to other LLMs and datasets. This feedback is"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not sufficiently clear in some aspects and provides a list of questions to address. However, it does not specify which aspects are unclear or what specific improvements are needed. The comment also suggests that the weaknesses could be fixed until the final paper submission, but it lacks concrete guidance on how to achieve this. The authors are left with a general sense of what needs to be improved but without detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment indicates that the paper is not sufficiently clear in some aspects, but it does not specify which parts of the paper are unclear or provide specific questions or issues. This lack of detail makes it difficult for the authors to identify the exact areas needing improvement. Additionally, the comment suggests that the weaknesses could be fixed until the final paper submission, but it does not provide any guidance on how to address these weaknesses. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or detailed reasoning to support this claim. The comment mentions a list of questions, but these are not included in the review point itself. Without the list, it is difficult for the authors to understand the specific issues or areas that need clarification. The lack of detailed justification or examples makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the paper lacks clarity in certain aspects and provides a list of questions to address. However, it does not specify which parts of the paper are unclear or what specific issues need to be resolved. Additionally, the comment suggests that the weaknesses could be fixed until the final paper submission, but it does not offer actionable guidance on how to achieve this. While the comment highlights areas for improvement, it lacks depth and specificity, making it somewhat helpful. The authors are given a general direction to improve clarity but without detailed feedback on how to do so. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. While these questions imply that the authors should clarify these aspects in their draft, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to provide more information about these elements, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. These questions highlight potential gaps in the clarity and completeness of the paper, prompting the authors to provide more detailed information about these aspects. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending additional explanations or examples. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights specific areas where the paper could be improved, such as addressing problems like memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, it does not specify which part of the paper should include these improvements or where these issues are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issues that need to be addressed. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not address specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, the comment lacks any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, it is difficult for the authors to understand the basis of these claims or how they might address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved by addressing problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address these issues. While it points out potential weaknesses, it does not offer a clear path for improvement, making it somewhat helpful. The authors are given some insight into areas needing attention but are not fully supported in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that the authors should provide statistical distribution data on paper venues, such as ACL, EMNLP, and Arxiv, to address the concern about the bias introduced by Arxiv papers. However, the comment does not explicitly instruct the authors to include this data or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical distribution data but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that the authors should provide statistical distribution data on paper venues, such as ACL, EMNLP, and Arxiv. However, the comment does not specify which part of the paper should include this information, making it weakly grounded. The comment is specific in its critique of the inclusion of Arxiv papers and the potential bias they introduce, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. The reviewer suggests that Arxiv papers are not peer-reviewed and are hardly considered formal publications, which could introduce bias. The comment provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim about Arxiv papers being of lower quality. This makes the claim somewhat verifiable, as it provides a reasonable basis for the concern but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that the authors should provide statistical distribution data on paper venues, such as ACL, EMNLP, and Arxiv, to address the potential bias introduced by Arxiv papers. The comment also expresses reservations about including Arxiv papers in the study, as it believes they are not peer-reviewed and of lower quality. While the comment identifies a potential issue and provides some reasoning, it lacks specific suggestions or guidance on how the authors might address this concern or improve their study. The feedback is somewhat helpful as it highlights an area for improvement but does not offer detailed, actionable advice, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that the authors should provide statistical distribution data on paper venues, such as ACL, EMNLP, and Arxiv, to address the potential bias introduced by Arxiv papers. However, the comment does not explicitly instruct the authors to include this data or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical distribution data but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. It suggests that the authors should provide statistical distribution data on paper venues, such as ACL, EMNLP, and Arxiv, to address the potential bias introduced by Arxiv papers. However, the comment does not specify which part of the paper should include this information, making it weakly grounded. The comment is specific in its critique of the inclusion of Arxiv papers and the potential bias they introduce, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the statistical distribution of papers from different venues, specifically questioning the inclusion of Arxiv papers in the study. The reviewer suggests that Arxiv papers are not peer-reviewed and are hardly considered formal publications, which could introduce bias. The comment provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim about Arxiv papers being of lower quality. This makes the claim somewhat verifiable, as it provides a reasonable basis for the concern but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. While the comment implies that the authors should shift their focus, it does not provide specific guidance on how to achieve this or what aspects of the framework should be emphasized. The action is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested change. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework rather than the applications. However, it does not specify which part of the paper this feedback pertains to, such as sections discussing the framework or applications. This makes it difficult for the authors to pinpoint where the focus should be adjusted. Additionally, the comment lacks specificity regarding what aspects of the framework or applications should be emphasized or how the focus should be shifted. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than the applications. However, it does not provide any supporting evidence, reasoning, or examples to justify why this shift in focus would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. While it identifies a potential imbalance in the paper\\'s content, it lacks specificity and actionable guidance on how to achieve this shift in focus. Without detailed suggestions or examples, the authors may struggle to understand how to reallocate their efforts effectively. Therefore, the comment is barely helpful, as it points out an area for improvement but does not provide sufficient direction for the authors to make meaningful changes to their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. However, it does not provide any specific guidance or suggestions on how the authors could improve their draft or address any remaining concerns. The comment lacks actionable details, such as recommending specific areas for further improvement or suggesting additional analyses or considerations. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the limitations or societal impact were addressed. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. However, the comment lacks specific reasoning or evidence to support these claims. It does not provide details on what aspects of the work are considered marginal or how the limitations and societal impacts were addressed. Without such information, the claim remains unverifiable, as it does not provide sufficient justification for the authors to understand or address the feedback. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a general assessment of the work, stating that it is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. However, it lacks specificity and actionable feedback. It does not identify specific areas where the work could be improved or provide guidance on how the authors might enhance their draft. Without detailed suggestions or constructive criticism, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the simplicity of the dataset and suggests that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to its similarity to existing datasets like GSM8K. However, the comment does not provide explicit guidance or actionable steps for the authors to address these concerns. It lacks specific suggestions on how to enhance the research impact or differentiate the paper from existing methods. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the simplicity of the current dataset and suggests that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. Additionally, it implies that the paper may have limited research impact due to its similarity to existing datasets like GSM8K and suggests that future studies might follow a similar path. However, the comment does not specify which part of the paper discusses the dataset or the methodology, making it weakly grounded. The comment is specific in detailing the potential limitations and implications of the dataset, but without explicit references to sections or elements of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the simplicity of the current dataset could be solved by a straightforward method involving natural language translation and code or search libraries. It further suggests that the paper may have limited research impact due to its similarity to existing datasets like GSM8K and the potential use of methods such as PAL or LLMs with code interpreters. While the comment provides some reasoning by mentioning the potential ease of solving the dataset and the similarity to existing datasets, it lacks specific examples or references to support the claim about the dataset\\'s simplicity or the potential impact on future research. This makes the claim somewhat verifiable, as it provides a basis for the argument but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the simplicity of the dataset, suggesting that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to its similarity to existing datasets like GSM8K and the potential use of methods such as PAL or LLMs with code interpreters. While the comment identifies a potential weakness in the paper's contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or differentiate their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment raises concerns about the simplicity of the dataset and suggests that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to its similarity to existing datasets like GSM8K. However, the comment does not provide explicit guidance or actionable steps for the authors to address these concerns. It lacks specific suggestions on how to enhance the research impact or differentiate the paper from existing methods. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the simplicity of the dataset and suggests that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to its similarity to existing datasets like GSM8K and the potential use of methods such as PAL or LLMs with code interpreters. However, the comment does not specify which part of the paper discusses the dataset or the methodology, making it weakly grounded. The comment is somewhat specific in detailing the potential limitations and implications of the dataset, but without clear references to sections or elements of the paper, it remains weakly grounded. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the simplicity of the current dataset could be solved by a straightforward method involving natural language translation and code or search libraries. It also suggests that the paper may have limited research impact due to its similarity to existing datasets like GSM8K and the potential use of methods such as PAL or LLMs with code interpreters. While the comment provides some reasoning by mentioning the potential ease of solving the dataset and the similarity to existing datasets, it lacks specific examples or"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising a statement about maximum likelihood estimation and notes that the limitations of the proposed measure are not adequately discussed. It also points out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not outperform them experimentally. While the comment implies that the authors should revise the statement and discuss the limitations more thoroughly, it does not provide specific guidance on how to revise the statement or what aspects of the limitations should be addressed. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (25 and 242), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the statement about maximum likelihood estimation, suggesting that the limitations of the proposed measure are not adequately discussed. The comment further elaborates on the issue by pointing out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not outperform them experimentally. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement about maximum likelihood estimation and suggests that the limitations of the proposed measure are not adequately discussed. The reviewer provides a detailed explanation of their concern, referencing the presentation and noting that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not outperform them experimentally. This detailed reasoning and specific examples make the claim fully verifiable, as it provides a robust basis for the critique. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statement about maximum likelihood estimation, suggesting that it may not accurately reflect the limitations of the proposed measure. It points out that the limitations of the proposed measure are not adequately discussed, particularly in terms of its theoretical connection to generalization and its experimental performance compared to competing measures. This feedback is clear and actionable, as it directs the authors to revise the statement and provide a more thorough discussion of the limitations. However, the comment could be more helpful if it offered suggestions on how to address these limitations or provided examples of how to strengthen the discussion. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include these results, but it lacks concrete instructions on how to implement this change or what specific LLMs should be considered. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these results should be included. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the need for these results but lacks grounding as it does not point to a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source Large Language Models (LLMs) is \"quite important\" for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these results are crucial or how their absence impacts the benchmark. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. This is a relevant point that could impact the comprehensiveness and relevance of the study. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or why it is important. Without additional context or specific recommendations, the authors may find it challenging to understand the full impact of this feedback or how to incorporate it into their work. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific LLMs to include or how to incorporate these results into the study. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific gap in the paper, namely the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these results should be included. The comment lacks grounding as it does not point to a particular section or part of the paper, making it challenging for the authors to identify the exact area needing attention. While the comment is specific in identifying the need for these results, the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source Large Language Models (LLMs) is \"quite important\" for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these results are crucial or how their absence impacts the benchmark. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. This is a relevant point that could impact the comprehensiveness and relevance of the study. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or why it is important. Without additional context or specific recommendations, the authors may find it challenging to understand"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the training process of the regression model, specifically asking for details on the input, output, and parameter space differences between models with varying feature sizes. It also inquires about the potential impact of the number of parameters on model performance. While the questions imply that the authors should provide this information, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the training process of the regression model, specifically asking for details on the input, output, and parameter space differences between models with varying feature sizes. It also inquires about the potential impact of the number of parameters on model performance. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the regression model is discussed. The comment is specific in detailing what information is missing or unclear, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the training process and model performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the training process of the regression model, specifically inquiring about the input, output, and parameter space differences between models with varying feature sizes. It also questions whether the model performance is affected by the number of parameters. These questions are relevant and could help the authors clarify and improve their methodology section. However, the comment does not provide specific suggestions or guidance on how to address these issues, which limits its helpfulness. While it prompts the authors to consider important aspects of their methodology, it lacks actionable feedback that would empower them to make significant improvements. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an issue with the operator used in equation 6 and related equations, suggesting that the operator should be the multiplication of the underlying vector space and not \\\\cross_g. This feedback provides a clear and specific action for the authors to take, which is to correct the operator notation in the equations. The comment is direct and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the operator used in the equations, suggesting that it should be the multiplication of the underlying vector space and not \\\\cross_g. This provides clear guidance on what needs to be revised in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space and not \\\\cross_g, suggesting that it is an operator between a scalar and a tensor, not just between two scalars. This claim is somewhat verifiable as it provides a logical reasoning based on the mathematical context, but it lacks specific references or examples to fully substantiate the claim. The authors would need to verify this themselves, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the operator used in equation 6 and related equations. It identifies a potential error in the notation, suggesting that the operator should be the multiplication of the underlying vector space and not \\\\cross_g. This feedback is clear and precise, allowing the authors to make a direct correction to improve the accuracy and clarity of their mathematical expressions. The comment is highly helpful as it offers a concrete step for the authors to enhance the quality and precision of their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifies two areas where additional experiments should be conducted: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be added to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper should include these additional experiments, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the ablation experiments, providing clear guidance on what the authors should focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. However, the comment does not provide specific examples or references to support why these experiments are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of these experiments or how they would improve the paper. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the addition of more ablation experiments. It specifically identifies two areas where additional experiments could be conducted: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is valuable as it guides the authors on how to enhance the robustness and comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it included specific examples or guidance on how to design these experiments. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms like those proposed by Phan et al. (2017, 2019, 2020) and other related works as baseline approaches for comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or which datasets or tasks to focus on. The authors are given a general idea of what to aim for but are left to determine the specifics on their own. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that the datasets used in the experiments have limited dimensions, such as dim=24 in power consumption, dim=6 in real estate valuation, and dim=30 in breast cancer detection. It recommends using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, it suggests considering adaptive mechanisms like those proposed by Phan et al. (2017, 2019, 2020) and other related works as baseline approaches for comparison. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the experimental results and discussion sections. The suggestion is specific, as it provides a clear direction for expanding the experiments and includes references to related works. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. The comment provides specific examples of datasets and learning tasks that could be explored, which adds some level of verifiability. However, it lacks detailed reasoning or evidence to support why these specific datasets or tasks would be more beneficial or how they would enhance the experimental results. The mention of adaptive mechanisms and related works provides some context, but the claim could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the experimental results by recommending the use of more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also suggests considering adaptive mechanisms like those proposed by Phan et al. (2017, 2019, 2020) and other related works as baseline approaches for comparison. This feedback is specific and offers a concrete direction for enhancing the experimental setup, which can significantly improve the robustness and relevance of the study. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or specific examples of datasets or tasks to consider. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also mentions that the results from Table 4 do not show the advantage of using PRESENCE. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their results. The feedback lacks actionable steps, such as recommending specific analyses or experiments to clarify the results. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the experiment results, particularly the relationship between temperature $\\\\tau$ and downstream performance, as well as the lack of advantage shown in Table 4. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). The reviewer provides some reasoning by noting that using a positive or negative $\\\\tau$ can yield improvement over no reweighting, which raises questions about the necessity of reweighting. However, the comment lacks specific examples, detailed explanations, or references to support the claim fully. While the reasoning is somewhat logical, it is not fully substantiated, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also notes that the results from Table 4 do not show the advantage of using PRESENCE. While the comment identifies weaknesses in the experimental results, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback highlights areas for improvement but does not provide actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also mentions that the results from Table 4 do not show the advantage of using PRESENCE. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their results. Without actionable steps or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the experiment results, particularly the relationship between temperature $\\\\tau$ and downstream performance, as well as the lack of advantage shown in Table 4. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also notes that the results from Table 4 do not show the advantage of using PRESENCE. The comment provides some reasoning by suggesting that using a positive or negative $\\\\tau$ can yield improvement over no reweighting, which raises questions about the necessity of reweighting. However, the comment lacks specific examples, detailed explanations, or references to support the claim fully. While the reasoning is somewhat logical, it is not fully substantiated, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also notes that the results from Table 4 do not show the advantage of using"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how the authors should address this observation or what steps they should consider to investigate or clarify the reason behind the performance gain. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the results for k=1 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. This provides clear guidance on what aspect of the results needs further exploration or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. This claim is somewhat verifiable as it provides a specific observation from the results, which could prompt the authors to reconsider the interpretation of their findings. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as comparisons with other factors or alternative explanations. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the interpretation of the results in Table 2, specifically noting that the results for k=1 are already better than the baselines. This observation suggests that the performance gain might be due to a reason other than applying Eq.10, which could lead the authors to reconsider their analysis or interpretation of the results. However, the comment lacks specific guidance or suggestions on how the authors might investigate or address this potential issue. While it points out an area for further exploration, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, it does not provide any explicit or implicit action for the authors to take in response to this observation. There is no guidance on whether this finding should prompt further investigation, analysis, or clarification in the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the interpretation of the results, suggesting that the performance gain might be due to a reason other than applying Eq.10. This provides clear guidance on what aspect of the results needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. This claim is somewhat verifiable as it provides a specific observation from the results, which could prompt the authors to reconsider their interpretation. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as comparisons with other factors or alternative explanations. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the interpretation of the results in Table 2, noting that the results for k=1 are already better than the baselines. This observation suggests that the performance gain might be due to a reason other than applying Eq.10, which could lead the authors to reconsider their analysis or interpretation of the results. However, the comment lacks specific guidance or suggestions on how the authors might investigate or address this potential issue. While it points out an"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific improvements. The feedback is implicit, as the authors need to infer that they should justify their choice of mixed-integer programming and clarify its advantages. Additionally, the comment is vague because it does not specify what kind of justification or comparison is needed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the proposed method for lacking solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where these choices are made. This makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in identifying the issue with the choice of mixed-integer programming and its advantages, it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, the comment does not provide any supporting evidence, examples, or references to justify why the choice of mixed-integer programming is not justified or how it compares to alternative approaches. This lack of detailed reasoning or evidence makes the claim difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it lacks solid grounding and that the choice of mixed-integer programming is not fully justified. It also points out that the advantages of this approach over alternative methods are unclear. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it directs the authors to reconsider their methodological choices and their justifications, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of solid grounding in the proposed method, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a lack of solid grounding in the proposed method, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the issue with the choice of mixed-integer programming, it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, the comment does not provide any supporting evidence, examples, or references to justify why the choice of mixed-integer programming is not justified or how it compares to alternative approaches. This lack of detailed reasoning or evidence makes the claim difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it lacks solid grounding and that the choice of mixed-integer programming is not fully justified. It also points out that the advantages of this approach over alternative methods are unclear. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these concerns or clarify the advantages of their approach. This lack of actionable feedback limits the comment\\'s usefulness to the authors. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment identifies a lack of solid grounding in the proposed method, specifically mentioning the choice of mixed-integer programming and its"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific issues: the confusing notation in Equation 1, where \"c\" is used instead of \"o,\" and the missing reference \"Pedersen et al 2007\" in the reference section. These are explicit and concrete actions that the authors can take to improve their draft. The first part of the comment provides a clear correction for the notation, and the second part highlights a missing reference that needs to be added. Both actions are direct and provide specific guidance on how to address the issues, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the confusing notation in Equation 1 and the missing reference \"Pedersen et al 2007\" in the reference section. This provides clear guidance on what the authors need to revise or add to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two observations: one about confusing notation in Equation 1 and another about a missing reference in the reference section. These are factual statements that do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues that need attention: the confusing notation in Equation 1, where \"c\" is used instead of \"o,\" and the missing reference \"Pedersen et al 2007\" in the reference section. These are clear and actionable points that the authors can directly address to improve the clarity and completeness of their draft. By pinpointing these specific errors, the comment provides the authors with concrete steps to enhance the quality of their work. However, it could be more helpful if it offered additional context or suggestions on how to handle similar issues in the future. Overall, the comment is mostly helpful, as it effectively directs the authors to make necessary corrections.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a lack of novelty in the paper's contribution of combining SSMs with Attention, noting that this has been proposed before in MEGA and Block-state Transformer. It also points out similarities between the proposed architecture in Figure 5 and the architecture in MEGA. The reviewer explicitly instructs the authors to discuss and ablate the similarities and differences between S++ and the proposed work. This feedback provides a clear and concrete action for the authors to take, specifically to conduct a thorough discussion and ablation of the similarities and differences. The explicit nature of the suggestion and the detailed guidance on what needs to be done make this comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second contribution of the paper, the proposal to combine SSMs with Attention, and references specific works (MEGA and Block-state Transformer) that have previously proposed similar ideas. It also refers to Figure 5, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details what needs to be addressed, namely a thorough discussion and ablation of the similarities and differences between S++ and the proposed work. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the second contribution of the paper, the proposal to combine SSMs with Attention, is not novel and has been proposed before in MEGA and Block-state Transformer. The reviewer supports this claim by referencing specific works (MEGA and Block-state Transformer) that have previously proposed similar ideas. Additionally, the comment notes that the architecture in Figure 5 is similar to the architecture in MEGA, suggesting that the authors should discuss and ablate the similarities and differences between S++ and the proposed work. This provides a clear and detailed justification for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper's second contribution, which is the proposal to combine SSMs with Attention. It points out that this idea has been proposed before in MEGA and Block-state Transformer, and suggests that the authors discuss and ablate the similarities and differences between their work and these previous contributions. This feedback is clear and actionable, as it directs the authors to thoroughly analyze and compare their work with existing literature, which could enhance the originality and impact of their contribution. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the specific reason for reporting results on knowledge transfer only on a few select environments. While it implies that the authors should provide an explanation or justification for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for reporting results on knowledge transfer only on a few select environments, providing clear guidance on what aspect of the paper needs clarification or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reporting of results on knowledge transfer. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific reason for reporting results on knowledge transfer only on a few select environments. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their reporting. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of what might need clarification. Therefore, it is rated as barely helpful, as it points out a potential area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the lack of specific ablation experiments, which could lead to confusion regarding the performance improvement attributed to the pre-trained weights rather than the proposed method. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should conduct ablation experiments to clarify the contribution of their proposed method. However, the comment does not specify which aspects of the method should be tested or how to design these experiments. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of specific ablation experiments, which could lead to confusion about the performance improvement attributed to pre-trained weights rather than the proposed method. However, it does not specify which part of the paper should include these ablation experiments or where the confusion arises. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where ablation experiments are typically discussed, the comment lacks full grounding. It is specific about the issue of attribution but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance improvement could be attributed to the pre-trained weights rather than the proposed method, due to the lack of specific ablation experiments. This claim is somewhat verifiable as it highlights a potential issue with the manuscript\\'s evaluation methodology. However, it lacks specific examples or references to similar studies that have addressed this issue, which would provide more robust evidence. The comment suggests that detailed ablation comparisons could clarify the contribution of the proposed method, but without further elaboration, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the manuscript, specifically the lack of specific ablation experiments. It highlights a potential concern that the performance improvement could be attributed to the pre-trained weights rather than the proposed method, which could lead to confusion. By pointing out the absence of detailed ablation comparisons, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to design these ablation experiments or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a significant area needing attention and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major concern regarding the limitation of the lemmatizer, specifically that it strips suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on potential solutions, alternative approaches, or modifications that could be made to mitigate this limitation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the lemmatizer, which is the stripping of suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about real-world texts with evolving vocabularies, providing a clear indication of what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This claim is somewhat verifiable as it provides a clear explanation of the issue, but it lacks specific examples or references to support the assertion that this is a major concern for real-world texts with evolving vocabularies. The comment could be strengthened by providing evidence or examples of how this limitation affects real-world applications, which would help the authors understand the significance of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a relevant concern, especially for real-world texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential weakness, it lacks actionable feedback or constructive advice that could help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out an area of concern but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. Without actionable guidance or recommendations, the authors are left without a clear path forward. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about real-world texts with evolving vocabularies, providing a clear indication of what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a relevant issue, particularly for real-world texts with evolving vocabularies. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore this issue to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a relevant concern, especially for real-world texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential weakness, it lacks actionable feedback or constructive advice that could help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out an area of concern but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method. The reviewer suggests that this comparison may not be meaningful because it implies that the segmentation of those methods + DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches for comparison. The action is implicit and vague, leaving the authors uncertain about how to improve the draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of segmentation metrics under the condition of using pre-trained DGCNN for each completion method. The comment provides a clear rationale for why the comparison may not be meaningful and suggests that the segmentation of those methods + DGCNN is worse than the proposed method. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method, is not meaningful because it implies that the segmentation of those methods + DGCNN is worse than the proposed method. The comment provides a logical reasoning by suggesting that the comparison lacks meaningfulness due to the use of pre-trained DGCNN. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method. The reviewer points out that this comparison may not be meaningful because it implies that the segmentation of those methods + DGCNN is worse than the proposed method. While the comment highlights a specific concern, it lacks actionable suggestions or guidance on how the authors might address this issue or improve the comparison. Without additional context or recommendations, the authors may struggle to understand how to enhance the draft based on this feedback. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method. It suggests that the comparison may not be meaningful because it implies that the segmentation of those methods + DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches for comparison. The action is implicit and lacks concrete details, making it barely actionable. The authors are left uncertain about how to improve their draft based on this feedback.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of segmentation metrics under the condition of using pre-trained DGCNN for each completion method. The comment provides a clear rationale for why the comparison may not be meaningful and suggests that the segmentation of those methods + DGCNN is worse than the proposed method. This level of detail and clarity makes the comment fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method, is not meaningful because it implies that the segmentation of those methods + DGCNN is worse than the proposed method. The comment provides a logical reasoning by suggesting that the comparison lacks meaningfulness due to the use of pre-trained DGCNN. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison presented in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method. The comment suggests that the comparison may not be meaningful because it implies that the segmentation of those methods + DGCNN is worse than"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is challenging to obtain rules in real-world applications and proposes that statistical rules learned from data might be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this insight could be applied to improve the paper, nor are there suggestions for further exploration or analysis. As a result, the comment lacks actionability, leaving the authors without direction on how to use this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that it is challenging to obtain rules in real-world applications and proposes that statistical rules learned from data might be feasible. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the rules or statistical methods are being discussed or how they could be improved. Without clear grounding or specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is challenging to obtain rules in real-world applications and proposes that statistical rules learned from data might be feasible. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it is challenging to obtain rules in real-world applications and proposes that statistical rules learned from data might be feasible. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not identify any particular weaknesses or areas where the authors could enhance their work, nor does it offer guidance on how to address the issue of obtaining rules in real-world applications. As a result, the feedback is not helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include a comparison with dynamic sparse training-based and other sparsity-based methods. While the comment implies that the authors should add this comparison, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its request for a comparison, as it clearly identifies what is missing in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a comparison with dynamic sparse training-based and other sparsity-based methods. This feedback is somewhat helpful as it identifies a potential gap in the paper that could enhance its comprehensiveness and relevance. However, the comment lacks specific guidance on how to conduct this comparison or what aspects should be considered, leaving the authors with a general idea but no detailed direction for improvement. To be more helpful, the comment could include suggestions on which specific methods to compare or how to structure the comparison. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the explanation provided in the paper regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. It suggests that the reason for the intractability might not be solely due to the intractability of $p_\\\\theta(z|x)$, as both the posterior and likelihood can be tractable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their explanation. The feedback lacks actionable steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly quotes a specific statement from the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the explanation provided, questioning the assumption that the intractability of $p_\\\\theta(y|x)$ is solely due to the intractability of $p_\\\\theta(z|x)$. The comment provides a clear example of a potential misunderstanding or oversimplification in the paper, which helps the authors understand what needs to be clarified or revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation provided in the paper regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. The reviewer suggests that the intractability might not be solely due to the intractability of $p_\\\\theta(z|x)$, as both the posterior and likelihood can be tractable. This claim is somewhat verifiable as it provides a logical reasoning by contrasting the intractability of $p_\\\\theta(y|x)$ with the tractability of $p_\\\\theta(z|x)$ and $p_\\\\theta(y|x, z)$. However, the comment lacks specific examples or references to support this alternative explanation, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the explanation provided in the paper regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. It suggests that the intractability might not be solely due to the intractability of $p_\\\\theta(z|x)$, as both the posterior and likelihood can be tractable but $p_\\\\theta(y|x)$ may still be intractable. This feedback is somewhat helpful as it identifies a potential misunderstanding or oversimplification in the paper's explanation. However, it lacks specific suggestions or guidance on how the authors might clarify or correct this issue, which limits its usefulness. The comment provides some insight but does not offer actionable steps for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point questions the explanation provided in the paper regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. It suggests that the intractability might not be solely due to the intractability of $p_\\\\theta(z|x)$, as both the posterior and likelihood can be tractable but $p_\\\\theta(y|x)$ may still be intractable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their explanation. Without specific recommendations or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly quotes a specific statement from the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the explanation provided, questioning the assumption that the intractability of $p_\\\\theta(y|x)$ is solely due to the intractability of $p_\\\\theta(z|x)$. The comment provides a clear example of a potential misunderstanding or oversimplification in the paper, which helps the authors understand what needs to be clarified or revised. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation provided in the paper regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. It suggests that the intractability might not be solely due to the intractability of $p_\\\\theta(z|x)$, as both the posterior and likelihood can be tractable but $p_\\\\theta(y|x)$ may still be intractable. This claim is somewhat verifiable as it provides a logical reasoning by contrasting the intractability of"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the irreproducibility of the study due to the inaccessible datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might make the datasets accessible or what steps they could take to improve reproducibility. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what changes are needed to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the irreproducibility of the study due to the inaccessible datasets outside of the associated groups. However, it does not specify which part of the paper discusses the datasets or how the authors could address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is irreproducible due to the inaccessible datasets outside of the associated groups. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the study\\'s reproducibility due to the inaccessible datasets outside of the associated groups. This is a critical concern for the validity and impact of the research, as reproducibility is a cornerstone of scientific research. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to make the datasets accessible or suggesting alternative datasets that could be used. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point highlights an issue with the irreproducibility of the study due to inaccessible datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might make the datasets accessible or what steps they could take to improve reproducibility. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what changes are needed to improve their draft. Therefore, it aligns with a score of 1 for being unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the irreproducibility of the study due to the inaccessible datasets outside of the associated groups. However, it does not specify which part of the paper discusses the datasets or how the authors could address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is irreproducible due to the inaccessible datasets outside of the associated groups. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the study\\'s reproducibility due to the inaccessible datasets outside of the associated groups. This is a significant concern for the validity and impact of the research, as reproducibility is a cornerstone of scientific research. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to make the datasets accessible or suggesting alternative datasets that could be used. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point highlights an issue"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the presence of a missing equation before the phrase \"where p is the firing rate\" in section 3.4.1. While it explicitly points out a potential issue, it does not provide any guidance on how to address it or what the missing equation might be. The authors are left to infer that they should look for and include the missing equation, but without further details, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential absence of an equation before the phrase \"where p is the firing rate,\" providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the presence of an equation before a specific phrase. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the manuscript, namely the potential absence of an equation before the phrase \"where p is the firing rate\" in section 3.4.1. This is a precise and actionable piece of feedback, as it directs the authors to check for and possibly include the missing equation. However, the comment could be more helpful if it provided additional context or suggested why the equation might be important for understanding the content. Despite this, the feedback is clear and provides a concrete step for the authors to take, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation of sentiment word detection and correction is lacking, given that the key ideas of SWRM involve these aspects. It suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the evaluation process. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of sentiment word detection and correction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the validation of the effects of the sentiment word position detection module and the predicted sentiment word candidates. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of sentiment word detection and correction is lacking, given that the key ideas of SWRM involve these aspects. The reviewer suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the necessity of these experiments. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the paper, specifically the lack of evaluation for sentiment word detection and correction. It highlights that the key ideas of SWRM involve these aspects and suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a specific direction for improving their work. By addressing this point, the authors can enhance the comprehensiveness and impact of their study. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific metrics to use. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results of KMLM-XLM-R_{large}(ours) in all the result tables, suggesting that the authors did not report all the performance of KMLM-large without logical reasoning. While the comment implies that the authors should include these results, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment mostly actionable. The authors know they need to report the results but may not be entirely sure of the exact steps to take, such as where to include these results in the tables.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the results of KMLM-XLM-R_{large}(ours) in all the result tables. The comment suggests that the authors did not report all the performance of KMLM-large without logical reasoning, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the completeness of the results reported in the paper, specifically asking about the results of KMLM-XLM-R_{large}(ours) in all the result tables. However, it does not provide any supporting evidence, reasoning, or examples to justify why these results are missing or how their omission affects the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the completeness of the results reported in the paper, particularly regarding the performance of KMLM-XLM-R_{large}(ours) in all the result tables. It questions whether the authors have omitted reporting all the performance of KMLM-large without logical reasoning. This feedback is somewhat helpful as it identifies a potential gap in the presentation of results, prompting the authors to ensure that all relevant performance metrics are included. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as which specific results should be added or how to present them logically. Therefore, the comment provides some insight but could be more comprehensive and actionable, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the results of KMLM-XLM-R_{large}(ours) in all the result tables, suggesting that the authors may have omitted reporting all the performance of KMLM-large without logical reasoning. While the comment implies that the authors should include these results, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment mostly actionable. The authors know they need to address the issue but may not be entirely sure of the exact steps to take, such as where to include these results in the tables.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the results of KMLM-XLM-R_{large}(ours) in all the result tables. The comment suggests that the authors did not report all the performance of KMLM-large without logical reasoning, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the completeness of the results reported in the paper, specifically asking about the results of KMLM-XLM-R_{large}(ours) in all the result tables. However, it does not provide any supporting evidence, reasoning, or examples to justify why these results are missing or how their omission affects the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the completeness of the results reported in the paper, particularly regarding the performance of KMLM-XLM-R_{large}(ours) in all the result tables. It questions whether the authors have omitted reporting all the performance of KMLM-large without logical reasoning. This feedback is somewhat helpful as it identifies a potential gap in the presentation of results, prompting the authors to ensure that all relevant performance metrics are included. However, the comment lacks detailed guidance or"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that these results may be due to large variance or uncareful design of the baselines and recommends providing more explanations to support the reliability of the claims. While the comment identifies a potential issue and suggests a need for additional explanation, it does not provide specific guidance on how to address the problem or what kind of explanations are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a specific issue with the results of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that these results may be due to large variance or uncareful design and recommends providing more explanations to support the reliability of the claims. However, the comment does not specify which part of the paper these results are discussed in, making it weakly grounded. The comment is specific in detailing the issue and the need for additional explanations. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that certain in-context learning baselines underperform the backbone due to large variance or uncareful design. The comment suggests that more explanations are needed to support the reliability of the claims. However, the claim lacks specific examples, detailed reasoning, or references to substantiate the assertion about the underperformance or the issues with the baselines. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the results of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that these results may be due to large variance or uncareful design of the baselines and recommends providing more explanations to support the reliability of the claims. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their results and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to investigate and address the issue of large variance or uncareful design. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a specific issue with the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that these results may be due to large variance or uncareful design and recommends providing more explanations to support the reliability of the claims. While the comment highlights a potential problem, it does not provide explicit guidance on how to address it or what specific explanations are needed. The action is implicit and somewhat vague, leaving the authors to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a specific issue with the performance of in-context learning baselines, such as static few-shot and chain-of-thought, which underperform the backbone in many items. It suggests that these results may be due to large variance or uncareful design and recommends providing more explanations to support the reliability of the claims. However, the comment does not specify which part of the paper discusses these results, making it weakly grounded. The authors might infer that it relates to sections discussing the experimental results or baselines, but this is not explicitly stated. The comment is specific in detailing the issue and the need for additional explanations. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that certain in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone due to large variance or uncareful design. The comment suggests that more explanations are needed to support the reliability of the claims. However, the claim lacks specific examples, detailed reasoning, or references to substantiate the assertion about the underperformance or the issues with the baselines. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the performance of in-context learning baselines,"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an ambiguity in the key innovation of GFNSeqEditor, specifically regarding the clarity of the claim that it produces novel sequences with improved properties. The reviewer suggests that the paper should better articulate the novel techniques or insights that lead to these claimed improvements. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific improvements or techniques that need to be clarified. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ambiguity in the key innovation of GFNSeqEditor, specifically regarding the clarity of the claim that it produces novel sequences with improved properties. It suggests that the paper should better articulate the novel techniques or insights that lead to these claimed improvements. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the clarity of the key innovation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the key innovation in the paper, specifically regarding the claim that GFNSeqEditor produces novel sequences with improved properties. The reviewer suggests that the paper should better articulate the novel techniques or insights that lead to these claimed improvements. While the comment identifies a potential issue with the clarity of the innovation, it lacks specific examples or detailed reasoning to support the claim. The authors may find it challenging to address the feedback without more explicit guidance on what aspects need clarification. Therefore, the comment is somewhat verifiable, as it highlights a concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the clarity of the key innovation in the paper, specifically regarding the claim that GFNSeqEditor produces novel sequences with improved properties. It suggests that the paper should better articulate the novel techniques or insights that lead to these claimed improvements, thereby enhancing the reader's understanding of the method's unique value. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and insights into their method's innovations. However, the comment could be more helpful if it offered specific suggestions on how to articulate these novel aspects or provided examples of what kind of information would be beneficial. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and impact of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment to show that it is less at risk to biases compared to other methods. While the action is explicit, it lacks concrete details on what specific experiments should be conducted or how to design them. The authors are given a clear direction to address the issue but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the faithfulness of the proposed approach and suggests that the authors need to demonstrate their claim about the method being less at risk to biases with at least a simple experiment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a demonstration of the claim, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to demonstrate the faithfulness of their proposed approach by conducting a simple experiment to show that it is less at risk to biases compared to other methods. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the current demonstration is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the faithfulness of the proposed approach and suggesting that the authors demonstrate their claim about the method being less at risk to biases with at least a simple experiment. This feedback is clear and actionable, providing a concrete suggestion for the authors to address the issue of faithfulness. However, the comment could be more helpful if it offered additional guidance on how to design the experiment or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is limited to state-action spaces, which may not be suitable for continuous real-world applications. It suggests that this limitation is not the best \"motivation\" for the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative motivations or modifications to the method. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft in response to this critique. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"Most real-world applications are continuous in nature and are quite difficult to discretize or solve with discrete state-action spaces,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, which is its limitation to state-action spaces, making it not the best \"motivation\" for the method. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is limited to state-action spaces, which may not be suitable for continuous real-world applications. This claim is somewhat verifiable as it provides a logical reasoning that real-world applications are often continuous and difficult to discretize. However, the comment lacks specific examples or references to support the assertion that the method is not suitable for continuous applications. Providing such details would strengthen the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the manuscript, specifically the limitation of the proposed method to state-action spaces, which may not be suitable for continuous real-world applications. It suggests that this limitation is not the best \"motivation\" for the proposed method. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the motivation for their method. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation of the proposed method, noting that it is limited to state-action spaces and may not be suitable for continuous real-world applications. However, it does not provide any explicit guidance or suggestions on how the authors might address this limitation or improve the motivation for their method. The feedback lacks actionable details, leaving the authors uncertain about how to enhance their draft in response to this critique. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence in the manuscript, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the proposed method, which is its limitation to state-action spaces, making it not the best \"motivation\" for the method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is limited to state-action spaces, which may not be suitable for continuous real-world applications. This claim is somewhat verifiable as it provides a logical reasoning that real-world applications are often continuous and difficult to discretize. However, the comment lacks specific examples or references to support the assertion that the method is not suitable for continuous applications. Without additional evidence or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, noting that it is limited to state-action spaces and may not be suitable for continuous real-world applications. This is a relevant observation that could impact the applicability and relevance of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the motivation for their method. While it highlights an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation of the proposed method, noting that it is limited to state-action spaces and may not be suitable for continuous real-world applications. However, it does not provide"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the competitiveness of the experiment results compared to state-of-the-art (SOTA) methods and the clarity of the presentation of the main results in Table 1. It suggests that the baseline should be moved to the ablation study and only show the proposed method. While the comment provides explicit actions for the authors to take, it lacks concrete details on how to improve the clarity of the presentation or what specific changes should be made to the table. The authors are given a clear direction but without detailed guidance on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the competitiveness of the results compared to state-of-the-art (SOTA) methods and the clarity of the presentation in Table 1, particularly regarding the use of different backbones compared to prior methods. The comment also suggests moving the baseline to the ablation study and only showing the proposed method. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with state-of-the-art (SOTA) methods, suggesting that they only have minor improvements. However, the comment lacks specific examples or detailed comparisons to substantiate this claim. Additionally, it mentions that the presentation of the main results in Table 1 is unclear due to the use of different backbones compared to prior methods. While the comment provides some reasoning, it does not offer concrete evidence or references to support the claim about the competitiveness of the results. This makes the claim somewhat verifiable, as it provides some insight but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the competitiveness of the experiment results compared to state-of-the-art (SOTA) methods and the clarity of the presentation of the main results in Table 1. It suggests that the baseline should be moved to the ablation study and only show the proposed method. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to enhance the competitiveness of the results or improve the clarity of the presentation. The feedback is somewhat helpful as it points out specific issues but does not provide detailed, actionable advice for the authors to address these concerns effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two main issues: the competitiveness of the experiment results compared to state-of-the-art (SOTA) methods and the clarity of the presentation of the main results in Table 1. It suggests that the baseline should be moved to the ablation study and only show the proposed method. While the comment provides explicit actions for the authors to take, it lacks detailed guidance on how to improve the clarity of the presentation or what specific changes should be made to the table. The authors are given clear directions but without detailed instructions on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the competitiveness of the results compared to state-of-the-art (SOTA) methods and the clarity of the presentation in Table 1, particularly regarding the use of different backbones compared to prior methods. The suggestion to move the baseline to the ablation study and only show the proposed method provides clear guidance on what needs to be addressed. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not very competitive with state-of-the-art (SOTA) methods, suggesting that they only have minor improvements. However, the comment lacks specific examples or detailed comparisons to substantiate this claim. Additionally, it mentions that the presentation of the main results in Table 1 is unclear due to the use of different backbones compared to prior methods. While the comment provides some reasoning, it does not offer comprehensive justification or evidence to support the claim about the competitiveness of the results. This makes the claim somewhat verifiable, as it provides some insight but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback provides a clear and explicit action for the authors to take, which is to clarify the copyright scenario in their manuscript. The comment is specific in its request, leaving no ambiguity about what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, it does not specify which part of the manuscript should address this issue, making it weakly grounded. The comment is specific in its request for clarification on the copyright scenario, providing a clear direction for the authors to improve their draft. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the manuscript. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the manuscript could benefit from a clearer delineation of the copyright scenario. It provides a clear and actionable suggestion by asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is valuable as it guides the authors to clarify a potentially confusing aspect of their work, which could enhance the clarity and comprehensibility of their manuscript. However, the comment could be more helpful if it offered additional guidance or examples on how to present this information effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical justification and intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014an intuitive explanation or theoretical justification for the observed behavior. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the theoretical justification and intuitive explanation provided in the paper regarding the behavior of low-rank and high-rank adapters. It points out that there is no theoretical basis or explanation for why these adapters acquire domain-agnostic or domain-specific information, respectively, beyond experimental observation. This feedback highlights an important area for improvement, as understanding the underlying mechanisms could enhance the paper\\'s theoretical contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing theoretical frameworks or models to explore. While it provides a clear direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the lack of theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a gap in the theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014an intuitive explanation or theoretical justification for the observed behavior. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for why low-rank and high-rank adapters acquire domain-agnostic and domain-specific information, respectively. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain-specific information, respectively. This is an important area for improvement, as understanding the underlying mechanisms could enhance the paper\\'s theoretical contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary theoretical justification. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a gap in the paper regarding the theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of acquiring domain-agnostic and domain"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statement on local explanations, specifically questioning why it is true that local models will only be nontrivial if the data point is near a decision boundary. It also asks why we cannot measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors should address these questions or clarify the statement. The authors are left to infer that they need to provide additional explanation or justification, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the statement about local models being nontrivial only if the data point is near a decision boundary and asks for clarification on why this is true. Additionally, it raises a specific point about measuring differences in probabilities, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the statement regarding local models and decision boundaries. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the statement regarding local explanations, specifically questioning why local models will only be nontrivial if the data point is near a decision boundary. It also asks why we cannot measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" This feedback is somewhat helpful as it prompts the authors to clarify and potentially expand on their explanation of local explanations. However, it lacks specific suggestions or guidance on how the authors might address these questions or improve their explanation. While it identifies areas for clarification, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and suggests including results on classic datasets like CIFAR-10 and CIFAR-100. This feedback provides a clear and explicit action for the authors to take, which is to expand their experimental evaluation to include these classic datasets. The suggestion is concrete, as it specifies exactly what additional results should be included to enhance the comprehensiveness of the study. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and the specific datasets \"ImageNet,\" \"CIFAR-10,\" and \"CIFAR-100,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on classic datasets like CIFAR-10 and CIFAR-100. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and suggests including results on classic datasets like CIFAR-10 and CIFAR-100. This is a factual observation rather than a claim or suggestion requiring verification. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental evaluation, noting that the results are only reported on ImageNet and do not include classic datasets like CIFAR-10 and CIFAR-100. This feedback is clear and actionable, as it provides a direct suggestion for expanding the experimental scope to include additional datasets. By addressing this point, the authors can enhance the comprehensiveness and generalizability of their findings. However, the comment could be more helpful if it explained why including these datasets is important or how it might impact the results. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the DinoSR part in Figure 1, specifically noting that the softmax layer is not clearly shown in the figure, unlike in the original DinoSR paper. The reviewer implies that the authors should clarify the figure to match the description in the text. While the comment identifies a specific issue, it does not provide explicit instructions on how to resolve it, such as suggesting ways to improve the figure or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the confusion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the softmax layer is not clearly shown in the figure, unlike in the original DinoSR paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, unlike in the original DinoSR paper. The reviewer provides a logical reasoning by comparing the figure with the original paper, which is considered clear. This comparison offers a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or details about how the figure is confusing, which would enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the softmax layer is not clearly shown in the figure, unlike in the original DinoSR paper. This feedback is valuable as it highlights a potential confusion in the presentation of the figure, which could impact the reader\\'s understanding of the paper. By pointing out this discrepancy, the reviewer provides the authors with a clear direction for improvement, namely to ensure that the figure accurately reflects the text description. However, the comment could be more helpful if it offered suggestions on how to improve the figure or what specific changes should be made. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the softmax layer is not clearly shown, unlike in the original DinoSR paper. While it highlights the problem, it does not provide explicit instructions on how to address it, such as suggesting ways to improve the figure or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to resolve the confusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the softmax layer is not clearly shown in the figure, unlike in the original DinoSR paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, unlike in the original DinoSR paper. The reviewer provides a logical reasoning by comparing the figure with the original paper, which is considered clear. This comparison offers a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or details about how the figure is confusing, which would enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the softmax layer is not clearly shown, unlike in the original DinoSR paper. This feedback is valuable as it highlights a potential confusion in the presentation of the figure, which could impact the reader\\'s understanding of the paper. By pointing out this discrepancy, the reviewer provides the authors with a clear direction for improvement, namely to ensure that the figure accurately reflects the text description. However, the comment could be more helpful if it offered suggestions on how to improve the figure or what specific changes should be made. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more related work on causal inference, specifically mentioning three references ([1], [2], [3]). While the comment implies that the authors should review these works, it does not explicitly instruct them to do so or provide guidance on how to integrate these references into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should review these works and integrate them into their discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should review related work on causal inference and mentions specific references ([1], [2], [3]). However, it does not specify which part of the paper should include this review or how it should be integrated, making it difficult for the authors to pinpoint the exact section that needs revision. The authors can infer that it relates to the literature review or discussion sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting related works to consider, but without clear guidance on where to integrate this information, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more related work on causal inference, specifically mentioning references [1], [2], and [3]. While the comment implies that these references are relevant, it does not provide detailed reasoning or justification for why these specific works are important or how they relate to the paper. The lack of explicit explanation or context makes it difficult for the authors to understand the significance of these references or how they should be integrated into the paper. Therefore, the claim is somewhat verifiable, as it provides a suggestion but lacks sufficient detail to fully substantiate the reasoning behind it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include more related work on causal inference, specifically mentioning three references ([1], [2], [3]). This feedback is somewhat helpful as it identifies a specific area for improvement by recommending additional literature to consider. However, the comment lacks detailed guidance on how to integrate these references into the paper or why they are particularly relevant. Without further elaboration, the authors may find it challenging to effectively incorporate this feedback into their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that sections 3.1 and 3.2 could be avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. It also points out that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. While the comment provides a clear action to consider using the LLM2Vec encoder and suggests a validation method (ablation studies), it does not specify how to conduct these studies or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to avoid these sections if the authors used the LLM2Vec encoder, which is already cited in the paper. The comment further specifies the need for validation with ablation studies to justify the decision not to use the LLM2Vec encoder. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that sections 3.1 and 3.2 could be avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. The reviewer questions the reasoning behind not adopting this approach and suggests that the decision should be validated with ablation studies. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or detailed explanations of how the LLM2Vec encoder could be used or what ablation studies would entail. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the paper by suggesting that sections 3.1 and 3.2 could be avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. It points out that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for improvement by recommending the use of the LLM2Vec encoder and the need for validation through ablation studies. However, the comment could be more helpful if it included additional guidance on how to conduct these studies or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. While this observation highlights a potential limitation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including real-world problems in their experiments, but it does not specify how to do so or why this inclusion would be beneficial. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and no real-world problems are included. This provides a clear indication of what aspect of the experiments is being critiqued, making the comment fully grounded. However, it lacks specificity as it does not detail why the inclusion of real-world problems is important or how it could be addressed. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup. However, the comment lacks specific examples or references to real-world problems that could have been used, which would strengthen the claim. The authors might find it challenging to address this feedback without additional context or suggestions for real-world problems. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment points out a limitation in the experimental setup, specifically that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This feedback is somewhat helpful as it identifies a potential weakness in the evaluation of the method, prompting the authors to consider incorporating real-world problems to strengthen the validity of their claims. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending particular real-world problems or datasets to include. To be more helpful, the comment could provide examples or references to real-world problems that could be used in the experiments. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. While this observation highlights a potential limitation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including real-world problems in their experiments, but it lacks specific instructions or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and no real-world problems are included. This provides a clear indication of what aspect of the experiments is being critiqued, making the comment fully grounded. However, it lacks specificity as it does not detail why the inclusion of real-world problems is important or how it could be addressed. The comment highlights a potential limitation but does not provide actionable guidance for improvement. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup. However, the comment lacks specific examples or references to real-world problems that could have been used, which would strengthen the claim. Without additional context or suggestions for real-world problems, the authors may find it challenging to address this feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, specifically noting that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This feedback highlights a potential weakness in the evaluation of the method, suggesting that the authors should consider incorporating real-world problems to strengthen the validity of their claims. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending particular real-world problems or datasets to include. While it points out an important area for"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors conduct a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify the findings regarding the challenge of distinguishing roles using explanation-focused cues. While the comment implies a specific action\u2014conducting an analysis\u2014it does not provide detailed guidance on how to perform this analysis or what specific aspects to focus on. The action is concrete but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the challenge of distinguishing roles using explanation-focused cues. It suggests that this challenge might be due to LLMs relying more on language style than informational depth. The comment also proposes a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for further analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging, suggesting that LLMs might rely more on language style than informational depth. The comment provides a logical reasoning by proposing a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the details of the analysis required to address the claim, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific challenge in the paper, namely the difficulty in distinguishing roles using explanation-focused cues. It suggests that this might be due to LLMs relying more on language style than informational depth. The comment provides a constructive suggestion for improvement by recommending a detailed analysis of benchmark sentence differences between explanation and listener-focused parts. This feedback is clear and actionable, offering the authors a concrete direction to enhance their analysis and potentially strengthen their findings. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the analysis. Overall, the comment is mostly helpful, as it provides valuable insights and a clear path for improvement.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a challenge in distinguishing roles using explanation-focused cues and suggests that this might be due to LLMs relying more on language style than informational depth. It proposes a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects to focus on. The action is concrete but inferred, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the challenge of distinguishing roles using explanation-focused cues. It suggests that this challenge might be due to LLMs relying more on language style than informational depth. The comment proposes a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, it does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for further analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging, suggesting that LLMs might rely more on language style than informational depth. The comment provides a logical reasoning by proposing a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the details of the analysis required to address the claim, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific challenge in the paper, namely the difficulty in distinguishing roles using explanation-focused cues. It suggests that this might be due to LLMs relying more on language style than informational depth. The comment provides a constructive suggestion for improvement by proposing a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. This feedback is clear and actionable, offering the authors a concrete direction to enhance their analysis and potentially strengthen their findings. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the analysis. Overall, the comment is mostly"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper excessively uses acronyms, which impacts readability, and specifically mentions that the acronym \"DU\" is used without a clear definition. This feedback implies that the authors should provide definitions for the acronyms used in the paper, particularly for \"DU.\" While the action is not explicitly stated, it is clear and concrete, as the authors know exactly what needs to be done to improve the readability of their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the issue of heavy use of acronyms in the paper, specifically mentioning the acronym \"DU\" without a clear definition. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper this issue is found in, such as specific sections or paragraphs. The authors can infer that it relates to sections where acronyms are used, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what needs to be addressed. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper excessively uses acronyms, which affects readability, and specifically mentions the acronym \"DU\" being used without a clear definition. This claim is somewhat verifiable as it provides a specific example of an acronym that lacks a definition, which could indeed impact readability. However, the comment does not provide further examples or detailed reasoning on how the use of acronyms generally affects readability, nor does it reference any standards or guidelines for acronym usage. This makes the claim somewhat verifiable, as it provides a starting point but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the excessive use of acronyms, which can affect readability. It highlights the lack of a clear definition for the acronym \"DU,\" which is a concrete example of the problem. This feedback is clear and actionable, as it provides the authors with a specific area to address by ensuring that all acronyms are properly defined. However, the comment could be more helpful if it suggested ways to balance the use of acronyms with definitions to improve readability. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in section 2.3, specifically questioning how it is estimated and whether it is determined using the sample variance of quality values in the training data. It also asks whether the complete covariance matrix is approximated or if a diagonal covariance matrix is assumed, which the reviewer suggests might not be a reasonable assumption for the problem. While the comment identifies specific areas of concern, it does not provide explicit instructions or suggestions for how the authors should address these questions. The authors can infer that they need to clarify or justify their assumptions about variance estimation, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the estimation of variance, particularly regarding its independence from sentences and the method used to determine it. The comment provides clear guidance on what needs to be clarified or addressed, such as how the variance is estimated and whether it is determined using the sample variance of quality values in the training data. This level of detail provides clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the estimation of variance in section 2.3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the assumptions and estimation methods used in section 2.3, specifically regarding the variance of the distribution p(q|s). It asks how the variance is estimated and whether it is determined using the sample variance of quality values in the training data. Additionally, it questions whether the complete covariance matrix is approximated or if a diagonal covariance matrix is assumed, which the reviewer suggests might not be a reasonable assumption for the problem. This feedback is clear and actionable, as it prompts the authors to clarify and justify their assumptions and estimation methods, which are crucial for the validity and robustness of their work. By addressing these questions, the authors can improve the clarity and rigor of their paper. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically mentioning the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this observation is significant, if it needs further investigation, or how the authors should address it in their paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the initial accuracy of the MIL-based baseline model compared to the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically for the NSCLC dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically for the NSCLC dataset. While it identifies a potential area of interest or concern, it lacks depth and does not provide any guidance or suggestions for the authors to address this issue. The comment does not offer insights into why this observation might be significant or how it could be investigated further. Without actionable feedback or specific directions for improvement, the comment is not particularly helpful for the authors in enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using other datasets to explore the generalization of their proposed method across diverse data sources. While the action is explicit, it lacks concrete guidance on which specific datasets to consider or how to incorporate them into the study. The authors are given a clear direction to expand their analysis, but the lack of detailed instructions on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the discussion on the MuAViC dataset, but this inference is not direct. The comment is specific in its suggestion to consider other datasets for generalization, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why other datasets would be beneficial or how they would enhance the generalization of the method. Without such supporting information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should consider using other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is somewhat helpful as it identifies a potential limitation in the current focus on the MuAViC dataset and provides a direction for expanding the scope of the study. However, the comment lacks specific guidance on which datasets to consider or how to incorporate them into the analysis. To be more helpful, the comment could include suggestions for datasets or methodologies to enhance the generalizability of the proposed method. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed at the start of the paper to establish alternative hypotheses and discriminate between them. It implies that the current analysis is confirmatory and lacks a critical test of the hypothesis. The comment provides a clear direction for improvement by suggesting that the authors should establish alternative hypotheses and design experiments to discriminate between them. However, it does not specify which alternative hypotheses to consider or how to implement these changes, leaving some ambiguity in execution. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed at the start of the paper to establish alternative hypotheses and discriminate between them. It implies that the current analysis is confirmatory and lacks a critical test of the hypothesis. However, the comment does not specify which part of the paper this issue is related to, such as the introduction or methodology sections, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely establishing alternative hypotheses and designing experiments to discriminate between them. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed to establish alternative hypotheses and discriminate between them. The comment provides a logical reasoning by questioning the current analysis as a confirmatory one and highlights the need for a critical test of the hypothesis. However, it lacks specific examples or references to support the claim or suggest how to address the issue. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully actionable by the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed at the start of the paper to establish alternative hypotheses and discriminate between them. It points out that the current analysis is confirmatory and lacks a critical test of the hypothesis. The comment provides a clear direction for improvement by emphasizing the need to establish alternative hypotheses and design experiments to discriminate between them. This feedback is actionable and encourages the authors to broaden their analysis and provide a more comprehensive evaluation of their systems. However, the comment could be more helpful if it offered specific examples of alternative hypotheses or suggested methods for testing them. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed at the start of the paper to establish alternative hypotheses and discriminate between them. It implies that the current analysis is confirmatory and lacks a critical test of the hypothesis. While the comment identifies a potential issue, it does not provide explicit guidance or concrete steps for the authors to address it. The authors are left to infer that they need to establish alternative hypotheses and design experiments to discriminate between them, but without specific suggestions, the action remains vague. Therefore, the comment is somewhat actionable, as it points out an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The review comment raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed at the start of the paper to establish alternative hypotheses and discriminate between them. It implies that the current analysis is confirmatory and lacks a critical test of the hypothesis. However, the comment does not specify which part of the paper this issue is related to, such as the introduction or methodology sections, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely establishing alternative hypotheses and designing experiments to discriminate between them. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expectation of Bayes-optimality in the systems being investigated and suggests that more work is needed to establish alternative hypotheses and discriminate between them. The comment implies that the current analysis is confirmatory and lacks a critical test of the hypothesis. While it provides a logical reasoning by questioning the current analysis and suggesting the need for alternative hypotheses, it does not provide specific examples or references to support the claim. The comment lacks"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add confidence intervals to the reported values in Table 1, which provides the performance of different fairness improvement techniques. This feedback is clear and specific, giving the authors a direct action to take to improve their draft. The suggestion is concrete, as it specifies exactly what needs to be added to the table to enhance the analysis. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being very close, making it difficult to draw conclusions. The comment suggests adding confidence intervals to provide a clearer understanding of the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to address this issue. While the comment identifies a potential problem with the data presentation, it lacks specific examples or detailed reasoning to support the claim that the values are too close to be meaningful. The suggestion to add confidence intervals is a logical step to address the issue, but the comment itself does not provide enough evidence or justification to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it difficult to draw conclusions. It provides a clear and actionable suggestion by recommending the addition of confidence intervals to provide a clearer understanding of the results. This feedback is valuable as it guides the authors on how to enhance the interpretability and robustness of their findings. However, the comment could be more helpful if it explained why confidence intervals are important or how they would improve the analysis. Overall, the comment is mostly helpful, as it offers a concrete step for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some choices in the paper are not justified or are unclear, but it does not specify which choices are in question or provide any guidance on how to address these issues. The comment ends with a request for questions from the authors, which implies that the authors should provide clarification or justification for these choices. However, without explicit instructions or concrete details, the authors are left to infer what needs to be clarified or justified. The action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that some choices in the paper are not justified or are unclear, but it does not specify which choices are in question or provide any context for where these choices are discussed in the paper. This lack of grounding makes it difficult for the authors to identify the specific parts of the paper that need attention. Additionally, the comment lacks specificity as it does not detail what aspects of the choices are unclear or how they could be justified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some choices in the paper are not justified or are unclear, but it does not provide any specific examples or reasoning to support this claim. The comment ends with a request for questions from the authors, which implies that the reviewer is looking for clarification. Without specific examples or references, the claim remains unverifiable, as it lacks the necessary evidence or explanation to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that some choices in the paper are not justified or are unclear, but it does not specify which choices are in question or provide any guidance on how to address these issues. The comment ends with a request for questions from the authors, which suggests that the authors should provide clarification or justification for these choices. However, without specific examples or detailed feedback, the authors are left without actionable steps to improve their draft. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that affect both FLOPs and accuracy, making the tuning process laborious. It suggests that there should be multiple solutions that hit the same FLOPs, which complicates the tuning process. The reviewer requests detailed discussions regarding the grid search process to improve reproducibility. While the comment identifies a specific issue and suggests a need for detailed discussion, it does not provide explicit instructions on how to conduct the grid search or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameter tuning, specifically mentioning the two hyperparameters that affect both FLOPs and accuracy. It highlights the complexity of the tuning process and requests detailed discussions regarding the grid search process for reproducibility. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where hyperparameters and tuning are discussed. The comment is specific in detailing the issue and the need for detailed discussions, but it lacks explicit grounding in the paper. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that affect both FLOPs and accuracy, making the tuning process laborious. The reviewer suggests that there should be multiple solutions that hit the same FLOPs, complicating the tuning process. While the comment identifies a potential issue with the hyperparameter tuning process, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for detailed discussions regarding the grid search process is a logical request for improvement, but the comment could be strengthened with more explicit evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires additional detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding hyperparameter tuning, noting that the paper has two hyperparameters that affect both FLOPs and accuracy, making the tuning process laborious. It highlights the complexity of the tuning process due to the multiple solutions that can hit the same FLOPs, which complicates the decision-making process. The comment also points out the lack of clarity in the current presentation regarding the grid search process and requests detailed discussions on this issue for reproducibility. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a method for enhancing the paper\\'s clarity and reproducibility. However, it could be more helpful if it offered specific guidance on how to conduct the grid search or what aspects to discuss in more detail. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, and it questions the clarity of the difference between known and unknown attacks. While the comment highlights a specific issue, it does not provide explicit guidance on how to address it. The authors can infer that they need to include the accuracies in Figure 1 to clarify the distinction, but the comment lacks concrete instructions on how to present this information. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of accuracies of the target model using different defenses against the FGSM attack in Figure 1. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear whether known attacks differ from unknown attacks. This claim is somewhat verifiable as it highlights a gap in the presentation of results, but it lacks specific examples or references to support the assertion about the difference between known and unknown attacks. The authors would need to infer the potential impact of this omission, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of results in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This omission makes it unclear whether known attacks differ from unknown attacks. The comment is clear and actionable, as it directly points out a gap in the presentation that the authors can address to improve the clarity and comprehensiveness of their results. However, it could be more helpful if it provided suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that some figures are difficult to read and recommends using a log-scale for the y-axis to improve readability. This feedback provides a clear and direct action for the authors to take, specifying exactly what change should be made to enhance the clarity of the figures. The suggestion is concrete, as it outlines a specific step the authors can implement to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not specify which figures are problematic, making it difficult for the authors to identify the exact parts of the paper that need attention. While the authors might have an idea of which figures are being referred to, the lack of explicit references makes the comment weakly grounded. The suggestion to use a log-scale is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not provide any specific examples or reasoning to support why this change would improve readability. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of some figures in the paper and provides a clear and actionable suggestion to improve them. By recommending the use of a log-scale for the y-axis, the reviewer offers a concrete step that the authors can take to enhance the clarity and accessibility of their figures. This feedback is valuable as it directly addresses a potential weakness in the presentation of results, providing the authors with a straightforward way to improve their draft. However, the comment could be more helpful if it included additional details on how to implement this change or why it would be beneficial. Overall, the comment is mostly helpful, as it effectively guides the authors toward a specific improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a gap in the validation of the proposed method, specifically mentioning that the authors claimed the method is useful for categories where augmentation information is beneficial, such as flowers and birds. However, the comment notes that this claim was not validated in the experiments. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. While the comment implies that the authors should include these datasets in their experiments, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"case where \"augmentation information is useful\" as claimed by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this claim was not validated in the experiment and suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method was motivated by the usefulness of augmentation information, specifically for categories like flowers and birds, as claimed in the introduction. However, the comment notes that this claim was not validated in the experiments. The reviewer suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. While the comment provides a logical reasoning for the need to validate the claims, it lacks specific references or detailed examples of how these datasets could be used to substantiate the claims. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the validation of the proposed method, specifically noting that the authors claimed the method is useful for categories where augmentation information is beneficial, such as flowers and birds. However, this claim was not supported by experimental validation. The comment suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. This feedback is clear and actionable, providing the authors with a specific direction to improve their work by including additional validation datasets. The suggestion is detailed and constructive, making the comment highly helpful for enhancing the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the paper\\'s claim that opponents will evolve toward the Nash equilibrium and the lack of theoretical analyses or empirical evidence to support this claim. While it highlights a potential issue, it does not provide explicit guidance on how the authors should address it. The comment implies that the authors should include theoretical analyses or empirical evaluations to support their claim, but it does not specify what kind of analyses or evaluations are needed or how to conduct them. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of theoretical analyses and empirical evidence to support the claim that GEMS converges to Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s statement about opponents evolving toward the Nash equilibrium lacks theoretical analyses and empirical evidence to support it. This claim is somewhat verifiable as it highlights a gap between the claim and the evidence provided. However, it does not offer specific examples or references to theoretical analyses or empirical evaluations that could support the claim. The comment suggests that the authors need to provide more evidence to substantiate their claim, but without detailed guidance or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that opponents will evolve toward the Nash equilibrium, noting the lack of theoretical analyses and empirical evidence to support this assertion. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct the theoretical analyses or empirical evaluations needed to support the claim. While it points out a critical area for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between the paper\\'s claim about opponents evolving toward the Nash equilibrium and the lack of theoretical analyses or empirical evidence to support this claim. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The comment implies that the authors should include theoretical analyses or empirical evaluations to support their claim, but it lacks specific suggestions or details on how to conduct these analyses. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of theoretical analyses and empirical evidence to support this claim, providing clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s statement about opponents evolving toward the Nash equilibrium lacks theoretical analyses and empirical evidence to support it. This claim is somewhat verifiable as it highlights a gap between the claim and the evidence provided. However, the comment does not offer specific examples or references to theoretical analyses or empirical evaluations that could support the claim. Without detailed guidance or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that opponents will evolve toward the Nash equilibrium, noting the lack of theoretical analyses and empirical evidence to support this assertion. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct the theoretical analyses or empirical evaluations needed to support the claim. While it points out a critical area for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between the paper\\'s claim about opponents evolving toward the Nash equilibrium and the lack of theoretical analyses or empirical evidence to support this claim. While it identifies a potential issue, it does not"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with Equation (1), including its unclear purpose, the definition of the optimization variable, and the unusual constraints notation. It explicitly asks for clarification on whether the equation defines a loss function or an optimization problem, and whether the optimization variable x should be in R^n or R^k. Additionally, it points out the unusual notation for constraints. These questions provide clear and concrete actions for the authors to take, such as revising the equation to clarify its purpose and ensuring the notation is consistent and understandable. The explicit nature of the questions and the specific areas needing clarification make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with Equation (1), including the unclear purpose, the definition of the optimization variable, and the unusual constraints notation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of Equation (1), specifically questioning its purpose and the definition of the optimization variable. It also points out an unusual notation for constraints. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The authors may need to infer the exact nature of the confusion or how to address it, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with Equation (1), providing clear and actionable feedback for the authors. It questions the purpose of the equation, whether it defines a loss function or an optimization problem, and suggests that it may be mixing both. Additionally, it points out the unusual definition of the optimization variable x as being in R^n, which might be intended to be in R^k. The comment also notes the unusual notation for constraints, \"s.t. C(A, x),\" which could be clarified. By addressing these points, the authors can significantly improve the clarity and precision of their equation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a strange observation in the paper, where including the collected LIV-EN parallel data for fine-tuning actually results in a worse performance of the NMT system. The reviewer explicitly asks for more discussions or explanations on this phenomenon. While the action is clear\u2014providing additional discussions or explanations\u2014the comment does not specify how the authors should approach this task or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation\u2014namely, that including the collected LIV-EN parallel data for fine-tuning results in a worse performance of the NMT system\u2014and asks for more discussions or explanations on this phenomenon. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that including the collected LIV-EN parallel data for fine-tuning results in a worse performance of the NMT system. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the observation and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation in the paper, noting that including the collected LIV-EN parallel data for fine-tuning results in a worse performance of the NMT system. It asks for more discussions or explanations on this phenomenon, which is a clear and actionable request for the authors to provide additional context or analysis. However, the comment could be more helpful if it suggested specific areas or methods for further exploration or analysis. Overall, the feedback is somewhat helpful as it directs the authors to a particular issue that needs clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" and notes the lack of adequate reasoning or references to support these claims. However, it does not provide explicit guidance on how the authors should address this issue or what specific reasoning or references should be included. The action is implicit, as the authors need to infer that they should provide more detailed reasoning and references, but it remains vague due to the lack of concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not explicitly mention which part of the paper this claim is located in, making it weakly grounded. The comment is specific in pointing out the lack of substantiation and reasoning for the conjectures, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. This claim is somewhat verifiable as it highlights a lack of supporting evidence or references, which is a common issue in academic writing. However, the comment does not provide specific examples or detailed reasoning to substantiate the claim, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" It points out the lack of adequate reasoning or references to support these claims, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might substantiate their conjectures or what kind of reasoning or references would be appropriate. While it highlights a significant area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. However, it does not provide explicit guidance on how the authors should address this issue or what specific reasoning or references should be included. The feedback lacks actionable steps or detailed suggestions, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not explicitly mention which part of the paper this claim is located in, making it weakly grounded. The comment is specific in pointing out the lack of substantiation and reasoning for the conjectures, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. This claim is somewhat verifiable as it highlights a lack of supporting evidence or references, which is a common issue in academic writing. However, the comment does not provide specific examples or detailed reasoning to substantiate the claim, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. This feedback highlights a critical area for improvement, as it points out the lack of substantiation for the claims made in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of reasoning or references would be appropriate. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. This is an explicit suggestion, providing a clear action for the authors to take. However, it does not offer detailed guidance on how to incorporate NaturalSpeech 3 into the study or what specific aspects should be compared. While the action is explicit, the lack of concrete details on implementation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where FACodec is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential baseline for comparison, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec could be beneficial. However, the comment does not provide any reasoning or evidence to support why NaturalSpeech 3 would be a suitable baseline or how it would improve the study. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. This is a specific and actionable piece of feedback that could help the authors improve their work by providing a comparative benchmark. However, the comment does not elaborate on why NaturalSpeech 3 is a suitable choice or how it would enhance the study. While it offers a clear direction for improvement, the lack of detailed justification or explanation limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a useful suggestion but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically questioning whether the proposed method should be allowed to train on the first 4 weeks of data while other methods are not. The reviewer explicitly asks for clarification on the experimental setting, indicating that they might have misunderstood it. This comment provides a clear and direct action for the authors to take, which is to clarify the experimental setting and address the fairness concern. The feedback is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the fairness of the experiments, specifically questioning whether the proposed method should be allowed to train on the first 4 weeks of data while other methods are not. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the experimental setting, as it clearly identifies the fairness issue and requests clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically questioning whether the proposed method should be allowed to train on the first 4 weeks of data while other methods are not. The reviewer suggests that this could lead to an unfair advantage for the proposed method. However, the comment lacks specific examples or references to support the claim of unfairness, making it difficult for the authors to fully understand and address the concern. The reasoning is somewhat verifiable, as it highlights a potential issue but requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically questioning whether the proposed method should be allowed to train on the first 4 weeks of data while other methods are not. This feedback highlights a potential issue with the experimental setup that could affect the validity of the results. By pointing out this concern, the reviewer provides the authors with valuable insight into an area that needs clarification or adjustment. However, the comment could be more helpful if it offered suggestions on how to address this fairness issue or provided examples of alternative experimental setups. Overall, the comment is somewhat helpful as it identifies a critical aspect of the experimental design that requires attention, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models, with varying model sizes and sparsity categories. This feedback provides a clear and direct action for the authors to take, specifying exactly what additional results should be included in the paper. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models, with varying model sizes and sparsity categories. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in detailing what additional results should be reported, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models, with varying model sizes and sparsity categories. However, the comment does not provide any justification or reasoning for why this additional information is necessary or how it would impact the paper\\'s conclusions. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors report results on the speedup obtained compared to the dense and SparseGPT models, with varying model sizes and sparsity categories. This feedback is specific and offers a concrete direction for enhancing the completeness and depth of the results section, which can help the authors better demonstrate the performance and efficiency of their approach. However, the comment could be more helpful if it included additional context or reasoning about why this information is important or how it might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it guides the authors on a specific enhancement to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of sequential bias on the VisDial results. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how it should be investigated, or what specific steps should be taken to explore this issue. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of sequential bias on the VisDial results. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. Additionally, the comment lacks specificity regarding what aspects of the sequential bias should be addressed or how it affects the VisDial results. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of sequential bias on the VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \"No\" the correct label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of sequential bias on the VisDial results. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions for the authors to explore this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, the comment is not particularly helpful, aligning with a score of 2, as it barely provides any value for the authors.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. However, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy or improve their draft. The comment raises a concern but lacks actionable steps or concrete advice for the authors to follow. As a result, the authors are left without a clear understanding of what changes, if any, are needed to align the results with the stated goal. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the experimental results on the ImageNet-LT dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the performance improvement for head classes and tail classes, and how this contradicts the stated goal of LTAP. This provides clear guidance on what aspect of the results needs further clarification or explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. This claim is somewhat verifiable as it provides a logical reasoning based on the experimental results. However, the comment lacks specific data or examples from the paper to fully substantiate the claim, such as exact performance metrics or comparisons between ATO, RReg, and LTAP. This makes it challenging for the authors to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. It highlights that LTAP achieves a larger performance improvement for head classes than for tail classes, suggesting a contradiction with the stated goal. This feedback is valuable as it points out a potential weakness in the paper\\'s claims and encourages the authors to address this inconsistency. However, the comment could be more helpful if it provided suggestions on how to resolve this discrepancy or offered insights into potential reasons for the observed results. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. However, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy or improve their draft. The comment lacks actionable steps or concrete advice, leaving the authors without a clear understanding of what changes, if any, are needed to align the results with the stated goal. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the experimental results on the ImageNet-LT dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the performance improvement for head classes and tail classes, and how this contradicts the stated goal of LTAP. This provides clear guidance on what aspect of the results needs further clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. This claim is somewhat verifiable as it provides a logical reasoning based on the experimental results. However, the comment lacks specific data or examples from the paper to fully substantiate the claim, such as exact performance metrics or comparisons between ATO, RReg, and LTAP. This makes it challenging for the authors to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. It highlights that LTAP achieves a larger performance improvement for head classes than for tail classes, suggesting a contradiction with the stated goal. This feedback is valuable as it points out a potential weakness in the paper\\'s claims and encourages the authors to address this discrepancy. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations, as LLMs may generate inaccurate scores. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve the reliability of their evaluation process. The feedback lacks specific suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance on LLM-based evaluation for reward computation, which raises concerns about the reliability of the search process. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about potential biases or inconsistencies in the quality assessment due to LLM-generated scores. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. The claim is supported by logical reasoning, as it highlights the potential for biases or inconsistencies in the quality assessment due to the reliance on LLMs. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It raises concerns about the possibility of introducing biases or inconsistencies in the quality assessment of generated documentations due to the potential inaccuracies in LLM scores. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve the reliability of their evaluation process. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations, as LLMs may generate inaccurate scores. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the reliability of their evaluation process. Without specific actions or recommendations, the authors are left uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance on LLM-based evaluation for reward computation, which raises concerns about the reliability of the search process. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about potential biases or inconsistencies in the quality assessment due to LLM-generated scores. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations, as LLMs may generate inaccurate scores. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to substantiate the claim further. The absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore and verify the concerns themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It raises concerns about the possibility of introducing biases or inconsistencies in the quality assessment of generated documentations due to the potential inaccuracies in LLM scores. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve the reliability of their evaluation process. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the reliability of the reward computation, which relies on LLM-based evaluation by"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples to demonstrate the effectiveness of the described process and compare it to state-of-the-art (SOTA) performance from referenced papers. It also mentions that Equation 12 might contribute to this, but it is unclear. While the comment implies that the authors should clarify Equation 12, it does not explicitly instruct them to do so or provide specific guidance on how to improve the clarity of the equation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify Equation 12 and provide empirical examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effectiveness of the described process is unclear and suggests using empirical examples and comparing to SOTA performance. However, it does not provide specific guidance on how to clarify Eq 12 or what empirical examples to use. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the effectiveness of the described process is surprising and recommends using empirical examples and comparing to state-of-the-art (SOTA) performance. However, it does not provide specific examples or references to support the claim that the process is surprising or unclear. The mention of \"Eq 12\" indicates a potential area of confusion, but without further elaboration or examples, the claim remains vague. This lack of detailed justification or evidence makes the comment borderline verifiable, as it provides some direction but insufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the effectiveness of the described process, suggesting that it is surprising and recommending the use of empirical examples and comparisons to state-of-the-art (SOTA) performance. It also points out that Equation 12 might contribute to this but is unclear. This feedback is somewhat helpful as it highlights a potential weakness in the paper and provides a direction for improvement by suggesting the use of empirical examples and comparisons. However, the comment could be more helpful if it offered specific guidance on how to clarify Equation 12 or provided examples of how to effectively use empirical examples. Overall, the comment provides some actionable insights but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples to demonstrate the effectiveness of the described process and compare it to state-of-the-art (SOTA) performance from referenced papers. It also mentions that Equation 12 might contribute to this but is unclear. While the comment identifies areas for improvement, it does not explicitly instruct the authors to clarify Equation 12 or provide specific guidance on how to enhance the empirical examples. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effectiveness of the described process is surprising and suggests using empirical examples and comparing to state-of-the-art (SOTA) performance from referenced papers. However, it lacks specificity in terms of providing detailed guidance on how to clarify Eq 12 or what specific empirical examples to use. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the effectiveness of the described process is surprising and recommends using empirical examples and comparing to state-of-the-art (SOTA) performance. However, it does not provide specific examples or references to support the claim that the process is surprising or unclear. The mention of \"Eq 12\" indicates a potential area of confusion, but without further elaboration or evidence, the claim remains vague. This lack of detailed justification or evidence makes the comment borderline verifiable, as it provides some direction but insufficient support for the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the effectiveness of the described process is surprising and suggesting that empirical examples and comparisons to state-of-the-art (SOTA) performance should be used to clarify this. It also mentions that Equation 12 might contribute to this but is unclear. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to address the issue or clarify Equation 12. The feedback is somewhat helpful as it points out a potential weakness but does"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem and provides a detailed explanation of Assumption 1, which limits the adversary\\'s ability to select samples. It also offers a specific example of how the assumption affects the number of samples after removal, suggesting that it still suffices for accurate recovery under certain conditions. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The feedback is more of an observation and explanation rather than a direct action for the authors to take. As a result, the comment is somewhat actionable, as it provides insight but lacks concrete steps for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1\" and provides a specific explanation of the problem\\'s difficulty, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by explaining the limitations of Assumption 1 and provides a detailed example to illustrate the point. This level of detail and clarity makes the comment fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of how the assumption limits the adversary\\'s ability to select samples and offers a specific example to illustrate the point. This detailed reasoning and example provide a robust foundation for the claim, making it fully verifiable. The authors can follow the reasoning and example to understand and address the concern effectively. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the difficulty of the problem being addressed, specifically focusing on Assumption 1. It provides a detailed explanation of the assumption and its implications, including a specific example to illustrate how it affects the number of samples after removal. This level of detail and clarity is highly beneficial for the authors, as it allows them to understand the critique and potentially address it in their work. However, the comment could be more helpful if it offered suggestions on how to strengthen the argument or improve the draft. Overall, the feedback is mostly helpful as it provides valuable insights and a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of the assumption and its implications, including a specific example to illustrate the point. However, the comment does not offer explicit guidance or suggestions on how the authors might address this concern or improve their draft. While it provides valuable insight, the lack of actionable steps or concrete advice makes it somewhat actionable. The authors are informed of the issue but are left to determine how to address it themselves.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific explanation of the problem\\'s difficulty and uses a detailed example to illustrate the point. This level of detail and clarity makes the comment fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of the assumption and its implications, including a specific example to illustrate the point. This detailed reasoning and example provide a robust foundation for the claim, making it fully verifiable. The authors can follow the reasoning and example to understand and address the concern effectively. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the difficulty of the problem being addressed, specifically focusing on Assumption 1. It provides a detailed explanation of the assumption and its implications, including a specific example to illustrate the point. This level of detail and clarity is highly beneficial for the authors, as it allows them to understand the critique and potentially address it in their work. However, the comment could be more helpful if it offered suggestions on how to strengthen the argument or improve the draft. Overall, the feedback is mostly helpful as it provides valuable insights and a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the difficulty of the problem being addressed, specifically focusing on Assumption 1. It provides a detailed explanation of the assumption and its implications, including a specific example to illustrate the point. However, the comment does not"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between Figure 1 and the last two columns of Table 1, specifically regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, it does not provide explicit guidance on how the authors should address this contradiction or suggest specific actions to resolve it. The comment implies that the authors should investigate and clarify this discrepancy, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 and the last two columns of Table 1 contradict each other regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, the comment does not provide specific details or examples from the figures or table to support this claim. Without detailed evidence or references, the authors may find it challenging to understand and address the contradiction. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This feedback is valuable as it points out a potential error or inconsistency in the paper that the authors need to address. However, the comment does not provide specific guidance on how to resolve this contradiction or suggest ways to clarify the relationship between the two figures. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, it does not provide explicit guidance on how the authors should address this contradiction or suggest specific actions to resolve it. The comment implies that the authors need to investigate and clarify this discrepancy, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the last two columns of Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, the comment does not provide specific details or examples from the figures or table to support this claim. Without detailed evidence or references, the authors may find it challenging to understand and address the contradiction. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. This is a valuable observation that could help the authors ensure the accuracy and consistency of their results. However, the comment lacks specific guidance or suggestions on how the authors should address this contradiction or clarify the relationship between the figures and table. While it points out an important issue, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a contradiction between Figure 1 and the last two columns of Table 1 regarding the relationship between NNGS"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It specifically asks about the impact of a large number of tasks on the set of shared parameters and requests the authors to address this question in their experiments. The comment provides a clear and explicit action for the authors to take, which is to address the impact of the number of tasks on their approach. The suggestion is concrete, as it specifies exactly what needs to be investigated and presented in the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It specifically asks about the impact of a large number of tasks on the set of shared parameters and requests the authors to address this question in their experiments. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the experiments are discussed. The comment is specific in detailing what needs to be addressed regarding the impact of the number of tasks on the proposed approach. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests the authors to address this in their experiments. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the challenges in multitask learning. The suggestion for addressing the question is clear, but the claim itself is not fully substantiated with detailed reasoning or evidence. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the concern but requires more detailed justification to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It specifically asks about the impact of a large number of tasks on the set of shared parameters and requests the authors to address this question in their experiments. This feedback is clear and actionable, as it prompts the authors to consider and discuss the scalability of their approach. By addressing this question, the authors can provide insights into the limitations and potential improvements of their method. However, the comment could be more helpful if it offered suggestions on how to investigate or mitigate the challenges mentioned. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the eyetracking data selection/filtering is perplexing, suggesting that everything is analyzed with some exclusions. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify or improve the analysis, nor are there suggestions for additional experiments or explanations. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"eyetracking data selection/filtering\" and notes that it appears everything is analyzed with some exclusions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the eyetracking data selection/filtering are perplexing or how they could be clarified. Without clear references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point describes a perceived issue with the eyetracking data selection/filtering, stating that \"it looks like everything is analyzed with some exclusions.\" However, the comment lacks specific examples, detailed reasoning, or references to support the claim that this approach is perplexing or problematic. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the eyetracking data selection/filtering, noting that it appears everything is analyzed with some exclusions. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or clarify the analysis. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the credibility of the Appendix results for InitNO, noting that while InitNO reported improved text-image alignment on StableDiffusion-v1-4, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the credibility of their results. It lacks specific actions or recommendations, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and references \"Table 6,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the credibility of the Appendix results, noting that while InitNO reported improved text-image alignment, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the credibility of the Appendix results for InitNO, referencing a specific table (Table 6) that shows InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This provides a logical basis for the claim, as it directly compares the results presented in the paper. However, the comment could be strengthened by providing more detailed reasoning or additional evidence to fully substantiate the claim. As it stands, the comment is mostly verifiable, as it offers a clear comparison but lacks comprehensive justification or references to support the claim fully. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the Appendix results for InitNO, noting that while the paper reported improved text-image alignment on StableDiffusion-v1-4, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This feedback is somewhat helpful as it identifies a potential issue with the credibility of the results presented in the Appendix. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the credibility of their results. To be more helpful, the comment could include recommendations for verifying the results or suggesting additional analyses to support the credibility of the findings. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the credibility of the Appendix results for InitNO, noting that while the paper reported improved text-image alignment on StableDiffusion-v1-4, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the credibility of their results. It lacks specific actions or recommendations, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and references \"Table 6,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the credibility of the Appendix results, noting that while InitNO reported improved text-image alignment, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the credibility of the Appendix results for InitNO, referencing a specific table (Table 6) that shows InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. This provides a logical basis for the claim, as it directly compares the results presented in the paper. However, the comment could be strengthened by providing more detailed reasoning or additional evidence to fully substantiate the claim. While the comparison is clear, the lack of comprehensive justification or references makes the claim mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the Appendix results for Init"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could benefit from additional editing, particularly from a language-usage and type perspective, rather than a technical perspective. It also mentions that the equations' notation can become unwieldy and suggests considering the possibility of dropping some sub/superscripts for convenience, with the note to indicate this decision. While the comment provides explicit suggestions for improvement, it lacks detailed guidance on which specific parts of the writing or equations should be edited or simplified. The authors are given a clear direction to improve the clarity and readability of their draft, but the lack of specific examples or detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the writing style and the complexity of equations, suggesting that some sub/superscripts could be dropped for convenience. However, it does not specify which parts of the writing or equations are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is weakly grounded because it does not explicitly mention specific sections or equations, but it is specific in suggesting a potential solution. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly from a language-usage and type perspective. It also mentions that the equations' notation can become unwieldy and suggests considering the possibility of dropping some sub/superscripts for convenience. While the comment provides some reasoning for the suggestion, it lacks specific examples or detailed explanations of where the writing is uneven or where the notation becomes unwieldy. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issues without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of observations and suggestions for improvement. It notes that the writing is uneven and could benefit from additional editing, particularly from a language-usage and type perspective. This feedback is somewhat helpful as it highlights an area for improvement, but it lacks specific guidance on how to address the unevenness or what aspects of the writing need improvement. Additionally, the comment suggests considering the possibility of dropping some sub/superscripts in equations for convenience, which is a concrete suggestion. However, it does not provide examples or detailed guidance on which sub/superscripts could be dropped. Overall, the comment offers some actionable advice but could be more comprehensive and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the writing could benefit from additional editing, particularly from a language-usage and type perspective, rather than a technical perspective. It also mentions that the equations' notation can become unwieldy and suggests considering the possibility of dropping some sub/superscripts for convenience, with the note to indicate this decision. While the comment provides explicit suggestions for improvement, it lacks specific guidance on which parts of the writing or equations should be edited or simplified. The authors are given a clear direction to improve the clarity and readability of their draft, but the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the writing style and the complexity of equations, suggesting that the notation could become unwieldy. It provides a specific suggestion to consider dropping some sub/superscripts for convenience, with the note to indicate this decision. However, the comment does not specify which parts of the writing or equations are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of explicit references to specific sections or equations results in weak grounding. Despite this, the comment is specific in its suggestion to simplify the notation. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly from a language-usage and type perspective. It also mentions that the equations' notation can become unwieldy and suggests considering the possibility of dropping some sub/superscripts for convenience. While the comment provides some reasoning for the suggestion, it lacks specific examples or detailed explanations of where the writing is uneven or where the notation becomes unwieldy. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issues without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of observations and suggestions for improvement. It notes"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: the small size of the dataset relative to the development cost and the need for an explanation of the image acquisition cost and manual collection methods. It also mentions a minor comment regarding the clarity of a line in the manuscript and a request for clarification on \"regulatory requirements\" and \"politically sensitive\" content. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more information and clarification, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two distinct issues: the small size of the dataset relative to the development cost and the need for clarification on specific lines in the manuscript. It also mentions a minor comment regarding the clarity of a line and a request for clarification on \"regulatory requirements\" and \"politically sensitive\" content. While the comment does not explicitly mention specific lines or sections, the authors can infer that it pertains to the methodology and discussion sections. The comment is specific in detailing what needs to be clarified or addressed, but it lacks full grounding as it does not explicitly mention the exact lines or sections. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: the small size of the dataset relative to the development cost and the need for clarification on specific lines in the manuscript. The first claim is somewhat verifiable as it suggests that the dataset size is disproportionate to the cost, but it lacks specific details or examples to substantiate this claim. The second claim about the line reading is more straightforward and can be addressed with clarification. Overall, the review point provides some support for its claims but lacks detailed evidence or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two distinct areas for improvement. First, it points out that the dataset size is relatively small compared to the development cost, suggesting that the authors should explain the rationale behind the high cost of image acquisition and the nature of the manual collection process. This feedback is actionable and prompts the authors to provide more context and justification for their dataset choices. Second, the comment highlights a minor issue with the clarity of a line in the manuscript, suggesting that it contains two questions and asking for clarification on \"regulatory requirements\" and \"politically sensitive\" content. This feedback is also actionable, as it guides the authors to improve the clarity and precision of their writing. Overall, the comment is mostly helpful as it provides specific and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises two issues: the small size of the dataset relative to the development cost and the need for clarification on specific lines in the manuscript. It suggests that the authors should explain the image acquisition cost and the manual collection process. Additionally, it points out a minor comment regarding the clarity of a line and requests clarification on \"regulatory requirements\" and \"politically sensitive\" content. While the comment identifies areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The review comment addresses two distinct issues: the small size of the dataset relative to the development cost and the need for clarification on specific lines in the manuscript. It also mentions a minor comment regarding the clarity of a line and a request for clarification on \"regulatory requirements\" and \"politically sensitive\" content. While the comment does not explicitly mention specific lines or sections, the authors can infer that it pertains to the methodology and discussion sections. The comment is specific in detailing what needs to be clarified or addressed, but it lacks full grounding as it does not explicitly mention the exact lines or sections. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: the small size of the dataset relative to the development cost and the need for clarification on specific lines in the manuscript. The first claim is somewhat verifiable as it suggests that the dataset size is disproportionate to the cost, but it lacks specific details or evidence to substantiate this claim. The second claim about the line reading is more straightforward and can be addressed with clarification. Overall, the review point provides some support for its claims but lacks detailed evidence or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two distinct areas for improvement. First,"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the generation of the third column of Figure 7, noting that the visualizations appear to lack normalization. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this curiosity or improve the figure. The comment implies that the authors should investigate and clarify the normalization process, but it does not specify how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the generation of the third column and the lack of normalization in the visualizations. This provides clear guidance on what the authors need to investigate or clarify. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about the generation of the third column of Fig. 7, noting that the visualizations appear to lack normalization. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the visualizations are not normalized. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses curiosity about the generation of the third column of Figure 7, noting that the visualizations appear to lack normalization. While it identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the figure. The comment lacks depth and actionable advice, leaving the authors with only a vague indication of what might be wrong. As a result, the feedback is barely helpful, as it points out a potential issue but does not offer a clear path for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses curiosity about the generation of the third column of Figure 7, noting that the visualizations appear to lack normalization. However, it does not provide any explicit guidance or suggestions on how the authors should address this curiosity or improve the figure. The comment lacks actionable details, such as recommending specific normalization techniques or providing examples of how to achieve normalization. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the generation of the third column and the lack of normalization in the visualizations. This provides clear guidance on what the authors need to investigate or clarify. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about the generation of the third column of Fig. 7, noting that the visualizations appear to lack normalization. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the visualizations are not normalized. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses curiosity about the generation of the third column of Figure 7, noting that the visualizations appear to lack normalization. While it identifies a potential issue, it does not provide any specific guidance or suggestions on how the authors might address this curiosity or improve the figure. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a potential area of concern but does not offer actionable advice.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses curiosity about the generation of the third column of Fig. 7, noting that the visualizations appear to lack normalization. However, it does not provide any explicit guidance or suggestions on how the authors should address this curiosity or improve the figure. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the feedback is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the heuristic nature of the assignment entropy maximization objective and the lack of evaluation of its advantages in the ablation experiment. It also points out the absence of discussion on potential negative societal impacts. While the comment highlights areas that need attention, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to provide a more rigorous evaluation of the assignment entropy maximization and discuss potential societal impacts, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"assignment entropy maximization\" objective and the \"ablation experiment\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as evaluating the advantages of using assignment entropy maximization and discussing potential negative societal impacts. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assignment entropy maximization objective is heuristic and lacks evaluation in the ablation experiment. It also mentions the absence of discussion on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or evidence to support the claim about the heuristic nature of the objective or the lack of evaluation. The absence of specific examples or references makes it challenging for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it highlights areas for improvement but lacks sufficient detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement in the paper. First, it points out that the assignment entropy maximization objective is regarded as heuristic, suggesting that the authors should provide a more rigorous evaluation of its benefits in the ablation experiment. This feedback is actionable and encourages the authors to strengthen their methodology by offering a clearer demonstration of the objective\\'s effectiveness. Second, the comment notes the absence of discussion on potential negative societal impacts, which is an important consideration for the authors to address. While the comment highlights these areas, it could be more helpful by providing specific suggestions or examples of how to evaluate the assignment entropy maximization or discuss societal impacts. Overall, the feedback is mostly helpful as it directs the authors to important aspects of their work that need further exploration and justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the presence of only one baseline model in the experimental section. However, it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether additional baseline models should be included, which specific models might be appropriate, or how the authors could enhance their experimental setup. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of having only one baseline model, which provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the validity or comprehensiveness of the study. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the experimental section, specifically the presence of only one baseline model. This feedback is somewhat helpful as it identifies a potential weakness in the study design that could affect the robustness and comprehensiveness of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional baseline models or explaining why multiple baselines are necessary. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the presence of only one baseline model in the experimental section. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting the inclusion of additional baseline models or explaining why multiple baselines are necessary. Without actionable guidance or suggestions, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of having only one baseline model, which provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the validity or comprehensiveness of the study. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the experimental section, noting that there is only one baseline model. This is a relevant observation that could impact the robustness and comprehensiveness of the study. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation, such as recommending additional baseline models or explaining why multiple baselines are necessary. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the presence of only one baseline model in the experimental section, which could be a limitation. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting the inclusion of additional baseline models or explaining why multiple baselines are necessary. Without actionable guidance or suggestions, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the experimental section, noting the presence of only one baseline model. However, it does not specify which part of the experimental section this issue pertains to"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies several missing baselines and literature comparisons, such as traditional quantization-aware training (QAT) methods like LSQ and LSQ+, other LLM-based QAT work, and more recent post-training quantization (PTQ) baselines like SpinQuant. It also suggests comparing the results to traditional QAT to understand the benefits of using extra memory instead of relying on fine-tuning low-rank adapters. This feedback provides clear and concrete actions for the authors to take, specifying which comparisons are missing and why they are important. The explicit nature of the suggestions and the detailed reasoning behind them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the comparisons, such as traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and more recent PTQ baselines like SpinQuant. The comment further suggests comparing the results to traditional QAT to understand the benefits of using extra memory instead of relying on fine-tuning low-rank adapters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some baselines and literature comparisons are missing, specifically mentioning traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and more recent PTQ baselines like SpinQuant. The reviewer suggests that comparing the results to traditional QAT would be important to understand the benefits of using extra memory instead of relying on fine-tuning low-rank adapters. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support why these comparisons are crucial. The claim is somewhat verifiable, as it provides a logical basis for the suggestion but requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of certain baselines and literature comparisons, such as traditional quantization-aware training (QAT) methods like LSQ and LSQ+, other LLM-based QAT work, and more recent post-training quantization (PTQ) baselines like SpinQuant. It suggests that comparing the results to traditional QAT would be important to understand the benefits of using extra memory instead of relying on fine-tuning low-rank adapters. This feedback is clear and actionable, providing the authors with specific areas to consider for improving their draft. By addressing these comparisons, the authors can enhance the comprehensiveness and relevance of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the definition of \"attribute\" and the differences between attributes, suggesting that more detailed instructions should be provided. While the comment identifies areas that need clarification, it does not explicitly instruct the authors on how to address these issues or what specific information should be included in the instructions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but they may not be entirely sure of the exact content or format of these instructions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the definition and differentiation of attributes, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these questions pertain to, such as a specific section or discussion where attributes are mentioned. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the authors might have an idea of where attributes are discussed, the comment lacks full grounding. It is specific in its request for more detailed instructions but does not provide enough context for full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the definition and differentiation of attributes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition and differentiation of attributes, suggesting that more detailed instructions should be provided. While it identifies an area that could benefit from clarification, it lacks specificity and does not offer actionable guidance on how the authors might address this issue. The comment does not provide examples or suggestions for improving the clarity of the definitions or instructions, leaving the authors with only a vague idea of what needs to be improved. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern that the theory presented in the paper may not be helpful for predicting the robustness of models to adversarial perturbations. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve their theory. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be taken to enhance the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the theory presented in the paper, specifically questioning whether it can help predict the robustness of models to adversarial perturbations. However, it does not specify which part of the paper this theory is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the theory are problematic or how it could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theory in the paper is insufficient to predict the robustness of models to adversarial perturbations. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the theoretical foundation of the paper, specifically questioning whether the theory can help predict the robustness of models to adversarial perturbations. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their theory. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the term \"scenario\" in the paper, specifically asking whether it refers to class or instances and where the \"agnostic\" part comes into play. While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this aspect. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the term \"scenario,\" but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the term \"scenario\" in the paper, specifically asking whether it refers to class or instances and where the \"agnostic\" part comes into play. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification about the term \"scenario,\" but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the term \"scenario\" in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the term \"scenario\" in the paper, specifically asking whether it refers to class or instances and where the \"agnostic\" part comes into play. While it identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might clarify this aspect of their work. The comment highlights a need for clarification but lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of naming the method \"Maestro\" and points out that it is never introduced in the paper. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this naming should be changed, if so, how it should be changed, or if there are alternative names to consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the choice of naming the method \"Maestro\" and points out that it is never introduced in the paper. However, it does not specify which part of the paper this issue is related to, such as the introduction or methodology sections. The authors might infer that it relates to the introduction or methodology, but this inference is not direct. The comment is specific in questioning the naming choice but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of naming the method \"Maestro\" and points out that it is never introduced in the paper. However, it does not provide any reasoning or evidence to support why this naming choice is inappropriate or confusing. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the naming of the method \"Maestro,\" noting that it is never introduced in the paper and suggesting that it seems unusual. While it points out a potential issue with the naming convention, it does not provide any constructive feedback or suggestions on how to address this concern. The comment lacks depth and actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define what \"best\" means in the context of the paper, specifically regarding the \"best\" candidate. It provides a clear action for the authors to take by asking them to clarify whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This feedback is direct and provides concrete guidance on how to improve the clarity of the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a definition of \"best\" within the context of the paper. The comment provides a clear direction for improvement by asking for clarification on what \"best\" means in terms of relevance for prediction, confidence scores, or other criteria. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"best\" is not clearly defined in the paper, specifically on page 5. It requests clarification on whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or other criteria. This comment is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the definition of \"best\" candidate on page 5. It provides a clear and actionable suggestion by asking the authors to explicitly define what \"best\" means within the context of the paper. This feedback is valuable as it helps the authors improve the precision and understanding of their terminology, which is crucial for the clarity and effectiveness of their work. However, the comment could be more helpful if it offered examples of how to define \"best\" or suggested alternative terms that might be clearer. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some claims in the paper are over-asserted, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make the claims more accurate. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to revise their claims effectively. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the claims made about the proposed method, particularly noting that it does not consider feed-forward layers but is described as if it does. However, it does not specify which parts of the paper contain these over-claims, making it weakly grounded. The comment is specific in identifying the issue with the claims but lacks grounding because it does not direct the authors to specific sections or lines where these claims are made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some points are over-asserted, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment lacks detailed reasoning or evidence to support this claim. It does not provide specific examples or references to substantiate the assertion that the claims are over-asserted. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claims made in the paper regarding the proposed method. It points out that the method does not consider feed-forward layers but is described as if it does, which could lead to over-assertions. This feedback is valuable as it highlights a potential inconsistency in the paper\\'s claims, prompting the authors to reconsider and possibly revise their statements to accurately reflect the method\\'s capabilities. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue, such as clarifying the limitations of the method or revising the text to accurately reflect its scope. Overall, the comment is somewhat helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that some claims in the paper are over-asserted, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make the claims more accurate. The feedback lacks actionable details, leaving the authors uncertain about how to revise their claims effectively. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the claims made in the paper regarding the proposed method, particularly noting that it does not consider feed-forward layers but is described as if it does. However, it does not specify which parts of the paper contain these over-claims, making it weakly grounded. The comment is specific in detailing the issue with the claims but lacks grounding because it does not direct the authors to specific sections or lines where these claims are made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some points are over-asserted, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment lacks detailed reasoning or evidence to support this claim. It does not provide specific examples or references to substantiate the assertion that the claims are over-asserted. This makes it difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claims made in the paper regarding the proposed method. It points out that the method does not consider feed-forward layers but is described as if it does, which could lead to over-assertions. This feedback is valuable as it highlights a potential inconsistency in the paper\\'s claims, prompting the authors to reconsider and possibly revise their statements to accurately reflect the method\\'s capabilities. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue, such as clarifying the limitations of the method or revising the text to accurately reflect its scope. Overall, the comment is somewhat helpful as it directs the authors to a critical area needing"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the motivation of the experiments. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to enhance the clarity of their experimental design. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"no variations\" and \"Up to 18 games\" finetuning methods, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation for the experiments and the finetuning methods. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these methods lack motivation or clarity. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the experimental design, noting that the experiments lack clear motivation, particularly regarding the \"no variations\" and \"Up to 18 games\" finetuning methods. While it points out a potential weakness, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or improve the motivation of their experiments. Without actionable feedback or specific recommendations, the authors are left with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that it is necessary to evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. It provides references to specific works, [A] and [B], which likely guide the authors on how to approach this evaluation. The comment is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the method performance under missing modality cases, such as testing sets with different missing ratios. The comment further references specific works, [A] and [B], which provide context for the evaluation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that only the Miss-V and Miss-A results are shown in table 1/2, and it is necessary to evaluate the method performance under missing modality cases. The comment provides a logical reasoning by highlighting the importance of testing sets with different missing ratios to fully assess the method\\'s performance. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this evaluation themselves, which adds to the complexity of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the evaluation of the method, noting that only the Miss-V and Miss-A results are shown in table 1/2. It emphasizes the importance of evaluating the method under missing modality cases, such as testing sets with different missing ratios. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of additional results to better assess the method\\'s performance. It also references specific works, [A] and [B], which can guide the authors in understanding the context and potential approaches for evaluation. This feedback is mostly helpful as it offers a concrete direction for enhancing the evaluation section of the paper, although it could be further improved by providing more detailed guidance on how to implement the suggested evaluation. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. While the action is implied, it is clear and concrete, as it specifies exactly what needs to be added to the study. The authors know that they need to conduct an ablation study on the image feature effect, providing a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including an ablation study on the effect of using image features, indicating that the conditions are not changed during browsing the web shop. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an ablation study on image features, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this ablation study is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. This feedback is somewhat helpful as it identifies a specific area for improvement by recommending an additional analysis that could enhance the understanding of the paper\\'s findings. However, the comment lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be examined. To be more helpful, the comment could include suggestions on how to design the ablation study or what specific questions it should address. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. While the action is implied, it is clear and concrete, as it specifies exactly what needs to be added to the study. The authors know that they need to conduct an ablation study on the image feature effect, providing a clear direction for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an ablation study on image features, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. However, the comment lacks any supporting evidence, reasoning, or references to justify why this ablation study is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. This feedback is somewhat helpful as it identifies a specific area for improvement by recommending an additional analysis that could enhance the understanding of the paper\\'s findings. However, the comment lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be examined. To be more helpful, the comment could include suggestions on how to design the ablation study or what specific questions it should address. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how the authors might investigate this, or what specific steps they should take to explore challenging settings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its inquiry about challenging settings but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the approach can perform well in challenging settings, specifically mentioning Transformer Big and deep Transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. This is a valuable point that could prompt the authors to consider the robustness and generalizability of their approach. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments or analyses could be conducted to explore these challenging settings. While it identifies an area for potential improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights an important consideration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a misunderstanding of the concept of identifiability, stating that it is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. However, the comment does not provide any explicit or implicit actions for the authors to take to address this misunderstanding. It lacks guidance on how the authors might clarify or correct their understanding of identifiability in their paper. Without specific suggestions or examples, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the authors\\' understanding of identifiability, which is a concept related to the model\\'s properties. However, it does not specify which part of the paper this misunderstanding is present in, making it weakly grounded. The comment is specific in its critique, as it clearly states that the authors\\' understanding is incorrect and provides a rationale for why this is the case. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect, stating that it is a property of a model assuming infinite data can be observed. This claim is supported by logical reasoning, as it provides a clear explanation of what identifiability entails and why the authors\\' assertion is flawed. However, the comment could be strengthened by providing specific examples or references to support the claim further. As it stands, the comment is mostly verifiable, as it offers a reasonable explanation but lacks detailed evidence or examples to fully substantiate the claim. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific misunderstanding regarding the concept of identifiability in the context of the paper. It clarifies that identifiability is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. This feedback is valuable as it provides the authors with a clear correction to their understanding, which could significantly impact the accuracy and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to incorporate this correction into the paper or provided examples of how to address the issue. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a misunderstanding of the concept of identifiability, stating that it is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. However, it does not provide any explicit or implicit actions for the authors to take to address this misunderstanding. There is no guidance on how the authors might clarify or correct their understanding of identifiability in their paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the authors\\' understanding of identifiability, which is a concept related to the model\\'s properties. However, it does not specify which part of the paper this misunderstanding is present in, making it weakly grounded. The comment is specific in its critique, as it clearly states that the authors\\' understanding is incorrect and provides a rationale for why this is the case. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect, stating that it is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. This claim is supported by logical reasoning, as it provides a clear explanation of what identifiability entails and why the authors\\' assertion is flawed. However, the comment could be strengthened by providing specific examples or references to support the claim further. While the reasoning is sound, the lack of detailed evidence or examples makes the comment mostly verifiable. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific misunderstanding regarding the concept of identifiability, which is crucial for understanding the model\\'s properties. It clarifies that identifiability is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. This feedback is valuable as it provides the authors with a clear correction to their"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting ways to improve the results or proposing alternative baselines for comparison. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the results by stating that they show no particular benefit with respect to the simple baseline the authors compare with. However, it does not specify which results or sections of the paper this observation is based on, nor does it provide details on what aspects of the results are lacking or how they could be improved. Without explicit references to specific parts of the paper, the authors cannot confidently determine which results or comparisons need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the results, stating that they show no particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their results or what specific changes could be made to enhance their comparison with the baseline. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the results by stating that they show no particular benefit with respect to the simple baseline the authors compare with. However, it does not specify which results or sections of the paper this observation is based on, nor does it provide details on what aspects of the results are lacking or how they could be improved. Without explicit references or specific guidance, the authors cannot effectively identify the areas needing attention or improvement. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the results, stating that they show no particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their results or what specific changes could be made to enhance their comparison with the baseline. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the results by stating that"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues related to efficiency: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. While it identifies these areas as needing attention, it does not provide explicit guidance on how to address them. The authors are left to infer that they should discuss the time cost and potentially optimize the inference process, but the comment lacks concrete suggestions or steps for improvement. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper related to efficiency, including the training process and the inference process. It mentions the use of a vocoder pre-trained on 60k-hour LibriLight and the incorporation of a diffusion-based vocoder for waveform refinement. However, it does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the issues with efficiency, such as the time cost of pre-training and the slower inference speed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the efficiency of the method, specifically mentioning the time cost of pre-training the vocoder and the slower inference speed due to the use of a diffusion-based vocoder. While the comment provides some reasoning by highlighting the potential inefficiencies, it lacks specific details or references to support the claim fully. The authors might find it challenging to address these concerns without more detailed information or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas of concern regarding the efficiency of the method. It points out that the training process involves a vocoder pre-trained on a large dataset, which may not be practical for some applications, and it does not describe the time cost of this pre-training process. Additionally, it notes that the inference process incorporates a diffusion-based vocoder, which could result in slower inference speed compared to other methods. While the comment highlights important issues, it lacks actionable suggestions or guidance on how the authors might address these concerns or improve the efficiency of their method. The feedback is somewhat helpful as it provides insight into potential weaknesses, but it could be more beneficial with additional guidance or suggestions for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two specific issues related to efficiency: the time cost of pre-training the vocoder and the slower inference speed due to the use of a diffusion-based vocoder. However, it does not provide explicit guidance or suggestions on how the authors might address these issues, such as optimizing the pre-training process or exploring alternative methods for inference. The feedback is implicit and lacks concrete details, making it somewhat actionable. The authors are left to infer that they should discuss these aspects, but without clear direction, the action remains vague.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper related to efficiency, including the training process and the inference process. It mentions the use of a vocoder pre-trained on 60k-hour LibriLight and the incorporation of a diffusion-based vocoder for waveform refinement, which results in slower inference speed. However, it does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the issues with efficiency, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the efficiency of the method, specifically mentioning the time cost of pre-training the vocoder and the slower inference speed due to the use of a diffusion-based vocoder. While the comment provides some reasoning by highlighting the potential inefficiencies, it lacks specific details or references to support the claim fully. The authors might find it challenging to address these concerns without more detailed information or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas of concern regarding the efficiency of the method. It points out that the training process involves a vocoder pre-trained on a large dataset, which may not be practical for some applications, and it does not describe the time cost of this pre-training process. Additionally, it notes that the inference process incorporates a diffusion-based vocoder, which could result in slower inference speed compared to other methods. While the comment"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, this generalization is not explored. The comment implies that the authors should investigate this generalization to strengthen the framework. However, it does not explicitly instruct the authors to conduct this exploration or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the generalization themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the scoring function s(\u00b7; G) and its generalization for multiple goal documents or without any gold document. However, it does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the lack of exploration of this generalization, which is a clear issue that the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generalization of the scoring function s(\u00b7; G) is not explored, which questions the overall generalization of the framework. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper regarding the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while this generalization is mentioned, it is not explored, which questions the overall generalizability of the framework. This feedback is somewhat helpful as it highlights an area that requires further investigation or clarification. However, the comment could be more helpful if it provided specific suggestions on how to explore this generalization or examples of how it could be applied. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but this generalization is not explored. It implies that the authors should investigate this generalization to strengthen the framework. However, the comment does not explicitly instruct the authors to conduct this exploration or provide guidance on how to do so. The action is implicit and somewhat vague, making it somewhat actionable. The authors can infer that they need to explore the generalization, but the lack of specific instructions or examples makes it less actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. However, it does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the lack of exploration of this generalization, which is a clear issue that the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generalization of the scoring function s(\u00b7; G) is not explored, which questions the generalizability of the framework. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper regarding the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while this generalization is mentioned, it is not explored, which questions the overall generalizability of the framework. This feedback is somewhat helpful as it highlights an area that requires further investigation or clarification. However, the comment lacks specific suggestions or guidance on how the authors might explore this generalization or what aspects to focus on. To be more helpful, the comment could provide examples or methods for exploring the generalization. Therefore, the comment aligns with a score of 3.\", 'help"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach's performance. It explains how this data can offer insights into the framework's comparative performance throughout the recommendation process, allowing readers to assess its effectiveness more thoroughly. The comment also provides a specific reference to a related work, which could guide the authors in understanding how to present this information effectively. The action is clear and concrete, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It explicitly mentions the need for this data to offer insights into the framework\\'s comparative performance throughout the recommendation process. However, it does not specify which part of the paper should include this information, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the success rate at each conversation turn. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach's performance. The comment supports this claim by referencing a related work, 'Multiple choice questions based multi-interest policy learning for conversational recommendation,' which could guide the authors in understanding how to present this information effectively. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work. As it stands, the claim is mostly verifiable due to the reference provided, but it could benefit from additional context or examples. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the comprehensiveness of the paper by recommending the inclusion of information on the success rate at each conversation turn. This feedback is valuable as it offers a specific way to enhance the understanding of the proposed approach's performance throughout the recommendation process. By suggesting a particular metric and referencing a related work, the comment provides a concrete direction for the authors to improve their draft. This level of detail and guidance makes the comment highly helpful, as it empowers the authors to make a meaningful enhancement to their work. Therefore, the comment deserves a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and recommends that the authors consider presenting numbered lists as actual lists instead of embedding them within paragraphs. This feedback provides a clear and explicit action for the authors to take, which is to reformat the numbered lists to improve readability. The suggestion is concrete, as it specifies the change that should be made to enhance the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and recommends presenting numbered lists as actual lists instead of embedding them within paragraphs. However, it does not specify which parts of the paper are particularly dense or where the numbered lists are located, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where the numbered lists are, the comment lacks full grounding. It is specific about the suggestion to present lists as actual lists, but without clear grounding, it is challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is dense and suggests that numbered lists should be presented as actual lists instead of being embedded in paragraphs. However, the comment lacks specific examples or detailed reasoning to support why this change would improve readability. Without concrete evidence or examples, the claim is not fully substantiated, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a general issue with the paper\\'s readability, noting that it is dense and difficult to follow in parts. It provides a specific suggestion to consider presenting numbered lists as actual lists instead of embedding them within paragraphs, which could improve readability. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional guidance on where these changes should be made or how they might impact the overall structure of the paper. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or explore the implications of this observation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the underlying principles of \"fake image detectors,\" but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to help the authors understand the basis of the question or how it relates to their work. As a result, the claim is unverifiable, making it difficult for the authors to address the concern effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it lacks specificity and actionable guidance for the authors. It does not provide any suggestions on how the authors might explore this question or what aspects of their work could be improved to address this concern. Without clear direction or actionable feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might explore or address this question in their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity in terms of what needs to be addressed or improved, and it does not provide any guidance on how to explore or address the question. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to help the authors understand the basis of the question or how it relates to their work. As a result, the claim is unverifiable, making it difficult for the authors to address the concern effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it lacks specificity and actionable guidance for the authors. It does not provide any suggestions on how the authors might explore or address this question in their work. Without clear direction or actionable feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point raises a question about the fundamental nature of \"fake image detectors\" and whether they rely on similar spectral cues. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might explore or address this question in"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to analyze both satisfied and unsatisfied cases in the visualization results. It also mentions the need for analysis in class-incremental learning for semantic segmentation, which is not related to the visualization issue. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on. While the action is clear, the lack of detailed instructions on how to implement the analysis makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the visualization results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the visualization results are \"terrible\" compared to the ground truth and requests an analysis of satisfied and unsatisfied cases. Additionally, it references a specific topic, \"Class-incremental learning for semantic segmentation,\" which provides further context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" compared to the ground truth and requests an analysis of satisfied and unsatisfied cases. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the visualization results are indeed \"terrible.\" Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the visualization results, describing them as \"terrible\" compared to the ground truth. It suggests that the authors analyze both satisfied and unsatisfied cases to better understand the performance of their method. Additionally, it references a specific topic, \"Class-incremental learning for semantic segmentation,\" which could provide context or relevance to the paper. However, the comment lacks detailed guidance on how to conduct the analysis or what specific aspects to focus on, which limits its helpfulness. While it points out an area for improvement, it does not offer actionable steps or suggestions for the authors to follow, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The feedback lacks actionable details, such as recommending specific changes or additional analyses to mitigate the potential issues. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not specify which part of the paper discusses the previous work or the implementation process, making it weakly grounded. The comment is specific in identifying the potential issue with the reliance on previous work and the similarity to GAN, but it lacks grounding in the paper\\'s structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential impact of limitations or issues in previous work on the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specific examples or references to the previous works that might have issues, making it difficult for the authors to understand the basis of the concern. The claim is somewhat verifiable as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a potential issue with the paper's reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. While the comment identifies a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or differentiate their work from previous studies. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from previous studies. Without specific recommendations or actionable steps, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not specify which part of the paper discusses the previous work or the implementation process, making it weakly grounded. The comment is somewhat specific in identifying the potential issue with the reliance on previous work and the similarity to GAN, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential impact of limitations or issues in previous work on the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specific examples or references to the previous works that might have issues, making it difficult for the authors to understand the basis of the concern. The claim is somewhat verifiable as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the use of information during the partitioning step, specifically questioning whether any information unavailable to the policy is being used. It also suggests that if such information is used for clustering participants but not in policy training, it could be incorporated to improve the policy. While the comment implies that the authors should clarify or address this issue, it does not explicitly instruct them to do so. The action is concrete but inferred, making this comment mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the methodology, specifically regarding the use of information during the partitioning step. It questions whether any information unavailable to the policy is being used and suggests that if such information is used for clustering participants but not in policy training, it should be incorporated. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of information and suggests a potential improvement, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology, specifically regarding the use of information during the partitioning step. It suggests that if information like patient characteristics is used for clustering but not in policy training, it should be incorporated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim or suggest why it is an issue. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the methodology, specifically regarding the use of information during the partitioning step. It questions whether any information unavailable to the policy is being used and suggests that if such information is used for clustering but not in policy training, it should be incorporated. This feedback is valuable as it prompts the authors to clarify their methodology and consider whether all relevant information is being utilized effectively. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or examples of how to incorporate the suggested information. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the methodology, specifically regarding the use of information during the partitioning step. It suggests that if information like patient characteristics is used for clustering but not in policy training, it should be incorporated to improve the policy. While the comment implies that the authors should clarify or address this issue, it does not explicitly instruct them to do so. The action is concrete but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the methodology, specifically regarding the use of information during the partitioning step. It suggests that if information like patient characteristics is used for clustering but not in policy training, it should be incorporated. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its inquiry about the use of information and suggests a potential improvement, but without clear grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology, specifically regarding the use of information during the partitioning step. It suggests that if information like patient characteristics is used for clustering but not in policy training, it should be incorporated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim or suggest why it is an issue. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the methodology, specifically regarding the use of information during the partitioning step. It suggests that if information like patient characteristics is used for clustering but not in policy training, it should be incorporated. This feedback is valuable as it prompts the authors to clarify their methodology and consider whether all relevant information is being utilized effectively. However, the comment could be more helpful if it provided specific suggestions or examples on how to address the issue. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether this observation is significant, if it needs addressing, or how the authors might investigate or improve the rendering quality. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Appendix C,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by questioning the rendering quality of NeRF compared to NeuS and Geo NeuS, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the rendering quality of NeRF compared to NeuS and Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, as mentioned in Appendix C. While it identifies a potential area of interest or concern, it does not provide any specific guidance or suggestions for the authors to address this issue. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, as it points out a potential area for exploration but does not offer meaningful assistance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this assumption or clarify their evaluation approach. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning a bold assumption regarding the suitability of purely unsupervised large-scale pretraining for NLP applications and expressing confusion about how this conclusion is drawn from the proposed evaluation approach. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer expresses confusion about how this conclusion is drawn from the proposed evaluation approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or clarify the evaluation approach. This lack of justification makes the claim unverifiable, as the authors may struggle to understand or address the critique without additional information. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It highlights a potential weakness in the evaluation approach by expressing confusion about how this conclusion is drawn. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their evaluation approach. While it identifies a critical area for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues regarding the related work section, specifically mentioning the omission of recent related work, including [A] and DCN [18], which are not discussed or included in Table 3. It also notes that [B] is relevant to transductive label propagation. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to include these references and discuss them in the related work section, but the comment lacks concrete guidance on how to integrate them effectively. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, such as \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing in the related work section, including the omission of recent related work such as [A] and DCN [18], and the need to discuss these in the context of performance and transductive label propagation. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper fails to discuss recent related work, specifically mentioning [A] and DCN [18], which are not included in the related work section or Table 3. The reviewer provides specific references to support the claim, indicating that these works achieve higher performance on certain datasets. This detailed reference to external works provides a robust foundation for the claim, making it fully verifiable. The inclusion of specific examples and references allows the authors to understand the basis of the critique and address it effectively. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies specific gaps in the related work section, highlighting the omission of recent related work, including [A] and DCN [18], which are not discussed or included in Table 3 despite achieving higher performance on certain datasets. It also notes the relevance of [B] in the context of transductive label propagation. This feedback is clear and actionable, as it directs the authors to include these references and discuss their contributions, thereby enhancing the comprehensiveness and accuracy of the related work section. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references effectively. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for improving the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the operator should be the Hadamard product between the DAG and Attention, rather than addition, as depicted in Figure 2. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is specific and leaves no ambiguity about what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the operator used in the figure, which should be the Hadamard product between the DAG and Attention, instead of addition. This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the operator should be the Hadamard product between the DAG and Attention, instead of addition, as depicted in Figure 2. However, the comment does not provide any reasoning or evidence to support why the Hadamard product is more appropriate or why the current addition is incorrect. Without additional context or justification, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the operator used in Figure 2, recommending that it should be the Hadamard product between the DAG and Attention, rather than addition. This feedback is clear and directly addresses a potential error or misrepresentation in the figure, offering a concrete way for the authors to improve the accuracy and clarity of their presentation. By following this suggestion, the authors can enhance the precision of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review point provides specific feedback on the authors' response to concerns, particularly regarding the achievement of optimal rates for SOBA under additional smoothness assumptions. It acknowledges that the authors have addressed weaknesses and increased the score accordingly. However, it also points out that limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment suggests that the non-standard assumption could be anticipated in the abstract and that the discrepancy should be more thoroughly addressed in the paper. While the feedback is specific and provides clear guidance on what needs to be improved, it does not explicitly instruct the authors on how to address these points. Therefore, the comment is mostly actionable, as it provides concrete suggestions but requires the authors to infer the exact actions to take.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, such as \"No.7. 2022. Post authors\u2019 response\" and \"weakness 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues that need to be addressed, such as the achievement of optimal rates for SOBA under additional smoothness assumptions, the limitations of the theoretical analysis, and the discrepancy between theoretical and practical updates of SABA. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point provides a detailed assessment of the authors' response to concerns raised in the original review. It acknowledges that the authors have addressed weaknesses, particularly concerning the achievement of optimal rates for SOBA under additional smoothness assumptions, which are considered realistic. The reviewer also notes that the limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment provides specific examples and references to the authors' response, making it mostly verifiable. However, it could be further strengthened by providing more detailed reasoning or examples for the limitations, which would elevate it to a fully verifiable comment. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed evaluation of the authors' response to concerns raised in the original review. It acknowledges that the authors have addressed weaknesses, particularly concerning the achievement of optimal rates for SOBA under additional smoothness assumptions, which are considered realistic. The reviewer also notes that the limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. The comment suggests that the non-standard assumption could be anticipated in the abstract and that the discrepancy should be more thoroughly addressed. This feedback is clear and actionable, offering specific guidance on how the authors can improve their draft by addressing these points. However, it could be more helpful if it provided additional suggestions or examples for addressing the limitations. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a discrepancy between the paper's claim and the experimental results, noting that UnKE's ability to retain original knowledge is worse than the baseline in the experiments. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their claim. There is no guidance on potential modifications, additional experiments, or alternative explanations that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper claims UnKE\\'s cause-driven optimization can preserve pre-trained knowledge, but the experiments show that UnKE\\'s ability to retain original knowledge is worse than the baseline. The comment further references an external work, providing a specific example of a related study. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the paper\\'s claim that UnKE\\'s cause-driven optimization can preserve pre-trained knowledge during the editing process. It provides evidence from the experiments, specifically mentioning that UnKE\\'s ability to retain original knowledge is worse than the baseline (MMLU in Table 2 and Src-Acc and Tgt-Acc in Table 3). The comment also references an external work, \"Rosati D, Gonzales R, Chen J, et al. Long-form evaluation of model editing [J]. arXiv preprint arXiv:2402.09394,\" which supports the claim by providing a comparison with another study. This combination of experimental evidence and external reference makes the claim fully verifiable, as it provides a robust basis for the critique. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment challenges the paper's claim that UnKE's cause-driven optimization can preserve pre-trained knowledge during the editing process. It provides specific evidence from the experiments, showing that UnKE's ability to retain original knowledge is worse than the baseline (MMLU in Table 2 and Src-Acc and Tgt-Acc in Table 3). Additionally, the comment references an external work, which adds credibility to the critique. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and possibly revise their experimental results or analysis to better support their argument. However, the comment could be more helpful if it offered suggestions on how to address the discrepancy or improve the paper's claims. Overall, the comment is mostly helpful, as it provides valuable insights and a direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, it does not provide explicit guidance on how to improve the explanation or suggest specific changes to make it clearer. The authors are left to infer that they need to enhance the explanation, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the explanation of the intention of BWTP/GLBW, indicating that many details are in the appendix, which makes it difficult to understand at first sight. However, it does not specify which part of the paper this explanation is located in, making it weakly grounded. The comment is specific in pointing out the issue with the appendix and the difficulty in understanding the details, but without explicit references, the authors may struggle to pinpoint the exact section needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. This feedback highlights a clear area for improvement, as it points out that the paper could benefit from a more accessible explanation of its key concepts. However, the comment lacks specific suggestions or guidance on how to improve the explanation or present the details more effectively. While it provides some insight into the problem, it does not offer actionable steps for the authors to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, it does not provide specific suggestions or guidance on how to improve the explanation or make the details more accessible. The authors are left to infer that they need to enhance the explanation, but without concrete actions or examples, the comment remains vague. Therefore, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the explanation of the intention of BWTP/GLBW, noting that many details are in the appendix, which makes it difficult to understand at first sight. However, it does not specify which part of the paper this explanation is located in, making it weakly grounded. The comment is specific in pointing out the issue with the appendix and the difficulty in understanding the details, but without explicit references, the authors may struggle to pinpoint the exact section needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. This feedback highlights a clear area for improvement, as it points out the need for a more accessible explanation of the key concepts. However, the comment lacks specific suggestions or guidance on how to enhance the explanation or present the details more effectively. While it provides some insight into the problem, it does not offer actionable steps for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the explanation of the intention of BWTP/GL"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a proof that was omitted due to space constraints, either in the revision or as supplementary material. The action is clear and concrete, providing specific guidance on how to address the issue. The reviewer even suggests that the proof might fit into the main paper, offering a potential solution to the space constraint. This level of detail makes the comment highly actionable, as it provides a direct and concrete path for the authors to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of a proof due to space constraints and suggests including it in the revision, either as supplementary material or possibly within the main paper. This provides clear guidance on what the authors need to address. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a proof is omitted due to space constraints and requests its inclusion in the revision, either as supplementary material or possibly within the main paper. The claim is based on the logical reasoning that including the proof would enhance the paper\\'s comprehensiveness and transparency. However, the comment does not provide specific details or references to support why the proof is necessary or how it would benefit the paper. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of the proof themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that a proof is missing due to space constraints. It provides a clear and actionable suggestion for improvement by recommending that the proof be included either in the revision or as supplementary material. This feedback is valuable as it helps the authors understand the importance of including the proof and offers a practical solution to address the issue. However, the comment could be more helpful if it explained why the proof is important or how it would enhance the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide specific experimental results or references instead of relying on a vague reason like \"Since the NPPs lack any direct dependence on magnitudes\" to explain why NPPs perform worse than ETAS. This feedback implies that the authors should include more detailed evidence or references to support their claims. While the action is not explicitly stated, it is clear and concrete, as it specifies the type of information that should be added. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing specific experimental results or references instead of relying on a vague reason for why NPPs perform worse than ETAS. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or discussion where this issue is addressed. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its suggestion to provide more detailed evidence, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide specific experimental results or references instead of relying on a vague reason for why NPPs perform worse than ETAS. However, the comment does not provide any supporting evidence or reasoning to justify why the current explanation is insufficient or how the proposed changes would improve the paper. Without additional context or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide specific experimental results or references instead of relying on a vague reason like \"Since the NPPs lack any direct dependence on magnitudes\" to explain why NPPs perform worse than ETAS. This feedback is clear and actionable, as it directs the authors to include more detailed evidence or references to support their claims. By doing so, the authors can strengthen their argument and provide a more robust justification for their findings. However, the comment could be more helpful if it offered specific examples of what kind of experimental results or references would be beneficial. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the implementation details, specifically regarding the connectivity patterns between layers as outlined in Equations 3 and 4. It points out that these details are not applied to complex architectures like UNet or ResNet and MobileNet, as shown in Tables 1 and 5, and notes that these details are not included in the Appendix. The comment implies that the authors should provide more detailed guidance on how to apply these connections to complex architectures. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they need to add specific guidance on the implementation details. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Equations 3 and 4) and tables (Tables 1 and 4, Table 5) where the implementation details are discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of guidance on applying the connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. Additionally, it points out that these details are not included in the Appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically regarding the connectivity patterns between layers as outlined in Equations 3 and 4. The reviewer highlights that these details are not applied to complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1 and 5, and notes that these details are not included in the Appendix. This claim is somewhat verifiable as it identifies specific areas where the implementation details are lacking and provides examples of where these issues arise. However, the comment could be strengthened by offering more detailed reasoning or examples of how the lack of implementation guidance affects the understanding of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details in the paper. It points out that while Equations 3 and 4 outline the connectivity patterns between layers, there is no specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1 and 5. Additionally, it notes that these details are not included in the Appendix, which raises serious problems for readers trying to understand the paper. The comment is clear and actionable, as it highlights the need for more detailed guidance on the implementation, which would significantly improve the paper\\'s comprehensibility. However, it could be more helpful by suggesting specific ways to present this information or providing examples of how to apply the connectivity patterns to complex architectures. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the HTER label calculation, which relies on automatic scripts, and suggests that the authors should experiment on other languages and annotations to verify this scalability. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for further experimentation, but it is inferred rather than directly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the calculation of HTER label, which relies on automatic scripts, and raises concerns about its scalability to other annotations like MQM or DA. It suggests that if this is not the case, the authors should experiment on other languages and annotations to verify scalability. However, the comment does not specify which part of the paper discusses the calculation of HTER label, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the scalability of the calculation, providing clear guidance on what the authors should consider. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the HTER label calculation, which relies on automatic scripts, to other annotations like MQM or DA. The reviewer suggests that if this is not the case, the authors should experiment on other languages and annotations to verify scalability. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the limitations of the current approach. The suggestion to experiment on other languages and annotations is a logical step, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the scalability of the HTER label calculation, which relies on automatic scripts. It suggests that if this is not the case, the authors should experiment on other languages and annotations to verify the scalability. This feedback is clear and actionable, as it provides a specific direction for the authors to explore to enhance the robustness and applicability of their method. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how overall performance depends on $m$ in $G_m$. While it raises an important question, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this question should be addressed in the paper, how it should be addressed, or what specific aspects should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how overall performance depends on $m$ in $G_m$, which suggests a potential area for further exploration or clarification in the paper. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this dependency might be discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the dependency, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the dependence of overall performance on $m$ in $G_m$. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about how overall performance depends on $m$ in $G_m$. While it identifies a potential area for further exploration or clarification, it does not provide any specific guidance or suggestions on how the authors might address this question in their paper. The comment lacks depth and actionable advice, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential theory-practice gap, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment implies that the authors should address this gap, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific aspects of Causal-Stonet that should be discussed. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a theoretical-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the theoretical or methodological sections. The suggestion is specific, as it points out a particular area for improvement and provides a reference for further exploration. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential theory-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). This provides a clear reference to support the claim that theoretical works often do not reflect practice in deep learning. The suggestion to comment on this gap is logical and provides a basis for the authors to consider the key elements that allow Causal-Stonet to learn sparse neural nets. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential theory-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. This feedback is clear and actionable, as it provides a specific area for the authors to address in their paper. By addressing this gap, the authors can enhance the comprehensibility and relevance of their work for readers. However, the comment could be more helpful if it offered additional guidance or suggestions on how to effectively comment on this gap. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment highlights a potential theory-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment implies that the authors should address this gap, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific aspects of Causal-Stonet that should be discussed. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential theory-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the theoretical or methodological sections. The suggestion is specific, as it points out a particular area for improvement and provides a reference for further exploration. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential theory-practice gap in the context of sparse neural nets, referencing a specific work by Farrell, Liang, and Misra (ECTA 2021). This provides a clear reference to support the claim that theoretical works often do not reflect practice in deep learning. The suggestion to comment on this gap is logical and provides a basis for the authors to consider the key elements that allow Causal-Stonet to"}
{"generated_text": "{'actionability_rationale': \"The review comment provides explicit and concrete suggestions for improving the manuscript's layout and readability. It advises the authors to consider making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are clear and provide specific actions that the authors can take to address the issue of cluttered and condensed content. The comment also indicates that these changes could be implemented in the camera-ready version if the paper is accepted, offering a clear timeline for potential revisions. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the manuscript, such as \"Figures and tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of cluttered and condensed content due to the proximity of figures and tables to the text, and provides concrete suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the manuscript is cluttered due to the close proximity of figures and tables to the text. The reviewer provides specific suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. While the comment offers a logical reasoning for the issue and provides actionable suggestions, it lacks specific examples or references to support the claim of cluttered content. This makes the claim somewhat verifiable, as the authors would need to infer the extent of the clutter and apply the suggested improvements. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific and actionable feedback on the layout and presentation of the manuscript. It identifies a potential issue with the manuscript's density, noting that figures and tables are positioned too closely to the text, which can make the paper appear cluttered and condensed. The reviewer offers concrete suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are clear and provide a straightforward way for the authors to enhance the readability and organization of their manuscript. Additionally, the comment indicates that these changes could be implemented in the camera-ready version if the paper is accepted, offering a practical timeline for potential revisions. This level of detail and guidance makes the feedback highly helpful for the authors in improving their draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests that the ReCPE method is too strategic and lacks a strong theoretical guarantee, implying that the authors should strengthen the article from this perspective. This is an explicit suggestion with a clear action for the authors to take, but it lacks concrete guidance on how to strengthen the theoretical foundation. Second, it points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7. This is a straightforward correction that the authors can easily implement. Overall, the comment is mostly actionable, as it provides a clear direction for improvement in one part and a specific correction in the other. However, the first part could be more detailed in terms of how to strengthen the theoretical foundation, which would make it fully actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions the ReCPE method and the theoretical guarantee, allowing the authors to infer that it relates to the methodology section. However, it does not specify which part of the paper discusses the ReCPE method or the theoretical guarantee, making it weakly grounded. The comment is specific in pointing out the lack of theoretical guarantee and suggesting that the authors could strengthen the article from this perspective. Additionally, it provides a minor comment about a spelling error in Note 2 on page 7. Overall, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes two claims. The first claim is that the ReCPE method is too strategic and lacks a strong theoretical guarantee, suggesting that the authors could strengthen the article from this perspective. However, the comment does not provide specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. The second claim is a minor comment about a spelling error in Note 2 on page 7, which is factual and does not require verification. Overall, the review point lacks sufficient evidence or reasoning to support the first claim, making it borderline verifiable. Therefore, the overall score is 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides two pieces of feedback. First, it suggests that the ReCPE method is too strategic and lacks a strong theoretical guarantee, implying that the authors should strengthen the article from this perspective. This is a valuable observation that could guide the authors in improving the theoretical foundation of their work. However, the comment does not provide specific suggestions or examples on how to strengthen the theoretical aspect, which would make it more actionable. Second, the comment points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7, which is a straightforward correction. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two distinct issues. First, it suggests that the ReCPE method is too strategic and lacks a strong theoretical guarantee, implying that the authors should strengthen the article from this perspective. However, it does not provide specific guidance on how to achieve this strengthening. Second, it points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7, which is a straightforward correction. While the first part of the comment provides a general direction for improvement, it lacks actionable details, making it somewhat actionable. The second part is clear and actionable. Overall, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The review point addresses two distinct issues. First, it critiques the ReCPE method for being too strategic and lacking a strong theoretical guarantee, suggesting that the authors could strengthen the article from this perspective. However, it does not specify which part of the paper discusses the ReCPE method or the theoretical guarantee, making it weakly grounded. Second, it points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7, which is a straightforward correction. Overall, the comment is weakly grounded because it does not specify the parts of the paper being addressed, but it is specific in pointing out the spelling error. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes two claims. First, it suggests that the ReCPE method is too strategic and lacks a strong theoretical guarantee, implying that the authors could strengthen the article from this perspective. However, the comment does not provide specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the critique. Second, it points out a minor spelling error in the phrase"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of the method to generation tasks, other than NLU tasks. While it implies that the authors should consider this possibility, it does not explicitly instruct them to do so. Additionally, the comment lacks concrete guidance on how to explore or address this question. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method to generation tasks, other than NLU tasks. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion about the method\\'s scope. This makes it difficult for the authors to pinpoint where this question fits into their draft. While the authors might have an idea of where generation tasks are discussed, the comment lacks full grounding. It is specific in its inquiry about the applicability to generation tasks but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking whether the method can be applied to generation tasks beyond NLU tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the method to generation tasks, other than NLU tasks. While it identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or why it is relevant. The comment is vague and does not offer actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that \"$N_d$ is not defined\" and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, which is to define $N_d$ and clarify the number of observations per task. The comment is specific and actionable, giving the authors a concrete step to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of $N_d$ and the clarification that there could be a different number of observations per task. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"$N_d$ is not defined\" and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. However, the comment does not provide any supporting evidence or reasoning to justify why this is an issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that \"$N_d$ is not defined\" and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and precision of the manuscript. By addressing this point, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why this clarification is important or how it impacts the overall argument. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a formatting issue where the appendix is not properly separated from the main paper, and it specifies that the PDF provided for the main paper is a 14-page document. This feedback implies that the authors should ensure the appendix is clearly distinguished from the main paper and that the PDF is properly formatted. While the action is implicit, it is concrete because it specifies the issue and provides a clear expectation for the authors to address it. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a formatting issue regarding the separation of the appendix from the main paper. However, it does not specify which part of the paper is being referred to, such as the section where the appendix should be located or the specific issue with the PDF format. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the authors might have an idea of where the appendix is located, the comment lacks full grounding. It is specific about the issue with the PDF format but does not provide detailed guidance on how to resolve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a factual statement about the formatting of the paper, specifically regarding the separation of the appendix from the main paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a formatting issue with the paper, specifically noting that the appendix is not properly separated from the main paper. It specifies that the PDF provided for the main paper is a 14-page document, which implies that the appendix is not included in the main paper as intended. This feedback is clear and actionable, as it guides the authors to ensure that the appendix is properly integrated into the main paper. However, the comment could be more helpful if it provided suggestions on how to integrate the appendix or clarified the purpose of the appendix in the context of the paper. Despite this, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the main improvement in the proposed model, which appears to come from the ternary potential. It suggests that without the ternary potential, the model does not outperform existing models for 2 modalities setup, except for HieCoAtt. The reviewer explicitly asks the authors to provide more insight into this observation. While the comment clearly identifies an area that needs further explanation, it does not offer specific guidance on how the authors should address this issue or what additional information should be included. The action is explicit but somewhat vague, as the authors know they need to provide more insight but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue: the main improvement in the proposed model seems to come from the ternary potential, and without it, the model does not outperform existing models for 2 modalities setup, except for HieCoAtt. The comment clearly specifies what needs to be addressed, namely, providing more insight into this observation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, as evidenced by the results in Table 1. The reviewer provides a logical reasoning by comparing the performance of the proposed model with existing models for 2 modalities setup, except for HieCoAtt. This comparison offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples of the models being compared. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed model, noting that the main improvement seems to come from the ternary potential. It highlights that without the ternary potential, the model does not outperform existing models for 2 modalities setup, except for HieCoAtt. The comment is clear in its request for the authors to provide more insight into this observation. While it points out a potential weakness, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their model. The feedback is somewhat helpful as it directs the authors to a critical area needing further exploration, but it could be more beneficial with additional guidance or suggestions. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a specific observation regarding the main improvement in the proposed model, which appears to come from the ternary potential. It suggests that without the ternary potential, the model does not outperform existing models for 2 modalities setup, except for HieCoAtt. The reviewer explicitly asks the authors to provide more insight into this observation. While the comment identifies a clear area for improvement, it lacks specific guidance on how the authors should address this issue or what additional analysis or discussion is needed. The action is implicit and somewhat vague, as the authors know they need to provide more insight but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue: the main improvement in the proposed model seems to come from the ternary potential, and without it, the model does not outperform existing models for 2 modalities setup, except for HieCoAtt. The comment clearly specifies what needs to be addressed, namely, providing more insight into this observation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, as evidenced by the results in Table 1. The reviewer provides a logical reasoning by comparing the performance of the proposed model with existing models for 2 modalities setup, except for HieCoAtt. This comparison offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples of the models being compared. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed model, noting that the"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide additional information in the tables to facilitate easier assessment of the degree of apples-to-applesness of the comparisons. Specifically, it recommends noting which methods use data augmentations, what architecture they use, and what objective they employ (such as episodic or joint training). This feedback is explicit and provides concrete guidance on what additional information should be included, making it clear to the authors how to improve their draft. The comment is highly actionable as it offers specific suggestions for enhancing the clarity and comprehensiveness of the tables.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing additional information in the tables to facilitate easier assessment of the comparisons. It specifically mentions the need to note which methods use data augmentations, what architecture they use, and what objective they employ, such as episodic or joint training. While the comment does not explicitly mention a specific table, the authors can infer that it relates to the tables where comparisons are presented. The suggestion is specific, as it clearly outlines what additional information should be included to improve the clarity of the comparisons. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing additional information in the tables, such as which methods use data augmentations, what architecture they use, and what objective they employ, would help assess the degree of apples-to-applesness of the comparisons. The comment is somewhat verifiable as it logically suggests a way to improve the clarity and comparability of the results. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity and comparability of the results presented in the tables. It recommends noting which methods use data augmentations, what architecture they employ, and what objective they use, such as episodic or joint training. This feedback is clear and constructive, offering the authors a concrete way to enhance the transparency and comprehensiveness of their results. By addressing this point, the authors can significantly improve the interpretability of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the state-of-the-art nature of the architectures used in the paper (LSTM and LSH networks) and questions the applicability of the hyperpruning method to more recent benchmarks and architectures. It suggests that it would be interesting to see how LSH performs on actual state-of-the-art models. However, the comment does not provide explicit guidance or concrete steps for the authors to address these concerns. The authors are left to infer that they might need to test their method on more recent benchmarks or architectures, but the comment lacks specific instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific claims made in the paper regarding the hyperpruning methods and the state-of-the-art nature of the architectures used (LSTM and LSH networks). It questions the applicability of the hyperpruning method to more recent benchmarks and architectures, suggesting that it would be interesting to see how LSH performs on actual state-of-the-art models. The comment also raises concerns about the PTB benchmark being a small dataset and questions the generalizability of the hyperpruning method to more recent benchmarks. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed, such as testing on more recent benchmarks and architectures. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that hyperpruning methods would beat the state-of-the-art by noting that the architectures used (LSTM and LSH networks) are not state-of-the-art for language modeling. It suggests testing LSH on more recent models to verify the claim. Additionally, it questions the applicability of the hyperpruning method to more recent benchmarks and architectures, given the small size of the PTB dataset. While the comment provides logical reasoning and a suggestion for further testing, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the critique but could benefit from more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's claims regarding the superiority of hyperpruning methods. It points out that the architectures used (LSTM and LSH networks) may not be state-of-the-art for language modeling, suggesting that it would be interesting to see how LSH performs on more recent models. Additionally, it questions the applicability of the hyperpruning method to more recent benchmarks and architectures, noting that the PTB dataset is small. While the comment raises valid concerns and provides some direction for further exploration, it lacks specific suggestions or actionable steps for the authors to address these issues. The feedback is somewhat helpful as it highlights areas for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more experimental details, such as the neural networks and hyperparameters used, in the appendix. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be added to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including more experimental details, such as neural networks and hyperparameters, in the appendix. However, it does not specify which part of the paper currently lacks these details, making it weakly grounded. The comment is specific in its request for additional information, but without clear grounding, the authors may struggle to identify where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, such as neural networks and hyperparameters, should be included in the appendix. However, it does not provide any justification or reasoning for why these details are necessary or how they would improve the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the importance of including these details. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including more experimental details, such as the neural networks and hyperparameters used, in the appendix. This feedback is actionable and provides a clear direction for the authors to enhance the transparency and reproducibility of their experimental setup. By recommending the inclusion of specific details, the comment helps the authors improve the completeness and clarity of their work. However, it could be more helpful if it provided examples of how to present this information or why these details are particularly important. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that Section 5.1 does not provide useful information on why the new model is superior. However, it does not specify what kind of information is missing or suggest how the authors should improve this section. The feedback lacks explicit guidance or concrete details on what the authors should do to enhance the section, leaving the authors uncertain about how to address the issue. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 5.1,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by stating that the section does not provide useful information regarding why the new model is superior. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"section 5.1 does not seem to provide useful information regarding why the new model is superior.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific issue with Section 5.1, noting that it does not provide useful information on why the new model is superior. This feedback is somewhat helpful as it highlights a potential weakness in the paper's presentation of the new model's advantages. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve the section. To be more helpful, the comment could include examples of what kind of information would be useful or how the authors might structure the section to better convey the model's superiority. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison is necessary to determine if the single-IMP has transferability, although it may not be as strong as the multi-IMP. While the comment implies that a comparison should be made, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and determine the specifics of how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison is necessary to determine if the single-IMP has transferability, although it may not be as strong as the multi-IMP. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on how to conduct the comparison or what aspects should be considered. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the single-IMP might have transferability, although not as strong as the multi-IMP, and implies that a comparison is necessary. However, the comment lacks specific reasoning or evidence to support the claim about the transferability of the single-IMP. Without detailed justification or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that a comparison is necessary to determine if the single-IMP has transferability, although it may not be as strong as the multi-IMP. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. The authors are left with a general suggestion but without actionable steps or examples to follow. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should consider checking human-factors literature to address ethical concerns and practical challenges related to interacting with humans. While the comment implies that the authors should explore this literature, it does not provide specific guidance on which aspects of the literature to focus on or how to integrate this knowledge into their work. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the literature to consult. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions a specific date, 'No.03. 2020,' which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of ethical concerns with the proposed methods and mentions that the authors have listed some limitations under the weaknesses and suggestions section. The comment further suggests that the authors should consider checking human-factors literature to address these concerns. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that there are no specific ethical concerns with the proposed methods and suggests that the authors should consider human-factors literature to address practical challenges related to interacting with humans. However, the comment does not provide any specific examples or references to support the claim about ethical concerns or the limitations of the proposed method. The suggestion to check human-factors literature is a general recommendation without detailed justification or examples. This lack of specific evidence or reasoning makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concerns without further guidance.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the lack of specific ethical concerns with the proposed methods and suggests that the authors consider human-factors literature to address practical challenges related to interacting with humans. While it identifies a potential area for improvement, the comment lacks specific guidance or examples of ethical concerns that should be addressed. It also does not provide detailed suggestions on how to incorporate human-factors literature into the work. The feedback is somewhat helpful as it points out a potential gap but does not offer comprehensive or actionable advice for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges the lack of specific ethical concerns with the proposed methods and suggests that the authors consider human-factors literature to address practical challenges related to interacting with humans. While the comment implies that the authors should explore human-factors literature, it does not provide specific guidance on which literature to consult or how to integrate this knowledge into their work. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the literature to explore. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions a specific date, 'No.03. 2020,' which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of ethical concerns with the proposed methods and mentions that the authors have listed some limitations under the weaknesses and suggestions section. The comment further suggests that the authors should consider checking human-factors literature to address these concerns. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that there are no specific ethical concerns with the proposed methods and suggests that the authors should consider human-factors literature to address practical challenges related to interacting with humans. However, the comment does not provide any specific examples or references to support the claim about ethical concerns or the limitations of the proposed method. The suggestion to check human-factors literature is a general recommendation without detailed justification or reasoning. This lack of specific evidence or reasoning makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concerns without further guidance.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the lack of specific ethical concerns with the proposed methods and suggests that the authors consider human-factors literature to address practical challenges related to interacting with humans. While it identifies a potential area for improvement, the comment lacks specific guidance or examples of ethical concerns that should be addressed. It also does not provide detailed suggestions on how to incorporate human-factors literature into the work. This limits the usefulness of the feedback, as the authors are left with a general suggestion without actionable steps to follow. Therefore, the comment is somewhat helpful, as it points out an area for"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. While the comment implies that the authors should explore the scalability and compare their approach with others, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these comparisons or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments conducted on a toy dataset, specifically mentioning MNIST and MNIST-fashion. It raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section. The comment is specific in its request for a comparison with other neural network pruning methods and questions the scalability of the approach. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It suggests comparing the approach with other neural network pruning methods. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim about scalability or comparisons. The suggestion to compare with other methods is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It suggests that the authors should explore the applicability of their approach to other datasets, which is a relevant and constructive suggestion. Additionally, the comment points out the need for a comparison with other neural network pruning methods, which could provide a more comprehensive evaluation of the proposed approach. While the comment identifies important areas for improvement, it could be more helpful by offering specific guidance on how to conduct these comparisons or suggesting which other methods to consider. Overall, the feedback is mostly helpful as it directs the authors toward meaningful enhancements to their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several specific mathematical formulation issues and inconsistencies in the paper, providing explicit examples and suggestions for correction. It highlights problems such as incorrect notation, inconsistent index usage, and unclear explanations in the hypervolume formula. Each point is concrete, allowing the authors to directly address the issues by making the necessary corrections. The explicit nature of the feedback ensures that the authors know exactly what needs to be changed, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 345,\" \"Line 347,\" \"Line 344,\" \"Line 374,\" \"Line 225,\" and \"Line 819,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the mathematical formulation issues and inconsistencies, such as the incorrect use of \"$max$\" instead of \"$max$\", inconsistent index notation, and unclear explanations in the hypervolume formula. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies several specific mathematical formulation issues and inconsistencies in the paper, providing explicit examples and corrections. Each line mentioned is pinpointed, allowing the authors to easily locate and address the issues. The comment is fully verifiable as it provides clear and precise examples of the mathematical errors, making it straightforward for the authors to understand and correct them. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies several specific mathematical formulation issues and inconsistencies in the paper. It provides explicit examples and corrections, such as suggesting the correct use of \"$max$\" instead of \"$max$\" in Line 345, clarifying the index notation inconsistency, and addressing the unexplained $x'$ in the hypervolume formula. These detailed observations and suggestions empower the authors to make precise corrections, significantly improving the clarity and accuracy of their mathematical formulations. The feedback is actionable and provides clear guidance for enhancing the draft, making it highly beneficial for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The authors can infer that they need to explore the impact of varying the number of particles, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the current clarity on the importance of this choice is lacking. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where this information is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to conduct experiments but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from experiments demonstrating the effect of using different numbers of particles. However, it does not provide specific examples or references to support why this choice is unclear or important. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the necessity of the suggested experiments. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the lack of clarity regarding the importance of this choice. However, the comment does not provide specific guidance on how to design these experiments or what aspects to focus on, leaving the authors with a general idea but without detailed direction. To be more helpful, the comment could include suggestions on how to structure the experiments or what specific outcomes to look for. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the current clarity on this choice is lacking. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The authors can infer that they need to explore the impact of varying the number of particles, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the current clarity on this choice is lacking. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the suggestion is specific in terms of what could be explored, the lack of grounding in the paper's structure makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from experiments demonstrating the effect of using different numbers of particles. However, it does not provide specific reasoning or evidence to support why this choice is unclear or important. The comment lacks detailed justification or examples, making it difficult for the authors to understand the necessity of the suggested experiments. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient support or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the current clarity on this choice is lacking. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for additional experiments to clarify the importance of this choice. However, the comment lacks specific guidance on how to design these experiments or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could include suggestions on how to structure the experiments or what specific outcomes to look for. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, indicating that the current clarity on this choice is lacking. While the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a comparison of the methods on plasticity evaluation metrics, specifically mentioning the covariance metric. While it identifies an area that needs attention, it does not provide explicit instructions or suggestions on how to incorporate this comparison or which specific aspects to focus on. The action is implicit, as the authors can infer that they need to include a comparison of their methods with plasticity evaluation metrics, but the comment lacks concrete guidance on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in identifying the need for a comparison on plasticity evaluation metrics, but without clear grounding, the authors may struggle to pinpoint where this comparison should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the comparison of methods on plasticity evaluation metrics, such as the covariance metric. This feedback is valuable as it highlights a gap in the paper that the authors can address to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate this comparison effectively. Despite this, the feedback is somewhat helpful as it directs the authors to an important aspect of their work that needs attention. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. While it identifies an area for improvement, it does not provide explicit instructions or suggestions on how to incorporate this comparison into the paper. The action is implicit, and the comment lacks concrete guidance on how to execute the suggested improvement. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific area where the paper lacks comparison, namely the plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in identifying the need for a comparison on plasticity evaluation metrics, but without clear grounding, the authors may struggle to pinpoint where this comparison should be added. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the comparison of methods on plasticity evaluation metrics, such as the covariance metric. This feedback is valuable as it highlights a gap in the paper that the authors can address to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate this comparison effectively. Despite this, the feedback is somewhat helpful as it directs the authors to an important aspect of their work that needs attention. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric. However, it does not provide explicit instructions or suggestions on how to incorporate this comparison into the paper. The action is implicit, as the authors can infer that they need to include a comparison, but the comment lacks concrete guidance on how to do"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies two specific areas that need improvement: the need for better explanation of the elements A, B, C, and D in Table 5, and the lack of explanation regarding why positive paths lead to monotonic solutions and under what scenarios. These requests provide clear and direct actions for the authors to take, specifying exactly what needs to be clarified or added to improve the draft. The feedback is concrete and actionable, ensuring the authors know exactly how to address the reviewer\\'s concerns. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a better explanation of the elements A, B, C, and D in Table 5 and asks for an explanation of why positive paths lead to monotonic solutions and under what scenarios. This provides clear guidance on what needs to be clarified or added to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 5 requires better explanation and provides specific questions about the elements A, B, C, and D, as well as the explanation of why positive paths lead to monotonic solutions. However, it does not provide any supporting evidence or reasoning to justify why these explanations are necessary or how they would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of these explanations or how they might address the reviewer\\'s concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires improvement, namely the need for better explanation of Table 5. It points out the lack of clarity regarding the elements A, B, C, and D in the table and questions the explanation of why positive paths lead to monotonic solutions and under what scenarios. This feedback is clear and actionable, as it directly guides the authors to provide additional context and explanation for these elements, which could enhance the clarity and understanding of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of what kind of explanation would be beneficial. Overall, the comment is mostly helpful, as it effectively directs the authors to address a specific weakness in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as a predictor of DS accuracy, based on observations from Figure 1. The reviewer asks how power law prediction can be used for model selection in practice, referencing Appendix Fig. F6, F7, F8, and F9. While the comment raises important questions and suggests potential areas for exploration, it does not provide explicit guidance or concrete steps for the authors to address these issues. The authors are left to infer that they might need to explore alternative methods or provide more detailed explanations, but the lack of specific instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. The comment further questions the reliability of early predictions of US accuracy as a predictor of DS accuracy and asks how power law prediction can be used for model selection in practice. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It references Figure 1 to support the claim that the curve is saturated only towards the end, indicating that early predictions may not be reliable. The comment also questions the use of power law prediction for model selection, referencing Appendix Fig. F6, F7, F8, and F9. While the comment provides some reasoning and references, it lacks detailed explanations or specific examples to fully substantiate the claims. This makes the comment somewhat verifiable, as it provides a basis for the claims but requires further elaboration to be fully actionable by the authors. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a practical concern about the time cost associated with obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheaper estimation. It also questions the reliability of early predictions of US accuracy as a predictor of DS accuracy, based on observations from Figure 1. The comment further explores the use of power law prediction for model selection, referencing Appendix Fig. F6, F7, F8, and F9. While the comment identifies important areas for consideration and provides some context, it lacks specific suggestions or guidance on how the authors might address these issues or improve their approach. The feedback is somewhat helpful as it prompts the authors to consider alternative methods and the reliability of their predictions, but it could be more actionable with additional detail or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is concrete, as it outlines a specific type of analysis that should be conducted, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where these studies should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific in terms of what needs to be done\u2014conducting ablation studies\u2014but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, the comment does not provide any justification or reasoning for why these studies are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of conducting these studies. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of the factors contributing to the performance of epsilon sampling. By conducting ablation studies, the authors can gain insights into which factors are most influential, potentially leading to improvements in their methodology or results. However, the comment could be more helpful if it provided examples of specific factors to consider or detailed guidance on how to design and execute these studies. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore how the proposed attack performs against the mode connectivity-based defense proposed in the ICLR paper. While the comment implies a specific action, it does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. The authors are left to infer the exact steps needed to address this suggestion, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references a specific ICLR publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which provides a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in this paper. However, the comment does not explicitly mention which part of the current paper this suggestion pertains to, such as specific sections or experiments. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in its request to test the proposed attack against the mode connectivity-based defense, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point references a specific ICLR publication to support the claim that Fine-Tuning is not the most effective approach to recover backdoor models unless sufficient clean data is available. This provides a logical reasoning for the claim, as it references an external source that validates the assertion. However, the comment could be strengthened by providing more details or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment references a specific ICLR publication to highlight a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in the referenced paper. This feedback is somewhat helpful as it directs the authors to consider an external source that could impact their work and suggests a specific comparison to make. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects to focus on, which limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in a specific ICLR paper. While the comment implies a specific action, it does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. The authors are left to infer the exact steps needed to address this suggestion, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references a specific ICLR publication to support a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in this paper. However, the comment does not explicitly mention which part of the current paper this suggestion pertains to, such as specific sections or experiments. While the authors can infer that it relates to the discussion or results sections, the lack of explicit grounding makes it challenging to pinpoint the exact area needing attention. The comment is specific in its request to test the proposed attack against the mode connectivity-based defense, but the lack of explicit grounding reduces its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point references a specific ICLR publication to support a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in this paper. While the reference to the ICLR paper provides some support for the claim, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work. As it stands, the claim is somewhat verifiable, as it points to an external source but lacks comprehensive justification within the context of the current paper. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment references a specific ICLR publication to highlight a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should explore how their proposed attack performs against the mode connectivity-based defense proposed in the referenced paper. This"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the authors\\' decision not to include the codes during the review process, which affects the transparency of the claims. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on whether the authors should include the codes, how to do so, or what specific steps to take to enhance transparency. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the authors\\' decision not to include the codes during the review process, which affects the transparency of the claims. However, it does not specify which part of the paper this issue pertains to, such as the methodology section or the results section. The authors might infer that it relates to the transparency of the claims, but this inference is not direct. The comment is specific in identifying the issue of transparency but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' decision not to include the codes during the review process makes the claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this decision affects transparency. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the transparency of the claims due to the authors\\' decision not to include the codes during the review process. However, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without further elaboration or recommendations, the authors are left with a general concern but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential problem but does not offer sufficient guidance for the authors to effectively address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part, \"3) is not necessary,\" is vague and does not provide any actionable guidance or explanation for the authors. The second part, \"I encourage the authors to validate the proposed approach in Waymax in the future,\" is more actionable. It explicitly suggests that the authors should validate their approach in Waymax, which provides more traffic scenarios. However, it does not specify how this validation should be conducted or what aspects should be focused on. The overall comment provides some direction but lacks detailed guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, making it difficult for the authors to identify the specific section or aspect being discussed. Additionally, the comment lacks specificity regarding what is considered unnecessary or what needs to be addressed in the paper. The suggestion to validate the approach in Waymax is somewhat specific, but without clear grounding, the authors may struggle to understand the context or importance of this suggestion. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two parts. The first part, \"3) is not necessary,\" is a subjective claim without any supporting evidence or reasoning, making it unverifiable. The second part, \"I encourage the authors to validate the proposed approach in Waymax,\" is a suggestion rather than a claim. It does not contain any justification or evidence to support the need for validation in Waymax. Therefore, the overall comment is a mix of subjective claims and suggestions, with the latter being verifiable. However, the lack of justification for the first part makes the entire comment unverifiable. This aligns with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a mix of feedback. It initially states that a particular aspect is not necessary, which lacks clarity and actionable guidance. However, it then offers a more helpful suggestion by encouraging the authors to validate their proposed approach in Waymax, which provides more traffic scenarios compared to the current version. This part of the comment is actionable and provides a clear direction for the authors to consider expanding their validation efforts. Overall, the comment is somewhat helpful as it identifies a potential area for improvement and offers a specific suggestion, but it could be more comprehensive with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment critiques the technical contribution of the paper, noting that the transformer-based TAPG method has been studied in previous works and that the main difference lies in the visual features. It also mentions the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA), which has been proven effective in dance action recognition. The reviewer suggests that the choice of additional features may not provide significant insights to the community. However, the comment does not offer specific guidance or suggestions on how the authors could enhance the significance of their technical contribution or address the critique. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the technical contribution of the paper, specifically mentioning the transformer-based TAPG method and its relation to previous works like RTD-Net (ICCV2021). It highlights the main differences between RTD-Net and the proposed method, which include the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The comment also discusses the effectiveness of LMA in dance action recognition and suggests that the choice of additional features may not provide significant insights to the community. However, the comment does not specify which part of the paper this critique is based on, such as the introduction or related work section. While the authors can infer that it relates to the technical contribution, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the critique of the technical contribution and the potential lack of novelty. Therefore, this comment is weakly grounded and specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the technical contribution of the paper is not significant, as the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). The reviewer provides a rationale for this claim by noting that the main difference between RTD-Net and the proposed method lies in the visual features, and that the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA) is not groundbreaking. The reviewer supports this claim by referencing the effectiveness of LMA in dance action recognition, suggesting that the use of additional features may not provide significant insights. However, the comment could be strengthened by providing specific references or examples of previous works that have used similar features. Overall, the claim is mostly verifiable due to the logical reasoning and references provided, but it could benefit from more detailed evidence or examples.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works and that the main difference lies in the visual features. It notes that the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA) is not groundbreaking, as LMA has been proven effective in dance action recognition. The comment implies that the choice of additional features may not provide significant insights to the community. However, the feedback lacks specific suggestions or actionable steps for the authors to enhance the significance of their contribution. Without detailed guidance or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment critiques the technical contribution of the paper, noting that the transformer-based TAPG method has been studied in previous works and that the main difference lies in the visual features. It also mentions the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA), which has been proven effective in dance action recognition. The reviewer suggests that the choice of additional features may not provide significant insights to the community. However, the comment does not offer specific guidance or suggestions on how the authors could enhance the significance of their technical contribution or address the critique. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the technical contribution of the paper, specifically mentioning the transformer-based TAPG method and its relation to previous works like RTD-Net (ICCV2021). It highlights the main differences between RTD-Net and the proposed method, which include the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The comment also discusses the effectiveness of LMA in dance action recognition and suggests that the choice of additional features may not provide significant insights to the community. However, the comment does not specify"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The authors can infer that they need to perform additional experiments, but the lack of concrete details makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"implementation of tree construction\" and the \"different design choices of merging nodes among adjacent layers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more experimental comparisons to evaluate these design choices. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. However, the comment does not provide any specific reasoning, examples, or references to support why these comparisons are necessary or how they would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by conducting additional experiments. However, the comment could be more helpful if it offered specific suggestions on how to design these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include several baselines that outperform their work in Table 2, even though their results are slightly weak. This feedback provides a clear and direct action for the authors to take, specifying exactly which baselines need to be added to the table. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by pointing out that the paper hides several baselines that outperform it and suggests that these should be reported for completeness, even though their results are slightly weak. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete because it hides several baselines that outperform the paper\\'s results. The reviewer suggests that these baselines are reported in the Re-BART paper and should be included for completeness, even though their results are slightly weak. This claim is somewhat verifiable as it references an external source (Re-BART) to support the need for inclusion. However, the comment lacks specific examples or detailed reasoning about why these baselines are important or how their inclusion would impact the paper. Providing more detailed justification or examples would strengthen the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and hides several baselines that outperform the paper\\'s results. It suggests that these baselines should be reported for completeness, even though their results are slightly weak. This feedback is clear and actionable, as it provides a direct suggestion for improving the completeness of the paper by including additional baselines. However, the comment could be more helpful if it explained why these baselines are important or how their inclusion would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it guides the authors on how to enhance the completeness of their work, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment implies that the authors should provide more comprehensive evaluations, it does not explicitly instruct them to do so or specify which sequences should be included. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluations and provide more details on the chosen scenes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or results section. The comment is specific in its request for more thorough evaluations and questions about the chosen scenes, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. However, it does not provide any specific reasoning or evidence to support why more scenes should be included or why the chosen scenes are insufficient. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the evaluations on real datasets could be more thorough. It questions the choice of only three scenes from the HS-ERGB dataset and asks about the performance on other sequences. This feedback is somewhat helpful as it prompts the authors to consider expanding their evaluation to include more scenes or datasets, which could enhance the robustness and generalizability of their findings. However, the comment lacks specific guidance or suggestions on how to conduct these additional evaluations or which sequences to include, leaving the authors with a general direction but without detailed direction. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment implies that the authors should provide more comprehensive evaluations, it does not explicitly instruct them to do so or specify which sequences should be included. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluations and provide more details on the chosen scenes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or results section. The comment is specific in its request for more thorough evaluations and questions about the chosen scenes, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. However, the comment lacks specific reasoning or evidence to support why more scenes or sequences should be included. The suggestion is based on a general observation rather than a detailed critique or reference to established practices, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to expand the evaluations or which sequences should be included. The feedback provides some direction for the authors to consider, but it could be more helpful with detailed advice or examples. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', '"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of 44 bits, suggesting that more bits could be used without affecting computation time on GPU. It also questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the use of 44 bits and the interpretation of bit-embeddings in the context of predicting the rank of words. It raises questions about the semantic relations among words with odd ranks and whether the model is simply memorizing the data. However, the comment does not explicitly mention which part of the paper these issues pertain to, such as specific sections or experiments. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the issues and questions raised. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of 44 bits, suggesting that more bits could be used without affecting computation time on GPU. It also questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors may find it challenging to understand and address the issues without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main concerns: the use of 44 bits, which is considered too small, and the interpretation of bit-embeddings in the context of predicting the rank of words. It questions the semantic relations among words with odd ranks and whether the model is simply memorizing the data. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback provides some insight into the limitations of the current approach but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the use of 44 bits, suggesting that more bits could be used without affecting computation time on GPU. It also questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the use of 44 bits and questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. However, it does not specify which part of the paper these issues pertain to, such as specific sections or experiments. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment lacks specificity in detailing what needs to be addressed or improved, making it challenging for the authors to pinpoint the exact areas requiring attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the use of 44 bits, suggesting that more bits could be used without affecting computation time on GPU. It also questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or further explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main concerns: the use of 44 bits,"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. While the comment highlights a problem, it does not offer explicit guidance or suggestions on how the authors might address this issue. The action is implicit, as the authors need to infer that they should provide a solution for mitigation, and it is vague because it lacks specific steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the proposed method, namely the requirement for human annotation to provide semantically meaningful information, which can be subjective. It mentions that this limitation is discussed in the appendix but notes the absence of a solution for mitigation. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of subjective annotation and the lack of a mitigation solution, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. The comment acknowledges that this limitation is mentioned in the appendix but notes the absence of a solution for mitigation. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the subjective nature of human annotation. The absence of detailed reasoning or evidence makes it somewhat verifiable, as the authors would need to further explore and address the issue themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks depth and actionable advice, leaving the authors with only a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights a problem, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit, as the authors need to infer that they should provide a solution for mitigation, and it is vague because it lacks specific steps or examples. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the proposed method, namely the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment identifies a relevant aspect of the paper, it does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. However, the comment is specific in detailing the issue and the need for a mitigation solution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. The comment acknowledges that this limitation is mentioned in the appendix but notes the absence of a solution for mitigation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim about the subjective nature of human annotation. The absence of concrete evidence or references makes it somewhat verifiable, as the authors would need to further explore and address the issue themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks depth and actionable advice, leaving the authors with only a general direction to explore. Therefore, the comment"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, including \"Pretrain a CausalLM using this dataset (mixed with other datasets used by ObscuraCoder, except obfuscated ObscuraX)\" and \"Compare its performance against ObscuraCoder to conclusively attribute any improvements to the deobfuscation objective.\" These actions are clear and concrete, giving the authors specific steps to follow to improve their draft. The comment provides detailed guidance on how to implement these actions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests pretraining a CausalLM using a specific dataset and compares its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to use a particular dataset and compare against ObscuraCoder, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests pretraining a CausalLM using a specific dataset and compares its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any justification or reasoning for why this approach would be beneficial or how it would help in attributing improvements. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. This feedback is specific and offers a concrete step for the authors to enhance their analysis and provide a more robust evaluation of their method. By following this suggestion, the authors can strengthen their paper by demonstrating the effectiveness of their approach. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is particularly relevant to the study. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a minor issue with the loss equation in the paper, specifically pointing out that the geometric loss should be added to the reconstruction loss, rather than being itself. This feedback provides a clear and direct action for the authors to take, which is to correct the equation as specified. The comment is specific and actionable, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the loss equation shown in lines 264-266, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the correction of the loss equation by adding the geometric loss to the reconstruction loss, rather than itself. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction to the loss equation, specifically stating that the geometric loss should be added to the reconstruction loss, rather than itself. This claim is based on a logical reasoning that the geometric loss should be part of the reconstruction loss, which is a common practice in similar contexts. However, the comment does not provide references or detailed explanations to fully substantiate the claim, making it somewhat verifiable. The authors would need to verify this themselves, as the reasoning is not fully articulated in the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a minor issue with the loss equation in the paper, specifically pointing out that the geometric loss should be added to the reconstruction loss, rather than being itself. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their work. By addressing this minor error, the authors can enhance the precision of their methodology, which is beneficial for the overall quality of the paper. However, the comment could be more helpful if it explained the significance of this correction or provided additional context on why it is important. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method should also be employed in autoregressive language models, which are more prevalent in real-world applications. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the paper to incorporate this idea. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method should also be employed in autoregressive language models, which are more prevalent in real-world applications. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to employ the method in autoregressive models, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should also be employed in autoregressive language models, which are more prevalent in real-world applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method should also be applied to autoregressive language models, which are more prevalent in real-world applications. While this is a relevant point, the comment lacks specificity and does not provide actionable guidance on how the authors might implement this suggestion or why it would be beneficial. Without detailed feedback or examples, the authors may find it challenging to determine how to incorporate this suggestion into their work. Therefore, the comment is barely helpful, as it identifies an area for improvement but does not offer sufficient detail or guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the claim that the GAN is difficult to optimize and use adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section does not address how to avoid the issue of the vanishing gradient and model collapsing. While the comment highlights areas that need clarification and improvement, it does not provide explicit guidance or concrete suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more detailed explanations and solutions to these problems, but the lack of specific instructions makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim about the difficulty of optimizing the GAN and using adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification and additional discussion on these topics. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the GAN is difficult to optimize and use adversarial gradient updating, suggesting that it is not clear why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. While the comment raises valid concerns, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors may find it challenging to address these concerns without additional context or evidence. Therefore, the comment is somewhat verifiable, as it highlights important issues but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the claim that the GAN is difficult to optimize and use adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. While the comment identifies critical areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback highlights important concerns but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the claim that the GAN is difficult to optimize and use adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. While the comment identifies areas that need clarification and improvement, it does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable steps or specific advice, leaving the authors to infer the necessary improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the claim that the GAN is difficult to optimize and use adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification and additional discussion on these topics, but without clear grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the GAN is difficult to optimize and use adversarial gradient updating, suggesting that it is not clear why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient and model collapsing in the method section. While the comment raises valid concerns, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors may find it challenging to address these concerns without additional context or evidence. Therefore, the comment is somewhat verifiable, as it highlights important issues but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the claim that the GAN is difficult to optimize and use adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on how to avoid the issue of the vanishing gradient"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of models for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors can infer that they might need to justify or clarify their choice of models, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of models for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. This question highlights a potential issue with the methodology or rationale behind the study. However, the comment does not specify which part of the paper discusses the ablation study, making it weakly grounded. The authors can infer that it relates to the methodology or results section, but this inference is not direct. The comment is specific in questioning the choice of models, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of models for the ablation study. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of models for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. This question highlights a potential gap in the methodology or rationale behind the study, prompting the authors to reconsider or justify their choice of models. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative models or explaining the reasons behind the choice. While it identifies a potential area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the removal of previous reports of SciBERT, which exacerbates an earlier problem in the paper where the analyses of the models were cursory and lacked deeper analysis. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the depth of the analyses. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to respond to this critique. Since the comment does not offer a clear path for improvement, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the removal of previous reports of SciBERT, which exacerbates an earlier problem in the paper where the analyses of the models were cursory and lacked deeper analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem of cursory analyses and the unfairness of writing it as a weakness, but it lacks grounding as it does not direct the authors to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of previous reports of SciBERT exacerbates an earlier problem in the paper, where the analyses of the models were cursory and lacked deeper analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. It also suggests that writing it as a weakness is unfair, but it lacks a clear explanation of why this is the case. The comment lacks sufficient evidence or justification to fully substantiate the claim, making it somewhat verifiable. Therefore, the feedback is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's approach, specifically the removal of previous reports of SciBERT, which exacerbates an earlier problem where the analyses of the models were cursory and lacked deeper analysis. However, the comment suggests that writing this as a weakness is unfair because the current paper does not mention it. While the comment highlights a relevant concern, it lacks actionable guidance or suggestions on how the authors might address this issue or improve the depth of their analyses. The feedback is somewhat helpful as it points out a potential weakness but does not provide specific directions for improvement, leaving the authors with limited guidance on how to enhance their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights a concern about the removal of previous reports of SciBERT, which exacerbates an earlier problem in the paper where the analyses of the models were cursory and lacked deeper analysis. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the depth of their analyses. The comment lacks actionable details, leaving the authors uncertain about how to respond to this critique. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the removal of previous reports of SciBERT, which exacerbates an earlier problem in the paper where the analyses of the models were cursory and lacked deeper analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem of cursory analyses and the unfairness of writing it as a weakness, but it lacks grounding as it does not direct the authors to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of previous reports of SciBERT exacerbates an earlier problem in the paper, where the analyses of the models were cursory and lacked deeper analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. It also suggests that writing it as a weakness is unfair, but it lacks a clear explanation of why this is the case. The absence of concrete evidence or justification makes it difficult for the authors to understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's approach, specifically the removal of previous reports of SciBERT, which exacerbates an earlier problem where the analyses of the models were cursory and lacked deeper analysis. However, the comment suggests that writing this as a weakness is unfair because the current paper does not mention it. While the comment highlights a relevant"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the origin of the connectivity graph $\\\\cal{G}_{F}$ in the \"Functional connectivity encoder\" section and the unclear source of patches and how they are mixed. While the comment identifies areas of confusion, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to clarify the source of the connectivity graph and the mixing process of the patches, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues, namely the unclear origin of the connectivity graph $\\\\cal{G}_{F}$ and the difficulty in discerning the source of patches and how they are mixed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the mixing process of patches. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of unclearness. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the \"Functional connectivity encoder\" section, particularly questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the mixing process of patches. This feedback highlights a critical area that needs clarification, which is essential for readers to understand the methodology and results. However, the comment does not provide detailed guidance or suggestions on how to improve the clarity or what specific aspects need to be addressed. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the \"Functional connectivity encoder\" section, particularly questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the mixing process of patches. While it highlights areas of confusion, it does not provide explicit guidance or suggestions on how to address these issues. The authors can infer that they need to clarify these aspects, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues, namely the unclear origin of the connectivity graph $\\\\cal{G}_{F}$ and the difficulty in discerning the source of patches and how they are mixed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the mixing process of patches. However, the comment lacks supporting evidence, reasoning, or specific examples to substantiate the claim of unclearness. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the \"Functional connectivity encoder\" section, particularly questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the mixing process of patches. This feedback highlights a critical area that needs clarification, which is essential for readers to understand the methodology and results. However, the comment does not provide detailed guidance or suggestions on how to improve the clarity or what specific aspects need to be addressed. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the \"Functional connectivity encoder\" section, particularly questioning the origin of the connectivity"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the claim in Figure 4(b) that the proposed method results in faster training, suggesting that it seems far-fetched given that all networks are trained for the same amount of epochs. The reviewer also recommends a longer discussion of related work. While the comment identifies specific issues with the claim and suggests an area for improvement, it does not provide explicit guidance on how to address these concerns or what specific aspects of the related work should be discussed. The action is implicit and somewhat vague, as the authors know they need to address the claim and discuss related work but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and the claim about faster training, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the claim in Figure 4(b) and suggests that the proposed method does not result in faster training due to all networks being trained for the same amount of epochs. Additionally, the comment provides a specific suggestion for improvement by recommending a longer discussion of related work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Figure 4(b) indicates faster training due to the proposed method, suggesting that it seems far-fetched given that all networks are trained for the same amount of epochs. The reviewer also points out that pruning is a broad field and recommends a longer discussion of related work. While the comment provides some reasoning and suggests a potential issue with the claim, it lacks specific examples or references to support the assertion that the claim is far-fetched. This makes the comment somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment addresses a specific claim in the paper regarding the faster training of the proposed method, questioning the validity of Figure 4(b) and suggesting that the claim seems far-fetched given that all networks are trained for the same amount of epochs. This feedback is valuable as it prompts the authors to reconsider their claims and provide a more robust justification for their results. Additionally, the comment suggests that the paper would benefit from a longer discussion of related work, which could enhance the context and depth of the paper. While the comment identifies a specific issue and provides a direction for improvement, it could be more helpful by offering suggestions on how to address the concern about the claim or how to effectively integrate a discussion of related work. Overall, the comment is mostly helpful as it provides actionable feedback but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment questions the validity of a claim regarding faster training in Figure 4(b) and suggests that it seems far-fetched given that all networks are trained for the same amount of epochs. It also recommends a longer discussion of related work. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address the issue with the claim or how to effectively incorporate a discussion of related work. The actions are implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and the claim about faster training, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the claim in Figure 4(b) and suggests that it seems far-fetched given that all networks are trained for the same amount of epochs. Additionally, the comment provides a specific suggestion for improvement by recommending a longer discussion of related work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of a claim regarding faster training in Figure 4(b), suggesting that it seems far-fetched given that all networks are trained for the same amount of epochs. The reviewer also points out that pruning is a broad field and recommends a longer discussion of related work. While the comment provides some reasoning and suggests a potential issue with the claim, it lacks specific examples or references to support the assertion that the claim is far-fetched. This makes the comment somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment addresses a specific claim in the paper regarding faster training due to the proposed method, questioning the validity of Figure"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the derivative of the \"Lagrangian,\" pointing out that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This feedback provides a clear and direct action for the authors to take, which is to correct the derivative in their draft. The comment is specific and actionable, ensuring that the authors know exactly what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the derivative of the \"Lagrangian,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the derivative, noting that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the \"Lagrangian\" is incorrect, specifically stating that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}. This claim is based on a clear mathematical correction, which provides a straightforward and precise explanation of the error. The comment is fully verifiable as it offers a specific and accurate correction, allowing the authors to easily identify and address the issue. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the mathematical derivation of the paper, specifically pointing out that the derivative of the \"Lagrangian\" is incorrect. It provides a clear and actionable correction by specifying the correct derivative, which is -1/2n^{-3/2} instead of 1/2n^{-3/2}. This feedback is highly helpful as it directly addresses a critical mathematical error that could impact the validity of the paper\\'s conclusions. By correcting this error, the authors can significantly improve the accuracy and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is not clear, particularly due to a lack of background information on cognitive models in the introduction. It implies that the authors should refine their writing to improve clarity. However, the comment does not provide specific guidance on what aspects of the writing need improvement or how the authors should address the lack of background information. While the action is implied, it lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment indicates that the introduction lacks background information on cognitive models, suggesting that the authors need to refine their writing. However, it does not specify which parts of the introduction are unclear or how the authors should improve them. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is weakly grounded because it does not provide specific guidance on where the issues lie, and it is not specific in suggesting how to address the lack of background information. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not clear, particularly due to a lack of background information on cognitive models in the introduction. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand which parts of the introduction are unclear or how to improve them. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the introduction lacks background information on cognitive models. It suggests that the authors need to refine their writing to improve clarity. While the feedback highlights a clear area for improvement, it does not provide detailed guidance or specific suggestions on how to enhance the introduction or what aspects of the cognitive models should be included. This limits the usefulness of the comment, as it gives the authors a general direction but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claims and the actual performance of DFA on the NLP task, suggesting that DFA\\'s performance is not sufficiently emphasized in the paper. It implies that the authors should clarify this discrepancy in the abstract or elsewhere in the paper. However, the comment does not provide explicit instructions on how to address this issue, such as recommending specific changes to the abstract or suggesting ways to highlight the performance gap. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the clarity of their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that DFA performance lags behind backprop performance on this task and that this is not sufficiently emphasized in the paper, particularly in the abstract. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that DFA performance on the NLP task lags behind backprop performance and that this is not sufficiently emphasized in the paper. The reviewer provides a logical reasoning by pointing out the discrepancy between the abstract\\'s impression of DFA\\'s performance and the actual results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the abstract and the paper to understand the basis of the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claims and the actual performance of DFA on the NLP task, noting that DFA\\'s performance lags behind backprop performance. It points out that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract, which gives readers the impression that DFA works at near-backprop levels on this task. This feedback is clear and actionable, as it directs the authors to clarify and correct the misrepresentation in their abstract and elsewhere in the paper. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending ways to rephrase the abstract or include additional analysis. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the accuracy and clarity of their claims.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claims and the actual performance of DFA on the NLP task, noting that DFA\\'s performance lags behind backprop performance. It suggests that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract. However, the comment does not provide explicit guidance on how the authors should address this issue, such as recommending specific changes to the abstract or providing additional analysis. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that DFA performance lags behind backprop performance on this task and that this is not sufficiently emphasized in the paper, particularly in the abstract. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that DFA performance on the NLP task lags behind backprop performance and that this is not sufficiently emphasized in the paper. The reviewer provides a logical reasoning by pointing out the discrepancy between the abstract\\'s impression of DFA\\'s performance and the actual results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the abstract and the paper to understand the basis of the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claims and the actual performance of DFA on the NLP task, noting that DFA\\'s performance lags behind backprop performance. It points out that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract, which gives readers the impression that DFA works at near-backprop levels on this task. This feedback is clear and actionable, as it directs the authors to clarify and correct the misrepresentation in their abstract and elsewhere in the paper. However, the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It suggests including specific methods like SRW and FROT as baselines. This feedback provides a clear and direct action for the authors to take, specifying exactly which methods should be added to the baseline. The comment is explicit and concrete, giving the authors a straightforward path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of a baseline, specifically mentioning dimensional reduction methods in optimal transport estimation. It suggests including SRW and FROT as baselines, which provides a clear direction for improvement. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it identifies particular methods that should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It suggests including specific methods like SRW and FROT as baselines. While the comment identifies a potential gap in the paper, it lacks detailed reasoning or evidence to support why these methods are necessary or how they would improve the baseline. The suggestion is based on a general observation rather than a comprehensive analysis, making the claim somewhat verifiable. The authors would need to further explore and justify the inclusion of these methods to fully understand the rationale behind the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks a comprehensive baseline, particularly for dimensional reduction methods in optimal transport estimation. It suggests including specific methods like SRW and FROT as baselines, which provides clear and actionable feedback for the authors to enhance their work. By highlighting this gap and offering concrete examples of methods to consider, the comment empowers the authors to make significant improvements to their draft. However, it could be more helpful if it provided additional context or reasoning on why these methods are important or how they would impact the study. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a discussion on the advantages and disadvantages of transductive learning. However, it does not provide any explicit or implicit action for the authors to take, nor does it suggest how they might address this gap. Without specific guidance or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out the absence of a discussion on the advantages and disadvantages of transductive learning. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of transductive learning should be discussed or how the discussion should be structured. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the advantage and disadvantage of the transductive learning has not yet discussed.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this discussion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out the absence of a discussion on the advantages and disadvantages of transductive learning. While it identifies a potential gap in the paper, it lacks specificity and does not provide guidance on how the authors might address this issue or what aspects of transductive learning should be discussed. Without actionable feedback or suggestions, the authors are left with a general idea of what needs to be improved but no clear direction on how to proceed. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the invariance of the contractivity should be stated formally. While this implies a specific action\u2014formalizing the statement\u2014it does not provide detailed guidance on how to achieve this or what aspects of the contractivity should be formalized. The action is explicit but somewhat vague, as the authors know they need to formalize the statement but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the contractivity should be formalized or how this could be achieved. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of formalizing this aspect. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, which could enhance the clarity and rigor of the paper. However, it lacks specificity and does not provide detailed guidance on how to formalize this aspect or why it is important. Without additional context or suggestions, the authors may find it challenging to determine the exact steps needed to address this feedback. Therefore, the comment is barely helpful, as it identifies a potential improvement but does not offer actionable advice.', 'helpfulness_label': '2'}{'actionability_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, implying that the authors should provide a formal statement regarding this aspect. However, it does not specify what aspects of the contractivity should be formalized or how this should be done, leaving the authors with a vague understanding of what needs to be addressed. The lack of explicit guidance or concrete details makes it difficult for the authors to determine the exact steps to take to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, but it does not specify which part of the paper this pertains to, making it not grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contractivity should be formalized or how this could be achieved. Without clear guidance or references to specific sections, the authors may struggle to address the feedback effectively. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance or impact of formalizing this aspect. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, which could enhance the clarity and rigor of the paper. However, it lacks specificity and does not provide detailed guidance on how to formalize this aspect or why it is important. Without additional context or actionable advice, the authors may find it challenging to determine the exact steps needed to address this feedback. Therefore, the comment is barely helpful, as it identifies a potential improvement but does not offer sufficient guidance for the authors to implement it effectively.', 'helpfulness_label': '2'}{'actionability_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, implying that the authors should provide a formal statement regarding this aspect. However, it does not specify what aspects of the contractivity should be formalized or how this should be done, leaving the authors with a vague understanding of what needs to be addressed. The lack of explicit guidance or concrete details makes it difficult for the authors to determine the exact steps to take to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, but it does not specify which"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the potential contribution of uncertainty saliency maps, noting that without an application or evaluation, their significance is unclear. It also expresses disagreement with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide specific guidance or suggestions on how the authors could address these concerns or improve their draft. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without application or evaluation. It also expresses disagreement with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these maps or the evaluation, making it weakly grounded. The authors might infer that it relates to sections discussing the methodology or results, but this is not explicitly stated. The comment is specific in its critique of the claim and the need for evaluation, but it lacks grounding in the paper's structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the significance of uncertainty saliency maps without application or evaluation, suggesting that the claim about their trustworthiness is not substantiated. The reviewer provides a logical reasoning by questioning the trustworthiness of uncertainty/confidence generated from the same mechanism as the explanation. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and address these points to fully understand and respond to the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the potential contribution of uncertainty saliency maps, noting that without application or evaluation, their significance is unclear. It also challenges the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. While the comment identifies a potential weakness in the paper's argument, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback highlights an important area for clarification and improvement but does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the potential contribution of uncertainty saliency maps, noting that without application or evaluation, their significance is unclear. It also questions the trustworthiness of uncertainty/confidence generated from the same mechanism as the explanation. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. Without actionable steps or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without application or evaluation. It also challenges the claim about the trustworthiness of uncertainty/confidence generated from the same mechanism as the explanation. However, the comment does not specify which part of the paper discusses these maps or the evaluation, making it weakly grounded. The authors might infer that it relates to sections discussing methodology or results, but this is not explicitly stated. The comment is specific in its critique of the claim and the need for evaluation, but it lacks grounding in the paper's structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the significance of uncertainty saliency maps without application or evaluation, suggesting that their trustworthiness is not substantiated. It also challenges the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to further explore and address these points to fully understand and respond to the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the potential contribution of uncertainty saliency maps, noting that without application or evaluation, their significance is unclear. It also challenges the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. While the comment identifies important areas for consideration, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback highlights"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, asking what it offers that other methods cannot. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their draft by discussing the diffusion model. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer, asking what it offers that other methods cannot. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion about methods. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the unique contribution of the diffusion model, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, asking what it offers that other methods cannot. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is relevant or how it impacts the paper. The comment lacks any claim or suggestion that requires verification, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the significance of using the diffusion model in style transfer, asking what it offers that other methods cannot. This is a relevant point that could prompt the authors to clarify the unique contributions of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, it does not offer actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view's effect. While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to add this content or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and determine the specific aspects to compare. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the multi-view latent attack enhances the model's meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods. However, the comment does not specify which part of the paper this assessment is based on, nor does it provide detailed guidance on how to enhance understanding of the multi-view's effect. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the multi-view latent attack enhances the model's meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer supports this claim by comparing the multi-view training to task augmentation meta-learning methods, referencing specific works [1, 2, 3]. This provides a logical basis for the claim, as it connects the multi-view latent attack to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a thoughtful critique of the paper's contribution, specifically regarding the multi-view latent attack's enhancement of the model's meta generalizability. It suggests that this enhancement allows the model to outperform other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer also points out a similarity between the multi-view training and task augmentation meta-learning methods, which could be further explored in the related work section. This feedback is clear and actionable, as it guides the authors to include a discussion or comparison in the related work section to enhance understanding of the multi-view's effect. However, the comment could be more helpful if it provided specific suggestions on how to structure this discussion or comparison. Overall, the comment is mostly helpful as it offers a constructive direction for improving the draft, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view's effect. While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to add this content or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and determine the specific aspects to compare. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests including a discussion or comparison in the related work section to enhance understanding of the multi-view's effect. However, it does not specify which part of the paper this assessment is based on, nor does it provide detailed guidance on what aspects should be discussed or compared. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the multi-view latent attack enhances the model's meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer supports this claim by comparing the multi-view training to task augmentation meta-learning methods, referencing specific works [1, 2, 3]. This provides a logical basis for the claim, as it connects the multi-view latent attack to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_r"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the impact of Age and FaceID features is not studied in the ablation, implying that the authors should include an analysis of these features. However, the comment does not explicitly instruct the authors to conduct this analysis or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should add an ablation study on these features. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of study on the impact of Age and FaceID features in the ablation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where these features are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing analysis of Age and FaceID features, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved by pointing out that the impact of Age and FaceID features is not studied in the ablation. This feedback is clear and actionable, as it directs the authors to include an analysis of these features, which could enhance the comprehensiveness of their study. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights a clear area for improvement and provides some direction, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests moving the detailed discussion from Appendix to the main manuscript, which provides a clear and direct action for the authors to take. It also questions the purpose of the values in Table 2 and Fig. 5, implying that the authors should clarify or justify these values. The suggestion to move the discussion to the main manuscript is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the purpose of the values in Table 2 and Fig. 5 and suggests moving the detailed discussion from the Appendix to the main manuscript. This provides clear guidance on what needs to be addressed or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of Table 2 and Fig. 5 in the Appendix, suggesting that the values in these figures are not adequately discussed in the main manuscript. The reviewer provides a specific suggestion to move the discussion to the main manuscript, which is a clear and actionable recommendation. However, the comment lacks detailed reasoning or evidence to support why the values in Table 2 and Fig. 5 are insufficiently discussed in the main manuscript. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the ablation study results presented in Table 2 and Fig. 5 are not discussed in the main manuscript. It questions the purpose of these values and suggests moving the detailed discussion from the Appendix to the main manuscript. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the clarity and accessibility of their results. By addressing this point, the authors can enhance the comprehensibility and impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include more LLM-related results in their paper, specifically mentioning the need to conduct experiments on llama-3-70B and Mistral-7B, in addition to the current experiments on llama2-7B and mt-bench. This feedback provides a clear and direct action for the authors to take, specifying exactly what additional experiments are expected. The comment is explicit and concrete, offering specific guidance on how to enhance the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"main purpose\" of the Lorta method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely more LLM-related results, and suggests particular LLM models (llama-3-70B and Mistral-7B) that the authors should include in their experiments. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more LLM-related results, specifically mentioning the Lorta method\\'s purpose of efficient fine-tuning of LLMs. The reviewer suggests that the authors should conduct experiments on additional LLMs like llama-3-70B and Mistral-7B, which is a logical expectation based on the method\\'s purpose. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the importance of these additional experiments, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors include more LLM-related results in their experiments. It specifically mentions the Lorta method\\'s purpose of efficient fine-tuning of LLMs and suggests conducting experiments on additional LLMs like llama-3-70B and Mistral-7B, which were not included in the current experiments. This feedback is valuable as it directs the authors to expand their experimental scope, potentially enhancing the paper\\'s contribution and relevance. However, the comment could be more helpful if it provided additional context or reasoning about why these specific LLMs are important or how they relate to the paper\\'s objectives. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) outperforms ReAct prompting and is closely related to self-consistency + CoT and Tree-of-thoughts. However, it raises a concern about the performance of DFSDT for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to test DFSDT on other LLMs, but the comment lacks concrete steps or recommendations on how to do so. Therefore, the comment is somewhat actionable, as it points out an area for further investigation but does not provide detailed guidance on how to proceed.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and its relationship to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the performance of DFSDT for other types of LLMs not in the category of LLaMA, GPT, or Claude. However, the comment does not specify which part of the paper discusses DFSDT, making it weakly grounded. The comment is specific in detailing the issue with the performance of DFSDT for other LLMs, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the performance of DFSDT for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment provides some context by mentioning related techniques, it lacks specific examples or references to substantiate the claim about the relationship to self-consistency + CoT and Tree-of-thoughts. Additionally, the concern about performance on other LLMs is not supported by any evidence or reasoning. This makes the claim somewhat verifiable, as it provides some basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed \"Depth First Search-based Decision Tree\" (DFSDT) by pointing out its close relationship to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the performance of DFSDT for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment highlights a relevant point, it lacks specific suggestions or guidance on how the authors might address these concerns or further explore the performance of DFSDT across different LLMs. The feedback is somewhat helpful as it prompts the authors to consider the broader applicability of their method, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the appropriateness of proposing an identical method without proper acknowledgment of previous work. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific ways to acknowledge contributions or referencing relevant literature. The action is implicit and vague, leaving the authors uncertain about how to implement the feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the appropriateness of proposing an identical method without proper acknowledgment of previous work. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. The authors might infer that it relates to the discussion of related work, but this inference is not direct. The comment is specific in its critique of the ethical implications of claiming originality for an identical method, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method without proper acknowledgment of previous work. However, the comment does not provide specific examples or references to the existing work that the proposed method resembles, nor does it explain why this is considered inappropriate. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the ethical implications of proposing an identical method without proper acknowledgment of previous work. It highlights the importance of giving credit to contributors and the inappropriateness of claiming originality for an existing method. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending ways to properly acknowledge previous work or suggesting alternative approaches. While it identifies a significant concern, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance differences between XDC and MMV, specifically why MMV outperforms XDC despite not exceeding its fully-supervised baseline. It also asks if MMV's better performance is due to a better backbone architecture. While the comment implies that the authors should provide an explanation for these observations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this question in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific performance comparisons between XDC and MMV, mentioning their respective fully-supervised baselines. It raises a question about why MMV outperforms XDC despite not exceeding its fully-supervised baseline, and it asks if MMV's better performance is due to a better backbone architecture. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which sections or figures these comparisons are discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point presents a claim that MMV outperforms XDC despite not exceeding its fully-supervised baseline, and it asks the authors to explain this observation. The comment suggests that MMV's better performance might be due to a better backbone architecture. However, the claim lacks specific evidence, detailed reasoning, or references to support why MMV should outperform XDC or how the backbone architecture might influence performance. This makes the claim somewhat verifiable, as it provides a logical question but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the performance differences between XDC and MMV, particularly why MMV outperforms XDC despite not exceeding its fully-supervised baseline. It also asks whether MMV's better performance is due to a better backbone architecture. This feedback is somewhat helpful as it prompts the authors to provide an explanation for the observed performance differences, which could lead to a deeper understanding of their model\\'s strengths and weaknesses. However, the comment could be more helpful if it suggested specific areas or methods for the authors to explore to address these questions. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a question about the performance differences between XDC and MMV, specifically why MMV outperforms XDC despite not exceeding its fully-supervised baseline. It also asks if MMV's better performance is due to a better backbone architecture. While the comment implies that the authors should provide an explanation for these observations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this question in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific performance comparisons between XDC and MMV, mentioning their respective fully-supervised baselines. It raises a question about why MMV outperforms XDC despite not exceeding its fully-supervised baseline and asks if MMV's better performance is due to a better backbone architecture. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which sections or figures these comparisons are discussed in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance differences between XDC and MMV, specifically why MMV outperforms XDC despite not exceeding its fully-supervised baseline. It also asks if MMV's better performance is due to a better backbone architecture. While the comment highlights a potential issue, it lacks specific reasoning or evidence to support the claim that MMV's performance is due to a better backbone architecture. The question is based on an observation but does not provide detailed analysis or references to substantiate the claim. This makes the comment somewhat verifiable, as it requires further elaboration or evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the performance differences between XDC and MMV, particularly why MMV outperforms XDC despite not exceeding its fully-supervised baseline. It also asks if"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer advises the authors to concentrate on a main idea or two and provide analyses on why they work, rather than detailing a well-engineered system with numerous functions and considerations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to achieve this focus or which aspects to prioritize. The authors are given a general idea of what needs to be addressed but are left without detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the writing style, describing it as too verbose and lacking focus, and suggests that it resembles an implementation paper rather than a theoretical or general advancement. However, it does not specify which sections or parts of the paper are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while the comment provides a general suggestion to focus on a main idea or two, it lacks specific guidance on how to achieve this. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer suggests that the authors should concentrate on a main idea or two and provide analyses on why they work, rather than detailing a well-engineered system. While the comment provides a general critique of the writing style and focus, it lacks specific examples or detailed reasoning to support the claim. The suggestion to focus on a main idea is somewhat vague, making it challenging for the authors to understand and address the critique effectively. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the writing style, describing it as too verbose and lacking focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer suggests that the authors should concentrate on a main idea or two and provide analyses on why they work, rather than detailing a well-engineered system with numerous functions and considerations. This feedback is clear and actionable, offering a specific direction for the authors to improve the clarity and focus of their writing. However, it could be more helpful if it provided examples or detailed guidance on how to achieve this focus. Overall, the comment is mostly helpful, as it effectively directs the authors toward a more concise and impactful presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks the provision of code and supplementary documentation, which would significantly enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for readers to understand and replicate the methodology. The action is clear and concrete, as it specifies exactly what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of code and supplementary documentation, which could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these resources would be beneficial. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the provision of code and documentation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility. However, the comment does not provide any specific examples or reasoning to support why these resources are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of code and supplementary documentation, which could enhance clarity and reproducibility. By highlighting this issue, the comment provides a clear and actionable suggestion for improvement. The authors are informed that providing these resources would be beneficial for readers to understand and replicate the methodology. However, the comment could be more helpful if it offered specific guidance on how to structure the supplementary materials or suggested ways to present the code. Overall, the feedback is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss and empirically compare ensembles and uncertainty estimation in the context of offline RL, specifically mentioning that random ensembles (REM) have been found to significantly outperform DQN/naive ensembling in the offline setting. The comment provides a clear and explicit action for the authors to take, which is to include this discussion and empirical comparison in their paper. The suggestion is concrete, as it specifies the type of ensembles and the context in which they should be discussed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and references a specific study on offline RL in the context of discrete Atari games. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests discussing and empirically comparing ensembles with random ensembles (REM) to DQN/naive ensembling, and it highlights the importance of incorporating value uncertainty in offline RL. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles and uncertainty estimation have been studied before in the context of offline RL, specifically mentioning a study on discrete Atari games where random ensembles (REM) outperform DQN/naive ensembling. This claim is supported by a reference to a specific study, which provides a clear and logical reasoning for the assertion. The comment also suggests that this finding should be discussed and empirically compared in the paper, offering a concrete example of how the authors could incorporate value uncertainty in offline RL. The inclusion of a specific reference and a clear rationale makes the claim mostly verifiable, as it provides a solid basis for the authors to consider the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion by referencing a previous study on ensembles and uncertainty estimation in the context of offline RL. It highlights that random ensembles (REM) have been found to significantly outperform DQN/naive ensembling in the offline setting. The comment advises the authors to discuss and empirically compare these methods in their paper, which is a clear and constructive suggestion for improving the draft. By including this discussion and comparison, the authors can enhance the relevance and depth of their work in the field of offline RL. The feedback is mostly helpful as it offers a concrete direction for improvement, although it could be further enhanced by providing more detailed guidance on how to implement the suggested comparison. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should discuss and empirically compare ensembles and uncertainty estimation, specifically mentioning that random ensembles (REM) have been found to significantly outperform DQN/naive ensembling in the offline setting. The comment provides a clear and explicit action for the authors to take, which is to include this discussion and empirical comparison in their paper. The suggestion is concrete, as it specifies the type of ensembles and the context in which they should be discussed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and references a specific study on offline RL in the context of discrete Atari games. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests discussing and empirically comparing ensembles with random ensembles (REM) to DQN/naive ensembling, and it highlights the importance of incorporating value uncertainty in offline RL. This provides clear guidance on what the authors should address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles and uncertainty estimation have been studied before in the context of offline RL, specifically mentioning a study on discrete Atari games where random ensembles (REM) outperform DQN/naive ensembling. This claim is supported by a reference to a specific study, which provides a clear and logical reasoning for the assertion. The comment also suggests that this finding should be discussed and empirically compared in the paper, offering a concrete example of how the authors could incorporate value uncertainty in offline RL. The inclusion of a specific reference and a clear rationale makes the claim mostly verifiable, as it provides a solid basis for the authors to consider the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors\\' statements in the introduction and the proposed methodology imply a lack of novelty in combining two methods. However, it does not provide specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the combination of two methods lacks novelty. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the reviewer\\'s assessment and address the concern effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer actionable suggestions for how the authors might address this perceived lack of novelty. Without concrete feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the scalability of their approach. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to enhance scalability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, specifically noting that it seems that a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this scalability issue might be addressed, the comment lacks full grounding. It is specific in identifying the scalability issue but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of why this is a concern, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. This is a relevant point that could impact the practicality and efficiency of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this scalability issue or improve the scalability of their approach. Without actionable feedback or detailed insights, the authors are left with a general concern but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for consideration but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. However, it does not provide any explicit or implicit suggestions for how the authors might address this scalability issue or improve their approach. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance the scalability of their method. As a result, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, noting that it seems that a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this scalability issue might be addressed, the comment lacks full grounding. It is specific in identifying the scalability issue but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of why this is a concern, the authors may find it challenging to understand and address the issue. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the concern.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the proposed approach, noting that it appears that a different model needs to be fine-tuned for each target language. This is a relevant point that could impact the practicality and efficiency of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this scalability issue or improve the scalability of their approach. Without actionable feedback or detailed insights, the authors are left with a general concern but no clear path"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details should be provided in Eq.20 for readers unfamiliar with bAbI or question answering. It specifically asks if \"valid words\" refer to possible answer words for the given story and question. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to add this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors know they need to clarify the details but may not be entirely sure of the exact changes required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that more details should be provided for readers unfamiliar with bAbI or question answering, and it asks a clarifying question about the meaning of \"valid words.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details should be provided in Eq.20 for readers unfamiliar with bAbI or question answering. It asks a clarifying question about the meaning of \"valid words,\" which implies that the explanation is lacking. However, the comment does not provide any specific reasoning or examples to support why this clarification is necessary or how it would benefit the readers. The lack of detailed justification or evidence makes the claim borderline verifiable, as it provides a suggestion but does not offer sufficient support or context for the authors to fully understand the need for additional details.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where additional details are needed for readers unfamiliar with bAbI or question answering. It provides a clear and actionable suggestion by asking for clarification on the meaning of \"valid words\" in the context of possible answer words for the given story and question. This feedback is valuable as it guides the authors to enhance the clarity and accessibility of their work for a broader audience. However, the comment could be more helpful if it offered specific examples or suggestions on how to present this information. Overall, the comment is mostly helpful, as it effectively directs the authors to improve the clarity of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. While this observation highlights a potential issue with the novelty of the work, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest how the authors might address this issue, such as by clarifying the novelty of their approach or providing additional context. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the interested-region-based adversarial attacking, referencing an earlier work by Yao et al. This provides a specific critique of the paper, indicating that the idea is not novel. However, the comment does not explicitly mention which part of the paper discusses this idea, making it weakly grounded. The authors can infer that it relates to the methodology or literature review sections, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the interested-region-based adversarial attacking is not novel, referencing an earlier work by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. This provides a specific reference to an external source, which supports the claim by offering a clear example of prior work. The inclusion of a specific reference makes the claim fully verifiable, as it provides a concrete basis for the assertion. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. This feedback is valuable as it highlights a potential issue with the novelty of the work, which is an important consideration for the authors. However, the comment does not provide specific guidance on how the authors might address this issue or suggest ways to differentiate their work from the existing literature. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. However, it does not provide any guidance or suggestions on how the authors might address this issue or differentiate their work from the existing literature. The comment lacks actionable steps or specific advice, leaving the authors without a clear path to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the interested-region-based adversarial attacking, referencing an earlier work by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. This provides a specific critique of the paper, indicating that the idea is not novel. However, the comment does not explicitly mention which part of the paper discusses this idea, making it weakly grounded. The authors can infer that it relates to the methodology or literature review sections, but this inference is not direct. The comment is specific in identifying the issue of novelty but lacks grounding in terms of where the authors should focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the interested-region-based adversarial attacking is not a novel idea, referencing an earlier work by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. This provides a specific reference to an external source, which supports the claim by offering a clear example of prior work. The inclusion of a specific reference makes the claim fully verifiable, as it provides a concrete basis for the assertion. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019. This"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors could enhance the significance of their contribution or what specific aspects of the methods could be improved. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not specify which components are being referred to or how they contribute to the overall contribution of the paper. Additionally, it does not mention any specific sections, figures, or tables where these components are discussed, making it difficult for the authors to identify the exact parts of the paper that need attention. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, suggesting that the contribution of the paper may not be significant. However, the comment lacks specific examples or references to these well-known components, making it difficult for the authors to understand which components are being referred to or how they contribute to the overall contribution. Without detailed justification or evidence, the claim remains vague and unverifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide specific examples or details about which components are considered well-known or how they contribute to the overall contribution. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors could enhance the significance of their contribution or what specific aspects of the methods could be improved. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not specify which components are being referred to or how they contribute to the overall contribution of the paper. Additionally, it lacks grounding as it does not mention any specific sections, figures, or tables where these components are discussed. This makes it difficult for the authors to identify the exact parts of the paper that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, suggesting that the contribution of the paper may not be significant. However, the comment lacks specific examples or references to these well-known components, making it difficult for the authors to understand which components are being referred to or how they contribute to the overall contribution. Without detailed justification or evidence, the claim remains vague and unverifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying which components are considered well-known or how they contribute to the overall contribution, the authors are left without guidance on how to enhance their work. This lack of detail and actionable advice makes the comment unhelpful for the authors, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the dataset, noting that the test set includes multi-turn data and that the publicly available history conversation can provide some assistance in answering the final question. This suggests that there is a risk of data leakage in the dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of data leakage. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the test set, mentioning that it includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a potential risk of data leakage in the dataset. However, the comment does not specify which part of the paper discusses the dataset or the risk of data leakage, making it weakly grounded. The comment is specific in identifying the issue of data leakage but lacks grounding in the paper\\'s structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question, suggesting a risk of data leakage in the dataset. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, noting that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a risk of data leakage in the dataset. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the risk of data leakage. While it points out a critical area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights an important concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the dataset, noting that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a risk of data leakage in the dataset. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or mitigate the risk of data leakage. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the dataset, noting that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a potential risk of data leakage in the dataset. However, the comment does not specify which part of the paper discusses the dataset or the risk of data leakage, making it weakly grounded. The comment is specific in identifying the issue of data leakage but lacks grounding in the paper\\'s structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question, suggesting a risk of data leakage in the dataset. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, noting that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a risk of data leakage in the dataset. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the risk of data leakage. While it points out an important area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete details on how to implement the suggested comparison. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. The comment is based on the claim that TTUR improves performance as stated in the DMD2 paper. However, the comment lacks specific details or references to the DMD2 paper or other relevant literature to substantiate the claim fully. While the suggestion is logical, the absence of explicit evidence or references makes the claim somewhat verifiable. The authors would need to seek out the referenced paper or other sources to fully understand and address the suggestion, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves performance as stated in the DMD2 paper. This feedback is clear and actionable, as it directs the authors to consider an additional comparison that could strengthen their results. However, the comment could be more helpful if it provided further guidance on how to conduct this comparison or why it is important. Overall, the comment is mostly helpful as it identifies a potential area for improvement and provides a specific suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete details on how to implement the suggested comparison. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. The comment is based on the claim that TTUR improves performance as stated in the DMD2 paper. However, the review does not provide specific details or references to the DMD2 paper or other relevant literature to substantiate the claim fully. The suggestion is logical, but the lack of explicit evidence or references makes the claim somewhat verifiable. The authors would need to seek out the referenced paper or other sources to fully understand and address the suggestion, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the theoretical results presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. It questions the merit of the theoretical result in light of this discrepancy. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their theoretical results. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft in response to this critique. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"line 109\" and \"Assumption 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of OOD actions and the assumption made in Assumption 3.1, which leads to a critique of the theoretical result presented in the paper. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the theoretical result presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. The reviewer highlights a discrepancy between the definition of OOD actions and the assumption made in the paper, which questions the validity of the theoretical result. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and clarify the theoretical basis to address the critique effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the theoretical results presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. It points out a discrepancy between the definition of OOD actions and the assumption made in the paper, questioning the validity of the theoretical result. While the comment identifies a significant issue, it lacks specific suggestions or guidance on how the authors might address this discrepancy or clarify their theoretical framework. The feedback is somewhat helpful as it highlights a potential weakness in the paper's theoretical foundation, but it could be more beneficial with additional guidance or suggestions for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a critical question about the theoretical results presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. It questions the validity of the theoretical result in light of this discrepancy. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their theoretical framework. Without actionable advice or specific steps for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"line 109\" and \"Assumption 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1, which leads to a critique of the theoretical result presented in the paper. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a critical question about the theoretical results presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. The reviewer highlights a discrepancy between the definition of OOD actions and the assumption made in the paper, which questions the validity of the theoretical result. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and clarify the theoretical basis to address the critique effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the theoretical results presented in the paper, specifically regarding the definition of out-of-distribution (OOD) actions and the assumption made in Assumption 3.1. It points out a discrepancy between the definition of OOD actions and the assumption made"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It implies that if the analysis does not enhance the paper\\'s value or clarity, it should be moved to the appendix. Additionally, it suggests that essential details in the appendix, such as dataset splitting justifications, should be integrated into the main text. While the comment provides a clear direction for improvement, it does not specify which parts of the analysis are considered shallow or how the integration of appendix details should be done. The actions are explicit but somewhat vague in execution, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the linguistic dataset analysis, noting that it lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it mentions that essential details in the appendix, such as dataset splitting justifications, should be integrated into the main text. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the dataset analysis and appendix sections. The comment is specific in detailing what needs to be addressed regarding the analysis and integration of details. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper provides a \"shallow linguistic dataset analysis without clear takeaways or conclusions,\" suggesting that the analysis may not enhance the paper\\'s value or clarity. The reviewer implies that if this is the case, the analysis should be moved to the appendix. However, the comment lacks specific examples or detailed reasoning to support why the analysis is considered shallow or how it could be improved. Without concrete evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it should be moved to the appendix. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, providing the authors with a concrete direction for improving the depth and impact of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to enhance the analysis or what specific details should be included in the main text. Overall, the comment is mostly helpful, as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric used in Table 1 and the absence of experimental details such as the backbone choice, learning rate, and optimization schedules. While the comment does not explicitly instruct the authors to provide these details, the actions are clear and concrete. The authors can infer that they need to clarify the metric in Table 1 and include the missing experimental details. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the specific issues related to the metric and experimental details, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of clarity in the metric and the absence of experimental details such as the backbone choice, learning rate, and optimization schedules. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence renders the claim unverifiable, as it does not provide sufficient support for the authors to address the issues effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric used in Table 1 and the absence of detailed experimental information such as the backbone choice, learning rate, and optimization schedules. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the transparency and reproducibility of their experimental setup. However, the comment could be more helpful if it suggested how to present this information or provided examples of how similar studies have addressed these issues. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not leverage the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y. It suggests that the paper should discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment identifies a specific area for improvement, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they need to discuss the impact of previous decisions on observable data, but without detailed guidance on how to implement this discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the advantage of POMDPs and how it is not leveraged in the paper. It suggests that the paper should discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the leverage of POMDPs and the discussion of observable data changes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y. The reviewer provides a specific example of how this advantage is not utilized, mentioning the lack of discussion on how previous decisions change the data observable to the decision-maker. This reasoning is somewhat verifiable as it highlights a specific area where the paper could improve, but it lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific weakness in the paper, noting that the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper should discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. This feedback is clear and actionable, as it directs the authors to address a critical gap in their work by incorporating a discussion on the impact of previous decisions on observable data. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this discussion. Overall, the comment is mostly helpful as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, noting that the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper should discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment highlights a clear area for improvement, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they need to include a discussion on observable data changes, but without detailed guidance, the feedback is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper regarding the leverage of the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y. It suggests that the paper should discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it points out a particular area for improvement, but without clear grounding, the authors may struggle to pinpoint where to make these changes. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which is their assumption that the decision-maker does not directly observe the target variable Y. The reviewer provides a specific example of how this advantage is not utilized, mentioning the lack of discussion on how previous decisions change the data observable to the decision-maker. This reasoning is somewhat verifiable as it highlights a specific area where the paper could improve, but it lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is rated as "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two issues: the small number of pretraining tokens_per_sample (256) and the use of a batch_size=64 for pretraining. It suggests that these settings may not be sufficient for a regular-size program. However, the comment does not provide specific guidance on how to address these issues, such as recommending a larger number of tokens or a different batch size. While the actions are clear, the lack of detailed instructions on how to implement them makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the pretraining tokens_per_sample and the batch_size used for pretraining. It explicitly mentions the number of tokens_per_sample (256) and the batch_size (64), providing clear guidance on what needs to be addressed. This makes the comment fully grounded, as the authors can accurately identify the parts of the paper being discussed. The comment is also specific, as it clearly specifies the issues with the current settings and suggests that they may not be sufficient for a regular-size program. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of pretraining tokens_per_sample (256) is insufficient for a regular-size program and questions the use of a batch_size=64 for pretraining. However, the comment lacks specific reasoning or evidence to support these claims. It does not provide examples or references to justify why these settings might be inadequate or how they could be improved. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand and address the critique effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the pretraining process, noting that the tokens_per_sample (256) is insufficient for a regular-size program and questioning the use of a batch_size=64. This feedback is clear and actionable, as it highlights a potential weakness in the experimental setup that could impact the effectiveness of the pretraining. By pointing out these specific concerns, the comment provides the authors with a concrete direction for improvement. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative settings that might be more appropriate. Overall, the comment is mostly helpful as it effectively directs the authors\\' attention to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the need for additional ablation experiments to better understand the proposed method. It specifically mentions the possibility of replacing the clustering algorithm with other approaches, such as K-Means, and questions the model\\'s performance when applied to different-sized descendant models. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the lack of ablation experiments in the paper, specifically mentioning the need for additional experiments to understand the proposed method. It provides specific examples, such as replacing the clustering algorithm with other approaches like K-Means and questioning the model\\'s performance when applied to different-sized descendant models. However, the comment does not explicitly mention which part of the paper should include these experiments, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the ablation experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples, such as questioning the use of the clustering algorithm and its performance when applied to different-sized descendant models. This detailed reasoning and specific examples make the claim mostly verifiable, as it offers a clear direction for the authors to address the lack of ablation experiments. However, the comment could be strengthened by referencing specific studies or methodologies that have successfully used ablation experiments in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of ablation experiments to help readers understand the proposed method. It provides specific examples, such as questioning the use of the clustering algorithm and its performance when applied to different-sized descendant models. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their work by conducting additional experiments. However, the comment could be more helpful if it suggested specific ablation experiments or methodologies to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include a comparison of their proposed method with the Talking Heads Transformer as the de-facto baseline for all tasks, rather than just comparing against the vanilla transformer. This feedback provides a clear and direct action for the authors to take, specifying that they should conduct additional comparisons to better assess the benefits of their proposed interaction modules and many-to-many formulation. The comment is specific and actionable, giving the authors a concrete task to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"many to many formulation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the comparison with the Talking Heads Transformer should be expanded to all tasks, rather than just those in Table 1, and questions the benefit of the proposed interaction modules compared to a simple linear transform. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks, and it questions the comparison against the vanilla transformer, implying that the proposed interaction modules and many-to-many formulation may not offer significant benefits. The comment provides a logical reasoning by suggesting that a comparison with the Talking Heads Transformer would provide a clearer understanding of the benefits of the proposed method. However, it lacks specific examples or references to support the claim that the Talking Heads Transformer is the most relevant baseline, making the claim somewhat verifiable. The authors would need to further explore and substantiate this suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the paper that requires further attention: the need for a more comprehensive comparison with the Talking Heads Transformer, which the reviewer considers the de-facto baseline for all tasks. The comment highlights that while there is a comparison in Table 1, it suggests that this comparison should be expanded to all tasks presented in the paper. This feedback is actionable as it provides a clear direction for the authors to enhance their analysis by including a more thorough comparison with the Talking Heads Transformer. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this comparison or discussed the potential implications of such an analysis. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should check and benchmark speaker identification on the HI-MIA dataset, which is recorded in a real-time environment with noise and a microphone array. This feedback provides a clear and explicit action for the authors to take, which is to evaluate their scenario on the HI-MIA dataset. The suggestion is concrete, as it specifies the exact dataset and task to be benchmarked. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests checking and benchmarking speaker identification on the HI-MIA dataset, which is recorded in a real-time environment with noise and a microphone array. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular dataset and task for benchmarking, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the scenario described in the paper should be benchmarked on the HI-MIA dataset, which is recorded in a real-time environment with noise and a microphone array. The comment provides a specific dataset and context for benchmarking, which supports the claim. However, it lacks detailed reasoning or references to explain why this dataset is particularly relevant or how it would enhance the evaluation. While the suggestion is based on a specific dataset, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should check and benchmark their scenario on the HI-MIA dataset, which is recorded in a real-time environment with noise and a microphone array. This feedback is clear and actionable, as it provides a specific dataset and task for the authors to consider, which could enhance the validity and applicability of their work. By addressing this suggestion, the authors could improve the robustness of their findings and potentially expand the scope of their evaluation. However, the comment could be more helpful if it included additional context or reasoning about why this dataset is relevant or how it might impact the results. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for revising the framing of the paper. It suggests that the introduction should focus on the loss function and its applications rather than breast cancer specifically. The reviewer provides a clear rationale for this suggestion, explaining that the paper\\'s primary contribution is the loss function, which can be applied to any semantic segmentation network and extended to solve other problems. This feedback is explicit and provides concrete guidance on how to reframe the introduction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the framing of the paper, suggesting that the focus should shift from breast cancer to the loss function and its applications. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper\\'s framing should shift from breast cancer to the loss function and its applications. The reviewer provides a logical reasoning by explaining that the paper\\'s primary contribution is the loss function, which can be applied to any semantic segmentation network and extended to solve other problems. This reasoning is supported by the evaluation of the loss function over multiple datasets and its application to various problems in semantic segmentation. However, the comment could be strengthened by providing specific examples or references to similar works that have successfully applied loss functions in different contexts. As it stands, the claim is mostly verifiable, as it offers a clear rationale but lacks detailed evidence or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for revising the framing of the paper. It points out that while the introduction focuses on breast cancer, the paper\\'s primary contribution is a loss function applicable to any semantic segmentation network. The reviewer suggests an alternative framing that emphasizes the loss function and its broader applications, which could better align with the paper\\'s actual focus. This feedback is clear and actionable, offering a specific direction for the authors to improve the clarity and relevance of their introduction. However, the comment could be more helpful if it included specific examples or guidance on how to reframe the introduction to better reflect the paper\\'s contributions. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for enhancing the paper\\'s clarity and focus.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This is a clear and direct action for the authors to take, providing them with a specific task to perform. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 3.1 or 3.2,\" providing full grounding by directing the authors to the specific sections of the paper where the inclusion of agreement statistics should be addressed. It is also specific because it clearly specifies what needs to be included\u2014agreement statistics for the corpus. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for agreement statistics to be included in sections 3.1 or 3.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for factual information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for additional information, specifically asking the authors to include agreement statistics for the corpus in sections 3.1 or 3.2. While this feedback identifies a potential gap in the paper, it lacks depth and does not provide any guidance or suggestions on why this information is important or how it might impact the paper. The comment is vague and does not offer actionable advice, making it barely helpful for the authors. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also mentions that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but it is inspired by goal-conditioned RL approaches. The comment does not provide specific guidance or suggestions for improvement, such as how the authors could enhance the novelty or differentiate their work further. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to address the points raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically focusing on the use of instruction aggregation and LLMs, as well as the novelty of cross-trajectory chaining. It mentions that many of the techniques used in cross-trajectory chaining are inspired by goal-conditioned RL approaches, such as offline goal chaining. However, the comment does not specify which part of the paper these points are discussed in, making it weakly grounded. The comment is specific in detailing the novelty and inspiration of the techniques, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also mentions that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but it is inspired by goal-conditioned RL approaches. The comment provides some reasoning by referencing goal-conditioned RL approaches and offline goal chaining, which helps to support the claim. However, the comment could be strengthened by providing more detailed examples or references to specific techniques or studies that are being compared. As it stands, the claim is mostly verifiable, as it provides a logical basis for the critique but lacks comprehensive evidence or detailed comparisons. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but it is inspired by goal-conditioned RL approaches. The comment provides some insight into the novelty and inspiration of the techniques used, which could help the authors understand the strengths and weaknesses of their approach. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or differentiate their work further. While it offers some insight, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also mentions that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but it is inspired by goal-conditioned RL approaches. The comment does not provide specific guidance or suggestions for improvement, such as how the authors could enhance the novelty or differentiate their work further. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically focusing on the use of instruction aggregation and LLMs, as well as the novelty of cross-trajectory chaining. It acknowledges that many of the techniques used in cross-trajectory chaining are inspired by goal-conditioned RL approaches, such as offline goal chaining. However, the comment does not specify which part of the paper these points are discussed in, making it weakly grounded. The comment is somewhat specific in detailing the novelty and inspiration of the techniques, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also mentions that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but it is inspired by goal-conditioned RL approaches. The comment provides some reasoning by referencing goal-conditioned RL approaches and offline goal chaining, which helps to support the claim. However, the comment could be strengthened by providing more detailed examples or references to specific techniques or studies that are being compared. As it stands, the claim is mostly verifiable, as it"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. While the comment implies that the authors should provide additional discussion, it does not explicitly instruct them to do so or provide specific guidance on what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to sections discussing the attention module or its implementation, but this inference is not direct. The comment is specific in its request for more discussion on the identity of the attention map and its impact, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification and an opinion suggesting that more discussion should be conducted. It does not contain any subjective claims, opinions, or suggestions that require verification. The statement is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic, implying that the current explanation or justification is insufficient. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the identity of the attention map should be discussed. This limits the comment\\'s usefulness to the authors, as it provides only a vague direction for improvement. Therefore, the comment is somewhat helpful, as it points out an area for further exploration but does not offer detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to explain why they are considering decoder-only transformers. This is a direct request for clarification, providing a clear action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is an explanation of why the authors are considering decoder-only transformers. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the choice of using decoder-only transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for clarification regarding the choice of using decoder-only transformers. It does not provide any critique or suggestions for improvement, nor does it offer any context or reasoning behind the request. The comment is vague and lacks actionable feedback, leaving the authors without guidance on how to address the issue. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the qualitative analysis lacks important details, specifically the proportion of each error category. It suggests that the contribution could be strengthened by including more insightful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. While the comment implies that the authors should add more detailed analysis and insights, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors know they need to enhance the analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"qualitative analysis\" and the \"proportion of each error category,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis, namely the inclusion of more detailed insights and speculations about the underlying causes of the observed issues and potential mitigation strategies. The reference to \"[Turpin et al.] Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. arXiv-23\" provides an external source for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the qualitative analysis is lacking important details, specifically the proportion of each error category. It suggests that the contribution could be strengthened by including more insights into the underlying causes of the observed issues and potential mitigation strategies. The comment references an external source, \"[Turpin et al.] Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. arXiv-23,\" which could provide additional context or examples for the authors to consider. However, the comment does not explicitly cite specific details from the referenced work or provide detailed reasoning on how the current analysis could be improved. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive support with specific examples or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the qualitative analysis, noting the lack of detailed information on the proportion of each error category. It suggests that the contribution could be strengthened by including more insightful thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment provides a clear direction for enhancing the analysis by referencing an external source, \"[Turpin et al.] Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting. arXiv-23,\" which could guide the authors in developing a more comprehensive analysis. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to incorporate these insights. Overall, the feedback is mostly helpful as it highlights a critical area for improvement and provides a starting point for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should empirically validate the suitability of Reinforcement Learning, RNNs, and Wasserstein GANs for their proposed approach by applying these methods with data filled by simple methods. This is an explicit suggestion with concrete details on how to implement the validation, providing clear guidance on what the authors need to do to improve their draft. The comment is highly actionable as it offers a specific action and detailed steps for the authors to follow.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' mention of \"The typical MTTP baselines like Reinforcement Learning, RNNs, Wasserstein GANs require a significant amount of data to train a network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a specific action\u2014empirically validating the suitability of these methods by applying them with data filled by simple methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the applicability of certain baseline methods, such as Reinforcement Learning, RNNs, and Wasserstein GANs, due to their data requirements. The reviewer suggests that these methods are not suitable for the proposed approach and proposes an empirical validation using a Markov chain approach. However, the comment lacks specific examples or references to substantiate why these methods are unsuitable or how the proposed validation would demonstrate this. This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improving the paper by empirically validating the suitability of certain baseline methods, such as Reinforcement Learning, RNNs, and Wasserstein GANs, for the proposed approach. It suggests applying these methods with data filled by simple methods to demonstrate their unsuitability for incomplete, small data. This feedback is clear and actionable, offering a concrete way for the authors to test and validate their claims. However, the comment could be more helpful if it included additional guidance on how to implement this validation or discussed the potential implications of the results. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the authors should empirically validate the suitability of certain baseline methods, such as Reinforcement Learning, RNNs, and Wasserstein GANs, for their proposed approach. It provides a specific suggestion to apply these methods with data filled by simple methods. This feedback is explicit and provides concrete guidance on how to conduct the validation, making it highly actionable. The authors know exactly what steps to take to improve their draft based on this comment.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly references the authors\\' mention of \"The typical MTTP baselines like Reinforcement Learning, RNNs, Wasserstein GANs require a significant amount of data to train a network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a specific action\u2014empirically validating the suitability of these methods by applying them with data filled by simple methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the applicability of certain baseline methods, such as Reinforcement Learning, RNNs, and Wasserstein GANs, due to their data requirements. It suggests that these methods are not suitable for the proposed approach and proposes an empirical validation using a Markov chain approach. However, the comment lacks specific examples or references to substantiate why these methods are unsuitable or how the proposed validation would demonstrate this. This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improving the paper by empirically validating the suitability of certain baseline methods, such as Reinforcement Learning, RNNs, and Wasserstein GANs, for the proposed approach. It suggests applying these methods with data filled by simple methods to demonstrate their unsuitability for incomplete, small data. This feedback is clear and actionable, offering a concrete"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of baseline comparison in the paper, specifically mentioning that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompt. The reviewer implies that the authors should include a comparison with the G-EVAL method using the simplest prompt for these LLMs. While the action is not explicitly stated, it is clear and concrete, as the authors can infer that they need to conduct this comparison to strengthen their work. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and the \"GPT-3.5 and GPT-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of baseline comparison using the simplest prompt for these LLMs. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically mentioning that the G-EVAL method is based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompt. This claim is somewhat verifiable as it highlights a potential gap in the evaluation process. However, it lacks specific examples or references to support the assertion that such a comparison is necessary or how it would enhance the paper. The comment provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of baseline comparison for the G-EVAL method. It points out that the method is based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompt, which could provide a benchmark for comparison. This feedback is clear and actionable, as it suggests a specific area for improvement that would enhance the paper\\'s rigor and comprehensiveness. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their approach. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the process of updating weights in multi-agent environments, specifically mentioning the computation of expected rewards or NE gaps for different perturbations. It raises a concern about the requirement for full knowledge of game payoffs and policies of other agents, which is relevant to the methodology section of the paper. However, the comment does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in detailing the issue with the requirement for full knowledge and the computation of NE gaps. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. The comment provides a logical reasoning by explaining that this requirement is unlike the base policies, which only update based on observed rewards. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires additional information for a more robust justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. It highlights a potential limitation of the approach, noting that this requirement is unlike the base policies, which only update based on observed rewards. The comment also points out that computing NE gaps requires knowledge of the policies of other agents. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it prompts the authors to consider the implications of their assumptions and potentially explore alternative methods, but it lacks actionable advice for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their approach. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is somewhat specific in detailing the requirement for full knowledge and the computation of NE gaps, but it lacks detailed guidance on how to address or mitigate this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. The comment provides a logical reasoning by explaining that this requirement is unlike the base policies, which only update based on observed rewards. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. While it highlights a potential limitation, the absence of detailed justification makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the methodology, specifically the requirement for full knowledge of game payoffs and policies of other agents to compute expected rewards or NE gaps for updating weights in multi-agent environments. This is a relevant observation that could impact the applicability and effectiveness of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it highlights an important area for"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any guidance or suggestions on how this comparison should be improved or expanded. There is no explicit or implicit action for the authors to take, nor are there any concrete details on how to enhance the comparison. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a comparison with \"DiffUCO,\" but it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment does not provide specific details on what aspects of the comparison are lacking or how it could be improved, making it not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of this comparison or how it could be improved. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper primarily compares the proposed methods with DiffUCO. While it identifies a potential limitation in the scope of the comparison, it does not provide any specific suggestions or guidance on how the authors might broaden or deepen their comparisons. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, the superficiality of the exposition, and the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies areas that need improvement, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and proofs, but without concrete suggestions, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically focusing on the value decomposition and the claim of equivalence between the local policy product and the globally optimal policy. However, it does not specify which sections or parts of the paper are repetitive or superficial, making it difficult for the authors to pinpoint the exact areas needing improvement. While the comment provides some guidance on what is lacking\u2014explicit definitions of local subtasks and their policies, as well as a complete proof of equivalence\u2014it does not offer specific examples or detailed feedback. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is repetitive and superficial in its exposition of the value decomposition method, specifically regarding the equivalence of the local policy product to the globally optimal policy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide explicit evidence or references to substantiate the assertion that the paper is superficial or lacks depth. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity and depth in the exposition of the value decomposition method. It points out that the paper claims to prove the equivalence of the local policy product to the globally optimal policy but fails to provide a complete proof or detailed explanation of the decomposition method. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to enhance the clarity and rigor of their theoretical contributions. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of what a more detailed exposition might look like. Overall, the comment is mostly helpful as it directs the authors to a significant area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a lack of clarity and depth in the paper regarding the value decomposition method, specifically the equivalence of the local policy product to the globally optimal policy. It points out that the paper is repetitive and superficial in its exposition, lacking explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them. However, the comment does not provide specific guidance or suggestions on how to address these issues, such as recommending ways to improve the exposition or providing a more detailed proof. The lack of actionable advice makes it difficult for the authors to know how to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the lack of clarity and depth in the exposition of the value decomposition method, particularly regarding the equivalence of the local policy product to the globally optimal policy. However, it does not specify which sections or parts of the paper are repetitive or superficial, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment lacks specificity in detailing what needs to be addressed or improved, such as the explicit definition of local subtasks and their corresponding policies, or the relationship between them. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is repetitive and superficial in its exposition of the value decomposition method, specifically regarding the equivalence of the local policy product to the globally optimal policy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide explicit evidence or references to substantiate the assertion that the paper is superficial or lacks depth. This makes it difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity and depth in the exposition of the value decomposition method. It points out that the paper claims to"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the performance curve of each algorithm during training is missing. This provides a clear and direct action for the authors to take, which is to include the performance curve in their draft. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out the absence of performance curves for each algorithm during training. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where performance curves are typically discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing element, which is the performance curve, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"the performance curve of each algorithm during the training is missing.\" However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s conclusions. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the performance curve of each algorithm during training is missing. This is a clear and actionable piece of feedback, as it highlights a gap in the presentation of results that the authors can address to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to incorporate these performance curves or discussed their potential impact on the paper. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing attention. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method. There is no guidance on potential modifications, alternative approaches, or optimizations that could be considered. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Gaussian kernel-based graph construction method\" and refers to \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity. This provides clear guidance on what aspect of the method is problematic. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This claim is somewhat verifiable as it provides a logical reasoning based on the time complexity of computing the adjacency matrix, which is O(N^2). However, the comment lacks specific examples or references to substantiate the claim further, such as comparisons with other methods or detailed explanations of the computational overhead. This makes it somewhat challenging for the authors to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This feedback is valuable as it highlights a potential bottleneck in the method that the authors should address. However, the comment does not provide specific suggestions or alternative approaches to mitigate this issue, such as proposing more efficient algorithms or optimizations. While it points out a critical weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a limitation of the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method. There is no guidance on potential modifications, alternative approaches, or optimizations that could be considered. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Gaussian kernel-based graph construction method\" and refers to \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity. This provides clear guidance on what aspect of the method is problematic. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This claim is somewhat verifiable as it provides a logical reasoning based on the time complexity of computing the adjacency matrix, which is O(N^2). However, the comment lacks specific examples or references to substantiate the claim further, such as comparisons with other methods or detailed explanations of the computational overhead. This makes it somewhat challenging for the authors to fully understand and address the issue without additional context or evidence. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This feedback is valuable as it highlights a potential bottleneck in the method that the authors should address. However, the comment does not provide specific suggestions or alternative approaches to mitigate this issue, such as proposing more efficient algorithms or optimizations. While it points out a critical weakness, the lack of actionable guidance limits its helpfulness. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) in Eq. (5) over case (3), which is found to archive the best performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address it. The authors can infer that they might need to reconsider their choice of reweighting case or provide a more compelling explanation, but the lack of concrete suggestions makes the action implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the choice of loss reweighting case (1) in Eq. (5) and the observed best performance in case (3). The comment further questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) over case (3), which is found to archive the best performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. While the comment highlights a potential inconsistency, it does not provide specific reasoning or evidence to support the claim that the authors\\' explanation is flawed. The lack of detailed justification or references makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some insight but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy in the paper regarding the choice of loss reweighting case (1) over case (3), which is found to archive the best performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of reweighting case and provide a more compelling explanation for their decision. However, the comment could be more helpful if it offered suggestions on how to address the discrepancy or improve the explanation. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment critiques the paper's claims and results, stating that the main results are general and do not leverage the unique characteristics of tabular data or LLMs. However, it does not provide specific guidance on how the authors could address this issue or improve their work. The comment lacks actionable details, such as suggesting ways to incorporate unique characteristics or providing examples of how to make the results more relevant to the paper's scope. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the paper's claims regarding the study of model multiplicity in machine learning and the unique challenges of fine-tuning multiplicity in Tabular LLMs. It points out that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, suggesting that the main result is irrelevant to the paper's scope. However, the comment does not specify which part of the paper these claims are made in, nor does it provide detailed guidance on how to address the issue. This makes it difficult for the authors to pinpoint the exact sections that need revision or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point critiques the paper's claims by stating that while model multiplicity has been studied in various contexts, the unique challenges of fine-tuning multiplicity in Tabular LLMs are relatively unexplored. The reviewer argues that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, making them irrelevant to the paper's scope. However, the comment lacks specific examples or references to support the claim that the results are general or irrelevant. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the paper's claims by questioning the relevance of the main results to the paper's scope. It points out that while the paper claims to address the unique challenges of fine-tuning multiplicity in Tabular LLMs, the results are general and do not leverage the unique characteristics of tabular data or LLMs. This feedback is somewhat helpful as it identifies a potential gap in the paper's contribution and highlights the need for more specific or relevant results. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their work. To be more helpful, the comment could provide specific examples or directions for enhancing the relevance of the results to the paper's scope. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the paper's claims by questioning the relevance of the main results to the paper's scope. It points out that the results are general and do not leverage the unique characteristics of tabular data or LLMs. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or improve their work. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the paper's claims regarding the study of model multiplicity in machine learning and the unique challenges of fine-tuning multiplicity in Tabular LLMs. It points out that the main results are general and do not leverage the unique characteristics of tabular data or LLMs, suggesting that the main result is irrelevant to the paper's scope. However, the comment does not specify which part of the paper these claims are made in, nor does it provide detailed guidance on how to address the issue. This lack of specificity and grounding makes it difficult for the authors to identify and improve the relevant sections of their draft. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point critiques the paper's claims by questioning the relevance of the main results to the paper's scope. It argues that while the paper claims to address the unique challenges of fine-tuning multiplicity in Tabular LLMs, the results are general and do not leverage the unique characteristics of tabular data or LLMs. However, the comment lacks specific examples, references, or detailed reasoning to support this critique. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered unverifiable.\", 'verifiability_label"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the paper. It suggests that the summation should be double, with one over multi-layered garments and the other over vertices of the garment. It also asks for clarification on the function f(\u00b7) in the line just above eq. 3. Additionally, it mentions existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body and asks for details on simulating multiple layers. While the comment provides specific questions and observations, it does not offer explicit actions or concrete guidance on how the authors should address these points. The authors can infer that they need to clarify the summation and provide details on simulating multiple layers, but the lack of explicit instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line just above eq. 3\" and \"Figure 12,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the summation, the function f(\u00b7), and the comparison with existing works like TailorNet and Patel et al. 2021. The comment provides clear guidance on what needs to be clarified or addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the summation and the function f(\u00b7) in the paper. It also mentions existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body. While the comment highlights potential areas for clarification and comparison, it does not provide specific reasoning or evidence to support the claim that the summation should be double or that simulating multiple layers is more challenging. The references to existing works are relevant but do not directly address the specific issues raised in the comment. Therefore, the claim is somewhat verifiable, as it provides some context but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several points that could help the authors improve their draft. It questions the summation in the paper, suggesting that it should be a double summation, and asks for clarification on the function f(\u00b7) in the line just above eq. 3. Additionally, it references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body, suggesting that the authors could provide details on simulating multiple layers. While the comment identifies areas for clarification and comparison, it lacks specific guidance or suggestions on how the authors might address these points. The feedback is somewhat helpful as it points out potential weaknesses and areas for improvement, but it could be more actionable with additional detail or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises several questions and points out potential areas for clarification in the paper. It suggests that the summation should be double, with one over multi-layered garments and the other over vertices of the garment. It also asks for clarification on the function f(\u00b7) in the line just above eq. 3. Additionally, it references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body and asks for details on simulating multiple layers. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete guidance on how the authors should address these points. The authors can infer that they need to clarify the summation and provide details on simulating multiple layers, but the lack of explicit actions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line just above eq. 3\" and \"Figure 12,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions and points for clarification, such as the summation, the function f(\u00b7), and the comparison with existing works like TailorNet and Patel et al. 2021. The comment provides clear guidance on what needs to be clarified or addressed, making it fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the summation and the function f(\u00b7) in the paper, suggesting that it should be a double summation. It also references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body."}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as \\\\gamma(\\\\frac{B}{\\\\hat{d}_{\\\\min}^k})^{\\\\frac{1}{2}} and how the proposed GRADE reduces this supremum. While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors can infer that they need to clarify the theoretical analysis, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the theoretical analysis, particularly why the supremum is defined as \\\\gamma(\\\\frac{B}{\\\\hat{d}_{\\\\min}^k})^{\\\\frac{1}{2}} and how the proposed GRADE reduces this supremum. This provides clear guidance on what aspect of the theoretical analysis needs clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as \\\\gamma(\\\\frac{B}{\\\\hat{d}_{\\\\min}^k})^{\\\\frac{1}{2}} and how the proposed GRADE reduces this supremum. This is a request for clarification rather than a claim or opinion requiring verification. It does not express an opinion or suggest a change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the theoretical analysis, questioning the definition of the supremum and its relevance to proving that the proposed GRADE reduces it. This feedback is clear and actionable, as it points out a potential weakness in the theoretical framework that the authors need to address. By addressing this issue, the authors can improve the clarity and rigor of their theoretical analysis. However, the comment could be more helpful if it provided suggestions on how to clarify the theoretical analysis or offered examples of how to prove the reduction of the supremum. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on such dialogues. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to perform the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on such dialogues. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the results or analysis section, but this inference is not direct. The comment is specific in its request for analysis on lengthy dialogues, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether performance will drop on such dialogues. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on such dialogues. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for additional analysis on lengthy dialogues. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. While it offers a direction for further exploration, it could be more helpful with additional context or suggestions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, to enhance the evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities, which could guide the authors in expanding their dataset to include these additional modalities. While the comment does not explicitly instruct the authors to include these modalities, the references provide concrete examples of how to address the issue. The action is implicit but concrete, as the authors can infer that they need to expand their dataset and consider the references for guidance. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including more natural modalities, such as audio and visual, in the datasets to enhance evaluation. It references specific works that discuss modality bias and learning rates between modalities, providing a basis for the suggestion. However, the comment does not specify which part of the paper should include these additional modalities, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the datasets used in the study should include more natural modalities, such as audio and visual, to enhance evaluation. The comment supports this claim by referencing specific works that discuss modality bias and learning rates between modalities. These references provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific recommendations on how to incorporate these modalities into the datasets. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a limitation in the datasets used in the study, noting that they only contain visual modality data. It suggests that including more natural modalities, such as audio and visual, would enhance the evaluation. The comment provides references to existing works that discuss modality bias and learning rates between modalities, which could guide the authors in expanding their dataset to include these additional modalities. This feedback is clear and actionable, offering a concrete suggestion for improvement that could significantly enhance the robustness and applicability of the study. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}{'actionability_rationale': \"The review comment suggests including more natural modalities, such as audio and visual, in the datasets to enhance evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities, which could guide the authors in expanding their dataset. However, the comment does not explicitly instruct the authors to include these modalities or provide specific guidance on how to incorporate them. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to expand their dataset but may not be entirely sure of the exact steps to take.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests including more natural modalities, such as audio and visual, in the datasets to enhance evaluation. It references specific works that discuss modality bias and learning rates between modalities, providing a basis for the suggestion. However, the comment does not specify which part of the paper should include these additional modalities, making it weakly grounded. The references to existing works provide some specificity in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may struggle to implement the suggestion effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the datasets used in the study should include more natural modalities, such as audio and visual, to enhance evaluation. It supports this claim by referencing specific works that discuss modality bias and learning rates between modalities. These references provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific recommendations on how to incorporate these modalities into the datasets. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a limitation in the datasets used in the study, noting that they only contain visual modality data. It suggests that including more natural modalities, such as audio and visual, would enhance the evaluation. The comment provides references to existing works that discuss modality bias and learning rates between modalities, which could guide the authors in expanding their dataset to include these"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. While the comment highlights a potential oversight, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include a discussion of these related works, but the comment lacks concrete instructions on how to integrate this information into their paper. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper should discuss these related works, making it weakly grounded. The comment is specific in identifying the issue of not discussing these related works, but it lacks detailed guidance on how to address this omission. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not provide specific examples or references to these works, making it difficult for the authors to verify the claim. The lack of detailed justification or examples results in the comment being classified as \"1: Unverifiable,\" as it does not offer sufficient evidence or reasoning to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper, noting that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it points out that these related works are not discussed in the paper. This feedback is somewhat helpful as it highlights an area where the paper could be improved by including a discussion of these related works. However, the comment lacks specific guidance on how the authors might integrate this information into their paper or why it is important to do so. To be more helpful, the comment could suggest how the authors might incorporate this discussion or explain its relevance to their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. While the comment identifies a potential oversight, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include a discussion of these related works, but the comment lacks concrete instructions on how to integrate this information into their paper. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper should discuss these related works, making it weakly grounded. The comment is specific in identifying the issue of not discussing these related works, but it lacks detailed guidance on how to address this omission. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not provide specific examples or references to these works, making it difficult for the authors to verify the claim. The lack of detailed justification or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not offer sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper, noting that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it points out that these related works are not discussed in the paper. This feedback highlights an area where the paper could be improved by including a discussion of these related works. While the comment effectively points out the omission, it lacks specific guidance or suggestions on how the authors might integrate this discussion into their paper. To be more helpful, the comment could provide examples of how to incorporate these related works or explain their relevance to the paper. Despite this, the comment is somewhat helpful as it directs the authors to an important aspect of their work that"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper lacks depth in exploring how the observed phenomena could be used to design better resilient systems. It provides a specific example of a linear architecture and asks whether a proposed defense method could be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. While the comment implies that the authors should consider adding such insights, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s discussion of the observed phenomenon, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by questioning how the observations could be used to design better resilient systems and suggesting a potential adaptation of a proposed defense method to resemble a hierarchical system. This provides clear guidance on what the authors could explore to deepen their research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the depth of the paper's exploration into the observed phenomenon, suggesting that it does not provide insights on how to use these observations to design better resilient systems. The reviewer proposes a specific example of a linear architecture and asks whether a proposed defense method could be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observations. This comment is mostly verifiable as it provides a logical reasoning and a specific example to support the claim, but it lacks detailed references or further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's exploration of the observed phenomenon, noting that it does not delve into how these observations could be used to design better resilient systems. It provides a specific suggestion by proposing the adaptation of a proposed defense method to resemble a hierarchical system, which could demonstrate the usefulness and significance of the observed results. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work by exploring the practical implications of their findings. However, the comment could be more helpful if it included additional suggestions or examples of how to implement this adaptation. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a limitation in the paper's exploration of the observed phenomenon, suggesting that it does not provide insights on how to use these observations to design better resilient systems. It offers a specific example of a linear architecture and asks whether a proposed defense method could be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making the comment mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s discussion of the observed phenomenon, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by questioning how the observations could be used to design better resilient systems and suggesting a potential adaptation of a proposed defense method to resemble a hierarchical system. This provides clear guidance on what the authors could explore to deepen their research. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the depth of the paper's exploration into the observed phenomenon, suggesting that it does not provide insights on how to use these observations to design better resilient systems. The reviewer proposes a specific example of a linear architecture and asks whether a proposed defense method could be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. This comment is mostly verifiable as it provides a logical reasoning and a specific example to support the claim, but it lacks detailed references or further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's exploration of the observed phenomenon, noting that it does not provide insights on how to use these observations to design better resilient systems. It suggests a specific approach by proposing the adaptation of a proposed defense method to resemble a hierarchical system, which could demonstrate the usefulness and significance of the observed results. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work by exploring the practical implications of their findings. However, the comment could be"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but it notes that no rigorous definitions are provided. While the comment identifies a gap in the paper, it does not explicitly instruct the authors on what specific definitions should be included or how to address this issue. The action is implicit, as the authors can infer that they need to provide definitions, but it remains vague because it lacks concrete guidance on how to implement this change. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of rigorous definitions for evaluating the reliability or trust of LLMs. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for definitions but does not provide detailed guidance on what these definitions should cover or how they should be integrated into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but no rigorous definitions are provided. This statement is somewhat verifiable as it highlights a gap in the paper regarding the lack of definitions. However, it lacks specific examples or references to support the claim, such as what rigorous definitions should be included or how they would enhance the evaluation. The comment provides a general observation but does not offer detailed reasoning or evidence to fully substantiate the claim, leaving the authors with a vague understanding of the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of rigorous definitions for evaluating the reliability or trust of LLMs. This is an important observation that could significantly impact the clarity and validity of the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular definitions or frameworks to consider. While it highlights a significant area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of rigorous definitions for evaluating the reliability or trust of LLMs, but it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete details on what definitions should be included or how to improve the evaluation process. As a result, the authors are left without clear direction on how to enhance their draft. The feedback is vague and lacks actionable steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of rigorous definitions for evaluating the reliability or trust of LLMs. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the need for definitions but lacks detailed guidance on how to address this issue or what specific definitions should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but no rigorous definitions are provided. This statement is somewhat verifiable as it highlights a gap in the paper regarding the lack of definitions. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the issue or address it effectively. The comment provides a general observation but does not offer detailed reasoning or evidence to substantiate the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of rigorous definitions for evaluating the reliability or trust of LLMs. This is an important observation that could significantly impact the clarity and validity of the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular definitions or frameworks to consider. While it highlights a significant area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of rigorous definitions for evaluating the reliability or trust of LLMs, but it does not provide specific guidance or suggestions on how the"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment highlights areas of interest and potential concerns, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors can infer that they need to provide explanations or evidence regarding these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the necessity of masked self-attention and the reasons behind the choice of ProbSparse. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the necessity of masked self-attention and the choice of ProbSparse over other methods. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment identifies relevant areas for further exploration and questions that could lead to improvements in the paper, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider and potentially expand on these aspects, but it could be more beneficial with additional direction or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment identifies areas of interest and potential concerns, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors can infer that they need to provide explanations or evidence regarding these aspects, but the feedback lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer detailed direction.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the necessity of masked self-attention and the reasons behind the choice of ProbSparse. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and the reasons behind the choice of ProbSparse over"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a theoretical analysis, but it does not specify what aspects should be covered or how to conduct this analysis. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the theoretical analysis of why deep layer parameters are more suitable for distillation. However, it does not explicitly mention which part of the paper this analysis is supposed to be in, making it weakly grounded. The comment is specific in identifying the lack of theoretical analysis, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks theoretical analysis, namely the suitability of deep layer parameters for distillation. This is a relevant point that could help the authors improve their work by providing a theoretical foundation for their approach. However, the comment is vague and does not offer specific suggestions or guidance on how the authors might address this issue or what aspects of the theoretical analysis should be included. While it points out an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that a significant amount of important paper details are located in the appendix, suggesting that the paper is not sufficiently self-contained. However, it does not provide explicit guidance on how the authors should address this issue, such as recommending that these details be moved to the main text or providing specific examples of what should be included. The action is implicit and vague, leaving the authors uncertain about how to improve the self-containment of their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the distribution of important paper details, noting that they are primarily located in the appendix. However, it does not specify which sections or details are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what details are missing or how they could be better integrated into the main text. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not sufficiently self-contained. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to particular sections or details, the authors may find it challenging to understand which parts of the paper need improvement. As a result, the claim is considered borderline verifiable, as it lacks sufficient support to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a significant issue with the paper, noting that a large portion of important details are located in the appendix, which makes the paper less self-contained. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to reconsider the placement of important information. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending that certain details be moved to the main text or providing examples of what should be included. While it points out a problem, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering, but it expresses a concern that the largest dataset used is only about 50K points, which may not be considered \"large enough.\" However, the comment does not provide any explicit or implicit suggestions for how the authors could address this concern or improve their argument. There is no guidance on whether the authors should provide additional evidence, discuss the limitations of their dataset, or suggest ways to scale their method to larger datasets. As a result, the comment lacks actionability, leaving the authors without direction on how to respond to the feedback. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is about 50K points. However, it does not specify which part of the paper this concern is based on, such as a particular section or discussion about dataset size. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment lacks specificity regarding what needs to be addressed or improved, making it weakly grounded and not specific. Therefore, this comment aligns with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern that the largest dataset used is only about 50K points, which may not be considered \"large enough.\" However, the comment lacks specific reasoning or evidence to support the claim that 50K points is insufficiently large. Without further elaboration or references to standard benchmarks or expectations for dataset size, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is only about 50K points. While it identifies a potential weakness in the experimental setup, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their argument. The feedback lacks actionable advice or detailed insights that could help the authors strengthen their draft. As a result, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is only about 50K points. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their argument. There is no guidance on whether the authors should provide additional evidence, discuss the limitations of their dataset, or suggest ways to scale their method to larger datasets. As a result, the comment lacks actionability, leaving the authors without direction on how to respond to the feedback. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is about 50K points. However, it does not specify which part of the paper this concern is based on, such as a particular section or discussion about dataset size. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment lacks specificity regarding what needs to be addressed or improved, making it weakly grounded and not specific. Therefore, this comment aligns with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is about 50K points. However, the comment lacks specific reasoning or evidence to support the claim that 50K points is insufficiently large. Without further elaboration or references to standard benchmarks or expectations for dataset size, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering but expresses a concern about the size of the largest dataset used, which is only about 50K points. While it identifies a potential weakness in the experimental setup, it does not provide"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically questioning the feasibility of \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their assumptions. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"assumption 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the practicality of the assumptions and the reliance on \"overloading the library with ASD subroutines.\" This provides clear guidance on what aspect of the assumptions needs further clarification or justification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically questioning the feasibility of \"overloading the library with ASD subroutines\" (assumption 3.2). However, the comment lacks any supporting evidence, reasoning, or references to substantiate why this assumption might be impractical or how it could be addressed. Without additional context or justification, the claim remains vague and difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions made in the paper, specifically questioning the feasibility of \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their assumptions. Without actionable feedback or detailed advice, the authors are left with a general idea of what needs attention but no clear path to take. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the excitement of their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on how the methodology is used or why it lacks excitement. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or understand the basis of the reviewer\\'s concern. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the methodology used in data augmentation lacks excitement. However, it does not provide any supporting evidence, reasoning, or examples to justify why this methodology is considered unexciting. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not provide any specific feedback or suggestions on how the authors might enhance the novelty or excitement of their work. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty or excitement of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on how the methodology is used or why it lacks excitement. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or understand the basis of the reviewer\\'s concern. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the methodology used in data augmentation lacks excitement. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might enhance the novelty or excitement of their work. Without actionable advice or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. Without specific guidance or suggestions on how to enhance the novelty or excitement of their work, the authors are left without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of excitement in utilizing a methodology commonly used in data augmentation. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on how the methodology is used or why it lacks excitement. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or understand the basis of the reviewer\\'s concern. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an inconsistency in the paper regarding the claim that \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting.\" It explicitly states that this claim is incorrect based on the results presented in Fig. 4, which shows that the multi-IMP performs essentially the same as others. This feedback provides a clear and explicit action for the authors to take, which is to correct the statement in the paper. The comment is specific and actionable, as it directly identifies the issue and suggests a specific change to make the paper more accurate. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement in section 4 regarding the performance of \"multi-image IMP\" compared to \"multi-IMP\" and others, as shown in Fig. 4. This provides clear guidance on what needs to be revised or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a statement in section 4 regarding the performance of \"multi-image IMP\" compared to \"multi-IMP\" and others. The reviewer supports this claim by referencing a figure (Fig. 4) that shows the performance of these methods. This provides a clear and specific reference to the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the paper regarding the claim about the performance of \"multi-image IMP\" in improving the quality of LIPs in the cross-domain setting. It points out that the results presented in Fig. 4 contradict this claim, as the multi-IMP shows essentially the same performance as others. This feedback is clear and actionable, as it directs the authors to correct the misrepresentation in their paper. By highlighting this discrepancy, the comment provides valuable guidance for the authors to ensure the accuracy and integrity of their claims. However, it could be more helpful if it suggested how the authors might address this issue or provide additional context to support their claims. Overall, the comment is mostly helpful, as it effectively identifies a critical error and guides the authors toward improving the accuracy of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a comparison of the proposed method\\'s rank on the VLN Leaderboard to existing methods, specifically mentioning [1, 2, 3] as examples. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue of their method\\'s performance compared to existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a specific comparison of the proposed method\\'s rank on the VLN Leaderboard to existing methods, mentioning specific references [1, 2, 3]. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. The comment also specifies what needs to be addressed, namely the comparison of the proposed method\\'s performance to existing methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method\\'s results are not better than existing methods, specifically mentioning references [1, 2, 3] as examples. The comment provides specific references to external works that demonstrate better results, which supports the claim. This makes the comment mostly verifiable, as it offers a clear rationale and references to substantiate the assertion. However, it could be further strengthened by providing more detailed comparisons or analysis of the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific comparison of the proposed method\\'s performance on the VLN Leaderboard to existing methods, citing references [1, 2, 3] as examples. This feedback is valuable as it highlights a potential weakness in the paper\\'s contribution by pointing out that the proposed method does not outperform existing methods. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their method to achieve better results. While it identifies a problem, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point provides a specific comparison of the proposed method\\'s rank on the VLN Leaderboard to existing methods, mentioning references [1, 2, 3] as examples. However, it does not provide any explicit or implicit actions for the authors to take in response to this information. There is no guidance on how the authors might address the issue of their method\\'s performance compared to existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a specific comparison of the proposed method\\'s rank on the VLN Leaderboard to existing methods, mentioning references [1, 2, 3] as examples. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. The comment also specifies what needs to be addressed, namely the comparison of the proposed method\\'s performance to existing methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method\\'s results are not better than existing methods, providing specific references [1, 2, 3] as examples. This provides a clear and detailed comparison, making the claim mostly verifiable. The references to external works support the assertion, allowing the authors to understand the context and basis of the comparison. However, the comment could be further strengthened by including more detailed comparisons or analysis of the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific comparison of the proposed method\\'s performance on the VLN Leaderboard to existing methods, citing references [1, 2, 3] as examples. This feedback is valuable as it highlights a potential weakness in the paper\\'s contribution by pointing out that the proposed method does not outperform existing methods. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their method to achieve better results. While it identifies a problem, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point provides a specific comparison of the proposed method\\'s rank on the VLN Leaderboard to"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide specific guidance on what aspects of the discussion are lacking or how the authors could improve it. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to address the issue. Without detailed feedback, the authors may struggle to determine what changes are needed to make the discussion more convincing. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of convincingness in the discussion regarding how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the discussion in section 2.2, noting that it is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might improve the clarity or persuasiveness of their explanation. Without actionable feedback or detailed insights, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss the uncertainty in fitted parameter values and to provide sensitivity analysis for the SEPAI3R3O model. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and offers concrete guidance on how to address the issue of parameter estimation and uncertainty, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of having over 10 parameters, which may be difficult to estimate given limited real-world observations, and suggests discussing the uncertainty in fitted parameter values and providing sensitivity analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SEPAI3R3O model introduces over 10 parameters, which may be difficult to estimate given limited real-world observations. It further suggests that modeling these parameters as time-varying exacerbates the estimation challenge. The comment is mostly verifiable as it provides a logical reasoning for the claim, explaining the potential difficulty in estimating parameters with limited data. However, it lacks specific examples or references to support the assertion, which would strengthen the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the SEPAI3R3O model, specifically the introduction of over 10 parameters, which may be challenging to estimate given limited real-world observations. It further highlights the complexity introduced by modeling these parameters as time-varying. The comment is mostly helpful as it provides a clear and actionable suggestion for the authors to discuss the uncertainty in fitted parameter values and conduct a sensitivity analysis. This feedback is valuable as it guides the authors to address a critical aspect of their model that could impact its reliability and applicability. However, the comment could be more helpful if it offered specific guidance on how to conduct the sensitivity analysis or provided examples of similar analyses in related work. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. It also questions the reliability of the proposed method's performance and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about how parameters change across domains. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific assumption about the causal parameters across domains and questions its validity. It also raises concerns about the performance of the proposed method and the reliability of the output, particularly in the absence of knowledge about parameter changes across domains. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the implications of not knowing how parameters change, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. The reviewer provides a logical reasoning by questioning the reliability of the proposed method and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about parameter changes across domains. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. It questions the reliability of the proposed method's performance and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about how parameters change across domains. This feedback is valuable as it challenges a fundamental assumption of the paper and prompts the authors to reconsider their methodology and assumptions. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or alternative approaches to consider. Overall, the comment is somewhat helpful as it identifies a significant area for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. It also questions the reliability of the proposed method's performance and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about how parameters change across domains. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. Without actionable steps or concrete advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. It also questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about parameter changes across domains. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing assumptions or results, but this inference is not direct. The comment is specific in detailing the issue with the assumption and the implications of not knowing how parameters change, but without clear grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. It raises concerns about the reliability of the proposed method and the relative performances of MC, IB, and HSIC test methods, given the uncertainty about parameter changes across domains. While the comment provides logical reasoning and highlights a potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is somewhat verifiable, aligning with a score of 3.',"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be new and that this is reflected in the paper title, which weakens the narrative. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might clarify the novelty or improve the narrative, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method, suggesting that it may not be new and that this is reflected in the paper title. However, it does not specify which part of the paper discusses the structural optimization method or how the novelty is perceived as questionable. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be new and that this is reflected in the paper title. However, the comment lacks specific evidence, examples, or references to support the claim that the method is not novel. Without detailed justification or comparisons to existing literature, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the novelty of the structural optimization method, suggesting that it may not be new and that this is reflected in the paper title. However, it does not provide specific examples or references to support this claim, nor does it offer actionable suggestions for how the authors might address this issue or improve the narrative. Without detailed feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the proof, specifically that it assumes lambda is not 0.5, which is not the case in standard mixup. However, it does not provide explicit guidance on how the authors should address this issue or suggest any specific actions to correct the proof. The comment implies that the authors should reconsider the proof or provide an explanation for the assumption, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proof assumes lambda is not 0.5, which is not the case in standard mixup. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof assumes lambda is not 0.5, which is not the case in standard mixup. This claim is supported by logical reasoning, as it highlights a potential inconsistency between the proof and standard practice in mixup. However, the comment could be strengthened by providing specific examples or references to standard mixup methods to fully substantiate the claim. As it stands, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or references. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it assumes lambda is not 0.5, which is not the case in standard mixup. This observation is valuable as it highlights a potential flaw in the theoretical foundation of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the proof. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it assumes lambda is not 0.5, which is not the case in standard mixup. However, it does not provide explicit guidance on how the authors should address this issue or suggest any specific actions to correct the proof. The comment implies that the authors should reconsider the proof or provide an explanation for the assumption, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proof assumes lambda is not 0.5, which is not the case in standard mixup. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof assumes lambda is not 0.5, which is not the case in standard mixup. This claim is supported by logical reasoning, as it highlights a potential inconsistency between the proof and standard practice in mixup. However, the comment could be strengthened by providing specific examples or references to standard mixup methods to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it assumes lambda is not 0.5, which is not the case in standard mixup. This observation is valuable as it highlights a potential flaw in the theoretical foundation of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the proof. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it assumes lambda is not 0.5, which is not the case in standard mixup. However, it does"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It asks the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. Additionally, it suggests extracting some of the inlined math into environments to facilitate looking up symbols, specifically on page 6. These requests are clear and provide concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraph above Theorem 3.1 and page 6, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done: highlighting the set of equations with the same form as the Riccati equation and extracting some of the inlined math into environments to facilitate symbol lookup. This provides clear direction for the authors to improve the clarity and organization of their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for improving the presentation of mathematical content. It does not contain subjective opinions, judgments, or claims that require verification. The requests are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by asking the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. Additionally, it suggests extracting some of the inlined math into environments to facilitate symbol lookup, particularly on page 6. This feedback is clear and constructive, offering the authors concrete steps to improve the clarity and organization of their draft. By addressing these points, the authors can enhance the readability and accessibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the use of subjective terms like \"significant\" that could be improved with statistical evidence, such as p-values. While the comment provides explicit actions\u2014clarifying structure and transitions and using statistical evidence for subjective terms\u2014it does not offer detailed guidance on how to achieve these improvements. The authors are given a clear direction but may need to determine the specific changes themselves. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the use of subjective terms like \"significant\" that could be improved with statistical evidence. However, it does not specify which sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact parts that need improvement. While the comment provides some specificity regarding the use of subjective terms and the need for statistical evidence, it lacks full grounding because it does not explicitly mention the sections or lines being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the use of subjective terms like \"significant\" that could be improved with statistical evidence. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that statistical evidence would clarify the use of \"significant.\" This makes the claim somewhat verifiable, as the authors would need to infer the specific sections or terms that require clarification and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the clarity of the writing in the paper. It suggests that certain sections would benefit from clearer structure and transitions, which is a valuable piece of advice for improving the overall coherence and readability of the paper. Additionally, the comment points out the use of subjective terms like \"significant\" and recommends using statistical evidence, such as p-values, to support these claims. This guidance is clear and constructive, offering the authors a concrete way to enhance the rigor and clarity of their work. However, the comment could be more helpful if it provided examples of how to implement these suggestions or offered more detailed guidance on structuring and transitions. Overall, the feedback is mostly helpful, as it effectively directs the authors toward improving the quality of their writing and argumentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of detailed information regarding the construction of graphs, specifically mentioning the need to define edges and construct a graph for non-euclidean datasets. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is specific and leaves no ambiguity about what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of detailed information regarding the construction of graphs, specifically mentioning the need to define edges and construct a graph for non-euclidean datasets. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where graph construction is discussed. The comment is specific in detailing what information is missing, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"the detailed information for graph construction is missing,\" specifically mentioning the need to define edges and construct a graph for non-euclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this information is crucial or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this information or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the detailed information for graph construction, particularly the definition of edges and the construction of graphs for non-euclidean datasets. This feedback is clear and actionable, as it points out a concrete area where the authors can provide additional information to enhance the clarity and completeness of their methodology. By addressing this issue, the authors can improve the comprehensibility and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of what details should be included. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It also references a specific paper, \"Conditional mutual information constrained deep learning for classification,\" which suggests that the authors might need to provide more information or justification for their choices. However, the comment does not explicitly instruct the authors to include this information or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the hyper-parameter settings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which is a specific issue related to the methodology or experimental setup. However, it does not explicitly mention which part of the paper discusses these hyper-parameters, making it weakly grounded. The authors might infer that it relates to the methodology or experimental sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the determination of default settings for hyper-parameters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It does not contain any subjective claims, opinions, or suggestions that require verification. The request for information is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which is a critical aspect of the experimental setup. By asking for clarification on this point, the reviewer prompts the authors to provide more detailed information or justification for their choices. This feedback is actionable as it directs the authors to address a specific gap in their methodology, potentially improving the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how the authors might present this information or provided examples of how similar studies have addressed this issue. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and provides some direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the visual or textual representations used in each method in Table 4. It suggests that this information is necessary to understand whether the end-to-end performance gain is due to the proposed attention model. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is clear but stated implicitly, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for clarity on the visual or textual representations used in each method to understand the end-to-end performance gain. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Table 4, specifically questioning whether the end-to-end performance gain is due to the proposed attention model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the results. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 4, questioning the clarity of the visual or textual representations used in each method. It suggests that this information is crucial for understanding whether the end-to-end performance gain is due to the proposed attention model. While the comment highlights an important area for clarification, it lacks detailed guidance or suggestions on how the authors might address this issue. Providing examples of what kind of information should be included or how to present it would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. It also points out that Eq. (15) is not well justified. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what changes should be made. The authors are left to infer that they need to clarify the convergence analysis, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"convergence analysis\" and the \"appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the convergence analysis, such as the lack of clarity in the main part, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. The comment also points out that Eq. (15) is not well justified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the convergence analysis is unclear, as the authors provide a simple proof in the appendix and do not present any related content in the main part of the paper. The reviewer also notes that the proof itself is unclear, with notations like D and G not being clearly presented, and the assumption that \\\\( \\\\alpha_k \\\\) converges to \\\\( \\\\alpha \\\\) not being stated. Additionally, the justification of Eq. (15) is questioned. The comment provides specific examples of what is lacking, making the claim mostly verifiable. However, it could be strengthened by providing more detailed reasoning or references to support the critique. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies several critical issues with the convergence analysis section of the paper. It points out that the main part of the paper does not provide any related content to the convergence analysis, and the appendix contains a simple proof that is not clearly presented. Additionally, the comment highlights specific notations, such as D and G, that are not clearly defined, and it questions the assumption that \\\\( \\\\alpha_k \\\\) converges to \\\\( \\\\alpha \\\\) and the justification of Eq. (15). This feedback is clear and actionable, as it directs the authors to improve the clarity and rigor of their convergence analysis by providing more detailed explanations and justifications. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the presentation. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the quality of their analysis.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the presentation of the studied problems, noting that the description of uncertainty calibration is insufficient and unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment provides explicit actions\u2014organizing and summarizing the issues\u2014it does not offer detailed guidance on how to achieve this. The authors are given a clear direction but lack specific instructions on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of insufficient description of uncertainty calibration, which is unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for better organization and summarization of the issues, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration as unfriendly for new readers. The comment suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to organize and summarize the issues is logical, but without specific guidance or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the studied problems, noting that the description of uncertainty calibration is insufficient and unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and organization of their paper. However, the comment could be more helpful if it offered specific suggestions on how to organize and summarize the issues effectively. Overall, the comment is mostly helpful as it provides valuable insights and guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific experiments to conduct. The action is implicit, as the authors can infer that they need to include results on the incorporation of PAC-tuning with other techniques, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these techniques are discussed. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the authors might have an idea of where these techniques are mentioned, the comment lacks full grounding. It is specific about the missing results but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. This feedback highlights an area where the authors could expand their work to provide a more comprehensive analysis. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on, which limits its helpfulness. While it provides some insight into potential improvements, it does not offer detailed, actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental analysis is insufficient and should be validated on more models. It also references a specific question, which likely provides additional context or guidance on what needs to be addressed. However, without the content of the fourth question, the authors may not fully understand the context or the specific aspects that need improvement. The action is clear but lacks concrete details on how to implement the validation on more models. Therefore, the comment is somewhat actionable, as it provides an explicit action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental analysis is insufficient and should be validated on more models. However, it does not specify which part of the paper this analysis is located in, making it weakly grounded. The comment does provide a specific suggestion for improvement by recommending validation on more models, but it lacks grounding as it does not reference a specific section or table. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate why more models are needed or how the current analysis is insufficient. As a result, the claim is unverifiable, as it does not provide enough information for the authors to understand or address the issue effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the experimental analysis, which is described as insufficient. It suggests that the analysis should be validated on more models, providing a clear direction for enhancing the robustness and generalizability of the findings. However, the comment lacks depth and does not specify which models should be considered or how the validation should be conducted. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some guidance but not comprehensive direction for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the proposed method's improvement over the original initialization, noting that it only shows trainability on CIFAR with a network of 100 layers and that ImageNet experiments are based on networks with varying normalization layers. The reviewer references specific works, suggesting that the proposed method only has marginal improvement over baselines. However, the comment does not provide explicit guidance or suggestions on how the authors could address these issues or improve their method. It lacks actionable steps or concrete advice, leaving the authors uncertain about how to enhance their work. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s improvement over the original initialization, specifically mentioning the trainability of a network with 100 layers on CIFAR and the ImageNet experiments. It references specific works, suggesting that the proposed method only has marginal improvement over baselines. However, the comment does not explicitly mention which part of the paper discusses these experiments or improvements, making it weakly grounded. The comment is specific in detailing the issues with the proposed method\\'s trainability and improvement over baselines, but without clear references to sections or experiments, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method only shows marginal improvement over baselines, particularly in ImageNet experiments where networks have varying normalization layers. The reviewer supports this claim by referencing specific works, such as \"Zagoruyko et al. DiracNets\" and \"Qi et al. Deep Isometric Learning,\" which provide context and evidence for the comparison. This reference to external works and the specific mention of the proposed method\\'s limitations on CIFAR and ImageNet experiments provide a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a critical evaluation of the proposed method's improvement over the original initialization, noting that it only shows trainability on CIFAR with a network of 100 layers and that ImageNet experiments are based on networks with varying normalization layers. The comment references specific works, suggesting that the proposed method only has marginal improvement over baselines. While the comment identifies a limitation in the proposed method's generalizability and provides references to relevant literature, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their method. The feedback is somewhat helpful as it highlights areas for improvement but does not offer detailed, constructive advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the proposed method's improvement over the original initialization, noting that it only shows trainability on CIFAR with a network of 100 layers and that ImageNet experiments are based on networks with varying normalization layers. The reviewer references specific works, suggesting that the proposed method only has marginal improvement over baselines. However, the comment does not provide any explicit guidance or suggestions on how the authors could address these issues or improve their method. Without actionable advice or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s improvement over the original initialization, specifically mentioning the trainability of a network with 100 layers on CIFAR and the ImageNet experiments. It references specific works, suggesting that the proposed method only has marginal improvement over baselines. However, the comment does not explicitly mention which part of the paper discusses these experiments or improvements, making it weakly grounded. The comment is specific in detailing the issues with the proposed method\\'s trainability and improvement over baselines, but without clear references to sections or experiments, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method only shows marginal improvement over baselines, particularly in ImageNet experiments where networks have varying normalization layers. The reviewer supports this claim by referencing specific works, such as \"Zagoruyko et al. DiracNets\" and \"Qi et al. Deep Isometric Learning,\" which provide context and evidence for the comparison. This reference to external works and the specific mention of the proposed method\\'s limitations on CIFAR and ImageNet experiments provide a solid"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. While the comment explicitly states the action to take, it does not provide specific guidance on how to conduct this comparison or what aspects should be focused on. The authors are given a clear direction to include a discussion, but the lack of detailed instructions on execution makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a comparison, but without clear grounding, the authors may struggle to identify where this discussion should fit into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would benefit the paper. Without such support, the claim lacks verifiability, making it difficult for the authors to understand the importance of this addition. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could include suggestions on how to structure the discussion or what specific aspects of robustness and immunizability should be highlighted. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. While the comment explicitly states the action to take, it lacks specific guidance on how to conduct this comparison or what aspects should be focused on. The authors are given a clear direction but without detailed instructions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a comparison, but without clear grounding, the authors may struggle to identify where this discussion should fit into the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any justification or reasoning for why this comparison is necessary or how it would benefit the paper. Without specific examples, references, or detailed explanation, the claim lacks verifiability. The authors may find it challenging to understand the importance of this addition or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct this comparison or what specific aspects should be focused on. To be more helpful, the comment could include suggestions on how to structure the discussion or what specific aspects of robustness and immunizability should be highlighted. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the proposed algorithm for adaptive top-k decoding, asking the authors to clarify if the reviewer misunderstands something. It also suggests that the authors should provide a plot of the time complexity of the decoding scheme as a function of m. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3) this work proposes an algorithm for adaptive top-k decoding to produce arguably \\\"better\\\" samples,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the need for a plot of the time complexity of the decoding scheme as a function of m. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and a suggestion for additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. The request for a plot of time complexity is a request for further analysis, not a claim. Therefore, the review point is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the proposed algorithm for adaptive top-k decoding, asking the authors to clarify if the reviewer misunderstands something. It also suggests that the authors should provide a plot of the time complexity of the decoding scheme as a function of m. While the comment identifies a potential area for clarification and improvement, it lacks specific guidance or detailed suggestions on how to address these points. The request for a plot is a constructive suggestion, but the overall feedback could be more actionable and comprehensive. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the postprocessing effort in footnote 2 is unclear. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors should clarify the postprocessing effort or what specific details should be included. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of unclear postprocessing effort, providing clear guidance on what needs to be clarified. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the postprocessing effort mentioned in footnote 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have run their codes for multiple seeds and reported the mean. While it implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the authors have run their codes for multiple seeds and reported the mean. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it difficult for the authors to pinpoint where this information should be included or addressed. The comment is not grounded because it does not provide explicit references to sections or elements of the paper. It is also not specific because it lacks detailed guidance on what needs to be done or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the experimental setup, specifically whether the authors have run their codes for multiple seeds and reported the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the authors have run their codes for multiple seeds and reported the mean. While it identifies a potential area for improvement in the experimental setup, it lacks specificity and does not provide guidance on why this is important or how it could impact the results. The comment is vague and does not offer actionable advice, making it barely helpful for the authors. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for these datasets. It specifically mentions the absence of results for models like InceptionV3 and ResNet in Table 3, while they are included in Table 2. While the comment highlights areas of inconsistency, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to clarify the differences between the datasets and the experimental setup, and possibly include results for the mentioned models in Table 3. However, the comment lacks concrete guidance on how to implement these changes, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the differences between the BCI and IHC4BC datasets and the experimental setup for these datasets. The comment further details the absence of results for models like InceptionV3 and ResNet in Table 3, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the differences between the BCI and IHC4BC datasets and the experimental setup. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for these datasets. It highlights a specific issue with Table 3, noting the absence of results for models like InceptionV3 and ResNet, while Table 2 includes them. This feedback is valuable as it points out a potential inconsistency in the experimental setup that the authors should address to ensure the clarity and completeness of their results. However, the comment could be more helpful if it provided suggestions on how to resolve this inconsistency or offered insights into why these models are relevant. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not specify what aspects of the results should be described more thoroughly or how the authors should go about doing this. While the action is explicit, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 4,\" which allows the authors to accurately identify the specific part of the paper being addressed, providing full grounding. It also specifies what needs to be addressed, namely a more thorough description of the results shown in Figure 4. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a more thorough description of the results shown in Figure 4 is needed. However, it does not provide any specific reasoning, examples, or references to support why this description is insufficient or how it could be improved. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the manuscript by requesting a more thorough description of the results shown in Figure 4. This feedback is specific and directly addresses a potential weakness in the paper, guiding the authors on how to enhance the clarity and comprehensiveness of their results section. However, the comment could be more helpful if it offered examples of what aspects of the results should be described more thoroughly or how the authors might structure this description. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their work with a specific literature, [11], in the method part or in more detail. While the comment implies that the authors should include a comparison with this literature, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to incorporate this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the work with a specific literature, [11], and recommends either comparing it in the method part or in more detail. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in its suggestion to compare with [11] and provides a clear direction for improvement, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing the work with this literature in the method part or in more detail. However, the comment does not provide any specific reasoning or evidence to support why [11] is the most relevant literature or how it should be compared. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing the work with this literature in the method part or in more detail. This feedback is somewhat helpful as it identifies a specific literature that could be relevant for comparison, which could enhance the paper\\'s relevance and depth. However, the comment lacks detailed guidance on how to incorporate this comparison or what specific aspects should be highlighted. Additionally, it does not provide context or reasoning for why this literature is particularly relevant, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, as it provides some direction but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests comparing the work with a specific literature, [11], in the method part or in more detail. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so or provide guidance on how to incorporate it into their draft. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the work with a specific literature, [11], and recommends either comparing it in the method part or in more detail. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in its suggestion to compare with [11], but without clear references to sections or parts of the paper, the authors may struggle to implement the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing the work with this literature in the method part or in more detail. However, the comment lacks specific reasoning or evidence to support why [11] is the most relevant literature or how it should be compared. Without detailed justification or examples, the claim remains vague and difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing the work with this literature in the method part or in more detail. This feedback is somewhat helpful as it identifies a specific literature that could be relevant for comparison, which could enhance the paper\\'s relevance and depth. However, the comment lacks detailed guidance on how to incorporate this comparison or what specific aspects should be highlighted. Additionally, it does not provide context or reasoning for why [11] is particularly relevant, which would make the feedback more actionable. Therefore, the comment provides some insight but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests comparing the work with a specific literature, [11], and recommends either comparing it in"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their process. The action is implicit and vague, as the authors are left to infer that they need to reconsider their justification but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the justification for the process, but without clear grounding, the authors may struggle to identify where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, 'Ten Years of BabelNet: A Survey,' which suggests that there can be legitimate shared words between English and language-specific vocabularies. This feedback is somewhat helpful as it highlights a potential flaw in the methodology and provides a reference for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or alternative approaches to consider. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their process. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The reference to the paper provides some specificity regarding the potential issue, but without clear grounding, the authors may struggle to identify where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there can be legitimate shared words between English and language-specific vocabularies. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, 'Ten Years of BabelNet: A Survey,' which suggests that there can be legitimate shared words between English and language-specific vocabularies. This feedback is somewhat helpful as it highlights a potential flaw in the methodology"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While the comment implies that the authors should expand their analysis to include additional models, it does not specify which models should be studied or how this would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the need for a broader study and to determine which models to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or analyses. The authors might infer that it relates to the conclusions or discussion sections, but this inference is not direct. The comment is specific in its suggestion to study more models, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study should consider examining more models to verify the findings, particularly regarding conclusions drawn for large vision-language models. However, the comment does not provide specific examples of additional models that should be studied or explain why more models would be beneficial. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which additional models should be studied or how this would enhance the study. The comment is somewhat helpful as it points out a direction for further exploration, but it does not offer actionable steps or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that the authors should provide further explanation or exploration of the reason behind this discrepancy. While the comment implies that the authors should investigate and clarify this issue, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer the need for further explanation and exploration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy between the significant reduction in the norm shown in Figure 7 and the lack of significant improvement in object localization in Table 3. The comment suggests that further explanation or exploration of this discrepancy would be helpful for wider adoption. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that further explanation or exploration of this discrepancy would be beneficial for wider adoption. While the comment identifies a potential issue, it lacks specific reasoning or evidence to support why this discrepancy is significant or how it affects the overall results. The suggestion for further explanation is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that further explanation or exploration of this discrepancy would be beneficial for wider adoption. While the comment highlights an important area for clarification, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the discrepancy need further exploration. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed direction for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that further explanation or exploration of this discrepancy would be beneficial for wider adoption. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need further exploration. The action is implicit and somewhat vague, as the authors need to infer the need for further explanation and exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy between the significant reduction in the norm shown in Figure 7 and the lack of significant improvement in object localization in Table 3. The comment suggests that further explanation or exploration of this discrepancy would be helpful for wider adoption. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that further explanation or exploration of this discrepancy would be beneficial for wider adoption. While the comment identifies a potential issue, it lacks specific reasoning or evidence to support why this discrepancy is significant or how it affects the overall results. The suggestion for further exploration is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results shown in Figure 7 and Table 3 regarding the performance of OpenCLIP. It suggests that further explanation or exploration of this discrepancy would be beneficial for wider adoption. While the comment highlights an important area for clarification, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the discrepancy need further exploration. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed direction for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the use of 3D renders in conjunction with G, particularly in Section 3.3. It explicitly asks for more details on how the point cloud is utilized in this stage and how the 3D rendering and GAN objective are combined. This feedback provides a clear and direct action for the authors to take, which is to provide additional information on these aspects. The comment is explicit and concrete, offering specific guidance on what needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of clarity on how the 3D renders are used along with G, particularly regarding the point cloud and the GAN objective. The comment provides a clear direction for the authors to enhance their explanation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how 3D renders are used in conjunction with G, specifically questioning the role of the point cloud in this process. The comment highlights a lack of detail in Section 3.3 regarding the combination of 3D rendering and the GAN objective. While the comment identifies an area needing clarification, it does not provide specific examples or references to support the claim. The authors are left to infer the need for more detailed explanation, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the use of 3D renders in conjunction with G, particularly in Section 3.3. It highlights the lack of clarity on how the point cloud is utilized in this stage and suggests that more details about the combination of 3D rendering and the GAN objective would be beneficial. This feedback is clear and actionable, as it points out a specific area that needs further explanation and provides a direction for the authors to improve the clarity of their manuscript. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how similar concepts have been effectively communicated in other works. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the clarity and comprehensiveness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence is based on simple architectures and datasets, which is deemed unconvincing. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to strengthen the evidence. The feedback lacks actionable details, such as recommending specific experiments or analyses to provide more robust evidence. As a result, the authors are left without clear steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It critiques the supporting evidence for parameter insensitivity, noting that it relies heavily on simple architectures and datasets. However, the comment does not specify which part of the paper discusses these hyperparameters or the supporting evidence, making it weakly grounded. The comment is specific in detailing the issue with the supporting evidence, but without clear grounding, the authors may struggle to identify where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model, and that the supporting evidence for parameter insensitivity relies heavily on simple architectures and datasets. This claim is somewhat verifiable as it provides a logical reasoning that the complexity of the model is increased due to additional hyperparameters. However, the comment lacks specific examples or references to the datasets or architectures used in the supporting evidence, which would strengthen the claim. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence relies heavily on simple architectures and datasets, which is considered unconvincing. This feedback highlights a critical area for improvement, as it questions the robustness of the model\\'s performance claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or datasets to strengthen the evidence. While it points out a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights an issue with the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence relies heavily on simple architectures and datasets, which is considered unconvincing. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or strengthen their evidence. Without specific recommendations or actionable steps, the authors are left without clear direction on how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the increased hyperparameter complexity of the QIF model compared to the traditional LIF model, noting that the supporting evidence for parameter insensitivity relies heavily on simple architectures and datasets. However, it does not specify which part of the paper discusses these hyperparameters or the supporting evidence, making it weakly grounded. The comment is specific in detailing the issue with the supporting evidence, but without clear grounding, the authors may struggle to identify where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model and that the supporting evidence for parameter insensitivity relies heavily on simple architectures and datasets. This claim is somewhat verifiable as it provides a logical reasoning that the complexity of the model is increased due to additional hyperparameters. However, the comment lacks specific examples or references to the datasets or architectures used in the supporting evidence, which would strengthen the claim. Without detailed evidence or examples, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence relies heavily on simple architectures and datasets, which is considered unconvincing. This feedback highlights a critical area for improvement"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made with other PLMs like RoBERTa and T5. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and real-world scenarios. While the comment provides a general direction for improvement, it lacks specific guidance on how to address these concerns or what aspects to focus on. The authors are left with a sense of what needs to be improved but without concrete steps on how to achieve it. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the marginal improvements over baselines and suggests that further improvements could be achieved with other PLMs like RoBERTa and T5. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and real-world scenarios. However, the comment does not specify which part of the paper discusses the improvements or the experiments, making it weakly grounded. The comment is specific in its suggestions for improvement, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made with other PLMs like RoBERTa and T5. The reviewer provides a logical reasoning by comparing the proposed method's performance with other PLMs, which is a valid point. However, the comment lacks specific examples or references to support the claim that these other PLMs would indeed lead to better performance. Additionally, the suggestion to discuss meaningful aspects in the context of LLMs is not fully supported by evidence or examples. Therefore, the claim is somewhat verifiable, as it provides a reasonable suggestion but lacks detailed justification or evidence.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines, suggesting that further improvements could be made with other PLMs like RoBERTa and T5. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and real-world scenarios. This feedback is mostly helpful as it provides a clear direction for improvement by suggesting alternative approaches and emphasizing the need for a broader perspective on the method's significance. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these aspects into the discussion or analysis. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment raises concerns about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made with other PLMs like RoBERTa and T5. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and real-world scenarios. While the comment provides a general direction for improvement, it lacks specific guidance on how to address these concerns or what aspects to focus on. The authors are left with a sense of what needs to be improved but without concrete steps on how to achieve it. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises concerns about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made with other PLMs like RoBERTa and T5. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs and real-world scenarios. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this is not explicitly stated. The comment is specific in its suggestions for improvement, but without clear grounding, it aligns with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made with other PLMs like RoBERTa and T5. The reviewer provides a logical reasoning by comparing the proposed method's performance with other PLMs, which is a valid point. However, the comment lacks specific examples or references to support the claim that these other PLMs would indeed lead to better performance. Additionally, the suggestion to discuss meaningful aspects in the context of LLMs is not fully supported by evidence or examples. Therefore, the claim is somewhat verifiable, as it provides a reasonable suggestion but lacks detailed justification or evidence.\", 'ver"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It questions whether the authors have reported an experiment to prove their conjecture. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the explanation and possibly include an experiment to support their conjecture. However, the comment lacks concrete details on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of the methodology\" and the \"explanation of using soft assignment instead of hard assignment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors have reported an experiment to prove their conjecture. This provides clear guidance on what aspect of the explanation needs further clarification or evidence. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It questions whether the authors have reported an experiment to prove their conjecture. However, the comment does not provide any supporting evidence or reasoning to substantiate the claim that the explanation is unclear or lacks experimental validation. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explanation of using soft assignment instead of hard assignment in the methodology. It highlights the need for clarity and suggests that the authors may have not reported an experiment to prove their conjecture. This feedback is somewhat helpful as it points out a potential gap in the explanation and encourages the authors to clarify or substantiate their claims. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of what kind of experiment could be conducted to support the conjecture. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity in the explanation of using soft assignment instead of hard assignment in the methodology. It questions whether the authors have reported an experiment to prove their conjecture. While the comment identifies an area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to clarify the explanation and possibly include an experiment, but the comment does not specify how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of the methodology\" and the \"explanation of using soft assignment instead of hard assignment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors have reported an experiment to prove their conjecture. This provides clear guidance on what aspect of the explanation requires clarification or evidence. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It questions whether the authors have reported an experiment to prove their conjecture. However, the comment lacks specific reasoning or evidence to support the claim that the explanation is unclear or incomplete. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explanation of using soft assignment instead of hard assignment in the methodology. It raises a valid concern about whether the authors have reported an experiment to prove their conjecture. This feedback is somewhat helpful as it highlights a potential gap in the explanation that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or substantiate their explanation. To be more helpful, the comment could include examples of what kind of experiment could be conducted or how the explanation could be improved. Overall, the comment provides some direction but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the generalizability of the methods. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their applicability to general federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses these methods or the cross-silo setting, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides some insight into the limitations of the methods, it lacks specificity and grounding, as it does not direct the authors to a particular section or suggest specific improvements. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the applicability of the methods. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. While it identifies a limitation, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable feedback or detailed insights that could help the authors enhance their work. As a result, the comment is barely helpful, as it points out a potential issue but does not offer a clear path for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses these methods or the cross-silo setting, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the limitations could be addressed or improved. Without clear guidance or suggestions, the authors are left without a clear understanding of what needs to be done to enhance the applicability of their methods. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the applicability of the methods. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. Without actionable feedback or detailed insights, the comment offers limited value to"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what constitutes distributional generalization in the context of regression. It provides an example to illustrate the phenomenon, suggesting that a smooth regression model interpolating the training data would naturally exhibit distributional generalization. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how this insight could be applied to improve the paper or what specific changes might be necessary. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression. It provides an example to illustrate the phenomenon, suggesting that a smooth regression model interpolating the training data would naturally exhibit distributional generalization. However, the comment does not explicitly mention a specific section, figure, or table in the paper, making it weakly grounded. The authors might infer that it relates to sections discussing regression or generalization, but this is not clearly stated. The comment is specific in its inquiry about the definition of distributional generalization in regression, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and an observation about the phenomenon of distributional generalization in the context of regression. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression. It provides an example to illustrate the phenomenon, suggesting that a smooth regression model interpolating the training data would naturally exhibit distributional generalization. However, the comment does not offer any specific suggestions or actionable feedback for the authors to improve their draft. It lacks depth and does not provide guidance on how the authors might address this issue or enhance their work. As a result, the comment is barely helpful, as it identifies a potential area of interest but does not provide actionable steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams\" to find additional results. While the comment implies that the authors should update their references and baselines, it does not explicitly instruct them to do so or provide specific examples of recent research to include. The suggestion to search for \"Item Frequencies of Data Streams\" is concrete, but the overall comment lacks explicit instructions on how to implement the changes. Therefore, the comment is mostly actionable, as it provides a clear direction but requires some interpretation by the authors.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of outdated references and baselines, suggesting that more recent research should be covered. However, it does not specify which references or baselines are outdated or which recent research should be included, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment mentions searching for \"Item Frequencies of Data Streams,\" but this is not explicitly grounded in the paper. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the references and baselines are outdated and suggests that more recent research should be covered. However, the comment does not provide specific examples of outdated references or baselines, nor does it reference any recent research that should be included. The suggestion to search for \"Item Frequencies of Data Streams\" is a general statement without detailed guidance or justification. This lack of specific evidence or references makes the claim borderline verifiable, as it provides some direction but insufficient support for the authors to fully understand and address the issue. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the references and baselines are outdated. It suggests that more recent research should be included, which is a valuable piece of feedback for the authors to consider. Additionally, the comment provides a specific suggestion to search for \"Item Frequencies of Data Streams,\" which could lead the authors to additional relevant research. However, the comment could be more helpful if it provided examples of recent research or specific references that should be included. Overall, the feedback is somewhat helpful as it highlights a relevant area for improvement but lacks detailed guidance on how to implement the suggested changes.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for \"Item Frequencies of Data Streams\" to find additional results. While the comment identifies areas for improvement, it lacks explicit instructions on how to update the references and baselines or how to effectively incorporate the suggested search criteria. The feedback is somewhat actionable as it provides a direction for improvement but requires the authors to infer the specific steps needed to address the issues. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of outdated references and baselines, suggesting that more recent research should be included. It also provides a specific suggestion to search for \"Item Frequencies of Data Streams\" to find additional results. However, the comment does not specify which references or baselines are outdated or which recent research should be considered, making it difficult for the authors to pinpoint the exact areas needing improvement. The mention of \"Item Frequencies of Data Streams\" provides some direction, but it is not explicitly grounded in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the references and baselines are outdated and suggests that more recent research should be covered. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to identify which references or baselines are outdated. Additionally, the suggestion to search for \"Item Frequencies of Data Streams\" is a general statement without detailed guidance or justification. This lack of specific evidence or references makes the claim borderline verifiable, as it provides some direction but insufficient support for the authors to fully understand and address the issue. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the references and baselines are outdated. It suggests that more recent research should be included, which is a valuable piece of feedback"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a discrepancy between the introduction's emphasis on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential gap in the experimental analysis, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they should conduct additional experiments or analysis in high-dimensional spaces, but without specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out an area for improvement but lacks detailed instructions for execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the discrepancy between the introduction\\'s emphasis on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The comment further specifies what needs to be addressed, namely the need for more in-depth analysis of ARAM\\'s performance in high-dimensional action spaces, such as complex robotic manipulators. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the introduction\\'s emphasis on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential gap in the experimental analysis, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the introduction's emphasis on the computational challenges of scaling quadratic programs to high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by expanding the experimental analysis to better align with the introduction's claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a concern about the lack of information regarding the computational requirements of the model, suggesting that the extra performance might be due to increased parameters or computation. It implies that by reducing the model's floats, the performance would be more comparable to the original transformers. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for implementation. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the lack of information regarding the computational requirements of the experimental results, suggesting that the extra performance might be due to increased parameters or computation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to compare the model's performance with the original transformers by reducing the floats, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the computational requirements of the model, suggesting that the extra performance might be due to increased parameters or computation. The reviewer provides a logical reasoning by comparing the model's performance with the original transformers when reduced floats are used. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and verify the claim themselves, as the reasoning is based on a hypothesis rather than concrete evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's experimental results, specifically questioning the computational requirements needed to achieve the observed performance. It suggests that the extra performance might be due to increased parameters or computation, and proposes a method to test this by reducing the model's floats. This feedback is somewhat helpful as it points out a critical area for further investigation and provides a potential approach to address the concern. However, the comment could be more helpful if it offered specific guidance on how to conduct the suggested experiment or discussed the implications of such findings. Overall, the comment provides some actionable insight but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a concern about the lack of information regarding the computational requirements of the experimental results, suggesting that the extra performance might be due to increased parameters or computation. It provides a specific suggestion to compare the model's performance with the original transformers when reduced floats are used. However, the comment does not explicitly instruct the authors to include this information or provide detailed guidance on how to implement the suggested comparison. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the lack of information regarding the computational requirements of the experimental results, suggesting that the extra performance might be due to increased parameters or computation. It provides a specific suggestion to compare the model's performance with the original transformers when reduced floats are used. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, but without clear grounding, the authors may struggle to identify where to make the necessary adjustments. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the computational requirements of the model, suggesting that the extra performance might be due to increased parameters or computation. The reviewer provides a logical reasoning by comparing the model's performance with the original transformers when reduced floats are used. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's experimental results, specifically questioning the computational requirements needed to achieve the observed performance. It suggests that the extra performance might be due to increased parameters or computation and proposes a method to test this by comparing the model's performance with the original transformers when reduced floats are used. This feedback is somewhat helpful as it points out a critical area for further investigation and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance or examples on how to conduct the suggested experiment. Overall, the comment provides some actionable insight but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}{'action"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing, as the results do not show consistent trends and some improvements are not statistically significant. However, it does not provide specific guidance on how to address these issues or suggest ways to improve the evaluation or results. The feedback lacks actionable details, such as recommending specific statistical tests or suggesting alternative approaches to demonstrate consistency and significance. As a result, the authors are left without clear steps to take in order to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation and results, stating that they are not convincing due to inconsistent trends and lack of statistical significance. However, it does not specify which parts of the evaluation or results are being referred to, nor does it provide details on what aspects are inconsistent or how the improvements are not statistically significant. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out that the evaluation and results are not convincing, as they lack consistent trends and some improvements are not statistically significant. However, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the evaluation and results. Without actionable feedback or detailed advice, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies a problem but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should highlight the percentage of subjective questions contributing to the error rate, by examining human agreement. While the comment implies that the authors should conduct an analysis to determine this percentage, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of analysis needed, but it is inferred rather than directly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the subjective nature of certain questions and suggests highlighting the percentage of subjective questions contributing to the error rate. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to examine human agreement to determine the percentage of subjective questions, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should highlight the percentage of subjective questions contributing to the error rate, by examining human agreement. While the comment provides a logical reasoning for why this information could be useful, it lacks specific examples or references to support the claim. The suggestion is based on a plausible assumption, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to further explore and substantiate this suggestion themselves, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the subjective nature of some questions contributing to the error rate. It suggests that highlighting the percentage of subjective questions and examining human agreement could be beneficial. This feedback is actionable as it provides a specific direction for the authors to consider, which could help them address the issue of subjectivity in their work. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper would benefit from including additional NLP tasks beyond intent recognition, such as sentiment classification and named-entity recognition. This feedback provides a clear and direct action for the authors to take, specifying the types of tasks that should be considered. The comment is concrete in its suggestion, leaving no ambiguity about what needs to be done to improve the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the evaluation section, noting that it is weak due to the use of only a single dataset and limited NLP tasks (intent recognition). It suggests that the paper would benefit from considering additional NLP tasks like sentiment classification and named-entity recognition. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The suggestion to include additional tasks is specific, but without clear grounding, the authors may struggle to identify where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak due to the use of only a single dataset and limited NLP tasks (intent recognition). The reviewer suggests that the paper would benefit from considering additional NLP tasks like sentiment classification and named-entity recognition. While the comment identifies specific areas for improvement, it lacks detailed justification or examples of how these additional tasks would enhance the evaluation. The claim is somewhat verifiable, as it provides a logical suggestion for improvement but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation section of the paper, noting that it is limited to a single dataset and only a few NLP tasks (intent recognition). The reviewer suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition. This feedback is clear and actionable, providing the authors with specific areas to expand their evaluation, which could enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered additional guidance on how to incorporate these tasks or suggested specific datasets to consider. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the label for \"class semantic feature\" in Figure 3 should be changed from \"c\" to \"s.\" This is a clear and direct action that the authors can take to improve the clarity and accuracy of their figure. The comment provides specific guidance on what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the labeling of the \"class semantic feature\" as \"s\" instead of \"c.\" This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the labeling of a feature in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the labeling of a feature in Figure 3. By pointing out that the label for \"class semantic feature\" should be changed from \"c\" to \"s,\" the reviewer offers a clear and precise correction that can improve the clarity and accuracy of the figure. This feedback is highly helpful as it directly addresses a minor but important detail that could enhance the reader\\'s understanding of the figure. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a distinction between de-identification and face swapping, noting that the proposed method appears to be a form of face swapping, similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction. While the comment implies that the authors should conduct a comparison, it does not provide specific guidance on how to perform this comparison or which face swapping algorithms to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the distinction between de-identification and face swapping, specifically noting that the proposed method appears to be a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The suggestion to compare with state-of-the-art face swapping algorithms is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where these comparisons should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the distinction between de-identification and face swapping is not clear, as the proposed method appears to be a form of face swapping similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison with deepfake technology and suggests a specific action for the authors to take. However, it lacks detailed examples or references to specific face swapping algorithms, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key distinction between de-identification and face swapping, noting that the proposed method appears to be a form of face swapping, similar to deepfake technology. It highlights the need for a clear boundary between the two approaches and suggests that the authors should compare their method with state-of-the-art face swapping algorithms. This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by clarifying the distinction and comparing their method with relevant benchmarks. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be taken to enhance the compellingness of the results. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the experimental results on word embeddings to Gaussian embeddings, which is the chief baseline from the literature. This provides clear guidance on what aspect of the results needs further clarification or improvement. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results presented in Tables 1 and 2, noting that they are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. While this feedback highlights a potential weakness in the paper, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their results. Without specific recommendations or examples, the authors are left with only a vague understanding of what needs to be improved. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. Without specific guidance or actionable steps, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the experimental results on word embeddings to Gaussian embeddings, which is the chief baseline from the literature. This provides clear guidance on what aspect of the results needs further clarification or improvement. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results presented in Tables 1 and 2, noting that they are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. While this feedback highlights a potential weakness in the paper, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their results. Without specific recommendations or examples, the authors are left with only a vague understanding of what needs to be improved. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not very compelling compared to Gaussian embeddings, which is the chief baseline from the literature. However, it does not provide"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method appears to be similar to existing methods, with only a change in the task and reward function. It suggests that the contribution is small if this is the only difference. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might enhance the contribution or differentiate their work from previous studies. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and its similarity to previous studies, specifically mentioning references to Shi et al., 2018, and Ghosh et al., 2021. It highlights the lack of significant difference between the proposed method and existing work, except for the change in task and reward function. However, the comment does not specify which part of the paper discusses these comparisons, making it weakly grounded. The comment is specific in identifying the issue of a small contribution due to minor differences, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is similar to existing studies, with only minor differences in task and reward function. The reviewer supports this claim by referencing specific studies (Shi et al., 2018; Ghosh et al., 2021) and providing a rationale for why the contribution might be considered small. However, the comment lacks detailed comparisons or specific examples from the referenced studies to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment points out a potential issue with the novelty of the proposed method, noting that it seems to be similar to existing studies, except for a change in the task and reward function. It acknowledges the importance of the finding that IRL is effective in text summarization but suggests that the contribution is minor if this is the only difference. The comment also references specific studies, which could help the authors situate their work within the existing literature. However, the comment lacks actionable suggestions or guidance on how the authors might enhance the contribution or differentiate their work from previous studies. While it identifies a potential weakness, it does not provide a clear path for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method appears to be similar to existing studies, with only minor differences in task and reward function. It suggests that the contribution is small if this is the only difference. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern or enhance the contribution. Without specific guidance or suggestions on how to differentiate the work or improve its contribution, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and its similarity to existing studies, specifically mentioning references to Shi et al., 2018, and Ghosh et al., 2021. It highlights the lack of significant difference between the proposed method and existing work, except for the change in task and reward function. However, the comment does not specify which part of the paper discusses these comparisons, making it weakly grounded. The comment is specific in identifying the issue of a small contribution due to minor differences, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is similar to existing studies, with only minor differences in task and reward function. The reviewer supports this claim by referencing specific studies (Shi et al., 2018; Ghosh et al., 2021) and providing a rationale for why the contribution might be considered small. However, the comment lacks detailed comparisons or specific examples from the referenced studies to fully substantiate the claim. While the references provide a basis for the critique, the absence of detailed evidence makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects of the paper could be improved. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not specify which parts of the paper are being evaluated for novelty or how the dataset fits into the overall contribution. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, suggesting that the main contribution is a new IT-related dataset. However, the comment lacks specific examples, detailed reasoning, or references to substantiate this claim. Without concrete evidence or a clear explanation of how the novelty is perceived as limited, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the novelty of the paper is limited, primarily due to the focus on a new IT-related dataset. While it identifies a potential issue with the paper's contribution, it lacks specific suggestions or guidance on how the authors might enhance the novelty or address the perceived limitation. Without actionable feedback or detailed advice, the comment provides only a vague indication of a problem without offering a path for improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. This feedback gives a clear and direct action for the authors to take, namely to conduct an ablation study on query embedding. The suggestion is concrete, as it specifies exactly what needs to be added to the paper to improve it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests the inclusion of an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, it does not specify which part of the paper currently lacks this ablation study, making it weakly grounded. The comment is specific in its request for an ablation study related to query embedding, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, the comment does not provide any specific reasoning, examples, or references to support why an ablation study is necessary or how it would benefit the paper. Without additional context or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of an ablation study related to query embedding. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by conducting an ablation study that would provide insights into the significance and impact of the query embedding component. By addressing this point, the authors can gain a deeper understanding of their model and its components, potentially leading to improvements in the paper. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying what aspects of the contribution are considered marginal or how the authors might address this perception. Without concrete suggestions or explicit actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or tables where the contribution is discussed. Additionally, it does not provide specific details on what aspects of the contribution are considered marginal or how they compare to previous works. This lack of grounding and specificity makes it difficult for the authors to identify and address the issue effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal compared to previous works, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the claim remains unverifiable, as it lacks the necessary support to help the authors understand or address the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper is marginal compared to previous works, but it does not provide any specific details or examples to support this claim. It lacks actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of how to address the perceived lack of contribution. Without specific guidance or constructive criticism, the comment does not assist the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying which aspects of the contribution are considered marginal or how the authors might address this perception. Without concrete feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or tables where the contribution is discussed. Additionally, it does not provide specific details or examples to support the claim, making it difficult for the authors to identify and address the issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal compared to previous works, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the claim remains unverifiable. The authors are left without a clear understanding of what aspects of the contribution are considered marginal or how it compares to previous works. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal compared to previous works, but it does not provide any specific details, examples, or reasoning to support this claim. Without actionable feedback or constructive suggestions, the authors are left without a clear understanding of how to address the perceived lack of contribution. The comment lacks specificity and does not offer a path for improvement, making it not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying which aspects of the contribution are considered marginal or how the authors might address this perception. Without concrete feedback or explicit instructions, the authors are left without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion that the contribution is marginal compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. While it raises a valid point, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this question should lead to further analysis, clarification, or a specific action by the authors. Without any actionable advice or suggestion, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the attribution of the loss of performance, but without clear grounding, the authors may struggle to identify the exact section or context being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. While it raises a valid point, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or what specific aspects of the analysis could be improved. As a result, the comment is not particularly helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the paper\\'s motivation regarding overoptimization and its evaluation approach, which focuses on calibration and human evaluation. The reviewer suggests that the paper should directly evaluate overoptimization by not using early stopping and discuss the benefits of this approach. This feedback provides a clear and explicit action for the authors to take, which is to conduct an evaluation without early stopping and discuss the tradeoffs. The suggestion is concrete, as it specifies the exact action and its potential benefits. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s motivation regarding overoptimization and the evaluation approach, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the evaluation of overoptimization and the discussion of the benefits of not using early stopping. The comment provides clear guidance on what the authors should consider and address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the evaluation approach of the paper, suggesting that it does not directly address overoptimization as motivated. The reviewer references \"AlignProp\" as a current work that gets away with overoptimization through early stopping, implying that this aspect should be discussed in the paper. The comment provides a logical reasoning by pointing out the discrepancy between the motivation and the evaluation approach, and suggests a specific way to address it by evaluating without early stopping. However, the comment could be strengthened by providing more detailed examples or references to support the claim about overoptimization and early stopping. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s motivation regarding overoptimization and its evaluation approach, which focuses on calibration and human evaluation. It suggests that the paper should directly evaluate overoptimization by not using early stopping and discusses the benefits of this approach. The comment provides a clear and actionable suggestion for the authors to consider, which could significantly enhance the paper by addressing a key issue in the evaluation methodology. However, the comment could be more helpful if it included specific examples or guidance on how to implement this evaluation without early stopping. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis demonstrating the equivalence of the proposed TW model to TR, and provide a discussion justifying the use of TW over TR. While the comment implies that these additions should be made, it does not explicitly instruct the authors to do so. The action is concrete, as it specifies the type of analysis and discussion needed, but it is stated implicitly. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the proposed TW model and suggests that it is equivalent to TR, providing a specific analysis and a request for a discussion justifying TW over TR. However, it does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the equivalence of TW and TR and the justification for TW. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed TW model is equivalent to TR, providing a specific analysis to support this claim. The reviewer explains that by representing the core tensor C as a TR and fusing it with the cores G_n, a TR representation equivalent to the TW model can be achieved. This detailed explanation offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing references or examples of similar analyses in the literature, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the authors should include an analysis demonstrating this equivalence and discuss why TW might be preferable over TR. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the relationship between the two models and justifying the use of TW. However, the comment could be more helpful if it included additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the transferability of their toolset and experiment to create a general toolset for all tasks. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but inferred, and the suggestion is concrete, as it specifies the type of experiment that could be conducted. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the transferability of the toolset, specifically mentioning that the toolset for the VQA task and the toolset for the reasoning task are not the same. This provides a clear indication of the specific aspect of the paper being discussed, making it fully grounded. The comment also suggests an action for the authors to experiment with creating a general toolset for all tasks, which adds specificity to the feedback. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the transferability of the toolset should be discussed, noting that the toolset for the VQA task and the reasoning task are different. The reviewer proposes an experiment to create a general toolset for all tasks. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the current toolsets are not transferable. The suggestion for an experiment is a logical step, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the transferability of the toolset across different tasks, specifically noting that the toolset for the VQA task and the reasoning task are not the same. It suggests that the authors should discuss this aspect and experiment to create a general toolset for all tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and improve the applicability of their toolset. However, the comment could be more helpful if it included additional guidance on how to approach the experiment or what specific aspects to consider when creating a general toolset. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to implement this evaluation or specify how to conduct it. The action is implicit but concrete, as the authors can infer the need for additional experiments and understand the rationale behind them. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiple Random Orders,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. The comment suggests a baseline to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which could help the authors understand the potential benefits of such an evaluation. However, the comment lacks specific examples or references to support the claim, such as studies that have successfully used this approach or the expected outcomes of such evaluations. This makes it challenging for the authors to fully understand and implement the suggestion without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the model\\'s performance. It suggests using multiple random feature orders to assess the impact of feature order variability, which could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. This feedback is specific and offers a concrete method for the authors to enhance their experimental design, making it highly helpful. By addressing this point, the authors can gain valuable insights into the robustness and generalizability of their findings. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to implement this evaluation or specify how to conduct it. The action is implicit but concrete, as the authors can infer the need for additional experiments and understand the rationale behind them. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It provides a clear rationale for this approach, which could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment does not explicitly mention a specific section or part of the paper where this evaluation should be included, making it weakly grounded. The suggestion is specific in terms of the methodology it proposes, but without explicit grounding, the authors may struggle to pinpoint where to implement this change. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which could help the authors understand the potential benefits of such an evaluation. However, the comment lacks specific examples or references to support the claim, such as studies that have successfully used this approach or the expected outcomes of such evaluations. This makes it challenging for the authors to fully understand and implement the suggestion without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the related work section is lacking, specifically mentioning the omission of lexically constrained decoding methods. It suggests that these methods should be included both in the related work section and as baselines for comparison. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to improve the draft. The comment is explicit and concrete, offering a specific direction for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the omission of lexically constrained decoding methods both in the related work section and as baselines for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is lacking, specifically mentioning the omission of lexically constrained decoding methods. However, the comment does not provide any specific references or examples of these methods, nor does it explain why their inclusion would be beneficial. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the related work section of the paper, specifically pointing out the omission of lexically constrained decoding methods. It suggests that these methods should be included both in the related work section and as baselines for comparison. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. By highlighting the missing references and suggesting their inclusion, the comment offers valuable guidance for enhancing the comprehensiveness and relevance of the related work section. However, it could be more helpful if it provided examples of specific lexically constrained decoding methods or explained why their inclusion is important. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, which should be included for a more comprehensive comparison. This provides a clear and explicit action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be added to improve the draft, ensuring they have a concrete understanding of how to address the feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that important baseline models and datasets are missing, which affects the comprehensiveness of the comparison. It explicitly mentions two specific models, SimVLM and OFA, which provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed by including these models in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It supports this claim by explicitly mentioning two specific models, SimVLM and OFA, which should be included for a more comprehensive comparison. This provides a clear and specific reference to the missing elements, making the claim mostly verifiable. However, the comment could be strengthened by providing additional examples or explaining why these models are crucial for the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the comparison is not comprehensive due to the absence of important baseline models and datasets. It specifically mentions two models, SimVLM and OFA, which should be included for a more comprehensive comparison. This feedback is clear and actionable, providing the authors with specific models to consider adding to their analysis. By addressing this point, the authors can enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to integrate these models into the comparison or discussed the potential impact of including them. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present new data, only derivative data from existing datasets. This feedback highlights a discrepancy between the paper\\'s framing and its content, which could be disappointing to readers expecting new data. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the paper. It lacks specific suggestions for what the authors could do to enhance the paper, such as suggesting ways to present the existing data or discussing its potential uses. As a result, the authors are left without clear actions to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the framing of the manuscript as a dataset paper, noting that it does not present new data but rather derivative data from existing datasets. This provides a clear critique of the paper\\'s content. However, the comment does not specify which part of the manuscript should address this issue, such as the introduction or the dataset section, making it weakly grounded. The comment is specific in detailing what is disappointing about the paper, namely the lack of new data, but it does not provide guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present new data, only derivative data from existing datasets. This claim is supported by logical reasoning, as it highlights a discrepancy between the paper\\'s framing and its content. However, the comment lacks specific examples or references to the existing datasets used, which would provide more detailed evidence for the claim. This makes the comment somewhat verifiable, as it provides a logical basis but requires additional information to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant discrepancy between the framing of the manuscript as a dataset paper and the content it actually presents. It points out that the paper does not introduce new data but rather provides derivative data, specifically 3D pose estimates from existing datasets. This feedback is clear and actionable, as it highlights a potential source of disappointment for readers who were expecting new, potentially useful data sources. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue, such as discussing the implications of using derivative data or suggesting ways to enhance the paper\\'s value. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification or improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present new data, only derivative data from existing datasets. This feedback highlights a discrepancy between the paper\\'s framing and its content, which could be disappointing to readers. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve the paper. Without specific actions or recommendations, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the framing of the manuscript as a dataset paper, noting that it does not present new data but rather derivative data from existing datasets. This provides a clear critique of the paper\\'s content. However, the comment does not specify which part of the manuscript should address this issue, such as the introduction or the dataset section, making it weakly grounded. The comment is specific in detailing what is disappointing about the paper, namely the lack of new data, but it lacks guidance on how the authors might address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present new data, only derivative data from existing datasets. This claim is supported by logical reasoning, as it highlights a discrepancy between the paper\\'s framing and its content. However, the comment lacks specific examples or references to the existing datasets used, which would provide more detailed evidence for the claim. This makes the comment somewhat verifiable, as it provides a logical basis but requires additional information to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant discrepancy between the framing of the manuscript as a dataset paper and the content it actually presents. It points out that the paper does not introduce new data but rather provides derivative data from existing datasets, which could be disappointing to readers expecting new, potentially useful data sources. This feedback is clear and highlights a critical issue that the authors need to address"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the learning rate schedules are problematic or how they relate to the authors\\' critique. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence or references to substantiate the claim that the authors\\' critique is unfounded. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any constructive feedback or suggestions for improvement. It lacks clarity on how the authors might address this critique or what specific aspects of their analysis could be strengthened. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this issue or improve their analysis. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the learning rate schedules are problematic or how they relate to the authors\\' critique. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence or reasoning to substantiate the claim that the authors\\' critique is unfounded. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any constructive feedback or suggestions for improvement. It lacks clarity on how the authors might address this critique or what specific aspects of their analysis could be strengthened. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the focus of the quantitative and qualitative analysis, which is primarily on the comparison between AE and diffusion. It suggests that the authors should delve deeper into the analysis of the results themselves, particularly in terms of what visualizations can teach us about crucial elements for detecting a chair, such as the handle's consistency across different chairs. While the comment implies that the authors should expand their analysis to include these aspects, it does not provide explicit instructions or concrete steps on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the specific areas to explore and how to approach them. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the quantitative and qualitative analysis, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it highlights the need for a deeper analysis of the results themselves, particularly in terms of what visualizations can teach us about crucial elements for detecting a chair, such as the handle's consistency across different chairs. The comment provides clear guidance on what aspects of the analysis could be expanded upon, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the focus of the quantitative and qualitative analysis, suggesting that it is primarily on the comparison between AE and diffusion rather than on the analysis of the results themselves. The reviewer raises specific questions about the visualizations, such as the consistency of the handle across different chairs and its importance as a feature. While the comment highlights areas for improvement, it lacks specific examples or references to support the claim that the analysis is too focused on AE and diffusion. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential imbalance in the focus of the quantitative and qualitative analysis, which is primarily on the comparison between AE and diffusion. It suggests that the authors should delve deeper into the analysis of the results themselves, particularly in terms of what visualizations can teach us about crucial elements for detecting a chair, such as the handle's consistency across different chairs. The comment raises important questions about the analysis's depth and encourages the authors to explore these aspects further. However, it lacks specific guidance or suggestions on how to conduct this deeper analysis or what specific elements should be examined. While the feedback is insightful, it could be more helpful with additional direction or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential imbalance in the focus of the quantitative and qualitative analysis, suggesting that it is primarily on the comparison between AE and diffusion rather than on the analysis of the results themselves. The reviewer raises specific questions about what visualizations can teach us about crucial elements for detecting a chair, such as the handle's consistency across different chairs. While the comment implies that the authors should expand their analysis to include these aspects, it does not provide explicit instructions or concrete steps on how to conduct this deeper analysis. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the quantitative and qualitative analysis, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it highlights the need for a deeper analysis of the results themselves, particularly in terms of what visualizations can teach us about crucial elements for detecting a chair, such as the handle's consistency across different chairs. The comment provides clear guidance on what aspects of the analysis could be expanded upon, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the focus of the quantitative and qualitative analysis, suggesting that it is primarily on the comparison between AE and diffusion rather than on the analysis of the results themselves. The reviewer raises specific questions about the visualizations, such as the consistency of the handle across different chairs and its importance as a feature. While the comment highlights areas for improvement, it lacks specific examples or references to support the claim that the analysis is too focused on AE and diffusion. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential imbalance in the focus of the quantitative and"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific correction regarding the wording in the beginning of Section 2.2, suggesting that it should be \"at most\" instead of \"at least.\" It also explains the reasoning behind this correction by detailing the worst-case scenario and how the ratio would behave in different cases. This feedback is explicit and provides concrete guidance on how to correct the draft, ensuring that the authors know exactly what needs to be changed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear correction regarding the wording of a statement and explains the reasoning behind it, including the worst-case scenario and how the ratio behaves in different cases. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual correction regarding the wording in the beginning of Section 2.2, suggesting that \"at most\" should be used instead of \"at least.\" The reviewer provides a logical explanation of why this correction is necessary, detailing the worst-case scenario and how the ratio behaves in different cases. This reasoning is clear and supports the claim, making the comment fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable correction regarding the wording in Section 2.2, suggesting that the phrase \"at most\" should be used instead of \"at least.\" It also offers a detailed explanation of the reasoning behind this correction, including a discussion of the worst-case scenario and how the ratio behaves in different cases. This feedback is clear and constructive, allowing the authors to make a precise and meaningful improvement to their draft. The comment is highly helpful as it empowers the authors to enhance the accuracy and clarity of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the notation \"D^{alpha}_{x}\" in Theorem.1, asking whether it denotes the derivatives of the probabilistic measure \\\\mu. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors can infer that they need to clarify the notation, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking what \"D^{alpha}_{x}\" denotes and whether it represents the derivatives of the probabilistic measure \\\\mu. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the notation \"D^{alpha}_{x}\" in Theorem.1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the notation \"D^{alpha}_{x}\" in Theorem.1, asking whether it denotes the derivatives of the probabilistic measure \\\\mu. This feedback is somewhat helpful as it identifies a potential area of confusion or lack of clarity in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their notation. While it points out a specific point of confusion, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing element in Figure 2, specifically the proper expression for the third face image. This provides a clear and direct action for the authors to take, which is to add the missing expression. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the proper expression for the third face image. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the expression for the third face image in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual observation seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting the absence of a proper expression for the third face image. This feedback is clear and actionable, as it directly points out a missing element that the authors can address to improve the clarity and completeness of their figure. By providing this specific guidance, the comment empowers the authors to make a concrete improvement to their draft. However, it could be more helpful if it offered suggestions on what the proper expression might be or how to present it effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit suggestion, providing a clear action for the authors to take. However, it lacks concrete details on how to implement this comparison or what specific aspects should be considered. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the comparison should be focused on or how the example should be integrated into the paper. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any justification or reasoning for why this comparison would be beneficial or how it would enhance the paper. Without specific examples or detailed explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is a specific and actionable suggestion that could help the authors demonstrate the effectiveness of their proposed model against a well-known baseline. However, the comment lacks depth and does not provide further guidance on how to implement this comparison or what specific aspects should be focused on. While it offers a clear direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit suggestion, providing a clear action for the authors to take. However, the comment lacks detailed guidance on how to implement this comparison or what specific aspects should be considered. While the action is explicit, the lack of concrete details on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the comparison should be focused on or how the example should be integrated into the paper. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any justification or reasoning for why this comparison would be beneficial or how it would enhance the paper. Without specific examples or detailed explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is a specific and actionable suggestion that could help the authors demonstrate the effectiveness of their proposed model against a well-known baseline. However, the comment lacks depth and does not provide further guidance on how to implement this comparison or what specific aspects should be focused on. While it offers a clear direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as mostly helpful, consistent with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit suggestion, providing a clear action for the authors to take. However, the comment lacks detailed guidance on how to implement this comparison or what specific aspects should be considered. While the action is explicit, the lack of concrete details on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that for the code summarization task and the code search task, the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. This is an explicit action, as it clearly states what the authors need to do to address the concern. However, it does not provide detailed guidance on how to achieve this, such as specific methods or considerations for balancing the dataset sizes. While the action is explicit, the lack of concrete details on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"code summarization task\" and the \"code search task,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the dataset size of Vault and CSN should be the same to demonstrate the superiority of Vault in terms of data quality. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that for the code summarization task and the code search task, the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the evaluation. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, namely that the dataset sizes for Vault and CSN should be the same to fairly demonstrate the superiority of Vault in terms of data quality. This feedback is clear and actionable, as it provides a concrete suggestion for improving the experimental design. By ensuring that the dataset sizes are equal, the authors can better isolate and evaluate the impact of data quality on their results. However, the comment could be more helpful if it included additional guidance on how to achieve this balance or if it discussed the potential implications of this change on the overall evaluation. Despite this, the feedback is mostly helpful as it directs the authors toward a specific improvement that can enhance the validity of their experimental findings.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific terms that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It explicitly instructs the authors to explain these terms more carefully, providing clear guidance on what needs to be addressed. The comment is explicit in its request and concrete in terms of what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies specific terms that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" However, it does not specify which sections or parts of the paper these terms appear in, making it difficult for the authors to pinpoint the exact areas that need improvement. While the authors might have an idea of where these terms are used, the comment lacks full grounding. It is specific about what needs to be addressed regarding the explanation of these terms but does not provide detailed guidance on how to improve them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some important concepts are not explained well, specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence or detailed reasoning to justify why these terms are not explained well or how they impact the paper. Without specific examples or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity, particularly in explaining important concepts such as \"action-repeat\" and \"dithering phenomenon.\" By pointing out these terms that keep appearing in the paper without proper explanation, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to better explain these concepts or provided examples of how they are used in the paper. Overall, the feedback is somewhat helpful as it highlights areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. It also recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. This feedback provides a clear and explicit action for the authors to consider, along with a rationale for why this approach might be beneficial. The suggestion is concrete, as it outlines specific steps the authors could take to improve their method. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. It also recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the comment provides a specific suggestion for improvement, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. The reviewer provides a rationale for why this approach might be beneficial, stating that it avoids discretization issues that could arise from decoding. However, the comment lacks specific examples, references, or detailed explanations to fully substantiate the claim. While the suggestion is logical, the absence of concrete evidence or references makes it somewhat verifiable. The authors would need to further explore the suggestion to fully understand its implications, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the methodology by proposing an alternative approach to the current method. It suggests creating an instruction embedding from the state encoding and directly passing it to the executor, rather than generating text and then re-encoding it. Additionally, it recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. This feedback is clear and offers a concrete way to enhance the robustness and effectiveness of the method, potentially leading to better results. By providing a detailed and constructive suggestion, the comment is highly helpful for the authors in refining their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. It also recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the comment provides a clear suggestion for improvement, it lacks specific guidance on how to implement this approach or what specific changes to make. The authors are left with a general idea of what could be done but without detailed instructions on how to execute the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. It also recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the comment provides a specific suggestion for improvement, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method, proposing to create an instruction embedding from the state encoding and directly passing it to the executor. It also recommends adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the suggestion is logical and provides a rationale for why it might be beneficial, it lacks specific examples, references, or detailed explanations to fully substantiate the claim. The authors would need to further explore the suggestion to understand its implications fully. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the methodology by proposing an alternative approach."}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the proposed model is not significant. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their model. The comment lacks actionable details, such as recommending ways to enhance the model\\'s novelty or providing examples of how to differentiate it from existing work. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the novelty of the proposed model is not significant. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model lack novelty or how it could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not provide any specific reasoning, examples, or suggestions on how the authors might enhance the novelty of their work. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their model lack novelty or how they might address this issue. This lack of specificity and actionable advice makes the comment unhelpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. It points out that the accuracy measure may not be a good indicator of quality in this case, as it could be influenced by the imbalance in class representation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as proposing alternative measures or adjustments to the dataset. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the dataset, namely the proportion of each class used for the pool subset, which makes the dataset easier rather than harder. It provides a specific example of the imbalance in class representation, such as the low number of observations for the digit \"9\" compared to \"6\" and \"7,\" and suggests that accuracy may not be a good measure of quality in this case. However, the comment does not explicitly mention which part of the paper discusses this dataset or the accuracy measure, making it weakly grounded. The comment is specific in detailing the issue with the dataset\\'s class distribution and its impact on accuracy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class makes the dataset easier rather than harder. The reviewer provides a specific example of the imbalance in class representation, such as the low number of observations for the digit \"9\" compared to \"6\" and \"7,\" and explains how this affects the accuracy measure. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the example provides some support, the absence of additional evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. It provides a specific example of the imbalance in class representation, such as the low number of observations for the digit \"9\" compared to \"6\" and \"7,\" and explains how this affects the accuracy measure. This feedback is somewhat helpful as it identifies a potential issue with the dataset that could impact the evaluation of the model\\'s performance. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. It provides a specific example of the imbalance in class representation and explains how this affects the accuracy measure. However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or improve their analysis. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the dataset, namely the proportion of each class used for the pool subset, which is suggested to make the dataset easier rather than harder. It provides a specific example of the imbalance in class representation, such as the low number of observations for the digit \"9\" compared to \"6\" and \"7,\" and explains how this affects the accuracy measure. However, the comment does not explicitly mention which part of the paper discusses this dataset or the accuracy measure, making it weakly grounded. The comment is specific in detailing the issue with the dataset\\'s class distribution and its impact on accuracy, but without clear grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. The reviewer provides a specific example of the imbalance in class representation, such as the low number of observations for the digit \"9\" compared to \"6\" and \"7,\" and explains how this affects the accuracy measure. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the example provides some support, the absence of additional evidence or references makes the claim somewhat verifiable."}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main contribution of the paper, suggesting that the authors clarify the strategic aspects of prediction. It also asks for clarification on the \"true\" payoff in Table 1 and references a work by Vapnik. The reviewer suggests looking into the work by Vapnik and notes a similarity with the discrepancy p alongside x,y. While the comment implies that the authors should address these points, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"Table 1\" and references a work by Vapnik, which helps the authors identify the specific parts of the paper being addressed. However, it lacks full grounding because it does not explicitly mention which section or part of the paper is being discussed. The comment is specific in its request for clarification on the \"true\" payoff in Table 1 and references a work by Vapnik, providing some guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point begins with an agreement that \"prediction is not done in isolation,\" but then questions the main contribution of the paper regarding the \"task of prediction may have strategic aspects.\" The reviewer raises specific questions about the \"true\" payoff in Table 1 and references a work by Vapnik, suggesting a similarity with the discrepancy p alongside x,y. While the comment includes some reasoning and references, it lacks detailed justification or examples to fully substantiate the claim about the main contribution. The questions and references provide some context but do not fully support the claim, making the comment somewhat verifiable. Therefore, the feedback is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the reviewer's agreement with the paper's perspective on prediction not being done in isolation but questions the main contribution regarding the strategic aspects of the task. It raises specific questions about the 'true' payoff in Table 1 and suggests looking into the work by Vapnik. The comment also notes a potential similarity with the discrepancy p alongside x,y. While it identifies areas for clarification and suggests references, it lacks detailed guidance or actionable steps for the authors to improve their draft. The feedback provides some insight but could be more helpful with more specific suggestions or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises questions about the main contribution of the paper and the \"true\" payoff in Table 1. It also references a work by Vapnik and suggests a similarity with the discrepancy p alongside x,y. However, the comment does not provide explicit guidance or actionable steps for the authors to address these points. The questions and references are more of an inquiry than a direct instruction, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"Table 1\" and references a work by Vapnik, which helps the authors identify the specific parts of the paper being addressed. However, it lacks full grounding because it does not explicitly mention which section or part of the paper is being discussed. The comment is specific in its request for clarification on the \"true\" payoff in Table 1 and references a work by Vapnik, providing some guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point begins with an agreement but then questions the main contribution of the paper regarding the strategic aspects of prediction. It raises specific questions about the \"true\" payoff in Table 1 and references a work by Vapnik, suggesting a similarity with the discrepancy p alongside x,y. While the comment provides some reasoning and references, it lacks detailed justification or examples to fully substantiate the claim about the main contribution. The questions and references offer some context but do not fully support the claim, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the reviewer's agreement with the paper's perspective on prediction not being done in isolation but questions the main contribution regarding the strategic aspects of the task. It raises specific questions about the 'true' payoff in Table 1 and references a work by Vapnik, suggesting a similarity with the discrepancy p alongside x,y. While the"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training, given that the proposed method focuses solely on domain-alignment methods. While the comment implies an action, it does not provide specific guidance on which self-training method to explore or how to integrate it into the existing framework. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, given that the proposed method focuses solely on domain-alignment methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its recommendation to explore another UDA method, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method focuses solely on domain-alignment methods and recommends exploring another UDA method based on self-training. However, the comment does not provide specific examples or references to existing UDA methods that could be explored. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. As a result, the claim is borderline verifiable, as it provides some direction but lacks sufficient evidence or reasoning to fully substantiate the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, which focuses solely on domain-alignment methods within the context of unsupervised domain adaptation (UDA). It suggests exploring another UDA method based on self-training, which is a relevant and constructive suggestion for expanding the scope of the study. However, the comment lacks specific guidance or examples of self-training methods that could be explored, which would make it more actionable. While it provides a direction for improvement, the feedback could be more helpful with additional details or references. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, given that the proposed method focuses solely on domain-alignment methods. While the suggestion is explicit, it lacks concrete guidance on which specific self-training method to explore or how to integrate it into the existing framework. The authors are left with a clear action to take but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, given that the proposed method focuses solely on domain-alignment methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its recommendation to explore another UDA method, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method focuses solely on domain-alignment methods and recommends exploring another UDA method based on self-training. However, the comment lacks specific examples or references to existing UDA methods that could be explored, making it difficult for the authors to understand the basis of the suggestion. The claim is somewhat verifiable as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, which focuses solely on domain-alignment methods within the context of unsupervised domain adaptation (UDA). It suggests exploring another UDA method based on self-training, which is a relevant and constructive suggestion for expanding the scope of the study. However, the comment lacks specific guidance or examples of self-training methods that could be explored, which would make it more actionable. While it provides a direction for improvement, the feedback could be more helpful with additional details or references. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer asks whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. While the comment highlights an issue, it does not provide explicit guidance or suggestions on how the authors should address it. The authors are left to infer that they might need to investigate or clarify these pathologies, but the lack of concrete actions or suggestions makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, particularly the high-accuracy spikes in low confidence regimes, and questions whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. This provides clear guidance on what aspect of the reliability diagrams needs further exploration or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reliability of the proposed methods based on the accuracy vs confidence plots (reliability diagrams) in Figure 1. It highlights specific pathologies, such as high-accuracy spikes in low confidence regimes, and asks whether these are due to dataset pathologies or variance in the methods. While the comment raises a valid concern, it lacks specific examples or references to support the claim that these pathologies are indicative of dataset issues or method variance. The reasoning is somewhat verifiable, as it provides a logical basis for the concern, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reliability diagrams, noting that they do not support the proposed methods and exhibit notable pathologies, such as high-accuracy spikes in low confidence regimes. It raises a critical question about whether these pathologies are due to dataset issues or variance in the proposed methods. This feedback is valuable as it highlights a potential weakness in the evaluation of the proposed methods and prompts the authors to investigate and address this issue. However, the comment could be more helpful if it provided suggestions on how to diagnose or mitigate these pathologies or offered guidance on how to improve the reliability diagrams. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a concern with the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer asks whether these pathologies are due to dataset issues or variance in the proposed methods. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern or investigate the root cause of the pathologies. The feedback lacks actionable steps or specific recommendations, leaving the authors with a general direction but no clear path forward. Therefore, the comment is rated as barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, particularly the high-accuracy spikes in low confidence regimes, and questions whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. This provides clear guidance on what aspect of the reliability diagrams needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reliability of the proposed methods based on the accuracy vs confidence plots (reliability diagrams) in Figure 1. It highlights specific pathologies, such as high-accuracy spikes in low confidence regimes, and asks whether these are due to dataset pathologies or variance in the methods. While the comment raises a valid concern, it lacks specific examples or references to support the claim that these pathologies are indicative of dataset issues or method variance. The reasoning is somewhat verifiable, as it provides a logical basis for the concern, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the limitations of the paper's evaluation, specifically regarding the potential for more advanced attacks and the lack of consideration for backdoor removal methods. It highlights the need for the authors to address these issues by evaluating the robustness of their approach against more advanced attacks and discussing the state-of-the-art (SOTA) methods for backdoor removal. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to implement these changes or what specific aspects to focus on. The authors are left with a general understanding of what needs to be addressed but without concrete steps on how to proceed. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the paper's evaluation of backdoor attacks and the potential for more advanced attacks, such as fine-tuning on a partial subset of D. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it details the issue of the customer not being able to verify misbehaviors due to the potential presence of the backdoor in the partial subset of D. Additionally, it points out the lack of discussion on SOTA methods for backdoor removal. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the robustness of the paper's evaluation, specifically regarding the potential for more advanced attacks and the lack of consideration for backdoor removal methods. The comment provides a logical reasoning by highlighting the possibility of the attacker fine-tuning on a partial subset of D, which could still contain the poisoned data, thus hindering the customer's ability to verify misbehaviors. However, the comment lacks specific examples or references to support the claim about the robustness of the evaluation or the state-of-the-art (SOTA) methods for backdoor removal. This makes the claim somewhat verifiable, as it provides a reasonable basis for concern but requires more detailed evidence or examples to fully substantiate the argument.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical limitation in the paper's evaluation, specifically the potential for more advanced attacks beyond those considered in the study. It highlights the possibility of the attacker fine-tuning on a partial subset of D, which could still contain the poisoned data, thereby hindering the customer's ability to verify misbehaviors. The comment also points out the lack of discussion on state-of-the-art (SOTA) methods for backdoor removal, which is an important aspect that should be addressed. While the comment effectively identifies areas for improvement, it could be more helpful by providing specific suggestions or examples of advanced attacks or SOTA methods to consider. Overall, the feedback is mostly helpful as it directs the authors' attention to significant gaps in their evaluation and encourages them to expand their analysis, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the use of the original GCN (Kipf and Welling) and the paper\\'s approach, which uses the original adjacency matrix without explanation or ablation study. The reviewer wonders if there is a reason for not using the conventional graph convolutional operation. While the comment highlights a potential issue, it does not explicitly instruct the authors to address it or provide guidance on how to incorporate the conventional operation or conduct an ablation study. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly explain or justify their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the original GCN (Kipf and Welling) and contrasts it with the paper\\'s approach, which uses the original adjacency matrix without explanation or ablation study. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason behind not using the conventional graph convolutional operation and whether there is a justification for this choice. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the original GCN (Kipf and Welling) in the paper, noting that it uses the original adjacency matrix without explanation or ablation study. The reviewer expresses curiosity about the reason for not using the conventional graph convolutional operation. While the comment raises a valid point about the methodology, it lacks specific reasoning or references to support the claim that the conventional operation would be more appropriate. The absence of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to further explore and address the reasoning themselves.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the methodology used in the paper and the conventional approach in the field, specifically the use of the original GCN (Kipf and Welling) versus the paper's use of the original adjacency matrix without explanation or ablation study. This feedback highlights a potential area for improvement, as it questions the rationale behind the choice of methodology and suggests that an explanation or comparison with the conventional approach could be beneficial. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending an ablation study or explaining the reasons behind the choice. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between the use of the original GCN (Kipf and Welling) and the paper\\'s approach, which uses the original adjacency matrix without explanation or ablation study. The reviewer wonders if there is a reason behind not using the conventional graph convolutional operation. While the comment highlights a potential issue, it does not explicitly instruct the authors to address it or provide guidance on how to investigate or justify their choice. The action is implicit and somewhat vague, as the authors need to infer that they should explore and possibly explain their methodology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the original GCN (Kipf and Welling) and contrasts it with the paper\\'s approach, which uses the original adjacency matrix without explanation or ablation study. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason behind not using the conventional graph convolutional operation and whether there is a justification for this choice. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the original adjacency matrix in the paper, contrasting it with the conventional graph convolutional operation (GCN) used by Kipf and Welling. The reviewer expresses curiosity about the reason for not using the conventional operation and suggests that an explanation or ablation study might be necessary. While the comment raises a valid point, it lacks specific reasoning or references to support the claim that the conventional operation would be more appropriate. The absence of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to further explore and address the reasoning themselves.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the methodology used in the paper and the conventional approach in the field, specifically the use of the original GCN (Kipf and Welling) versus"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the availability of a link for WMT\\'14 training corpora, which is not provided despite a link for WMT\\'15 corpora. This implies that the authors should provide a link for the WMT\\'14 corpora as well. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to implement this action. The action is implicit and somewhat vague, as the authors need to infer that they should add a link for WMT\\'14 corpora. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the availability of a link for WMT\\'14 training corpora, which is not provided despite a link for WMT\\'15 corpora. This implies that the authors should address this inconsistency. However, the comment does not specify which part of the paper this issue pertains to, such as a section discussing data sources or references. The authors can infer that it relates to the data or references section, but this inference is not direct. The comment is specific in pointing out the absence of a link for WMT\\'14 corpora, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the availability of a link for WMT\\'14 training corpora, which is not provided despite a link for WMT\\'15 corpora. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the availability of a link for WMT\\'14 training corpora, which is not provided despite a link for WMT\\'15 corpora. This feedback is somewhat helpful as it points out a potential inconsistency in the paper that the authors may need to address. However, the comment does not provide any suggestions or guidance on how to resolve this issue, such as whether the authors should include the link or clarify why it is missing. To be more helpful, the comment could offer additional context or suggest a solution. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to select other hyperparameters. This provides a clear and direct action for the authors to take, which is to identify and specify these bounds. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the upper and lower bounds for adaptive matrices A_t and B_t, which need to be known to select other hyperparameters. However, it does not explicitly mention which part of the paper discusses these matrices, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the bounds and hyperparameters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim that \"upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to pick other hyperparameters.\" However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is necessary or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the need for upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. This feedback is clear and actionable, as it points out a potential gap in the methodology that the authors need to address. By highlighting this requirement, the comment provides the authors with a concrete area to investigate and potentially improve their work. However, the comment could be more helpful if it offered suggestions on how to determine or set these bounds or discussed their implications for the study. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their methodology that requires attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this issue. While the comment implies that the authors should include experimental results on the PDBbind dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these results or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this issue. However, the comment does not specify which part of the paper discusses the novelty or where the experimental results are presented, making it weakly grounded. The suggestion to include results on the PDBbind dataset is specific, but without clear grounding, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand which techniques are being referred to or why they are considered unoriginal. The suggestion to include experimental results on the PDBbind dataset is a logical suggestion but lacks the necessary evidence or reasoning to fully substantiate the claim about the novelty. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this concern. While the comment identifies a weakness in the novelty of the work, it does not provide specific guidance or suggestions on how to enhance the novelty or what aspects of the PDBbind dataset could be particularly relevant. The feedback is somewhat helpful as it highlights an area for improvement but lacks detailed, actionable advice, leaving the authors with a general direction to consider rather than a concrete path forward. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this issue. While the comment implies that the authors should include experimental results on the PDBbind dataset, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these results. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this issue. However, the comment does not specify which part of the paper discusses the novelty or where the experimental results are presented, making it weakly grounded. The suggestion to include results on the PDBbind dataset is specific, but without clear grounding, the authors may struggle to identify where to make these changes. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which techniques are being referred to or why they are considered unoriginal. The suggestion to include experimental results on the PDBbind dataset is a logical suggestion but lacks the necessary evidence or reasoning to fully substantiate the claim about the novelty. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests considering experimental results on the PDBbind dataset to address this concern. While the comment identifies a weakness in the novelty of the work, it does not provide specific guidance or suggestions on how to enhance the novelty or what aspects of the PDBbind dataset could be particularly relevant. The feedback is somewhat helpful as it highlights an area for improvement but lacks detailed, actionable advice, leaving the authors with"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the results of comparing pairs of models would benefit from the addition of error bars. This feedback provides a clear and direct action for the authors to take, which is to include error bars to demonstrate that the differences between models are statistically significant. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding error bars to the results of comparing pairs of models to demonstrate statistical significance. However, it does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The comment is specific in its suggestion to include error bars, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to the results of comparing pairs of models would help demonstrate statistical significance. However, the comment does not provide any specific reasoning or evidence to support why error bars are necessary or how they would improve the analysis. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the necessity of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of results by recommending the inclusion of error bars when comparing pairs of models. This feedback is clear and directly addresses a potential weakness in the paper, which could enhance the robustness and clarity of the results. By suggesting a concrete method to demonstrate statistical significance, the comment offers valuable guidance for the authors to improve their draft. However, it could be more helpful if it explained why error bars are important or how they would impact the interpretation of the results. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"full state\" is not defined properly on page 2, line 81, and asks what is included in a full state. This feedback implies that the authors should clarify the definition of \"full state\" in their paper. While the action is implicit, it is clear and concrete, as it specifies exactly what needs to be addressed: providing a definition of \"full state.\" Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of \"full state\" and what is included in it. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the definition of \"full state\" in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, pointing out that the term \"full state\" is not defined properly on page 2, line 81. This is a valuable observation as it highlights a potential source of confusion for readers. However, the comment does not provide further guidance or suggestions on how the authors might clarify this definition or improve the explanation. While it directs the authors to an important area needing clarification, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the study is a good empirical analysis but points out a lack of new proposals for neural architecture encoding. While it highlights the importance of new initial proposals based on the analysis, it does not provide specific guidance or suggestions on how the authors might develop such proposals. The comment implies that the authors should consider adding new proposals, but it lacks concrete details on what these proposals might entail or how to implement them. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the study as a good empirical analysis but points out a lack of new proposals for neural architecture encoding. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what specific proposals are missing or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is a good empirical analysis but lacks new proposals for neural architecture encoding. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to existing literature or specific aspects of the analysis that could be improved. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the study as a good empirical analysis but points out a lack of new proposals for neural architecture encoding. It highlights the importance of new initial proposals based on the analysis, which is a valuable insight for the authors. However, the comment does not provide specific guidance or suggestions on how the authors might develop such proposals or what areas could be explored. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors are given a direction to consider new proposals, but the feedback could be more comprehensive and detailed to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the lack of empirical comparisons with existing algorithms and suggests that the paper should be evaluated as 'Marginally above the acceptance threshold.' It also points out that theoretical comparisons with existing algorithms have been done comprehensively and expresses anxiety about the practical usefulness of the algorithm due to potential communication costs. Additionally, it mentions that \\\\Delta_i, \\\\Delta_{med}, and \\\\nabla_i are not defined in the paper. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The suggestion to evaluate the paper as 'Marginally above the acceptance threshold' is implicit, and the comment on empirical comparisons and theoretical comparisons is somewhat vague. The lack of detailed instructions on how to improve the empirical comparisons or define the mentioned terms makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements such as \"p.5 \\\\Delta_i, \\\\Delta_{med} and \\\\nabla_i are not defined,\" and \"Theoretical comparison with existing algorithms has been done comprehensively.\" This allows the authors to accurately identify the parts of the paper being addressed. Additionally, the comment is specific because it details what needs to be addressed, including the lack of empirical comparisons with existing algorithms and the need for clarification on \\\\Delta_i, \\\\Delta_{med}, and \\\\nabla_i. The suggestion to evaluate the paper as \"Marginally above the acceptance threshold\" adds further specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of empirical comparisons with existing algorithms and suggests that the paper should be evaluated as \"Marginally above the acceptance threshold.\" The reviewer provides some justification by mentioning that theoretical comparisons with existing algorithms have been done comprehensively and expresses anxiety about the practical usefulness of the algorithm due to potential communication costs. However, the comment lacks specific examples or references to support the claim about the practical usefulness or the need for empirical comparisons. This makes the claim somewhat verifiable, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper, specifically the lack of empirical comparisons with existing algorithms. It suggests that the paper should be evaluated as 'Marginally above the acceptance threshold' due to the absence of empirical results, despite comprehensive theoretical comparisons. The comment also raises concerns about the practical usefulness of the algorithm, particularly regarding the potential communication costs between the master and workers. Additionally, it points out that \\\\Delta_i, \\\\Delta_{med}, and \\\\nabla_i are not defined in the paper, which is a clear and actionable suggestion for improvement. While the comment provides valuable insights and suggestions for enhancing the paper, it could be more helpful by offering specific guidance on how to incorporate empirical comparisons or address the practical usefulness concerns. Overall, the feedback is mostly helpful, as it directs the authors to important areas for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a discrepancy between the proposed approach's performance in simulations and its performance in real data, questioning the practical advantage of the method. It suggests that including more real data analyses or comparisons could help support the method's practicality. While the comment implies that the authors should include more real data analyses, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate this additional analysis. The action is implicit and somewhat vague, as the authors need to infer the need for more real data analyses and determine how to implement them. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the performance of the proposed approach in both simulations and real data, questioning the practical advantage of the method. It suggests including more real data analyses or comparisons to support the method's practicality. However, the comment does not specify which part of the paper discusses the real data analysis or where the proposed method's performance is evaluated, making it weakly grounded. The comment is specific in suggesting a potential improvement by including more real data analyses, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the practical advantage of the proposed method by highlighting its strong performance in simulations but poor performance in real data. The reviewer suggests that including more real data analyses or comparisons could support the method's practicality. While the comment logically points out a discrepancy between simulated and real-world performance, it lacks specific examples or references to substantiate the claim. The suggestion to include more real data analyses is a reasonable one, but without detailed guidance or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant discrepancy between the proposed method's performance in simulations and its performance in real data, questioning the practical advantage of the method. It suggests that including more real data analyses or comparisons could help support the method's practicality. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness of their findings by incorporating real data analyses. However, the comment could be more helpful if it offered specific guidance on how to conduct these analyses or which real data sets to consider. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment highlights a discrepancy between the proposed method's performance in simulations and its performance in real data, questioning its practical advantage. It suggests that including more real data analyses or comparisons could help support the method's practicality. While the comment implies that the authors should include more real data analyses, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate this additional analysis. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the performance of the proposed approach in both simulations and real data, questioning its practical advantage. It suggests including more real data analyses or comparisons to support the method's practicality. However, the comment does not specify which part of the paper discusses the real data analysis or where the proposed method's performance is evaluated, making it weakly grounded. The suggestion to include more real data analyses is specific, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the practical advantage of the proposed method by highlighting its strong performance in simulations but poor performance in real data. The reviewer suggests that including more real data analyses or comparisons could support the method's practicality. While the comment logically points out a discrepancy between simulated and real-world performance, it lacks specific examples or references to substantiate the claim. The suggestion to include more real data analyses is a reasonable one, but without detailed guidance or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant discrepancy between the proposed method's performance in simulations and its performance in real data, questioning the practical advantage of the method. It suggests that including more real data analyses or comparisons could help support the method's practicality. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness of their findings by incorporating real data analyses. However,"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a claim made by the authors regarding the low discrimination risk and improved fairness of their solution, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, it does not provide specific guidance or suggestions on how the authors should address these points or improve their draft. The comment lacks actionable details, such as recommending ways to demonstrate the low discrimination risk or suggesting methods to ensure the underlying data distribution is maintained. As a result, the authors are left without clear steps to take in response to this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding the low discrimination risk and improved fairness of their solution. It also mentions the importance of maintaining the underlying data distribution after imputation. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of maintaining the data distribution and its impact on model effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' solution has a low discrimination risk and improves fairness, but it also emphasizes the importance of maintaining the underlying data distribution after imputation. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the authors' claim regarding the low discrimination risk and improved fairness of their solution, while also highlighting the importance of maintaining the underlying data distribution after imputation. However, the comment lacks specific guidance or actionable suggestions on how the authors might address these points or improve their draft. It does not provide detailed feedback or examples that would help the authors enhance their work. As a result, the comment is somewhat helpful, as it identifies areas of interest but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges the authors' claim regarding the low discrimination risk and improved fairness of their solution, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, it does not provide specific guidance or suggestions on how the authors might address these points or improve their draft. The comment lacks actionable details, such as recommending ways to demonstrate the low discrimination risk or suggesting methods to ensure the underlying data distribution is maintained. As a result, the authors are left without clear steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim regarding the low discrimination risk and improved fairness of their solution, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of maintaining the data distribution and its impact on model effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the authors\\' claim regarding the low discrimination risk and improved fairness of their solution, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or a clear explanation, the authors may find it challenging to understand the basis of the claim and how to address it. As a result, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the authors' claim regarding the low discrimination risk and improved fairness of their solution, while also emphasizing the importance of maintaining the underlying data distribution after imputation. However, it does not provide specific guidance or actionable suggestions on how the authors might address these points or improve their draft. The comment lacks depth and does not offer detailed feedback or examples that would help the authors enhance their work. As a result, the comment is barely helpful, as it identifies areas of interest but does not provide comprehensive guidance for improvement.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment acknowledges the authors' claim regarding the low discrimination risk and improved fairness of their"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. While the comment implies an action\u2014expanding the use of ReferIt\u2014it does not provide explicit instructions or concrete details on how to implement this suggestion. The authors are left to infer the specific steps or considerations needed to follow this advice. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific line in the paper, \"792,\" which provides full grounding as it allows the authors to identify the exact part of the paper being addressed. However, the comment lacks specificity as it does not detail what needs to be addressed or improved regarding the use of ReferIt or the transition to other datasets. Without specific guidance or examples, the authors may struggle to understand the exact issue or how to address it. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this suggestion would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to effectively use more of ReferIt\\'s data. The comment does not offer actionable steps or a clear rationale for why this approach would be beneficial, leaving the authors with limited direction on how to implement the suggestion. Therefore, the comment is somewhat helpful, as it provides a general idea but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. However, it does not provide explicit instructions or details on how to implement this suggestion, such as specific amounts of data to use or how to integrate it into the existing framework. The action is implicit and lacks concrete guidance, making it somewhat actionable. The authors have an idea of what could be done but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific line in the paper, \"792,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what needs to be addressed or improved regarding the use of ReferIt or the transition to other datasets. Without specific guidance or examples, the authors may struggle to understand the basis of the suggestion. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this approach would be beneficial or necessary. Without additional context or explanation, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to effectively use more of ReferIt\\'s data. Without actionable steps or a clear rationale, the authors may find it challenging to implement the suggestion. Therefore, the comment is somewhat helpful, as it provides a general direction but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors could further exploit ReferIt by using more of its data before moving on to other datasets. While the suggestion implies an action, it lacks explicit instructions or concrete details on how to implement this suggestion. The authors are left to infer the specific steps or considerations needed to follow this advice. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to elaborate on the explanation provided in lines 243-245, specifically questioning the choice of 5*3 over 5*2 and the use of k-NN as a classifier. The reviewer asks for clarification on the value of k and the distance metric used. This feedback is explicit and provides concrete details on what the authors need to address, making it highly actionable. The authors know exactly what information is missing and how to improve their draft by providing additional explanation and details.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 243-245, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the explanation of the choice of 5*3 over 5*2, the use of k-NN as a classifier, and the value of k and the distance metric used. This provides clear guidance on what the authors need to clarify or elaborate on in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific aspects of the paper, such as the choice of 5*3 over 5*2 and the use of k-NN as a classifier. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas of the paper where the explanation is unclear, particularly in lines 243-245. It asks for clarification on the choice of 5*3 over 5*2 and the use of k-NN as a classifier, including questions about the value of k and the distance metric used. This feedback is clear and actionable, as it directs the authors to provide additional details and explanations that can help improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information more effectively. Overall, the comment is mostly helpful, as it provides valuable insights for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a detailed description of the background of Sharpness-Aware Minimization (SAM). This is a clear and direct action that the authors can take to improve their draft. However, the comment does not provide specific guidance on what aspects of the background should be detailed or how to present this information. While the action is explicit, the lack of concrete details on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or paragraph where the background is discussed. This lack of explicit reference makes it weakly grounded. The comment is specific in its request for a detailed description of the background, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any justification or reasoning for why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing more context or explanation about SAM. However, the comment lacks depth and does not offer specific guidance on what aspects of SAM should be detailed or how this information could be integrated into the paper. To be more helpful, the comment could include suggestions on what specific aspects of SAM are crucial to understand or how the authors might present this information effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experimental setup lacks comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific examples of how to enhance the evaluation, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline. These suggestions are concrete and provide clear guidance on how to improve the experimental setup. The authors know exactly what changes to make to strengthen the evaluation of LAFT\\'s efficacy. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of comprehensive comparisons in the experimental setup, specifically between language-assisted and vision-assisted approaches. It suggests incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline to provide valuable insights. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results sections. The suggestion is specific, as it outlines particular methods that could be used to enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. The reviewer suggests specific methods, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline, to provide valuable insights. This suggestion is based on logical reasoning and provides a clear direction for improvement, making the claim mostly verifiable. However, the comment could be strengthened by referencing existing studies or providing more detailed examples of how these methods have been successfully applied in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for enhancing the evaluation, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline. These suggestions are actionable and offer a clear direction for the authors to strengthen their evaluation of LAFT\\'s efficacy. By addressing these points, the authors can significantly improve the depth and rigor of their experimental analysis. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment identifies a gap in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline. These suggestions are clear and provide concrete guidance on how to enhance the evaluation of LAFT\\'s efficacy. The authors know exactly what changes to make to improve their experimental setup. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the experimental setup, namely the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline. These suggestions are clear and provide a concrete direction for enhancing the evaluation of LAFT\\'s efficacy. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. Despite this, the suggestions are specific, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It suggests specific methods, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline, to provide valuable insights. This claim is supported by logical reasoning and specific suggestions, making it mostly verifiable. However, the comment could be strengthened by referencing existing studies or providing more detailed examples of how these methods have been successfully applied in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for enhancing the evaluation, such as incorporating image guidance with related reference normal images or color-augmentation for a kNN baseline. These suggestions are actionable and offer clear directions for the authors to strengthen their evaluation of LAFT\\'s efficacy. By addressing these points, the authors can significantly improve the depth and rigor of their experimental analysis. Therefore, the comment is highly helpful, aligning with a score of "}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of related work on collective entity linking, which the authors propose as a special case. It suggests that the paper should include this line of work, providing a clear and explicit action for the authors to take. The comment is specific about what needs to be added to the paper, making it highly actionable. The authors know exactly what to do to improve their draft, which is to include a discussion on collective entity linking as a related work. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of related work on collective entity linking, which the authors propose as a special case. It suggests that the paper should include this line of work, providing a clear direction for improvement. However, the comment does not specify which part of the paper should include this related work, making it weakly grounded. The suggestion is specific, as it identifies a particular area that needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking and suggests that the paper should include related work on this topic. However, the comment lacks specific references or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or examples, the claim remains vague and unverifiable, as it does not provide sufficient evidence or justification for the authors to act upon. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the literature review by pointing out the absence of related work on collective entity linking, which the authors propose as a special case. This feedback is valuable as it highlights an area where the paper could be strengthened by including relevant literature. However, the comment could be more helpful if it provided specific examples of related works or suggested how the authors might integrate this line of work into their paper. Despite this, the comment offers clear and actionable guidance, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues. First, it suggests that truncating the log likelihood function can lower sensitivity and recommends comparing this aspect, which provides a clear and explicit action for the authors to take. Second, it points out a minor issue with Algorithm 1, noting that the query functions for all d data sources are the same, while the general framework allows them to be different. The reviewer wonders how to design a customized query function for each data source and suggests removing the subscript for clarity. Both parts of the comment provide explicit actions with concrete details, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions specific elements like \"algorithm 1\" and \"log likelihood function,\" which helps the authors identify the relevant parts of the paper. However, it lacks full grounding because it does not specify which sections or figures these elements are located in. The comment is specific in suggesting a comparison related to truncating the log likelihood function and providing a minor comment about the query functions in Algorithm 1. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the potential impact of truncating the log likelihood function on sensitivity. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The suggestion to compare this aspect is vague and lacks detailed explanation, making it difficult for the authors to understand the basis of the claim. Additionally, the comment about the query functions in Algorithm 1 is a minor observation that does not require verification. Overall, the lack of detailed justification or evidence makes the claims unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides two pieces of feedback. First, it suggests a comparison of the impact of truncating the log likelihood function on sensitivity, which is a relevant and actionable suggestion for the authors to consider. Second, it points out a minor issue with Algorithm 1, noting that the query functions for all d data sources are the same, while the general framework allows them to be different. The reviewer wonders how to design a customized query function for each data source and suggests removing the subscript for clarity. This feedback is mostly helpful as it identifies specific areas for improvement and provides clear guidance on how to address them. However, it could be more helpful if it included additional suggestions or examples for designing customized query functions. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation should be expanded to include a larger and more diverse dataset, specifically mentioning the need to test the method on more complex molecules and materials. While the comment implies that the authors should conduct additional evaluations, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is clear but inferred, and the comment lacks concrete details on how to execute the suggested expansion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the evaluation to include a larger and more diverse dataset, specifically mentioning the MD17 dataset. However, it does not specify which part of the paper this evaluation is currently limited to, making it weakly grounded. The comment is specific in its suggestion to include more complex molecules and materials, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends testing the method on a larger and more diverse dataset. While the comment identifies a potential limitation in the evaluation, it does not provide specific examples or references to support the claim that a larger dataset would be beneficial. The suggestion is based on logical reasoning, as expanding the dataset could potentially reveal more comprehensive performance metrics. However, without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the method, noting that it is restricted to a small set of molecules from the MD17 dataset. It suggests that the method's performance should be tested on a larger and more diverse dataset, including more complex molecules and materials. This feedback is clear and actionable, as it provides a specific direction for expanding the evaluation to enhance the robustness and generalizability of the results. However, the comment could be more helpful if it included suggestions on how to select or define the additional datasets or molecules to test. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their evaluation strategy.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper under review is similar to the StreamingLLM paper, which sets sink tokens and performs local attention. It points out that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The reviewer recommends clarifying the differences between the two papers, especially since the StreamingLLM paper has recently been uploaded. While the comment implies that the authors should address these differences, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact differences that need to be clarified. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the StreamingLLM paper [1] and provides specific details about its content, such as setting sink tokens and performing local attention. It also suggests that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The comment is specific in its request to clarify the differences between the current paper and the StreamingLLM paper, especially given the recent upload of the latter. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper under review is similar to the StreamingLLM paper, which sets sink tokens and performs local attention. The reviewer provides specific details about the potential correspondence of sink tokens to $C_{special}$ and $C_{punct}$, and suggests that clarifying the differences between the two papers would be beneficial. The comment is supported by referencing the StreamingLLM paper, which has recently been uploaded, and provides a clear rationale for why the differences should be clarified. This level of detail and the reference to an external source make the claim mostly verifiable, as it provides a solid basis for the authors to understand and address the issue.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential similarity between the current paper and the StreamingLLM paper, noting that both set sink tokens and perform local attention. It suggests that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The comment highlights the need to clarify the differences between the two papers, especially given the recent upload of the StreamingLLM paper. This feedback is somewhat helpful as it points out a potential overlap and encourages the authors to differentiate their work, but it could be more helpful if it provided specific suggestions on how to address this issue or what aspects to focus on for clarification. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the paper under review is similar to the StreamingLLM paper, which sets sink tokens and performs local attention. It points out that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The reviewer recommends clarifying the differences between the two papers, especially given the recent upload of the StreamingLLM paper. While the comment identifies a potential overlap and suggests an area for improvement, it does not provide explicit instructions or detailed guidance on how to address this issue. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the StreamingLLM paper [1] and provides specific details about its content, such as setting sink tokens and performing local attention. It also suggests that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The comment further recommends clarifying the differences between the current paper and the StreamingLLM paper, especially given the recent upload of the latter. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper under review is similar to the StreamingLLM paper, which sets sink tokens and performs local attention. It provides specific details about potential correspondences between sink tokens and categories like $C_{special}$ and $C_{punct}$. The reviewer suggests that clarifying the differences between the two papers would be beneficial, especially given the recent upload of the StreamingLLM paper. This claim is supported by referencing the StreamingLLM paper, which provides a clear basis for the authors to understand and address the issue. The detailed comparison and reference to an external source make the claim mostly verifiable, as it offers a solid foundation for the authors"}
{"generated_text": "{'actionability_rationale': 'The review point makes a comparison between the qualitative results of the current work and ConceptWeaver, noting that there doesn\\'t seem to be a significant improvement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results of the paper and compares them to ConceptWeaver, which is mentioned as a relevant work. However, it does not specify which part of the paper discusses the qualitative results, making it weakly grounded. The comment is specific in its critique of the qualitative results, suggesting that there is no significant improvement compared to ConceptWeaver. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. The reviewer supports this claim by referencing a specific work, \"Concept Weaver,\" which provides a basis for comparison. However, the comment lacks detailed analysis or specific examples from the referenced work to substantiate the claim fully. While the reference provides some support, the absence of detailed comparison or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential issue with the qualitative results of the paper, suggesting that there is no significant improvement compared to ConceptWeaver, which can handle more than two concepts. It references a specific work, \"Concept Weaver,\" providing a basis for comparison. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. While it highlights a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data and implies that it could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete details on how the authors should implement this approach or where in the paper this suggestion should be applied. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the problem can be reduced to subspace clustering with missing data and implies that it could be solved by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what exactly needs to be addressed or improved in the context of subspace clustering or matrix completion. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the problem can be reduced to subspace clustering with missing data and implies that it could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the problem can be reduced to subspace clustering with missing data and implies that it could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks clarity and does not provide specific guidance or actionable steps for the authors to follow. It does not explain how this suggestion relates to the current work or how it could be implemented, leaving the authors without a clear path for improvement. The feedback is vague and does not offer sufficient detail to be helpful, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the reliance of CCKT-Det++ on the quality and alignment of teacher models, suggesting that limitations or biases in the teacher models could propagate to CCKT-Det++, affecting performance and introducing unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete actions or recommendations for improvement, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on teacher models and the potential propagation of limitations or biases from these models. However, it does not specify which part of the paper discusses the teacher models or the impact of their quality and alignment on CCKT-Det++. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where teacher models are discussed, the comment lacks full grounding. It is specific about the potential issue of bias propagation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. While the comment logically argues that the quality and alignment of teacher models are crucial, it lacks specific examples or references to substantiate the claim. The authors might find it challenging to address the issue without more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a logical reasoning but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance of CCKT-Det++ on teacher models, highlighting the need for careful consideration of the quality and alignment of these models. It suggests that limitations or biases in the teacher models could propagate to CCKT-Det++, affecting performance and introducing unintended biases. While the comment raises an important point about the robustness of the system, it lacks specific guidance or suggestions on how the authors might address this issue or mitigate potential biases. The feedback is somewhat helpful as it points out a critical area for consideration, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. It lacks specific actions or recommendations for improvement, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on teacher models and the potential propagation of limitations or biases from these models. However, it does not specify which part of the paper discusses the teacher models or the impact of their quality and alignment on CCKT-Det++. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the potential issue of bias propagation, it lacks full grounding as it does not direct the authors to a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. The comment logically argues that the quality and alignment of teacher models are crucial, but it lacks specific examples or references to substantiate the claim. While the reasoning is sound, the absence of detailed evidence or examples makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is categorized as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance of CCKT-Det++ on teacher models, highlighting the need for careful consideration of the quality and alignment of these models. It suggests that limitations or biases in the teacher models could propagate to CCKT-Det++, affecting performance and introducing unintended biases. While the comment raises an important point about the robustness of the system, it lacks specific guidance or suggestions on how the authors might address this issue or mitigate potential biases. The"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the comparison. There is no guidance on whether the authors should update the comparison objects, consider new benchmarks, or provide additional analysis. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison objects used in the experiment, indicating that they are outdated and that the performance has not significantly improved. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the outdated comparison objects and the lack of significant performance improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. While it identifies a potential issue with the choice of comparison objects, it lacks specific suggestions or guidance on how the authors might address this problem or improve their experimental setup. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their experimental setup. Without specific guidance or actionable steps, the authors are left without a clear understanding of what changes to make to their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison objects used in the experiment, indicating that they are outdated and that the performance has not significantly improved. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the outdated comparison objects and the lack of significant performance improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their experimental setup. Without specific guidance or actionable steps, the authors are left without a clear understanding of what changes to make to their draft. As a result, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison objects used in the experiment, indicating that they are outdated and that the performance has not significantly improved. However, it does not specify which part of the paper this comparison"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how masks are handled in CNN layers, specifically in the representation block. While it raises a valid inquiry, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing or how the authors might investigate or clarify this aspect of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not specify which part of the paper discusses these layers or the representation block, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these concepts are discussed, the comment lacks full grounding. It is specific in its inquiry about the handling of masks but does not provide detailed guidance on what needs to be addressed or improved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about how masks are handled in CNN layers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how masks are handled in CNN layers, specifically in the representation block. While it identifies a potential area of interest or confusion, it does not provide any context, explanation, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance for the authors to enhance their draft. Without additional context or suggestions, the authors are left without a clear understanding of how to address this inquiry. Therefore, the comment is rated as barely helpful, as it points out an area of interest but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for an explanation regarding the larger training loss observed when \"without dropout\" is used, given that activation clipping may reduce the model capacity. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the explanation should focus on. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an explanation for the larger training loss observed when \"without dropout\" is used, given that activation clipping may reduce the model capacity. This provides clear guidance on what the authors need to address in their explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the observed phenomenon in Figure 8, specifically questioning why \"without dropout\" has a larger training loss. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about Figure 8, asking for an explanation of why \"without dropout\" has a larger training loss, given that activation clipping may reduce the model capacity. This feedback is somewhat helpful as it prompts the authors to provide a clearer explanation of their results, which could enhance the understanding of their findings. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context that would aid the authors in their explanation. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should emphasize the significance of establishing a large-scale matting dataset, which is currently under-discussed. However, it does not provide specific guidance on how to incorporate this suggestion into the paper, such as where to add this information or what specific aspects to highlight. The action is implicit and vague, as the authors are left to infer that they should address this point but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s most significant contribution is the establishment of a large-scale matting dataset, which is not adequately discussed in the paper. However, it does not specify which part of the paper should address this issue or provide details on how to incorporate this contribution. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper\\'s most significant contribution is the establishment of a large-scale matting dataset, which is not adequately discussed in the paper. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples, it is difficult for the authors to understand the basis of the reviewer\\'s perspective or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper\\'s most significant contribution is the establishment of a large-scale matting dataset, which is not adequately discussed in the paper. While it identifies a potential area for improvement, it lacks specificity and actionable guidance on how the authors might address this issue. The comment does not provide detailed suggestions or examples of how to incorporate this contribution into the paper, leaving the authors with only a vague idea of what needs to be improved. Therefore, the feedback is barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of adversarial examples is insufficient to demonstrate a distribution. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as increasing the number of examples, using a different method to generate adversarial examples, or providing additional analysis. Without specific guidance or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the number of adversarial examples being insufficient to demonstrate a distribution. However, it does not specify which part of the paper this issue is related to, such as a particular section, figure, or analysis. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what constitutes a \"distribution\" or how the number of adversarial examples impacts the demonstration. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is insufficient to demonstrate a distribution. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the number of adversarial examples used in the study, suggesting that it may be insufficient to demonstrate a distribution. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue, such as increasing the number of examples or using different methods to generate adversarial examples. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It also points out that the analysis experiments or 'Qualitative Studies' in Section 5.2 are conducted with a subset of common corruptions, and recommends doing them with the full set for thoroughness and comparability with other results. The comment provides explicit actions for the authors to take, such as conducting experiments with the full set of corruptions, which are clear and concrete. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5), which is not appropriate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proposed channel-sparse gradients, explaining why they may not save time or memory in practice due to the limitations of most frameworks. The comment further provides specific guidance on how to improve the analysis experiments or \"Qualitative Studies\" by recommending the use of the full set of corruptions for thoroughness and comparability. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the claim that channel-sparse gradients save time or memory in practice, citing the limitation of most frameworks supporting only dense gradients. The reviewer provides logical reasoning by explaining why zeroing out a particular channel may not alter the computation performed. Additionally, the comment suggests that the analysis experiments or 'Qualitative Studies' in Section 5.2 should be conducted with the full set of corruptions for thoroughness and comparability. This reasoning is clear and supported by logical arguments, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed critique of the proposed channel-sparse gradients, questioning their practicality and suggesting potential limitations. It explains why these gradients may not save time or memory in practice, given the limitations of most frameworks supporting only dense gradients. The comment also points out that the analysis experiments or 'Qualitative Studies' in Section 5.2 are conducted with a subset of common corruptions, and recommends conducting them with the full set for thoroughness and comparability with other results. This feedback is clear, actionable, and provides specific guidance on how to improve the experimental design and analysis, making it highly helpful for the authors to enhance the robustness and generalizability of their findings. Therefore, the comment deserves a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim that they do not consider sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their claims. It lacks actionable details, such as recommending specific changes or additional analyses to support their claims. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the proof and its connection to low rank. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\\' claim regarding low rank, suggesting that the proof might imply a connection to low rank despite the authors\\' assertion. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim that they do not consider sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. The reviewer provides a logical reasoning by pointing out that the high probability considering the tails of the distribution could be related to low rank. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the connection between concentration-of-measure and low rank to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim that they do not consider sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. The reviewer points out that the results are likely a simple extension of existing results, questioning the novelty of the work. While the comment identifies a potential issue with the authors\\' claims, it lacks specific suggestions or guidance on how the authors might address this concern or clarify their claims. The feedback provides some insight into the critique but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the authors\\' claim regarding sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their claims. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the proof and its connection to low rank. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\\' claim regarding low rank, suggesting that the proof might imply a connection to low rank despite the authors\\' assertion. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim that they do not consider sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. The reviewer provides a logical reasoning by pointing out that the high probability considering the tails of the distribution could be related to low rank. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the connection between concentration-of-measure and low rank to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim that they do not consider sparsity or low rank, suggesting that the proof might be related to concentration-of-measure, which could imply a connection to low rank. The reviewer points out that the results might be a simple extension of existing results, questioning the novelty of the work. While the comment identifies a potential issue with the authors\\' claims, it lacks specific suggestions or guidance on how the authors might address"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Limitations section is too concise, contrasting with the detailed writing style of the main body. However, it does not provide specific guidance on how to expand or improve the Limitations section. The authors are left without clear instructions on what additional information or details should be included to make the Limitations section more comprehensive. The feedback is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Limitations section,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, the comment lacks specificity as it does not detail what is considered too concise or what specific aspects of the Limitations section need to be expanded upon. Without specific guidance or examples, the authors may struggle to understand how to improve this section. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the Limitations section is too concise, contrasting with the detailed writing style of the main body. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is difficult for the authors to understand which aspects of the Limitations section are insufficient or how they might address this issue. As a result, the claim is considered unverifiable due to the lack of supporting information.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a discrepancy in the writing style between the Limitations section and the rest of the paper, noting that the Limitations section is too concise compared to the detailed writing style of the main body. While it identifies a potential issue with the manuscript, it lacks specific guidance or suggestions on how to improve the Limitations section. Without actionable advice or examples, the authors may struggle to address the concern effectively. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not provide detailed feedback or suggestions for enhancement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty of their method or differentiate it from existing work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed method, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the novelty is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its critique of the novelty, it is not grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific references or detailed reasoning to support this claim. Without explicit examples or comparisons to the original work, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. While the comment highlights a concern about the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their method. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their method or differentiate it from existing work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed method, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the novelty is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its critique of the novelty, it is not grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific references or detailed reasoning to support this claim. Without explicit comparisons or examples, it is difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered borderline verifiable, as it provides some context but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the novelty of the proposed method, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty of their method or differentiate"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about each challenge, suggesting that this information be included in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, the reviewer recommends listing all the prompts used in the evaluation, either in the appendix or on GitHub. These suggestions are clear and provide concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more details about each challenge, which can be inferred to be related to the evaluation section or the repository. It also specifies what needs to be addressed, such as providing more details about each challenge and listing all prompts used in the evaluation. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions for running the code, which is a factual observation. However, it does not provide any supporting evidence or reasoning to justify why this lack of instructions is problematic or how it affects the paper\\'s quality. Additionally, the suggestion to provide more details about each challenge and list prompts in the appendix is a recommendation rather than a claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clear instructions for running the code due to missing details in the repository. It provides a specific and actionable recommendation to improve the manuscript by suggesting that the authors provide more details about each challenge, either in an extensive version of Table 1 or in the appendix, similar to binpwn. Additionally, the comment recommends listing all prompts used in the evaluation, either in the appendix or on GitHub. This feedback is clear, actionable, and offers concrete steps for the authors to enhance the clarity and accessibility of their work, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to align the results with the major claim. The comment implies that the authors should reconsider the importance of the global representation or the interpretation of the results, but it lacks concrete suggestions or detailed instructions on how to proceed. As a result, the authors are left with a general idea of what needs to be addressed but without clear steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the model ablation results and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components, as indicated by the model ablation results in Table 3. However, it does not provide specific reasoning or evidence to support why this is the case, nor does it explain how this finding relates to the major claim of interpretable VQA. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA. It highlights that the global representation g_v appears to be more crucial than other components, which slightly contradicts the claim that correct answers should be anchored on correct visual content. This feedback is somewhat helpful as it points out a potential inconsistency that the authors need to address. However, the comment lacks specific suggestions or guidance on how to reconcile this discrepancy or improve the alignment between the results and the major claim. To be more helpful, the comment could provide insights into how the authors might adjust their interpretation or analysis to better align with their claims. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to align the results with the major claim. The comment implies that the authors need to reconsider the importance of the global representation or the interpretation of the results, but it lacks actionable steps or detailed suggestions. As a result, the authors are left with a general understanding of the issue but without clear direction on how to proceed. Therefore, the comment is rated as barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the model ablation results and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components, as indicated by the model ablation results in Table 3. However, it does not provide specific reasoning or evidence to support this claim, nor does it explain how this finding relates to the major claim of interpretable VQA. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This highlights a potential inconsistency that the authors need to address. However, the comment lacks specific guidance or suggestions on how the authors might resolve this discrepancy or align their results with"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion to avoid using the notation $f^{-1} = g$ in the notation paragraph of section 3. The reviewer explains the issue with this notation, stating that $f$ cannot be an invertible function when $d<D$, as it is defined on a domain of $\\mathbb{R}^D$. The reviewer suggests using the language of left inverses instead. This feedback is explicit and provides concrete guidance on how to improve the notation, making it clear what the authors need to do to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"notation paragraph in sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed explanation of the issue with the notation, suggesting that $f^{-1} = g$ should be avoided due to the domain definition of $f$. The reviewer offers a specific alternative, recommending the use of left inverses. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the notation used in the paper, specifically $f^{-1} = g$, and provides a logical reasoning for why this notation might be problematic. The reviewer explains that when $d < D$, $f$ cannot be an invertible function due to its domain definition as $\\\\mathbb{R}^D$. This reasoning is clear and logical, providing a sound basis for the claim. However, the comment does not cite external references or provide specific examples to further substantiate the claim. While the reasoning is robust, the lack of additional evidence or references makes the claim mostly verifiable. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation used in the paper. It points out a potential issue with the notation $f^{-1} = g$ and explains why it might be problematic, given the domain definition of $f$. The reviewer offers an alternative suggestion by recommending the use of left inverses, which is a clear and constructive piece of feedback. This guidance helps the authors improve the clarity and accuracy of their notation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in their ablation studies on the motion tokenizer. This feedback provides a clear and direct action for the authors to take, specifying exactly what additional comparisons are needed to enhance the comprehensiveness of their analysis. The comment is concrete, as it outlines a specific step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer. This provides clear guidance on how to enhance the comprehensiveness of the analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies on the motion tokenizer in Table 4 should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], to provide a more comprehensive understanding of the model\\'s relative effectiveness. The claim is supported by logical reasoning, as it highlights the importance of comparing the proposed approach with existing benchmarks to validate its performance. However, the comment could be strengthened by providing specific examples or detailed reasoning about why these comparisons are necessary. As it stands, the claim is mostly verifiable, as it offers a clear direction for improvement but lacks exhaustive justification. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer. This feedback is specific and offers a concrete way to enhance the comprehensiveness and validity of the experimental results. By suggesting a particular comparison, the comment guides the authors on how to strengthen their analysis and provide a more robust evaluation of their proposed approach. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make a significant improvement to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue or what specific aspects should be clarified. The authors are left to infer that they need to define the \"primary-secondary\" relationship more clearly, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"primary-secondary\" relationship and its comparison with the concept of nuclearity. However, it does not specify which part of the paper discusses these concepts, making it weakly grounded. The comment is specific in pointing out the lack of clarity and precise definition of the \"primary-secondary\" relationship compared to nuclearity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but lacks clarity and precise definition compared to the concept of nuclearity. This feedback highlights a potential area for improvement, as it points out a lack of clarity that could impact the reader\\'s understanding of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this relationship or improve the definition. While it identifies a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies an area that needs improvement, it does not provide explicit guidance on how the authors should clarify or define the \"primary-secondary\" relationship. The comment lacks specific suggestions or examples, leaving the authors with a general idea of what needs to be addressed but without concrete steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the lack of clarity and precise definition of the \"primary-secondary\" relationship compared to the concept of nuclearity. However, it does not specify which part of the paper discusses these concepts, making it weakly grounded. The comment is specific in pointing out the need for clarification and definition, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the observation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but lacks clarity and precise definition compared to the concept of nuclearity. This feedback highlights a potential area for improvement, as it points out a lack of clarity that could impact the reader\\'s understanding of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or define the \"primary-secondary\" relationship more effectively. While it identifies a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies an area that needs improvement, it does not provide specific guidance or suggestions on how the authors might clarify or define the \"primary-secondary"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the effect of mask ratio across different datasets, noting that this could lead to more tuning. It also points out the absence of insight into the impact of mask ratio in the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address it or what specific aspects should be included in the guide. The action is implicit and somewhat vague, as the authors need to infer that they should add insights and a guide but lack detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effect of the mask ratio across different datasets, noting that this could lead to more tuning, as mentioned in the limitations. However, it does not specify which part of the paper discusses the mask ratio or where the insights are missing. The authors might infer that it relates to the limitations or discussions sections, but this inference is not direct. The comment is specific in suggesting that an intuitive guide for choosing the mask ratio would be helpful, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which could lead to more tuning. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. The comment also suggests that the impact of the mask ratio is missing in the discussions and proposes an intuitive guide for choosing this ratio. While the suggestion is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It highlights the absence of insights into the impact of the mask ratio in the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. This feedback is clear and actionable, as it points out a gap in the paper and provides a concrete suggestion for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to develop this intuitive guide. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a discrepancy in the effect of the mask ratio across different datasets, noting that this could lead to more tuning. It also points out the absence of insights into the impact of the mask ratio in the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment identifies a gap in the paper, it does not provide explicit instructions or specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should add insights and a guide but lack detailed direction on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effect of the mask ratio across different datasets, noting that this could lead to more tuning, as mentioned in the limitations. However, it does not specify which part of the paper discusses the mask ratio or where the insights are missing. The suggestion to include an intuitive guide for choosing the mask ratio is specific, but the comment lacks grounding as it does not pinpoint the exact section that needs improvement. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which could lead to more tuning. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. The comment also suggests that the impact of the mask ratio is missing in the discussions and proposes an intuitive guide for choosing this ratio. While the suggestion is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It highlights the absence of insights into the impact of the mask ratio in the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. This feedback is clear and actionable"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide guidance on how to improve the clarity of these sections. The action is implicit, as the authors need to infer that they should proof-read the paper further, and it is vague because it lacks specific details on what needs to be improved. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide specific examples of what makes them difficult to follow. This lack of detail makes it challenging for the authors to identify and address the issues effectively. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is challenging for the authors to identify which sections need improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide specific examples of what makes them difficult to follow. This lack of detail limits the usefulness of the feedback, as the authors are left without clear guidance on how to improve the clarity of their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, and the reviewer guesses it refers to stochastic gates but is uncertain. While the comment identifies a potential issue with terminology, it does not provide explicit guidance on how the authors should address it. The authors can infer that they need to clarify the term or provide a definition, but the comment lacks concrete instructions on how to implement this change. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the term \"STG layer\" has never been mentioned in the manuscript and suggests that it might refer to stochastic gates, although it is not entirely sure. This provides clear guidance on what needs to be clarified or addressed in the manuscript. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, suggesting that it might refer to stochastic gates. However, the comment lacks specific reasoning or evidence to support this claim, such as references to other parts of the manuscript where the term \"STG layer\" is used or examples of how it is typically referred to. This makes the claim somewhat verifiable, as the authors would need to make an effort to understand and address the issue without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with terminology in the manuscript, specifically pointing out that the term \"STG layer\" in Figure 2 has never been mentioned elsewhere in the document. The reviewer suggests that it might refer to stochastic gates but is uncertain about this. This feedback is somewhat helpful as it highlights a gap in the manuscript that could lead to confusion for readers. However, it lacks specific guidance on how the authors should address this issue, such as suggesting where to introduce the term or clarifying its usage. To be more helpful, the comment could provide suggestions on how to integrate the term into the manuscript or offer examples of how similar terms are used elsewhere. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, suggesting that it might refer to stochastic gates. However, it does not provide explicit guidance on how the authors should address this issue, such as whether they should clarify the term or introduce it elsewhere in the manuscript. The comment lacks concrete instructions, making it somewhat vague and leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the term \"STG layer\" has never been mentioned in the manuscript and suggests that it might refer to stochastic gates, although it is not entirely sure about it. This provides clear guidance on what needs to be clarified or addressed in the manuscript. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, suggesting that it might refer to stochastic gates. However, the comment lacks specific reasoning or evidence to support this claim, such as references to other parts of the manuscript where the term is used or examples of how it is typically referred to. This makes the claim somewhat verifiable, as the authors would need to make an effort to understand and address the issue without clear guidance. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with terminology in the manuscript, specifically pointing out that the term \"STG layer\" in Figure 2 has never been mentioned elsewhere in the document. It suggests that the term might refer to stochastic gates but is uncertain about this. This feedback is somewhat helpful as it highlights a gap in the manuscript that could lead to confusion for readers. However, the comment lacks specific guidance on how the authors should address this issue, such as suggesting where to introduce the term or clarifying its usage. To be more helpful, the comment could"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the improvements resulting from the proposed methodology appear limited in some instances and even underperform compared to the baseline in the cases of FiQA and CONALA. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their methodology. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be taken to enhance the performance. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitations of the proposed methodology in terms of its improvements and performance compared to the baseline, specifically mentioning FiQA and CONALA. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the areas where the methodology underperforms, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements resulting from the proposed methodology appear limited and even underperform compared to the baseline in the cases of FiQA and CONALA. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out that the improvements resulting from the proposed methodology appear limited in some instances and even underperform compared to the baseline in the cases of FiQA and CONALA. However, it does not provide specific details or suggestions on how the authors might address these issues or improve their methodology. Without actionable feedback or guidance, the authors are left with only a vague understanding of the problem, making it difficult for them to make meaningful improvements to their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. While the comment implies that the authors should provide a clearer explanation of their contributions, it does not explicitly instruct them to do so. Additionally, it does not provide concrete guidance on how to address the issue or what specific aspects need to be clarified. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. However, it does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The comment is specific in its request for clarification on the contributions or advantages, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. However, it does not provide any supporting evidence or reasoning to justify why the comparisons are unclear or how the contributions or advantages are lacking. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved, namely in providing a clearer explanation of its contributions. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include examples of what kind of clarification is needed or how the authors might structure their response to better highlight their contributions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It explicitly instructs the authors to provide a well-explained justification for why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what needs to be improved and how to address the issue, ensuring they can effectively enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method\" and its role in making multi-modal learning less greedy, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a well-explained justification for why using the average feature of previous samples can stop the training of the uni-modal branch. This provides clear guidance on what aspect of the method needs further clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method is not well described and analyzed in the paper. It suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It points out that the explanation of why using the average feature of previous samples can stop the training of the uni-modal branch is lacking. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the method, which could enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of similar methods that have been well-explained. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It explicitly instructs the authors to provide a well-explained justification for why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what needs to be improved and how to address the issue, ensuring they can effectively enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method\" and its role in making multi-modal learning less greedy, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a well-explained justification for why using the average feature of previous samples can stop the training of the uni-modal branch. This provides clear guidance on what aspect of the method requires further clarification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method, used to make multi-modal learning less greedy, is not well described and analyzed in the full text. It suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It points out that the explanation of why using the average feature of previous samples can stop the training of the uni-modal branch"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks for a comparison of the \"Reduce\" part with EATA, specifically in terms of differences and advantages. Second, it inquires whether harmful out-of-distribution (OOD) instances can be identified using an entropy metric instead of an energy one. While the questions imply that the authors should provide a comparison and suggest an alternative metric, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and the specific part of the paper being addressed, allowing the authors to accurately identify the section being discussed. It is also specific because it raises two distinct questions: first, it asks for a comparison of the \"Reduce\" part with EATA, highlighting the differences and advantages, and second, it inquires whether harmful out-of-distribution (OOD) instances can be identified using an entropy metric instead of an energy one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the \"Reduce\" part in Section 4.1. It asks for a comparison with EATA, specifically in terms of differences and advantages, and suggests an alternative metric for identifying harmful out-of-distribution (OOD) instances. These questions are actionable and provide clear directions for the authors to enhance their draft by offering a comparative analysis and suggesting a potential improvement in methodology. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is mostly helpful as it guides the authors toward improving their work by addressing specific areas of interest and suggesting potential enhancements.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider this comparison but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the comparison of the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential comparison but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or necessary. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting direction for further exploration by comparing the proposed method against deterministic control, given the popularity of deterministic policies. This feedback is somewhat helpful as it provides a potential area for expanding the scope of the paper, which could enhance its relevance and impact. However, the comment does not offer specific guidance or suggestions on how to conduct this comparison or why it would be beneficial, leaving the authors with a general idea but without detailed direction. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential naming inconsistency in Table 4, suggesting that the 3r column should not be named ATE and clarifying that Corr is also Cau-Ant. This feedback is explicit and provides a clear action for the authors to take, which is to correct the naming inconsistency. The comment is specific and actionable, as it directly instructs the authors on what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential naming inconsistency in the 3r column and clarifies that Corr is also Cau-Ant. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the naming of columns in Table 4 and a clarification about the meaning of Corr and Cau-Ant. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the naming of columns in Table 4, suggesting that the 3r column should not be named ATE and clarifying that Corr is also Cau-Ant. This feedback is clear and actionable, as it provides a direct correction to the table, which can help improve the clarity and accuracy of the presentation. By addressing this point, the authors can enhance the readability and precision of their work. However, the comment could be more helpful if it explained why this naming inconsistency is problematic or how it affects the overall understanding of the results. Despite this, the feedback is mostly helpful as it provides a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the lack of clear anchoring of the mechanism in prior work, particularly in the experiments section. It suggests that more explanation or references to prior work might be beneficial. Additionally, it points out that the figures in the paper do not clearly communicate the significance of the differences in the curves, and recommends annotating or zooming in to provide quantitative grounding. While the comment provides some direction, it lacks specific guidance on how to achieve these improvements. The actions are implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions the \"experiments section\" and the \"methods section,\" allowing the authors to identify the relevant parts of the paper. However, it does not specify which figures or specific elements in the figures are unclear, making it weakly grounded. The comment is specific in its critique of the lack of anchoring in prior work and the difficulty in understanding the significance of the differences in the curves. It provides clear guidance on what needs to be improved, such as anchoring the mechanism in prior work and annotating or zooming in on the figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of clear anchoring of the mechanism in prior work, despite the experiments section. It suggests that more explanation or references to prior work might be helpful. The comment also points out that the figures do not clearly communicate the significance of the differences in the curves, recommending annotation or zooming in to provide quantitative grounding. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the lack of anchoring in prior work. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clear anchoring of the mechanism in prior work. It notes that while the experiments section provides some insight, there is still a vague sense of the mechanism's basis. The comment suggests that more explanation or references to prior work might be beneficial, which is a clear and actionable suggestion for the authors to improve the clarity and context of their work. Additionally, the comment highlights a specific issue with the figures, noting that the differences in the curves are not clearly communicated and recommending annotation or zooming in to provide quantitative grounding. This feedback is mostly helpful as it provides specific areas for improvement and actionable steps to enhance the clarity and comprehensiveness of the paper. However, it could be more helpful if it offered more detailed guidance on how to achieve these improvements. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a major concern about the limited novelty of the paper, noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not specify which part of the paper this concern is based on, nor does it provide details on how the novelty could be improved or what aspects of the pre-trained mechanism are seen as complicated. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. The reviewer describes the main idea as \"not exciting\" and \"a bit complicated,\" which implies a lack of novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. It describes the main idea as \"not exciting\" and \"a bit complicated,\" which suggests that the paper lacks a compelling contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies an issue but lacks the depth and specificity needed to be more beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the paper empirically validates the usefulness of certain setups and parameters for test-time training, it lacks a theoretical understanding of why these do not collapse. However, the comment does not provide explicit guidance or suggestions on how the authors should address this gap. It implies that the authors should explore theoretical explanations, but it does not specify what kind of theoretical analysis or understanding is needed. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical understanding in the paper regarding why certain setups or parameters do not collapse during test-time training. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a theoretical understanding, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a theoretical understanding of why certain setups or parameters do not collapse during test-time training. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment is vague and lacks detailed explanation, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, specifically the lack of theoretical understanding regarding why certain setups or parameters do not collapse during test-time training. While it points out an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer actionable advice, making it somewhat helpful. The authors are informed of a gap but are not directed on how to fill it, limiting the utility of the feedback.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a gap in the paper, specifically the lack of theoretical understanding regarding why certain setups or parameters do not collapse during test-time training. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or what kind of theoretical analysis could be conducted. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not collapse during test-time training. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a theoretical understanding, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a theoretical understanding of why certain setups or parameters do not collapse during test-time training. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, specifically the lack of theoretical understanding regarding why certain setups or parameters do not collapse during test-time training. While it highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment points out a weakness but does not offer actionable advice, making it somewhat helpful. The authors are informed of a gap but are not directed on how to fill it, limiting the utility of the feedback.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a gap in the paper, specifically the lack of theoretical understanding regarding why certain setups or parameters do not collapse during test-time training. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or what kind of theoretical analysis could be conducted. The feedback lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a gap in the paper regarding the theoretical understanding of why certain setups or parameters do not collapse during test-time training. However, it does not specify which part of the paper"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding whether the visual analysis in Section 4.4 is based on training or test images. While it points out a potential issue, it does not provide explicit guidance on how the authors should address this ambiguity. The authors can infer that they need to clarify this distinction, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec.4.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the visual analysis in Section 4.4 is based on training or test images. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. This is a relevant point that could impact the interpretation of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect in their draft. While it points out a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests exploring the application of the DEER method to other methods like LEM or UnICORNN to assess their performance and potential for better results. It implies that the authors should conduct experiments to determine if these methods could be trained faster with the DEER method and whether this would lead to improved performance. While the comment provides a clear direction for further exploration, it does not specify which methods should be tested or how the experiments should be structured. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, which provides a specific direction for further analysis. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as specific sections or experiments where these methods are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential exploration. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the application of the DEER method to other methods like LEM or UnICORNN to assess their performance and potential for better results. The comment provides a logical reasoning by questioning whether these methods could be trained faster with the DEER method and whether this would lead to improved performance. However, it lacks specific examples or references to support the claim that these methods could be trained faster or the potential benefits of using the DEER method. This makes the claim somewhat verifiable, as it provides a basis for further exploration but requires additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It raises a pertinent question about whether these methods could be trained faster with the DEER method and whether this would lead to better performance. This feedback is valuable as it encourages the authors to broaden their analysis and potentially enhance the impact of their work by exploring new applications. However, the comment could be more helpful if it provided specific guidance on how to conduct these explorations or suggested which methods to prioritize. Overall, the comment is mostly helpful as it identifies a meaningful area for further investigation and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN to assess their performance and potential for better results. It implies that the authors should conduct experiments to determine if these methods could be trained faster with the DEER method and whether this would lead to improved performance. While the comment provides a clear direction for further exploration, it lacks specific guidance on how to implement these experiments or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, which provides a specific direction for further analysis. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as specific sections or experiments where these methods are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The suggestion is specific in terms of what could be explored, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the application of the DEER method to other methods like LEM or UnICORNN to assess their performance and potential for better results. The comment provides a logical reasoning by questioning whether these methods could be trained faster with the DEER method and whether this would lead to improved performance. However, it lacks specific examples or references to support the claim that these methods could be trained faster or the potential benefits of using the DEER method. This makes the claim somewhat verifiable, as it provides a basis for further exploration but requires additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as reducing the number of notations, clarifying their usage, or providing more context. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to improve the presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation is difficult to follow due to the use of too many notations. However, it does not specify which sections or parts of the paper contain these notations, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding which notations are problematic or how they could be simplified. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples or reasoning to support this claim, such as which notations are particularly confusing or how their number impacts the clarity of the presentation. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue, such as recommending ways to simplify the notation or clarify its usage. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests including results for GPT-4V, even though its API is not yet released. The reviewer provides a concrete suggestion by recommending that the authors conduct some quick experiments through ChatGPT\\'s UI. This feedback is clear and provides a specific action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft based on this comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results for GPT-4V, even though its API is not yet released. It provides a specific suggestion to conduct some quick experiments through ChatGPT\\'s UI. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results for GPT-4V, even though its API is not yet released. The comment provides a specific suggestion to conduct experiments through ChatGPT\\'s UI, which is a concrete action that could be taken. However, the claim lacks detailed reasoning or evidence to support why including these results would be beneficial or necessary. The suggestion is based on a potential future development, which adds some level of verifiability but not as robustly as it could be. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a suggestion but lacks comprehensive justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including results for GPT-4V, even though its API is not yet released. The reviewer provides a specific and actionable recommendation to conduct some quick experiments through ChatGPT\\'s UI. This feedback is clear and provides a concrete step for the authors to take, which could enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it explained why including these results would be beneficial or how they might impact the paper\\'s conclusions. Despite this, the suggestion is valuable and offers a direct way for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the implications of their theoretical analysis and provide a comparison with baselines to understand why CoPur could perform better. While the comment implies that the authors should include such discussions, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to conduct these discussions or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context and analysis, but they may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. However, it does not specify which part of the paper this analysis is located in, making it weakly grounded. The comment is specific in its request for a discussion on the implications of the analysis and the performance of CoPur relative to baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the analysis is extensive or to explain why CoPur might outperform baselines. This makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. While the comment identifies a potential area for improvement by asking for a more detailed discussion of the theoretical analysis, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a gap in the paper but does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should discuss the implications of their theoretical analysis and provide a comparison with baselines to understand why CoPur could perform better. While the comment implies that the authors should include such discussions, it does not explicitly instruct them to do so or provide specific guidance on how to conduct these discussions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context and analysis, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. However, it does not specify which part of the paper this analysis is located in, making it weakly grounded. The comment is specific in its request for a discussion on the implications of the analysis and the performance of CoPur relative to baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. However, the comment lacks specific reasoning or evidence to support the claim that the analysis is extensive or to explain why CoPur might outperform baselines. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. While the comment identifies a potential area for improvement by asking for a more detailed discussion of the theoretical analysis, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a gap in the paper but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper provides an extensive theoretical analysis and recommends discussing what this analysis means and why CoPur could perform better compared to baselines. While"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol. It points out that the metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions but not their quality. Additionally, it questions the clarity of the evaluation protocol, specifically asking whether camera parameters are the same for all frames when generating videos. While the comment highlights areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the evaluation protocol and consider additional metrics, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Result/eval\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the reported metrics, particularly the lack of metrics related to dynamics and the unclear evaluation protocol regarding camera parameters. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It claims that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions. Additionally, it questions the clarity of the evaluation protocol, specifically asking whether camera parameters are the same for all frames when generating videos. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim about the evaluation protocol. The authors may find it challenging to fully understand and address these concerns without additional context or examples. Therefore, the comment is somewhat verifiable, as it provides some insight but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol in the paper. It points out that the metrics are mostly focused on 3D NVS and lack metrics related to dynamics, specifically noting that the keypoint distance metric only assesses the size of motions without evaluating their quality. Additionally, the comment questions the clarity of the evaluation protocol, particularly regarding whether camera parameters are consistent across all frames when generating videos. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it provides insight into potential weaknesses but could be more actionable with additional detail or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol. It points out that the metrics are mostly for 3D NVS and lack metrics related to dynamics, specifically noting that the keypoint distance metric only assesses the size of motions without evaluating their quality. Additionally, it questions the clarity of the evaluation protocol, specifically asking whether camera parameters are the same for all frames when generating videos. While the comment highlights areas that need clarification or improvement, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to clarify the evaluation protocol and consider additional metrics, but the lack of concrete suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Result/eval\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the reported metrics and evaluation protocol, particularly the lack of metrics related to dynamics and the clarity of the evaluation protocol regarding camera parameters. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It claims that the reported metrics are mostly for 3D NVS and lack metrics related to dynamics, specifically noting that the keypoint distance metric only assesses the size of motions without evaluating their quality. Additionally, it questions the clarity of the evaluation protocol, specifically asking whether camera parameters are the same for all frames when generating videos. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claims about the evaluation protocol. The authors may find it challenging to fully understand and address these concerns without additional context or examples. Therefore, the comment is somewhat verifiable, as it provides some insight but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol in"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the two parts of pretraining and regularization, which the authors want to emphasize, appear to be incremental additions rather than naturally integrated components. It suggests that this disjointed presentation detracts from the coherence of the paper and needs to be addressed. However, the comment does not provide specific guidance on how to integrate these components more effectively or what changes should be made to achieve coherence. The action is implicit and vague, as the authors are left to infer the necessary improvements without concrete steps or suggestions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the presentation of pretraining and regularization, suggesting that they appear as incremental additions rather than naturally integrated components. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the disjointed presentation and its impact on the coherence of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the two parts of pretraining and regularization are presented as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the presentation of pretraining and regularization in the paper, noting that these components appear as incremental additions rather than naturally integrated parts. This observation is crucial as it affects the coherence and overall understanding of the paper. The comment highlights the need for a more cohesive presentation of these components, which is a valuable insight for the authors to consider. However, the comment lacks specific suggestions or guidance on how to integrate these components more effectively, which would make it more actionable. While it points out a critical area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the importance of Renyi divergence is not well explained and questions why it is considered special for readers unfamiliar with differential privacy. However, it does not provide any explicit or implicit suggestions for how the authors could improve this explanation. There is no guidance on what specific aspects of Renyi divergence should be clarified or how the authors might address the issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the explanation of Renyi divergence, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this explanation is lacking, making it weakly grounded. The comment is specific in that it clearly identifies the issue of not explaining why Renyi divergence is special for readers unfamiliar with differential privacy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved, namely the explanation of Renyi divergence and its importance in the context of differential privacy. It highlights a potential gap in the paper that could be addressed to make it more accessible to readers unfamiliar with the topic. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the explanation. While it points out an area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying on mathematical theories. While the comment implies that the authors should simplify their explanations and focus on clarity, it does not provide specific guidance on how to achieve this or which parts of the paper need particular attention. The action is implicit and lacks concrete details, leaving the authors with a general direction but no clear steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on simplicity and clarity rather than relying on mathematical theories. However, it does not specify which parts of the paper are overly complex or where the mathematical theories are excessively detailed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity rather than relying on mathematical theories. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions on how the authors might achieve greater simplicity and clarity. Without detailed justification or examples, the comment lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying on mathematical theories. While it identifies a potential issue with the manuscript, it lacks specificity and actionable guidance. It does not provide examples of where the mathematical theories are overly complex or how the authors might simplify their explanations. Without detailed feedback or suggestions, the authors are left with a general direction but no clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablation study in the work is limited and specifically mentions that the impact of the pre-defined threshold \u03f5 should be further studied. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this further study or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors know they need to expand the ablation study but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"pre-defined threshold \u03f5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further studies on the impact of the pre-defined threshold \u03f5. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study is limited and suggests that the impact of the pre-defined threshold \u03f5 should be further studied. However, the comment does not provide specific examples, reasoning, or references to support why the current study is insufficient or how the impact of the threshold could be better explored. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically pointing out that the impact of the pre-defined threshold \u03f5 should be further explored. This feedback is somewhat helpful as it highlights a specific area for improvement in the study. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to conduct this further study or what specific aspects should be examined. While it offers a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the evaluation process, specifically that only Rouge-L is used for evaluation, which may not be reliable for certain classification tasks. However, it does not provide any explicit or implicit suggestions on how the authors could address this issue or improve the evaluation process. There is no guidance on alternative metrics, additional evaluations, or modifications to the current evaluation method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of Rouge-L as the sole evaluation metric, suggesting that it may not be reliable for certain classification tasks. However, it does not specify which part of the paper discusses the evaluation metrics, making it weakly grounded. The comment is specific in identifying the issue with Rouge-L as a metric, but without clear grounding, the authors may struggle to pinpoint where this issue is addressed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation is unreliable, especially for classification tasks, as Rouge-L is not sensitive enough. However, the comment lacks specific examples or references to support this claim, such as studies that demonstrate the limitations of Rouge-L in classification tasks. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a limitation in the evaluation process, specifically the reliance on Rouge-L as the sole metric for evaluation. It highlights that Rouge-L may not be sensitive enough for classification tasks, which is a relevant observation. However, the comment does not provide specific suggestions or alternative metrics that could be used to improve the evaluation process. While it points out an area for improvement, it lacks actionable guidance, making it somewhat helpful. The authors are informed of a potential issue but are not directed on how to address it effectively. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the evaluation process, specifically the reliance on Rouge-L as the sole metric for evaluation. It suggests that Rouge-L may not be sensitive enough for classification tasks. However, the comment does not provide any explicit or implicit suggestions on how the authors could address this issue or improve the evaluation process. There is no guidance on alternative metrics, additional evaluations, or modifications to the current evaluation method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the evaluation process, noting that only Rouge-L is used as the evaluation metric and suggesting that it may not be reliable for classification tasks. However, it does not specify which part of the paper discusses the evaluation metrics, making it weakly grounded. The comment is specific in identifying the issue with Rouge-L as a metric, but without clear grounding, the authors may struggle to pinpoint where this issue is addressed in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation is unreliable, especially for classification tasks, as Rouge-L is not sensitive enough. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or comparisons to other metrics or evaluation methods, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation process, specifically the reliance on Rouge-L as the sole metric for evaluation. It points out that Rouge-L may not be sensitive enough for classification tasks, which is a relevant observation. However, the comment lacks specific suggestions or guidance on how the authors could address this issue or improve the evaluation process. Without actionable advice or alternative metrics to consider, the feedback provides only limited value to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment identifies a limitation in the evaluation process, specifically the reliance on Rouge-L as the sole metric for evaluation. It suggests that Rouge-L may not be sensitive enough for classification tasks. However, the comment does not provide any explicit or implicit suggestions on how the authors could address this issue or improve the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the definitions of variables in lines 580-588, stating that they do not properly match the formula (Equation 3) and that the variable \"n_k\" is missing. This provides a clear and direct action for the authors to take, which is to correct the definitions to ensure they accurately reflect the formula. The comment is specific and provides concrete guidance on what needs to be revised, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not properly matching the formula (Equation 3) and the absence of the variable \"n_k\" in Equation 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables in lines 580-588 do not properly match the formula (Equation 3) and that the variable \"n_k\" is missing. This is a specific and verifiable claim as it directly points out a discrepancy between the definitions and the formula, allowing the authors to easily identify the issue. The comment provides a clear rationale for the claim, making it fully verifiable. Therefore, the feedback is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables in lines 580-588, noting that they do not properly match the formula (Equation 3) and that the variable \"n_k\" is missing. This feedback is clear and actionable, as it directly points out a discrepancy that the authors need to address to ensure the accuracy and consistency of their work. By highlighting this issue, the comment provides the authors with a concrete step to improve their draft, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. It also mentions that some key experiments are missing. While the comment implies that the authors should address the issue of the class-specific token and consider the missing experiments, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary changes and experiments to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. It also mentions that some key experiments are missing. However, the comment does not specify which part of the paper discusses the class-specific token or the missing experiments, making it weakly grounded. The comment is specific in its critique of the class-specific token strategy and the need for additional experiments, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. This is a relevant point that could impact the validity of the paper\\'s approach. Additionally, the comment points out that some key experiments are missing, which is important for the completeness and robustness of the paper. While the comment identifies important areas for consideration and improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights significant concerns but does not provide detailed direction for improvement, leaving the authors with a general idea of what needs attention but without actionable steps. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. It also mentions that some key experiments are missing. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how to address these concerns or what specific experiments are missing. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. It also mentions that some key experiments are missing. However, the comment does not specify which part of the paper discusses the class-specific token or the missing experiments, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its critique of the class-specific token strategy and the need for additional experiments, but without clear references or detailed guidance, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that such a strategy might conflict with the sample-specific assumption of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks detailed explanation or examples that would help the authors understand the basis of the concern or how to address it. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the sufficiency of a single vector for each class with large variances in the semantic"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, suggesting that further clarification is needed to ensure a fair comparison. The comment explicitly states that the authors should provide clarification on the intent discovery experiment setting to address this limitation. While the action is clear, it lacks specific guidance on how to achieve this clarification or what aspects of the experiment setting need to be addressed. Therefore, the comment is somewhat actionable, as it provides a direct action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"IntenDD experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of known number of intent classes during graph construction and questions the comparability of the IntenDD experiments to the cited baselines. The comment further suggests that further clarification is needed to ensure a fair comparison with the baselines. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the assumption of known number of intent classes during graph construction, questioning the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. The reviewer acknowledges that this is a limitation of the work but suggests that further clarification is needed to ensure a fair comparison. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for further clarification is logical, but the comment could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, suggesting that further clarification is needed to ensure a fair comparison. The comment acknowledges the authors\\' acknowledgment of this limitation but emphasizes the need for additional clarification on the intent discovery experiment setting. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the experimental setup to address the limitation. However, it could be more helpful if it offered specific suggestions on how to clarify the experiment setting or what aspects of the comparison need further elaboration. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, suggesting that further clarification is needed to ensure a fair comparison. The comment explicitly states that the authors should provide clarification on the intent discovery experiment setting to address this limitation. While the action is clear, it lacks specific guidance on how to achieve this clarification or what aspects of the experiment setting need to be addressed. Therefore, the comment is somewhat actionable, as it provides a direct action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"IntenDD experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of known number of intent classes during graph construction and questions the comparability of the IntenDD experiments to the cited baselines. The comment further suggests that further clarification is needed to ensure a fair comparison with the baselines. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the assumption of known number of intent classes during graph construction, questioning the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. The reviewer acknowledges that this is a limitation of the work but suggests that further clarification is needed to ensure a fair comparison. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for further clarification is logical, but the comment could be strengthened with more detailed evidence or references"}
{"generated_text": "{'actionability_rationale': \"The review comment appreciates the rigorous experimentation but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The reviewer provides references to related work, suggesting that the authors consider these references in their analysis. However, the comment does not explicitly instruct the authors to incorporate these references or provide specific guidance on how to address the limitations in their results. The action is implicit and somewhat vague, as the authors need to infer that they should consider these references and possibly incorporate them into their analysis. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work, suggesting that the authors consider these references in their analysis. However, it does not specify which part of the paper these issues pertain to, such as specific sections or experiments. While the authors might infer that it relates to the results and experimental sections, the comment lacks explicit grounding. It is specific about the limitations and references but does not provide detailed guidance on how to address them. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point appreciates the rigorous experimentation but criticizes the significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The reviewer supports these claims by referencing related work, specifically mentioning \"Invariant risk minimization\" and \"Last layer re-training is sufficient for robustness to spurious correlations.\" These references provide a solid foundation for the critique, making the claim mostly verifiable. However, the comment could be further strengthened by providing more detailed reasoning or examples from the referenced works, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment appreciates the rigorous experimentation in the work but points out a limitation in the significance of the results. It explains that the application of d-separation criteria in the intervened graph with known variables and causal relationships is expected to work, and the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work, suggesting that the authors consider these references in their analysis. While the comment identifies a limitation and offers some guidance by referencing related work, it lacks specific suggestions or actionable steps for the authors to address the issue. The feedback is somewhat helpful as it provides insight into the limitations of the work but could be more comprehensive with additional guidance. Therefore, it is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment appreciates the rigorous experimentation but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work, suggesting that the authors consider these references in their analysis. However, it does not explicitly instruct the authors to incorporate these references or provide specific guidance on how to address the limitations in their results. The action is implicit and somewhat vague, as the authors need to infer that they should consider these references and possibly incorporate them into their analysis. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation but points out limitations in the significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work, suggesting that the authors consider these references in their analysis. However, it does not specify which part of the paper these issues pertain to, such as specific sections or experiments. While the comment is specific about the limitations and references, it lacks grounding as it does not direct the authors to a particular part of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting alternative methods or approaches to consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this concern pertains to, such as specific sections or experiments where these methods are discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodological approach but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reliance on gradient-based saliency methods to evaluate feature map channel importance may not align with the underlying feature selection mechanisms in the human brain. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or explore alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity in terms of what aspects of the methodology or results are problematic, and it does not provide suggestions for improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the reliance on gradient-based saliency methods to evaluate the importance of feature map channels may not align with the underlying feature selection mechanisms in the human brain. However, the comment lacks supporting evidence, detailed reasoning, or references to substantiate this claim. Without specific examples or references to alternative methods or studies, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that this may not align with the underlying feature selection mechanisms in the human brain. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the reliance on gradient-based saliency"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the paper uses Pythia, which is not state-of-the-art (SOTA), but it does have the advantage of available checkpoints. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider using a more advanced model, how to address the lack of state-of-the-art status, or if there are any specific improvements that could be made. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the choice of model used in the paper, specifically mentioning \"Pythia,\" which provides full grounding as it allows the authors to identify the specific part of the paper being discussed. However, the comment lacks specificity as it does not elaborate on why Pythia is not state-of-the-art or how it could be improved. It also does not provide suggestions for alternative models or improvements. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper uses Pythia, which is not state-of-the-art (SOTA), but it does have the advantage of available checkpoints. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why Pythia is considered not state-of-the-art. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper uses Pythia, which is not state-of-the-art (SOTA), but it does have the advantage of available checkpoints. While this observation highlights a potential limitation in the choice of model, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their work. Without specific recommendations or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the challenges in the image observation version of Franka Kitchen and suggests that more information or resources should be provided to address these challenges. It asks whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be intuitively completed with the provided offline data. The comment implies that the authors should provide additional information or resources to help the community address these challenges. However, it does not explicitly instruct the authors on what specific information or resources should be provided or how to address the questions raised. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the challenges in the image observation version of Franka Kitchen, suggesting that more information or resources should be provided to address these challenges. It asks whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be intuitively completed with the provided offline data. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in terms of what needs to be addressed, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions asking for more information or resources to address specific challenges in the image observation version of Franka Kitchen. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the challenges in the image observation version of Franka Kitchen. It suggests that more information or resources should be provided to address these challenges, which is a valuable point for the authors to consider. The comment also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and whether the task can be intuitively completed with the provided offline data. These questions prompt the authors to critically evaluate their work and consider alternative approaches or data sources. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these challenges. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question asking for insight into why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. While it implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to address this issue, but it is somewhat vague because it lacks specific guidance on how to provide the insight. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the performance of the multilingual model on specific evaluations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance of the multilingual model, specifically why it is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This is a relevant point that could help the authors understand and address potential weaknesses in their model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or improve the model\\'s performance. While it prompts the authors to consider an important aspect of their results, it does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for further exploration but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the numbers in brackets in tables #1 and #2. While it explicitly asks for clarification, it does not provide any guidance on how the authors should address this issue or what specific information should be included. The action is clear but lacks concrete details on how to implement the change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of the numbers in brackets (1),(4) in those tables. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of numbers in brackets in specific tables. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the meaning of the numbers in brackets in tables #1 and #2. While it identifies a potential area of confusion, it does not provide any context or explanation about what these numbers might represent or why they are included. This lack of context makes it difficult for the authors to understand the significance of the question or how to address it effectively. The comment is somewhat helpful as it points out a potential issue, but it lacks depth and actionable guidance, leaving the authors with only a vague direction for improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It asks how these results relate to long-term fairness, as claimed in the paper. While the comment highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the connection between their results and the limitations discussed. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented RDRO results and the listed limitations, specifically questioning how these results relate to the limitations of previous fairness notions. However, it does not specify which part of the paper discusses these limitations, making it weakly grounded. The comment is specific in its inquiry about the connection between the results and long-term fairness, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the connection between the presented RDRO results and the listed limitations of previous fairness notions. The reviewer acknowledges the paper\\'s focus on repeated distributionally robust optimization and convergence analysis but expresses uncertainty about how these results relate to the limitations discussed. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable due to the absence of supporting evidence or detailed explanation.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It highlights a potential gap in the paper regarding how these results relate to long-term fairness, as claimed in the paper. While the comment identifies an area of concern, it lacks specific suggestions or guidance on how the authors might address this issue or clarify the connection. The feedback is somewhat helpful as it prompts the authors to consider and potentially expand on this aspect of their work, but it could be more beneficial with additional detail or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It asks how these results relate to long-term fairness, as claimed in the paper. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the connection. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to clarify the connection, but the comment does not offer specific steps or examples to guide them in doing so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It acknowledges the paper\\'s focus on repeated distributionally robust optimization and convergence analysis but expresses uncertainty about how these results relate to the limitations discussed. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The question is specific in its inquiry about the connection to long-term fairness, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the connection between the presented RDRO results and the listed limitations of previous fairness notions. While it acknowledges the paper\\'s focus on repeated distributionally robust optimization and convergence analysis, it expresses uncertainty about how these results relate to the limitations discussed. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable due to the absence of supporting evidence or detailed explanation.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It highlights a potential gap in the paper regarding how these results relate to long-term fairness, as claimed in the paper. While the comment identifies an area of concern, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify the connection. The feedback prompts the authors to consider and potentially expand on this aspect of their work, but it lacks actionable advice or detailed direction. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_r"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether these errors are normalized to per datapoint position errors and, if so, whether the error of 5 cm with HDR-IL is unreasonable. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors can infer that they need to clarify the normalization process and possibly provide additional context or analysis, but the comment lacks concrete steps or suggestions for improvement. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the accuracy of 29 percent with table assembly tasks and questions the normalization of Euclidean distance error units. The comment provides a clear critique of the results and suggests a potential issue with the normalization process, offering a specific point for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether these errors are normalized to per datapoint position errors and suggests that an error of 5 cm with HDR-IL might be unreasonable. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claims. The authors are left to infer the basis of the concern, which makes the comment somewhat verifiable. Therefore, the feedback is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the accuracy of 29 percent in table assembly tasks and questions the normalization of Euclidean distance error units in Table 1. It raises a concern about the high error units, particularly with an error of 5 cm with HDR-IL, suggesting that this might be unreasonable. While the comment highlights a potential problem, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve the accuracy of their results. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more beneficial with additional context or actionable advice. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether these errors are normalized to per datapoint position errors and suggests that an error of 5 cm with HDR-IL might be unreasonable. While the comment identifies specific issues, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The authors can infer that they need to clarify the normalization process and possibly provide additional analysis, but the feedback lacks concrete steps or detailed advice. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not fully guide the authors on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the accuracy of 29 percent with table assembly tasks and questions the normalization of Euclidean distance error units. The comment provides a clear critique of the results and suggests a potential issue with the normalization process, offering a specific point for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether these errors are normalized to per datapoint position errors and suggests that an error of 5 cm with HDR-IL might be unreasonable. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claims. The authors are left to infer the basis of the concern, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the accuracy of 29 percent in table assembly tasks and questions the normalization of Euclidean distance error units in Table 1. It raises a concern about the high error units, particularly with an error of 5 cm with HDR-IL"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the article does not reach a conclusion and suggests that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might revise their work to reach a conclusion or what specific changes could be made to strengthen their argument. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this issue pertains to, such as specific sections or discussions. The authors might infer that it relates to the conclusion or discussion sections, but this inference is not direct. The comment is specific in its critique of the article\\'s lack of conclusion, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article does not reach a conclusion and suggests that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the article, noting that it does not reach a conclusion and suggesting that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not clarify what aspects of the conclusion are missing or how the authors might address the issue of existing models being capable of handling both types of sentences. Without detailed guidance or examples, the authors are left with a vague understanding of the problem and no clear path to improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the article does not reach a conclusion and suggests that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how the authors might revise their work to reach a conclusion or improve the analysis of existing models. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in terms of what aspects of the conclusion are missing or how the authors might address the issue of existing models being capable of handling both types of sentences. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the article does not reach a conclusion and suggests that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the article, noting that it does not reach a conclusion and suggesting that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not clarify what aspects of the conclusion are missing or how the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results are not particularly surprising and have limited contribution to the algorithm design, as the design is based on a pre-defined labeler strategy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the theoretical results or contribute more to the algorithm design. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, stating that they are not particularly surprising and have limited contribution to the algorithm design. However, it does not specify which part of the paper these theoretical results are discussed in, nor does it provide details on what aspects of the results are considered unimportant or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results are not particularly surprising and have limited contribution to the algorithm design, as the design is based on a pre-defined labeler strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to substantiate the assertion, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment critiques the theoretical results, stating that they are not particularly surprising and have limited contribution to the algorithm design. It suggests that the algorithm design is based on a pre-defined labeler strategy. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. Without identifying specific aspects of the theoretical results that are unhelpful or offering guidance on how to enhance them, the authors are left without a clear path to address the critique. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the theoretical results, stating that they are not particularly surprising and have limited contribution to the algorithm design. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might enhance the theoretical results or their contribution to the algorithm design. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, stating that they are not particularly surprising and have limited contribution to the algorithm design. However, it does not specify which part of the paper these theoretical results are discussed in, nor does it provide details on what aspects of the results are considered unimportant or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results are not particularly surprising and have limited contribution to the algorithm design, as the design is based on a pre-defined labeler strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to substantiate the assertion, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the theoretical results, stating that they are not particularly surprising and have limited contribution to the algorithm design. It suggests that the algorithm design is based on a pre-defined labeler strategy. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. Without identifying specific aspects of the theoretical results that are unhelpful or offering guidance on how to enhance them, the authors are left without a clear path to address the critique. As a result, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label':"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the lack of detail on how reverse chain is effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional analyses, experiments, or explanations. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the lack of detail on how reverse chain is effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint where improvements are needed. The comment lacks grounding as it does not reference specific sections, figures, or tables. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two claims: \"How reverse chain proved to be effective in multi-API planning is not delineated in detail\" and \"This article focuses on comparing multiple tools or methods in API calling & planning & reduces research contribution.\" The first claim is a subjective opinion about the lack of detail on the effectiveness of reverse chain, while the second claim is a judgment about the focus of the article. Neither of these claims is supported by specific reasoning, examples, or references, making it difficult for the authors to understand the basis of the critique. Therefore, the review point is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the effectiveness of the reverse chain in multi-API planning is not detailed, suggesting that this aspect needs more explanation or elaboration. Second, it critiques the focus of the article, which is on comparing multiple tools or methods in API calling and planning, stating that this reduces the research contribution. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it provides some insight into potential weaknesses, but it could be more beneficial with additional detail or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two issues: the lack of detail on how reverse chain is effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the explanation of reverse chain or suggestions for enhancing the research contribution. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies two issues: the lack of detail on how reverse chain is effective in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, it does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint where improvements are needed. The comment lacks grounding as it does not reference specific sections, figures, or tables. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two claims: \"How reverse chain proved to be effective in multi-API planning is not delineated in detail\" and \"This article focuses on comparing multiple tools or methods in API calling & planning & reduces research contribution.\" The first claim is a subjective opinion about the lack of detail on the effectiveness of reverse chain, while the second claim is a judgment about the focus of the article. Neither of these claims is supported by specific reasoning, examples, or references, making it difficult for the authors to understand the basis of the critique. Therefore, the review point is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the effectiveness of the reverse chain in multi-API planning is not detailed, suggesting that this aspect"}
{"generated_text": "{'actionability_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it does not offer any explicit or implicit actions for the authors to take to address these weaknesses. The comment lacks guidance on how the authors might improve the experimental rigour or what specific changes could be made to support acceptance. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it does not specify which weaknesses are being referred to or provide details on how these weaknesses could be addressed. Additionally, it does not mention any specific sections, figures, or tables that need improvement, making it difficult for the authors to pinpoint the exact areas needing attention. The lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, the comment lacks detailed justification or examples to support the claim that the weaknesses cannot be fixed in time, content space, or degree. It also does not provide specific suggestions or references to address these issues, making it difficult for the authors to understand the basis of the rejection. As a result, the claim is not verifiable due to the absence of supporting evidence or reasoning, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it lacks specificity and does not offer actionable suggestions or guidance on how the authors might address these weaknesses or improve the paper. The comment does not provide details on what aspects of the experimental rigour are problematic or how they could be resolved. Without specific feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it does not offer any explicit or implicit actions for the authors to take to address these weaknesses or improve the paper. The comment lacks actionable guidance or suggestions on how the authors might strengthen their experimental rigour or address the identified issues. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it does not specify which weaknesses are being referred to or provide details on how these weaknesses could be addressed. Additionally, it lacks grounding as it does not mention specific sections, figures, or tables that need improvement. The comment also lacks specificity in terms of what aspects of the experimental rigour are problematic or how they could be fixed. As a result, the authors are left without clear guidance on how to address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it lacks detailed justification or evidence to support the claim that the weaknesses cannot be fixed in time, content space, or degree. Additionally, it does not provide specific examples or references to substantiate the assertion about the unrealistic nature of the required editing. Without concrete reasoning or evidence, the claim remains unverifiable, making it difficult for the authors to understand the basis of the rejection. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a recommendation for rejection based on the weaknesses identified in the paper, specifically regarding experimental rigour. However, it lacks specificity and actionable guidance on how the authors might address these weaknesses or improve the paper. The comment does not provide detailed feedback on what aspects of the experimental rigour are problematic or how they could be strengthened. Without specific suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies an issue with the comparison between Medusa and Medusa+ParallelSpec, specifically noting the unfair competition due to the change in draft model architecture. It suggests that a baseline should be provided where the only alteration is the draft model architecture, or the modified setting should be given a different name to avoid confusion. This feedback provides a clear and explicit action for the authors to take, which is to either provide a baseline or rename the modified setting. The suggestion is concrete, as it specifies the exact changes needed to address the issue. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions specific lines (266-267) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the unfair competition between Medusa and Medusa+ParallelSpec, and suggests providing a baseline or renaming the modified setting to avoid confusion regarding the draft model architecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the fairness of the competition between Medusa and Medusa+ParallelSpec, specifically noting the change in draft model architecture from an MLP-like structure to a single-layer Transformer model. The reviewer questions whether the speedup gain is due to the model architecture change or parallel prediction. The comment suggests providing a baseline or renaming the modified setting to avoid confusion. While the claim is based on a logical reasoning about the potential impact of model architecture changes, it lacks specific examples or references to support the assertion. This makes the claim somewhat verifiable, as it provides a reasonable basis for the critique but requires further elaboration to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the fairness of the comparison between Medusa and Medusa+ParallelSpec, specifically noting the change in draft model architecture from an MLP-like structure to a single-layer Transformer model. It questions whether the speedup gain is due to the model architecture change or parallel prediction. The comment suggests providing a baseline or renaming the modified setting to avoid confusion regarding the draft model architecture. This feedback is clear and actionable, as it guides the authors to address a potential source of bias in their experimental setup. By suggesting specific steps to clarify the comparison, the comment offers valuable guidance for improving the draft. Therefore, it is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the reason for focusing on Masked Language Models and whether experiments did not work with an autoregressive LM. While it raises a valid point, it does not provide explicit guidance or suggestions for the authors to follow. The comment lacks actionable details, such as recommending specific experiments or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the focus on Masked Language Models and whether experiments did not work with an autoregressive LM. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the reasons behind the choice of Masked Language Models and the outcomes of experiments with autoregressive LMs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of Masked Language Models and whether experiments did not work with an autoregressive LM. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the focus on Masked Language Models and whether experiments did not work with an autoregressive LM. While it highlights a potential area of interest or concern, it does not provide specific guidance or suggestions for the authors to address this issue. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is rated as barely helpful, as it identifies a potential area for exploration but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks how the map is encoded, and second, it suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. The first question implies that the authors should provide more information about the encoding process, but it does not specify how this information should be presented or what details are missing. The second question is more explicit, as it directly instructs the authors to show the effectiveness of their method on specific experiments. However, it lacks concrete guidance on how to achieve this demonstration. Overall, the comment provides some direction but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific questions: how the map is encoded and whether the authors have shown the effectiveness of their method on the experiments proposed in YNet. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors might infer that these questions relate to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the encoding of the map and the demonstration of effectiveness on YNet experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for clarification and additional information. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions: how the map is encoded and whether the authors have demonstrated the effectiveness of their method on the experiments proposed in YNet. While these questions highlight areas that need clarification or further elaboration, they do not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address these issues or enhance their draft, leaving the authors with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, as it identifies areas of concern but lacks depth and specificity in guiding the authors toward improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements to the model or providing additional analysis. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the comparison between the proposed model and the MSA Transformer in terms of r2. However, it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the proposed model not being significantly better than the MSA Transformer in terms of r2. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the proposed model, noting that it is not significantly better than the MSA Transformer in terms of r2. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their model. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment requests more mathematical details regarding the explanation of the hypothesis that large chunks of the final representation of wide DNNs behave approximately like an ensemble of independent measures of the full feature space. The reviewer explicitly states that they do not understand the term 'ensemble of independent measures on the full feature space' and why it explains the scaling. This feedback provides a clear and explicit action for the authors to take, which is to include more detailed mathematical explanations. The comment is specific in its request for additional information, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"top of page 6\" and refers to specific content, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: more mathematical details regarding the explanation of the hypothesis and the term \"ensemble of independent measures on the full feature space.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the clarity of a statement regarding the interpretation of the decay of test error in wide DNNs. It requests more mathematical details to understand the explanation provided. While the comment highlights a lack of clarity, it does not present a claim or opinion that requires verification. It is a request for clarification, making it a normal statement. Therefore, it should be labeled as 'No'.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper where the explanation is lacking clarity, particularly regarding the interpretation of the decay of test error in wide DNNs. It highlights the need for more mathematical details to support the hypothesis that large chunks of the final representation behave like an ensemble of independent measures of the full feature space. This feedback is clear and actionable, as it directs the authors to provide additional mathematical explanations to clarify their argument. However, the comment could be more helpful if it offered specific suggestions on how to present these details or examples of similar explanations in the literature. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider using BlenderBot 2.0 with incorporated knowledge to improve dialog quality by leveraging domain ontologies from the SGD dataset. While the suggestion is explicit, it lacks concrete guidance on how to implement this idea or what specific aspects to focus on. The authors are given a clear direction to explore, but the comment could be more actionable if it provided details on how to integrate the suggested approach or what specific outcomes to expect. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an action related to using BlenderBot 2.0 with incorporated knowledge to improve dialog quality by leveraging domain ontologies from the SGD dataset. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use BlenderBot 2.0 with incorporated knowledge and leveraging domain ontologies, providing clear guidance on what could be explored. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an action for the authors to consider using BlenderBot 2.0 with incorporated knowledge to improve dialog quality by leveraging domain ontologies from the SGD dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it might impact the results. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting exploration by recommending the use of BlenderBot 2.0 with incorporated knowledge to improve dialog quality by leveraging domain ontologies from the SGD dataset. This feedback is somewhat helpful as it provides a specific direction for the authors to consider, which could lead to innovative improvements in their work. However, the comment lacks depth and does not offer detailed guidance or examples on how to implement this suggestion. To be more helpful, the comment could include specific considerations, potential challenges, or expected outcomes. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. While the comment identifies a specific issue that needs clarification, it does not provide explicit instructions on how to address it. The authors can infer that they need to clarify this aspect in their paper, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the clarity of information about the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification on the overlap of samples, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make the necessary changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. However, the comment lacks specific examples or detailed reasoning to support this assumption, making it difficult for the authors to understand the basis of the claim. Without explicit evidence or references, the claim remains somewhat vague, requiring the authors to infer the rationale behind the suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of information regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$, but this assumption is not explicitly stated in the paper. This feedback is somewhat helpful as it points out a potential area of confusion or lack of clarity in the manuscript. However, it does not provide specific suggestions on how to address this issue, such as recommending where this information should be included or how to present it clearly. Therefore, the comment is rated as somewhat helpful, as it highlights an area for improvement but lacks detailed guidance for the authors.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue regarding the clarity of information about the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. However, the comment does not provide explicit guidance on how the authors should address this issue or where in the paper this information should be clarified. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the clarity of information about the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification on the overlap of samples, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make the necessary changes. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, given the calculation of Krippendorff $\\\\alpha$. However, the comment lacks specific examples or detailed reasoning to support this assumption, making it difficult for the authors to understand the basis of the claim. Without explicit evidence or references, the claim remains vague, requiring the authors to infer the rationale behind the suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the clarity of information about the number of samples rated by GPT-4 and whether"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. While the comment identifies areas of confusion, it does not explicitly instruct the authors on how to address these issues or provide concrete steps for clarification. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms and provide additional explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the terms and the intuition provided, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and an intuition about the relationship between pred-wise consistency and label annotation agreement. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement, which could be relevant to the paper\\'s discussion. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the clarity of their explanations. While it identifies areas of confusion, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are provided, could enhance reproducibility. It also recommends sharing the code of the implementation, which is considered the maximum level of reproducibility one can expect. The comment explicitly states the actions to take\u2014providing more details and sharing the code\u2014and offers clear guidance on how to implement these actions. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are provided, to enhance reproducibility. It also recommends sharing the code of the implementation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these details would be discussed. The suggestion to share the code is specific, but the comment lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, could enhance reproducibility. It also recommends sharing the code of the implementation, which is considered the maximum level of reproducibility. While the comment provides a logical reasoning for the importance of these details, it lacks specific examples or references to support the claim. The suggestion to share the code is a common practice for reproducibility, but the comment could be strengthened by offering more detailed reasoning or examples of how these details would improve reproducibility. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are provided. This guidance is valuable as it directly addresses a potential barrier to reproducibility. Additionally, the comment recommends sharing the code of the implementation, which is considered the maximum level of reproducibility one can expect. This suggestion is clear and constructive, offering the authors a concrete way to enhance the reproducibility of their work. The feedback is mostly helpful as it provides actionable steps for improvement, although it could be further enhanced by offering more detailed guidance on how to implement these suggestions. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are provided, to enhance reproducibility. It also recommends sharing the code of the implementation, which is considered the maximum level of reproducibility one can expect. The comment explicitly states the actions to take\u2014providing more details and sharing the code\u2014and offers clear guidance on how to implement these actions. This makes the feedback highly actionable, as the authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing the code of the implementation, which is considered the maximum level of reproducibility. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these details would be discussed. The suggestion to share the code is specific, but the comment lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, could enhance reproducibility. It also recommends sharing the code of the implementation, which is considered the maximum level of reproducibility one can expect. While the comment provides a logical reasoning for the importance of these details, it lacks specific examples or references to support the claim. The suggestion to share the code is a common practice for reproducibility, but the comment could be strengthened by offering more detailed reasoning or examples of how these details would improve reproducibility. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a repeated paragraph in the first paragraph of section 3.3, which is a clear and direct action for the authors to take. By pointing out the repetition, the reviewer provides specific guidance on what needs to be addressed, ensuring that the authors know exactly what changes to make. The comment is highly actionable as it provides concrete instructions for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a repeated paragraph in the first paragraph of section 3.3. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a repeated paragraph in the first paragraph of section 3.3. This is a factual observation about the content of the paper, which does not require any verification or justification. It is a statement of fact rather than an opinion or suggestion, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, pointing out that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and actionable, as it directly instructs the authors to identify and remove the repeated content. By addressing this issue, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to avoid such repetitions in the future. Overall, the comment is mostly helpful as it provides a concrete step for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data, suggesting that the authors consider these aspects. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what specific actions they should take to improve the sustainability and reusability of synthetic data. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to respond to the feedback. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the sustainability and reusability of synthetic data, which is generated on-the-fly. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or discussion related to data generation or sustainability. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the sustainability and reusability of synthetic data, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data generated on-the-fly. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might impact the study. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the sustainability and reusability of synthetic data generated on-the-fly. This is a relevant concern that could impact the practicality and long-term applicability of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it highlights a potential weakness, it does not offer actionable feedback or detailed insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a relevant area for consideration but lacks the depth needed to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. While it highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they should explore alternative RNA structures and incorporate RNA abundance into their dataset building process, but without specific instructions or examples, the actions remain vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to the challenge of RNA folding. It highlights two specific issues: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. However, the comment does not explicitly mention which part of the paper discusses the ProbTransfomer model or the RNA folding challenge, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the examination of alternative RNA structures and the consideration of RNA abundance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the ProbTransfomer model\\'s application to RNA folding, specifically noting that the likelihood of alternative RNA structures is mostly dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. While the comment identifies potential areas for improvement, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors are left to infer the importance of these considerations, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. This is a relevant observation that could enhance the paper\\'s analysis. Second, the comment suggests considering RNA abundance when building datasets, which is another important aspect that could improve the robustness of the study. While the comment highlights these areas, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it provides some insight into potential weaknesses but does not offer comprehensive guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two areas for improvement: the examination of alternative RNA structures and the consideration of RNA abundance when building datasets. While it highlights these issues, it does not provide explicit guidance or suggestions on how the authors should address them. The comment lacks concrete steps or examples, leaving the authors to infer the necessary actions. As a result, the feedback is somewhat actionable, as it points out areas for improvement but does not offer detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to the challenge of RNA folding. It highlights two specific issues: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. However, the comment does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to sections discussing the model or dataset building, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding alternative RNA structures and RNA abundance, providing clear guidance on potential improvements. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the ProbTransfomer model\\'s application to RNA folding, specifically noting that the likelihood of alternative RNA structures is mostly dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. While the comment identifies potential areas for improvement, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors are left to infer the importance of these considerations, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. This is a relevant observation that could enhance the paper\\'s analysis. Second, the comment suggests considering RNA abundance when building datasets, which is another important aspect that could improve the robustness of the study. While the comment highlights these areas, it lacks detailed"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\\\eta=1200), which the reviewer suspects is a weak regularization term. The reviewer suggests that this could lead to sparse couplings and favor their method. The comment explicitly advises the authors to acknowledge this in the paper and not overlook it. While the action is clear\u2014acknowledging the potential issue\u2014it does not provide specific guidance on how to address it, such as suggesting alternative regularization coefficients or methods to test. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of a single entropic regularization coefficient (\\\\eta=1200) and suggests that this could lead to sparse couplings, which may favor the authors\\' method. The comment further advises the authors to acknowledge this in the paper and not overlook it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the numerical results, specifically the use of a single entropic regularization coefficient (\\\\eta=1200), which the reviewer suspects is a weak regularization term. The comment suggests that this could lead to sparse couplings and favor the authors' method, but it does not provide specific evidence or references to support this claim. The reasoning is based on logical deduction, but without detailed justification or examples, the claim remains somewhat verifiable. The authors would need to further investigate and verify the claim themselves, making it a 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\\\eta=1200), which the reviewer suspects is a weak regularization term. This could lead to sparse couplings and favor the authors' method. The comment advises the authors to acknowledge this in the paper and not overlook it, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to address this issue or suggested alternative regularization coefficients to consider. Overall, the feedback is somewhat helpful as it points out a potential weakness and encourages the authors to address it, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\\\eta=1200), which the reviewer suspects is a weak regularization term. The comment suggests that this could lead to sparse couplings and favor the authors' method. The reviewer advises the authors to acknowledge this in the paper and not overlook it. While the comment provides a clear direction for the authors to address the issue, it lacks specific guidance on how to investigate or mitigate the potential problem. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of a single entropic regularization coefficient (\\\\eta=1200) and suggests that this could lead to sparse couplings, which may favor the authors\\' method. The comment further advises the authors to acknowledge this in the paper and not overlook it. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the numerical results, specifically the use of a single entropic regularization coefficient (\\\\eta=1200), which the reviewer suspects is a weak regularization term. The comment suggests that this could lead to sparse couplings and favor the authors' method. While the reasoning is based on logical deduction, it lacks specific evidence or references to support the claim that \\\\eta=1200 is a weak regularization term. The comment also does not provide detailed reasoning or examples to substantiate the concern about sparse couplings. This makes the claim somewhat verifiable, as the authors would need to further investigate and verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the statement in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s claim that the dataset includes sources used by the journalists. However, it does not provide explicit guidance on how the authors should address this discrepancy. The comment implies that the authors should clarify or correct the information in Table 1, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the statement in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s claim that it includes sources used by the journalists. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s statement that it includes sources used by the journalists. This discrepancy is supported by the paper\\'s claim that it includes sources such as tables with statistics and reports from governments, think tanks, and other organizations. However, the comment does not provide specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to verify the accuracy of the paper\\'s claim by reviewing the dataset and its sources, which is a reasonable expectation but could be improved with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s statement that it includes sources used by the journalists. This feedback is valuable as it points out a potential inconsistency that the authors need to address. However, the comment does not provide specific guidance on how to resolve this discrepancy or suggest ways to clarify the information in Table 1. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s statement that it includes sources used by the journalists. However, it does not provide explicit guidance on how the authors should address this discrepancy. The comment implies that the authors should clarify or correct the information in Table 1, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the statement in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s claim that it includes sources used by the journalists. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the paper\\'s statement that it includes sources used by the journalists. The comment provides a specific reference to the paper\\'s claim about the sources included, which supports the assertion. However, it lacks detailed evidence or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to verify the accuracy of the paper\\'s claim by reviewing the dataset and its sources, which is a reasonable expectation but could be improved with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no evidence and the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include details about the parameters used in each simulator, such as whether they used the GPU pipeline in IsaacGym, the CPU pipeline, the number of substeps for physics simulation, and the total number of vertices in the simulation. This feedback provides a clear and direct action for the authors to take, specifying exactly what information needs to be added to improve the draft. The comment is specific and actionable, ensuring that the authors know exactly what changes to make to enhance their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to include details about the parameters for each simulator, such as the GPU pipeline in IsaacGym or the CPU pipeline, the number of substeps for physics simulation, and the total number of vertices in the simulation. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific, as it clearly specifies what information should be included to address the issue of different simulators having different parameters that affect performance. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that including details about the parameters used in different simulators is important for understanding their performance. However, the comment does not provide any specific reasoning or evidence to support why this information is crucial or how it might affect the overall performance. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion by recommending that the authors include details about the parameters used in each simulator. This feedback is clear and directly addresses a potential weakness in the paper, which is the lack of transparency regarding the parameters that could significantly impact the overall performance. By following this advice, the authors can enhance the comprehensiveness and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or how they might influence the results. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the empirical selection of hyperparameters $s$ and $k$ in the proposed method, which affects the generalizability of the loss function. It suggests that the authors should provide a more detailed explanation or justification for these choices. While the comment implies that the authors should include additional information in the main text, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to provide more context or justification for their choices. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the empirical selection of hyperparameters $s$ and $k$ and its impact on the generalizability of the proposed loss function. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the empirical selection of hyperparameters $s$ and $k$ reduces the generalizability of the proposed loss function. The reviewer supports this claim by noting that only the choice of $s$ and $k$ as $5$ is mentioned in the supplementary material, without providing a rationale or justification for this choice. This lack of detailed explanation or evidence makes the claim somewhat verifiable, as the authors would need to further explore the reasoning behind the empirical selection to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically the empirical selection of hyperparameters $s$ and $k$ in the sparse-CL and k-NL mask. It highlights that the choice of these parameters is crucial for the effectiveness of the method but notes that only a cross-validation-based selection is provided in the supplementary material. This feedback is valuable as it points out a potential limitation in the generalizability of the proposed loss function. However, the comment could be more helpful if it suggested ways to justify or explain the choice of $s$ and $k$ or provided guidance on how to improve the generalizability of the method. Overall, the comment is somewhat helpful as it identifies a significant area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a critical issue with the empirical selection of hyperparameters $s$ and $k$ in the proposed method, which affects the generalizability of the loss function. It suggests that the authors should provide a more detailed explanation or justification for these choices. While the comment implies that the authors should include additional information in the main text, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to provide more context or justification for their choices. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the empirical selection of hyperparameters $s$ and $k$ and its impact on the generalizability of the proposed loss function. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the empirical selection of hyperparameters $s$ and $k$ reduces the generalizability of the proposed loss function. The reviewer supports this claim by noting that only the choice of $s$ and $k$ as $5$ is mentioned in the supplementary material, without providing a rationale or justification for this choice. This lack of detailed explanation or evidence makes the claim somewhat verifiable, as the authors would need to further explore the reasoning behind the empirical selection to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically the empirical selection of hyperparameters $s$ and $k$ in the sparse-CL and k-NL mask. It highlights that the choice of these parameters is crucial for the effectiveness of the method but notes that only a cross-validation-based selection is provided in the supplementary material. This feedback is valuable as it points out a potential limitation in the generalizability of"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to perform the comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and how to implement the comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner\" and the specific technique used by the authors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the optimization times with OpenTuner, which can adaptively use different search techniques. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would benefit the authors. The suggestion is based on a general observation about OpenTuner\\'s adaptability, but without further elaboration or examples, the claim remains vague. Therefore, the comment is considered borderline verifiable, as it provides an initial suggestion but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the evaluation of the proposed method. By comparing the optimization times, the authors could gain insights into the efficiency and adaptability of their approach relative to OpenTuner. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the novelty of the work is limited, as many other works have already introduced diffusion models into the anomaly detection area. It references specific works ([1], [2], [3]) and notes that while the paper introduces NCSN, it is not an original idea. The reviewer also mentions that the work only makes minor adjustments to NCSN when adapting it to anomaly detection by combining popular techniques like time step embedding and finding a correspondence relationship between anomaly and score in the diffusion model. However, the comment does not provide specific guidance or suggestions on how the authors could enhance the novelty or address the limitations mentioned. Without actionable advice or concrete steps for improvement, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the novelty of the work, mentioning that many other works have introduced diffusion models into the anomaly detection area. It references specific works ([1], [2], [3]) and notes that while the paper introduces NCSN, it is not an original idea. The comment also mentions that the work only makes minor adjustments to NCSN when adapting it to anomaly detection. However, it does not specify which part of the paper this critique is based on, such as the introduction or methodology sections. The authors can infer that it relates to the novelty and adaptation of the NCSN to anomaly detection, but the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the critique of novelty and the adjustments made to NCSN, but without clear references to sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the work lacks novelty, as many other works have already introduced diffusion models into the anomaly detection area. It references specific works ([1], [2], [3]) to support this claim, providing a clear indication of the existing literature. Additionally, the comment notes that while the paper introduces NCSN, it is not an original idea and only makes minor adjustments to adapt it to anomaly detection. The inclusion of references and a detailed explanation of the adjustments made to NCSN provide a solid foundation for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment critiques the novelty of the work, noting that many other works have already introduced diffusion models into the anomaly detection area. It references specific works ([1], [2], [3]) and points out that while the paper introduces NCSN, it is not an original idea. The comment also mentions that the work only makes minor adjustments to NCSN when adapting it to anomaly detection by combining popular techniques like time step embedding and finding a correspondence relationship between the anomaly score and score in the diffusion model. While the comment identifies a significant issue with the novelty of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the originality of their contribution. Without actionable feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific grammar errors in the paper, such as \"The teacher and the student are jointly trained to make the teacher\u2019s knowledge more friendly to the students called online distillation\" and \"Our approach achieves better parameter-efficient and student-friendly KD\u2026.\" This provides explicit actions for the authors to correct the grammar errors. Additionally, the comment points out that Figure 2\\'s axes are not labeled, which is another explicit action that can be taken to improve the draft. The feedback is clear and provides concrete guidance on how to address these issues, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two specific issues: grammar errors and the labeling of Figure 2. The first point is fully grounded as it explicitly mentions specific sentences with grammar errors, allowing the authors to accurately identify the parts of the paper being addressed. The second point is fully grounded as it refers to Figure 2, which is a specific visual element in the paper. Both points are specific, as they clearly specify what needs to be addressed regarding grammar and figure labeling. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations about grammar errors and the labeling of Figure 2. It does not express any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific grammar errors in the paper, such as incorrect phrasing and punctuation, which are crucial for maintaining the clarity and professionalism of the manuscript. It also points out a more general issue with Figure 2, noting that its axes are not labeled. These are actionable feedback points that can help the authors improve the readability and professionalism of their work. However, the comment could be more helpful if it provided examples of how to correct the grammar errors or suggested ways to label the figure axes. Overall, the feedback is mostly helpful as it provides clear guidance on specific areas needing improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis in section 5.2 is inadequate and suggests that more quantitative error analysis would be beneficial. This provides a clear and direct action for the authors to take, which is to conduct a more quantitative error analysis. The comment is specific in its request, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"5.2,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. It also specifies the issue by suggesting that the error analysis is inadequate and recommending more quantitative error analysis. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the current analysis is inadequate. Without these elements, the authors may find it challenging to understand the basis of the critique and how to improve their analysis. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in section 5.2, describing it as \"crappy\" and suggesting that more quantitative error analysis would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a more quantitative approach to error analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct this quantitative analysis or examples of what kind of quantitative metrics to consider. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It advises against relying solely on t-SNE for evaluating distribution alignment and suggests measuring the Proxy-A distance between distributions. Additionally, it points out a potential issue with Fig. 6c and 6d, suggesting that the authors should cross-check if the Proxy-A distance is close. The comment is clear and provides concrete guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. Additionally, it points out a potential issue with the figures, suggesting that the authors should cross-check if the Proxy-A distance is close. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that relying solely on t-SNE for evaluating distribution alignment is not sufficient and recommends measuring the Proxy-A distance between distributions. However, the comment does not provide specific reasoning or evidence to support why this is necessary or how it would improve the evaluation. Additionally, the mention of \"Fig. 6c, 6d\" suggests a potential issue, but it lacks detailed explanation or examples. This makes the claim somewhat verifiable, as it provides a suggestion but lacks comprehensive justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. This is a clear and constructive suggestion that can help the authors improve their evaluation methodology. Additionally, the comment points out a potential issue with Fig. 6c and 6d, suggesting that the authors should cross-check if the Proxy-A distance is close. This feedback is valuable as it guides the authors to consider alternative metrics and verify the accuracy of their figures, which can enhance the rigor and reliability of their work. Overall, the comment is mostly helpful, as it provides clear guidance on improving the draft, but it could be more comprehensive by offering additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. It also points out a potential issue with Fig. 6c and 6d, suggesting that the authors should cross-check if the Proxy-A distance is close. While the comment provides explicit actions for the authors to take, it lacks detailed guidance on how to implement these suggestions, such as specific methods or criteria for measuring the Proxy-A distance. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks comprehensive guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. Additionally, it points out a potential issue with the figures, suggesting that the authors should cross-check if the Proxy-A distance is close. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that relying solely on t-SNE for evaluating distribution alignment is not sufficient and recommends measuring the Proxy-A distance between distributions. However, the comment lacks specific reasoning or evidence to support why this is necessary or how it would improve the evaluation. Additionally, the mention of \"Fig. 6c, 6d\" suggests a potential issue, but it does not provide detailed justification or examples. This makes the claim somewhat verifiable, as it provides a suggestion but lacks comprehensive justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. This is a clear and constructive suggestion that can help"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While the comment implies that the authors should provide an explanation or discuss these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and asks about the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what the authors need to address or clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and inquires about the performance when using a reinforcement algorithm for all phrases. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and provide additional context or justification for their choices. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their draft. While it identifies areas for clarification, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper did not discuss these works in the related work section. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include these references in the related work section, but it lacks concrete instructions on how to integrate them effectively. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the related work section, noting that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but these works are not discussed in the paper. This provides full grounding as it clearly identifies the part of the paper being addressed, specifically the related work section. The comment is also specific because it points out the omission of these references, which is a clear issue that the authors can address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but these works are not discussed in the related work section. This statement is somewhat verifiable as it highlights a potential oversight in the literature review. However, it lacks specific references or detailed reasoning to fully substantiate the claim, such as explaining why these works are relevant or how their inclusion would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the related work section, noting that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but these works are not discussed in the paper. This feedback is clear and actionable, as it directs the authors to include these references in their related work section to provide a more comprehensive literature review. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references effectively. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 1 only presents test loss as a metric for performance degradation, without including any generation results such as BLEU scores to assess the quality of output. This implies that the authors should include BLEU scores in their table to provide a more comprehensive evaluation of their model\\'s performance. While the action is not explicitly stated, it is clear and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of generation results such as BLEU scores, which are necessary to assess the quality of output. This provides clear guidance on what needs to be added to improve the table. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including generation results like BLEU scores to assess the quality of output. This is a factual observation about the content of the table, and it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation, without providing generation results such as BLEU scores to assess the quality of output. This feedback is clear and actionable, as it suggests a concrete improvement by recommending the inclusion of additional metrics to provide a more comprehensive evaluation of the model\\'s performance. By addressing this point, the authors can enhance the depth and comprehensiveness of their results section, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments to validate their theoretical analysis, particularly for discussions on different regimes. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The authors can infer that they need to add experimental validation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to validate the analysis, but without clear grounding, the authors may struggle to identify where to incorporate these suggestions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the theoretical analysis, particularly for discussions on different regimes, would be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. Without such justification, the claim is unverifiable, as it lacks the necessary evidence or explanation to guide the authors in understanding the importance of the suggested experiments. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including experiments to validate the theoretical analysis, particularly for discussions on different regimes, would be beneficial. This feedback is somewhat helpful as it identifies a specific area where the paper could be strengthened by providing empirical evidence to support the theoretical claims. However, the comment lacks detailed guidance on how to design these experiments or what specific aspects should be focused on. While it points out a potential improvement, it does not offer actionable steps or examples, leaving the authors with a general direction but without detailed instructions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different regimes. While the action is implied, it is not explicitly stated, and the comment lacks specific guidance on how to conduct these experiments or what aspects to focus on. The authors can infer that they need to add experimental validation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to validate the analysis, but without clear grounding, the authors may struggle to identify where these experiments should be integrated. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the theoretical analysis, particularly for discussions on different regimes, would be beneficial. However, the comment lacks specific reasoning or evidence to support why these experiments are necessary or how they would enhance the paper. Without detailed justification or examples, the claim remains unverifiable, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different regimes. This feedback is somewhat helpful as it identifies a specific area where the paper could be strengthened by providing empirical evidence to support the theoretical claims. However, the comment lacks detailed guidance or examples on how to design these experiments or what specific aspects should be focused on. Without actionable suggestions or a clear rationale, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different regimes. While the action is implied, it is not explicitly stated, and the comment lacks specific guidance on how to conduct these experiments or what aspects to focus on. The authors can infer that they need to add experimental validation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate the theoretical analysis, particularly for discussions on different"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. This is a clear and direct action for the authors to take, as it specifies exactly what additional baselines should be included. The comment is concrete in its request, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these baselines could be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines what additional baselines could be considered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, the comment does not provide any justification or reasoning for why these specific baselines would be beneficial or how they would contribute to the understanding of the benchmark. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. This feedback is clear and actionable, offering a specific suggestion that could enhance the comprehensiveness of the study by comparing the proposed method against simple baselines. By doing so, the authors could gain a better understanding of the performance gains achieved by their approach. However, the comment could be more helpful if it explained why these specific baselines are relevant or how they might impact the interpretation of the results. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or reasoning.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, noting that the description of advantage-weighted regression is incomplete because it fails to mention the Q function being referenced to \\\\mu. This omission is crucial as it affects the understanding of how Eq. 4 solves the constrained optimization problem. The comment provides a clear and explicit action for the authors to take: they need to include the missing piece of information about the Q function being referenced to \\\\mu. This feedback is concrete and directly guides the authors on what needs to be added to improve the clarity of their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preliminaries\" and the specific equation \"Eq. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the description of advantage-weighted regression, namely the mention of the Q function being referenced to \\\\mu, which is crucial for understanding the constrained optimization problem. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is incomplete, specifically missing the mention of the Q function being referenced to \\\\mu. This omission is crucial as it affects the understanding of how Eq. 4 solves the constrained optimization problem. The comment provides a clear rationale for the claim by highlighting the importance of the Q function in the context of the optimization problem. However, it lacks specific references or examples to fully substantiate the claim, making it mostly verifiable. The authors would need to further explore the context to fully understand and address the issue, thus justifying a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, noting that the description of advantage-weighted regression is incomplete. It highlights the omission of the Q function being referenced to \\\\mu, which is crucial for understanding how Eq. 4 solves the constrained optimization problem. This feedback is clear and actionable, as it directs the authors to include this missing piece of information to improve the clarity and accuracy of their explanation. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, noting that the description of advantage-weighted regression is incomplete because it fails to mention the Q function being referenced to \\\\mu. This omission is crucial for understanding how Eq. 4 solves the constrained optimization problem. The comment provides a clear and explicit action for the authors to take: they need to include the missing piece of information about the Q function being referenced to \\\\mu. This feedback is concrete and directly guides the authors on what needs to be added to improve the clarity of their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preliminaries\" and the specific equation \"Eq. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the description of advantage-weighted regression, namely the mention of the Q function being referenced to \\\\mu, which is crucial for understanding the constrained optimization problem. This provides clear guidance on what needs to be addressed to improve the clarity of the explanation. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is incomplete, specifically missing the mention of the Q function being referenced to \\\\mu. This omission is crucial for understanding how Eq. 4 solves the constrained optimization problem. The comment provides a clear rationale for the claim by highlighting the importance of the Q function in the context of the optimization problem. However, it lacks specific references or examples to fully substantiate the claim, making it mostly verifiable. The authors would need to further explore the context to fully understand and address the issue, thus justifying a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, noting that the description of advantage-weighted regression is incomplete. It highlights the omission of the Q function being referenced to \\\\mu, which is crucial for understanding"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method has multiple stages, which makes it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the algorithm. There is no guidance on potential modifications, alternative approaches, or specific steps the authors could take to simplify the algorithm. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm and its complexity compared to existing pruning methods. However, it does not specify which part of the paper discusses the algorithm or the stages involved, making it weakly grounded. The comment is specific in pointing out the issue of multiple stages and the need for fine-tuning, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to having multiple stages, while many existing pruning methods do not require fine-tuning. However, the comment lacks specific examples or references to existing pruning methods that do not require fine-tuning, making it difficult for the authors to understand the basis of the claim. The absence of detailed evidence or comparisons leaves the claim somewhat verifiable, as it provides a general observation but lacks the necessary support to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a potential issue with the proposed method, noting that while each part is effective, the overall algorithm is cumbersome due to having multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or simplify their algorithm. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method has multiple stages, making it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might simplify the algorithm or address this issue. Without specific guidance or actionable steps, the authors are left without a clear direction for improvement. As a result, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm and its complexity compared to existing pruning methods. However, it does not specify which part of the paper discusses the algorithm or the stages involved, making it weakly grounded. The comment is specific in pointing out the issue of multiple stages and the need for fine-tuning, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to having multiple stages, while many existing pruning methods do not require fine-tuning. However, the comment lacks specific examples or references to these existing pruning methods, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or comparisons, the claim remains somewhat verifiable, as it provides a general observation but lacks the necessary support to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that while each part is effective, the overall algorithm is cumbersome due to having multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or simplify their algorithm. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method has multiple stages, making it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or simplify their algorithm. Without specific guidance or actionable steps, the authors are left without a clear path forward. As"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the advantage of the new quantile function (3) over the existing function (2) is not justified, as it changes the multiplicative factors into an additive term, making the function less sensitive to tail parameters when they are large. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or present supporting data. The feedback lacks actionable details, such as recommending specific experiments or analyses to demonstrate the advantage or suggesting ways to improve the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"new quantile function (3) compared to the existing function (2),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the changes made to the multiplicative factors and the potential reduction in sensitivity to tail parameters. However, it lacks specificity regarding what kind of supporting data or evidence should be provided to justify the advantage of the new function. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the justification for the advantage of the new quantile function (3) over the existing function (2), noting that the changes made to the multiplicative factors result in a less sensitive function to tail parameters when they are large. However, the comment lacks supporting data or evidence to substantiate why the reduced sensitivity is desired or beneficial. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional information to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the justification for the advantage of the new quantile function (3) over the existing function (2). It points out that the changes made to the multiplicative factors result in a less sensitive function to tail parameters when they are large, but the paper does not provide supporting data to justify why this reduced sensitivity is desirable. This feedback is somewhat helpful as it highlights a gap in the paper's argumentation and suggests that the authors should provide evidence or reasoning to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what kind of supporting data would be beneficial. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a potential issue with the justification for the advantage of the new quantile function (3) over the existing function (2). It highlights that the changes made to the multiplicative factors result in a less sensitive function to tail parameters when they are large, but the paper does not provide supporting data to justify this advantage. However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or present the necessary supporting data. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"new quantile function (3) compared to the existing function (2),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the changes made to the multiplicative factors and the potential reduction in sensitivity to tail parameters when they are large. However, it lacks specificity regarding what kind of supporting data or evidence should be provided to justify the advantage of the new function. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the justification for the advantage of the new quantile function (3) over the existing function (2), noting that the changes made to the multiplicative factors result in a less sensitive function to tail parameters when they are large. However, the comment lacks supporting data or evidence to substantiate why the reduced sensitivity is desired or beneficial. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional information to fully support the argument. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the justification for the advantage of the new quantile function (3) over the existing function (2). It points out that the changes made to the multiplicative factors result in a less sensitive function to"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: the confusion in Figure 3 and the claim of a low contribution over SWE-Bench. It provides some context by explaining that the contribution is low because the benchmark implicitly tests fault localization capabilities and that LLMs can handle unit test failures automatically. However, the comment does not offer specific guidance on how to improve Figure 3 or address the issue of low contribution. The feedback lacks actionable details, such as suggestions for clarifying the figure or revising the claims about the contribution. As a result, the authors are left without clear steps to take in response to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the issues with Figure 3, such as its confusion and the claim of a low contribution over SWE-Bench. The comment further elaborates on the reasoning behind the low contribution, explaining that fault localization is implicitly tested in repair benchmarks and that LLMs can handle unit test failures automatically. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the confusion in Figure 3 and the low contribution of the work over SWE-Bench. It provides logical reasoning to support the claim about the low contribution, explaining that fault localization is implicitly tested in repair benchmarks and that LLMs can handle unit test failures automatically. This reasoning is clear and well-supported, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the argument further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies two main issues: the confusion in Figure 3 and the claim of a low contribution over SWE-Bench. It provides some reasoning for the confusion in Figure 3, suggesting that the authors should improve it. However, the comment lacks specific guidance on how to clarify the figure or what aspects need improvement. Additionally, it questions the novelty of the contribution by pointing out that fault localization is implicitly tested in repair benchmarks and that LLMs can handle unit test failures automatically. While the comment highlights important areas for improvement, it does not offer detailed suggestions or actionable steps for the authors to address these issues. Therefore, the feedback is somewhat helpful, as it provides some insight but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a missing key description in the paper, specifically regarding the selection of topics for complementary attributes in topic control experiments. While it highlights the need for clarification, it does not provide explicit instructions or suggestions on how to address this issue. The authors can infer that they need to add a description of how to select topics for complementary attributes, but the comment lacks concrete guidance on how to implement this addition. Therefore, the comment is somewhat actionable, as it points out a gap but does not offer detailed instructions for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the description of topic control experiments, mentioning that there are five topics and questioning the selection of topics for complementary attributes. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results section, but this inference is not direct. The comment is specific in detailing what is missing\u2014descriptions of how to select topics for complementary attributes\u2014but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology of topic control experiments, specifically regarding the selection of topics for complementary attributes. However, it does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the description of topic control experiments. It points out that there are five topics and questions how to select the topics for complementary attributes. This feedback is somewhat helpful as it highlights a critical area that requires clarification, prompting the authors to provide additional details or explanations. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar experiments have been conducted. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the general applicability of the described system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve the presentation of their results. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be taken to strengthen the argument. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the system identification method will improve sim-to-real policy deployment, noting that real-world manipulation only contains a single case. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the system identification method are questionable or how the single case affects the general applicability. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. However, the comment lacks specific reasoning or evidence to support this claim, such as comparisons with other methods or examples of similar cases. The absence of detailed justification or references makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. This feedback highlights a potential weakness in the paper, prompting the authors to consider the broader implications of their findings. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or strengthen their argument. Without actionable advice or detailed feedback, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for concern but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment expresses skepticism about the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve the presentation of their results. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the system identification method are questionable or how the single case affects the general applicability. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. However, the comment lacks specific reasoning or evidence to support this claim, such as comparisons with other methods or examples of similar cases. Without detailed justification or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the general applicability of the system identification method for improving sim-to-real policy deployment, given that real-world manipulation only contains a single case. This feedback highlights a potential weakness in the paper, prompting the authors to consider the broader implications of their findings. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or strengthen their argument. Without actionable advice or detailed feedback, the authors are left with a general critique"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the quality of the ShortcutQA and questions whether the edits might introduce ambiguity, leading to performance degradation. The reviewer asks for details on how \"answerable\" the distracted texts are and requests examples and qualitative results. While the comment implies that the authors should provide additional information and examples, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the quality of the ShortcutQA, questioning whether the edits might introduce ambiguity, and asks for details on how \"answerable\" the distracted texts are. The comment further requests examples and qualitative results, providing clear guidance on what additional information is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses skepticism about the quality of the ShortcutQA, questioning whether the edits might introduce ambiguity, leading to performance degradation. The reviewer provides a logical reasoning by pointing out the manual verification of semantics but questions the guarantee of avoiding ambiguity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and address the concern themselves, as the comment does not provide detailed evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of the ShortcutQA, questioning whether the manual verification of semantics might lead to unintended ambiguity in the texts. It suggests that the authors provide details on how \"answerable\" the distracted texts are and requests examples and qualitative results to support their claims. This feedback is clear and actionable, as it directs the authors to provide additional information that could strengthen their work. However, it could be more helpful if it offered specific suggestions on how to address the concern or examples of what kind of qualitative results would be beneficial. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" This is an explicit suggestion, as it directly instructs the authors to add a reference to the definition of \"deep\" to improve clarity. However, it does not specify where in the text this reference should be added, leaving some ambiguity. While the action is clear, the lack of detailed guidance on implementation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"41,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a forward pointer to the definition of \"deep.\" This provides clear guidance on what the authors need to do to improve the clarity of their text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning or justification for why this would improve clarity or what specific issues the current text has. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" While this is a specific and actionable suggestion, it lacks context or explanation as to why the definition is unclear or how it could be improved. Without additional guidance, the authors may not fully understand the issue or how to address it effectively. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a practical concern about the number of archetypes, k, and asks whether there is a way to perform model selection to identify an appropriate k in the presented framework. While the comment implies that the authors should consider implementing a model selection process to determine the optimal number of archetypes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement model selection or what criteria to use for determining the appropriate k. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific question about the number of archetypes, k, and asks whether there is a way to perform model selection to identify an appropriate k in the presented framework. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the number of archetypes is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in its request for information about model selection and the identification of an appropriate k. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the number of archetypes, k, and whether there is a way to perform model selection to identify an appropriate k. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a practical concern about the number of archetypes, k, and asks whether there is a way to perform model selection to identify an appropriate k in the presented framework. This is a relevant question that could help the authors improve their work by addressing the issue of model selection. However, the comment lacks specific suggestions or guidance on how the authors might implement model selection or what criteria to consider for determining the appropriate k. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing element, Theorem 1, and points out that it is not present at the beginning of page 6, where Theorem 2 is located. The reviewer suggests keeping a clear separation between Assumptions, Lemmas, and Theorems. This feedback provides a direct action for the authors to take, which is to ensure that Theorem 1 is included and properly placed in the document. The comment is explicit and concrete, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presence and placement of Theorem 1, and suggests keeping a clear separation between Assumptions, Lemmas, and Theorems. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the absence of Theorem 1, which is directly followed by Theorem 2 on page 6. The comment suggests that the separation between Assumptions, Lemmas, and Theorems should be clear. However, the comment does not provide any supporting evidence or reasoning to justify why this separation is necessary or how it impacts the paper\\'s clarity. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the absence of Theorem 1, which is directly followed by Theorem 2 on page 6. It suggests that the separation between Assumptions, Lemmas, and Theorems should be clear. This feedback is clear and actionable, as it provides a direct correction to improve the organization and clarity of the paper. However, the comment could be more helpful if it explained why the separation is important or how it affects the reader\\'s understanding. Despite this, the comment is mostly helpful as it guides the authors on how to improve their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or explore the generalization to long document summarization. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption regarding the existence of a subsequence within a longer text that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and its potential implications, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. The reviewer questions whether this assumption will generalize to long document summarization. While the comment identifies a potential issue, it lacks specific examples, references, or detailed reasoning to support the claim that this assumption is heavy or may not generalize. The absence of explicit evidence or examples makes it challenging for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or explore the generalization to long document summarization. The feedback is somewhat helpful as it prompts the authors to consider the limitations of their assumption, but it could be more beneficial with additional context or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this concern. It lacks guidance on how the authors might address this issue or explore the generalization to long document summarization. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption regarding the existence of a subsequence within a longer text that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and its potential implications, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this assumption is heavy or may not generalize. Without concrete evidence or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the assumption that within a longer text, there exists a subsequence shorter than the length limit of pretrained Transformers that is necessary and sufficient for performing a target task. It questions whether this assumption will generalize to long document summarization. While the comment identifies a potential"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method appears straightforward and lacks significant novelty. It also mentions that some parts are unclear, specifically questioning how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. While the comment identifies areas of confusion, it does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks concrete steps or recommendations for improvement, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and mentions specific lines, such as \"line 180,\" which allows the authors to identify the part of the paper being discussed. This provides full grounding. The comment also raises specific questions about the novelty of the method and the clarity of certain aspects, such as how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. This specificity helps the authors understand what needs to be clarified or improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is straightforward and lacks significant novelty, suggesting that some parts are unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims. The mention of \"multiple different graphs\" and the question about the number of parameters is not enough to substantiate the claim. Without further elaboration or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a perceived lack of novelty in the proposed method and points out areas of confusion, specifically questioning the clarity of certain aspects. It raises a specific concern about how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. While the comment highlights potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues or improve the clarity of their method. The feedback is somewhat helpful as it prompts the authors to clarify certain aspects of their work, but it could be more beneficial with additional insights or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method appears straightforward and lacks significant novelty. It also mentions that some parts are unclear, specifically questioning how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. While the comment identifies areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their method. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and mentions specific lines, such as \"line 180,\" which allows the authors to identify the part of the paper being discussed. This provides full grounding. The comment also raises specific questions about the novelty of the method and the clarity of certain aspects, such as how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. This specificity helps the authors understand what needs to be clarified or improved. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is straightforward and lacks significant novelty. It also questions the clarity of certain aspects, such as how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references results in the comment being unverifiable. Therefore, it is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a perceived lack of novelty in the proposed method and points out areas of confusion, specifically questioning the clarity of certain aspects. It raises specific questions about how multiple different graphs can be obtained and whether learning a different weight for an edge would result in too many parameters. While the comment highlights potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues or improve the clarity of their method. The feedback is somewhat helpful as it prompts the authors to clarify certain aspects, but it could be more beneficial"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited in scope and points out that the examples provided are relatively simple, such as a unit sphere and spiral curves. It implies that the authors should consider including more complex manifolds to demonstrate the learning of geometry. While the comment provides a general direction for improvement, it does not specify which complex manifolds should be considered or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the scope of the experiments, specifically mentioning the use of a unit sphere and spiral curves as examples. It suggests that the experiments are limited and proposes including an example of learning geometry on a more complex manifold. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section. The suggestion is specific, as it provides a clear direction for expanding the experiments to include more complex manifolds. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere and spiral curves as examples. It suggests that including an example of learning geometry on a more complex manifold would be beneficial. While the comment provides a logical reasoning for expanding the experiments to include more complex manifolds, it lacks specific examples or references to support the claim. The suggestion is based on a general observation rather than detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, noting that the examples provided are relatively simple, such as a unit sphere and spiral curves. It suggests that including an example of learning geometry on a more complex manifold would be beneficial. This feedback is clear and actionable, as it provides a specific direction for expanding the experiments to enhance their scope and relevance. However, the comment could be more helpful if it offered additional guidance on how to select or design a more complex manifold or provided examples of such manifolds. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors\\' observation that the current knowledge relies on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit suggestions for how the authors might address this weakness or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges a point made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this observation is based on, nor does it provide details on how this weakness could be addressed or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges a claim made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, the comment does not provide any additional reasoning, examples, or references to support this claim or suggest how it could be addressed. Without further elaboration or evidence, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges a point made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any actionable feedback or suggestions for improvement. The comment does not specify how the authors might address this weakness or enhance their work, leaving them without clear guidance on how to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges a point made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit suggestions for how the authors might address this weakness or improve their work. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges a point made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this observation is based on, nor does it provide details on how this weakness could be addressed or improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges a claim made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, the comment does not provide any additional reasoning, examples, or references to support this claim or suggest how it could be addressed. Without further elaboration or evidence, the claim remains unverifiable, making it difficult for the authors to understand the basis of the critique or how to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges a point made by the authors regarding the reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks specificity and does not offer guidance on how the authors might address this weakness or enhance their work. Without clear direction or constructive advice, the comment does not assist the authors in improving their draft. Therefore, it is rated as not helpful"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the number of baselines is small, which affects the universality and generality of the work. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as recommending additional baselines or explaining how to improve the universality and generality of the study. Without specific guidance or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of having a small number of baselines, which affects the universality and generality of the work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the number of baselines, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines is small, which affects the universality and generality of the work. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the number of baselines used in the study, suggesting that this limitation affects the universality and generality of the work. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional baselines or explaining how to improve the universality and generality of the study. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information regarding the tokenizer training, specifically mentioning the absence of details about the mixture of corpus size used and the software stack. While it identifies a gap in the paper, it does not provide explicit instructions or suggestions on how the authors should address this issue. The authors are left to infer that they need to include this information, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of information regarding the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what information is missing, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of information regarding the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack. However, it does not provide any specific references or examples to support this claim, making it difficult for the authors to understand the importance of this information or how it impacts the paper. The lack of detailed justification or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the lack of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack. This feedback is valuable as it highlights an area where the authors can provide additional context or details that could enhance the comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is somewhat helpful as it points out a critical omission but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of the proposed method over prior work, specifically the co-training, positive mining, and alternate optimization steps. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, such as recommending specific analyses or comparisons that could help clarify the necessity of these contributions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed positive mining framework, comparing it to a similar approach in [A]. It questions the necessity of the additional complexity introduced by the proposed method, specifically the co-training, positive mining, and alternate optimization steps. However, the comment does not explicitly mention which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in detailing the issue of whether the additional complexity is warranted, but without clear references to sections or elements of the paper, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the proposed method over prior work, specifically the co-training, positive mining, and alternate optimization steps. The reviewer references a similar approach in [A] to support the claim that the additional complexity may not be justified. However, the comment lacks specific details or examples from [A] or other relevant literature to fully substantiate the claim. While the reference to [A] provides some context, the absence of detailed comparisons or evidence makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of the proposed method's additional complexity compared to simpler alternatives. It questions whether the co-training, positive mining, and alternate optimization steps are truly necessary for the proposed framework. While the comment identifies a potential weakness in the paper's contribution, it lacks specific suggestions or guidance on how the authors might address this issue or clarify the necessity of their method. The feedback is somewhat helpful as it prompts the authors to reconsider the justification of their approach, but it could be more beneficial with additional direction or examples. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the necessity of the proposed method over prior work, specifically the co-training, positive mining, and alternate optimization steps. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, such as recommending specific analyses or comparisons that could help clarify the necessity of these contributions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed positive mining framework, comparing it to a similar approach in [A]. It questions the necessity of the additional complexity introduced by the proposed method, specifically the co-training, positive mining, and alternate optimization steps. However, the comment does not explicitly mention which part of the paper discusses these contributions, making it weakly grounded. While it provides some context by referencing [A], it lacks specific guidance or suggestions for improvement. Therefore, the comment is weakly grounded and not specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the necessity of the proposed method over prior work, specifically the co-training, positive mining, and alternate optimization steps. It references a similar approach in [A] to support the claim that the additional complexity may not be justified. However, the comment lacks specific details or examples from [A] or other relevant literature to fully substantiate the claim. While the reference to [A] provides some context, the absence of detailed comparisons or evidence makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of the proposed method's additional complexity compared to simpler alternatives. It questions whether the co-training, positive mining, and alternate optimization steps are truly necessary for the proposed framework. While the comment identifies a potential weakness in the paper's contribution, it lacks specific suggestions or guidance on how the authors might address this issue or clarify the necessity of their method. The feedback"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the computational cost of the multi-marginal OT and spline calculations, which may limit the scalability of the approach for large datasets. It suggests that a more comprehensive discussion is needed to address this issue. While the comment identifies a potential problem, it does not provide specific guidance on how to conduct this discussion or what aspects should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the scalability issue but without clear direction on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the computational cost of multi-marginal OT and spline calculations, which is a specific concern regarding the scalability of the approach for large datasets. However, it does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the issue of scalability and the need for a more comprehensive discussion, but without clear references to sections or figures, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the computational cost of multi-marginal OT and spline calculations, which may limit the scalability of the approach for large datasets. The claim is somewhat verifiable as it logically suggests that the computational complexity could be a significant issue, especially in real-world applications. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. Providing more detailed evidence or examples would enhance the verifiability of the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the approach, specifically the computational cost of multi-marginal OT and spline calculations, which may restrict scalability for large datasets. It suggests that a more comprehensive discussion is needed to address this issue. While the comment highlights an important aspect that the authors should consider, it lacks specific guidance or suggestions on how to conduct this discussion or what aspects to focus on. The feedback is somewhat helpful as it points out a critical area for improvement but does not provide detailed direction for the authors to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential limitation in the scalability of the approach due to the computational cost of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this issue. However, the comment does not provide specific guidance on what aspects of the discussion should be expanded or how the authors might address the scalability concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed discussion but without clear direction on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the computational cost of multi-marginal OT and spline calculations, which may limit the scalability of the approach for large datasets. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the issue of scalability and the need for a more comprehensive discussion, but without clear references to sections or figures, the authors may struggle to pinpoint where to make improvements. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the computational cost of multi-marginal OT and spline calculations, which may limit the scalability of the approach for large datasets. The comment suggests that a more comprehensive discussion is needed to address this issue. While the claim is logical and highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors are left to infer the significance of the issue without concrete guidance on how to address it. Therefore, the comment is somewhat verifiable, aligning with a score of 3.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the scalability of the approach due to the computational cost of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this issue, which is a valuable insight for the authors. However, the comment lacks specific guidance or suggestions on how to conduct this discussion or what aspects should be included. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore"}
{"generated_text": "{'actionability_rationale': \"The review point challenges the authors' claim that non-uniform label noise is not too common in practice by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This feedback is explicit in pointing out the discrepancy between the authors' claim and the evidence from the literature. However, it does not provide specific guidance on how the authors should address this issue or incorporate this information into their work. While the action is clear in terms of verifying the claim, it lacks concrete steps for implementation. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment challenges the authors\\' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This provides full grounding as it clearly identifies the part of the paper where the claim is made and where the reference is relevant. The comment is also specific, as it details the evidence and source that contradict the authors\\' claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the authors' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This provides a clear and specific reference to evidence that contradicts the authors' claim, making the comment fully verifiable. The inclusion of a relevant citation and detailed evidence strengthens the argument, allowing the authors to effectively address the critique. Therefore, the comment is classified as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment challenges the authors' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This feedback is valuable as it prompts the authors to reconsider their claim and potentially revise their analysis or conclusions. By pointing out the discrepancy between their claim and the evidence from the literature, the comment provides a clear direction for the authors to strengthen their argument or address the issue. However, the comment could be more helpful if it offered suggestions on how to incorporate this evidence into the paper or discuss its implications. Overall, the comment is mostly helpful as it identifies a significant issue and provides a starting point for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review point challenges the authors' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This feedback is explicit in pointing out the discrepancy between the authors' claim and the evidence from the literature. However, it does not provide specific guidance on how the authors should address this issue or incorporate this information into their work. While the action is clear in terms of verifying the claim, it lacks concrete steps for implementation. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment challenges the authors\\' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This provides full grounding as it clearly identifies the part of the paper where the claim is made and where the reference is relevant. The comment is also specific, as it details the evidence and source that contradict the authors\\' claim. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the authors' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This provides a clear and specific reference to evidence that contradicts the authors' claim, making the comment fully verifiable. The inclusion of a relevant citation and detailed evidence strengthens the argument, allowing the authors to effectively address the critique. Therefore, the comment is classified as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment challenges the authors' claim about non-uniform label noise by referencing a specific real-world noise dataset, Clothing1M, and providing a citation to a paper that supports the existence of non-uniform label noise. This feedback is valuable as it prompts the authors to reconsider their claim and potentially revise their analysis or conclusions. By pointing out the discrepancy between their claim and the evidence from the literature,"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they might need to increase the sample size or provide a justification for the current sample size. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the evaluation was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. This provides clear guidance on what aspect of the evaluation needs attention. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. This claim is somewhat verifiable as it highlights a potential issue with the sample size, but it lacks specific examples or references to support the assertion that the sample size is too small to yield reliable results. The comment provides a logical reasoning for the concern but could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in Section 6.2, noting that it was based on only 10 samples. This is a relevant observation as a small sample size can lead to biased findings due to the limited scope of the experiment. The comment highlights a potential weakness in the study that the authors need to address, which is valuable for improving the reliability and generalizability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a larger sample size or alternative methods to ensure robust findings. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to resolve the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the method\\'s generalizability to significantly different combinatorial optimization problems, noting that the paper acknowledges this limitation but does not address it experimentally. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this limitation. The action is implicit, as the authors need to infer that they should conduct experiments to explore the method\\'s generalizability. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the method\\'s generalizability to significantly different combinatorial optimization problems, which the paper acknowledges but does not address experimentally. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of generalizability and the lack of experimental exploration, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The comment acknowledges this limitation but notes that the paper does not address it experimentally. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the method\\'s generalizability. The absence of detailed evidence or examples makes it somewhat challenging for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some reasoning but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. The comment acknowledges this limitation but points out that the paper does not address it experimentally. This feedback is somewhat helpful as it highlights an area that requires further exploration or discussion. However, it lacks specific suggestions or guidance on how the authors might address this limitation, such as proposing additional experiments or analyses. Therefore, the comment provides some insight but does not fully support the authors in making improvements, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. It acknowledges this limitation but points out that the paper does not address it experimentally. While the comment highlights an important issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation in their work. The action is implicit and lacks concrete details, making it somewhat actionable. The authors are left to infer that they should conduct additional experiments or analyses to explore the method\\'s generalizability, but without specific instructions, the feedback remains somewhat vague.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. It acknowledges this limitation but points out that the paper does not address it experimentally. However, the comment does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of generalizability and the lack of experimental exploration, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The comment acknowledges this limitation but notes that the paper does not address it experimentally. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the method\\'s generalizability. The absence of detailed evidence or examples makes it challenging for the authors to fully understand and address the concern. Therefore, the comment is categorized as somewhat verifiable, as it provides some reasoning but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. It acknowledges this limitation but points out that the paper does not address it experimentally. This feedback highlights an important area for further exploration or discussion, which could enhance the paper\\'s contribution. However, the comment lacks specific suggestions"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the clarity of the baseline description in the Results section, specifically mentioning lines 256-261. It points out that the authors attempt to bridge a gap but that the reviewer finds it difficult to understand how the baselines work or how they relate to InterFair. However, the comment does not provide explicit guidance on how the authors should improve the explanation or what specific aspects need clarification. The action is implicit and vague, as the authors are left to infer that they need to clarify the baselines and their relationship to InterFair. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Results section, specifically lines 256-261, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding how the baselines work and their relationship to InterFair. The comment provides a clear direction for the authors to improve the clarity of their explanation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors attempt to bridge a gap in the Results section regarding their baseline, but the reviewer finds it difficult to understand how these baselines work or their relationship to InterFair. However, the comment lacks specific examples or detailed reasoning to support the claim that the baselines are insufficiently competitive or poorly explained. Without concrete evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the baseline description in the Results section, particularly regarding the baselines denoted as Rerank and Adv. It points out that the authors attempt to bridge a gap but that the reviewer finds it difficult to understand how these baselines work or their relationship to InterFair. While the comment highlights a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might improve the explanation or clarify the relationship between the baselines and InterFair. This limits the comment\\'s usefulness to the authors, as it provides a general critique without actionable advice. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the clarity of the baseline description in the Results section, specifically mentioning lines 256-261. It points out that the authors attempt to bridge a gap but that the reviewer finds it difficult to understand how the baselines work or their relationship to InterFair. However, the comment does not provide explicit guidance on how the authors should improve the explanation or what specific aspects need clarification. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Results section, specifically lines 256-261, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding how the baselines work and their relationship to InterFair. The comment provides a clear direction for the authors to improve the clarity of their explanation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors attempt to bridge a gap in the Results section regarding their baseline, but the reviewer finds it difficult to grasp how these baselines work or their relationship to InterFair. However, the comment lacks specific examples or detailed reasoning to support the claim that the baselines are insufficiently competitive or poorly explained. Without concrete evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the baseline description in the Results section, particularly regarding the baselines denoted as Rerank and Adv. It points out that the authors attempt to bridge a gap but that the reviewer finds it difficult to understand how these baselines work or their relationship to InterFair. However, the comment lacks specific suggestions or guidance on how the authors might improve the explanation or clarify the relationship between the baselines and InterFair."}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide specific guidance on how the authors should improve this comparison or what additional baselines should be included. The action is implicit, as the authors need to infer that they should enhance the comparison, and it is vague because it lacks concrete details on how to achieve this enhancement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights an issue with the comparison to other baselines on cycle counting and ZINC, indicating that it is insufficient. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison are insufficient or how it could be improved. Without clear grounding or specific guidance, the authors may struggle to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient, which is a relevant observation. However, it lacks specificity and does not provide guidance on how the authors might enhance this comparison or what specific aspects need improvement. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. While the comment implies that the authors should provide this explanation, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to present this explanation or what specific aspects should be addressed. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be improved but without detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation regarding the effectiveness of a specific combination of mask snippets, while most similar ones are not. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for a clear explanation of the effectiveness of the combination, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically in terms of providing a more detailed rationale for the effectiveness of certain combinations. However, the comment lacks depth and does not offer specific guidance or suggestions on how the authors might address this issue. To be more helpful, the comment could include examples of similar combinations or provide a framework for explaining the effectiveness of the chosen combination. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not provide explicit instructions or guidance on how the authors should address this issue or what specific aspects should be clarified. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for a clear explanation, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback identifies a potential area for improvement in the paper, as understanding the effectiveness of the chosen combination could enhance the paper\\'s comprehensibility and impact. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing a detailed analysis or examples. While it points out an area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not provide explicit instructions or guidance on how the authors should address this issue or what specific aspects should be clarified. The action is implicit"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It specifically mentions that SLQ shows worse performance than CRD in Figure 3 and that the improvement over ACL in Figure 4 is very small. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the competitiveness of SLQ. The feedback lacks actionable steps or suggestions for enhancing the performance or presentation of SLQ. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of SLQ appears to be less competitive compared to previous CRD methods, particularly in terms of F1 score and conductance values. The comment provides specific details about the performance in Figures 3 and 4, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. The reviewer supports this claim by referencing specific figures (Figure 3 and Figure 4) where SLQ shows worse performance than CRD and a very small improvement over ACL. This provides a clear and specific example of the performance gap, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or additional references to substantiate the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of SLQ, as measured by F1 score and conductance values, compared to previous CRD methods. It points out that SLQ appears to be less competitive, particularly in Figure 3 where it shows worse performance than CRD, and in Figure 4 where the improvement over ACL is very small. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s results and provides a basis for further investigation or improvement. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or enhance the competitiveness of SLQ. To be more helpful, the comment could include specific recommendations or strategies for improving the performance or presentation of SLQ. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It references specific figures (Figure 3 and Figure 4) where SLQ shows worse performance than CRD and a very small improvement over ACL. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the competitiveness of SLQ. Without actionable steps or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. The comment provides specific details about the performance in Figures 3 and 4, making it clear what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. The reviewer supports this claim by referencing specific figures (Figure 3 and Figure 4) where SLQ shows worse performance than CRD and a very small improvement over ACL. This provides a clear and specific example of the performance gap, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or additional references to substantiate the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more baselines to their study to perform robust performance comparisons. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the draft. The suggestion is concrete, as it outlines a specific area for enhancement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines in the paper, suggesting that it is limited to naive or old models. It encourages the authors to add more baselines for robust performance comparisons. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to add more baselines is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where these changes should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive or old models, suggesting that more baselines should be added for robust performance comparisons. However, the comment does not provide specific examples of the existing baselines or reference any studies that might have used more comprehensive baselines. This lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the selection of baselines, noting that the current choices are limited to naive or old models. It encourages the authors to add more baselines to perform robust performance comparisons, which is a clear and actionable suggestion. This feedback provides the authors with a specific direction for improving their work by expanding the scope of their experimental comparisons. However, the comment could be more helpful if it offered examples of additional baselines that could be considered or explained why the current selection might be insufficient. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of target structures in Table 2 and questions whether the proposed method can be generalized to other target structures with different dimensions. It explicitly suggests that the authors either justify their choice or provide additional experiments demonstrating the method\\'s adaptability to various target structures. This feedback provides a clear and concrete action for the authors to take, which is to either justify their choice or conduct additional experiments. The comment is explicit and provides specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structures and suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to different target structures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of target structures in Table 2, questioning whether the proposed method can be generalized to other target structures with different dimensions. The reviewer suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability. This claim is somewhat verifiable as it logically questions the generalizability of the method and suggests a potential area for improvement. However, it lacks specific examples or references to support the claim or demonstrate the need for additional experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of target structures in Table 2, questioning whether the proposed method can be generalized to other target structures with different dimensions. It suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is clear and actionable, as it guides the authors to either explain their rationale or conduct supplementary experiments, which would enhance the paper\\'s generalizability and applicability. The comment is mostly helpful as it provides a focused direction for improvement, although it could be more comprehensive by suggesting specific target structures or dimensions to consider. Overall, the comment offers valuable insights that can help the authors improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the research should expand its application scope beyond the knapsack problem to include more realistic scenarios, such as medical diagnosis. While the comment implies that the authors should consider exploring applications in healthcare, it does not provide specific guidance on how to achieve this or what aspects of healthcare should be addressed. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to expand the application scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the application scope of the research beyond the knapsack problem to include more realistic scenarios, such as medical diagnosis. However, it does not specify which part of the paper should address this suggestion or provide details on how to incorporate these applications. The authors can infer that it relates to the methodology or discussion sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a direction for improvement but lacks detailed guidance on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the research\\'s application scope is limited to the knapsack problem and lacks exploration of more realistic scenarios, such as medical diagnosis. The claim is somewhat verifiable as it provides a logical reasoning that expanding the application scope could increase the paper\\'s impact and relevance. However, the comment lacks specific examples or references to support the assertion that medical diagnosis is a more realistic scenario. This makes it challenging for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s application scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would significantly increase the paper\\'s impact and relevance. This feedback is clear and actionable, as it provides a specific direction for expanding the paper\\'s scope and improving its applicability. However, the comment could be more helpful if it offered additional guidance on how to integrate these applications or provided examples of relevant medical scenarios. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests expanding the application scope of the research beyond the knapsack problem to include more realistic scenarios, such as medical diagnosis. While the comment implies that the authors should consider exploring applications in healthcare, it does not provide specific guidance on how to achieve this or what aspects of healthcare should be addressed. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to expand the application scope. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the application scope of the research beyond the knapsack problem to include more realistic scenarios, such as medical diagnosis. However, it does not specify which part of the paper should address this suggestion or provide details on how to incorporate these applications. The authors can infer that it relates to the methodology or discussion sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the research\\'s application scope is limited to the knapsack problem and suggests that exploring more realistic scenarios, such as medical diagnosis, would increase the paper\\'s impact and relevance. While the comment provides a logical reasoning for expanding the application scope, it lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario. This makes the claim somewhat verifiable, as the authors can understand the suggestion but may need to further develop the rationale themselves. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s application scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would significantly increase the paper\\'s impact and relevance. This feedback is clear and actionable, as it provides a specific direction for expanding the paper\\'s scope and improving its applicability. However, the comment could be more helpful if it offered additional guidance or examples on how to integrate these applications. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label':"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the method for not improving robustness and sensitivity, as claimed in the motivation for using evolutionary methods. It also mentions that the new method is noisier in two domains and equally noisy as the competitors in the rest. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might improve the robustness and sensitivity of their method or what specific changes could be made to achieve this. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method does not improve robustness and sensitivity as claimed, and provides a specific observation about the noise levels in the new method compared to the competitors. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation, referencing Fig. 3 to support this assertion. However, the comment lacks specific details or examples from Fig. 3 to substantiate the claim about noise levels and their impact on robustness and sensitivity. Without detailed evidence or analysis, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that the method does not improve robustness and sensitivity as claimed in the motivation. It provides a specific observation from Figure 3, noting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This feedback is clear and actionable, as it highlights a critical area for improvement and provides a concrete example to guide the authors in addressing the issue. However, the comment could be more helpful if it offered suggestions on how to enhance robustness and sensitivity or provided additional context on why the method is noisier. Overall, the comment is mostly helpful, as it effectively directs the authors\\' attention to a key weakness in their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the method does not improve robustness and sensitivity as claimed in the motivation, and provides a specific observation from Figure 3 regarding noise levels. However, it does not offer any explicit or implicit suggestions for how the authors might address this issue or improve their method. Without actionable guidance or recommendations, the authors are left without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method does not improve robustness and sensitivity as claimed, and provides a specific observation about the noise levels in the new method compared to the competitors. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation, referencing Figure 3 to support this assertion. However, the comment lacks specific details or examples from Figure 3 to substantiate the claim about noise levels and their impact on robustness and sensitivity. Without detailed evidence or analysis, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically that the method does not improve robustness and sensitivity as claimed in the motivation. It provides a specific observation from Figure 3, noting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This feedback is clear and actionable, as it directs the authors to address a significant concern regarding the effectiveness of their method. However, the comment could be more helpful if it offered suggestions on how to enhance robustness and sensitivity or provided additional context on why the method is noisier. Overall, the comment is mostly helpful, as it effectively highlights a key weakness and provides a starting point for improvement"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the robustness of the conclusion against more sophisticated or more aggressive removal methods. While it implies that the authors should consider testing their conclusion with different removal methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this test or which methods to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the robustness of the conclusion, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification or further exploration of the conclusion. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a valuable point that could help the authors validate the strength and generalizability of their findings. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what specific removal methods to consider. While it prompts the authors to think about the robustness of their conclusions, it does not provide actionable steps for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for further exploration but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper introduces explainable AI in the introduction but focuses on interpretable methods, without providing a clear definition of interpretability or explaining the difference between the two concepts. The reviewer also notes that the paper does not cite any work in this area. This feedback implies that the authors should clarify the definitions and provide references to relevant work. While the action is implicit, it is concrete because it specifies the need for clarification and references. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of explanation for the definition of interpretability, the difference between explainable AI and interpretable methods, and the absence of references to relevant work. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, without providing a clear definition of interpretability or explaining the difference between the two concepts. The reviewer also notes that the paper does not cite any work in this area. This claim is somewhat verifiable as it highlights a gap in the paper\\'s explanation and references, but it lacks specific examples or references to support the assertion about the lack of explanation or citations. Providing more detailed reasoning or examples would strengthen the claim, making it easier for the authors to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the introduction discusses explainable AI but focuses on interpretable methods. It points out that the authors do not provide a clear definition of interpretability and fail to explain the difference between explainable AI and interpretable methods. Additionally, the comment highlights the absence of references to relevant work in this area. This feedback is clear and actionable, as it directs the authors to clarify the definitions and provide references to relevant literature. However, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the explanation. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and depth of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the training data used for the probes in the compositionality and transitivity experiments. While it highlights a specific area that needs clarification, it does not provide explicit instructions or suggestions for the authors to follow. The action is implicit, as the authors can infer that they need to provide details on the training data, but it remains vague because it lacks concrete guidance on how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the training data used for the probes in the compositionality and transitivity experiments. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in asking for clarification on the training data, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the training data used in the compositionality and transitivity experiments. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training data used for the probes in the compositionality and transitivity experiments. This is a relevant point that could help the authors clarify their methodology and ensure transparency in their work. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their draft. While it points out an area that needs clarification, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the explanation of the term \"not only the complete captions but also parts thereof\" and questions the convincingness of the argument regarding why filling in the blanks is difficult. It also suggests that there are ways to perform bi-directional beam search for such applications. However, the comment does not provide explicit guidance on how the authors should clarify their explanation or improve their argument. The feedback is implicit and lacks concrete suggestions, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the explanation regarding \"not only the complete captions but also parts thereof\" and the convincingness of the argument about why filling in the blanks is difficult. Additionally, it suggests that there are ways to perform bi-directional beam search for such applications. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding \"not only the complete captions but also parts thereof\" and the convincingness of the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, which could provide a basis for improvement. However, the comment lacks specific examples or references to support the claim that the argument is unconvincing, making it somewhat verifiable. The authors would need to further explore the suggestion to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the explanation regarding the use of \"not only the complete captions but also parts thereof,\" and questions the convincingness of the argument about why filling in the blanks is difficult. It also suggests that there are ways to perform bi-directional beam search for such applications. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might clarify their explanation or strengthen their argument. The mention of bi-directional beam search provides some direction, but the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it points out an issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity in the explanation regarding the use of \"not only the complete captions but also parts thereof\" and questions the convincingness of the argument about why filling in the blanks is difficult. It also suggests that there are ways to perform bi-directional beam search for such applications. However, the comment does not provide explicit guidance on how the authors should clarify their explanation or improve their argument. The suggestion about bi-directional beam search is not actionable without further details or context. As a result, the comment is barely actionable, as it identifies an area for improvement but lacks specificity and actionable steps for the authors to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the explanation regarding \"not only the complete captions but also parts thereof\" and the convincingness of the argument about why filling in the blanks is difficult. Additionally, it suggests that there are ways to perform bi-directional beam search for such applications. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity and convincingness of the argument regarding why filling in the blanks is difficult, particularly in the context of \"not only the complete captions but also parts thereof.\" It suggests that there are ways to perform bi-directional beam search for such applications, which could provide a basis for improvement. However, the comment lacks specific examples or references to support the claim that the argument is unconvincing. While it points out a potential area for improvement, it does not provide sufficient evidence or reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights an area for improvement but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the explanation regarding the use of \"not only the complete captions but also parts thereof\" and questions the convincingness of the"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is significant for applications in rare event sampling, where covering all modes of a density is crucial. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest alternative approaches. The feedback is implicit and lacks concrete steps for the authors to take, leaving them uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of reverse KL in training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It also references recent work in normalizing flows to overcome these limitations. However, the comment does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to sections discussing the training process or the choice of loss functions, but this inference is not direct. The comment is specific in detailing the concerns and potential limitations of using reverse KL, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. The reviewer suggests that this limitation is significant for applications in rare event sampling, where covering all modes of a density is crucial. The comment references recent work in normalizing flows to overcome these limitations, providing a basis for the claim. However, the comment could be strengthened by citing specific studies or examples of the recent work mentioned, which would make the claim more verifiable. As it stands, the comment is mostly verifiable, as it provides a logical reasoning and a direction for further exploration, but lacks detailed references or examples. Therefore, it is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises important concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It highlights a potential limitation for applications in rare event sampling, where covering all modes of a density is crucial. The comment also references recent work in normalizing flows that address these limitations, providing a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues or incorporate the referenced work into the paper. Overall, the feedback is somewhat helpful as it identifies a critical area for improvement and provides some context, but it lacks detailed, actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is significant for applications in rare event sampling, where covering all modes of a density is crucial. The comment also references recent work in normalizing flows to overcome these limitations, indicating that this is a major limitation. However, the feedback does not provide explicit guidance or suggestions on how the authors might address these concerns or incorporate the referenced work into their study. The action is implicit and lacks concrete steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It references recent work in normalizing flows to overcome these limitations, suggesting that this is a major limitation for applications in rare event sampling. However, the comment does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to sections discussing the training process or the choice of loss functions, but this inference is not direct. The comment is specific in detailing the concerns and potential limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is significant for applications in rare event sampling, where covering all modes of a density is crucial. The comment references recent work in normalizing flows to overcome these limitations, providing a basis for the claim. However,"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is needed to address this issue. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct a specific analysis or provide guidance on how to perform it. The action is implicit but concrete, as the authors can infer that they need to analyze the dataset in detail. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. Additionally, it suggests a specific action\u2014conducting a detailed analysis of the curated dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset is needed to address this concern. While the comment highlights an important area for improvement, it lacks specific guidance or actionable steps for the authors to take. The suggestion to analyze the dataset is somewhat helpful, but it could be more beneficial with additional details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset is needed to address this issue. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the need for a detailed analysis without detailed instructions on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. Additionally, it suggests a specific action\u2014conducting a detailed analysis of the curated dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. However, the comment lacks supporting evidence, detailed reasoning, or references to substantiate this claim. Without specific examples or explanations, it is difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset is needed to address this concern. While the comment highlights an important area for improvement, it lacks specific guidance or actionable steps for the authors to take. The suggestion to analyze the dataset is somewhat helpful, but it could be more beneficial with additional details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is somewhat helpful, aligning with a score of 3.', '"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural or behavioral parallels. It also points out the need for sensitivity analysis regarding the value of n. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to justify the model implementation or address the concerns about the stopping rule. The authors are left to infer that they need to provide more rationale and sensitivity analysis, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model implementation, specifically mentioning the stopping rule with n consecutive identical samples and the need for sensitivity analysis regarding n. This provides some grounding as it refers to a specific aspect of the model implementation. However, it does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the stopping rule and sensitivity analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model implementation is not well-justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural or behavioral parallels. The comment also points out the absence of sensitivity analysis regarding the value of n. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that the stopping rule is arbitrary or the need for sensitivity analysis. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model implementation, noting that the stopping rule with n consecutive identical samples seems arbitrary and lacks neural or behavioral parallels. It also points out the absence of sensitivity analysis regarding the value of n. This feedback is clear and actionable, as it directs the authors to justify their stopping rule and consider its sensitivity to different values of n. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of alternative stopping rules. Overall, the comment is mostly helpful as it highlights important areas for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural or behavioral parallels. It also points out the need for sensitivity analysis regarding the value of n. While the comment identifies specific areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors are left to infer that they need to justify the stopping rule and conduct sensitivity analysis, but the lack of concrete steps makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model implementation, specifically mentioning the stopping rule with n consecutive identical samples and the need for sensitivity analysis regarding the value of n. This provides some grounding as it refers to a specific aspect of the model implementation. However, it does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the stopping rule and sensitivity analysis, providing clear guidance on potential improvements. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model implementation is not well-justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural or behavioral parallels. It also points out the absence of sensitivity analysis regarding the value of n. While the comment identifies specific areas for improvement, it lacks detailed reasoning or evidence to support the claim that the stopping rule is arbitrary. The absence of specific examples or references makes it challenging for the authors to fully understand and address the critique. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model implementation, noting that the stopping rule with n consecutive identical samples seems arbitrary and lacks neural or behavioral parallels. It also points out the absence of sensitivity analysis regarding the value of n. This feedback is clear and actionable, as it directs the authors to justify their stopping rule and consider its sensitivity to different values of n. However, the comment could be more"}
{"generated_text": "{'actionability_rationale': \"The review point highlights two main issues: the lack of time complexity analysis for the proposed algorithms and the discrepancy in the description of the proposed method as a 'learn-to-search' algorithm compared to the heuristics node pair selection policy used by MCSP and MCSP+RL. The reviewer explicitly instructs the authors to provide the time complexity analysis and to report the running time of the proposed method. Additionally, the comment suggests that it would be interesting to see if the proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. These suggestions are clear and provide concrete actions for the authors to take, making the comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed algorithms,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues: the lack of time complexity analysis, the discrepancy in the description of the proposed method, and the suggestion to compare the search time with state-of-the-art algorithms. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises two main claims. First, it claims that the authors should provide the time complexity of the proposed algorithms due to the NP-hard nature of the maximum common subgraph detection problem. This claim is somewhat verifiable as it logically follows that understanding the time complexity is crucial for evaluating the efficiency of the algorithms. Second, the comment questions the discrepancy in the description of the proposed method as a 'learn-to-search' algorithm compared to the heuristics node pair selection policy used by MCSP and MCSP+RL. This claim is also somewhat verifiable, as it highlights a potential inconsistency in the paper's description. However, both claims lack specific examples or references to support the suggestions, making them less robust. Therefore, the review point is categorized as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two critical areas for improvement in the paper. First, it points out the lack of time complexity analysis for the proposed algorithms, which is important given the NP-hard nature of the maximum common subgraph detection problem. This feedback is clear and actionable, as it directly instructs the authors to include a time complexity analysis to better understand the efficiency of their algorithms. Second, the comment highlights a discrepancy in the description of the proposed method, suggesting that it is a 'learn-to-search' algorithm rather than the heuristics node pair selection policy used by MCSP and MCSP+RL. The reviewer suggests that it would be interesting to see if the proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. Overall, the comment is highly helpful as it offers detailed and constructive suggestions for enhancing the paper's content and analysis.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the data quality. The feedback lacks concrete details on what kind of quality control or manual evaluation should be implemented, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable, making it difficult for the authors to know what steps to take to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the absence of quality control measures, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the data collection process, specifically the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. This is a relevant point that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for quality control or evaluation. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending specific methods for quality control or evaluation. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft in this regard. As a result, the comment is vague and unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the absence of quality control measures, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the data collection process, specifically the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. This is an important point that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for quality control or evaluation. While it highlights a critical area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending methods for quality control or evaluation. Without actionable advice or detailed instructions, the authors are left uncertain about how to improve their draft in this regard. Therefore, the comment is vague and unactionable, aligning with a score of "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare a confidence interval from a small development set with the Frechet bound. While the action is explicit, it lacks concrete guidance on how to implement this comparison or what specific aspects to focus on. The authors are given a clear direction but are left to determine the exact steps and methodology themselves. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing a confidence interval from a small development set with the Frechet bound. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare the confidence interval with the Frechet bound, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using a small dev set to tune hyperparameters is a common practice, as exemplified by the snorkel framework. It further proposes that these labels could be used to provide a bound on classifier performance, comparing a confidence interval from the small dev set with the Frechet bound. While the comment provides a logical reasoning for the suggestion, it lacks specific references or detailed examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a reasonable suggestion but requires additional evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between a confidence interval derived from a small development set and the Frechet bound. This feedback is somewhat helpful as it provides a specific suggestion for further analysis that could enhance the paper\\'s contribution. However, the comment lacks depth and does not offer detailed guidance on how to implement this comparison or what specific insights it might yield. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests comparing a confidence interval from a small development set with the Frechet bound. While the suggestion is explicit, it lacks concrete guidance on how to implement this comparison or what specific aspects to focus on. The authors are given a clear direction but are left to determine the exact steps and methodology themselves. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing a confidence interval from a small development set with the Frechet bound. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare the confidence interval with the Frechet bound, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing a confidence interval from a small development set with the Frechet bound. It provides a logical reasoning by referencing the snorkel framework, which relies on a small dev set for tuning hyperparameters. However, the comment lacks specific examples or references to substantiate the claim or demonstrate the potential benefits of this comparison. While the suggestion is reasonable, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further develop the rationale themselves to fully understand and implement the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between a confidence interval derived from a small development set and the Frechet bound. This is a relevant and potentially insightful suggestion that could enhance the paper by providing a new perspective on evaluating classifier performance. However, the comment lacks specific guidance or detailed instructions on how to conduct this comparison or what specific insights it might yield. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests comparing a confidence interval from a small development set with the Frechet bound. While the suggestion is explicit, it lacks concrete guidance on how to implement this comparison or what specific aspects to focus on. The authors are given a clear direction but are left to determine the exact steps and methodology themselves. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing a confidence interval from a small development set with the Frechet bound. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It explains that this limitation is due to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to expand the method\\'s applicability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It explains this limitation by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the method\\'s applicability and the cause of the limitation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3. This claim is supported by a logical reasoning that the curse of dimensionality is caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the issue, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It explains this limitation by pointing out that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. This feedback is valuable as it highlights a critical area where the method may not be widely applicable, providing the authors with insight into a potential weakness in their approach. However, the comment could be more helpful if it offered suggestions on how to address this limitation or expand the method\\'s applicability to higher-dimensional problems. Overall, the comment is somewhat helpful as it identifies a key issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It explains that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to expand the method\\'s applicability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It explains this limitation by mentioning the largest dimensionality in the experiments, which is 3, and attributes it to the curse of dimensionality caused by the use of a finite set of points in the surrogate modeling of the shape constraint. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the method\\'s applicability and the cause of the limitation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3."}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their claim. There is no guidance on whether the authors should provide additional evidence, clarify the claim, or consider alternative metrics. As a result, the comment lacks actionability, leaving the authors without direction on how to respond to the feedback. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This is a logical reasoning that challenges the claim by pointing out a potential limitation in the data presentation. However, the comment does not provide specific examples or references to support the claim that the standard deviations are too large to substantiate the claim of significant improvement. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This feedback is somewhat helpful as it prompts the authors to reconsider their claim and potentially provide additional evidence or analysis to support their assertion. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their claim. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their claim. There is no guidance on whether the authors should provide additional evidence, clarify the claim, or consider alternative metrics. As a result, the comment lacks actionability, leaving the authors without direction on how to respond to the feedback. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This is a logical reasoning that challenges the claim by pointing out a potential limitation in the data presentation. However, the comment does not provide specific examples or references to support the claim that the standard deviations are too large to substantiate the claim of significant improvement. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This is a relevant point that prompts the authors to reconsider their claim and potentially provide additional evidence or analysis to support their assertion. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their claim. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a challenge in generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should be addressed or improved in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a challenge in generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge related to generating synthetic tabular data, but without clear grounding, the authors may struggle to pinpoint where this issue is addressed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the complexity of generating synthetic tabular data due to the presence of multiple entries associated with the same entity. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The comment lacks detailed reasoning or specific instances that would help the authors understand the basis of the claim. As a result, the claim is considered unverifiable, as it does not provide sufficient justification for the authors to address the issue effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific challenge in generating synthetic tabular data, highlighting the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. This is a relevant observation that could help the authors understand the complexities involved in their data generation process. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the synthetic data generation method. While it points out a potential weakness, it does not provide enough detail or direction for the authors to effectively enhance their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights a challenge in generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might approach this challenge or improve their synthetic data generation process. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific challenge in generating synthetic tabular data, mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge related to generating synthetic tabular data, but without clear grounding, the authors may struggle to pinpoint where this issue is addressed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a specific challenge in generating synthetic tabular data, mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific challenge in generating synthetic tabular data, highlighting the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. This is a relevant observation that could help the authors understand the complexities involved in their data generation process. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the synthetic data generation method. While it points out a potential weakness, it does not provide enough depth or direction for the authors to effectively enhance their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks actionable feedback.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights a challenge in generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a potential issue with the paper's focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the paper. The feedback lacks concrete details on how to incorporate a broader context or validation, leaving the authors uncertain about how to proceed. As a result, the comment is vague and unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the creation of the AmbiQT benchmark and suggests that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, it does not specify which part of the paper discusses the AmbiQT benchmark, making it weakly grounded. The comment is specific in its critique of the potential limitations of the benchmark's applicability, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the potential overemphasis on the AmbiQT benchmark without broader context or validation on other datasets. This claim is somewhat verifiable as it highlights a potential issue with the paper's focus, but it lacks specific examples or references to other datasets or benchmarks that could be used for comparison. The comment suggests that the authors should consider the applicability and relevance of their work to other scenarios, but without detailed evidence or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. This feedback is valuable as it prompts the authors to consider the broader implications of their work and to provide a more comprehensive evaluation of their benchmark. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or contexts to consider. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential issue with the paper's focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or incorporate a broader context or validation. Without specific actions or recommendations, the authors are left without clear direction on how to improve their draft. Therefore, the comment is vague and unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the creation of the AmbiQT benchmark and raises a concern about the potential overemphasis on this specific benchmark without broader context or validation on other datasets. However, it does not specify which part of the paper discusses the AmbiQT benchmark, making it weakly grounded. The comment is specific in its critique of the potential limitations of the benchmark's applicability and relevance, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the potential overemphasis on the AmbiQT benchmark without broader context or validation on other datasets. This claim is somewhat verifiable as it highlights a potential issue with the paper's focus, but it lacks specific examples or references to other datasets or benchmarks that could be used for comparison. The comment suggests that the authors should consider the applicability and relevance of their work to other scenarios, but without detailed evidence or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. This feedback is valuable as it prompts the authors to consider the broader implications of their work and to provide a more comprehensive evaluation of their benchmark. However, the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of annotation training details and guidelines, noting that this is important because professional translators often struggle with non-standard tasks. It also mentions the lack of information about the tool used. While the comment highlights areas that need attention, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors can infer that they need to include this information, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in identifying the need for annotation training details and guidelines, as well as the lack of information about the tool used. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"no annotation training details and guidelines are shared,\" which is important because \"professional translators usually have issues with such kind of non-standard tasks.\" However, the comment lacks specific examples or references to support this claim, such as studies or experiences that highlight the importance of annotation training details. Additionally, the mention of a tool used is not elaborated upon, leaving the authors without clear guidance on what specific information is missing or how to address the issue. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the lack of annotation training details and guidelines, which is important for professional translators who may encounter non-standard tasks. It also points out the absence of information about the tool used, which could be crucial for understanding the methodology. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Providing more detailed feedback or examples of what kind of information should be included would make the comment more actionable. Therefore, the comment is somewhat helpful, as it directs the authors to important areas needing attention but does not fully support them in making improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. While it identifies important areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The comment implies that the authors should include this information, but it lacks specific guidance on what details should be provided or how to present them. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in identifying the need for annotation training details and guidelines and the lack of information about the tool used, providing clear guidance on what is missing. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"no annotation training details and guidelines are shared,\" which is important because \"professional translators usually have issues with such kind of non-standard tasks.\" However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. Additionally, the mention of the tool used is not elaborated upon, leaving the authors without clear guidance on what specific information is missing or how to address the issue. This lack of detailed evidence or examples makes it challenging for the authors to fully understand and address the concern. Therefore, the comment is rated as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper regarding the lack of annotation training details and guidelines, which is important for professional translators who may encounter non-standard tasks. It also points out the absence of information about the tool used, which could be crucial for understanding the methodology. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Providing more detailed feedback or examples of what kind of information should be included would make the comment more actionable. Therefore, the comment is somewhat helpful, as it directs the authors to important areas needing attention but does not fully support them in making improvements.', 'helpfulness_label': '3'}{'action"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about Table 1: whether \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. While the questions imply that the authors should clarify or verify these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to review and possibly revise the presentation of the data in Table 1, but the lack of detailed instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning whether \"EX/NORB\" should be bold-faced and whether the difference between the two values is statistically significant. This provides clear guidance on what needs to be clarified or addressed in the table. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the presentation of data in Table 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about Table 1, questioning whether \"EX/NORB\" should be bold-faced and whether the difference between the two values is statistically significant. While these questions highlight potential areas for clarification or verification, they do not provide actionable feedback or suggestions for improvement. The authors are left with questions but without guidance on how to address them or why these aspects are important. Therefore, the comment is barely helpful, as it identifies areas of concern but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should clarify the metric used, but it lacks concrete instructions on how to do so. The action is implicit and somewhat vague, as the authors know they need to provide details but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"video level supervision experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the metric used for this experiment, noting that it does not use tracklet-based metrics as mentioned in the paper and requests details on the metric used. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the metric used for the video level supervision experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. This is a relevant point that could impact the understanding and evaluation of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it highlights an area for improvement, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of \"person blocking\" on models, as shown in Figure 4, and suggests that models might learn person-related features that are undesirable. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their draft. The comment implies that the authors should provide an explanation or discussion on this topic, but it lacks concrete details or actionable steps. As a result, the authors are left to infer the necessary actions, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the impact of \"person blocking\" on models and suggesting that models might learn person-related features that are undesirable. This provides clear guidance on what aspect of the results or discussion needs further clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and an observation about the impact of \"person blocking\" on models, as shown in Figure 4. It suggests a possible explanation for the observed effect but does not present any evidence or reasoning to support this claim. The comment lacks specific examples, references, or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of \"person blocking\" on models, as shown in Figure 4. It suggests that models might learn person-related features that are undesirable, which is a relevant observation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it prompts the authors to consider an important aspect of their work, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have tried the combination of TF-IDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this approach, it does not explicitly instruct them to do so. Additionally, the comment lacks concrete guidance on how to implement this combination or why it might be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should explore this combination and determine its potential benefits. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the combination of TF-IDF and dense retrieval for evidence sentence extraction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the combination of techniques, but without clear grounding, the authors may struggle to identify where this suggestion fits into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors have tried the combination of TF-IDF and dense retrieval for evidence sentence extraction. While it raises a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how this combination might be beneficial or how it could be implemented. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, the comment is not particularly helpful, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were incorrectly identified as highly correlated despite not being neighboring countries. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides specific examples and questions that can guide the authors in identifying and addressing potential weaknesses in their analysis, it does not explicitly instruct them to include these examples or questions in the paper. The action is implicit but concrete, as the authors can infer the need to provide additional examples and analysis. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should include examples where time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where these predictions are analyzed. The comment is specific in detailing what information is missing and how it could be improved. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include examples where time-series prediction did not perform well, specifically mentioning the COVID-19 dataset and the correlation between UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides a specific example and a question, it lacks detailed reasoning or references to support the claim that these examples are indicative of broader issues with the prediction method. The suggestion is somewhat verifiable, as it highlights potential areas for improvement but requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improving the paper by asking the authors to include examples where time-series prediction did not perform well. It uses the COVID-19 dataset as an example, highlighting a potential issue with the correlation between UK and Russia, which are not neighboring countries. The comment also raises a question about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is clear and actionable, offering the authors a concrete way to enhance the comprehensiveness and robustness of their analysis. By addressing these points, the authors can provide a more balanced and thorough evaluation of their results. Therefore, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claims made about proposing a \"learning framework,\" suggesting that they are exaggerated. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this issue, such as clarifying their claims, revising their framework description, or providing additional evidence to support their claims. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims made about proposing a \"learning framework,\" suggesting that they are exaggerated. However, it does not specify which parts of the paper these claims are made in, nor does it provide details on what aspects of the framework are considered overblown. Without explicit references to sections, figures, or specific statements, the authors cannot confidently determine which parts of the paper need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the \"learning framework\" proposed is not a new framework but rather a modified loss and architecture. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the claims made about proposing a \"learning framework,\" suggesting that they are exaggerated. It points out that the framework is not entirely new but rather a modification of existing components. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not explain why the claims are considered exaggerated or how the authors might address this issue in their paper. Without detailed guidance or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for individual transformer-based architectures, which may hinder cross-model generalization. It suggests exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment provides a clear direction for improvement, it lacks specific guidance on how to achieve this or what specific features or optimizations to consider. The action is explicit but somewhat vague, as it leaves the authors with a general idea of what needs to be done but without detailed steps or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, and discusses the potential limitations in cross-model generalization. It suggests exploring the design of prompts with more universal features or optimization independent of model architecture. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of cross-model generalization and suggests potential improvements, making it specific. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, and suggests that this may limit cross-model generalization. The claim is somewhat verifiable as it provides a logical reasoning that the specificity of prompts to individual architectures could hinder generalization to other models or even slight architectural variations. However, the comment lacks specific examples or references to support the claim fully, such as studies showing the limitations of prompt customization. This makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2. It highlights the challenge of cross-model generalization and suggests that separate training of prompts for each new architecture may be necessary. The comment provides a valuable insight by recommending the exploration of designing prompts with more universal features or optimizing them independently of model architecture. This feedback is clear and actionable, offering a direction for the authors to enhance the applicability and generalizability of their approach. However, it could be more helpful if it included specific suggestions or examples of how to achieve this. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, which may hinder cross-model generalization. It suggests exploring the design of prompts with more universal features or optimizing them independently of model architecture. While the comment provides a clear direction for improvement, it lacks specific guidance on how to achieve this or what specific features or optimizations to consider. The action is implicit and somewhat vague, as it leaves the authors with a general idea of what needs to be done but without detailed steps or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, and discusses the potential limitations in cross-model generalization. It suggests exploring the design of prompts with more universal features or optimization independent of model architecture. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of cross-model generalization and suggesting potential improvements, but without explicit grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, and suggests that this may limit cross-model generalization. The comment provides a logical reasoning that the specificity of prompts to individual architectures could hinder generalization to other models or even slight architectural variations. However, the claim lacks specific examples or references to support the assertion that this limitation is significant or widespread. Without detailed evidence or comparisons, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights the absence of baselines and suggests that the model architecture used in the paper appears somewhat antiquated. It explicitly states that without comparisons to other models, there is no evidence of the current methodology's effectiveness or novelty for fMRI forecasting. The reviewer provides a concrete suggestion by recommending the evaluation of advanced time-series forecasting models available in the 'Time-Series Library' repository. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the concern, which is to include comparisons with contemporary time-series forecasting architectures.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment addresses the absence of baselines in the paper, which raises a concern about the antiquated nature of the model architecture. It suggests that without comparisons to other models, it is difficult to determine the effectiveness or novelty of the current methodology for fMRI forecasting. The comment provides a specific suggestion by recommending the evaluation of advanced time-series forecasting models available in the 'Time-Series Library' repository. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the model architecture and baselines. Therefore, this comment is weakly grounded and specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the absence of baselines in the paper, suggesting that the model architecture appears somewhat antiquated. The reviewer supports this claim by pointing out the lack of evidence for the current methodology's effectiveness or novelty compared to contemporary time-series forecasting architectures. The comment provides a specific suggestion to consider advanced time-series forecasting models available in the 'Time-Series Library' repository. This detailed reasoning and the reference to an external resource make the claim mostly verifiable, as it offers a clear direction for the authors to address the concern. However, the comment could be strengthened by providing more examples or references to specific models that could be used as baselines, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, specifically the absence of baselines, which raises concerns about the antiquated nature of the model architecture. It highlights the need for comparisons to other models to demonstrate the effectiveness and novelty of the current methodology for fMRI forecasting. The comment provides a specific suggestion by recommending the evaluation of advanced time-series forecasting models available in the 'Time-Series Library' repository. This feedback is clear, actionable, and offers a concrete direction for the authors to enhance their draft by including relevant comparisons. The detailed guidance on what could be included as baselines makes the comment highly helpful, as it empowers the authors to significantly improve their work. Therefore, the comment deserves a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. While the comment implies that the authors should add a strong baseline, it does not specify which task or type of baseline would be appropriate. The action is implicit and somewhat vague, as the authors need to infer which baselines would be considered strong and how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the baselines presented in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the inclusion of at least one strong baseline in one of the tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks strong baselines, specifically mentioning that the only baselines presented are standard MLPs. The reviewer acknowledges that the paper is primarily theoretical but suggests that including at least one strong baseline would be beneficial. However, the comment does not provide specific examples of strong baselines or tasks where they could be applied, making it somewhat verifiable. The authors would need to infer which baselines might be considered strong and how to incorporate them, thus requiring more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the only baselines presented are standard MLPs. It acknowledges that the paper is primarily theoretical but suggests that including at least one strong baseline in one of the tasks would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by expanding the range of baselines considered. However, the comment could be more helpful if it suggested which strong baselines might be appropriate or how they could be integrated into the paper. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to two prior works cited in the paper, specifically [3] and [5]. It also suggests including these prior works for comparison in the experimental results tables. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what changes to make to improve their draft. The comment is highly actionable as it provides specific guidance on how to enhance the paper\\'s clarity and comprehensiveness.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the two prior works cited by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more thorough comparison of the proposed method to these prior works and their inclusion in the experimental results tables. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. While the comment identifies specific prior works, it lacks detailed reasoning or examples to substantiate why these comparisons are necessary or how they would enhance the paper. The claim is somewhat verifiable, as it provides a direction for improvement but requires additional justification or evidence to fully support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. This feedback is clear and actionable, providing the authors with a specific direction to enhance the clarity and comprehensiveness of their work. By addressing this point, the authors can improve the novelty and contribution of their paper, making it more valuable to the readers. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claim about the lack of visualization systems for interpretable reinforcement learning is not clear, as it does not specify the broader goals that have been identified. This implies that the authors should clarify what these broader goals are. However, the comment does not provide explicit instructions or concrete details on how to address this issue, leaving the authors to infer that they need to provide a clearer explanation of their goals. While the action is implicit, it is somewhat vague because it lacks specific guidance on how to improve the clarity of the claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the lack of visualization systems for interpretable reinforcement learning. However, it does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The comment does specify the issue by questioning the clarity of the broader goals identified, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that there are no visualization systems for interpretable reinforcement learning that address broader goals. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. The comment does not provide any supporting evidence or references to substantiate the claim, nor does it offer a logical explanation or examples to clarify the broader goals. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the broader goals that have been identified for visualization systems in interpretable reinforcement learning. By pointing out this ambiguity, the comment highlights a critical area that needs clarification, which is essential for the authors to strengthen their argument. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the broader goals should be clarified. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the broader goals identified for visualization systems in interpretable reinforcement learning. It points out that without specifying these goals, it is difficult to evaluate the claim. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify these goals or what specific information should be included. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about the lack of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not specify where in the paper this claim is made, making it weakly grounded. The comment does specify the issue by questioning the clarity of the broader goals, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that there are no visualization systems for interpretable reinforcement learning that address broader goals. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim or clarify the broader goals. This lack of supporting information renders the claim unverifiable, as the authors cannot effectively address the critique without additional context. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the broader goals that have been identified for visualization systems in interpretable reinforcement learning. By pointing out this ambiguity, the comment highlights a critical area that needs clarification, which is essential for the authors to strengthen their argument. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the broader goals should be clarified. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the broader goals identified for visualization systems in interpretable reinforcement learning. It points out that without specifying these goals, it is"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the independence of the introduced AAL and SLS and questions the stability of their improvements when applied separately. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their approach. There is no guidance on potential modifications, additional experiments, or analyses that could be conducted to strengthen the claims. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the independence of the introduced AAL and SLS and questions the stability of their improvements when applied separately. However, it does not specify which part of the paper this observation is based on, such as a particular section or table where these improvements are discussed. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its critique of the improvements shown in Table (1-4), but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. However, it does not provide specific examples, detailed reasoning, or references to support the claim that the improvements are slight or unstable. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. It questions whether applying these methods separately still provides a stable improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed insights, the authors are left with only a vague understanding of the issue, making it difficult for them to make meaningful improvements. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their approach. There is no guidance on potential modifications, additional experiments, or analyses that could be conducted to strengthen the claims. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. However, it does not specify which part of the paper this observation is based on, such as a particular section or table where these improvements are discussed. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its critique of the improvements shown in Tables 1-4, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. However, it lacks specific examples, detailed reasoning, or references to support the claim that the improvements are slight or unstable. The comment does not provide sufficient evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is not verifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the independence and stability of the improvements provided by the introduced AAL and SLS, as shown in Tables 1-4. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this concern or improve their approach. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the experiments, specifically that they are limited to only one task (sentiment classification) and one dataset (SST2). It suggests that to gain deeper insights, the authors should explore the effects on different tasks or utilize multiple datasets for the same task. While the comment provides a clear direction for improvement, it does not specify which additional tasks or datasets should be considered or how to implement this exploration. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a limitation in the experiments, specifically that they are limited to only one task (sentiment classification) and one dataset (SST2). It suggests exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement by recommending the exploration of different tasks and datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task (sentiment classification) and one dataset (SST2), suggesting that exploring different tasks or datasets would provide deeper insights. This claim is somewhat verifiable as it logically points out a limitation in the scope of the experiments. However, it lacks specific examples or references to other tasks or datasets that could be explored, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that they are limited to only one task (sentiment classification) and one dataset (SST2). It suggests that to gain deeper insights, the authors should explore the effects on different tasks or utilize multiple datasets for the same task. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental setup to enhance the depth and generalizability of their findings. However, the comment could be more helpful if it offered examples of additional tasks or datasets that could be considered. Overall, the comment is mostly helpful as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern, such as suggesting the inclusion of real-world data or providing more detailed explanations about the simulated data used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. However, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the simulated nature of the data, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of the experimental designs, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes simulations. However, it does not provide any supporting evidence, reasoning, or references to justify why these simulations might be considered unrealistic or why simulated data would be easier to fit. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. While it identifies a potential issue with the experimental setup, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting the inclusion of real-world data or providing more detailed explanations about the simulated data used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. However, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment lacks specificity in detailing what aspects of the simulated data are problematic or how they could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the realism of the experimental designs, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes simulations. However, it does not provide any supporting evidence, reasoning, or references to justify why these simulations might be considered unrealistic or why simulated data would be easier to fit. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it would be easier to fit simulated data. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve their experimental setup. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including, for example, inter-class or intra-class Frechet Inception Distance (FID) as a quantitative assessment would enhance the comprehensiveness of the evaluation and comparison between different models. While the comment explicitly states the need for a specific metric, it does not provide detailed guidance on how to implement this suggestion or what other metrics could be considered. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement by recommending particular metrics. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the evaluation. While the comment provides a logical reasoning for the claim, it lacks specific references or examples of studies that have successfully used these metrics, making it somewhat verifiable. The authors would need to further explore the suggestion to fully understand and address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their work. By addressing this point, the authors can significantly enhance the rigor and utility of their study. However, the comment could be more helpful if it included additional details on how to implement these metrics or why they are particularly relevant. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. While the comment provides a clear suggestion for improvement, it lacks specific guidance on how to implement these metrics or what other metrics could be considered. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. While the comment provides a logical reasoning for the claim, it lacks specific references or examples of studies that have successfully used these metrics, making it somewhat verifiable. The authors would need to further explore the suggestion to fully understand and address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the potential application of the mechanism in vision transformers. While it raises an interesting point, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a suggestion for further exploration, a critique of the current work, or a request for clarification. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential application of the mechanism in vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or suggestions for how the mechanism might be applied in vision transformers. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification or further exploration of the mechanism\\'s applicability in vision transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the potential application of the mechanism in vision transformers. While it raises an interesting point, it lacks specificity and does not provide any actionable feedback or suggestions for the authors. The comment does not identify any weaknesses or areas for improvement in the current draft, nor does it offer guidance on how the authors might address this question or explore the application in vision transformers. As a result, the comment is not helpful at all, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the precision of IMLE compared to Adaptive IMLE, and another about the applicability of the proposed method to different domains. While the questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to provide explanations or evidence regarding these questions, but the lack of specific actions or suggestions makes the comment somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: one about the precision of IMLE compared to Adaptive IMLE, and another about the applicability of the proposed method to different domains. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific in terms of what they are asking, the lack of grounding in the paper's structure makes it challenging for the authors to address them effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the precision of IMLE compared to Adaptive IMLE and the applicability of the proposed method to different domains. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could help the authors clarify and expand upon certain aspects of their work. The first question asks why the precision of IMLE is better than the proposed Adaptive IMLE, which could prompt the authors to provide a detailed explanation or analysis of this difference. The second question inquires whether the proposed method has been applied to different domains, suggesting that the authors should consider testing their method in various contexts. While the comment identifies areas for improvement and encourages the authors to provide additional insights, it lacks specific guidance or suggestions on how to address these questions. Therefore, the feedback is somewhat helpful, as it points out areas for clarification but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are lacking and questions whether all the modules are necessary. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The feedback lacks concrete details on what aspects of the experimental results are insufficient or how the authors might improve them. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper these experimental results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experimental results are lacking or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the experimental results, questioning whether all the modules are necessary. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the experimental results, specifically questioning whether all the modules are necessary. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or improve their experimental setup. Without detailed feedback or actionable advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experimental setup. The feedback lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper these experimental results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experimental results are lacking or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the experimental results, questioning whether all the modules are necessary. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references, the authors may find it challenging to understand the basis of the concern or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve their experimental setup. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experimental setup. The feedback lacks concrete details or actionable steps, leaving the authors without clear direction on how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper these experimental results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the experimental results are lacking or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should explore the behavior of their network with more layers, specifically mentioning 32 and 64 layers. While the suggestion is explicit, it lacks concrete guidance on how to conduct this exploration or what specific aspects to focus on. The authors are given a clear action to take but are left without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the number of layers considered in the study, specifically mentioning up to 8 layers. It suggests exploring the network's behavior with more layers, such as 32 and 64. However, it does not specify which part of the paper discusses the number of layers, making it weakly grounded. The comment is specific in its suggestion to explore additional layers, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should consider using more layers in their network, citing the common issue of oversmoothing in GNNs as more layers are added. This claim is somewhat verifiable as it references a known issue in the field, providing a logical basis for the suggestion. However, the comment lacks specific examples or references to studies that demonstrate this issue, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the study, noting that the authors have considered only a limited number of layers, up to 8. It highlights a common issue in graph neural networks (GNNs), namely oversmoothing, which occurs as more layers are added. The comment suggests exploring the network's behavior with more layers, such as 32 and 64, which could provide valuable insights into the model's performance and limitations. While the comment identifies a relevant area for further exploration, it lacks specific guidance or suggestions on how to conduct this analysis or interpret the results. Despite this, the feedback is somewhat helpful as it directs the authors' attention to an important aspect of their work that could be expanded upon. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the authors should explore the behavior of their network with more layers, specifically mentioning 32 and 64 layers. While the suggestion is explicit, it lacks detailed guidance on how to conduct this exploration or what specific aspects to focus on. The authors are given a clear direction but are left without concrete instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the number of layers considered in the study, specifically mentioning up to 8 layers. It suggests exploring the network's behavior with more layers, such as 32 and 64. However, it does not specify which part of the paper discusses the number of layers, making it weakly grounded. The comment is specific in its suggestion to explore additional layers, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should consider using more layers in their network, citing the common issue of oversmoothing in GNNs as more layers are added. This claim is somewhat verifiable as it references a known issue in the field, providing a logical basis for the suggestion. However, the comment lacks specific references or examples to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the study, noting that the authors have considered only a limited number of layers, up to 8. It highlights a common issue in graph neural networks (GNNs), namely oversmoothing, which occurs as more layers are added. The comment suggests exploring the network's behavior with more layers, such as 32 and 64, which could provide valuable insights into the model's performance and limitations. While the suggestion is clear, it lacks specific guidance or examples on how to conduct this exploration or interpret the results. Despite this, the feedback is somewhat helpful as it directs the authors' attention to an important aspect of their work that could be expanded upon. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests exploring the network's behavior with more layers, specifically mentioning 32 and 64"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of their experimental results. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific recommendation for addressing the issue of limited improvement in MT over ST, making it highly actionable. The authors know exactly what steps to take to address the feedback, ensuring that the draft is improved accordingly.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST and suggests performing significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in suggesting a method to improve the reliability of the results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is \"very limited\" and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific examples, detailed reasoning, or references to support the claim about the limited improvement. Without these elements, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the improvement of MT over ST is \"very limited.\" It suggests performing significance tests to ensure the reliability of the experimental results. This feedback is clear and actionable, providing the authors with a concrete step to address the concern about the limited improvement. By recommending a specific method to verify the reliability of their results, the comment offers valuable guidance for improving the robustness and credibility of the experimental findings. However, it could be more helpful if it provided additional context or examples of how to conduct these tests. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. While the comment implies that the authors should test their framework on these additional GNN blocks, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and the specific models employed in the evaluation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the proposed framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, and particularly those employing LSTM-like aggregation. This provides clear guidance on what additional tests or comparisons are needed to strengthen the claim of model-agnosticism. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of the proposed framework being model-agnostic, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the framework is not truly model-agnostic. The suggestion for further evaluation is logical, but the comment does not provide detailed reasoning or evidence to substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but requires more detailed justification or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. This feedback is somewhat helpful as it prompts the authors to consider a broader evaluation of their framework across various GNN architectures, which could strengthen the claim of model-agnosticism. However, the comment could be more helpful if it provided specific suggestions on how to conduct these additional evaluations or discussed the potential implications of these results. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. While the comment implies that the authors should test their framework on these additional GNN blocks, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and the specific models employed in the evaluation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the proposed framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. This provides clear guidance on what additional tests or comparisons are needed to strengthen the claim of model-agnosticism. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of the proposed framework being model-agnostic, noting that it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the framework is not truly model-agnostic. The suggestion for further evaluation is logical, but the comment does not provide detailed reasoning or evidence to substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but requires"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an error analysis to understand how the approach behaves when one of its components fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" While the comment implies that the authors should conduct an error analysis, it does not explicitly instruct them to do so or provide detailed guidance on how to perform the analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an error analysis to understand the impact of potential mistakes in the method. However, it does not specify which part of the paper should include this analysis or which components are being referred to, such as \"gpt-4o.\" This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where error analysis could be relevant, the comment lacks full grounding. It is specific about the type of analysis needed but does not provide detailed guidance on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one component fails. However, the comment does not provide specific examples or detailed reasoning to support the need for this analysis. The lack of explicit examples or references to specific components that might fail makes the claim somewhat verifiable, as the authors would need to infer the details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the method has many components and suggesting that an error analysis should be conducted to understand how the approach behaves when one component fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" This feedback is somewhat helpful as it highlights an area for improvement and offers a clear direction for the authors to consider. However, it could be more helpful if it provided additional guidance or suggestions on how to conduct the error analysis or what specific aspects to focus on. Overall, the comment provides some actionable insight but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests conducting an error analysis to understand how the method behaves when one of its components fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" While the comment implies that the authors should include an error analysis, it does not explicitly instruct them to do so or provide detailed guidance on how to conduct the analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an error analysis to understand how the method behaves when one of its components fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" However, the comment does not specify which part of the paper should include this analysis or which components are being referred to, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where error analysis could be relevant, the comment lacks full grounding. It is specific about the type of analysis needed but does not provide detailed guidance on implementation. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one component fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" However, the comment lacks detailed reasoning or evidence to support the need for this analysis, making it somewhat verifiable. The authors would need to infer the importance of the error analysis and how it relates to the method\\'s components. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the method has many components and suggesting that an error analysis should be conducted to understand how the approach behaves when one component fails. It provides a specific example by asking about the consequences if \"gpt-4o misses some details.\" This feedback is somewhat helpful as it highlights an area for improvement and offers a clear direction for the authors to consider. However, it could be"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the computational cost of the reversible version, noting that it is 2-3 times slower. It questions the practicality of the approach given the current cost of memory. Additionally, it suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment implies that the authors should include these scores, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses two main points: the computational cost of the reversible version and the necessity of the gating mechanism. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in its suggestion to include perplexity/BLEU scores to verify the necessity of the gating mechanism, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of the reversible version, noting that it is 2-3 times slower. It questions the practicality of the approach given the current cost of memory. This claim is somewhat verifiable as it provides a logical reasoning based on the computational cost, but it lacks specific data or references to support the assertion about the practicality of the approach. The suggestion to include perplexity/BLEU scores is a separate point and does not directly relate to the computational cost claim. Therefore, the overall justification for the claim is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses two main points. First, it acknowledges the paper\\'s acknowledgment of the higher computational cost of the reversible version, questioning its practicality given the current cost of memory. This is a relevant observation that could prompt the authors to reconsider the practical implications of their approach. Second, the comment suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. This feedback is actionable and provides a clear direction for the authors to enhance their analysis and validation of the gating mechanism. However, the comment could be more helpful if it offered additional guidance or examples on how to present these scores effectively. Overall, the comment is mostly helpful as it identifies a critical aspect of the paper\\'s practicality and provides a specific suggestion for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the computational cost of the reversible version, noting that it is 2-3 times slower. It questions the practicality of the approach given the current cost of memory. Additionally, it suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment identifies a potential issue and provides a suggestion for improvement, it does not explicitly instruct the authors to include these scores or offer detailed guidance on how to implement the suggestion. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two main points: the computational cost of the reversible version and the necessity of the gating mechanism. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The suggestion to include perplexity/BLEU scores is specific, but without clear grounding, the authors may struggle to identify where this suggestion fits into the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of the reversible version, noting that it is 2-3 times slower. It questions the practicality of the approach given the current cost of memory. This claim is somewhat verifiable as it provides a logical reasoning based on the computational cost, but it lacks specific data or references to support the assertion about the practicality of the approach. Additionally, the suggestion to include perplexity/BLEU scores is a separate point and does not directly relate to the computational cost claim. Therefore, the overall justification for the claim is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the computational cost of the reversible version, noting that it is 2-3 times slower. It questions the practicality of the approach given the current cost of memory. This is a relevant point that could prompt the authors to reconsider the practical implications of their approach"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an error analysis, suggesting that it would be beneficial for understanding the limitations of SetCSE in certain scenarios. While the comment implies that an error analysis should be included, it does not explicitly instruct the authors to conduct one or provide guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer that they should add an error analysis but are not given specific steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an error analysis, which is a specific issue that could be addressed to better understand the limitations of SetCSE in certain scenarios. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing what is missing\u2014a lack of error analysis\u2014but lacks grounding in terms of where this should be addressed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no mention of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide any specific examples or reasoning to support why an error analysis is necessary or how it would improve understanding. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of an error analysis in the paper. It suggests that including an error analysis would be beneficial for understanding the limitations of SetCSE in certain scenarios. While the comment highlights a clear gap in the paper, it does not provide detailed guidance or suggestions on how to conduct an error analysis or what specific aspects should be considered. This limits the comment\\'s helpfulness, as it provides a general direction but lacks depth and actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The comment lacks actionable details, such as recommending specific methods or experiments to test these possibilities. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this topic is addressed, the comment lacks full grounding. It is specific in its critique of the measurement approach but does not provide detailed guidance on how to address the concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. While this is an important consideration, the comment lacks specificity and actionable guidance. It does not provide suggestions on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it highlights a potential weakness, but it does not offer detailed advice or examples to help the authors make improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The comment lacks actionable details, such as recommending specific methods or experiments to test these possibilities. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this topic is addressed, the comment lacks full grounding. It is somewhat specific in its critique of the measurement approach but does not provide detailed guidance on how to address the concern. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or a clear explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, suggesting that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. This is an important consideration that could impact the validity of the results. However, the comment"}
{"generated_text": "{'actionability_rationale': \"The review point provides an implicit suggestion for the authors to find other tasks or even artificial tasks to demonstrate the effectiveness of HA3C, given that the improvement over baseline algorithms on MuJoCo control tasks is marginal. While the comment implies a specific action, it does not provide detailed guidance on how to identify suitable tasks or what criteria to use for evaluation. The suggestion is somewhat vague, as it lacks concrete steps or examples for the authors to follow. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the experimental results, specifically the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. It provides a rationale for this observation, suggesting that the benefit of HA3C may be due to the structure of the problem and the complexity of the causal relationship. The reviewer also suggests that MuJoCo tasks may not be suitable for HA3C and recommends finding other tasks or artificial tasks to demonstrate its effectiveness. However, the comment does not explicitly mention which part of the paper discusses the experimental results, making it weakly grounded. The suggestion to find other tasks is specific, but without clear grounding, the authors may struggle to identify where to make these changes. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the effectiveness of HA3C based on its marginal improvement over baseline algorithms on MuJoCo control tasks. The reviewer provides a rationale for this observation, suggesting that the benefit of HA3C may be due to the structure of the problem, specifically the complexity of the causal relationship based on the current state versus the simplicity of the causal relationship based on history. The reviewer also suggests that MuJoCo tasks may not be suitable for HA3C and recommends finding other tasks or artificial tasks to demonstrate its effectiveness. While the comment offers a logical explanation and a suggestion for further exploration, it lacks specific examples or references to support the claim fully. Therefore, the comment is mostly verifiable, as it provides a reasonable argument but could benefit from more detailed evidence or examples.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a nuanced critique of the experimental results, noting that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal. It offers a rationale for this observation, suggesting that the benefit of HA3C may be due to the structure of the problem, specifically the complexity of the causal relationship based on the current state versus the simplicity of the causal relationship based on history. The reviewer also provides a constructive suggestion for the authors to find other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This feedback is clear and actionable, offering a specific direction for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included specific examples of alternative tasks or methodologies for evaluation. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper should focus on the insights derived from the data rather than just reporting aggregate numbers. It explicitly states that the authors should provide key takeaways or insights that are generalizable and hold broader significance for the community. While the comment clearly identifies the need for more detailed insights, it does not provide specific guidance on how to achieve this or what kind of insights would be most valuable. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the need for key contributions to focus on insights derived from the data rather than just reporting aggregate numbers. It clearly identifies the issue with the paper's focus on general observations about LLM performance without providing specific insights. The comment is also specific, as it clearly specifies what is missing\u2014key insights or takeaways that are generalizable and hold broader significance for the community. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper does not fully address the key contributions of the insights derived from the data, as it primarily reports aggregate numbers without providing clear takeaways. The reviewer suggests that the paper lacks generalizable insights that would be of broader significance to the community. While the comment identifies a potential issue with the paper's focus, it does not provide specific examples or references to support the claim. The lack of detailed justification or evidence makes it somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's focus, suggesting that the key contributions should be centered around the insights derived from the data rather than just reporting aggregate numbers. It points out that the paper lacks clear takeaways or generalizable insights that would be of broader significance to the community. The comment provides a clear direction for improvement by emphasizing the need for more detailed analysis and insights. However, it could be more helpful by offering specific examples or guidance on how to derive such insights. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides some direction, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the paper should focus on the insights derived from the data rather than just reporting aggregate numbers. It implies that the authors should provide key takeaways or insights that are generalizable and hold broader significance for the community. However, the comment does not provide specific guidance on how to achieve this or what kind of insights would be most valuable. The action is implicit and lacks concrete details, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly addresses the focus of the paper on insights derived from the data rather than just reporting aggregate numbers. It clearly identifies the issue with the paper's lack of key takeaways or generalizable insights that would be of broader significance to the community. The comment is specific in its critique, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with a score of 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper does not fully address the key contributions of the insights derived from the data, as it primarily reports aggregate numbers without providing clear takeaways or generalizable insights. The comment suggests that the authors should focus on deriving insights that are generalizable and hold broader significance for the community. While the comment identifies a potential issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific areas needing improvement, thus justifying a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's focus, suggesting that the key contributions should be centered around the insights derived from the data rather than just reporting aggregate numbers. It points out that the paper lacks clear takeaways or generalizable insights that would be of broader significance to the community. The comment provides a clear direction for improvement by emphasizing the need for more detailed analysis and insights. However, it could be more helpful by offering specific examples or guidance on how to derive such insights. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides some direction, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the paper should focus on the insights derived from the data rather than just reporting aggregate numbers. It"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a false claim made in the paper regarding the choice of vocoders, specifically mentioning that GAN is not the only choice and ignoring other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest alternative references or explanations. The action is implicit, as the authors need to infer that they should correct the claim and include a more accurate representation of the vocoders landscape. However, the comment lacks concrete details on how to implement the correction, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the false claim about GAN being the de facto choice for vocoders and suggests alternative choices like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, stating that \"GAN has been the de facto choice for vocoders,\" by providing a counter-argument that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. This critique is supported by logical reasoning, as it highlights the existence of alternative vocoders that are not mentioned in the paper. However, the comment could be strengthened by providing specific references or examples of these alternative vocoders to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the critique but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a false claim made in the paper regarding the choice of vocoders, specifically pointing out that GAN is not the only choice and ignoring other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This feedback is valuable as it highlights a potential oversight in the literature review and encourages the authors to provide a more comprehensive overview of vocoders. However, the comment could be more helpful if it suggested specific references or examples of these alternative vocoders to include in the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out a false claim regarding the choice of vocoders, specifically mentioning that GAN is not the only choice and ignoring other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this claim or suggest ways to incorporate these alternative vocoders into their discussion. The action is implicit and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the false claim about GAN being the de facto choice for vocoders and suggests alternative choices like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, stating that \"GAN has been the de facto choice for vocoders,\" by providing a counter-argument that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. This critique is supported by logical reasoning, as it highlights the existence of alternative vocoders that are not mentioned in the paper. However, the comment could be strengthened by providing specific references or examples of these alternative vocoders to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a false claim made in the paper regarding the choice of vocoders, specifically pointing out that GAN is not the only choice and ignoring other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This feedback is valuable as it highlights a potential oversight in the literature review and encourages"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the design choices need further explanation or justification. The action is implicit, as the authors can infer that they need to provide more explanation or justification for their design choices, but it remains vague without concrete steps or suggestions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies specific design choices that are not fully explained or empirically justified, such as the choice of token similarity metric. However, it does not specify which part of the paper these design choices are discussed in, making it weakly grounded. The comment is specific in pointing out the need for further explanation or justification of these choices, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric as an example. However, the comment lacks detailed reasoning or evidence to support why these choices are insufficiently justified. Without specific examples or references to how these choices could be improved, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a general concern about the approach, noting that while it is straightforward and sensible, it contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example, indicating that this aspect needs further clarification. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to justify the design choices. While it highlights an area for improvement, the feedback lacks actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side (LHS) has certain terms (T and W) that are not present on the right-hand side (RHS). This feedback is explicit and provides concrete guidance on what needs to be corrected, namely, ensuring that the notation is consistent throughout the equations. The authors know exactly what changes need to be made to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, \"Equation (4)\" and \"Equation (6),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, noting that the left-hand side (LHS) has certain terms (T and W) that are not present on the right-hand side (RHS) in both equations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side (LHS) has certain terms (T and W) that are not present on the right-hand side (RHS). This is a factual observation and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side (LHS) has certain terms (T and W) that are not present on the right-hand side (RHS). This feedback is clear and actionable, as it directly points out areas where the authors need to make corrections to ensure the consistency and clarity of their notation. By addressing these inconsistencies, the authors can improve the readability and professionalism of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to handle similar inconsistencies elsewhere in the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the evaluation is insufficient, including the number of models constructed, the evaluation of image distortion after warping, and the discussion on potential countermeasures against the proposed approach. While the comment highlights specific aspects that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to expand their evaluation and include discussions on potential countermeasures, but without detailed guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks specific instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses multiple issues related to the evaluation of the paper, including the number of models constructed, the evaluation of image distortion after warping, and the discussion on potential countermeasures against the proposed approach. However, it does not specify which part of the paper these issues pertain to, such as specific sections or figures where these evaluations should be expanded. This makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in detailing what is lacking, it is weakly grounded because it does not provide explicit references to the parts of the paper being addressed. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient due to the construction of less than 20 models, which is insufficient to demonstrate the effectiveness of the approach. The comment also mentions the lack of evaluation regarding image distortion after warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that 20 models are insufficient. The absence of specific examples or comparisons makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the evaluation of the paper is insufficient. It points out that only a limited number of models are constructed during evaluations, which is insufficient to demonstrate the effectiveness of the approach. Additionally, it highlights the lack of evaluation regarding the distortion of images after warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment effectively identifies weaknesses in the evaluation process, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it directs the authors to expand their evaluation and consider additional aspects, but it could be more beneficial with more detailed advice on how to improve the evaluation and discussion sections. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several areas where the evaluation is insufficient, including the number of models constructed, the evaluation of image distortion after warping, and the discussion on potential countermeasures against the proposed approach. While the comment highlights these weaknesses, it does not provide explicit instructions or concrete steps on how to address them. The authors are left to infer that they need to expand their evaluation and include discussions on potential countermeasures, but without specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies multiple areas where the evaluation is insufficient, including the number of models constructed, the evaluation of image distortion after warping, and the discussion on potential countermeasures against the proposed approach. However, it does not specify which part of the paper these issues pertain to, such as specific sections or figures where these evaluations should be expanded. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in detailing what is lacking, it is weakly grounded because it does not provide clear references to the parts of the paper being addressed. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient due to the construction of less than 20 models, which is insufficient to demonstrate the effectiveness of the approach. It also mentions the lack of evaluation regarding image distortion after warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas for improvement, it lacks detailed reasoning or evidence to support the claim that 20 models are insufficient. The absence of specific examples or references makes it challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks whether all the discourse particles in Table A3 are discourse particles or discourse + imported vocab. It suggests that if they are the latter, the table should be separated, and glosses would be helpful. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the table\\'s organization and clarity. The comment is explicit and concrete, offering specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether all the discourse particles are discourse particles or discourse + imported vocab, and suggests separating them if they are the latter and adding glosses for clarity. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the classification of discourse particles in Table A3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the organization of Table A3. It questions whether all the discourse particles are discourse particles or discourse + imported vocab, and suggests separating them if they are the latter. Additionally, it recommends including glosses to enhance clarity. This feedback is clear and constructive, offering a direct way for the authors to improve the presentation and understanding of their data. However, it could be more helpful if it explained why separating the discourse particles is important or how the glosses would benefit the reader. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the rationale behind formula (4), specifically asking why the maximum is taken over all possible pieces for unoccupied squares. While the comment highlights a lack of understanding, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the rationale behind the formula, but it is vague because it does not specify how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by questioning the rationale behind the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what aspect of the formula needs clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the rationale behind formula (4), specifically questioning the use of the maximum over all possible pieces for unoccupied squares. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding formula (4), questioning the rationale behind the maximum over all possible pieces for unoccupied squares. This feedback highlights a potential gap in the explanation or clarity of the paper, which is valuable for the authors to address. However, the comment does not provide suggestions on how to clarify this aspect or improve the explanation, limiting its helpfulness. While it points out an area for improvement, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments lack a comparison to state-of-the-art subset selection methods. While it identifies a specific area that needs improvement, it does not provide explicit guidance on which subset selection methods should be included or how to conduct the comparison. The action is implicit, as the authors can infer that they need to add comparisons to relevant methods, but it remains vague because it lacks concrete details on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, namely the lack of comparison to state-of-the-art subset selection methods. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in identifying what is missing\u2014comparisons to state-of-the-art methods\u2014but without clear grounding, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any specific examples or references to these methods, nor does it explain why such comparisons are necessary or how they would benefit the paper. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental section of the paper, noting the absence of comparisons to state-of-the-art subset selection methods. This feedback is clear and actionable, as it directs the authors to include comparisons with relevant methods to strengthen their experimental evaluation. However, the comment could be more helpful if it provided examples of specific subset selection methods that should be considered or suggested how to integrate these comparisons into the paper. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and provides a clear direction for enhancing the draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is vague and needs to be more concise. It also mentions that the primary components seem to integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific guidance on how to enhance the novelty or what aspects of the paper should be revised to make it more concise. The feedback lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components seem to integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which parts of the paper are being referred to, nor does it provide detailed guidance on how to enhance the novelty or conciseness. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is vague and suggests that the primary components integrate effective elements from previous works. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete references or explanations, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a concern about the novelty of the paper, suggesting that it may be somewhat vague and lacks conciseness. It also notes that the primary components seem to integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the novelty or conciseness of their work. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but no clear path to address it. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the novelty of the paper is vague and needs to be more concise. It also mentions that the primary components seem to integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific guidance on how to enhance the novelty or provide more concise explanations. Without explicit instructions or concrete suggestions, the authors are left uncertain about how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components seem to integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which parts of the paper are being referred to or provide detailed guidance on how to enhance the novelty or conciseness. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is vague and suggests that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the previous works being integrated, it is difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a concern about the novelty of the paper, suggesting that it may be somewhat vague and lacks conciseness. It also notes that the primary components seem to integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the novelty or conciseness of their work. Without actionable feedback or detailed advice, the authors are left with a general understanding of the issue but no clear path to address it. Therefore, the comment is barely helpful,"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback provides a clear and explicit action for the authors to take, which is to include such benchmarks to enhance the usability and availability of the evaluation framework to the community. The suggestion is concrete, as it specifies the type of evaluation that should be conducted. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use evaluation benchmarks to enhance the usability and availability of the evaluation framework to the community. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using evaluation benchmarks of the user simulator could demonstrate how smaller models perform as user simulators. However, the comment lacks specific examples, references, or detailed reasoning to support why this would make the benchmark more usable or available to the community. Without these details, the claim is not fully substantiated, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an important enhancement to the evaluation framework by recommending the use of evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is clear and actionable, as it provides a specific direction for improving the usability and availability of the evaluation framework to the community. By addressing this suggestion, the authors can significantly enhance the impact and applicability of their work. However, the comment could be more helpful if it included additional details or examples of how to implement these benchmarks. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, how it should be addressed, or even if it is relevant to the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where open-set detectors are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the authors might have an idea of where open-set detectors are discussed, the comment is not fully grounded. It is specific in its inquiry about the impact of open-set detectors but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the impact of open-set detectors on the performance of the proposed method. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of open-set detectors on the performance of the proposed method. While it identifies a potential area of interest or concern, it lacks specificity and does not provide any guidance or suggestions for the authors to address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, the comment is not particularly helpful, aligning with a score of 1: The comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues: the lack of explanation for the star (*) next to \"oracle goals\" in Table 1, and the ambiguity regarding the term \"from-scratch\" in Table 5. The reviewer explicitly asks for clarification or a fix, providing clear guidance on what needs to be addressed. The comment is explicit and concrete, leaving no ambiguity about the actions required by the authors. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the symbols and terms used in these tables. The comment clearly specifies what needs to be addressed, such as the lack of explanation for the star (*) in Table 1 and the ambiguity regarding the term \"from-scratch\" in Table 5. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and questions about the presence of symbols and terms in the tables. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of explanation for the symbol (*) in Table 1 and the ambiguity regarding the term \"from-scratch\" in Table 5. By pointing out these inconsistencies, the comment provides clear and actionable feedback that can help the authors improve the clarity and accuracy of their tables. However, the comment could be more helpful if it offered suggestions on how to clarify these issues or provided examples of how to address them. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the expected behavior of transferability with increasing noise intensity and suggests that the results may not be as exciting as expected. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes, if any, they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expected behavior of transferability with increasing noise intensity and suggesting that different neurons might be activated to reduce confidence in source samples, leading to increased misclassification. This provides clear guidance on what aspect of the results is being questioned and why they might not be as exciting as expected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the expected behavior of transferability with increasing noise intensity, suggesting that as inputs become more deformed, different neurons should be activated to reduce confidence in source samples, leading to increased misclassification. However, the comment does not provide specific evidence, examples, or references to support this claim. The reasoning is based on logical reasoning but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the expected behavior of transferability with increasing noise intensity, suggesting that as inputs become more deformed, different neurons should be activated to reduce confidence in source samples, leading to increased misclassification. This observation challenges the authors' findings and prompts them to reconsider their interpretation of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their results. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a question about the expected behavior of transferability with increasing noise intensity and suggests that the results may not be as exciting as expected. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their draft based on this feedback. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expected behavior of transferability with increasing noise intensity and suggesting that different neurons might be activated to reduce confidence in source samples, leading to increased misclassification. This provides clear guidance on what aspect of the results is being questioned and why they might not be as exciting as expected. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the expected behavior of transferability with increasing noise intensity, suggesting that as inputs become more deformed, different neurons should be activated to reduce confidence in source samples, leading to increased misclassification. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on logical reasoning but requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the expected behavior of transferability with increasing noise intensity, suggesting that as inputs become more deformed, different neurons should be activated to reduce confidence in source samples, leading to increased misclassification. This observation challenges the authors' findings and prompts them to reconsider their interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their results. While it identifies a potential weakness, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a question about the expected behavior of transferability with increasing noise intensity and"}
{"generated_text": "{'actionability_rationale': 'The review point provides multiple actionable suggestions. First, it explicitly recommends conducting ablation studies with only importance weighting or the rejection to better understand their effects, which is a clear and concrete action. Second, it points out that the fonts in the figures are too small to read, providing a specific issue that can be addressed. Lastly, it raises a question about the ChopperCommand results in Fig. 6(a) and asks for an explanation, which implies that the authors should provide more detailed analysis or discussion. Each of these points is explicit and provides concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"ablation studies,\" \"Fig. 6(a),\" and \"ChopperCommand results,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on what needs to be addressed: conducting ablation studies to understand the effects of importance weighting or rejection, improving the readability of fonts in figures, and explaining the ChopperCommand results in Fig. 6(a). The comment provides clear guidance on what needs to be improved, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims. The first claim about the need for ablation studies is somewhat verifiable, as it suggests that conducting such studies would help understand the effects of importance weighting or rejection. However, it lacks specific examples or references to support this claim. The second claim about the small fonts in figures is factual and does not require verification. The third claim about the ChopperCommand results in Fig. 6(a) is more of a question seeking clarification rather than a claim. Overall, the review point provides some support for its claims but lacks detailed justification or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It explicitly recommends conducting ablation studies with only importance weighting or the rejection to better understand their effects, which is a clear and concrete recommendation. Additionally, it points out the issue with the small fonts in the figures and asks for clarification on the ChopperCommand results in Fig. 6(a), suggesting that the authors provide more detailed explanation or analysis. These suggestions are specific and provide the authors with clear directions on how to enhance their draft, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the technical framework, specifically mentioning the main learning framework Equation (18) and the need to explain how to implement the balancing term and the penalty term. While the comment highlights specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and examples, but the comment does not offer concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for the main learning framework and the implementation of the balancing term and penalty term. This provides clear guidance on what the authors need to clarify or elaborate on in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning that the main learning framework Equation (18) is not explained and questions the implementation of the balancing term and penalty term. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to support the claim that the technical clarity is weak. The absence of specific references or detailed explanations makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of weakness in the paper, namely the lack of clarity in the technical framework, particularly regarding Equation (18) and the implementation of the balancing term and penalty term. This feedback is valuable as it points out a critical area that needs improvement, helping the authors understand where their explanation is insufficient. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how to effectively explain these concepts. Overall, the comment is somewhat helpful as it highlights a significant issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds. It suggests that these results should be updated as feature vectors update during training and emphasizes the need to clarify how well the fixed tessellations capture the model\\'s behavior. Additionally, it highlights concerns about using 2D projections to represent high-dimensional decision boundaries, noting that results can vary significantly based on the selected projection method and parameters. While the comment identifies specific issues and suggests the need for clarification, it does not provide explicit guidance on how to address these concerns or improve the analysis. The authors are left to infer the necessary steps to enhance their draft, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures\" and the \"Voronoi tesselation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the projection results and decision boundaries should be updated as feature vectors update during training, and it raises concerns about the use of 2D projections to represent high-dimensional decision boundaries. The comment provides clear guidance on what needs to be clarified and improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite the feature vectors updating during training. The reviewer suggests that these fixed tessellations may not accurately capture the model\\'s behavior and raises concerns about the use of 2D projections to represent high-dimensional decision boundaries. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the fixed tessellations are inadequate. The reasoning is somewhat verifiable, as it highlights a potential problem but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the decision boundary generation process, noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite the feature vectors updating during training. It emphasizes the importance of clarifying how well these fixed tessellations capture the model\\'s behavior as feature vectors update. Additionally, it raises concerns about the use of 2D projections to represent high-dimensional decision boundaries, highlighting the potential variability based on the selected projection method and parameters. This feedback is clear and actionable, as it directs the authors to address the issue of updating the decision boundaries and clarifying their representation. However, it could be more helpful if it provided specific suggestions on how to update the decision boundaries or discuss the implications of using 2D projections. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study and the lack of comparison to methods from the past decade. While it identifies specific areas that need attention, it does not provide explicit instructions or suggestions on how to conduct these ablation studies or comparisons. The authors are left to infer that they should include these elements, but the comment lacks concrete guidance on how to implement them. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation study and the lack of comparison to methods from the past decade. However, it does not specify which part of the paper should include these elements, making it weakly grounded. The comment is specific in identifying the need for an ablation study and a comparison to past methods, but without clear references to sections or figures, the authors may struggle to pinpoint where these additions should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how their absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: the absence of an ablation study and the lack of comparison to methods from the past decade. While it highlights these gaps, it does not provide detailed guidance or suggestions on how to conduct these studies or comparisons. The comment is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what to address but without specific direction on how to proceed. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of an ablation study and the lack of comparison to methods from the past decade. While it identifies specific areas that need improvement, it does not provide explicit instructions or suggestions on how to conduct these studies or comparisons. The authors are left to infer that they should include these elements, but without concrete guidance, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation study and the lack of comparison to methods from the past decade. However, it does not specify which part of the paper these elements should be included in, making it weakly grounded. The comment is specific in identifying the need for an ablation study and a comparison to past methods, but without clear references to sections or figures, the authors may struggle to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how their absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: the absence of an ablation study and the lack of comparison to methods from the past decade. While it highlights these gaps, it does not provide detailed guidance or suggestions on how to conduct these studies or comparisons. The comment points out the need for additional analysis but lacks actionable advice, making it somewhat helpful. The authors are informed of the areas needing attention but are left without clear direction on how to address them. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the absence of an ablation study and the lack of comparison to methods from the past decade. While it identifies specific areas for improvement, it does not provide explicit guidance or suggestions on how to conduct these studies or comparisons. The authors are left to infer that they should include these elements, but without concrete instructions, the action remains vague. Therefore, the comment is somewhat actionable, as it points out areas for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies the absence of an ablation study and the lack of comparison to methods from"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on which models to consider or how to incorporate these results. The authors can infer that they need to expand their theoretical analysis, but the lack of concrete details makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, it does not specify which sections or parts of the paper currently focus on SVC, making it difficult for the authors to pinpoint where these additional results should be included. The comment is specific in its suggestion to include more theoretical results on more complicated models, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these additional results are necessary or how they would improve the paper. Without such supporting information, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which models or aspects of the models should be considered. The comment does not offer actionable suggestions or examples of what additional theoretical results could be included, leaving the authors with a general idea of what might be improved but without clear direction on how to achieve it. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifically mentions that the existing results in Fig. 11 are insufficient for this purpose. This feedback provides a clear and direct action for the authors to take, which is to conduct additional ablation studies to support their claim. The comment is specific in identifying what needs to be done and why, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, specifically mentioning Fig. 11. This provides full grounding as it clearly identifies the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for additional ablation studies to support the necessity of the proposed DA Inversion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, specifically mentioning that the existing results in Fig. 11 are insufficient. While the comment identifies a potential gap in the evidence provided, it does not offer specific examples or detailed reasoning to support why additional studies are necessary. The lack of detailed justification or references makes it somewhat verifiable, as the authors would need to infer the exact nature of the additional studies required. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It points out that the existing results in Fig. 11 are insufficient for this purpose, providing a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on what types of ablation studies would be beneficial or how to structure them. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and provides a clear action for the authors to take. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of clustering in the second phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this issue. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and determine its specifics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of clustering in the second phase of training and suggests conducting a clear ablation study to address this issue. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the second phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. The comment suggests that a clear ablation study should be presented to address this issue. While the comment raises a valid concern, it lacks specific examples or references to support the claim that clustering is unnecessary. The suggestion for an ablation study is logical, but the comment could be strengthened by providing more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology, specifically questioning the necessity of clustering in the second phase of training if a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this concern. This feedback is clear and actionable, as it provides a specific direction for the authors to conduct an ablation study to clarify the role of clustering in their approach. However, the comment could be more helpful if it offered additional guidance on how to design or interpret the ablation study. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment mentions that the forgetting in Figure 2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is a concern, if it needs addressing, or how the authors might investigate or address it. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by noting that the forgetting in Figure 2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. This provides clear guidance on what aspect of the figure needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the forgetting in Figure 2a, stating that it is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific observation regarding the forgetting in Figure 2a, noting that it is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, it does not provide any further context, explanation, or suggestions for improvement. The comment lacks actionable feedback or guidance on how the authors might address this observation or what implications it might have for their work. Without additional context or suggestions, the authors are left with a vague observation that does not significantly aid in improving their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract, but it acknowledges that having a data-dependent bound is acceptable. While the comment provides a clear action to take\u2014highlighting the data-dependent nature of the results\u2014it does not offer specific guidance on how to implement this suggestion or what aspects of the data-dependent nature should be emphasized. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the data-dependent nature is discussed. This lack of explicit reference makes it weakly grounded. The comment is specific in suggesting a potential improvement by highlighting the data-dependent nature, but without clear grounding, the authors may struggle to identify where to make this change. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract, but acknowledges that having a data-dependent bound is acceptable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract, but acknowledges that having a data-dependent bound is acceptable. This feedback is somewhat helpful as it points out a potential area for improvement in terms of clarity and presentation of the results. However, the comment lacks specific guidance on how to effectively communicate the data-dependent nature or what aspects should be emphasized. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification regarding the meaning of RMSD in Figure 3. It provides a specific question about whether RMSD refers to the RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus. This direct request for clarification leaves no ambiguity about what the authors need to do to improve their draft. The action is clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD, distinguishing between RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion regarding the interpretation of RMSD in Figure 3. By asking whether RMSD refers to the RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus, the comment provides clear and actionable feedback. This guidance helps the authors clarify their presentation and ensure that their figures accurately represent the intended meaning. The specificity of the question allows the authors to make a direct improvement to their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It also asks whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the authors should address this question, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing phase transitions or regret scaling, but this inference is not direct. The comment is specific in its request for a more thorough treatment and a discussion of the question posed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment identifies a potential area for improvement, it lacks specific examples, references, or detailed reasoning to support the claim. The suggestion is based on a logical inquiry but requires further elaboration to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a pertinent question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. This feedback is clear and actionable, as it directs the authors to consider an important aspect of their work that may not have been adequately addressed. However, the comment could be more helpful if it provided additional guidance or examples on how to approach this analysis. Overall, the comment is mostly helpful as it highlights a critical area for enhancement and provides a direction for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the authors should address this question, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing phase transitions or regret scaling, but this inference is not direct. The comment is specific in its request for a more thorough treatment and a discussion of the question posed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment identifies a potential area for improvement, it lacks specific examples, references, or detailed reasoning to support the claim. The suggestion is based on a logical inquiry but requires further elaboration to be fully verifiable. Therefore, the comment is categorized as somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.', 'ver"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited in the paper (e.g., RARL). It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback provides a clear and explicit action for the authors to take, which is to either include comparisons to these methods or clarify their inclusion in GAD or EG. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of comparisons to previous robust RL methods, despite these methods being cited in the paper. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion or results sections where comparisons are typically made. The suggestion to be explicit is specific, as it points out a potential gap in the paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparisons to previous robust RL methods are missing, despite these methods being cited. The reviewer suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment identifies a potential gap in the paper, it lacks specific examples or references to the missing comparisons, making it somewhat verifiable. The authors would need to infer which specific comparisons are missing and how to address this issue, thus requiring more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by pointing out the absence of comparisons to previous robust reinforcement learning (RL) methods, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback is clear and actionable, as it directs the authors to either include comparisons or clarify the inclusion of these prior works. However, the comment could be more helpful if it provided specific examples of the missing comparisons or suggested which prior works should be included. Overall, the comment is mostly helpful as it highlights an area for improvement and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is clear and specific, giving the authors a direct action to take\u2014namely, to include additional details in their draft. The comment provides concrete guidance on what needs to be addressed, ensuring that the authors know exactly how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for additional details, but without clear grounding, the authors may struggle to identify where these details should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not provide any specific reasoning or evidence to support why these details are necessary or how they would improve the paper. The comment lacks any justification or examples, making it difficult for the authors to understand the importance of these details or how they might address the issue. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is clear and actionable, as it directly points out where the authors can enhance their draft by offering additional information. However, the comment could be more helpful if it provided examples or guidance on how to present these details effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the relationship between HIS and the negative inverse of mean response time. While it highlights a potential issue or lack of explanation, it does not provide explicit guidance or suggestions for the authors to address this question. The authors are left to infer that they should clarify or explain this relationship, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the proportionality of HIS to the negative inverse of mean response time, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time. While it identifies a potential area of confusion or lack of explanation in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment highlights a specific point that needs clarification but lacks actionable feedback or detailed advice on how to improve the draft. As a result, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it questions the rationale behind choosing a particular sparse representation learning method and suggests comparing FTA as a baseline in the experiments. Second, it points out the inconsistency in comparing the method in a supervised learning setting but omitting it in a reinforcement learning (RL) setting, questioning the validity of the performance comparison. The reviewer explicitly suggests that a rigorous comparison is necessary for an empirical paper. While the comment provides clear actions for the authors to take, it lacks specific guidance on how to implement these suggestions, such as detailing the specific aspects of the sparse representation learning method that should be compared or how to conduct the comparison in the RL setting. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two main points: the rationale behind choosing a particular sparse representation learning method and the need for a rigorous comparison in the experiments. It suggests comparing FTA as a baseline and questions the omission of the method in the reinforcement learning (RL) setting. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the methodology and experimental sections. The comment is specific in detailing what needs to be addressed regarding the choice of method and the comparison with FTA. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main claims. First, it questions the rationale behind choosing a particular sparse representation learning method, suggesting that a rigorous comparison is necessary. Second, it points out the inconsistency in comparing the method in a supervised learning setting but omitting it in a reinforcement learning setting, questioning the validity of the performance comparison. While the comment provides logical reasoning for the need for a rigorous comparison, it lacks specific examples or references to support the claim about the method\\'s choice. The suggestion to compare FTA as a baseline is a reasonable point, but the comment could be strengthened by providing more detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important points. First, it questions the rationale behind choosing a particular sparse representation learning method and suggests comparing FTA as a baseline in the experiments. This feedback is valuable as it prompts the authors to justify their methodological choices and consider a more comprehensive comparison. Second, the comment points out an inconsistency in the experimental setup, questioning why the method is compared in a supervised learning setting but omitted in a reinforcement learning (RL) setting. This observation highlights a potential gap in the paper\\'s evaluation and suggests that a rigorous comparison is necessary for an empirical paper. While the comment identifies key areas for improvement, it could be more helpful by providing specific guidance on how to address these issues or by suggesting alternative methods for comparison. Overall, the feedback is mostly helpful as it provides clear directions for enhancing the paper\\'s rigor and comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have made a choice of shift and scaling but have not provided an explanation for why this choice is more appropriate. While the comment identifies a gap in the explanation, it does not explicitly instruct the authors to provide this justification. The action is implicit, as the authors can infer that they need to explain their choice, but it is vague because it lacks specific guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it points out the lack of explanation for the choice of shift and scaling, which is stated as \"the more appropriate\" but without justification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of explanation for a choice of shift and scaling made by the authors, stating that it is \"the more appropriate\" choice but without justification. This claim is somewhat verifiable as it points out a gap in the explanation, but it lacks specific reasoning or evidence to support why this choice is more appropriate. The comment prompts the authors to provide a rationale for their decision, but without additional context or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors have made a choice of shift and scaling but have not provided an explanation for why this choice is more appropriate. This feedback is valuable as it highlights a gap in the justification provided by the authors, which is crucial for the reader\\'s understanding and acceptance of the methodology. However, the comment could be more helpful if it offered suggestions on how the authors might address this gap, such as by discussing the rationale behind their choice or providing additional evidence. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the authors have made a choice of shift and scaling but have not provided an explanation for why this choice is more appropriate. While it identifies a gap in the explanation, it does not explicitly instruct the authors to provide this justification or suggest how they might do so. The action is implicit and lacks concrete guidance, making it barely actionable. The authors can infer that they need to explain their choice, but the comment does not provide specific steps or examples to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it points out the lack of explanation for the choice of shift and scaling, which is stated as \"the more appropriate\" but without justification. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of explanation for the choice of shift and scaling made by the authors, stating that it is \"the more appropriate\" but without justification. This claim is somewhat verifiable as it points out a gap in the explanation, but it lacks specific reasoning or evidence to support why this choice is more appropriate. The comment prompts the authors to provide a rationale for their decision, but without additional context or references, the claim remains somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors have made a choice of shift and scaling but have not provided an explanation for why this choice is more appropriate. This feedback is valuable as it highlights a gap in the justification provided by the authors, which is crucial for the reader\\'s understanding and acceptance of the methodology. However, the comment could be more helpful if it offered suggestions on how the authors might address this gap, such as by discussing the rationale behind their choice or providing additional evidence. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the authors have made a choice of shift and scaling but have"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors revise the use of \"partial inference of GFlowNets\" in the title and elsewhere, indicating that the current phrasing is problematic. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be revised. The comment is explicit and concrete, leaving no ambiguity about the necessary changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be revised, namely the use of \"partial inference\" in the title and elsewhere. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims an issue with the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting a revision. However, the comment does not provide any reasoning or justification for why this phrase is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that this phrase should be revised. While it points out a potential inconsistency or confusion in the terminology, it does not provide further explanation or guidance on why this change is necessary or how it could be improved. The comment is somewhat helpful as it highlights a potential issue, but it lacks depth and actionable suggestions for improvement, leaving the authors with only a vague direction for revision. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only uses BertScore to measure the similarity of the newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not provide specific guidance on which matrices to consider or how to incorporate them into the analysis. The action is implicit, as the authors need to infer that they should explore additional metrics, and it is vague because it lacks concrete details on how to implement this suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"bertscore\" to measure similarity, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of discussion on other matrices that could measure the stealthiness of the generated content. This provides clear guidance on what aspect of the paper needs further exploration or discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only uses BertScore to measure the similarity of the newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, the comment does not provide specific examples or references to these alternative matrices, making it difficult for the authors to understand which matrices might be more appropriate. The lack of detailed justification or examples results in the comment being somewhat verifiable, as it provides a general suggestion but lacks the necessary support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the use of BertScore as the sole metric for measuring the similarity of the newly generated text. It suggests that there are other matrices that could be used to measure the stealthiness of the generated content, which is a valuable insight. However, the comment lacks specific suggestions or examples of alternative metrics that could be considered, which would make it more actionable. While it points out an area for improvement, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, as it provides some direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues that need to be addressed, including the need to highlight issues with existing estimators, define basic notation, and clarify the heuristic nature of Algorithm 1. While the comment lists multiple areas for improvement, it does not provide specific guidance or concrete steps on how to address these issues. The authors are left to infer the necessary actions but without detailed instructions on how to implement them. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.2 or Eq. 3,\" \"p. 2,\" \"an outer product ( v ) \u2297 2 (Alg. 1),\" \"the constraint set \u0398 (Alg. 2),\" and \"the constant d 2 (Thm. 2, Eq. 5),\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues, such as the need to highlight issues with existing estimators, define basic notation, and clarify the heuristic nature of Algorithm 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several issues, including the need to highlight issues with existing estimators and the lack of definition for basic notation. However, it does not provide specific examples or detailed reasoning to support these claims. The comment mentions that the notation is not defined and provides some examples, but it does not explain why this lack of definition is problematic or how it affects the paper\\'s clarity. Additionally, the comment does not provide references or detailed examples to substantiate the claim about existing estimators. This makes the comment somewhat verifiable, as it provides some insight but lacks comprehensive justification and evidence. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues that need to be addressed in the paper. It highlights the need to clearly highlight issues with existing estimators, which is crucial for the paper\\'s applicability. Additionally, it points out that basic notation is not defined, which can lead to confusion for readers. The comment also mentions that certain terms, such as \"dimensionality p,\" \"unit ball S p,\" \"outer product,\" \"constraint set \u0398,\" and \"constant d 2,\" are not clearly defined, making it difficult for readers to understand the paper. Furthermore, it suggests that the heuristic nature of Algorithm 1 is unclear. While the comment identifies several areas for improvement, it lacks specific guidance or suggestions on how to address these issues, such as providing definitions or clarifying the heuristic nature. Therefore, the comment is somewhat helpful, as it provides valuable insights but lacks detailed actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to introduce three perceptual loss functions for PSR, but notes that the neural network and loss functions used (reconstruction error, TV, perceptual loss, and dice) are not novel in the field of medical imaging. The reviewer suggests that the authors should elaborate on which parts of the loss functions are new. This feedback provides a clear and explicit action for the authors to take, which is to provide more detail on the novelty of the loss functions. The suggestion is concrete, as it specifies exactly what additional information is needed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the perceptual loss functions for PSR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the neural network and loss functions used are not novel in the field of medical imaging and suggests that the authors elaborate on which parts of the loss functions are new. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the perceptual loss functions for PSR, noting that the neural network and loss functions used (reconstruction error, TV, perceptual loss, and dice) are not novel in the field of medical imaging. The reviewer suggests that the authors elaborate on which parts of the loss functions are new. While the comment highlights a potential issue with the novelty claim, it lacks specific examples or references to substantiate the claim that these components are not novel. This makes the claim somewhat verifiable, as it provides a logical basis for the critique but requires further detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty claim made by the paper, specifically regarding the perceptual loss functions for PSR. It points out that while the paper claims two of the loss functions are new, the neural network and loss functions used (reconstruction error, TV, perceptual loss, and dice) are not novel in the field of medical imaging. The comment suggests that the authors should elaborate on which parts of the loss functions are new, providing a clear and actionable suggestion for improvement. This feedback is helpful as it guides the authors to clarify their claims and provide more detailed information, which can enhance the credibility and originality of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to differentiate the new aspects of the loss functions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the experimental results do not demonstrate significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. However, it does not provide specific guidance or suggestions on how the authors could address these issues or improve their experimental results. The feedback lacks actionable details, such as recommending specific datasets or methods to enhance the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and references \"Table 5 in [1],\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the experimental results do not exhibit significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the experimental results do not demonstrate significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of 'Table 5 in [1]' provides some context, but without further elaboration or evidence, the claims remain vague. This makes the comment somewhat verifiable, as it provides a starting point for the authors to explore but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the experimental results, noting that they do not demonstrate any significant improvement in real-life datasets. It also critiques the comparison on the ZINC dataset, suggesting that it is lacking. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their experimental results. The feedback is somewhat helpful as it points out a weakness but does not provide actionable steps for improvement, leaving the authors with a general direction to consider but no detailed guidance on how to proceed. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the experimental results do not demonstrate significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. However, it does not provide specific suggestions or guidance on how the authors could address these issues or improve their experimental results. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and references \"Table 5 in [1],\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the experimental results do not demonstrate significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the experimental results do not demonstrate significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of 'Table 5 in [1]' provides some context, but without further elaboration, the claims remain vague. This lack of detailed justification makes the comment somewhat verifiable, as it provides a starting point for the authors but lacks the depth needed for full verification. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the experimental results, noting that they do not demonstrate any significant improvement in real-life datasets. It also critiques the comparison on the ZINC dataset, suggesting that it is lacking. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their experimental results. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to resolve it. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not provide comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the experimental"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that the SLM performs better than larger models due to limited data availability. It provides examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. However, the comment does not explicitly instruct the authors to address this issue or suggest how they might refute or clarify their claim. The action is implicit and lacks concrete guidance on how to implement the suggested analysis or correction. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3 (b)\" and provides specific examples of experiments, such as LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the claim that the SLM performs better than larger models due to limited data availability. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This detailed evidence supports the counter-argument, making the claim mostly verifiable. However, the comment could be strengthened by providing more context or references to the experiments mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This feedback is valuable as it challenges the authors to reconsider their claim and provides concrete evidence from the experiments to support the counter-argument. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and provides some guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment questions the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. However, the comment does not explicitly instruct the authors to address this issue or suggest how they might refute or clarify their claim. The action is implicit and lacks concrete guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3 (b)\" and provides specific examples of experiments, such as LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the claim that the SLM performs better than larger models due to limited data availability. Therefore, this comment is labeled as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This detailed evidence supports the counter-argument, making the claim mostly verifiable. However, the comment could be strengthened by providing more context or references to the experiments mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) showing LucaOne performing better than BSM"}
{"generated_text": "{'actionability_rationale': 'The review comment points out inconsistencies in the notation, specifically mentioning the issue with the notation for nu in Figures 2 & 3 and again in Figures 4. This feedback highlights a specific area where the authors need to address the inconsistency in their notation. However, the comment does not provide explicit instructions on how to resolve the issue or suggest specific changes to make the notation consistent. While the action is implicit, it is concrete because it clearly identifies the problem area. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figures 2 & 3 and Figure 4, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the inconsistency in the notation, particularly with the variable nu. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, specifically mentioning the issue with the variable nu in Figures 2 & 3 and again in Figures 4. This claim is somewhat verifiable as it highlights specific instances where the notation appears to differ, providing a basis for the critique. However, the comment lacks detailed examples or explanations of how the inconsistencies affect the clarity or understanding of the paper. To fully substantiate the claim, the reviewer could provide more specific examples or references to the expected notation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, noting inconsistencies in the representation of variables, particularly the variable \"nu.\" It highlights particular instances where the notation in figures does not match the notation in the algorithm description and again changes on page 4 and in Figure 4. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their notation. By addressing this issue, the authors can enhance the readability and professionalism of their draft. However, the comment could be more helpful if it provided suggestions on how to standardize the notation or offered examples of how to resolve the inconsistencies. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area needing attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of their proposed method. This feedback provides a clear and direct action for the authors to take, specifying the type of task and reference to a relevant source. The suggestion is concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup or validation of the proposed method, but this inference is not direct. The comment is specific in suggesting a particular type of task to validate the effectiveness of the method, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments should be conducted in challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the validation of the method. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This feedback is clear and actionable, providing a specific direction for the authors to enhance the robustness and applicability of their work. By recommending a particular type of task and referencing a relevant source, the comment offers a concrete step for improvement. However, it could be more helpful if it included additional details on how to design these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction regarding the assumptions made by various papers. It questions whether the assumption of linear separability is too strong and suggests that it might refer to orthogonally separable data. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the assumptions. The feedback lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to improve the draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the fairness of the summary of Williams et al. (2019) and other papers, particularly regarding the assumption of linear separability and the strength of the assumption. The comment further asks whether it refers to orthogonally separable data, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary in the introduction regarding the assumptions made by various papers. It suggests that some of these papers assume linear separability, which is considered a stronger assumption than the one made in the paper. The reviewer provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. However, the comment lacks detailed reasoning or evidence to support why the assumptions are unfair or how they relate to orthogonally separable data. This makes the claim somewhat verifiable, as it provides a direction for further exploration but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the fairness of the summary in the introduction regarding the assumptions made by various papers. It questions whether the assumption of linear separability is too strong and suggests that it might refer to orthogonally separable data. This feedback is somewhat helpful as it prompts the authors to reconsider the fairness of their summary and consider the implications of the assumptions made. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the fairness of their summary. While it provides a direction for improvement, it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the fairness of the summary in the introduction regarding the assumptions made by various papers. It questions whether the assumption of linear separability is too strong and suggests that it might refer to orthogonally separable data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their assumptions. Without specific actions or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the fairness of the summary regarding the assumptions made by various papers, particularly regarding linear separability and its relation to orthogonally separable data. The comment provides a clear direction for the authors to consider, making it fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary in the introduction regarding the assumptions made by various papers. It suggests that some of these papers assume linear separability, which is considered a stronger assumption than the one made in the paper. The comment provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. However, the comment lacks detailed reasoning or evidence to support why the assumptions are unfair or how they relate to orthogonally separable data. This makes the claim somewhat verifiable, as it provides a direction for further exploration but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the fairness of the summary in the introduction regarding the assumptions made by various papers. It questions whether the assumption of linear separability is too strong and suggests that it might refer to orthogonally separable data. This feedback prompts the authors to reconsider the fairness of their summary and consider the implications of the assumptions made. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the fairness of their summary. While it raises an important point"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from 0 during training. However, it does not provide explicit guidance on how to address this issue or suggest specific modifications to improve the method. The authors are left to infer that they might need to revise or clarify the theoretical basis of their method, but the comment lacks concrete steps or suggestions for doing so. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that it holds only when the upweight is very close to 0 and provides a rationale for why this might be problematic. The comment further suggests that the influence function might not reflect each sample\\'s influence correctly when weights are far from 0 during training iteration. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability of the per-sample weight tuning method, specifically questioning the validity of the influence function when the upweight is not close to 0. The comment provides a logical reasoning by explaining that the theoretical approximation of each sample\\'s contribution from Taylor\\'s first-order expansion may not be accurate when weights are far from 0. This reasoning is based on a common understanding of Taylor\\'s approximation and its limitations. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore this issue to fully address the concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from 0 during training iteration. This is a critical observation that could impact the reliability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with centering in partial shapes or scenes, suggesting that centering may not be well-defined for such cases. It explicitly advises the authors to address this issue. Additionally, it provides a clarification about the experiment with up to 50% missing points, noting that it is an augmentation with the ground-truth center provided, which may not be the case in general when training with partial shapes. While the comment clearly identifies areas that need attention, it does not provide specific guidance on how to address the issue or improve the methodology. The authors are left with a clear action to take but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of centering in partial shapes and scenes, suggesting that centering may not be well-defined for such cases. It provides a specific critique of the authors\\' approach, questioning the effectiveness of centering for partial shapes or scenes. Additionally, it clarifies that the experiment with up to 50% missing points is an augmentation with the ground-truth center provided, which may not be the case in general when training with partial shapes. This provides a clear context for the issue being discussed. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to sections discussing centering or partial shapes, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of centering for partial shapes or scenes, suggesting that it may not be well-defined in such cases. The reviewer provides a logical reasoning by pointing out that centering can be effective for complete shapes but may not be suitable for partial ones. Additionally, the reviewer clarifies that the experiment with up to 50% missing points is an augmentation with the ground-truth center provided, which may not be the case in general when training with partial shapes. This reasoning is supported by a clear explanation of the issue and a comparison with the experimental setup, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with centering in partial shapes or scenes, suggesting that centering may not be well-defined for such cases. It advises the authors to address this issue, which is a clear and actionable piece of feedback. Additionally, the comment clarifies a misunderstanding about the experiment with up to 50% missing points, noting that it is an augmentation with the ground-truth center provided, which may not be the case in general when training with partial shapes. This clarification is valuable for the authors to understand the limitations of their experimental setup. Overall, the comment is mostly helpful as it provides specific guidance on a critical aspect of the paper, though it could be more comprehensive by offering suggestions on how to address the issue of centering for partial shapes or scenes. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests an action by recommending that the authors try ensembling models trained with the proposed negative augmentations and without them to see if it improves performance. This is an explicit suggestion with concrete guidance on how to implement the action, providing clear steps for the authors to follow. The comment is highly actionable as it offers a specific method for testing the effectiveness of the proposed approach. Therefore, this comment is rated as a 5 on the actionability scale.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an action related to the proposed method of learning less about texture semantics by adding negative samples. It references a similar approach in [1] and suggests trying to ensemble models trained with the proposed negative augmentations and without them to see if performance improves. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The suggestion is specific, as it provides a clear direction for further experimentation. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests an action to improve the paper by proposing an ensemble of models trained with and without the proposed negative augmentations. However, it does not provide any supporting evidence or references to justify why this approach would be beneficial or how it relates to the current work. The comment lacks specific reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improving the paper by proposing an ensemble of models trained with and without the proposed negative augmentations. This feedback is actionable and offers a clear direction for the authors to test the effectiveness of their approach. By suggesting a method to evaluate the impact of the proposed negative samples, the comment helps the authors refine their methodology and potentially enhance the performance of their models. However, the comment could be more helpful if it included additional details or examples of how to implement the ensemble method. Overall, the feedback is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests an action by recommending that the authors try ensembling models trained with the proposed negative augmentations and without them to see if it improves performance. This is an explicit suggestion with concrete guidance on how to implement the action, providing clear steps for the authors to follow. The comment is highly actionable as it offers a specific method for testing the effectiveness of the proposed approach. Therefore, it aligns with a score of 5.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an action related to the proposed method of learning less about texture semantics by adding negative samples. It references a similar approach in [1] and suggests trying to ensemble models trained with the proposed negative augmentations and without them to see if performance improves. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of the action to take, but without clear grounding, the authors may struggle to identify where to implement this change. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests an action to improve the paper by proposing an ensemble of models trained with and without the proposed negative augmentations. However, it does not provide any supporting evidence or reasoning to justify why this approach would be beneficial or how it relates to the current work. The comment lacks specific examples or references to similar studies that have successfully used ensembling, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improving the paper by proposing an ensemble of models trained with and without the proposed negative augmentations. This feedback is actionable and offers a clear direction for the authors to test the effectiveness of their approach. By suggesting a method to evaluate the impact of the proposed negative samples, the comment helps the authors refine their methodology and potentially enhance the performance of their models. However, the comment could be more helpful if it included additional details or examples of how to implement the ensemble method. Overall, the feedback is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests an action by"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities and references a specific page and equation in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing or how the authors might investigate or address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (page 6 and Appendix B) and references a particular equation (Eq. 7), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the guarantee of D_i going through all possible transition probabilities and referencing the claim of sample efficiency in Eq. 7 over Eq. 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities, referencing a specific page and equation in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim or question being raised. The comment lacks detailed explanation or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the guarantee of D_i going through all possible transition probabilities, referencing a particular page and equation in the paper. This is a relevant point that could impact the validity of the claims made in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an area of concern, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities, referencing specific pages and equations in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing or how the authors might investigate or address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific pages (page 6 and Appendix B) and references a particular equation (Eq. 7), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the guarantee of D_i going through all possible transition probabilities and referencing the claim of sample efficiency in Eq. 7 over Eq. 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities, referencing specific pages and equations in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim or question being raised. The comment lacks detailed explanation or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to understand and address the issue. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the guarantee of D_i going through all possible transition probabilities, referencing a particular page and equation in the paper. This is a relevant point that could impact the validity of the claims made in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an area of concern, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the guarantee of D_i going through all possible transition probabilities, referencing specific pages and equations in the paper"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors form clusters for tokens in Figure 1, indicating that this process is unclear in Section 3. While the comment highlights a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this process in their draft. However, the comment does not offer concrete steps on how to achieve this clarification, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning how the authors form clusters for tokens in Figure 1, indicating that this process is unclear in Section 3. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the formation of clusters for tokens in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the process of forming clusters for tokens in Figure 1, as described in Section 3. By pointing out this lack of clarity, the comment highlights an important issue that the authors need to address to improve the comprehensibility of their work. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect, such as by offering a detailed explanation or additional examples. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s applicability to large language models in real-world settings. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method. There is no guidance on potential modifications, alternative approaches, or suggestions for reducing the complexity or time cost of experiments. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the introduction of additional hyperparameters in SimNPO, which increases the complexity and time cost of experiments. It highlights the potential limitation of this method for large language models in real-world settings. However, the comment does not specify which part of the paper discusses these hyperparameters or the experiments, making it weakly grounded. The comment is specific in detailing the issue with the additional hyperparameters and their impact on the method\\'s applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that require manual adjustment for optimal performance, significantly increasing the complexity and time cost of experiments. This claim is somewhat verifiable as it provides a logical reasoning for the increased complexity and time cost associated with the additional hyperparameters. However, the comment lacks specific examples or references to support the assertion about the impact on real-world applications, such as how these additional parameters affect the scalability or practicality of the method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, which can limit the method\\'s applicability in real-world settings, especially for large language models. While the comment highlights a critical weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the complexity and time cost. The feedback is somewhat helpful as it points out a potential limitation, but it lacks actionable advice for improvement, leaving the authors with only a general understanding of the problem. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s applicability in real-world settings. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method. There is no guidance on potential modifications, alternative approaches, or suggestions for reducing the complexity or time cost of experiments. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the introduction of additional hyperparameters in SimNPO, which increases the complexity and time cost of experiments. It highlights the potential limitation of this method for large language models in real-world settings. However, the comment does not specify which part of the paper discusses these hyperparameters or the experiments, making it weakly grounded. The comment is specific in detailing the issue with the additional hyperparameters and their impact on the method\\'s applicability, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that require manual adjustment for optimal performance, significantly increasing the complexity and time cost of experiments. This claim is somewhat verifiable as it provides a logical reasoning for the increased complexity and time cost associated with the additional hyperparameters. However, the comment lacks specific examples or references to support the assertion about the impact on real-world applications, such as how these additional parameters affect the scalability or practicality of the method. Without detailed evidence or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal"}
{"generated_text": "{'actionability_rationale': 'The review comment criticizes the paper for placing too much emphasis on affordance prompting, which is considered overengineered. However, it does not provide specific guidance on how the authors should address this issue or suggest ways to improve the presentation of affordance prompting. The comment lacks actionable details, such as recommending alternative approaches or providing examples of how to better demonstrate the advantages of affordance prompting. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the emphasis on affordance prompting, suggesting that it is overengineered and provides an example using the Pick&place example. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where affordance prompting is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its critique of affordance prompting, it is weakly grounded because it does not provide clear guidance on where to make improvements. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is considered overengineered. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the Pick&place example as an instance of overengineered affordance prompting is not elaborated upon, leaving the authors without clear guidance on how to address the issue. The lack of detailed justification or examples makes the claim borderline verifiable, as it provides some direction but insufficient evidence to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the paper for placing too much emphasis on affordance prompting, describing it as overengineered. It provides a specific example, the Pick&place example, to illustrate the issue. However, the comment lacks actionable suggestions or guidance on how the authors might address this concern or improve the presentation of affordance prompting. While it identifies a potential weakness, it does not offer detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the emphasis on affordance prompting, describing it as overengineered, and provides an example using the Pick&place example. However, it does not offer specific guidance or suggestions on how the authors might address this issue or improve the presentation of affordance prompting. The comment lacks actionable details, such as recommending alternative approaches or providing examples of how to better demonstrate the advantages of affordance prompting. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the emphasis on affordance prompting, describing it as overengineered, and provides an example using the Pick&place example. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where affordance prompting is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its critique of affordance prompting, it is weakly grounded because it does not provide clear guidance on where to make improvements. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is considered overengineered. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the Pick&place example as an instance of overengineered affordance prompting is not elaborated upon, leaving the authors without clear guidance on how to address the critique. The lack of detailed justification or examples makes the claim borderline verifiable, as it provides some direction but insufficient evidence to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the paper for placing too much emphasis on affordance prompting, describing it as overengineered. It provides a specific example, the Pick&place example, to illustrate the issue. However, the comment lacks actionable suggestions or guidance on how the authors might address this concern or improve the presentation of affordance prompting. While it identifies a potential weakness, it does not offer detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This is a clear and direct action for the authors to take, as it specifies exactly what kind of analysis is required to strengthen their work. The comment provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the paper should include these studies or where they should be integrated. This lack of explicit reference to specific sections or parts of the paper makes it weakly grounded. The comment is specific in its request for ablation studies to demonstrate the necessity of each part, but without clear grounding, the authors may struggle to identify where to implement these studies. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not provide any specific reasoning or examples to support why these studies are necessary or how they would benefit the paper. The comment lacks detailed justification or references to similar studies, making it difficult for the authors to understand the importance of the suggestion. As a result, the claim is considered unverifiable due to the absence of supporting evidence or reasoning.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the robustness and comprehensiveness of the paper. By conducting ablation studies, the authors can validate the contribution of each component, which is crucial for establishing the effectiveness and reliability of their methodology. However, the comment could be more helpful if it included specific guidance on how to design and execute these studies. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra training cost. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to demonstrate the necessity of the instruction-tuning stage more convincingly. The feedback is implicit and lacks concrete steps, leaving the authors to infer that they need to provide more evidence or analysis. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. However, it does not specify which part of the paper this conclusion is drawn from, making it weakly grounded. The comment is specific in questioning the necessity of the instruction-tuning stage and suggesting an alternative explanation for the performance improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. The reviewer raises a logical concern about whether the performance improvement could be attributed to these extra costs. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it provides a plausible alternative explanation, the absence of concrete evidence or references makes the claim somewhat verifiable. The authors would need to further explore and address this concern, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to these extra costs. This feedback is somewhat helpful as it prompts the authors to consider alternative explanations for the observed performance gains and encourages them to provide a more convincing demonstration of the necessity of the instruction-tuning stage. However, the comment lacks specific suggestions or guidance on how to address this concern or provide additional evidence, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to these extra costs. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or demonstrate the necessity of the instruction-tuning stage more convincingly. The feedback lacks actionable steps or specific recommendations, leaving the authors to infer that they need to provide more evidence or analysis. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. However, it does not specify which part of the paper this conclusion is drawn from, making it weakly grounded. The comment is specific in questioning the necessity of the instruction-tuning stage and suggesting an alternative explanation for the performance improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. The reviewer raises a logical concern about whether the performance improvement could be attributed to these extra costs. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it provides a plausible alternative explanation, the absence of concrete evidence or references makes the claim somewhat verifiable. The authors would need to further explore and address this concern, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of the instruction-tuning stage in MoE models, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to these extra costs, prompting the authors to consider alternative explanations. This feedback is somewhat helpful as it challenges the authors to provide a more convincing demonstration of the necessity of the instruction-tuning stage. However, the comment lacks specific suggestions"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies that the evaluation setup is outdated and suggests that the authors update it to reflect more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. It also recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback provides clear and concrete actions for the authors to take, specifying both the need for updating the evaluation setup and the type of testing that would be beneficial. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation setup, specifically mentioning that it is outdated and suggesting that the authors update it to reflect more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. It also recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or methodology sections. The suggestion is specific, as it provides clear guidance on how to update the evaluation setup and what type of testing would be beneficial. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated, citing the release of Llama-1 and Mistral-v0.1 more than a year ago and the advancement of current models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. The reviewer suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST. This claim is supported by logical reasoning and references to recent model advancements, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the advancements in these models, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated and does not reflect recent advancements in language models. It provides specific examples of models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2 that have been released since the evaluation setup was conducted. The comment also suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback is clear and actionable, offering the authors a concrete way to improve their evaluation setup and enhance the relevance and impact of their work. By addressing this point, the authors can significantly strengthen their paper. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of logical coherence in the second section, where many related works are presented. However, it does not provide specific guidance on how to improve the logical coherence or suggest ways to organize the content more effectively. The feedback is vague and lacks explicit instructions, leaving the authors uncertain about how to address the issue. Without concrete steps or examples, the authors may struggle to understand what changes are needed to improve the coherence. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"second section,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. However, the comment lacks specificity as it does not detail what aspects of the logical coherence are lacking or how the content could be better organized. Without specific guidance or examples, the authors may struggle to understand and address the issue. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence, resulting in a disorganized content. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to illustrate the lack of coherence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the second section of the paper, noting a lack of logical coherence that results in a somewhat disorganized content. While it highlights a potential problem, the comment does not provide detailed guidance or suggestions on how to improve the logical structure or organization of the content. Without specific advice or examples, the authors may struggle to understand and address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a problem but lacks depth and actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention the language they focus on when retrieving Reddit posts. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what information should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to mention the language used for retrieving Reddit posts, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the language used for retrieval. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the language used for retrieving Reddit posts. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for clarification regarding the language used for retrieving Reddit posts. While it identifies a specific area that needs to be addressed, it lacks depth and does not provide any guidance or suggestions on how the authors might improve this aspect of their work. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not offer actionable feedback or insights that would help the authors enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks comparisons with recent works, specifically mentioning \"[1].\" This provides a clear and direct action for the authors to take, which is to include comparisons with the referenced work. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a lack of comparisons with recent works, specifically mentioning \"[1].\" However, it does not specify which part of the paper should include these comparisons or where the comparisons are missing. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the mention of \"[1]\" provides some grounding, the lack of specificity regarding where the comparisons should be made results in weak grounding. The comment is specific in identifying the need for comparisons with recent works, but it does not provide detailed guidance on how to implement this. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"[1].\" However, it does not provide any further details or context about what these recent works are or how they relate to the paper. The mention of \"[1]\" is insufficient to substantiate the claim, as it does not explain why these comparisons are necessary or how they would improve the paper. Without additional context or justification, the claim is unverifiable, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparisons with recent works, specifically mentioning \"[1].\" This feedback is clear and actionable, as it directs the authors to include comparisons with relevant recent works to enhance the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively incorporate these comparisons. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. While it raises an interesting point, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern, an area for exploration, or a potential limitation that needs addressing. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of TSG in a particular context, but without clear grounding, the authors may struggle to identify where this question fits into their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the applicability of TSG in diffusion models without class label embedding. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. While this question highlights a potential area of interest or concern, it lacks specificity and does not provide any guidance or suggestions for the authors to address this issue. The comment does not offer insights into why this might be a concern or how it could impact the paper\\'s findings or methodology. Without actionable feedback or detailed suggestions, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints to enhance reproducibility. It provides a clear and concrete action for the authors to take, specifying that they should attach these materials via anonymous repositories in the paper submission. This direct and detailed guidance leaves no ambiguity about what the authors need to do to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of limited reproducibility in the paper, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses these elements, leaving the authors to infer that it relates to the methodology or results sections. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has limited reproducibility unless the authors release their training code, dialogue dataset, and model checkpoints. The reviewer provides a logical reasoning by stating that without these resources, it is challenging to reproduce the claims in the paper. This reasoning is supported by a common expectation in academic research that datasets and code should be made available for verification and reproducibility. However, the comment could be strengthened by providing specific examples of how the lack of these resources affects the reproducibility of the claims. As it stands, the claim is mostly verifiable, as it provides a reasonable basis for the assertion but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the reproducibility of the paper's claims, emphasizing the need for the authors to release their training code, dialogue dataset, and model checkpoints. This feedback is clear and actionable, providing a direct suggestion for enhancing the paper's reproducibility. By encouraging the authors to attach these resources via anonymous repositories, the reviewer offers a concrete step that can help reviewers and future researchers verify the claims and potentially replicate the results. This level of detail and constructive guidance makes the comment highly helpful, as it empowers the authors to significantly improve the transparency and verifiability of their work. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the main result is somewhat obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the paper, such as suggesting ways to address the obviousness or improve the novelty of the result. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the result are considered obvious or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is \"a bit obvious\" because gradient boosting minimizes objectives in functional space. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main result is somewhat obvious because gradient boosting inherently minimizes objectives in functional space. However, it does not provide any constructive feedback or suggestions on how the authors might address this perceived lack of novelty or improve the significance of their findings. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a significant issue with the paper's contribution and suggests that it is insufficient and incomplete. It points out that the paper lacks detailed explanations of the proposed model and mentions limited related work and inadequate analysis. However, the comment does not provide specific guidance on how to address these issues or what additional information or analysis should be included. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the contribution of the work, stating that it is insufficient and not explicitly expressed in the paper. It also mentions that the work appears incomplete due to limited related work and inadequate analysis. However, the comment does not specify which parts of the paper are lacking or how they could be improved, nor does it provide specific examples or suggestions for enhancement. This lack of detail makes it difficult for the authors to identify the exact areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the contribution of the work is insufficient and not explicitly expressed, and that the paper appears incomplete due to limited related work and inadequate analysis. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references to related work or specific aspects of the analysis that are missing. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's contribution, stating that it is insufficient and not explicitly expressed. It also notes that the work appears incomplete due to limited related work and inadequate analysis. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to resolve it. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not fully support the authors in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues with the presentation of results in Figure 2: the unclear meaning of \"training steps\" and the need for Figure 2a to include iterations or training steps on the x-axis. The comment explicitly instructs the authors to clarify the meaning of \"training steps\" and to provide Figure 2a with iterations or training steps on the x-axis. This feedback is explicit and provides concrete guidance on how to address the issues, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the presentation of results, particularly the unclear meaning of \"training steps\" and the need for Figure 2a to include iterations or training steps on the x-axis. This provides clear guidance on what needs to be clarified or improved in the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the results presented in Figure 2, specifically regarding the meaning of \"training steps\" and the need for Figure 2a to include iterations or training steps on the x-axis. The comment highlights a lack of clarity in the presentation, which is a logical observation. However, it does not provide specific examples or references to support the claim that the current presentation is unclear. This makes the comment somewhat verifiable, as it identifies an issue but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the presentation of results in Figures 2a and 2b. It points out that the meaning of \"training steps\" is unclear, whether they refer to outer-loop iterations or raw experience, and suggests that Figure 2a should include iterations or training steps on the x-axis. This feedback is clear and actionable, as it provides the authors with specific guidance on how to improve the clarity and accuracy of their results presentation. By addressing these points, the authors can enhance the comprehensibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of using different metrics (flops, latency, and 1/FPS) for different hardware instead of using the same cost for all devices. While the comment implies that the authors should consider using a uniform metric, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should standardize their metrics but lack specific instructions on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using different metrics (flops, latency, and 1/FPS) for different hardware instead of using a uniform metric. However, it does not specify which part of the paper this question pertains to, such as a specific section or analysis where these metrics are discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the choice of metrics but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of metrics used for different hardware. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of using different metrics (flops, latency, and 1/FPS) for different hardware instead of using a uniform metric. This question prompts the authors to reconsider their methodology and potentially standardize their approach, which could lead to clearer comparisons across devices. However, the comment does not provide specific suggestions or guidance on how to address this issue, nor does it explain why using a uniform metric might be beneficial. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. While it implies that the authors should provide information on the maximum iterations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the concern about training speed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"two-dimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution, and the application of the Sinkhorn algorithm to approximate it. The reviewer questions the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of iterations on training speed. The reasoning is somewhat verifiable, as it points out a relevant issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution. It highlights the application of the Sinkhorn algorithm to approximate the solution and the need for iterations before each gradient descent. The comment specifically asks about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. This feedback is clear and actionable, as it prompts the authors to provide additional information about their experimental setup and its potential impact on training efficiency. By addressing this question, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it suggested ways to mitigate the potential slowdown or provided insights into how to optimize the training process. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a major weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that the authors should provide theoretical results to support their approach. While the comment implies that the authors should include theoretical results, it does not explicitly instruct them to do so or provide guidance on how to present these results. The action is implicit and somewhat vague, as the authors need to infer that they should include theoretical results but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment identifies a major weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that theoretical results should be provided to support the approach. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the teacher and student policies are discussed. The comment is specific in detailing what needs to be addressed, namely the need for theoretical results to substantiate the approach. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's soundness is a major weakness, specifically questioning the ability of the student policy to perform correct distribution matching. The reviewer suggests that theoretical results should be provided to support the approach, implying that it currently appears more like a heuristic rather than a theoretically sound method. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim about the method's soundness. The suggestion for theoretical results provides some direction, but the claim itself remains somewhat vague. Therefore, the comment is categorized as somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that the paper lacks theoretical results to support its approach, which is currently perceived as more heuristic than theoretically sound. This feedback is clear and actionable, as it directs the authors to provide theoretical results to strengthen their methodology. However, the comment could be more helpful if it offered specific suggestions on how to derive these theoretical results or what aspects need to be addressed. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a major weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that the authors should provide theoretical results to support their approach, implying that the current version of the method appears more like a heuristic rather than a theoretically sound approach. While the comment highlights a critical area for improvement, it does not explicitly instruct the authors on how to address this issue or what specific theoretical results should be included. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment identifies a major weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that theoretical results should be provided to support the approach, implying that the current version appears more like a heuristic rather than a theoretically sound method. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely the need for theoretical results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims a major weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. The reviewer suggests that theoretical results should be provided to support the approach, implying that it currently appears more like a heuristic rather than a theoretically sound method. While the comment identifies a potential issue, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The suggestion for theoretical results provides some direction, but the claim itself remains somewhat vague. Therefore, the comment is categorized as somewhat verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper's soundness, specifically questioning the ability of the student policy to perform correct distribution matching. It suggests that theoretical results should be provided to support the approach, implying that the current version appears"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to analyze and discuss the reasons why the proposed method does not perform well in some classes in Table 3. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis and discussion of the reasons why the proposed method does not perform well in some classes. This provides clear guidance on what the authors need to focus on. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not perform well in some classes in Table 3 and suggests that reasons should be analyzed and discussed. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in certain classes, as shown in Table 3. It suggests that the reasons for this performance discrepancy should be analyzed and discussed. This feedback is clear and actionable, as it directs the authors to provide a deeper understanding of the method\\'s limitations and potential areas for improvement. However, the comment could be more helpful if it offered specific guidance on how to analyze and discuss these reasons or provided examples of what kind of analysis might be beneficial. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the lack of discussion or explanation regarding the variation of model behavior under different datasets or settings. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to redesign the experimental settings and discuss the results more thoroughly, but without detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the lack of discussion or explanation regarding the variation of model behavior under different datasets or settings. However, it does not explicitly mention which part of the paper these issues pertain to, such as specific sections or experiments. The authors can infer that it relates to the experimental methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what needs to be improved. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. However, the comment lacks detailed reasoning or examples to support why this is an issue or how it could be improved. Additionally, the suggestion to discuss or explain the variation of model behavior under different datasets or settings is not substantiated with specific examples or references. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that MTT should be tested on unseen tasks to ensure rigor. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. This feedback is somewhat helpful as it points out a potential weakness in the experimental design and encourages the authors to provide more detailed analysis of their results. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to implement the suggested improvements. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the lack of discussion or explanation regarding the variation of model behavior under different datasets or settings. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to redesign the experimental settings and discuss the results more thoroughly, but without detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the lack of discussion or explanation regarding the variation of model behavior under different datasets or settings. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without clear grounding, the authors may struggle to pinpoint the exact sections that require revision. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. However, the comment lacks detailed reasoning or examples to support why this is an issue or how it could be improved. Additionally, the suggestion to discuss or explain the variation of model behavior under different datasets or settings is not substantiated with specific examples or references. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that MTT should be tested on unseen tasks to ensure rigor. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. This feedback is somewhat helpful as it points out a potential weakness in the experimental design and encourages the authors to provide more"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the data collection process for the 5 layouts, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue but are not given specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the data collection process for the 5 layouts, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure where the data collection process is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed regarding the data collection process. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the data collection process, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. While the comment highlights a potential issue, it does not provide any supporting evidence or references to substantiate the claim about learning effects. The reasoning is based on logical inference, but without specific examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the data collection process for the 5 layouts, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. This feedback is valuable as it prompts the authors to consider and address potential biases in their data collection process. However, the comment could be more helpful if it provided specific suggestions on how to randomize the data collection or discussed the implications of learning effects on the study\\'s validity. Overall, the comment is somewhat helpful as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about whether the data collection for the 5 layouts was randomized, suggesting that the data was collected in the same order, which could lead to learning effects across different layouts. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly revise their data collection process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the data collection process for the 5 layouts, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed regarding the data collection process. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the data collection process, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. While the comment highlights a potential issue, it does not provide any supporting evidence or references to substantiate the claim about learning effects. The reasoning is based on logical inference, but without specific examples or references, the claim remains somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the data collection process for the 5 layouts, specifically asking if it was randomized. It suggests that the data was collected in the same order, which could lead to learning effects across different layouts. This feedback is valuable as it prompts the authors to consider and address potential biases in their data collection process. However, the comment could be more helpful if it provided specific suggestions on how to randomize the data collection or"}
{"generated_text": "{'actionability_rationale': 'The review point questions the role of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a misunderstanding, an oversight, or a point that needs clarification. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence, \"In order to cover the random ordering of the atoms in a specific point in the composition space,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the role of node ordering in this context, providing clear guidance on what aspect of the paper needs clarification or further explanation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the role of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or references to justify why node ordering should not play a role. The comment lacks detailed explanation or examples that would help the authors understand the basis of the reviewer\\'s claim. As a result, the claim is unverifiable due to the absence of supporting information, making it difficult for the authors to address the concern effectively. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the role of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. While it identifies a potential area of confusion or misunderstanding, it does not provide any constructive feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or clarify the role of node ordering. As a result, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the novelty of their work. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, which is said to detract from the novelty of the current work. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the previous work affects the novelty or what specific aspects of the current work could be improved to address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. The reviewer supports this claim by providing references to the previous work, including links to specific papers and reviews. This provides a solid foundation for the claim, as it is based on external evidence and references. However, the comment could be strengthened by explaining how the previous work specifically detracts from the novelty of the current work or by providing more detailed comparisons. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the work by highlighting that a previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands. This observation is relevant as it could affect the perceived originality of the current work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. It lacks actionable feedback or detailed advice, leaving the authors with only a general understanding of the problem without clear steps to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point highlights a potential issue with the novelty of the work due to the presence of a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the novelty of their work. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, which is said to detract from the novelty of the current work. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the previous work affects the novelty or what specific aspects of the current work could be improved to address this issue. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. The reviewer supports this claim by providing references to the previous work, including links to specific papers and reviews. This provides a solid foundation for the claim, as it is based on external evidence and references. However, the comment could be strengthened by explaining how the previous work specifically detracts from the novelty of the current work or by providing more detailed comparisons. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a potential issue with the novelty of the work by pointing out that a previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands. This observation is relevant as it could affect the perceived originality of the current work. However, the comment does"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the selection of datasets should be made clearer, including specifying the pool of datasets and the selection process. It provides examples of works that have done this effectively, such as OpenML100 and OpenML CC-18 for classification, and references Bischl et al. and Gijsbers et al. for further guidance. Additionally, the comment points out that the selection of the splitting procedure and split ratios is ad-hoc and lacks detail. This feedback provides clear and concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of datasets as a main contribution, allowing the authors to accurately identify the part of the paper being addressed. It specifies the need for clarity in the selection process, including the pool of datasets and the selection criteria. The comment also provides specific examples of works (OpenML100 and OpenML CC-18) that have effectively addressed dataset selection, offering a clear direction for improvement. Additionally, it points out the ad-hoc nature of the splitting procedure and split ratios, suggesting that these aspects are not detailed. This level of detail and specificity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the selection of datasets is a main contribution and should be made clearer. It provides examples of works (OpenML100 and OpenML CC-18) that have effectively addressed dataset selection, offering a clear rationale for the claim. Additionally, it points out the ad-hoc nature of the splitting procedure and split ratios, suggesting that these aspects are not detailed. The inclusion of specific references and examples provides a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed guidance on how to improve the clarity of the selection process. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement by suggesting that the selection of datasets should be made clearer. It provides specific guidance on what aspects need to be addressed, such as specifying the pool of datasets and the selection process. The comment also offers examples of works that have effectively addressed dataset selection, such as OpenML100 and OpenML CC-18, which can serve as references for the authors. Additionally, it points out the ad-hoc nature of the splitting procedure and split ratios, suggesting that these aspects are not detailed. This feedback is clear, actionable, and provides the authors with concrete steps to improve their draft, making it highly helpful. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the ablation study should include a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. This provides a clear and direct action for the authors to take, specifying the type of baseline that should be included to provide a relevant comparison. The comment also suggests that comparing to a model initiated with random parameters is not a relevant benchmark, further guiding the authors on what to avoid. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline where an unconditional diffusion model is refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. The comment further suggests that comparing to a model initiated with random parameters is not a relevant benchmark, providing clear guidance on what is missing in the current study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison, specifically mentioning the need for a baseline where an unconditional diffusion model is refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. The comment suggests that this comparison would help determine if the proposed method outperforms conventional baselines under the same computational constraints. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this comparison and how it could be implemented, thus requiring more detailed justification or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the ablation study, specifically the lack of a baseline where an unconditional diffusion model is refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. This feedback is valuable as it highlights the importance of comparing the proposed method against conventional baselines to determine its effectiveness under the same computational constraints. The comment also points out that comparing to a model initiated with random parameters is not a relevant benchmark, providing clear guidance on what kind of comparison would be more meaningful. This feedback is actionable and offers a specific direction for improving the study, making it mostly helpful. However, it could be further improved by suggesting specific baselines or methods to consider, which would enhance its comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects to design more diverse tasks. While the comment implies that the authors should consider expanding the task variety, it does not provide specific guidance on which tasks to include or how to incorporate these tasks into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific tasks to consider and how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects to design more diverse tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide a specific suggestion for improvement by mentioning specific projects ([1] and [2]) that could be referenced for task design. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the tasks in the paper are too homogeneous in terms of difficulty and suggests referring to other projects to design more diverse tasks. However, the comment does not provide specific examples or detailed reasoning to support this claim. The suggestion to refer to projects [1] and [2] is not elaborated upon, leaving the authors without clear guidance on how to address the issue. The lack of detailed justification or examples makes the claim borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the homogeneity of the tasks in the paper, suggesting that they are all based on grasping and have similar difficulties. It provides a constructive suggestion by recommending the authors refer to other projects to design more diverse tasks. This feedback is actionable and offers a specific direction for expanding the task variety, which could enhance the paper\\'s scope and contribution. However, the comment could be more helpful if it included specific examples or references to the projects mentioned, which would provide even clearer guidance for the authors. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison in Table 2 is unfair due to differences in training data sizes between the LEPA and \"Without Plan/Without Self-Reflection\" settings. It suggests that the settings should be aligned with lines 349-360, referencing a specific work, LUMOS, to provide context. However, the comment does not explicitly instruct the authors to make this alignment or provide detailed guidance on how to achieve it. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparison and consider the referenced work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and references specific lines (349-360), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, noting that the LEPA\\'s training data is likely larger than the \"Without Plan/Without Self-Reflection\" settings if the settings are aligned with the mentioned lines. The comment further provides a reference to a specific work, LUMOS, which could be relevant to the discussion. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to differences in training data sizes between the LEPA and \"Without Plan/Without Self-Reflection\" settings. The reviewer provides a logical reasoning by suggesting that the settings should be aligned with lines 349-360, referencing a specific work, LUMOS, to support the claim. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison in Table 2, noting that the training data size for LEPA may be larger than the \"Without Plan/Without Self-Reflection\" settings if the settings are aligned with lines 349-360. It references a specific work, LUMOS, which could provide context for the comparison. This feedback is somewhat helpful as it points out a potential flaw in the experimental setup that could affect the validity of the results. However, it lacks detailed guidance on how to address this issue or suggestions for improving the fairness of the comparison. While it provides some insight into a potential problem, the comment could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies an issue with the fairness of the comparison in Table 2, noting that the training data size for LEPA may be larger than the \"Without Plan/Without Self-Reflection\" settings if the settings are aligned with lines 349-360. It references a specific work, LUMOS, which could provide context for the comparison. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to align the settings or adjust the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly adjust the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and references specific lines (349-360), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, noting that the training data size for LEPA may be larger than the \"Without Plan/Without Self-Reflection\" settings if the settings are aligned with the mentioned lines. The comment further provides a reference to a specific work, LUMOS, which could be relevant to the discussion. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to differences in training data sizes between LEPA and the \"Without Plan/Without Self-Reflection\" settings. The reviewer provides a logical reasoning by suggesting that the settings should be aligned with lines 349-360 and references a specific work, LUMOS, to support the claim. This reasoning is clear and provides a basis for the claim,"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results on real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. It provides explicit actions for the authors to take, such as using datasets from the GLUE benchmark and showing results on real-world diversity datasets. The comment is clear and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include results on real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the methodology section. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting particular datasets to use, but it lacks grounding as it does not explicitly mention the sections of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results on real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. The comment provides a logical reasoning by suggesting that using real datasets would enhance the validity and applicability of the findings. However, it lacks specific examples or references to support the claim that real datasets would be more beneficial or necessary. This makes the comment somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the authors have only used synthetic datasets and have not shown results on real datasets. It suggests using datasets from the GLUE benchmark, which includes tasks like QQP, and mentions real-world diversity datasets. This feedback is clear and actionable, as it provides specific examples of datasets that could be used to enhance the validity and applicability of the findings. By addressing this suggestion, the authors can significantly improve the robustness and generalizability of their results. However, the comment could be more helpful if it included additional guidance on how to integrate these datasets into the study or discussed the potential benefits of doing so. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be added, making it highly actionable. The authors know exactly what information is missing and how to address it, ensuring a clear path for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently missing. However, it does not specify which part of the paper should include these details, making it weakly grounded. The comment is specific in its request for additional information on the optimization process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks details on how to solve the optimization, which is an important piece of information. However, the comment does not provide any specific reasoning, examples, or references to support why this information is crucial or how its absence affects the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the optimization process. It suggests that adding information on how to solve the optimization would be beneficial, as this is an important aspect of the work. While the comment highlights a clear gap in the paper, it does not provide specific guidance or suggestions on how to address this issue. The authors are informed of the need for additional information but are not given detailed directions on how to incorporate it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper, highlighting that this information is currently missing. This direct request provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be added to improve their draft. The specificity of the feedback makes it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently missing. However, it does not specify which part of the paper should include these details, making it weakly grounded. The comment is specific in its request for additional information on the optimization process, but without clear grounding, the authors may struggle to identify where to incorporate this information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks details on how to solve the optimization, which is an important aspect of the work. However, the comment does not provide any specific reasoning, examples, or references to support why this information is crucial or how its absence affects the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the optimization process. It suggests that adding information on how to solve the optimization would be beneficial, as this is an important aspect of the work. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as which aspects of the optimization should be detailed or how to present this information effectively. While it points out a gap in the paper, it lacks actionable advice, making it somewhat helpful. The authors are informed of the need for additional information but are not given clear direction on how to improve their draft.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper, highlighting that this information is currently missing. This direct request provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be added to improve their draft. The specificity of the feedback makes it highly actionable, as the authors are given a direct path to enhance their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently missing. However, it does not specify which part of the paper should include these details, making it weakly grounded. The comment is specific in its request for additional information on the optimization process, but without clear grounding"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. The comment is clear and direct, leaving no ambiguity about what the authors should do to improve their draft. It provides a specific action\u2014adding these models to the evaluation\u2014and offers a rationale for why this inclusion would be beneficial. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in its request for a more comprehensive comparison, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. The claim is somewhat verifiable as it logically points out the potential benefits of including these models, but it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to further explore the rationale themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it directs the authors to consider expanding their evaluation to include these models, which could enhance the depth and relevance of their work. However, the comment could be more helpful if it provided additional context or reasoning on why these models are particularly relevant or how their inclusion would impact the study. Despite this, the feedback is mostly helpful as it offers a concrete suggestion for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include captions or descriptions along with OCR heavy datasets. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it highly actionable. The authors know exactly what changes to make to enhance their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including captions or descriptions along with OCR heavy datasets, which implies that it is related to a previous point. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for captions or descriptions and mentions OCR heavy datasets, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include captions or descriptions along with OCR heavy datasets. However, it does not provide any justification or reasoning for why this inclusion is necessary or how it would improve the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement by recommending the inclusion of captions or descriptions along with OCR heavy datasets. This feedback is clear and directly addresses a potential enhancement of the paper, offering the authors a concrete step to improve the clarity and completeness of their work. However, the comment could be more helpful if it explained why these additions are important or how they would benefit the paper. Despite this, the feedback is mostly helpful as it gives the authors a clear direction for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR is contradicted by the equation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this discrepancy or what changes, if any, are needed in their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the discrepancy between the assumption and the equation, indicating that the assumption about the loss of TKD being less than IYOR contradicts what is shown in Equation 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR is contradicted by the equation. This claim is somewhat verifiable as it points out a specific inconsistency between two parts of the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the equation contradicts the assumption. Providing more context or a clearer explanation would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR is contradicted by the equation. This feedback is somewhat helpful as it points out a potential inconsistency that the authors need to address. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might resolve this discrepancy or clarify the issue. To be more helpful, the comment could include suggestions for revising the assumptions or equations to align with the intended logic. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR contradicts what is shown in the equation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on whether the authors should revise the assumption, the equation, or both, or how to resolve the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the discrepancy between the assumption and the equation, indicating that the assumption about the loss of TKD being less than IYOR contradicts what is shown in Equation 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR contradicts what is shown in the equation. This claim is somewhat verifiable as it points out a specific inconsistency between two parts of the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the equation contradicts the assumption. Providing more context or a clearer explanation would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR is contradicted by the equation. This feedback is somewhat helpful as it points out a potential inconsistency that the authors need to address. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might resolve this discrepancy or clarify the"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether question 3, which is mentioned as a weakness, indicates other limitations. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this question needs to be addressed, clarified, or expanded upon in the paper. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"question 3\" and mentions weaknesses 2 and 4, which suggests it is addressing a specific part of the paper related to these weaknesses. However, it does not explicitly mention which section or part of the paper this question is discussing, making it weakly grounded. The comment is specific in that it questions whether question 3 indicates other limitations, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about whether question 3 indicates other limitations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether question 3, which is mentioned as a weakness, indicates other limitations. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing, or if there are specific actions the authors should consider to justify their choice. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where this choice is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the choice of layers but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why middle layers are more effective. Without specific examples or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. This feedback prompts the authors to reconsider their methodology and potentially justify their choice or explore alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be considered. While it identifies a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing or if there are specific actions the authors should consider to justify their choice. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the effectiveness of the chosen layers but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why middle layers are more effective. Without specific examples or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. This feedback prompts the authors to reconsider their methodology and potentially justify their choice or explore alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be considered. While it identifies a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, it does not provide any"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the motivation behind using GUE to determine modeling decisions for the generative model. It suggests that the use cases are poorly motivated and that the representations learned may lack generalizability. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve the motivation of their use cases. The feedback lacks specific suggestions or actionable steps, leaving the authors uncertain about how to enhance the motivation of their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two main issues: the motivation behind using GUE and the potential lack of generalizability in the representations learned. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in pointing out the potential incongruity in using GUE for modeling decisions and the lack of generalizability in the representations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the motivation behind using GUE to determine modeling decisions for a generative model. It claims that the use cases are poorly motivated and that the representations learned may lack generalizability due to the narrow set of tasks presented in GUE. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the critique. The lack of detailed justification or evidence results in the comment being classified as \"2: Borderline Verifiable,\" as it provides some reasoning but lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues: the lack of motivation behind using GUE for modeling decisions and the potential lack of generalizability in the representations learned. It raises a concern about the arbitrary nature of using GUE for these decisions and suggests that the representations may not be generalizable beyond the narrow set of tasks presented in GUE. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the motivation of their use cases. The feedback is somewhat helpful as it points out critical areas for consideration but does not provide detailed, actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the motivation behind using GUE to determine modeling decisions for a generative model and the potential lack of generalizability in the representations learned. However, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve the motivation of their use cases. The comment lacks actionable steps or detailed feedback, leaving the authors uncertain about how to enhance the motivation of their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two main issues: the motivation behind using GUE for modeling decisions and the potential lack of generalizability in the representations learned. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in pointing out the potential incongruity in using GUE and the lack of generalizability, but without clear references or detailed feedback, the authors may struggle to identify where these issues are most relevant in the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the motivation behind using GUE to determine modeling decisions for a generative model and the potential lack of generalizability in the representations learned. It suggests that the use cases are poorly motivated and that the representations may be optimized for a narrow set of tasks, which could limit their generalizability. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the critique. As a result, the claim is only borderline verifiable, as it provides some reasoning but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues: the lack of motivation behind using GUE to determine modeling decisions and the potential lack of generalizability in the representations learned. It raises a concern about the arbitrary nature of using GUE for these decisions and suggests that the representations may not be generalizable beyond the narrow set of tasks presented in GUE. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the motivation of their use cases. The feedback is somewhat helpful as it points out critical areas for improvement but"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper needs a major editing pass due to significant grammar and spelling errors. This provides a clear and direct action for the authors to take, which is to thoroughly edit the paper to improve its readability. The comment is specific in its request for a major editing effort, ensuring that the authors know exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights issues with the paper\\'s readability due to grammar and spelling errors, but it does not specify which parts of the paper contain these errors. This lack of explicit reference to specific sections or sentences makes it difficult for the authors to pinpoint where the issues lie. While the authors might have an idea of where the errors are, the comment lacks full grounding. It is specific in its critique of the paper\\'s readability but does not provide detailed guidance on how to address the issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper reads clunkily due to significant grammar and spelling errors, requiring a major editing pass. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of the errors, it is difficult for the authors to identify and address the issues effectively. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s readability due to grammar and spelling errors. It suggests that the paper requires a major editing pass to address these issues. While the comment highlights a critical area for improvement, it lacks specific examples or guidance on which parts of the paper are most affected or how to correct the errors. This limits the usefulness of the feedback, as the authors are left with a general direction but no detailed instructions on how to proceed. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the loss function being defined over minibatches and the potential issues with the objective function. While the comment highlights important areas for clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide more information or analysis regarding these topics, but the lack of specific guidance makes the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the loss function being defined over minibatches and the potential issues with the objective function. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these estimators and assumptions are discussed. The comment is specific in detailing what needs to be addressed, such as the assumptions and the implications of the objective function. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also raises concerns about the implications of the loss function being defined over minibatches and the potential issues with the objective function. While the questions are logical and seek further explanation, they do not contain subjective opinions or claims that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the loss function being defined over minibatches and the potential issues with the objective function. These questions are relevant and could help the authors clarify and strengthen their methodology. However, the comment does not provide specific suggestions or guidance on how to address these concerns, such as recommending additional analyses or experiments to verify the assumptions or the implications of the objective function. While it identifies critical areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises several questions about the consistency of the SITE estimator, the assumptions required for it to be a valid estimator of the causal effect, and the implications of the loss function being defined over minibatches. While the comment identifies important areas for clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The questions are more of an inquiry than a direct request for action, leaving the authors to infer that they need to provide more information or analysis. The lack of specific guidance makes the comment somewhat actionable, as the authors can deduce the need for additional explanation but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The review point raises several questions about the consistency of the SITE estimator, the assumptions required for it to be a valid estimator of the causal effect, and the implications of the loss function being defined over minibatches. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these estimators and assumptions are discussed. The questions are specific, as they pinpoint areas of potential confusion or lack of clarity. However, the comment lacks explicit grounding because it does not directly reference a specific part of the paper. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the loss function being defined over minibatches and the potential issues with the objective function. While the questions are logical and seek further explanation, they do not contain subjective opinions or claims that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implications of the loss function being defined over minibatches and the potential issues with the objective function. These questions are relevant"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation in the method, specifically the difficulty in shifting focus to a new target object if the target changes between clicks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method to overcome this limitation. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously, specifically addressing the issue of shifting focus to a new target object if the target changes between clicks. This provides a specific critique of the method\\'s limitations. However, the comment does not explicitly mention which part of the paper discusses OIS or interactive segmentation, making it weakly grounded. The authors can infer that it relates to sections discussing the method\\'s capabilities or limitations, but this inference is not direct. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It provides a logical reasoning by explaining that Object-level Understanding relies on Mask Guidance from previous interactions, which could lead to difficulties in shifting focus to a new target object if the target changes between clicks. This reasoning is supported by a reference to a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which likely provides additional context or evidence for the claim. However, the comment could be strengthened by including more detailed examples or further elaboration on how this limitation affects the method\\'s practical utility. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation in the method, specifically the difficulty in shifting focus to a new target object if the target changes between clicks. This is a relevant point that could impact the practical utility of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the method to overcome this limitation. While it identifies a significant area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation in the method, specifically the difficulty in shifting focus to a new target object if the target changes between clicks. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method to overcome this limitation. Without specific recommendations or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It provides a specific critique by explaining the potential limitation in the method, particularly the difficulty in shifting focus to a new target object if the target changes between clicks. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The authors might infer that it relates to sections discussing the method\\'s capabilities or limitations, but this inference is not direct. The comment is specific in detailing the potential limitation, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It provides a logical reasoning by explaining that Object-level Understanding relies on Mask Guidance from previous interactions, which could lead to difficulties in shifting focus to a new target object if the target changes between clicks. This reasoning is supported by a reference to a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which likely provides additional context or evidence for the claim. However, the comment could be strengthened by including more detailed examples or further elaboration on how this limitation affects the method\\'s practical utility. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It suggests that the knowledge of concepts implies a deep understanding of the domain. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, such as recommending ways to test or validate this assumption or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a specific example of anomaly detection systems used in intrusion and fraud detection, which helps ground the comment. However, it does not explicitly mention a specific section of the paper where this assumption is discussed, making it weakly grounded. The comment is specific in questioning the realism of the assumption and the implications of the knowledge of concepts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a specific example of anomaly detection systems used in intrusion and fraud detection to support the claim. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim about the assumption\\'s realism. While it provides a logical context, it does not offer specific examples or references to support the assertion, making it somewhat verifiable. The authors would need to further explore and address the question themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a relevant example of anomaly detection systems used in intrusion and fraud detection, which helps ground the critique. The comment highlights a potential gap in the paper\\'s assumptions and questions the practicality of the approach. However, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative assumptions. While it identifies a significant area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It suggests that the knowledge of concepts implies a deep understanding of the domain. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, such as recommending ways to test or validate this assumption or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a specific example of anomaly detection systems used in intrusion and fraud detection to support the critique. However, it does not explicitly mention a specific section of the paper where this assumption is discussed, making it weakly grounded. The comment is specific in questioning the assumption and its implications, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a relevant example of anomaly detection systems used in intrusion and fraud detection to support the claim. However, the comment lacks specific reasoning or evidence to fully substantiate the claim about the assumption\\'s realism. While it provides a logical context, it does not offer detailed justification or references to support the assertion, making it somewhat verifiable. The authors would need to further explore and address the question themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It provides a relevant example of anomaly detection systems used in intrusion and fraud detection to support the critique. This helps ground the comment and highlights a potential gap in the paper\\'s assumptions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the limitations and challenges of HLOP and the experimental design, which makes it difficult to assess the tradeoffs between using HLOP and other approaches. The reviewer explicitly suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. This feedback provides a clear and explicit action for the authors to take, namely to add a discussion on these topics. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the limitations and challenges of HLOP and the experimental design, which makes it difficult to assess the tradeoffs between using HLOP and other approaches. It suggests including a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment does not specify which part of the paper should include this discussion, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the discussion on limitations and potential downsides. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the limitations and challenges of HLOP and the experimental design, making it difficult to assess the tradeoffs between using HLOP and other approaches. The reviewer suggests including a discussion on the potential downsides of HLOP and the limitations of the evaluation process. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim or suggest how the authors might address these issues. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of discussion on the limitations and challenges of HLOP and the experimental design. This omission makes it difficult for readers to fully understand the tradeoffs between using HLOP and other approaches. The reviewer provides a clear and actionable suggestion by recommending that the authors include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and transparency of their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to address these issues. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, to enhance the contribution of their work. While the comment implies a specific action\u2014conducting evaluations on these models\u2014it does not provide detailed guidance on how to implement this evaluation or what specific aspects to focus on. The action is concrete but inferred, as the authors need to deduce the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, which are not studied in the current work. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or discussion of the proposed scheme, but this inference is not direct. The comment is specific in suggesting a potential improvement by evaluating on new language models, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, to enhance the contribution of their work. The claim is based on the observation that many new language models have been released since GPT-2, which have not been studied in the current work. However, the comment does not provide specific references or detailed reasoning to support why these models would be particularly relevant or how they would improve the contribution. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that many new language models have been released since GPT-2, which have not been studied in the current work. It suggests evaluating the effectiveness of the proposed gating scheme on these recently proposed language models, such as FlanT5 and/or Llama. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the contribution of their work by expanding their evaluation to include these new models. However, the comment could be more helpful if it included additional guidance on how to conduct these evaluations or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests evaluating the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, to enhance the contribution of the work. While the comment implies a specific action\u2014conducting evaluations on these models\u2014it does not provide detailed guidance on how to implement this evaluation or what specific aspects to focus on. The action is concrete but inferred, as the authors need to deduce the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, which are not studied in the current work. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or discussion of the proposed scheme, but this inference is not direct. The comment is specific in suggesting a potential improvement by evaluating on new language models, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and/or Llama, which have not been studied in the current work. The claim is based on the observation that many new language models have been released since GPT-2, which could enhance the contribution of the work by expanding its evaluation. However, the comment lacks specific reasoning or evidence to support why these particular models would be relevant or how they would improve the contribution. Without detailed justification or references, the claim remains somewhat verifiable, as the authors would need to further explore and substantiate the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that many new language models have been released since G"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should cite and compare their work with more recent works that might be highly correlated, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This provides a clear and concrete action for the authors to take, as they know exactly which work to consider and how to integrate it into their draft. The comment is explicit and provides specific guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare their work with more recent works, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This provides a specific example of a work that might be relevant to the proposed method. However, the comment does not explicitly mention which part of the paper should include this comparison, leaving the authors to infer that it relates to the discussion or literature review sections. While the authors can infer the relevant sections, the comment lacks full grounding. It is specific about the need for comparison but does not provide detailed guidance on how to integrate this work into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should cite and compare their work with more recent works, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This claim is somewhat verifiable as it provides a specific example of a relevant work that could be compared against. However, the comment lacks detailed reasoning or explanation on why this particular work is relevant or how it might impact the proposed method. Without further elaboration or justification, the authors may find it challenging to fully understand the importance of this comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should cite and compare their work with more recent works that might be highly correlated, specifically mentioning a particular work by Wang et al. This feedback is clear and actionable, as it provides a specific example of a relevant work that could be included in the literature review or discussion section. By doing so, the authors can enhance the context and relevance of their work, making it more comprehensive and impactful. However, the comment could be more helpful if it provided additional guidance on how to integrate this work into the paper or discussed the potential implications of this comparison. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder, or at least including a citation to the dictionary-based replacement strategy used. This feedback provides a clear and explicit action for the authors to take, either by adding more detail or a citation. The suggestion is concrete, as it specifies exactly what additional information or reference is needed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder or including a citation to the dictionary-based replacement strategy used. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional detail or a citation, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder or including a citation to the dictionary-based replacement strategy used. While the comment identifies a potential area for improvement, it does not provide specific reasoning or evidence to support why this addition is necessary or how it would enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion without sufficient support or explanation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder, or at least including a citation to the dictionary-based replacement strategy used. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of additional information or a citation. By addressing this point, the authors can enhance the clarity and comprehensiveness of their methodology section. However, the comment could be more helpful if it provided examples or further guidance on how to effectively incorporate this information. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. This is an explicit suggestion, as it directly instructs the authors to include a comparison in their experiments. However, the comment does not provide specific guidance on how to conduct this comparison or which particular methods should be considered. While the action is clear, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting a comparison with pre-trained models, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. However, the comment does not provide any specific examples or references to these methods, nor does it explain why such comparisons are necessary or how they would benefit the paper. This lack of detailed justification or examples makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental evaluation by including a comparison with relevant existing methods. However, the comment could be more helpful if it included specific examples of these methods or explained why such comparisons are important. Despite this, the suggestion is valuable and offers a concrete step for the authors to improve their draft, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. This is an explicit suggestion, as it directly instructs the authors to include a comparison in their experiments. However, the comment does not provide specific guidance on how to conduct this comparison or which particular methods should be considered. While the action is clear, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting a comparison with pre-trained models but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. However, the comment does not provide specific examples or references to these methods, nor does it explain why such comparisons are necessary or how they would benefit the paper. This lack of detailed justification or examples makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their method with other state-of-the-art (SOTA) code summarization methods, such as those involving pre-trained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental evaluation by including a comparison with relevant existing methods. However, the comment could be more helpful if it included specific examples of these methods or explained why such comparisons are important. Despite this, the suggestion is"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistical significance of the results in Table 3, specifically regarding the comparison between Scheduled Bernoulli and AttendOut. It asks for an explanation of why AttendOut has lower variance and seeks the statistical significance value of the comparison. While the comment implies that the authors should provide additional statistical analysis or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical significance values or explanations in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the statistical significance of the results, specifically why AttendOut has lower variance and seeks the statistical significance value when comparing Scheduled Bernoulli and AttendOut. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the results presented in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the presentation of results in Table 3, noting that the result of Scheduled Bernoulli on RTE is even better than AttendOut. It raises two important questions: the reason for the lower variance in AttendOut and the statistical significance value when comparing Scheduled Bernoulli and AttendOut. These questions prompt the authors to provide additional context and analysis that can enhance the clarity and robustness of their results. However, the comment could be more helpful if it suggested specific methods or analyses to address these questions. Overall, the feedback is somewhat helpful as it directs the authors to a critical area needing clarification but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the prediction lengths used in the experimental results do not accurately reflect the \"long-term\" setting. It recommends following the same settings as the original dataset, specifically mentioning {96, 192, 336, 720}. This feedback provides a clear and concrete action for the authors to take, which is to adjust the prediction lengths to align with the suggested settings. The comment is explicit and provides specific guidance on how to implement the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the specific prediction lengths used, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the prediction lengths used in the experimental results and suggests following the same settings as the original dataset. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction lengths used in the experimental results do not accurately reflect the \"long-term\" setting, suggesting that they should follow the same settings as the original dataset. However, the comment lacks specific reasoning or evidence to support why the current prediction lengths are insufficient for a \"long-term\" setting. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the prediction lengths used do not accurately reflect the \"long-term\" setting. It suggests following the same settings as the original dataset, which is a clear and actionable recommendation. This feedback provides the authors with a concrete way to improve the consistency and validity of their experimental setup, making it highly helpful. The comment is detailed and constructive, offering a specific direction for enhancing the robustness of the experimental results. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out an issue with the difference between confidence and accuracy for a single sample when used in a specific equation. However, it does not provide any guidance on how to address this issue or suggest potential solutions. The authors are left without any explicit or implicit actions to take, making it difficult for them to know how to improve their draft. Without actionable advice or suggestions, the comment remains unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights an issue with the difference between confidence and accuracy for a single sample when used in a specific equation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this equation is used, the comment lacks full grounding. It is specific about the issue of unreasonable difference but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for a single sample is unreasonable when used in a specific equation. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the difference between confidence and accuracy for a single sample when used in a particular equation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It implicitly suggests that the authors consider adopting a method to account for the shift. However, the comment does not provide explicit guidance on how to implement this suggestion or which method might be suitable. The action is inferred and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the calculation of divergence between a sample and the data, mentioning the use of the residual approach. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the concern about the approach's potential failure when the sample is shifted from the data distribution and suggests considering a method to account for the shift. This provides some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the approach used to calculate divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. The comment suggests considering a method to account for the shift. However, the claim lacks specific examples, references, or detailed reasoning to support the assertion that the current approach might fail in certain settings. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It raises a pertinent question about whether the method can be adapted to account for such shifts. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or adapt their method. The feedback is somewhat helpful as it prompts the authors to consider an important aspect of their methodology, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential limitation in the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It raises a question about whether the method can be adapted to account for the shift. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is inferred and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the calculation of divergence between a sample and the data, noting that the approach may fail when the sample is shifted from the data distribution. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide a specific question about adapting the method to account for the shift, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. The comment suggests considering a method to account for the shift, but it does not provide specific examples, references, or detailed reasoning to support the claim that the current approach might fail. This lack of supporting evidence makes the claim somewhat verifiable, as it requires more detailed justification or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the approach used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It raises a pertinent question about whether the method can be adapted to account for such shifts. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or adapt their method. The feedback prompts the authors to consider an important aspect of their methodology, but it could be more helpful with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the context-independent replacement of words, specifically asking if it leads to incoherent text. It suggests that replacing entire phrases might be preferable to independent words. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to make a change or provide concrete guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of context-independent word replacement and consider alternative approaches. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the context-independent replacement of words and suggests that replacing entire phrases might be preferable to independent words. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and an assumption about the potential issue with context-independent word replacement. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the context-independent replacement of words, specifically asking if it leads to incoherent text. It suggests that replacing entire phrases might be preferable to independent words. This feedback is somewhat helpful as it identifies a potential issue with the text's coherence and provides a suggestion for improvement. However, the comment lacks depth and does not offer specific guidance or examples on how to address the issue. While it prompts the authors to consider the implications of their word replacement strategy, it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods. While the action is explicit, it lacks concrete details on how to conduct this comparison or which specific methods should be included. The authors are given a clear direction to add a runtime comparison, but without additional guidance on execution, the comment remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis where runtime comparisons could be added. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods. However, it does not provide any justification or reasoning for why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a specific and actionable piece of feedback. This suggestion could help the authors provide a more comprehensive evaluation of their work by comparing it with other methods in terms of computational efficiency. However, the comment lacks depth and does not provide specific guidance on how to conduct the comparison or which methods should be included. While it offers a clear direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods. While the action is explicit, it lacks concrete details on how to conduct the comparison or which specific methods should be included. The authors are given a clear direction to add a runtime comparison, but without additional guidance, the comment remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis where such a comparison could be added. Without explicit references to specific parts of the paper, the authors may find it challenging to determine where to incorporate this suggestion. The lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods. However, it does not provide any justification or reasoning for why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a specific and actionable piece of feedback. This suggestion could help the authors provide a more comprehensive evaluation of their work by comparing it with other methods in terms of computational efficiency. However, the comment lacks depth and does not provide specific guidance on how to conduct the comparison or which methods should be included. While it offers a clear direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, it is rated as mostly helpful, consistent with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a specific and actionable piece of feedback. However, it does not provide detailed guidance on how to conduct this comparison or which specific methods should be included. While the suggestion is clear, the lack of detailed instructions makes it somewhat actionable. The authors are given a direction to improve their draft, but the comment could be more helpful with additional guidance on execution. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods, which is a specific suggestion for improvement. However"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by comparing and exploring ECG-specific architectures that use SSL or transformer-based approaches. The comment provides a clear and explicit action for the authors to take, which is to compare and explore these architectures. However, it does not specify which ECG-specific architectures should be considered or how to implement the comparison. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the ECG encoder, suggesting that it could be improved by comparing and exploring ECG-specific architectures using SSL or transformer-based approaches. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder, which uses only 1-D CNN layers and average pooling, could be improved by comparing and exploring ECG-specific architectures using SSL or transformer-based approaches. The claim is somewhat verifiable as it provides a logical reasoning that more advanced architectures could enhance the ECG encoder. However, it lacks specific examples or references to these architectures, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the MEIT framework, namely the ECG encoder, which currently uses only 1-D CNN layers and average pooling. It suggests that the authors should compare and explore ECG-specific architectures using SSL or transformer-based approaches, similar to how different methods were explored for the other parts of the framework. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. By suggesting a specific comparison and exploration, the comment offers valuable guidance that can lead to significant improvements in the paper's methodology and results. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\", 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by comparing and exploring ECG-specific architectures using SSL or transformer-based approaches. While the comment provides a clear direction for improvement, it lacks specific guidance on which ECG-specific architectures to consider or how to implement the comparison. The action is explicit but somewhat vague, as the authors know they need to explore additional architectures but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the ECG encoder, suggesting that it could be improved by comparing and exploring ECG-specific architectures using SSL or transformer-based approaches. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder, which uses only 1-D CNN layers and average pooling, could be improved by comparing and exploring ECG-specific architectures using SSL or transformer-based approaches. The claim is somewhat verifiable as it provides a logical reasoning that more advanced architectures could enhance the ECG encoder. However, it lacks specific examples or references to these architectures, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the MEIT framework, namely the ECG encoder, which currently uses only 1-D CNN layers and average pooling. It suggests that the authors should compare and explore ECG-specific architectures using SSL or transformer-based approaches, similar to how different methods were explored for the other parts of the framework. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. By suggesting a specific comparison and exploration, the comment offers valuable guidance that can lead to significant improvements in the paper's methodology and results. Therefore, the comment is highly helpful, consistent with a score of 5.\", 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase the abstract to accurately reflect the focus on explainability rather than defense methodology. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the draft. The feedback is concrete, as it clearly identifies the issue and offers a specific solution, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inaccuracy in the abstract regarding the focus on a defense methodology versus a model-agnostic explainability technique. The comment provides clear guidance on how to correct the abstract to accurately reflect the paper\\'s focus. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed, instead highlighting the focus on a model-agnostic explainability technique for deep neural networks. The reviewer suggests rephrasing the abstract to accurately reflect this focus. While the comment provides a logical reasoning for the correction, it lacks specific examples or references to support the claim that the abstract is misleading. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue without additional guidance or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the abstract by accurately reflecting the focus of the paper, which is a model-agnostic explainability technique for deep neural networks rather than a defense methodology. This feedback is valuable as it helps the authors correct a potential misrepresentation in their abstract, ensuring that readers understand the true focus of their work. By addressing this issue, the authors can enhance the clarity and accuracy of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It explicitly suggests including comparisons to specific methods like FINER, Incode, and SL2A-INR. This feedback provides a clear and direct action for the authors to take, specifying which methods should be considered for comparison. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It mentions specific methods like FINER, Incode, and SL2A-INR, which provides some grounding as the authors can infer that these are the methods being referred to. However, the comment does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for comparisons to these particular methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It specifically mentions three methods: FINER, Incode, and SL2A-INR. This claim is somewhat verifiable as it provides a clear rationale for the need for comparison by referencing specific methods. However, the comment could be strengthened by providing more detailed information about how these methods differ or why they are relevant to the paper\\'s context. As it stands, the claim is supported by specific examples but lacks comprehensive justification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s evaluation, noting that it lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides specific examples of such methods, including FINER, Incode, and SL2A-INR, which the authors could consider for comparison. This feedback is clear and actionable, offering the authors a concrete direction to enhance the comprehensiveness and relevance of their work. By addressing this point, the authors can improve the depth and impact of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a gap in the paper by pointing out the lack of comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It specifically mentions three methods: FINER, Incode, and SL2A-INR. This feedback provides a clear and explicit action for the authors to take, which is to include comparisons to these methods. The suggestion is concrete, as it specifies the methods that should be considered for comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a gap in the paper by pointing out the lack of comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It specifically mentions three methods: FINER, Incode, and SL2A-INR, which provides some grounding for the authors to understand the context of the feedback. However, the comment does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for comparisons to these particular methods. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It specifically mentions three methods: FINER, Incode, and SL2A-INR. This claim is somewhat verifiable as it provides specific examples of methods that could be compared, which helps to substantiate the need for additional comparisons. However, the comment could be strengthened by providing more detailed information about how these methods differ or why they are relevant to the paper\\'s context. As it stands, the claim is supported by specific examples but lacks comprehensive justification, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the lack of comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides specific examples of such methods, including FINER, Incode, and SL"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a straightforward method, such as the one referenced in the comment, works well in practice and challenges the value of research on length extrapolation, particularly when models are finetuned. It implies that the evaluation setting could be improved. However, the comment does not provide specific guidance on how to improve the evaluation setting or what aspects should be considered for improvement. The action is implicit and vague, leaving the authors uncertain about how to address the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a straightforward method, such as the one referenced in the comment, works well in practice and challenges the value of research on length extrapolation, particularly when models are finetuned. However, it does not specify which part of the paper this evaluation setting should be improved upon, nor does it provide details on how to improve it. The authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity regarding the improvement needed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, particularly when models are finetuned. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that a straightforward method, such as the one referenced in the comment, works well in practice and challenges the value of research on length extrapolation, particularly when models are finetuned. It implies that the evaluation setting could be improved. However, the comment lacks specificity and does not provide actionable guidance on how to improve the evaluation setting or what specific aspects should be considered. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the training and testing environments of the autoencoder, specifically asking which environment is used for training and which for testing. It also suggests that a cross-validation approach might be preferable to demonstrate the robustness of the results. While the comment implies that the authors should clarify their methodology and consider cross-validation, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the training and testing environments of the autoencoder, suggesting that a cross-validation approach might be preferable to demonstrate the robustness of the results. This provides clear guidance on what aspect of the methodology needs clarification or improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments of the autoencoder, suggesting that a cross-validation approach might be preferable to demonstrate the robustness of the results. While the comment identifies a potential issue, it does not provide specific reasoning or evidence to support why cross-validation is necessary or how it would improve the results. The suggestion is based on logical reasoning but lacks detailed justification or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology described in Section 2.4, where the autoencoder is trained on one environment and tested on others. It raises a question about which environment is used for training and which for testing, suggesting that a cross-validation approach might be preferable. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and consider a cross-validation approach to demonstrate the robustness of their results. By addressing this point, the authors can enhance the rigor and validity of their experimental setup. However, the comment could be more helpful if it provided additional guidance on how to implement cross-validation or discussed its potential benefits in more detail. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the statistic on the number of refinements but points out that this only confirms the change rather than proving an improvement. While the comment identifies an area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific metrics or methods should be used. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison to show the improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the statistic on the number of refinements but points out that this only confirms the change rather than proving an improvement. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a comparison to show improvement, but without clear grounding, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. The comment acknowledges the statistic on the number of refinements but argues that this only confirms the change rather than proving an improvement. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the specific aspects that need to be addressed or improved, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by pointing out the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the statistic on the number of refinements but notes that this only confirms the change rather than proving an improvement. This feedback is clear and actionable, as it directs the authors to include a comparison that would substantiate the claim of improvement. However, the comment could be more helpful if it provided suggestions on how to conduct this comparison or what specific metrics or methods should be used. Overall, the comment is mostly helpful as it highlights a critical area for enhancement and provides some direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions: one asking about the missing threshold in the context of \"with... PMI\" and the other questioning whether the partitions were done randomly. These questions imply that the authors should provide additional information or clarification regarding these aspects. However, the comment does not explicitly instruct the authors to add this information or suggest how to address the issue. The actions are implicit and somewhat vague, as the authors need to infer what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers, \"336\" and \"371,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the missing threshold in the context of \"with... PMI\" and whether the partitions were done randomly. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions asking for clarification about the missing threshold in the context of \"with... PMI\" and whether the partitions were done randomly. These are requests for additional information and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, they are factual statements and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions, one asking about the missing threshold in the context of \"with... PMI\" and the other questioning whether the partitions were done randomly. While these questions highlight potential areas of confusion or missing information, they do not provide any constructive feedback or suggestions for improvement. The authors are left with questions but no guidance on how to address them or why these issues are important. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-tuning. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is clear but stated indirectly, making the comment mostly actionable. The authors know they need to provide the requested comparison but may not be entirely sure of the exact format or details to include.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-turning. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where these comparisons might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a comparison, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for additional information about the training time of the MDP and a suggestion to provide a comparison with ImageNet pretraining and individual dataset fine-turning. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-turning. This feedback is somewhat helpful as it identifies a specific area where the authors could enhance their paper by including additional data or analysis. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to conduct this comparison or why it is important. To be more helpful, the comment could include specific aspects of the training time or comparison that should be highlighted or why this information is crucial for the paper. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the author\\'s claim about the design of G-PDE and the actual structure of the model, which is an incremental improvement over GraphCON[1]. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE and its relationship to spike ODE and graph ODE. It references a specific structure, \"GraphCON[1],\" which provides some grounding for the authors to identify the part of the paper being discussed. However, the comment does not specify which section or part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the discrepancy between the claim and the actual structure of G-PDE. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE. It provides a counterpoint by noting that the fundamental structure of G-PDE is an incremental improvement over GraphCON[1], where the static encoder is substituted by SNN. This reasoning is based on a specific comparison with GraphCON[1], which provides a logical basis for the claim. However, the comment could be strengthened by referencing specific aspects of the structure or providing more detailed comparisons. As it stands, the claim is mostly verifiable, as it offers a reasonable basis for questioning the claim but lacks comprehensive evidence or detailed references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific claim made by the authors regarding the design of G-PDE, suggesting that it is an incremental improvement over GraphCON[1]. The comment points out that the static encoder in GraphCON[1] is replaced by SNN in G-PDE, which challenges the authors\\' assertion about the intentional design. While the comment identifies a potential discrepancy, it does not provide actionable feedback or suggestions for how the authors might address this issue or clarify their claims. The lack of guidance or constructive advice limits the comment\\'s usefulness to the authors, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point questions the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, suggesting that it is an incremental improvement over GraphCON[1]. However, it does not provide any explicit or implicit suggestions for the authors to address this issue or improve their draft. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE and its relationship to spike ODE and graph ODE. It references a specific structure, \"GraphCON[1],\" which provides some grounding for the authors to identify the part of the paper being discussed. However, the comment does not specify which section or part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the discrepancy between the claim and the actual structure of G-PDE, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE. It provides a counterpoint by noting that the fundamental structure of G-PDE is an incremental improvement over GraphCON[1], where the static encoder is substituted by SNN. This reasoning is based on a specific comparison with GraphCON[1], which provides a logical basis for the claim. However, the comment could be strengthened by referencing specific aspects of the structure or providing more detailed comparisons. As it stands, the claim is mostly verifiable, as it offers a reasonable basis for questioning the claim but lacks comprehensive evidence or detailed references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a significant issue with the proposed method's performance, noting that it does not outperform Jiang et al. significantly in several metrics. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their method's performance. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the method's effectiveness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific metrics and percentages, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the proposed method does not outperform Jiang et al. significantly in several metrics, such as Penetration(Dep), CR, and Sim-Disp(Mean). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform Jiang et al. significantly, providing specific metrics to support this claim. The comment includes percentages and values from the paper, such as \"In Penetration(Dep), In CR, Ours(100.00%) only outperforms Jiang et al.(99.97%) for 0.03%,\" and \"In Sim-Disp(Mean), Ours(1.74) is even worse than Jiang et al.(1.52),\" which provide a clear and detailed comparison. This level of specificity and precision in the data makes the claim fully verifiable, as it allows the authors to understand the basis of the critique and address it effectively. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a significant issue with the proposed method's performance, noting that it does not outperform Jiang et al. significantly in several metrics. It provides specific examples, such as the percentage difference in Penetration(Dep) and CR, and the actual values in Sim-Disp(Mean), which highlight the gap between the proposed method and the baseline. This feedback is clear and actionable, as it directs the authors to address the performance gap and potentially improve their method's effectiveness. However, the comment could be more helpful if it offered suggestions on how to enhance the method's performance or provided insights into why the current approach is not yielding better results. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides some context, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises two separate issues. First, it suggests that the term 'vFSAD' refers to OOD detection in time-series data and mentions a specific work (Kaur et al.) that has not been compared or mentioned. This part of the comment provides a specific example of a related work that should be considered, making it mostly actionable. Second, it critiques the related work subtitles of 'Policy' and 'Evaluation tasks' as not descriptive and seemingly unrelated to the actual content. However, this part of the comment does not provide specific guidance on how to improve these subtitles or what they should include. Overall, the comment provides some actionable feedback but lacks detailed instructions for the second part, making it mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions the term \"vFSAD\" and provides a specific example of related work (Kaur et al.), which helps the authors identify the part of the paper being addressed. However, it does not specify which section or part of the paper discusses \"vFSAD\" or the related work subtitles, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the related work subtitles, providing clear guidance on what is missing or unclear. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes two claims. First, it suggests that the term \"vFSAD\" refers to OOD detection in time-series data and mentions a specific work (Kaur et al.) that has not been compared or mentioned. This claim is somewhat verifiable as it provides a specific example of related work, but it lacks detailed reasoning or evidence to fully substantiate the claim about the term \"vFSAD.\" Second, the comment critiques the related work subtitles of \"Policy\" and \"Evaluation tasks\" as not descriptive and seemingly unrelated to the actual content. This claim is somewhat verifiable as it highlights a potential issue with the organization of the related work section, but it does not provide specific examples or suggestions for improvement. Overall, the review point provides some support for its claims but lacks comprehensive justification, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides two distinct pieces of feedback. First, it clarifies the term 'vFSAD' as referring to OOD detection in time-series data and mentions a specific work (Kaur et al.) that has not been compared or mentioned. This is a valuable observation that could help the authors situate their work within the existing literature. Second, the comment critiques the related work subtitles of 'Policy' and 'Evaluation tasks' as not descriptive and seemingly unrelated to the actual content. This feedback highlights a potential issue with the organization and clarity of the related work section, prompting the authors to reconsider the structure and content of these sections. While the comment provides some actionable insights, it could be more helpful if it offered specific suggestions on how to improve the related work section. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study should be added to justify the selection of memory size. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to address the ambiguity in the effect of memory size. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an ablation study to justify the selection of memory size, indicating that the effect of memory size is ambiguous. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where the memory size is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting a particular type of study (ablation study) to address the ambiguity in memory size. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific reasoning or evidence to support why the effect of memory size is ambiguous or how an ablation study would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting the addition of an ablation study to justify the selection of memory size. This feedback is clear and actionable, providing the authors with a concrete step to enhance the rigor and justification of their work. By addressing this point, the authors can strengthen their argument and provide a more comprehensive understanding of the impact of memory size on their results. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the use of the abbreviation \"GNN\" in the paper. It notes that the abbreviation appears on page 1 without a full definition, while the full definition is given later in Section 2. This comment implies that the authors should ensure consistency in the use of abbreviations by providing the full definition earlier in the paper. While the action is implicit, it is clear and concrete, as it specifies the need for consistency in abbreviation usage. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific location of the abbreviation \"GNN\" on page 1 and its full definition on page 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency in the use of abbreviations and the need for consistency in providing full definitions. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the use of abbreviations in the paper, noting that the abbreviation \"GNN\" appears on page 1 without a full definition, while the full definition is given later in Section 2. This observation is factual and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, noting that the abbreviation \"GNN\" appears on page 1 without a full definition, while the full definition is given later in Section 2. This feedback is clear and actionable, as it points out a potential inconsistency that the authors can address to improve the clarity and readability of their manuscript. By correcting this issue, the authors can enhance the overall quality of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to handle abbreviations consistently throughout the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue, such as suggesting improvements to the baseline methods or the loss function. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of baseline methods on the DAVIS dataset, comparing it with state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms. However, the comment does not specify which part of the paper discusses the baseline methods or the proposed loss function, making it weakly grounded. The comment is specific in detailing the issue with the performance comparison and the effectiveness of the loss function, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low, comparing with state-of-the-art results. It further questions the effectiveness of the proposed loss function on top-performing algorithms. The comment provides a specific reference to a state-of-the-art result, which supports the claim about the low performance of baseline methods. However, it lacks detailed reasoning or examples to fully substantiate the claim about the loss function\\'s effectiveness. While the reference provides some support, the comment could be strengthened with more detailed analysis or comparisons. Therefore, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms, suggesting that the performance on the baseline methods may not guarantee effectiveness on more advanced algorithms. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might improve the performance of their baseline methods or the effectiveness of their loss function. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of baseline methods on the DAVIS dataset, comparing it with state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. While it provides some context and references, it lacks detailed guidance on how to address the issues raised. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is rather low, comparing with state-of-the-art results. It further questions the effectiveness of the proposed loss function on top-performing algorithms. The comment provides a specific reference to a state-of-the-art result, which supports the claim about the low performance of baseline methods. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the loss function\\'s effectiveness. While the reference provides some support, the comment could be strengthened with more detailed analysis or comparisons. Therefore, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It also questions the effectiveness of the proposed loss function on top-performing algorithms, suggesting that the performance on the baseline methods may not guarantee effectiveness on more advanced algorithms"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the results for the proposed two-step decoding method, asking if they are reported in the paper and whether the results in Table 1 with decoder downsampling were obtained with or without the two-step method. The reviewer also inquires about the performance of the two-step method if it was not used. While the comment highlights a potential gap in the paper, it does not provide explicit instructions or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should clarify the results for the two-step method, and it is somewhat vague because it does not specify how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific question about the results for the proposed two-step decoding method, asking if they are reported in the paper and whether the results in Table 1 with decoder downsampling were obtained with or without the two-step method. This question highlights a potential gap in the paper regarding the presentation of results for the two-step method. However, the comment does not explicitly mention which part of the paper should address this issue, such as the results section or specific tables. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing what needs to be clarified. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the results for the proposed two-step decoding method. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the results for the proposed two-step decoding method, asking if they are reported in the paper and whether the results in Table 1 with decoder downsampling were obtained with or without the two-step method. It also inquires about the performance of the two-step method if it was not used. This feedback is somewhat helpful as it identifies a potential gap in the paper regarding the presentation and discussion of results. However, it lacks depth and does not provide suggestions on how the authors might address this issue or improve the clarity of their results section. While it prompts the authors to clarify their results, it does not offer actionable guidance on how to enhance the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to enhance the quality of their draft. The comment provides specific guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the font size in the figures, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely increasing the font size to improve readability. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a specific change to improve readability, specifically increasing the font size in figures. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the readability of the figures by increasing the font size. This feedback is clear and directly addresses a potential issue that could hinder the understanding of the figures by the readers. By following this advice, the authors can enhance the accessibility and clarity of their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or if it mentioned other aspects of figure presentation that could be improved. Overall, the comment is mostly helpful as it offers a concrete step for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that only synthetic problems are considered in the experiments. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion to include real-world problems, conduct additional experiments, or address any specific issues related to the synthetic problems used. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that only synthetic problems are considered in the experiments, but it does not specify which part of the paper this observation is based on. The authors cannot confidently determine which sections, tables, or figures are being referred to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on why synthetic problems are insufficient or how the authors could address this limitation. Therefore, this comment is weakly grounded and not specific, aligning with label 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that only synthetic problems are considered in the experiments. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts the validity of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the experimental setup, noting that only synthetic problems are considered. While it identifies a specific area that may need further exploration, it lacks depth and does not provide suggestions or guidance on how the authors might address this limitation. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This feedback provides a clear and direct action for the authors to take, specifying exactly what additional comparisons are needed to improve their draft. The comment is concrete, as it clearly outlines the action and its purpose, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of NLE (Natural Language Explanations) baselines in the comparison section, noting that the authors only compared to feature attribution type of explanations. It suggests that the explainer, which generates natural language explanations, should be compared with other NLE interpretability tools. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the comparison or evaluation section. The suggestion is specific, as it clearly identifies what needs to be addressed by including comparisons with other NLE interpretability tools. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. However, the comment does not provide any specific examples or references to these NLE interpretability tools, nor does it explain why such comparisons are necessary or how they would benefit the paper. This lack of detailed justification or examples makes the claim difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of comparisons with NLE (Natural Language Explanations) baselines. It highlights that the authors have only compared their explainer, which generates natural language explanations, with feature attribution type of explanations. The comment suggests that the authors should include comparisons with other NLE interpretability tools to provide a more comprehensive evaluation of their method. This feedback is clear and actionable, as it directs the authors to a specific area for improvement that can enhance the validity and relevance of their work. However, the comment could be more helpful if it provided examples of NLE interpretability tools or suggested specific metrics for comparison. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the use of Eq. (5), noting that it only considers one pertinent positive data point while many data points satisfy Eq. (1) and Eq. (2). It highlights that these data points contribute equally to Eq. (3) but have different perturbation directions. The comment suggests that Eq. (5) does not account for the diversity of all these data points. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the analysis. The feedback is somewhat actionable as it identifies a potential weakness but lacks detailed instructions on how to rectify it. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5)\" and references \"Eq. (1) and Eq. (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with Eq. (5), noting that it only uses one pertinent positive data point while many data points satisfy Eq. (1) and Eq. (2). The comment further specifies that these data points contribute equally to Eq. (3) but have different perturbation directions, and that Eq. (5) does not account for the diversity of all these data points. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Eq. (5) only uses one pertinent positive data point, while many data points satisfy Eq. (1) and Eq. (2). It further states that these data points contribute equally to Eq. (3) but have different perturbation directions, and that Eq. (5) does not account for the diversity of all these data points. While the comment identifies a potential issue with the analysis, it lacks specific examples or references to support the claim that these data points are not being fully utilized. The reasoning is somewhat verifiable, as it highlights a potential limitation, but it could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, noting that Eq. (5) only uses one pertinent positive data point while many data points satisfy Eq. (1) and Eq. (2). It highlights that these data points contribute equally to Eq. (3) but have different perturbation directions, and that Eq. (5) does not account for the diversity of all these data points. This feedback is clear and actionable, as it points out a limitation in the analysis and suggests that the authors should consider a more comprehensive test of the data points to account for their diversity. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to incorporate the diversity of data points into the analysis. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how document augmentation can enhance the performance of existing supervised retrievers, even when using the supervision data. It implies that the authors should compare the performance of their method with and without augmented queries or documents. While the comment provides a clear direction for improvement, it does not specify how to conduct these comparisons or what specific metrics to use. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison of results without using supervision data, which allows the authors to identify the specific part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely to demonstrate how document augmentation can enhance the performance of existing supervised retrievers. The comment specifies the need to show the additional performance boost from augmented queries or documents, or both, which provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results should be compared with existing supervised retrievers to demonstrate the additional performance boost from document augmentation. The claim is somewhat verifiable as it provides a logical reasoning for why such a comparison would be beneficial. However, it lacks specific examples or references to existing supervised retrievers or detailed explanations of how the augmentation could enhance performance. This makes it challenging for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the paper by recommending a comparison of the results with existing supervised retrievers. It highlights the importance of demonstrating how document augmentation can enhance the performance of existing supervised retrievers, even when using supervision data. This feedback is valuable as it offers a specific direction for expanding the analysis and showing the potential benefits of the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to conduct this comparison or what metrics to focus on. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the paper's contribution and impact.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied, the data they might share, and so on. It highlights a contradiction between the initial hierarchy claim and the lack of discussion on how the individual levels are applied together. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to discuss the cache hierarchy and its application, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"cache hierarchy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of discussion on the order in which the three dimensions are applied, the data they might share, and the contradiction with the initial hierarchy claim. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically mentioning the lack of information on the order in which the three dimensions are applied and the data they might share. The comment highlights a contradiction with the initial hierarchy claim, noting that the individual levels are discussed in detail but not how they are applied together. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim fully. The reasoning is somewhat verifiable, as it points out a potential inconsistency, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper regarding the discussion of the cache hierarchy. It points out that the order in which the three dimensions are applied, the data they might share, and other aspects of the hierarchy are not discussed. This is a critical omission, as understanding the cache hierarchy is essential for comprehending the paper's methodology and contributions. The comment also highlights a contradiction with the initial hierarchy claim, noting that the individual levels are discussed in detail but not how they are applied together. This feedback is clear and actionable, as it directs the authors to address a crucial oversight in their paper. However, it could be more helpful if it provided suggestions on how to integrate this discussion into the paper. Overall, the comment is mostly helpful, as it effectively guides the authors to improve their draft by addressing a significant gap in the content.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the management of GPU memory during pretraining, specifically regarding the forward and backward propagation. It asks how the authors managed to prevent out-of-memory (OOM) issues when forward propagation is performed 3 times before 1 backprop. While the question implies that the authors should provide an explanation or justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the authors managed their GPU memory to prevent out-of-memory (OOM) issues during pretraining, given the forward propagation requirement. This provides clear guidance on what aspect of the methodology needs clarification. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the management of GPU memory during pretraining. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the management of GPU memory during pretraining, as depicted in Figure 2. It highlights a potential issue with the forward propagation requirement, which is crucial for understanding the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a relevant aspect of the methodology, it lacks actionable feedback or constructive suggestions that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out an area of concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the Abstract to better present their contributions, indicating that the current version is not well written and difficult to understand. This feedback provides a clear and direct action for the authors to take, specifying that they need to improve the clarity and presentation of their contributions. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the Abstract section of the paper, indicating that it is not well written and difficult to understand the contributions. However, it does not specify which parts of the Abstract are problematic or suggest how to improve them. While the authors can infer that the Abstract is being referred to, the lack of specific guidance makes it challenging to pinpoint exact areas for improvement. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the Abstract is not well-written and difficult to understand the contributions. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to identify and address the issues in the Abstract. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the Abstract, noting that it is not well-written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite the Abstract to better present the contributions. This feedback is valuable as it guides the authors on how to improve the clarity and effectiveness of their abstract, which is crucial for readers\\' understanding and engagement with the paper. However, the comment could be more helpful if it offered specific examples or guidance on how to rephrase the Abstract for better clarity. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point continues a previous discussion about ADE being a dataset for Image parsing and potentially biased among different scenes, which may favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this information should be addressed or incorporated into the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous discussion about ADE being a dataset for Image parsing and potentially biased among different scenes. However, it does not explicitly mention which part of the paper this discussion is related to, making it weakly grounded. The comment does specify the issue of potential bias in the dataset, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that ADE is a dataset for Image parsing and suggests that it may be biased among different scenes, favoring the performance of the proposed method. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or mitigate potential biases. Without specific guidance or recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this information should be addressed or incorporated into the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not explicitly mention which part of the paper this discussion is related to, making it weakly grounded. The comment does specify the issue of potential bias, adding some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that ADE is a dataset for Image parsing and suggests that it may be biased among different scenes, favoring the performance of the proposed method. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or mitigate potential biases. Without specific guidance or recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. Without actionable advice or suggestions, the authors are left without a clear path forward. The comment lacks specificity and does not offer guidance on how to address the issue, making it unactionable. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous discussion about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not explicitly mention which part of the paper this discussion is related"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices for each relation (edge type) in section 2.1.2 and suggests that the two matrices might be the same. It also notes that many matrices are not used in the following text. While the comment highlights a potential issue, it does not provide explicit instructions or suggestions on how to address it. The authors can infer that they need to clarify the purpose of using two matrices and possibly revise the text to reflect this, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of two matrices for each relation (edge type) and notes that many matrices are not used in the following text. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations regarding the use of matrices in section 2.1.2. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the representation of relations (edge types) in section 2.1.2, noting that each relation is represented by two matrices (A, B, C, D, E, F) but questioning whether these matrices are indeed different. It also points out that many matrices are not used in the following text, suggesting a need for clarification or explanation. While the comment highlights an area that may require further explanation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. The feedback is somewhat helpful as it prompts the authors to clarify their methodology, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the semantics of the upsampled feature map, indicating that the authors do not understand the meaning of the phrase \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a misunderstanding that needs clarification, an error that needs correction, or if it is a point that should be addressed in the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear: the meaning of the phrase \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about a statement in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the phrase \"the semantics of the upsampled feature map can be stronger than the original one\" in Section 2. By pointing out this lack of clarity, the comment highlights an important issue that the authors need to address to improve the readability and understanding of their work. However, the comment does not provide any suggestions or guidance on how the authors might clarify this point or what specific aspects of the semantics are being referred to. While it directs the authors to an area needing clarification, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, such as the one referenced in [1]. This provides a clear and direct action for the authors to take, which is to address the differences between their method and the one mentioned in the reference. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning a reference [1] by Yang et al. This provides a clear reference to a specific work that the authors should consider in their clarification. However, the comment does not explicitly mention which part of the paper should include this clarification, making it weakly grounded. The suggestion is specific, as it clearly identifies the need to address the differences with a particular method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning a reference [1]. However, the comment does not provide any specific reasoning or examples to support why this clarification is necessary or how it would benefit the paper. The mention of a reference does not substantiate the claim, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors clarify the differences between their method and other methods for predicting user\\'s personality, such as the one referenced in [1]. This feedback is clear and actionable, as it directs the authors to provide a detailed comparison of their method with existing approaches. By addressing this point, the authors can enhance the clarity and novelty of their work. However, the comment could be more helpful if it provided additional context or guidance on how to effectively present these differences. Overall, the comment is mostly helpful, as it highlights a critical area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises two concerns: the theoretical justification for the empirical results in LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment lacks actionable details, such as recommending specific analyses or experiments to clarify the theoretical aspects or suggesting ways to demonstrate the theoretical claims. As a result, the authors are left without clear direction on how to improve their draft in response to these points. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two distinct issues: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the theoretical concerns and the perceived lack of clarity regarding the empirical results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims. The first claim questions the theoretical basis of LoRA tuning, suggesting that imposing specific constraints on matrices $B$ and $A$ may not be necessary for convergence. The second claim questions the necessity of step size tuning despite theoretical claims. While the comment provides some reasoning, it lacks specific examples, references, or detailed explanations to fully substantiate these claims. The authors may find it challenging to understand and address the concerns without additional context or evidence. Therefore, the claims are somewhat verifiable, as they provide a starting point for further exploration but require more detailed support to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two key areas of concern: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. It questions the empirical verification of LoRA tuning, suggesting that the theoretical explanation is not clear and that the authors may have overlooked a more straightforward approach. Additionally, it points out a potential issue with the theoretical claims regarding constant step size, indicating that step size tuning might still be necessary for the experiments. While the comment raises important questions and highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to reconsider their theoretical explanations and empirical results, but it could be more actionable with additional detail or examples. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises two concerns: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment lacks actionable details, such as recommending specific analyses or experiments to clarify the theoretical aspects or suggesting ways to demonstrate the theoretical claims. As a result, the authors are left without clear direction on how to improve their draft in response to these points. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The review point raises two distinct issues: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is somewhat specific in detailing the theoretical concerns and the perceived lack of clarity regarding the empirical results, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: one about the theoretical basis of LoRA tuning and the other about the necessity of step size tuning despite theoretical claims. The first claim questions the theoretical justification for the empirical results, suggesting that the theoretical explanation is not clear. The second claim questions the sufficiency of constant step size, implying that step size tuning might still be needed for the experiments. While the comment provides some reasoning, it lacks specific examples, references, or detailed explanations to fully substantiate these claims. The authors may find it challenging to understand and address these concerns without additional context or evidence. Therefore, the claims are somewhat verifiable, as they provide a starting point for further exploration but require more detailed support to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two key areas of concern: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. It questions the theoretical explanation for why imposing specific constraints on matrices $B$ and $A$ would accelerate convergence, suggesting that the authors may have overlooked a simpler approach. Additionally"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors conduct more ablation studies or analysis on problems other than shortest path problems to make their findings more convincing. While the comment implies that additional experiments are needed, it does not specify which problems should be considered or how the ablation studies should be structured. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental environments and the design of the architecture (PathGNN), specifically mentioning the bias towards the shortest path problem. It suggests conducting more ablation studies or analysis on problems other than shortest path problems to make the findings more convincing. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The suggestion is specific, as it clearly outlines what additional analysis or studies could be conducted. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem and that the architecture (PathGNN) has a bias towards this type of problem. The reviewer recommends conducting more ablation studies or analysis on problems other than shortest path problems to make the findings more convincing. While the comment identifies a potential limitation in the experimental scope, it lacks specific examples or references to support the claim that the bias is problematic or how it affects the results. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental scope of the paper, noting that most experimental environments are closely related to the shortest path problem. It suggests that the design of the architecture (PathGNN) may have a bias towards this type of problem, which could be addressed by conducting more ablation studies or analysis on problems other than shortest path problems. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental analysis to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered specific examples of alternative problems or methodologies for conducting the suggested analysis. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. While the action is implied, it is not explicitly stated, and the comment does not provide specific examples or guidance on which models to include. The authors can infer that they need to expand their baseline comparisons, but the lack of concrete details makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion of baselines. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, the comment does not provide specific examples or references to these models, making it difficult for the authors to identify which models should be included. The lack of detailed justification or examples results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient evidence or reasoning to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of more recent models. However, the comment lacks specificity and does not provide examples or guidance on which models should be considered. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is rated as somewhat helpful, as it provides some direction but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The feedback is vague and lacks concrete details, leaving the authors uncertain about how to enhance their draft. Without clear instructions or examples, the authors may struggle to determine the best course of action. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also mentions that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not specify which part of the paper should include this visualization or where the novelty and insight are missing. This makes it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these aspects are discussed, the comment lacks full grounding. It is specific about the lack of visualization and insight but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also suggests that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of explicit evidence or references renders the claim unverifiable, as it does not provide sufficient justification for the authors to address the feedback effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and insight into the approach. While the comment provides some insight into areas that need attention, it lacks detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it directs the authors to consider enhancing the visualization and analysis of their approach, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the draft. Without specific actions or detailed feedback, the authors may struggle to determine how to enhance their work. The lack of actionable advice makes this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not specify which part of the paper should include this visualization or where the novelty and insight are missing. This makes it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these aspects are discussed, the comment lacks full grounding and specificity. Therefore, it is weakly grounded and not specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also suggests that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of explicit evidence or references renders the claim unverifiable, as it does not provide sufficient justification for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that the paper would be stronger if results were reported for other models than MetaOptNet, emphasizing the generality of the method and convincingly demonstrating the improvement over multiple baseline models. While the comment explicitly states the need for additional results, it does not provide specific guidance on which models to include or how to present these results. The action is explicit but somewhat vague in terms of execution, as the authors know they need to report results for other models but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to report results for other models than MetaOptNet to emphasize the generality of the method and convincingly demonstrate improvement over multiple baseline models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental section, noting that the current results show only small benefits over the baseline model. The reviewer suggests that reporting results for other models would emphasize the generality of the method and convincingly demonstrate its improvement over multiple baseline models. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to other models that could be used for comparison. This makes the claim somewhat verifiable, as the authors would need to further explore and implement the suggestion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern with the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that the paper would be much stronger if results were reported for other models than MetaOptNet, emphasizing the generality of the method and convincingly demonstrating the improvement over multiple baseline models. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the robustness and generalizability of their findings. By addressing this suggestion, the authors can significantly improve the impact and credibility of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include additional well-established methods, such as FTML and LFW, in their comparison to provide a more comprehensive evaluation of the proposed method. While the comment explicitly states the action needed, it does not provide specific guidance on how to integrate these methods into the comparison or what aspects to focus on. The authors are given a clear direction but lack detailed instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. However, it does not specify which part of the paper currently lacks these comparisons, making it weakly grounded. The comment is specific in suggesting additional methods to include, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. This claim is somewhat verifiable as it provides a logical suggestion for improvement by referencing specific methods that could enhance the evaluation of the proposed method. However, the comment lacks detailed reasoning or evidence on why these methods are particularly relevant or how they would impact the evaluation. Providing more context or examples would strengthen the justification, making the claim clearer and more actionable for the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's comparison, suggesting that the authors should include well-established methods like FTML and LFW to provide a more comprehensive evaluation of their proposed method's strengths and weaknesses. This feedback is clear and actionable, offering specific guidance on how to enhance the paper's evaluation section. By suggesting particular methods to include, the comment empowers the authors to make a meaningful improvement to their draft. However, it could be more helpful if it provided additional context or rationale for why these methods are important. Overall, the comment is mostly helpful, as it effectively directs the authors toward a significant enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a significant issue with the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded. Additionally, it points out that location embeddings provide additional information on the main dataset but not on the extra dataset, implying that they may be useful for specific types of datasets. However, the comment does not provide specific guidance on how the authors should address these issues or improve their focus on modeling. The feedback is somewhat actionable as it highlights areas for improvement but lacks detailed instructions on how to implement the suggested changes.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the comparison between the proposed CRF variants and hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it details the issue with the performance of the CRF variants and suggests that the focus on modeling using a CRF should be downgraded. It further points out the potential usefulness of location embeddings for specific types of datasets and the lack of discussion on this in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proposed CRF variants underperform hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This claim is supported by the observation that the focus on modeling using a CRF should be downgraded. The comment also highlights that location embeddings provide additional information on the main dataset but not on the extra dataset, suggesting that they may be useful for specific types of datasets. However, the comment lacks specific examples or references to substantiate the claim about the underperformance of CRF variants or the potential usefulness of location embeddings. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling using a CRF should be downgraded, as the location embeddings provide additional information on the main dataset but not on the extra dataset. This feedback is clear and actionable, as it directs the authors to reconsider the focus of their paper and provides insights into the potential limitations of their approach. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or improve the paper's focus. Overall, the comment is mostly helpful as it provides valuable insights and guidance for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific steps they should consider to clarify the impact. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of training-testing inconsistency, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the training-testing inconsistency are unclear or how it affects the results. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency but does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the impact of training-testing inconsistency, which is a relevant issue that could affect the validity of the results. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or clarify the impact in their paper. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment raises a concern about the impact of training-testing inconsistency but does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific steps they should consider to clarify the impact. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of training-testing inconsistency, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the training-testing inconsistency are unclear or how it affects the results. This lack of detail makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the impact of training-testing inconsistency, but it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the impact of training-testing inconsistency, which is a relevant issue that could affect the validity of the results. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or clarify the impact in their paper. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment raises a concern about the impact of training-testing inconsistency but does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific steps they should consider to clarify the impact. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of training-testing inconsistency, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the training-testing inconsistency are unclear or how it affects the results. This lack of detail makes it difficult for the authors to understand and address the issue effectively."}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: the condition for y membership is unclear due to the disjoint nature of the sets S, and some claims are not backed up, specifically mentioning the second line after Eq. While the comment highlights specific areas of concern, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to clarify the condition for y membership and provide evidence for the claims, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"condition for y membership\" and the \"sets S,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the condition is unclear due to the disjoint nature of the sets S and that some claims are not backed up, specifically mentioning the second line after Eq. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The mention of \"some claims are not backed up\" is also vague and lacks specific examples or references. As a result, the claim is borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the condition for y membership, noting that the sets S are disjoint, as defined above. This is a clear and actionable point that can help the authors improve the clarity of their paper. Additionally, the comment points out that some claims are not backed up, specifically mentioning the second line after Eq. This feedback is somewhat helpful as it highlights areas where the authors need to provide more evidence or clarification. However, it could be more helpful if it offered suggestions on how to strengthen the claims or provide additional support. Overall, the comment provides valuable insights but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two issues: the condition for y membership is unclear due to the disjoint nature of the sets S, and some claims are not backed up, specifically mentioning the second line after Eq. While the comment highlights specific areas of concern, it does not provide explicit guidance or suggestions on how to address these issues. The authors can infer that they need to clarify the condition for y membership and provide evidence for the claims, but the lack of detailed instructions makes the comment somewhat vague. Therefore, the feedback is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"condition for y membership\" and the \"sets S,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the condition is unclear due to the disjoint nature of the sets S and that some claims are not backed up, specifically mentioning the second line after Eq. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Additionally, the comment mentions that some claims are not backed up, specifically pointing to the second line after Eq., but it lacks further explanation or examples to substantiate this claim. As a result, the claim is not well-supported, making it difficult for the authors to verify and address the issues effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues: the condition for y membership is unclear due to the disjoint nature of the sets S, and some claims are not backed up, specifically mentioning the second line after Eq. This feedback is somewhat helpful as it highlights areas where the paper lacks clarity and evidence, providing the authors with clear points to address. However, the comment could be more helpful if it offered suggestions on how to clarify the condition or provide evidence for the claims. Overall, the comment provides valuable insights"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that certain key references that are highly relevant are not compared or explained in the paper. However, it does not specify which references are missing or what aspects of these references should be addressed. The action is implicit, as the authors need to infer that they should include these references and explain their relevance, but it is vague because it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of certain key references that are highly relevant to the paper. However, it does not specify which references are missing or which sections of the paper should include these references. This lack of explicit grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of these references should be compared or explained. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that certain key references are not compared or explained in the paper. However, it does not specify which references are missing or provide any reasoning or evidence to support why these references are crucial. Without specific examples or detailed justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that certain key references that are highly relevant are not compared or explained. This feedback is valuable as it highlights a gap in the literature review that the authors need to address to strengthen their work. However, the comment lacks depth and does not provide specific guidance on which references are missing or how the authors might incorporate them into their analysis. While it points out an area for improvement, it does not offer actionable suggestions or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, noting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It suggests that the paper\\'s claim about the regularization effect of SCL on representation space may not be supported by the results. The reviewer also recommends checking if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific areas of concern and provides a direction for further analysis, it lacks explicit instructions or concrete steps on how to address these issues. The authors are left to infer the necessary actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, noting that the results do not meet expectations and suggesting a check on the benefits of COCO-LM in sentence retrieval tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the convincing nature of the analysis regarding SCL in section 5.2, particularly in the context of few-shot ability. The reviewer provides a specific example by referencing Figure 7(c) and (d), where the results do not align with the paper\\'s claims. This provides a clear example of the issue, making the claim somewhat verifiable. However, the comment could be strengthened by offering more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of SCL in section 5.2 regarding few-shot ability, noting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It questions the claim that a more regularized representation space by SCL leads to better generalization ability in few-shot scenarios. The comment provides a clear example of where the results do not support the claim, which is valuable feedback for the authors. Additionally, it suggests checking if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations, offering a direction for further exploration. This feedback is actionable and provides a constructive critique that can help the authors refine their analysis and improve the robustness of their claims. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, noting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It suggests that the paper\\'s claim about the regularization effect of SCL on representation space may not be supported by the results. The reviewer also recommends checking if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific areas of concern and provides a direction for further analysis, it lacks explicit instructions or concrete steps on how to address these issues. The authors are left to infer the necessary actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, noting that the results do not meet expectations and suggesting a check on the benefits of COCO-LM in sentence retrieval tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the convincing nature of the analysis regarding SCL in section 5.2, particularly in the context of few-shot ability. It provides specific examples by referencing Figure 7(c) and (d), where the results do not meet the authors\\' expectations. The reviewer notes that COCO-LM achieves more improvements with fewer labels and that the improvements gradually disappear with more labels. This provides a clear example of the issue, making the claim somewhat verifiable. However, the comment could be strengthened by offering more detailed reasoning or additional examples to"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete details on which specific LLMs should be tested or how the experiments should be structured. The authors are given a clear direction to conduct additional experiments but are left without specific guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its suggestion to conduct more experiments on other LLMs, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, the comment does not provide any specific reasoning, examples, or references to support why this would be beneficial or necessary. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending more comprehensive testing. However, the comment lacks specific guidance on which LLMs to include or how to design these additional experiments, leaving the authors with a general direction but without detailed instructions. To be more helpful, the comment could specify which LLMs are most relevant or provide examples of how to structure these additional experiments. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete details on which specific LLMs should be tested or how the experiments should be structured. The authors are given a clear direction to conduct additional experiments but are left without specific guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. The suggestion is specific in terms of what additional experiments should be conducted, but the lack of grounding in the paper's structure makes it challenging for the authors to implement the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, the comment lacks any supporting evidence, reasoning, or references to justify why this would be beneficial or necessary. Without specific examples or detailed explanation, the claim remains unverifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending more comprehensive testing. However, the comment lacks specificity, such as which specific LLMs should be tested or how the experiments should be structured. Without detailed guidance, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment provides some direction but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete details on which specific LLMs should be tested or how the experiments should be structured. The authors are given a clear direction to conduct additional experiments but are left without specific guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to clarify what is meant by \"short\" and \"long\" videos in the context of deciding the downsample layers. It also recommends conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for the qualitative examples added. While the comment provides explicit actions\u2014clarifying the terms and conducting a comparison\u2014it lacks concrete details on how to implement these actions. The authors know they need to clarify the terms and compare outputs, but the comment does not specify how to do so or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified regarding the terms \"short\" and \"long\" videos in the context of deciding the downsample layers. Additionally, it suggests conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for qualitative examples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests the need for clarity on the terms \"short\" and \"long\" videos in the context of deciding downsample layers. It also recommends conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for qualitative examples. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to support the claim that these clarifications are necessary. The suggestion for an apple-apple comparison is somewhat vague, as it does not specify which outputs should be compared or how this would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for clarity regarding the terms \"short\" and \"long\" videos in the context of deciding the downsample layers. It suggests that the authors provide more information on these terms to ensure that the decision-making process is well understood. Additionally, the comment recommends conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for qualitative examples that were added. This feedback is clear and actionable, as it guides the authors to improve the clarity of their methodology and provides a specific suggestion for enhancing the evaluation of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors need to clarify the terms \"short\" and \"long\" videos in the context of deciding the downsample layers. It also recommends conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for the qualitative examples added. While the comment provides explicit actions\u2014clarifying the terms and conducting a comparison\u2014it lacks concrete details on how to implement these actions. The authors know they need to clarify the terms and compare outputs, but the comment does not specify what aspects to focus on or how to structure the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified regarding the terms \"short\" and \"long\" videos in the context of deciding the downsample layers. Additionally, it suggests conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for qualitative examples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests the need for clarity on the terms \"short\" and \"long\" videos in the context of deciding the downsample layers. It also recommends conducting an apple-apple comparison of state-of-the-art VLM/Video-LLM outputs for qualitative examples. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to support the claim that these clarifications are necessary. The suggestion for an apple-apple comparison is somewhat vague, as it does not specify which outputs should be compared or how this would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in terms of efficiency when generating multiple objects, especially in scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate the identified limitation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the efficiency of generating multiple objects, indicating a potential limitation. However, it does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the potential limitation in terms of efficiency, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, indicating a potential limitation in terms of efficiency, especially for scenes with a high number of objects or complex interactions. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This is a relevant observation that could impact the practical applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their approach. While it highlights an important area for consideration, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical contribution is thin and that the algorithm proposed may be considered incremental because the interpolative decomposition used is not proposed by the paper. The reviewer recommends that the authors focus on finding additional applications and deeply evaluating the approach. This feedback provides a clear and explicit action for the authors to take, which is to explore additional applications and thoroughly evaluate their approach. The suggestion is concrete, as it outlines specific steps for the authors to follow to enhance the value of their manuscript. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the algorithm proposed and the use of the interpolative decomposition. However, it does not specify which part of the paper this assessment is based on, making it weakly grounded. The comment does provide specific guidance on what the authors could do to improve their work, such as focusing on finding additional applications and deeply evaluating the approach. This specificity helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is thin and suggests that the algorithm proposed may be considered incremental because the interpolative decomposition used is not proposed by the paper. The reviewer recommends focusing on finding additional applications and deeply evaluating the approach to enhance the manuscript. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the algorithm is incremental. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical evaluation of the technical contribution of the paper, suggesting that it may be considered incremental due to the use of an interpolative decomposition that is not proposed by the paper. The reviewer offers a constructive suggestion by recommending that the authors focus on finding additional applications and deeply evaluating their approach. This feedback is actionable and provides a clear direction for the authors to enhance the value of their manuscript by exploring new applications and properties of their representation. However, the comment could be more helpful if it included specific examples or guidance on how to find these additional applications or evaluations. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the neural network library used for implementing the system and notes the lack of details on the implementation. While it highlights an area that needs clarification, it does not provide explicit instructions or suggestions on how to address this issue. The authors can infer that they need to include details about the neural network library used, but the comment lacks concrete guidance on how to present this information. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the neural network library used for implementing the system and notes the lack of details on the implementation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where implementation details are expected. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for details on the implementation, but without clear grounding, it aligns with a score of 2. Therefore, the comment is weakly grounded and specific, corresponding to label 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question and an observation about the lack of details on the implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the neural network library used for implementing the system, noting the lack of details on the implementation. This is a specific and actionable point that can guide the authors to provide more information about their implementation choices, which is crucial for reproducibility and clarity in the paper. However, the comment could be more helpful if it suggested where or how to include this information in the paper. Overall, the feedback is somewhat helpful as it directs the authors to an important area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies that some descriptions are unclear, specifically mentioning that some mathematical notations are undefined and some details in Figure illustrations are missing. However, it does not provide explicit instructions or concrete guidance on how to address these issues. The comment implies that the authors should clarify the undefined notations and add missing details, but it lacks specific examples or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies specific issues with unclear descriptions, undefined mathematical notations, and missing details in Figure illustrations. However, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying undefined notations and adding missing details in figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some descriptions are unclear, specifically mentioning undefined mathematical notations and missing details in Figure illustrations. However, the comment does not provide specific examples or detailed reasoning to support these claims. The mention of \"See more below in my questions\" suggests that further explanation is provided elsewhere, but without that context, the current comment lacks sufficient support. This makes the claim borderline verifiable, as it provides some indication of the issue but requires additional information to be fully understood and addressed.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of descriptions, particularly noting undefined mathematical notations and missing details in Figure illustrations. By pointing out these areas, the comment provides the authors with clear directions for improvement. However, the comment lacks depth and does not offer specific suggestions or examples of how to clarify the undefined notations or add missing details. While it highlights important areas for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\\\nu in the text, as it is only explained in Algorithm 1. This direct request provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be added to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the meaning of the notation \\\\nu in the text. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of the notation \\\\nu is only found in Algorithm 1 and recommends mentioning its meaning in the text. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of the notation \\\\nu is only found in Algorithm 1 and suggesting that the meaning of \\\\nu should also be mentioned in the text. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and accessibility of the paper by ensuring that all relevant information is presented in the main text. By addressing this point, the authors can enhance the reader\\'s understanding of the notation used in their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a question about whether the model is underfit due to pseudo-labels being very accurate, suggesting that positive learning has better feedback than a toned-down robust loss. However, the comment does not provide explicit guidance or suggestions for the authors to address this observation. It lacks concrete actions or recommendations on how to investigate or resolve the issue, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the finding that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9, and it raises a question about whether the model is underfit due to pseudo-labels being very accurate. This provides clear guidance on what aspect of the results is being questioned and prompts the authors to consider the implications of this finding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It also raises a question about whether the model is underfit due to pseudo-labels being very accurate. While the comment provides a logical reasoning by comparing the performance of different methods, it lacks specific evidence or references to support the claim about the model being underfit. The reasoning is somewhat verifiable, as it highlights an interesting observation but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a pertinent question about whether the model is underfit due to pseudo-labels being very accurate, suggesting that positive learning has better feedback than a toned-down robust loss. This feedback is somewhat helpful as it identifies a potential issue and prompts the authors to consider the implications of their findings. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue or further explore the implications of the finding. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a question about whether the model is underfit due to pseudo-labels being very accurate, suggesting that positive learning has better feedback than a toned-down robust loss. However, the comment does not provide explicit guidance or suggestions for the authors to address this observation. It lacks actionable steps or concrete advice on how to investigate or resolve the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the finding that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9, and it raises a question about whether the model is underfit due to pseudo-labels being very accurate. This provides clear guidance on what aspect of the results is being questioned and prompts the authors to consider the implications of this finding. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a question about whether the model is underfit due to pseudo-labels being very accurate, suggesting that positive learning has better feedback than a toned-down robust loss. While the comment provides a logical reasoning by comparing the performance of different methods, it lacks specific evidence or references to support the claim about the model being underfit. The reasoning is somewhat verifiable, as it highlights an interesting observation but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim made in line 248, specifically questioning why an additional exponentiation would significantly increase the runtime to the point of being a concern for the attacker. While the reviewer expresses confusion, they do not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or justify their claim, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim about the runtime increase due to an additional exponentiation, providing clear guidance on what aspect of the claim is confusing. This level of detail helps the authors understand what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question expressing confusion about a claim made in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific claim made in the paper, questioning why an additional exponentiation would significantly increase the runtime to the point of being a concern for the attacker. This feedback highlights a potential misunderstanding or lack of clarity in the paper, prompting the authors to clarify or justify their claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the lack of comparison with state-of-the-art (SOTA) methods and questions the improvements offered by the proposed methods. It suggests that the experiments are insufficient and implies that the authors should compare their methods with existing related works. However, the comment does not provide explicit instructions or concrete steps on how to address these concerns, such as which specific related works should be compared or how to demonstrate improvements. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements of the proposed methods and suggesting a comparison with related works, such as \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the lack of comparison with state-of-the-art (SOTA) methods and suggests that the experiments are insufficient. It references specific related works, such as 'Rubi' and 'Removing bias in multi-modal classifiers,' to imply that these methods should be compared. However, the comment does not provide detailed reasoning or evidence on why these comparisons are necessary or how they would enhance the paper. The lack of specific examples or detailed justification makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the lack of comparison with state-of-the-art (SOTA) methods, which is a critical aspect of evaluating the proposed methods. It references specific related works, such as 'Rubi' and 'Removing bias in multi-modal classifiers,' and questions why these methods are not compared. This feedback is somewhat helpful as it highlights a gap in the experimental evaluation and suggests that the authors should consider including comparisons with these or other relevant works. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides some insight but lacks detailed, actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the lack of comparison with state-of-the-art (SOTA) methods and questions the improvements offered by the proposed methods. It suggests that the experiments are insufficient and implies that the authors should compare their methods with existing related works. However, the comment does not provide explicit instructions or concrete steps on how to address these concerns, such as which specific related works should be compared or how to demonstrate improvements. The action is implicit and lacks specificity, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements of the proposed methods and suggesting a comparison with related works, such as \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the lack of comparison with state-of-the-art (SOTA) methods and questions the improvements offered by the proposed methods. It references specific related works, such as 'Rubi' and 'Removing bias in multi-modal classifiers,' to imply that these methods should be compared. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The lack of specific examples or detailed justification makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the lack of comparison with state-of-the-art (SOTA) methods, which is crucial for evaluating the proposed methods' improvements. It references specific related works, such as 'Rubi' and 'Removing bias in multi-modal classifiers,' and suggests that these methods should be compared"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the proposed method enhances performance but notes that this is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks explicit guidance on how the authors could address this observation or enhance their work further. Without specific advice or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that the proposed method\\'s performance enhancement is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, it does not specify which part of the paper this observation is based on, nor does it provide details on how the authors could address this concern. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method\\'s performance enhancement is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, the comment lacks specific references or examples to support this claim, making it difficult for the authors to understand the basis of the assertion. The reasoning is somewhat verifiable, as it provides a logical connection to previous works, but it requires more detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the proposed method enhances performance, but it suggests that this is not surprising because it introduces learnable parameters, such as the temperature, which have been effective in previous works. While the comment identifies a potential limitation in the novelty of the approach, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work from existing literature. The feedback lacks actionable advice or constructive criticism that could help the authors improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges that the proposed method enhances performance but suggests that this is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks explicit guidance on how the authors might address this observation or differentiate their work from existing literature. Without specific advice or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the proposed method enhances performance but suggests that this is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, it does not specify which part of the paper this observation is based on, nor does it provide details on how the authors could address this concern or differentiate their work from existing literature. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively respond to the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the proposed method enhances performance but suggests that this is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. However, the comment lacks specific references or examples to support the claim that these parameters have been effective in previous works. Without detailed evidence or references, the claim remains somewhat verifiable, as it provides a logical connection but lacks the necessary support to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the proposed method enhances performance but suggests that this is not surprising due to the introduction of learnable parameters, such as the temperature, which have been effective in previous works. While it identifies a potential limitation in the novelty of the approach, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work from existing literature. The comment lacks actionable feedback or constructive criticism that could help the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to simplify the inspiration or integrate it more effectively into the main work. Without specific suggestions or steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint where the issue lies. Additionally, the comment lacks specificity regarding what aspects of the inspiration are unnecessary or distracting. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inspiration is considered unnecessary or distracting. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, it does not provide specific guidance or suggestions on how the authors might address this issue or integrate the neuroscience inspiration more effectively into their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to update Table 3 by adding information about the source dataset in the caption. This is a clear and direct action that the authors can take to improve the clarity of their table. The comment also provides a specific suggestion for improving the captions of images and tables, ensuring that all necessary information is included. The feedback is concrete and provides a specific step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for additional information about the source dataset in the table caption. The comment provides a clear suggestion to improve the clarity of the captions, ensuring that the reader does not need to search for information in the main text. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the caption of Table 3 is unclear regarding the source dataset used. It provides a specific suggestion to add information about the source dataset in the caption. This feedback is clear and actionable, but it lacks detailed reasoning or examples to fully substantiate the claim that the caption is unclear. The suggestion to include necessary information in the captions is logical, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the caption does not specify the source dataset used. It provides a clear and actionable suggestion to add this information to the caption, ensuring that the reader does not need to search for it in the main text. This feedback is valuable as it helps improve the clarity and accessibility of the table. Additionally, the comment concludes with a positive remark about the overall quality of the work, which is supportive and encourages the authors. While the comment focuses on a minor issue, it is still mostly helpful as it guides the authors to enhance the clarity of their presentation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks in the paper. This lack of detail makes it difficult for readers to replicate and evaluate the approach. The comment implies that the authors should provide explicit descriptions of these architectures to improve the paper. While the action is not explicitly stated, it is clear and concrete, as it specifies exactly what needs to be done to enhance the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the absence of explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks. This lack of detail makes it difficult for readers to replicate and evaluate the approach. However, the comment does not specify which part of the paper should include these descriptions, making it weakly grounded. The comment is specific in detailing what is missing, namely the explicit descriptions of the architectures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. The comment is somewhat verifiable as it highlights a potential issue with the paper\\'s clarity and replicability. However, it does not provide specific examples or references to support the claim, which would help the authors understand the impact of this omission. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. The feedback is clear and actionable, as it directly points out the need for additional information that would enhance the paper\\'s replicability and evaluation. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of what kind of descriptions would be beneficial. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights the absence of explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks in the paper. This lack of detail makes it difficult for readers to replicate and evaluate the approach. The comment implies that the authors should provide explicit descriptions of these architectures to improve the paper. While the action is not explicitly stated, it is clear and concrete, as it specifies exactly what needs to be done to enhance the draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the lack of explicit descriptions of the architectures used for the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. However, the comment does not specify which part of the paper should include these descriptions, making it weakly grounded. The comment is specific in detailing what is missing, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. The comment is somewhat verifiable as it highlights a potential issue with the paper\\'s clarity and replicability. However, it does not provide specific examples or references to support the claim, which would help the authors understand the impact of this omission. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of explicit descriptions of the specific architectures used for the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. The comment is clear and actionable, as it directly points out the need for additional information that would enhance the paper\\'s replicability and evaluation. However, it could be more helpful if it provided suggestions on how to present this information or examples of what kind of descriptions would be beneficial. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'help"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as assuming the transition model P is true, requiring $Q^{\\pi}$ to be linear, and assuming learned models are consistent. However, it does not provide explicit guidance on how the authors should address these assumptions or suggest specific modifications to make EMCTS applicable. The comment lacks actionable details, such as recommending alternative assumptions or providing examples of how to test these assumptions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions related to EMCTS, such as the assumption that the transition model P is true, the requirement for $Q^{\\pi}$ to be linear, and the assumption of consistent learned models. However, it does not explicitly mention which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that are problematic, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the assumptions underlying EMCTS, specifically questioning the validity of assuming the transition model P is true, the requirement for $Q^{\"pi\"}$ to be linear, and the assumption of consistent learned models. While the comment identifies potential issues with these assumptions, it lacks specific examples or references to support the claim that these assumptions are unreasonable in many cases. The reasoning is somewhat verifiable, as it points out logical inconsistencies but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several assumptions that might render EMCTS inapplicable to real complex problems. It points out specific assumptions, such as the assumption that the transition model P is true, the requirement for $Q^{\\\\pi}$ to be linear, and the assumption of consistent learned models. This feedback is valuable as it highlights potential weaknesses in the theoretical foundation of the work, which could impact the applicability and effectiveness of EMCTS. However, the comment lacks actionable suggestions or guidance on how the authors might address these assumptions or modify their approach to make EMCTS more applicable. While it provides insight into areas that need attention, it does not offer specific steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as assuming the transition model P is true, requiring $Q^{\\\\pi}$ to be linear, and assuming consistent learned models. However, it does not provide explicit guidance on how the authors should address these assumptions or suggest modifications to make EMCTS more applicable. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies specific assumptions related to EMCTS that might make it inapplicable to real complex problems. It mentions assumptions such as the transition model P being true, $Q^{\\\\pi}$ being linear, and learned models being consistent. However, it does not specify which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that are problematic, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the assumptions underlying EMCTS, specifically questioning the validity of assuming the transition model P is true, the requirement for $Q^{\\\\pi}$ to be linear, and the assumption of consistent learned models. While the comment identifies potential issues with these assumptions, it lacks specific examples or references to support the claim that these assumptions are unreasonable in many cases. The reasoning is somewhat verifiable, as it points out logical inconsistencies but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several assumptions that might render EMCTS inapplicable to real complex problems. It highlights specific assumptions, such as assuming the transition model P is true, requiring $Q^{\\\\pi}$ to be linear, and assuming consistent learned models. This feedback is valuable as it points out"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the relationship between explicitness (E) and size (S) may be highly related to the given dataset, and that the different capacity requirements in the 3rd paragraph might be due to input modality differences. It also recommends that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. Additionally, it suggests considering the capacity of probing and factors like training time, cost, and learning rate that might influence the final value of DCI. While the comment provides a general direction for improvement, it lacks specific guidance on how to implement these suggestions or what specific aspects to focus on. The authors are left with a sense of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the relationship between explicitness (E) and size (S) and the potential impact of input modality differences on capacity requirements. The comment further suggests specific factors to consider, such as training time, cost, and learning rate, which provide clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that explicitness (E) and size (S) may be highly related to the given dataset, and that the different capacity requirements in the 3rd paragraph might be due to input modality differences. The comment provides a logical reasoning by suggesting that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. However, it lacks specific examples or references to support the claim about the relationship between explicitness and size, or the impact of input modality differences. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires further elaboration or evidence to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a thoughtful analysis of the relationship between explicitness (E) and size (S) and their potential impact on the given dataset. It suggests that the different capacity requirements in the 3rd paragraph might be due to input modality differences and offers a rationale for evaluating disentanglement, emphasizing the importance of providing enough capacity and training time. Additionally, it highlights the need to consider factors like training time, cost, and learning rate when evaluating the capacity of probing. While the comment is insightful and provides a clear direction for improvement, it could be more helpful by offering specific examples or methodologies for addressing these issues. Overall, the feedback is mostly helpful as it guides the authors toward a more comprehensive analysis of their work, but it could be more detailed to be fully actionable.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper title does not need to include abbreviations. This provides a clear and direct action for the authors to take, which is to remove the unnecessary abbreviations from the title. The feedback is specific and actionable, as it gives the authors a concrete task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the title of the paper, suggesting that it does not need to include abbreviations. However, it does not specify which part of the paper this suggestion pertains to, such as the abstract or the title section itself. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to remove abbreviations from the title, providing clear guidance on what needs to be changed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper title does not require abbreviations. However, it does not provide any reasoning or evidence to support this claim, such as explaining why abbreviations are unnecessary or how they might affect the title\\'s clarity or professionalism. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the title of the paper. It points out that the title does not need to include abbreviations, which is a clear and direct piece of feedback that can help the authors improve the clarity and professionalism of their work. By addressing this point, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it explained why abbreviations are unnecessary or provided examples of other titles that do not include them. Despite this, the feedback is mostly helpful as it offers a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the transferability of the discriminator to other tasks and domains without further training and whether it can be effectively trained with very little data. It also mentions that the discriminator can be small, which is an important insight. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or incorporate the insight about the discriminator being small. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about how to apply this information to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"L400,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the transferability of the discriminator to other tasks and domains without further training and whether it can be effectively trained with very little data. Additionally, it highlights the importance of the insight that the discriminator can be small. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the transferability and training requirements of the discriminator. It does not contain subjective opinions, judgments, or suggestions that require verification. The statements are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the transferability and training requirements of the discriminator, which are crucial considerations for the authors to address. It also highlights the significance of the observation that the discriminator can be small, which is an important insight. However, the comment lacks specific guidance or actionable suggestions on how the authors might explore these aspects further or improve their analysis. While it identifies relevant areas for consideration, it does not provide detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include and compare the current state-of-the-art (SOTA) GNN-QE as a baseline in their study. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added and compared, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"current SOTA GNN-QE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion and comparison of the current state-of-the-art GNN-QE as a baseline. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current state-of-the-art (SOTA) GNN-QE is omitted from the baselines, despite being the closest work in terms of components to the approach being studied. The reviewer suggests that this baseline should be added and compared. While the comment identifies a potential gap in the baselines, it does not provide specific reasoning or evidence to support why this omission is problematic or how it affects the study. The lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, specifically the exclusion of the current state-of-the-art (SOTA) GNN-QE as a baseline. This is crucial because the SOTA GNN-QE is the closest work in terms of components to the approach being studied. The comment is clear and actionable, as it explicitly instructs the authors to include and compare this baseline, which would provide a more comprehensive evaluation of their work. This feedback is highly helpful as it guides the authors to make a meaningful enhancement to their draft by addressing a critical gap in their experimental setup. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to prove the findings' correctness. The feedback is vague and lacks concrete steps or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment does not specify which part of the paper discusses the pretraining data or the findings being explored, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the concerns raised but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or further elaboration, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claims.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address these concerns or prove the findings' correctness. The feedback is somewhat helpful as it highlights an important area for consideration, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or prove the findings' correctness. The feedback lacks actionable steps or detailed advice, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment does not specify which part of the paper discusses these concerns, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific about the concerns raised but lacks full grounding, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could impact the validity of the findings. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or further elaboration, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the pretraining data's ability to help GPT-2 understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training, which could"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of terms in equation (4) and the optimization algorithm. It explicitly points out that the calculation of $p(x_k|d)$ is missing and suggests that every term in the mathematical expressions should be clearly explained unless it is extremely obvious. This feedback provides clear and concrete actions for the authors to take, such as filling in the missing computations and providing detailed explanations for the optimization algorithm. The explicit nature of the suggestions and the clarity on what needs to be addressed make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\" and the \"optimization algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing, such as the computation of terms in equation (4) and the optimization algorithm, including the calculation of $p(x_k|d)$. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of terms in equation (4) and the optimization algorithm. The reviewer provides a logical reasoning by suggesting that every term in the mathematical expressions should be clearly explained unless it is extremely obvious. This reasoning is based on a common expectation for clarity in mathematical explanations. However, the comment could be strengthened by providing specific examples or references to similar works that follow this expectation. As it stands, the claim is mostly verifiable, as it offers a reasonable basis for the critique but lacks detailed evidence or examples. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity and completeness of the proposed method, particularly in the explanation of the computation of terms in equation (4) and the optimization algorithm. It provides a clear and actionable suggestion by pointing out that every term in the mathematical expressions should be explained unless it is extremely obvious. This feedback is valuable as it guides the authors on where to improve the clarity and comprehensiveness of their methodological explanation. However, the comment could be more helpful if it offered additional guidance or examples on how to improve the explanation of these terms. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of implementation details for various aspects of the experiments, including the RAMP algorithm, algorithms compared, discretization used, and other experimental details. It explicitly states that the current form of the experimental results is not reproducible and that the lack of implementation details makes it difficult to assess fairness and evaluate significance. The comment provides a clear and concrete action for the authors to take: to provide a thorough description of the implementation details. This guidance is specific and actionable, giving the authors a clear path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies specific areas where the paper lacks implementation details, such as the RAMP algorithm, algorithms compared, discretization used in the state coverage metric, and other aspects of the experiments. It highlights the issue of non-reproducibility due to missing implementation details and the difficulty in assessing fairness and significance of the experimental results. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the methodology and results sections. The comment is specific in detailing what needs to be addressed, but it is weakly grounded because it does not explicitly mention the sections or parts of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of implementation details for the RAMP algorithm, algorithms compared, discretization used, and other aspects of the experiments makes the results non-reproducible and difficult to assess fairness and significance. The comment provides a logical reasoning by explaining how the absence of implementation details affects the reproducibility and fairness of the comparisons. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific details that are missing, which could be a challenge. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of implementation details for various aspects of the experiments, such as the RAMP algorithm, algorithms compared, discretization used, and other experimental details. This omission makes the experimental results non-reproducible and difficult to assess fairness and significance. The comment provides a clear and actionable suggestion for improvement by emphasizing the need for a thorough description of the implementation details. By addressing this feedback, the authors can significantly enhance the reproducibility and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not guide the authors on how to enhance their work or address any potential weaknesses. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the concept of employing a mixture of experts (MoE) for a task, noting that it is not unusual due to its extensive application in various tasks like general LLM, summarization, and machine translation. It also mentions that the application of MoE in text detection is relatively new but not groundbreaking. However, the comment does not specify which part of the paper this observation is based on, nor does it provide specific guidance on how the authors might address this issue or improve their work. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. The reviewer supports this claim by noting that while the application of MoE in text detection is relatively new, it is not groundbreaking in terms of its fundamental idea. This reasoning is based on the widespread use of MoE in other domains, providing a logical basis for the claim. However, the comment could be strengthened by referencing specific studies or examples to further substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not address any potential weaknesses or areas for enhancement in the paper. As a result, the comment does not offer the authors any guidance on how to improve their draft, making it not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. It also notes that while the application of MoE in text detection is relatively new, it is not groundbreaking in terms of its fundamental idea. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not guide the authors on how to enhance their work or address any potential weaknesses. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the concept of employing a mixture of experts (MoE) for a task, noting that it is not unusual due to its widespread application in various tasks like general LLM, summarization, and machine translation. It also mentions that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not specify which part of the paper this observation is based on, nor does it provide specific guidance or suggestions for improvement. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. As a result, the comment lacks both grounding and specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. It also notes that while the application of MoE in text detection is relatively new, it is not groundbreaking in terms of its fundamental idea. The comment provides logical reasoning by referencing the widespread use of MoE in other domains, which supports the claim. However, it"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the authors claim significant performance improvement for SpaceTGN compared to other baselines but fail to provide a statistical analysis to support this claim. While the comment identifies a specific area that needs attention, it does not explicitly instruct the authors to conduct a statistical analysis or specify which type of analysis should be performed. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical analysis to substantiate their claims. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the claim about SpaceTGN achieving significant performance improvement compared to other baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of statistical analysis to support the claim of significance. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the authors have made a claim about significant performance improvement for SpaceTGN compared to other baselines but fail to provide statistical analysis to support this claim. This is a factual observation about the lack of statistical analysis, which does not constitute a claim requiring verification. Therefore, it is classified as 'No'.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper's evaluation, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. This is an important point that the authors need to address to strengthen their claims and provide a more robust evaluation of their work. However, the comment does not offer specific guidance on how to conduct the statistical analysis or which statistical methods to use, leaving the authors with a clear area for improvement but without detailed direction on how to achieve it. Therefore, the comment is somewhat helpful, as it highlights a significant issue but lacks depth and actionable advice.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a gap in the paper, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. While it identifies a clear area for improvement, it does not provide explicit guidance on how to conduct the statistical analysis or which specific statistical methods to use. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical analysis but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the claim about SpaceTGN's performance improvement compared to other baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of statistical analysis to support the claim of significance. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the authors have made a claim about significant performance improvement for SpaceTGN compared to other baselines but fail to provide statistical analysis to support this claim. This is a factual observation about the lack of statistical analysis, which does not constitute a claim requiring verification. Therefore, the comment is classified as 'No'.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper's evaluation, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. This is an important observation that the authors need to address to strengthen their claims and provide a more robust evaluation of their work. However, the comment does not offer specific guidance or suggestions on how to conduct the statistical analysis or which methods to use, leaving the authors with a clear area for improvement but without detailed direction. Therefore, the comment is somewhat helpful, as it highlights a significant issue but lacks depth and actionable advice.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a gap in the paper, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. While it identifies a critical area for improvement, it does not provide explicit guidance on how to conduct the statistical analysis or which specific statistical methods to use. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical analysis but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the"}
{"generated_text": "{'actionability_rationale': 'The comment points out a potential source of confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the clarity of the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these scores are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in terms of the issue it raises, it is weakly grounded because it does not provide clear guidance on where to make improvements. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about potential confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion in the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. While it highlights an area that could benefit from clarification, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential problem, but it does not offer actionable steps for improvement, leaving the authors with only a vague direction to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The comment points out a potential source of confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect, but without concrete instructions, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the clarity of the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to sections, figures, or tables. Therefore, this comment aligns with a score of 3, indicating it is weakly grounded and specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about potential confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion in the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect. Without actionable feedback or detailed advice, the authors are left with only a vague understanding of the issue. Therefore, the comment is barely helpful, as it points out a potential problem but does not offer a clear path for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The comment points out a potential source of confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect, but without concrete instructions, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the clarity of the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However,"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. The reviewer suggests that the authors should comment on how consistency models achieve something that previous generative models cannot. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the novelty concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. It suggests that the authors should comment on how consistency models achieve something that previous generative models cannot. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the novelty of the method. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is not novel because it primarily involves applying consistency models in place of other generative models. The reviewer suggests that the authors should comment on how consistency models achieve something that previous generative models cannot. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that consistency models offer unique advantages over other generative models. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. It suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed advice on how to improve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. It suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to enhance the novelty of their work. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. It suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the novelty of the method. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is not novel because it primarily involves applying consistency models in place of other generative models. The reviewer suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that consistency models offer unique advantages over other generative models. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the method, noting that it primarily involves applying consistency models in place of other generative models. It suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed advice on how to improve it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric used in Table 2 is limited to MSE, which may not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should consider additional metrics, alternative evaluation methods, or improvements to the existing metric. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that MSE alone cannot reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric used in Table 2, which is MSE, does not accurately reflect the accuracy of nowcasting. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or comparisons to illustrate why MSE is insufficient or how it fails to capture the accuracy of nowcasting. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only employs MSE, which may not accurately reflect the accuracy of nowcasting. This feedback is valuable as it highlights a potential limitation in the evaluation process that the authors should address. However, the comment does not provide suggestions on how to improve the evaluation metric or alternative metrics that could be considered. While it points out a critical area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a lack of empirical evidence supporting the benefit of FFA-LoRA on differential privacy (DP) and notes that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address it. The authors are left to infer that they need to conduct additional empirical evaluations to demonstrate the benefit of FFA-LoRA on DP, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not offer detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP) and notes that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. This provides a specific critique of the empirical results, indicating that the impact of DP noise is the same on both models. However, the comment does not explicitly mention which part of the paper this critique is based on, such as specific sections or figures where these results are presented. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the issue with the empirical evaluation. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation, as the performance gap remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. The comment provides a logical reasoning by suggesting that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. However, the claim lacks specific examples, detailed comparisons, or references to substantiate the assertion fully. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires additional evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP). It points out that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$, suggesting that the impact of DP noise is the same on both models. This feedback is somewhat helpful as it highlights a potential weakness in the empirical evaluation and prompts the authors to consider further analysis or adjustments to demonstrate the benefit of FFA-LoRA on DP. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered specific guidance on additional empirical evaluations that could be conducted. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a lack of empirical evidence supporting the benefit of FFA-LoRA on differential privacy (DP) and notes that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific experiments or analyses to conduct. The feedback is somewhat actionable as it highlights a potential weakness but lacks detailed instructions on how to rectify it. Therefore, the comment aligns with a score of 3.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP) and notes that the performance gap remains constant across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some specificity by detailing the empirical result, it lacks grounding as it does not reference specific sections, figures, or tables. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to complete the ablation study of ENGINE by adding specific configurations, such as Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA, based on the overview model. Additionally, it suggests providing a more detailed analysis of the ablation results. These actions are clear and specific, giving the authors precise guidance on how to improve their draft. The comment provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the ablation study of ENGINE, suggesting that the authors should add specific configurations and provide more detailed analysis of the ablation results. However, it does not specify which part of the paper discusses the ablation study, making it weakly grounded. The comment is specific in suggesting what needs to be added and analyzed, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablation study of ENGINE is incomplete and recommends adding specific configurations and providing more detailed analysis. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these additions are necessary. The suggestion is based on logical reasoning, but without detailed justification or evidence, it remains somewhat verifiable. The authors would need to infer the importance of these additions and how they might impact the study, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the incomplete ablation study of ENGINE. It provides a clear suggestion by recommending the addition of specific configurations, such as Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA, based on the overview model. Additionally, it advises the authors to give more detailed analysis of the ablation results. This feedback is actionable and provides a concrete direction for enhancing the depth and comprehensiveness of the ablation study. However, the comment could be more helpful if it included additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers valuable insights and suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should include results on these datasets, it does not explicitly instruct them to do so. The action is clear but inferred, and the suggestion is concrete, as it specifies the type of dataset that would enhance the paper. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors might infer that it relates to the results or discussion sections, but this is not explicitly stated. The comment is specific in its request for additional results on specific datasets, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging datasets like LSUN and ImageNet would make the findings more convincing. The claim is somewhat verifiable as it references the difficulty of methods with CIFAR-10/Celeb-64 on LSUN/ImageNet, which provides a logical basis for the suggestion. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would enhance the credibility of the findings. This feedback is clear and actionable, as it directs the authors to expand their experimental evaluation to include datasets that are more representative of real-world scenarios. By addressing this suggestion, the authors could strengthen their paper by demonstrating the robustness of their methods across a broader range of datasets. However, the comment could be more helpful if it included specific guidance on how to analyze or present the results on these datasets. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a question about the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should include results on these datasets, it does not explicitly instruct them to do so. The suggestion is clear but inferred, and the authors may not be entirely sure of the exact action required. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The suggestion is specific in terms of what additional results could be included, but without explicit references to sections or figures, the authors may struggle to pinpoint where these changes should be made. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the performance of GAN optimization in GDIM and DDGAN, specifically regarding mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. The comment references the difficulty of methods with CIFAR-10/Celeb-64 on LSUN/ImageNet, which provides a logical basis for the suggestion. However, the claim lacks specific examples or references to support the assertion that methods might struggle with these datasets, making it somewhat verifiable. The authors would need to further explore and substantiate this claim themselves. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of GAN optimization in GD"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of a statement in Section 5.1, specifically regarding the phrase \"Each attribute of the table feature represents a scene.\" While the comment highlights a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this statement, but without further direction, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of the statement \"Each attribute of the table feature represents a scene,\" which provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding a statement in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" This indicates a potential area of confusion or lack of clarity for the reader. However, the comment does not provide any suggestions or guidance on how the authors might clarify this statement or address the issue. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should conduct an ablation study to determine how much better logsumexp aggregation is compared to direct addition, which would correspond to a basic prototype comparison with reweighted averages on each prototype. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and asks how the logsumexp aggregator compares. While the comment provides a clear direction for the authors to conduct an ablation study and raises important questions about the compatibility of the token reweighting scheme, it lacks specific guidance on how to implement these comparisons. The authors are left with a general idea of what needs to be done but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests conducting an ablation study to determine the effectiveness of logsumexp aggregation compared to direct addition. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and asks how the logsumexp aggregator compares. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these comparisons are discussed. The comment is specific in detailing what needs to be addressed, providing clear guidance on the potential improvements. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests conducting an ablation study to determine the effectiveness of logsumexp aggregation compared to direct addition. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers and asks how the logsumexp aggregator compares. While the comment identifies specific areas for improvement, it lacks detailed reasoning or evidence to fully substantiate the claims. The authors are left with a general idea of what needs to be addressed but without specific guidance or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires more detailed justification or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's analysis by pointing out the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests conducting an ablation study to determine the effectiveness of logsumexp aggregation compared to direct addition, which would provide valuable insights into the performance of the proposed method. Additionally, the comment raises a broader question about the compatibility of the token reweighting scheme with existing token-to-token classifiers and asks how the logsumexp aggregator compares. This feedback is clear and actionable, offering specific areas for the authors to explore and improve their draft. However, it could be more helpful if it provided additional guidance or examples on how to conduct the ablation study or compare the aggregators. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to critical areas needing further exploration.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the limitation of using only five datasets to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. While the comment provides a clear action\u2014expanding the dataset to include those mentioned in the references\u2014it does not specify how the authors should incorporate these datasets or what specific changes are needed. The action is explicit but somewhat vague in terms of execution, as the authors know they need to consider additional datasets but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of using only five datasets to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or experimental setup sections. The comment is specific in suggesting the consideration of additional datasets, providing references to support the claim. However, it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of only five datasets is insufficient to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. The comment provides specific references to support the claim, which enhances its verifiability. However, it lacks detailed reasoning or examples on why these specific datasets are more suitable or how they would improve the evaluation. While the references provide a solid foundation, the lack of additional justification or explanation makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's evaluation by pointing out that only five datasets are used to assess the effectiveness of ECGs. It suggests considering the large-scale datasets mentioned in references [1] and [2] as a means to improve the evaluation. This feedback is clear and actionable, as it provides specific references that the authors can use to expand their dataset and enhance the robustness of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to integrate these datasets or what specific aspects to focus on when using them. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a limitation in the use of only five datasets to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. While the comment provides a clear action\u2014expanding the dataset to include those mentioned in the references\u2014it does not offer specific guidance on how to implement this change or what additional datasets might be beneficial. The action is explicit but somewhat vague in terms of execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of using only five datasets to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or experimental setup sections. The comment is specific in its suggestion to consider additional datasets, providing references to support the claim. However, it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of only five datasets is insufficient to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. The comment provides specific references to support the claim, which enhances its verifiability. However, it lacks detailed reasoning or examples on why these specific datasets are more suitable or how they would improve the evaluation. While the references provide a solid foundation, the absence of additional justification or explanation makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's evaluation by pointing out that only five datasets are used to assess the effectiveness of ECGs. It suggests considering the large-scale datasets mentioned in references [1] and [2] as a means to improve the evaluation. This feedback is clear and actionable, as it provides specific"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clearly state the limitation of analyzing only fully connected ResNets and to include this information in the Broader Impact section. This provides a direct and concrete action for the authors to take, ensuring they know exactly what changes to make to improve their draft. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the paper, which is the analysis of fully connected ResNets instead of the typical convolutional layers used in practice. It suggests that the authors should clearly state this limitation and include it in the Broader Impact section. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or limitations sections. The suggestion to include this in the Broader Impact section provides some grounding, but it could be more precise. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation compared to the typical use of convolutional layers in practice. The reviewer suggests that this limitation should be clearly stated and included in the Broader Impact section. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that convolutional layers are more common in practice. This makes the claim somewhat verifiable, as the authors would need to further explore the literature or practice to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that it only analyzes fully connected ResNets, which is not the typical practice in using ResNets. It suggests that the authors should clearly state this limitation and include it in the Broader Impact section. This feedback is clear and actionable, as it provides a direct suggestion for improvement by highlighting the need to address the practical limitations of the analysis. By doing so, the authors can better situate their work within the broader context of ResNet usage and provide a more comprehensive understanding of their findings. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, highlighting the high accuracy achieved on MNIST, SVHN, and CIFAR10. It also mentions that standard knowledge distillation (KD) methods, such as Early KD and FitNets, have surpassed the reported KD performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this information should be used to improve the draft or what specific changes should be made. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the training of a student model on the training set, specifically mentioning the use of a ResNet18 model. It provides performance metrics on MNIST, SVHN, and CIFAR10 datasets, and references standard knowledge distillation (KD) methods. However, it does not specify which part of the paper this information pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the performance metrics and referencing external works, but it lacks grounding as it does not clearly identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, highlighting the high accuracy achieved on MNIST, SVHN, and CIFAR10. It also references standard knowledge distillation (KD) methods, such as Early KD and FitNets, which have surpassed the reported KD performance. This provides a robust foundation for the claim, as it is supported by specific performance metrics and references to established methods. The detailed comparison and references make the claim fully verifiable, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a detailed comparison of the student model\\'s performance on various datasets, highlighting the high accuracy achieved on MNIST, SVHN, and CIFAR10. It also references standard knowledge distillation (KD) methods, such as Early KD and FitNets, which have surpassed the reported KD performance. This information is valuable for the authors as it offers insights into the effectiveness of their model and its comparison with established methods. However, the comment does not provide specific suggestions or guidance on how to improve the draft or address any potential weaknesses. While it offers useful information, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point provides detailed information about the performance of the student model on various datasets, including MNIST, SVHN, and CIFAR10. It also references standard knowledge distillation (KD) methods, such as Early KD and FitNets, which have surpassed the reported KD performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this information should be used to improve the draft or what specific changes should be made. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides detailed information about the performance of the student model on various datasets, including MNIST, SVHN, and CIFAR10. It also references standard knowledge distillation (KD) methods, such as Early KD and FitNets, which have surpassed the reported KD performance. However, the comment does not specify which part of the paper this information pertains to, such as specific sections or experiments. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing the performance metrics and referencing external works, but it lacks grounding as it does not clearly identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, highlighting the high accuracy achieved on MNIST, SVHN, and CIFAR10. It also references standard knowledge distillation (KD) methods, such as Early KD and FitNets, which have surpassed the reported KD performance. This provides a robust foundation for the claim, as it is supported by specific performance metrics and references to established methods. The detailed comparison and references make the claim fully verifiable, align"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically inquires whether certain GCN variants, like Geniepath or Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM, would violate this assumption in the proposed framework. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should consider the implications of these GCN variants on their framework. However, the comment lacks concrete steps or suggestions on how to investigate or mitigate this potential issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It questions whether certain GCN variants, such as Geniepath or Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM, would violate this assumption in the proposed framework. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing the causal graph assumption or the methodology, but this inference is not direct. The comment is specific in detailing the potential issue with the assumption, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It references specific GCN variants, such as Geniepath and Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM. This reference provides a basis for questioning the assumption, making the claim somewhat verifiable. However, the comment lacks detailed reasoning or evidence to fully substantiate the concern about potential violations of the causal graph assumption. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the assumptions underlying the proposed framework, specifically regarding the directionality of causal factors and the role of node attributes X. It references specific GCN variants, such as Geniepath and Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM, and questions whether these methods would violate the causal graph assumption. This feedback is somewhat helpful as it prompts the authors to reconsider their assumptions and potentially explore the implications of these GCN variants on their framework. However, the comment could be more helpful if it provided suggestions on how to address this potential issue or offered insights into how to incorporate these GCN variants into the framework. Overall, the comment provides some direction for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It references specific GCN variants, such as Geniepath and Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM, and questions whether these methods would violate the causal graph assumption in the proposed framework. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It references specific GCN variants, such as Geniepath and Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM. This provides a clear context for the concern, making the comment fully grounded. The comment is also specific as it details the potential issue with the causal graph assumption in the proposed framework. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It references specific GCN variants, such as Geniepath and Gated GNN, which learn message passing routes and sub-graph structures coupled with LSTM. This reference provides a basis for questioning the assumption, making the claim somewhat verifiable. However, the comment lacks detailed reasoning or evidence to fully substantiate the concern about potential violations of the causal graph assumption. The authors would need to further explore and address this issue themselves. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifi"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the authors should consider pre-processing and post-processing modules in addition to message-passing layers, and it recommends listing the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This feedback is clear and provides specific guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pre-processing,\" \"message-passing,\" and \"post-processing,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the claim that message-passing is the most important part of GNN, suggesting that different tasks require different pre-/post-processing modules. The comment further provides a specific suggestion for improvement by recommending the listing of SOTA algorithm performance in each dataset discussed in Table 1. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that message-passing is the most important part of GNN, suggesting that different tasks require different pre-/post-processing modules. The reviewer provides a logical reasoning by pointing out that the importance of message-passing may vary across tasks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The suggestion to list the performance of SOTA algorithms in each dataset is a constructive suggestion but does not directly address the verifiability of the initial claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It questions the authors\\' claim that message-passing is the most important part of GNN, suggesting that different tasks may require different pre-/post-processing modules. The reviewer recommends listing the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1, which would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is constructive and offers a specific way to enhance the paper\\'s analysis and comprehensiveness, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. While the comment implies that the authors should provide this evidence, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include additional evidence but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be useful to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. However, it does not specify which part of the paper lacks this evidence or where the authors should focus their efforts to address this issue. The authors might infer that it relates to the sections discussing the method or results, but this inference is not directly guided by the comment. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it would be useful to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. The comment provides a logical reasoning by questioning the necessity of learning the advantage directly, but it lacks specific examples or references to substantiate the claim. This makes the comment somewhat verifiable, as it highlights a potential gap in the paper but does not provide detailed evidence or reasoning to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. While the comment identifies a potential gap in the paper, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback highlights an area for improvement but does not provide actionable steps or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and so on, in the appended algorithms. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to improve the draft. The suggestion is concrete, as it outlines a specific area for enhancement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on, in the appended algorithms. However, it does not specify which part of the paper these symbols are used in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these symbols are used, the comment lacks full grounding. It is specific about what needs to be addressed\u2014adding explanations for the variable symbols\u2014but does not provide detailed guidance on how to do so. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, etc., in the appended algorithms should be added. However, the comment does not provide any justification or reasoning for why these explanations are necessary or how they would improve the paper. Without additional context or evidence, the authors may find it challenging to understand the importance of these additions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding explanations for the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on, in the appended algorithms. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing clearer definitions for these symbols. By addressing this point, the authors can enhance the clarity and accessibility of their work for readers. However, the comment could be more helpful if it provided examples of how these explanations might be structured or what specific information should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the innovation or differentiate their method from existing ones. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the limited performance gains of the method, suggesting that it lacks innovation and may represent incremental changes to established methods. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the method are lacking innovation or how the performance gains could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation and may represent incremental changes to established methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the performance gains of the method, suggesting that it may lack innovation and represent incremental changes to established methods. While it identifies a potential issue, the comment lacks specific suggestions or guidance on how the authors might address this concern or enhance the innovation of their method. Without actionable feedback or detailed advice, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the innovation or differentiate their method from existing ones. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the limited performance gains of the method, suggesting that it lacks innovation and may represent incremental changes to established methods. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the method are lacking innovation or how the performance gains could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation and may represent incremental changes to established methods. However, it does not provide specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the performance gains of the method, suggesting that it may lack innovation and represent incremental changes to established methods. However, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the innovation of their method. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the innovation or differentiate their method from existing ones. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the limited performance gains of the method, suggesting that it may lack innovation and represent incremental changes to established methods. However, it"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. It implies that the authors should conduct a comparative analysis to provide a clearer picture of the proposed system\\'s strengths and weaknesses. However, the comment does not specify which existing methods or systems should be included in the comparison or how the authors should structure this analysis. While the action is implied, it lacks concrete details on how to implement the suggested improvement. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper should include this comparative analysis or where the current analysis is lacking. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where such an analysis could be integrated, the comment lacks full grounding. It is specific in suggesting a direction for improvement but does not provide detailed guidance on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it provides a logical reasoning that comparative analysis could enhance the clarity of the paper\\'s strengths and weaknesses. However, the comment lacks specific examples or references to existing methods or systems that could be included in the comparison, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is valuable as it highlights a potential area for improvement that could provide a clearer understanding of the proposed system\\'s strengths and weaknesses. However, the comment lacks specific guidance on which existing methods or systems should be included in the comparison or how the authors might structure this analysis. While it offers a direction for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. While it implies that the authors should conduct such an analysis, it does not provide specific guidance on which existing methods or systems to compare with or how to structure the analysis. The action is implicit and lacks concrete details, making it somewhat actionable. The authors have an idea of what needs to be done but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper should include this comparative analysis or where the current analysis is lacking. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the suggestion is specific in terms of what could be improved, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it provides a logical reasoning that comparative analysis could enhance the clarity of the paper\\'s strengths and weaknesses. However, the comment lacks specific examples or references to existing methods or systems that should be included in the comparison, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is valuable as it highlights a potential area for improvement that could provide a clearer understanding of the proposed system\\'s strengths and weaknesses. However, the comment lacks specific guidance on which existing methods or systems should be included in the comparison or how the authors might structure this analysis. While it offers a direction for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label':"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees, does not outperform existing methods on the real dataset (long-range graph benchmark). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the practical usefulness of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the performance or practicality of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"$\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$\" and the real dataset (long-range graph benchmark), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ not outperforming existing methods, which limits its practical usefulness. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a significant issue with the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees. It highlights that the prediction performance on the real dataset (long-range graph benchmark) does not outperform existing methods. This feedback is valuable as it identifies a critical area where the authors need to address to enhance the practical applicability of their method. However, the comment lacks specific suggestions or guidance on how the authors might improve the performance or address the limitations. While it provides a clear direction for improvement, the feedback could be more actionable with additional details or recommendations. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees, does not outperform existing methods on the real dataset (long-range graph benchmark). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the practical usefulness of their method. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"$\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$\" and the real dataset (long-range graph benchmark), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ not outperforming existing methods, which limits its practical usefulness. This provides clear guidance on what aspect of the method's performance is being evaluated. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees, does not outperform existing methods on the real dataset (long-range graph benchmark). However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of the critique and address it effectively. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees. It points out that the prediction performance on the real dataset (long-range graph benchmark) does not outperform existing methods, thereby limiting its"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their comparison. There is no guidance on alternative approaches or adjustments to the methodology that could make the comparison fairer. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, suggesting that it is unfair because the target of those algorithms is not to find an equilibrium. However, the comment does not specify which part of the paper this comparison is made, nor does it provide details on how the comparison is unfair or what specific aspects should be addressed. Without explicit references to sections, figures, or specific comparisons, the authors cannot confidently determine which parts of the paper need revision. The lack of specificity and grounding makes it difficult for the authors to understand and address the critique effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because their target is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that it is unfair because the target of those algorithms is not to find an equilibrium. While it identifies a potential issue with the comparison, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern or improve their analysis. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review point critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that it is unfair because the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their comparison. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, suggesting that it is unfair because the target of those algorithms is not to find an equilibrium. However, the comment does not specify which part of the paper this comparison is made, nor does it provide details on how the comparison is unfair or what specific aspects should be addressed. Without explicit references to sections, figures, or specific comparisons, the authors cannot confidently determine which parts of the paper need revision. The lack of specificity and grounding makes it difficult for the authors to understand and address the critique effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because their target is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that it is unfair because the target of those algorithms is not to find an equilibrium. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their comparison. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, arguing that"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should clarify its unique contributions in methodology and purpose by providing more detailed comparisons to similar works. It explicitly states that the paper should address the overlap with prior work on the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and that these tasks have been partially covered in prior benchmarks. The comment provides a clear action for the authors to take, which is to enhance the clarity of their contributions and comparisons with existing works. However, it does not specify which specific aspects of the methodology or purpose should be clarified or how to conduct these comparisons. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the overlap with prior work on three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and suggests that the paper should clarify its unique contributions in methodology and purpose. It provides specific guidance by recommending more detailed comparisons to similar works. However, the comment does not explicitly mention which part of the paper should include these clarifications, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the unique contributions and comparisons. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. The reviewer suggests that the paper should clarify its unique contributions and provide more detailed comparisons to similar works. While the comment identifies a potential overlap with prior work, it lacks specific references or examples of these prior benchmarks to substantiate the claim fully. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to identify and compare with the mentioned benchmarks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential overlap with prior work on three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and suggests that the paper should clarify its unique contributions in methodology and purpose. It provides a specific recommendation to include more detailed comparisons to similar works. This feedback is actionable and offers a clear direction for the authors to enhance the originality and impact of their work. However, the comment could be more helpful if it provided examples of similar works or detailed suggestions on how to present the comparisons. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and originality of their contributions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks supporting materials. However, it does not provide any explicit guidance on what kind of support materials are needed or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide supporting materials, but it remains vague because it does not specify what kind of materials are required or how to present them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of supporting materials for the statement \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"human perception is usually invariant to the texture resampling\" lacks supporting materials. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the statement \"human perception is usually invariant to the texture resampling\" lacks supporting materials in Section 1. While this feedback highlights a potential weakness in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or what kind of supporting materials would be appropriate. The comment lacks actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks supporting materials. However, it does not provide any explicit guidance on what kind of supporting materials are needed or how the authors should address this issue. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to provide supporting materials but without clear direction on what those materials should be or how to present them.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of supporting materials for the statement \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"human perception is usually invariant to the texture resampling\" lacks supporting materials. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the statement \"human perception is usually invariant to the texture resampling\" lacks supporting materials in Section 1. While this feedback highlights a potential weakness, it does not provide any guidance or suggestions on how the authors might address this issue or what kind of supporting materials would be appropriate. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out a problem but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks supporting materials. However, it does not provide any explicit guidance or suggestions on what kind of supporting materials are needed or how the authors should address this issue. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to provide supporting materials but without clear direction on what those materials should be or how to present them.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks beyond SR tasks. It explicitly recommends conducting additional experiments on a broader range of tasks to enhance the method\\'s perceived generalizability. This feedback provides a clear and direct action for the authors to take, specifying the need for additional experiments and the potential benefits of doing so. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the generality of the paper, specifically focusing on the applicability of MiPKD beyond SR tasks. It suggests that additional experiments on a broader range of tasks could enhance the method\\'s perceived generalizability. However, the comment does not explicitly mention which part of the paper discusses MiPKD\\'s performance in SR tasks, making it weakly grounded. The suggestion is specific, as it clearly outlines what the authors could do to improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that MiPKD is not specifically designed for the SR task and encourages the authors to demonstrate its applicability to other CV tasks. The claim is somewhat verifiable as it provides a logical reasoning that additional experiments on a broader range of tasks could enhance the method\\'s perceived generalizability. However, the comment lacks specific examples or references to support the claim, such as which other CV tasks could be tested or how the results would be expected to differ. This makes it challenging for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s generality, noting that MiPKD is primarily discussed in the context of SR tasks but may not be specifically designed for them. It suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks to enhance its perceived generalizability. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and improve the robustness of their method. By addressing this point, the authors can strengthen the applicability and relevance of their work across different domains. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This feedback provides a clear and explicit action for the authors to consider removing these equations. The suggestion is concrete, as it specifies exactly what should be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the specific part of the paper being addressed, providing full grounding. It also specifies the issue by suggesting that these equations may be omitted without affecting the flow of the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This claim is somewhat verifiable as it provides a logical reasoning that the equations may be redundant. However, the comment lacks specific examples or references to support the claim that these equations are not used, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it provides the authors with a concrete suggestion to simplify their draft by removing unnecessary equations. By addressing this point, the authors can improve the clarity and conciseness of their manuscript. However, the comment could be more helpful if it explained why these equations are not used or how their removal would impact the overall understanding of the section. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the optimization module uses a simple iteration strategy to optimize two loss functions and notes that the overall model seems incremental, standing on the shoulders of traditional approaches. However, it does not provide any explicit or implicit actions for the authors to take to address these observations. There is no guidance on how the authors might improve their approach or differentiate it from traditional methods. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the optimization module and its strategy for optimizing two loss functions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment also lacks specificity as it does not detail what aspects of the strategy are considered simple or incremental, nor does it provide suggestions for improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulders of traditional approaches. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the strategy is simple or incremental. Without these elements, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions, suggesting that the overall model is incremental and stands on the shoulders of traditional approaches. While it identifies a potential weakness in the originality of the approach, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing methods. The comment lacks actionable feedback, leaving the authors with only a vague understanding of the problem and no clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulders of traditional approaches. However, it does not provide any explicit or implicit actions for the authors to take to address these observations. There is no guidance on how the authors might improve their approach or differentiate it from traditional methods. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the optimization module and its strategy for optimizing two loss functions, suggesting that the overall model is incremental and stands on the shoulders of traditional approaches. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment lacks specificity as it does not provide details on what aspects of the strategy are considered simple or incremental, nor does it offer suggestions for improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulders of traditional approaches. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without these elements, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions, suggesting that the overall model is incremental and stands on the shoulders of traditional approaches. However, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing methods. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulders of traditional approaches. However, it"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper could be improved and specifically points out a confusing choice of F(X) for the E(d) case. It requests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. The suggestion to elaborate on the construction of F(X) in the main paper and provide additional examples in the appendix gives clear instructions on how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of F(X) for the E(d) case, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of F(X) and suggesting that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing of the paper could be improved, specifically mentioning a confusion regarding the choice of F(X) for the E(d) case. The reviewer requests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. While the comment identifies a potential issue, it lacks specific reasoning or examples to support the claim that the writing is unclear. The suggestion to elaborate on the construction of F(X) is a step towards improvement, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing of the paper, particularly the choice of F(X) for the E(d) case. It suggests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their work by providing more detailed explanations. However, the comment could be more helpful if it offered specific suggestions or examples of how to construct F(X) or what aspects of the construction are unclear. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the writing of the paper could be improved and specifically points out a confusing choice of F(X) for the E(d) case. It requests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This feedback is explicit and provides clear guidance on what the authors need to do to improve their draft. The suggestion to elaborate on the construction of F(X) in the main paper and provide additional examples in the appendix gives the authors concrete steps to follow. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of F(X) for the E(d) case, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of F(X) and suggesting that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing of the paper could be improved, specifically mentioning a confusing choice of F(X) for the E(d) case. It requests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. While the comment identifies a potential issue, it lacks specific reasoning or examples to support the claim that the writing is unclear. The suggestion to elaborate on the construction of F(X) is a step towards improvement, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing of the paper, particularly the choice of F(X) for the E(d) case. It suggests that the authors elaborate on how to construct F(X) in the main paper and provide additional examples in the appendix. This feedback is clear and actionable, as it directs the authors"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implicit assumptions the paper adopts to achieve successful few-shot learning. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions they should consider. The action is implicit and vague, as the authors are left to infer that they need to identify and discuss these assumptions, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions the paper adopts to achieve successful few-shot learning. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. However, the comment does not specify which part of the paper discusses these assumptions, making it weakly grounded. The authors can infer that it relates to the methodology or assumptions section, but this inference is not direct. The comment is specific in identifying the type of assumptions being questioned, but it lacks grounding in the paper\\'s structure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implicit assumptions used in the paper to achieve successful few-shot learning. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implicit assumptions the paper adopts to achieve successful few-shot learning. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. While this question prompts the authors to consider and potentially address these assumptions, it lacks specific guidance or suggestions on how to identify or address them. The comment identifies a potential area for improvement but does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks to facilitate comparison. While the comment implies specific actions, such as considering additional tasks and benchmarks, it does not explicitly instruct the authors to do so. The actions are concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models, and it recommends providing results for more standard benchmarks. However, it does not specify which part of the paper this comparison is currently lacking, making it weakly grounded. The comment is specific in its suggestions for improvement, as it outlines what additional comparisons and benchmarks could be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models, and recommends providing results for more standard benchmarks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would enhance the comparison. The reasoning is somewhat verifiable, as it points out a potential area for enhancement, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks to facilitate comparison. This feedback is clear and actionable, offering specific directions for enhancing the paper by expanding the scope of the comparison and providing a more comprehensive evaluation. By addressing these points, the authors can significantly improve the depth and relevance of their work. However, the comment could be more helpful if it included specific examples of prior work or benchmarks to consider. Overall, the feedback is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any explicit or implicit actions for the authors to take to improve the manuscript's contribution. There is no guidance on how to enhance the novelty or impact of the work, nor are there suggestions for additional experiments, analyses, or improvements to the methodology. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment suggests that the manuscript is more like an experimental discovery paper and describes the proposed method as similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or comparisons to other works, the authors may find it challenging to understand the basis of the reviewer's assessment. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides an initial observation that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it lacks depth and specificity in terms of identifying the exact weaknesses or areas for improvement. The comment does not offer actionable suggestions or detailed feedback on how the authors might enhance the contribution of their work. Without specific guidance or examples, the authors are left with limited direction on how to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any explicit or implicit actions for the authors to take to improve the manuscript's contribution. There is no guidance on how to enhance the novelty or impact of the work, nor are there suggestions for additional experiments, analyses, or improvements to the methodology. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment provides an initial observation about the manuscript's nature and the similarity of the proposed method to a traditional removal method. However, it lacks specificity and does not provide details on what aspects of the contribution are lacking or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or comparisons to other works, the authors may find it challenging to understand the basis of the reviewer's assessment. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides an initial observation that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it lacks depth and specificity, as it does not offer any constructive feedback or suggestions for improvement. Without identifying specific weaknesses or areas for enhancement, the comment does not provide the authors with actionable guidance to improve their draft. As a result, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without supporting references. However, the comment does not provide explicit guidance on how to address these issues or improve the clarity of the benefits. While it highlights areas for improvement, it lacks concrete suggestions or actionable steps for the authors to take. As a result, the authors are left to infer the necessary changes, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific benefits claimed in the paper, which allows the authors to identify the relevant sections of the paper. However, it does not explicitly mention which part of the paper these benefits are discussed in, making it weakly grounded. The comment is specific in pointing out that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without supporting references. This provides clear guidance on what needs to be addressed regarding the clarity and substantiation of the benefits. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three benefits of the paper are difficult to grasp, specifically noting that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements without supporting references. While the comment identifies specific issues with the benefits, it lacks detailed reasoning or examples to fully substantiate the claims. The absence of specific references or detailed explanations makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements without supporting references. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and substantiation of its claims. However, the comment could be more helpful if it provided specific suggestions on how to make the benefits more concrete or supported by evidence. Overall, the feedback offers some insight but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without supporting references. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity and substantiation of their claims. The feedback lacks actionable steps or detailed advice, leaving the authors to infer the necessary changes. As a result, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific benefits claimed in the paper, allowing the authors to identify the relevant sections. However, it does not explicitly mention which part of the paper these benefits are discussed in, making it weakly grounded. The comment is specific in pointing out that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without supporting references. This provides clear guidance on what needs to be addressed regarding the clarity and substantiation of the benefits. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three claimed benefits of the paper are difficult to grasp, specifically noting that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements without supporting references. While the comment identifies specific issues with the benefits, it lacks detailed reasoning or examples to fully substantiate the claims. The absence of specific references or detailed explanations makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without supporting references. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and substantiation of its claims. However, the comment could be more helpful if it provided specific suggestions on how to make the benefits more concrete or supported by evidence. While it points out the issues, it does not offer actionable guidance, limiting its usefulness. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies specific issues with the"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. However, it does not provide explicit guidance on how the authors should address this issue, such as recommending specific quantitative metrics or experiments to include. The comment also includes a conclusion about the paper's overall impact and suggests a borderline acceptance, but it does not offer actionable steps for improvement. As a result, the comment is vague and lacks explicit instructions, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. However, it does not specify which part of the paper should include these quantitative results or where the qualitative results are presented. The mention of \"Human Shape Bases Synchronization problem\" provides some grounding, but the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point questions the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. The reviewer acknowledges the qualitative results' impression but emphasizes the need for quantitative evidence. However, the comment does not provide specific examples or references to support the claim that quantitative results are necessary. This makes the claim somewhat verifiable, as it highlights a potential gap but lacks detailed justification or evidence to fully substantiate the need for quantitative results.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing quantitative evidence. However, the comment does not offer specific suggestions on how to incorporate quantitative results or what metrics should be used, leaving the authors with a general direction but no detailed guidance. Additionally, the comment includes a conclusion about the paper's overall impact and suggests a borderline acceptance, which is not directly related to the feedback on the lack of quantitative results. To be more helpful, the comment could provide more detailed guidance on how to address the issue of quantitative results. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. However, it does not provide explicit guidance on how the authors should address this issue, such as recommending specific quantitative metrics or experiments to include. The comment also includes a conclusion about the paper's overall impact and suggests a borderline acceptance, but it does not offer actionable steps for improvement. As a result, the feedback is vague and lacks explicit instructions, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. However, it does not specify which part of the paper should include these quantitative results or where the qualitative results are presented. The mention of \"Human Shape Bases Synchronization problem\" provides some grounding, but the comment lacks specificity in detailing what needs to be addressed or improved. As a result, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim that quantitative results are necessary. The mention of \"the only substantial negative is the limited impact of the approach\" provides a general critique but lacks detailed justification or evidence. This makes the claim somewhat verifiable, as it points out an area for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, suggesting that the qualitative results may not fully convey the effectiveness of the approach. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing quantitative evidence. However, the comment does not offer specific suggestions on how to incorporate quantitative results or what metrics should be used,"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the categorization of the paper under Fairness/Accountability/Transparency. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify the categorization, provide additional context, or make changes to the categorization. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency section. However, it does not specify which part of the paper this categorization is based on or where the confusion lies. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention or clarification. Additionally, the comment lacks specificity regarding what exactly is missing or unclear about the categorization. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the categorization of the paper under the Fairness/Accountability/Transparency section. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency section. While it highlights a potential oversight or confusion, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue or clarify the categorization. As a result, the comment is not helpful at all, as it does not offer any actionable steps for the authors to take to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a machine learning 2-step baseline to better understand the improvement over the heuristic methods. This feedback provides a clear and explicit action for the authors to take, which is to incorporate a specific type of baseline. The suggestion is concrete, as it specifies the type of baseline that should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the comparison of the proposed method, NaviFormer, with baselines, specifically noting that all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to better understand the improvement over the heuristic methods. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting a particular type of baseline to consider, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement in the proposed method, NaviFormer, could be due to the different class of algorithm rather than the authors\\' assertion that it tackles the routing and path planning problem jointly. The comment suggests including a machine learning 2-step baseline to better understand the improvement. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the improvement is solely due to the class of algorithm. This makes the claim somewhat verifiable, as it provides a direction for further exploration but requires additional evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of the proposed method, NaviFormer, by pointing out that all compared approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to better understand the improvement over the heuristic methods. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the evaluation by incorporating a more sophisticated baseline. However, the comment could be more helpful if it offered additional guidance on how to implement this baseline or discussed the potential implications of such an addition. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their evaluation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a fair comparison by applying the planning and layering method to the design images generated by other image generative models. This feedback provides a clear and explicit action for the authors to take, which is to conduct a specific comparison to clarify the reasons behind the better results. The suggestion is concrete, as it specifies the exact method to be applied, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the results section, specifically questioning whether the better results are due to a better image generative model. It suggests conducting a fair comparison by applying the planning and layering method to design images generated by other image generative models. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improving the comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the results, suggesting that the better performance might be due to a better image generative model rather than the planning and layering method. The reviewer recommends conducting a fair comparison by applying the method to images generated by other models. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the results are solely due to the image generative model. The suggestion for a fair comparison is logical, but the claim itself remains somewhat vague without detailed evidence or examples. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of the results, suggesting that the better performance might be due to a better image generative model rather than the planning and layering method. It provides a clear and actionable suggestion by recommending a fair comparison, specifically by applying the planning and layering method to design images generated by other image generative models. This feedback is valuable as it guides the authors to conduct a more comprehensive evaluation of their method, potentially leading to a more robust conclusion. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include a comparative study with state-of-the-art (SOTA) methods, such as those mentioned by the reviewer, to provide a more comprehensive evaluation of their proposed method. The comment also questions the validity of the authors\\' claim regarding the exploitation of information from modality-missing data due to the lack of comparison with SOTA methods. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with SOTA methods to strengthen their claims. The explicit nature of the suggestion and the detailed guidance on how to address the issue make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison of the proposed method with simpler baselines like zero padding and suggests including state-of-the-art (SOTA) methods for a more comprehensive comparison. It also references specific works such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), providing clear guidance on what needs to be addressed. The comment is specific in detailing what is missing in the comparative study and why the authors\\' claim is not justified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study is insufficient because it only includes relatively simpler baselines like zero padding, while it should also include state-of-the-art (SOTA) methods. The reviewer provides specific examples of SOTA methods, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), which supports the claim. This detailed list of SOTA methods provides a robust basis for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the comparative study of the proposed method, noting that it only includes relatively simpler baselines like zero padding. It suggests that the comparison should include state-of-the-art (SOTA) methods, such as those mentioned by the reviewer, to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their comparative analysis to strengthen their claims. By including SOTA methods, the authors can better justify their assertion about the effectiveness of their method. The comment is mostly helpful as it provides a specific direction for improvement, although it could be more helpful if it offered additional guidance on how to integrate these SOTA methods into the study. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusing aspect of the discussion regarding the dataset, specifically mentioning lines 329-334. It points out that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The reviewer suggests that if these elements are not relevant, they should not be included in the discussion. This feedback provides a clear and explicit action for the authors to take, which is to clarify or remove the irrelevant information. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 329-334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is the confusion regarding the task description and the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that if these elements are not relevant to the experiments, they should not be included, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, particularly regarding the task description. The reviewer suggests that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The comment provides a logical reasoning for the confusion, suggesting that if these elements are not relevant, they should be removed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of these elements themselves, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion of the dataset, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these elements are not relevant to the experiments, they should be removed. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and focus of the discussion. By addressing this point, the authors can enhance the coherence and relevance of their paper. However, the comment could be more helpful if it offered additional guidance on how to integrate the relevant information or suggested ways to clarify the discussion. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the discussion of the dataset, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The reviewer suggests that if these elements are not relevant, they should not be included in the discussion. This feedback provides a clear and explicit action for the authors to take, which is to clarify or remove the irrelevant information. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 329-334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is the confusion regarding the task description and the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that if these elements are not relevant to the experiments, they should not be included, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, particularly regarding the task description. The reviewer suggests that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may not be relevant to the experiments. The comment provides a logical reasoning for the confusion, suggesting that if these elements are not relevant, they should be removed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of these elements themselves, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count. It suggests that the authors should provide the number of parameters in the group CapNet to assess the benefit of enforcing equivariance. However, the comment does not explicitly instruct the authors to include this information, and it lacks concrete guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide parameter counts but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment continues a previous discussion, which suggests that the authors are unnecessarily restricting the capsule networks. It points out that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, which affects the judgment of the benefit of enforcing equivariance. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the lack of parameter count and the potential impact on judgment, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count provided. The reviewer suggests that this lack of information hinders the judgment of the benefit of enforcing equivariance. However, the comment does not provide specific reasoning or evidence to support why the restriction is unnecessary or how the parameter count would affect the judgment. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment continues a previous discussion about the potential unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count provided. It highlights a specific issue with the experiments, noting that the authors do not provide the number of parameters in the group CapNet, which affects the judgment of the benefit of enforcing equivariance. This feedback is somewhat helpful as it identifies a gap in the experimental analysis and suggests that the authors should provide the parameter count to better assess the impact of their approach. However, the comment could be more helpful if it offered specific suggestions on how to present this information or discussed the implications of the lack of parameter count. Overall, the comment provides some actionable insight but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the potential unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count provided. It suggests that the authors should provide the number of parameters in the group CapNet to assess the benefit of enforcing equivariance. However, the comment does not explicitly instruct the authors to include this information, and it lacks specific guidance on how to present the parameter count or what specific aspects to focus on. The action is implicit and somewhat vague, making it somewhat actionable. The authors can infer that they need to provide parameter counts, but the lack of detailed instructions limits the clarity and effectiveness of the feedback.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment continues a previous discussion about the potential unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count provided. It highlights a specific issue with the experiments, noting that the authors do not provide the number of parameters in the group CapNet, which affects the judgment of the benefit of enforcing equivariance. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the lack of parameter count and the potential impact on judgment, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential unnecessary restriction of capsule networks due to the depth of the group CapNet and the lack of parameter count provided. It suggests that the authors should provide the number of parameters in the group CapNet to assess the benefit of enforcing equivariance. However, the comment lacks specific reasoning or evidence to support why the restriction is unnecessary or how the parameter count would affect the judgment. The absence of detailed justification or examples makes it difficult for the authors to fully understand and address the concern. Therefore,"}
{"generated_text": "{'actionability_rationale': \"The review point acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and mentions that this issue has been addressed before in various approaches, such as DiME and FastDiME. It also references [He et al.] for more efficient implementations of the Tweedie approach. However, the comment does not provide explicit guidance or suggestions for the authors to address this challenge in their work. It lacks actionable steps or specific advice on how to incorporate these approaches or improve their own method. As a result, the authors are left without clear direction on how to apply this information to enhance their draft. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenge of obtaining meaningful gradients with respect to noisy images and references specific approaches like DiME, FastDiME, and [He et al.] that address this issue. The comment provides clear guidance on what needs to be addressed, namely the comparison or incorporation of these approaches into the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and references existing approaches like DiME and FastDiME, as well as [He et al.], which have more efficient implementations of the Tweedie approach. This provides a logical basis for the claim by referencing established methods and their implementations. However, the comment could be strengthened by providing more detailed comparisons or examples of how these approaches address the challenge, which would enhance its verifiability. As it stands, the claim is mostly verifiable, as it offers a reasonable basis for the assertion but lacks comprehensive detail. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and references existing approaches like DiME and FastDiME, as well as [He et al.], which have more efficient implementations of the Tweedie approach. This feedback is somewhat helpful as it provides the authors with a starting point for addressing the challenge by highlighting relevant literature and approaches. However, the comment could be more helpful if it offered specific suggestions or guidance on how to incorporate these approaches or improve their own method. Without actionable advice or detailed insights, the authors may find it challenging to fully leverage this information to enhance their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and references existing approaches like DiME, FastDiME, and [He et al.] that address this issue. However, it does not provide explicit guidance or suggestions for the authors on how to incorporate or improve upon these approaches in their work. The comment lacks actionable steps or concrete details on how to apply the referenced approaches to address the challenge. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenge of obtaining meaningful gradients with respect to noisy images and references specific approaches like DiME, FastDiME, and [He et al.] that address this issue. The comment provides clear guidance on what needs to be addressed, namely the comparison or incorporation of these approaches into the paper. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and references existing approaches like DiME, FastDiME, and [He et al.] that address this issue. This provides a logical basis for the claim by referencing established methods and their implementations. However, the comment could be strengthened by providing more detailed comparisons or examples of how these approaches address the challenge, which would enhance its verifiability. As it stands, the claim is mostly verifiable, as it offers a reasonable basis for the assertion but lacks comprehensive detail. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges a challenge related to obtaining meaningful gradients with respect to noisy images and references existing approaches like DiME, FastDiME, and [He et al.] that"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include an evaluation of inference speed on the hardware. This is a clear and direct action for the authors to take, providing them with a specific task to improve their draft. The comment is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including an evaluation of inference speed on the hardware, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including an evaluation of inference speed on the hardware would be beneficial. However, it does not provide any reasoning, examples, or references to support why this evaluation is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include an evaluation of inference speed on the hardware. This feedback is clear and actionable, as it provides a specific area for improvement that can enhance the comprehensiveness of the paper. By addressing this suggestion, the authors can provide additional insights into the practical implications of their work, which could be valuable for readers and reviewers. However, the comment could be more helpful if it included specific guidance on how to conduct this evaluation or why it is particularly important. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the lack of an SDP formulation for the modified problem described as convex. It implies that the authors should provide the SDP formulation to support their claim. While the comment does not explicitly instruct the authors to include the SDP formulation, it is clear that the authors need to address this omission. The action is implicit but concrete, as the authors know they need to provide the SDP formulation to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of an SDP formulation for the modified problem described as convex. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of an SDP formulation for a problem described as convex. However, it does not provide any supporting evidence, reasoning, or references to justify why the SDP formulation is necessary or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this omission. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out that the modified problem described as convex should be solved via an SDP, but the SDP formulation is missing. This feedback is clear and actionable, as it directly instructs the authors to include the SDP formulation to support their claim. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively present the SDP formulation. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out two specific issues: the lack of information on the number of new task combinations used to evaluate compositional generalizability in line 558, and the limited number of composite instructions in Table 7. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more details about the task combinations and the number of composite instructions used, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of information regarding the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it impacts the evaluation. Without additional context or explanation, the authors may find it challenging to understand the significance of these omissions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of information on the number of new task combinations used to evaluate compositional generalizability, and the limited number of composite instructions in Table 7. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the transparency and comprehensiveness of their evaluation. However, the comment could be more helpful if it suggested ways to address these issues, such as recommending additional experiments or providing more detailed analysis. Overall, the comment is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, is not well-formatted. However, it does not provide specific guidance on how to improve the layout or what aspects of the formatting are problematic. Without concrete suggestions or examples, the authors are left without clear direction on how to address the issue. The lack of actionable details makes it difficult for the authors to know what changes to make to improve the layout. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, particularly the figures, is not well-formatted. However, it does not specify which figures are problematic or provide details on what aspects of the layout are not satisfactory. Without explicit references to specific sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what constitutes a \"good layout\" or how the figures could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-formatted. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what constitutes a \"good layout,\" the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a general issue with the formatting of the paper, specifically mentioning that the figures are not well-formatted. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the layout or what aspects of the formatting are problematic. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment points out that the paper, particularly the figures, is not well-formatted. However, it does not provide specific guidance on how to improve the layout or what aspects of the formatting are problematic. Without concrete suggestions or examples, the authors are left without clear direction on how to address the issue. This lack of actionable information makes the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, particularly the figures, is not well-formatted. However, it does not specify which figures are problematic or provide details on what aspects of the formatting are not satisfactory. Without explicit references to specific sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what constitutes a \"good layout\" or how the figures could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-formatted. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is difficult for the authors to understand which aspects of the formatting are problematic or how to improve them. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a general issue with the formatting of the paper, specifically mentioning that the figures are not well-formatted. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the layout or what aspects of the formatting are problematic. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment points out that the paper, particularly the figures, is not well-formatted. However, it does not provide specific guidance or suggestions on how to improve the layout or what aspects of the formatting are problematic. Without actionable details, the authors are left without a clear understanding of what changes to make to improve the layout. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, particularly the figures, is not well-formatted. However, it does not specify which figures are problematic or provide details on what aspects of the formatting are not satisfactory. Without explicit references to specific sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what constitutes a \"good layout\" or how the figures could be improved. As a result, the comment is not"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the paper's contributions being perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should differentiate their work from existing works and conduct a detailed comparison, but it lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment highlights a concern about the paper's contributions being perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, it does not specify which parts of the paper should include this differentiation or comparison, making it weakly grounded. The comment is specific in identifying the issue of perceived novelty and the need for detailed comparisons, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. This claim is somewhat verifiable as it logically suggests that the absence of such differentiation and comparison could lead to a perceived lack of novelty. However, the comment lacks specific examples or references to existing works that could be compared to the paper's contributions, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's contributions, noting that without clear differentiation from existing works and detailed comparisons with similar techniques, the paper may be perceived as incremental or lacking substantial novelty. This is a significant concern for the authors, as it could impact the reception and perceived value of their work within the NLP community. The comment highlights a key area for improvement, which is crucial for the authors to address in order to enhance the impact and originality of their work. However, the comment could be more helpful by providing specific suggestions on how to differentiate the work or what aspects should be compared to existing techniques. Overall, the feedback is somewhat helpful as it points out a significant issue but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a concern about the paper's contributions being perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should differentiate their work from existing works and conduct detailed comparisons, but it lacks concrete steps or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment highlights a concern about the paper's contributions being perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. However, it does not specify which parts of the paper should include this differentiation or comparison, making it weakly grounded. The comment is specific in identifying the issue of perceived novelty and the need for detailed comparisons, but without explicit references to sections or elements of the paper, the authors may struggle to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparisons with similar techniques. This claim is somewhat verifiable as it logically suggests that the absence of such differentiation and comparison could lead to a perceived lack of novelty. However, the comment lacks specific examples or references to existing works that could be compared to the paper's contributions, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's contributions, noting that without clear differentiation from existing works and detailed comparisons with similar techniques, the paper may be perceived as incremental or lacking substantial novelty. This is a significant concern for the authors, as it could impact the reception and perceived value of their work within the NLP community. The comment highlights a key area for improvement, which is crucial for the authors to address in order to enhance the impact and originality of their work. However, the comment could be more helpful"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to explain the difference between the baseline results in Table 2 and those from Table 3 in [3]. This is a clear and direct request, providing the authors with a specific action to take\u2014namely, to provide an explanation for the discrepancy. The comment is explicit and concrete, as it clearly identifies what needs to be done and how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the difference between the baseline results in Table 2 and those from Table 3 in [3]. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the differences between baseline results in two tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests an explanation for the differences between the baseline results in Table 2 and those from Table 3 in [3]. This is a specific and actionable piece of feedback that prompts the authors to clarify a discrepancy in their results, which could be crucial for understanding the validity and reliability of their findings. By addressing this question, the authors can provide additional context or justification for their results, enhancing the transparency and robustness of their work. However, the comment could be more helpful if it suggested how the authors might investigate or present this information in their paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue with the use of 'execution feedback' in the paper, pointing out that it is misleading because no execution feedback signal is actually used. The reviewer explains that execution feedback is approximated based on structural perturbations in the AST and clarifies the misunderstanding in the definition of execution feedback (EF) in Equation 1. The comment provides concrete examples and references specific lines (233-238) to help the authors understand the issue. However, it does not offer explicit guidance on how to address this issue, such as suggesting alternative terminology or clarifying the definition. The action is implicit but concrete, as the authors can infer the need to revise the terminology and clarify the definition. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the definition of execution feedback, explaining that it is approximated based on structural perturbations in the AST and clarifying the misunderstanding in the definition of EF in Equation 1. The comment provides specific details about the problem, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading because no execution feedback signal is actually used in the work. The reviewer provides a detailed explanation of the misunderstanding, stating that execution feedback is approximated based on structural perturbations in the AST and clarifying the definition of execution feedback (EF) in Equation 1. The comment is supported by specific references to lines 233-238 and the definition of EF, which helps the authors understand the issue. This level of detail and logical reasoning makes the claim mostly verifiable, as it provides a clear explanation of the misunderstanding and its implications. However, it could be further strengthened with additional references or examples to fully substantiate the claim. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed critique of the use of the term 'execution feedback' in the paper, explaining that it is misleading because no execution feedback signal is actually used. The reviewer clarifies that execution feedback is approximated based on structural perturbations in the AST and points out a misunderstanding in the definition of execution feedback (EF) in Equation 1. The comment also highlights a potential issue with the assumption that any perturbation results in a failure, as there is no guarantee that such perturbations will make the tests fail. This feedback is clear and actionable, as it identifies specific areas of confusion and provides a basis for the authors to revise their terminology and clarify their methodology. However, it could be more helpful if it offered suggestions on how to address these issues or provided alternative terminology. Overall, the comment is mostly helpful, as it effectively guides the authors in improving the clarity and accuracy of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where additional information is needed, specifically regarding the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also mentions a lack of detail on how many games are sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas that require clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more details, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias. It also specifies the lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of information regarding the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also questions the details regarding the number of games sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas where additional information is needed, it does not provide any supporting evidence or references to substantiate these claims. The lack of detailed reasoning or examples makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it highlights areas for improvement but lacks sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity and detail, particularly regarding the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also points out a lack of information on how many games are sampled to demonstrate the severity of the bias problem. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to important aspects that need clarification, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies specific areas where additional information is needed, such as the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also mentions a lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. While the comment highlights these areas, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on how to do so. Therefore, the feedback is somewhat actionable, as it points out areas for improvement but does not offer specific steps for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also specifies the lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of information regarding the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also questions the details regarding the number of games sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas where additional information is needed, it does not provide any supporting evidence or references to substantiate these claims. The lack of detailed reasoning or examples makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity and detail, particularly regarding the use of \"40 target words\" and the role of \"a sequence of dots\" in removing bias in the model. It also points out a lack of information on how many games are sampled to demonstrate the severity of the bias problem. While the comment highlights important areas for improvement, it"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their experiments. There is no guidance on whether the authors should consider using more realistic datasets, different types of missing data, or any specific actions to enhance the validity of their experiments. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in pointing out the issues with the datasets and the missing data method, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these claims and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. While it identifies potential weaknesses in the experimental setup, it lacks specific suggestions or guidance on how the authors might address these issues or improve their experiments. The comment highlights areas for consideration but does not provide actionable feedback, making it somewhat helpful. The authors are given some insight into potential limitations of their work but are not directed on how to enhance their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 lacks legends, which makes it difficult to interpret the plots. It suggests that including what each data point or plot corresponds to would improve the figure\\'s interpretability. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to enhance the figure. The comment is explicit and concrete, offering a specific solution that the authors can easily implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of legends for the plots, making it difficult to interpret. The comment suggests a clear solution by recommending the inclusion of what each data point or plot corresponds to. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends, making it difficult to interpret the plots. The comment suggests that including what each data point or plot corresponds to would improve interpretability. While the claim is logical, it lacks specific examples or references to support the assertion that the lack of legends is a significant issue. The suggestion to include legends is a reasonable one, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends, which makes the plots difficult to interpret. It provides a clear and actionable suggestion by recommending the inclusion of what each data point or plot corresponds to. This feedback is valuable as it guides the authors on how to improve the clarity and interpretability of their figures, which is crucial for enhancing the overall understanding of the paper. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate legends or suggested specific information to include. Despite this, the feedback is mostly helpful as it provides a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper specifically addresses sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models. It also asks if there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models and requests that the authors highlight this if it exists. While the comment implies that the authors should clarify or highlight any specific aspects related to sequence-to-sequence models, it does not provide explicit instructions or concrete steps on how to address these points. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific concern of the paper with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models. It also asks if there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models and requests that the authors highlight this if it exists. However, the comment does not specify which part of the paper should address these questions, making it weakly grounded. The comment is specific in its request for clarification and highlighting potential benefits, but without explicit references to sections or elements of the paper, the authors may struggle to identify where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the applicability of the proposed method to sequence-to-sequence models and the specific benefits of the robustness-aware quantization scheme. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific concern of the paper with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models. It also asks if there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models and requests that the authors highlight this if it exists. This feedback is somewhat helpful as it prompts the authors to clarify the scope and applicability of their work, which could lead to a more focused presentation. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or improve their draft. To be more helpful, the comment could include specific areas or aspects of the paper that need clarification or examples of how to highlight the benefits of the proposed method for sequence-to-sequence models. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about whether the paper specifically addresses sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models. It also asks if there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models and requests that the authors highlight this if it exists. While the comment identifies areas for clarification and improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific concern of the paper with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models. It also asks if there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models and requests that the authors highlight this if it exists. However, the comment does not specify which part of the paper should address these questions, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its request for clarification and highlighting potential benefits, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the applicability of the proposed method to sequence-to-sequence models and the specific benefits of the robustness-aware quantization scheme. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific concern of the paper with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This is an explicit request for additional analysis, and it provides a clear action for the authors to take. However, the comment does not specify how to conduct this ablation or what specific aspects should be focused on, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a clear action but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This provides clear guidance on what additional analysis or discussion is needed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. However, it does not contain an opinion, judgment, or suggestion that requires verification. It is a request for additional analysis, which is factual and descriptive in nature. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This feedback is clear and actionable, as it directs the authors to conduct additional analysis that could enhance the understanding of their algorithm\\'s performance. However, the comment could be more helpful if it provided examples of what kind of ablation studies would be beneficial or how to structure the analysis. Despite this, the feedback is mostly helpful as it offers a concrete direction for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model and whether it is trained from scratch. While it implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question or what additional information should be provided. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the base encoder of the proposed model and whether it is trained from scratch. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this information should be included. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the base encoder, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the base encoder of the proposed model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the base encoder of the proposed model, asking whether it is trained from scratch or if there is a specific base encoder used. While this question is relevant to understanding the methodology, the comment lacks depth and does not provide any guidance or suggestions for improvement. It does not offer insights into why this information is important or how it might impact the paper\\'s conclusions or contributions. As a result, the feedback is barely helpful, as it highlights a potential area of clarification but does not assist the authors in addressing it effectively. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Ethical Statement should be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to address these challenges or what aspects should be included. The action is implicit and somewhat vague, as the authors know they need to expand the discussion but may not be entirely sure of the exact content to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests extending the discussion to include challenges related to gender beyond the binary, races other than Black, and other sources of social bias. This provides clear guidance on what additional content could be included to enhance the discussion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Ethical Statement could be improved by discussing challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment identifies specific areas for improvement, it lacks detailed examples or references to support the claim that these challenges are not adequately addressed. The suggestion is somewhat verifiable, as it provides a general direction for improvement but requires more specific guidance to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the Ethical Statement is well-written but suggests that it could be improved by expanding the discussion to include challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their ethical considerations. By addressing these points, the authors can improve the comprehensiveness and relevance of their ethical analysis. However, the comment could be more helpful if it offered examples or guidance on how to incorporate these discussions into the Ethical Statement. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation of variables from $$\\\\hat{m}_t$$ and $$g_t$$ in equation (13) to $$x$$ in equation (14). While it highlights a potential issue with clarity, it does not provide explicit guidance on how the authors should address this problem. The comment implies that the authors should clarify the transformation process, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the transformation of variables from $$\\\\hat{m}_t$$ and $$g_t$$ to $$x$$, indicating a need for clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the transformation of variables in equations (13) and (14), seeking clarification. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the transformation of variables from $$\\\\hat{m}_t$$ and $$g_t$$ in equation (13) to $$x$$ in equation (14). This is a relevant point that could impact the clarity and understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the equations. While it highlights a potential area for improvement, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the mini-batch size, noting that it may be non-integers and suggesting that this should be clarified to avoid any side effects. The reviewer asks a specific question about what happens if the mini-batch size is extremely small ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the concern or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and consider the implications of a small mini-batch size. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the mini-batch size, noting that it may be non-integers and suggesting that this should be clarified to avoid potential side effects. It raises a question about what happens if the mini-batch size is extremely small ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where mini-batch sizes are discussed. The comment is specific in detailing the issue and the potential implications, providing clear guidance on what needs to be clarified. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential issue of non-integer mini-batch sizes, suggesting that this should be clarified to avoid side effects. The reviewer asks a specific question about the implications of a very small mini-batch size ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. While the comment highlights a potential issue, it lacks specific examples or references to support the claim or provide a basis for the concern. The reasoning is somewhat verifiable, as it points out a potential problem but does not fully substantiate it with detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mini-batch size, noting that it may be non-integers and suggesting that this should be clarified to avoid potential side effects. It raises a pertinent question about the implications of a very small mini-batch size ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and consider the implications of their choices. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered examples of potential side effects. Overall, the comment is mostly helpful as it directs the authors to an important area for clarification and consideration, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a potential issue with the mini-batch size, noting that it may be non-integers and suggesting that this should be clarified to avoid any side effects. It raises a specific question about what happens if the mini-batch size is extremely small ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or detailed guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and consider the implications of a small mini-batch size. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the mini-batch size, noting that it may be non-integers and suggesting that this should be clarified to avoid potential side effects. It raises a question about the implications of a very small mini-batch size ($\\\\tau_t << 1$) and questions the validity of the analysis in such cases. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where mini-batch sizes are discussed. The comment is specific in detailing the issue and the potential implications, providing clear guidance on what needs to be clarified. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential issue of non-integer mini-batch sizes and suggests that this should be clarified to avoid side effects. It questions the validity of the analysis if the mini-batch size is extremely small ($\\\\tau_t << 1$"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. While the comment identifies a critical aspect that needs attention, it does not provide explicit guidance on how to conduct this examination or what specific metrics or analyses should be considered. The action is implicit, as the authors can infer that they need to analyze the computational cost, but it remains vague without concrete steps or suggestions on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the inference cost of the SCALE model, specifically mentioning the involvement of two types of decoding: STM decoding and LLM decoding. This provides a clear indication of the part of the paper being addressed, making it fully grounded. The comment also specifies what needs to be examined\u2014computational cost associated with the inference process of the SCALE model. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. While the comment identifies a relevant aspect of the model, it does not provide specific reasoning or evidence to support why this examination is crucial. The claim is somewhat verifiable as it points out a potential area for improvement, but it lacks detailed justification or examples to fully substantiate the need for this examination. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the need to examine the computational cost associated with the inference process of the SCALE model. It points out that the model involves two types of decoding: STM decoding and LLM decoding, and emphasizes the importance of analyzing the computational cost. This feedback is clear and actionable, as it directs the authors to consider a crucial aspect of their model that could impact its practical application and efficiency. However, the comment could be more helpful if it provided additional guidance or suggested methods for conducting this analysis. Overall, the comment is mostly helpful as it effectively directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of performance comparisons with state-of-the-art models and the presence of peculiar experimental results. While it identifies these areas as needing attention, it does not provide explicit guidance on how to address them. The authors are left to infer that they should include performance comparisons and possibly explain or rectify the peculiar results. However, the comment lacks concrete steps or suggestions on how to implement these changes, making the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues, such as the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, particularly the unsupervised result outperforming the supervised result in the 5th row of Table 2. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of performance comparisons with state-of-the-art models and the presence of peculiar experimental results. The claim about the unsupervised result outperforming the supervised result in Table 2 is specific and highlights a potential issue with the experimental setup. However, the comment does not provide detailed reasoning or references to support why this is problematic or how it affects the paper\\'s conclusions. The lack of explicit justification or examples makes it somewhat verifiable, as the authors would need to further explore and address these concerns themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of performance comparisons with state-of-the-art models and the presence of peculiar experimental results. The first point highlights the need for broader comparisons to demonstrate the effectiveness of the proposed methods, which is crucial for validating the paper\\'s claims. The second point about the peculiar results, such as the unsupervised result outperforming the supervised result, suggests that the authors should investigate and possibly explain these findings. While the comment effectively points out areas for improvement, it lacks specific guidance or suggestions on how to address these issues. Therefore, the feedback is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed direction for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the phrase \"lacks inherent semantic meaning\" is used without further elaboration. However, it does not provide any guidance on what specific elaboration is needed or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more explanation, but it is vague because it lacks concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to a specific phrase, \"lacks inherent semantic meaning,\" which provides some grounding as it allows the authors to identify the part of the paper being addressed. However, it does not specify what aspect of this phrase is problematic or how it could be elaborated upon. Without further details or suggestions, the comment lacks specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the phrase \"lacks inherent semantic meaning\" is used without further elaboration. However, it does not provide any supporting evidence or reasoning to justify why this is a concern or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the phrase \"lacks inherent semantic meaning,\" noting that it is used without further elaboration. However, it does not provide any guidance or suggestions on how the authors might clarify or expand on this concept. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out that treating unobserved ratings as zeros may introduce bias, which is not justified. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the use of a large number of hidden units, an additional elementwise function, and the treatment of unobserved ratings as zeros. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing sufficient details and justification for these choices and addressing the potential bias introduced by treating unobserved ratings as zeros. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of a large number of hidden units and an additional elementwise function, as well as the treatment of unobserved ratings as zeros. The claim is somewhat verifiable as it highlights specific issues that need clarification or justification. However, it lacks detailed reasoning or references to support why these choices might be problematic or biased. The authors would need to further explore and address these concerns to fully understand and respond to the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several specific issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out a potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment highlights important areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors' attention to critical aspects of their methodology that need clarification and justification. However, it lacks actionable steps or specific recommendations, which would make it more beneficial for the authors. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the robustness of the motivation claim, noting that MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, but this accuracy can be achieved with 100% accuracy using other tools. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their motivation claim. There is no guidance on potential modifications, additional experiments, or alternative explanations that could strengthen the motivation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on the constructed dataset for complex computations. It points out that while MathGLM achieves a high accuracy of 93.03%, other tools can achieve 100% accuracy. However, the comment does not specify which part of the paper this claim is made in, such as a particular section or paragraph, making it weakly grounded. The comment is specific in identifying the issue with the robustness of the motivation claim, but without clear grounding, the authors may struggle to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the robustness of the motivation claim by pointing out that MathGLM\\'s high accuracy of 93.03% on the constructed dataset for complex computations can be achieved with 100% accuracy using other tools. This claim is somewhat verifiable as it provides a logical reasoning by comparing the accuracy of MathGLM with other tools. However, the comment lacks specific examples or references to these other tools, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the robustness of the motivation claim by pointing out that while MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, other tools can achieve 100% accuracy. This feedback highlights a potential weakness in the paper\\'s argument and prompts the authors to reconsider or strengthen their motivation claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their motivation. While it identifies a problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on the constructed dataset for complex computations, noting that other tools can achieve 100% accuracy. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their motivation claim. Without actionable guidance or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on the constructed dataset for complex computations. It points out that while MathGLM achieves a high accuracy of 93.03%, other tools can achieve 100% accuracy. However, the comment does not specify which part of the paper this claim is made in, such as a particular section or paragraph, making it weakly grounded. The comment is specific in identifying the issue with the robustness of the motivation claim, but without clear grounding, the authors may struggle to pinpoint where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the robustness of the motivation claim by pointing out that while MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, other tools can achieve 100% accuracy. This critique is somewhat verifiable as it provides a logical reasoning by comparing the accuracy of MathGLM with other tools. However, the comment lacks specific examples or references to these other tools, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the robustness of the motivation claim by pointing out that while MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, other tools can achieve "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluation does not truly reflect event-based dense tracking. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their approach. There is no guidance on potential modifications, alternative datasets, or methodologies that could be explored to better align with event-based dense tracking. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the reliance on synthetic datasets for evaluating event-based optical flow in real-world settings, which is a significant weakness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem of not truly reflecting event-based dense tracking, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that relying on synthetic datasets for evaluation does not truly reflect event-based dense tracking, which is a significant weakness. However, the comment lacks specific examples or references to support this claim, such as alternative datasets or methods that could better align with event-based dense tracking. Without these details, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluation does not truly reflect event-based dense tracking. This is a critical point that the authors need to address to strengthen their work. However, the comment lacks specific suggestions or guidance on how the authors might overcome this limitation or improve their approach. While it highlights an important issue, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of clarity in the paper's motivation and suggests that the experiments are weak due to limited dataset and LLM size. It implies that the results may be unconvincing and potentially misleading if not thoroughly validated. However, the comment does not provide explicit guidance on how to address these issues or improve the motivation or experimental design. The authors are left to infer that they need to strengthen their motivation and experimental setup, but without specific suggestions, the action remains vague. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the motivation of the paper and the experiments conducted, specifically mentioning the limited dataset and LLM size. It highlights a potential issue with the paper's opposition to the common understanding of the importance of diversity in instruction-tuning data. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the concerns about the experiments and their potential impact on the community, but without clear references to specific parts of the paper, the authors may struggle to identify where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the motivation of the paper is unclear and that the experiments are weak due to limited dataset and LLM size. The reviewer supports this claim by referencing the widely recognized importance of diversity in instruction-tuning data and suggesting that the paper contradicts this understanding without strong justification. The comment also mentions that the results are unconvincing and could potentially mislead the community if not thoroughly validated. However, the comment lacks specific examples or references to substantiate the claim about the limited dataset and LLM size, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, thus justifying a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's motivation, suggesting that it contradicts the widely recognized importance of ensuring diversity in instruction-tuning data. The reviewer points out that the experiments are weak due to limited dataset and LLM size, which could lead to unconvincing results. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to strengthen their motivation and experimental design. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or improve the paper's impact. Overall, the comment is somewhat helpful as it directs the authors' attention to a crucial aspect of their work that needs attention, but it lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a lack of clarity in the paper's motivation and suggests that the experiments are weak due to limited dataset and LLM size. It also mentions that the results are unconvincing and potentially misleading if not thoroughly validated. However, the comment does not provide specific guidance or suggestions on how the authors can address these issues or improve their motivation and experimental design. The feedback lacks actionable steps or detailed advice, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the motivation of the paper and the experiments conducted, specifically mentioning the limited dataset and LLM size. It highlights a potential issue with the paper's opposition to the common understanding of the importance of diversity in instruction-tuning data. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is somewhat specific in detailing the concerns about the experiments and their potential impact on the community, but without clear references to specific parts of the paper, the authors may struggle to identify where improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the motivation of the paper is unclear and that the experiments are weak due to limited dataset and LLM size. It supports this claim by referencing the widely recognized importance of diversity in instruction-tuning data and suggesting that the paper contradicts this understanding without strong justification. The reviewer also mentions that the results are unconvincing and could potentially mislead the community if not thoroughly validated. However, the comment lacks specific examples or references to substantiate the claim about the limited dataset and LLM size, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, justifying a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of confidence intervals on the substitution ASR in Table 3. While it highlights an area that may require attention, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors can infer that they might need to include confidence intervals, but the comment lacks concrete instructions on how to implement this change. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of confidence intervals on the substitution ASR. This provides clear guidance on what the authors need to consider or address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the absence of confidence intervals on the substitution ASR in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 3, noting the absence of confidence intervals on the substitution ASR. This is a relevant point that could impact the interpretation and reliability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of confidence intervals or alternative methods for assessing variability. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity regarding how to estimate the mean element \\( \\\\mu_g \\) for different kernel spaces. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify this aspect, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the estimation process for \\( \\\\mu_g \\), but without clear grounding, the authors may struggle to pinpoint where this issue is discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of estimating the mean element \\( \\\\mu_g \\) for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand and resolve the problem. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of confusion regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces. This is a relevant point that could impact the clarity and understanding of the paper. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the explanation. While it points out a potential weakness, it does not offer actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces, indicating a lack of clarity. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the explanation. The comment implies that the authors need to clarify this aspect, but without concrete steps or examples, the action remains vague. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the estimation process for \\( \\\\mu_g \\), but without clear grounding, the authors may struggle to pinpoint where this issue is discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of estimating the mean element \\( \\\\mu_g \\) for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand and resolve the problem. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of confusion regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces. This is a relevant point that could impact the clarity and understanding of the paper. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the explanation. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment identifies a specific issue regarding the estimation of the mean element \\( \\\\mu_g \\) for different kernel spaces, indicating a lack of clarity. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the explanation. The comment implies that the authors need to clarify this aspect, but without concrete steps or examples, the action remains vague. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue regarding the estimation of the mean"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, would make the story more complete. While the comment implies that the authors should include such datasets in their analysis, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these datasets. The action is implicit and somewhat vague, as the authors need to infer that they should expand their dataset analysis to include larger clusters. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its suggestion to include larger datasets but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, would make the story more complete. However, the comment does not provide any specific reasoning or evidence to support why this would be beneficial or necessary. It lacks detailed justification or examples that would help the authors understand the importance of including these datasets. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand the basis of the suggestion. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to enhance the completeness of the story. This feedback is somewhat helpful as it provides a specific direction for expanding the dataset analysis, which could potentially strengthen the paper. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why it is particularly relevant to the study. To be more helpful, the comment could include specific reasons for considering larger datasets or how this would impact the study\\'s conclusions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. However, it does not provide explicit instructions or guidance on how to implement this suggestion or why it is important. The action is implicit and lacks concrete details, making it somewhat vague. The authors can infer that they should expand their dataset analysis, but the lack of specific guidance makes it challenging to know exactly how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to enhance the completeness of the story. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its suggestion but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to enhance the completeness of the story. However, the comment lacks specific reasoning or evidence to support why this would be beneficial or necessary. It does not provide detailed justification or examples that would help the authors understand the importance of including these datasets. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to enhance the completeness of the story. This feedback is somewhat helpful as it provides a specific direction for expanding the dataset analysis, which could potentially strengthen the paper. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why it is particularly relevant to the study. To be more"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of using cosine similarity score instead of Euclidean distance for computing Decidability. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a suggestion for further exploration or a critique that needs addressing. Without clear instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of cosine similarity score in biometric verification and its potential effectiveness compared to the Euclidean distance for computing Decidability. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where these metrics are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the authors might have an idea of where these metrics are discussed, the comment is not fully grounded. It is specific in questioning the suitability of the cosine similarity score but does not provide detailed guidance on how to address this question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of cosine similarity score compared to Euclidean distance for computing Decidability. It does not present an opinion, claim, or suggestion that requires verification. The comment is a request for clarification or further exploration, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about the suitability of using cosine similarity score instead of Euclidean distance for computing Decidability. This is a relevant point that could lead to further exploration and potentially improve the robustness of the methodology. However, the comment lacks specific guidance or suggestions on how the authors might investigate this alternative or why it might be beneficial. While it prompts the authors to consider an additional aspect of their work, it does not provide actionable steps or detailed feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights several weaknesses in the experimental section of the paper, including the use of only a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. The reviewer explicitly states that the experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not provide specific guidance on how to improve the experiments or suggest alternative methods for comparison. While the authors can infer that they need to conduct more experiments and include comparisons with other methods, the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the experimental section of the paper, specifically mentioning the use of a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. This provides some grounding as it refers to specific parts of the paper. However, the comment does not specify which toy experiment or real-world dataset is being referred to, making it weakly grounded. The comment is specific in identifying the issues with the experiments, such as the lack of comparison and insufficient validation of the proposed method. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experiments are weak due to the use of only a toy experiment and a real-world dataset, and the lack of comparison with other counterpart methods. The comment provides a logical reasoning by stating that the experimental results are insufficient to validate the effectiveness of the proposed method. However, it lacks specific examples or references to other methods that could be compared, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several weaknesses in the experimental section of the paper, specifically noting the use of only a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. This feedback highlights the need for more comprehensive and robust experimental validation to support the effectiveness of the proposed method. However, the comment does not provide specific suggestions or guidance on how to improve the experiments or what additional comparisons should be made. While it points out important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies several weaknesses in the experimental section of the paper, including the use of only a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. The comment explicitly states that the experimental results are insufficient to validate the effectiveness of the proposed method. However, it does not provide specific guidance on how to improve the experiments or suggest additional experiments or comparisons that could be made. The lack of detailed instructions or examples makes the feedback somewhat vague, leaving the authors with a general idea of what needs to be addressed but without clear steps to take. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the experimental section of the paper, specifically mentioning the use of a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. This provides some grounding as it refers to specific parts of the paper. However, the comment does not specify which toy experiment or real-world dataset is being referred to, making it weakly grounded. The comment is specific in identifying the issues with the experiments, such as the lack of comparison and insufficient validation of the proposed method. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experiments are weak due to the use of only a toy experiment and a real-world dataset, and the lack of comparison with other counterpart methods. The comment provides a logical reasoning by stating that the experimental results are insufficient to validate the effectiveness of the proposed method. However, it lacks specific examples or references to other methods that could be compared, which would strengthen the claim. The comment highlights the need for more comprehensive experiments and comparisons, but without detailed evidence or examples, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several weaknesses in the experimental section of the paper, specifically noting the use of only a toy experiment and a real-world dataset, as well as the lack of comparison with other counterpart methods. This feedback highlights the need for more comprehensive and robust experimental validation to support the effectiveness of the proposed method. However, the"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. While it identifies a specific problem, it does not provide explicit guidance on how to address it. The authors can infer that they need to ensure these figures are referenced in the appropriate sections, but the comment lacks concrete instructions on how to implement this action. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights an issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. However, it does not specify which figures are missing or which sections of the appendix they should be referenced in, making it difficult for the authors to pinpoint the exact areas needing attention. While the authors might have an idea of where the figures are located, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"the figures related to completion errors are not referenced in the relevant analysis sections of the appendix.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. This is a clear and actionable point that can help the authors improve the organization and clarity of their paper. By addressing this issue, the authors can ensure that their readers can easily locate and understand the figures and their relevance to the analysis. However, the comment could be more helpful if it provided suggestions on how to effectively integrate these figures into the appendix or offered additional guidance on improving the overall presentation of the figures. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured on consistent validation sets across different levels. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks specific instructions or concrete steps for the authors to take to clarify or resolve the issue. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether perplexity is measured on consistent validation sets across different levels. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the authors might have an idea of where perplexity is discussed, the comment lacks full grounding. It is specific in questioning the consistency of validation sets but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about whether perplexity is measured on consistent validation sets across different levels. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether perplexity is measured on consistent validation sets across different levels. While it identifies a potential area of confusion or inconsistency in the paper, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors without clear steps to improve their draft. Therefore, it is barely helpful, as it points out a potential problem but does not offer a solution or constructive advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides an opinion about the originality of the setting and algorithm, suggesting that they may seem like incremental combinations of existing methods. However, it does not offer any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the originality of their work or differentiate it from existing methods. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion about the originality of the setting and algorithm, suggesting that they may seem like incremental combinations of existing methods. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the setting or algorithm lack originality. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence to substantiate the claim, rendering it unverifiable. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides an opinion about the originality of the setting and algorithm, suggesting that they may seem like incremental combinations of existing methods. However, it also acknowledges that the algorithm for graph labelings is efficient and new. While the comment identifies a potential issue with originality, it lacks specific suggestions or guidance on how the authors might address this concern or differentiate their work from existing methods. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their approach. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the authors might address this concern or what alternative approaches could be considered. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the potential harm of using state-action pairs from the current policy in the target environment as regularization. It suggests that this approach could lead to suboptimal state-action distributions, which could negatively impact learning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left with only a general idea of the problem but no clear path to resolve it. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might modify their approach or what alternative methods could be considered. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the authors might address this concern or what alternative approaches could be considered. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this could harm learning due to the potential use of a suboptimal policy. However, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this issue. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about using state"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model's performance on base classes. It explicitly suggests that the authors should discuss how this issue could be mitigated to maintain performance on the base classes. While the action is clear, the comment does not provide specific guidance on how to address the potential degradation or what mitigation strategies to consider. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the objective of the feature compactness loss and sharpness-aware minimization, specifically focusing on its impact on reducing distances among base classes. It raises a concern about potential negative effects on the model's performance on base classes and suggests discussing mitigation strategies. However, the comment does not explicitly mention which part of the paper discusses these objectives or where the potential issue is addressed, making it weakly grounded. The comment is specific in detailing the concern and suggesting a potential mitigation strategy, but without clear grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model's performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this operation might negatively affect performance. Without concrete evidence or a clear explanation of the potential issue, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, specifically questioning whether this operation could negatively impact the model's performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated to maintain performance on the base classes. This feedback is clear and actionable, as it prompts the authors to consider the implications of their method and provide a discussion on potential mitigation strategies. However, the comment could be more helpful if it offered specific suggestions or examples of how to address the issue. Overall, the comment is mostly helpful as it directs the authors' attention to a critical aspect of their work that requires further exploration and discussion.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, specifically questioning whether this operation could negatively impact the model's performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated to maintain performance on the base classes. While the comment highlights a critical area for consideration, it does not provide specific guidance or suggestions on how to address the potential degradation. The action is implicit and somewhat vague, as the authors are left to infer the need for a discussion on mitigation strategies. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the objective of the feature compactness loss and sharpness-aware minimization, specifically focusing on its impact on reducing distances among base classes. It raises a concern about potential negative effects on the model's performance on base classes and suggests discussing how this issue could be mitigated. However, the comment does not explicitly mention which part of the paper discusses these objectives, making it weakly grounded. The authors might infer that it relates to sections discussing the methodology or results, but this is not clearly stated. The comment is specific in detailing the concern and suggesting a potential mitigation strategy, but without clear grounding, it aligns with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model's performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this operation might negatively affect performance. Without concrete evidence or a clear explanation, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, specifically questioning whether this operation could negatively impact the model's performance on base classes"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the insight of the work in developing new methods and how to prevent attention collapse in continual learning (CL). While it raises important questions, it does not provide explicit guidance or suggestions for the authors to address these issues. The comment lacks actionable details, such as recommending specific approaches or providing examples of how to prevent attention collapse. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the insight of the work in developing new methods and how to prevent attention collapse in continual learning (CL). However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what insights or methods are being referred to or how attention collapse can be prevented. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the insights and methods developed in the work, as well as a request for guidance on preventing attention collapse in continual learning. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the insights and methods developed in the work, as well as how to prevent attention collapse in continual learning. While it identifies areas of interest and potential weaknesses, it lacks specific guidance or suggestions for improvement. The comment prompts the authors to clarify their contributions and address a critical issue in their work, but it does not provide actionable steps or detailed feedback. This limits the comment\\'s usefulness, making it somewhat helpful as it highlights areas for further exploration but does not fully support the authors in addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the impact of the CHC model on the capabilities of MLLMs and asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. It also inquires about case studies or pilot experiments that illustrate the significance of this influence. While the comment highlights areas of potential improvement, it does not provide explicit instructions or concrete suggestions on how to address these questions. The authors can infer that they need to provide more detailed explanations and possibly include case studies or experiments, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CHC model\" and the \"main content,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about how the CHC model affects the capabilities of MLLMs and asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it inquires about case studies or pilot experiments that illustrate the significance of this influence. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, asking for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. It also inquires about case studies or pilot experiments that illustrate the significance of this influence. While the comment highlights a potential gap in the paper, it does not make a subjective claim or suggestion that requires verification. It is a request for clarification and further elaboration, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the impact of the CHC model on the capabilities of MLLMs. It raises a pertinent question about the attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit, and it asks for case studies or pilot experiments that illustrate the significance of this influence. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and evidence to clarify the impact of the CHC model on MLLMs. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of similar studies. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider integrating more recent pretraining models to showcase the significance and practical usage of their approach. It provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This feedback is explicit and provides concrete guidance on how to improve the draft by incorporating more up-to-date pretraining models. The authors are given clear instructions on what to do and how to implement the suggested changes, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of the pretraining model Pre-GNN (Hu et al., 2020) and suggests considering more recent pretraining models to showcase the significance and practical usage of the approach. It provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. However, the comment does not explicitly mention which part of the paper discusses the pretraining model, making it weakly grounded. The suggestion is specific, as it clearly identifies the need to update the pretraining model and provides examples of recent works. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pretraining model, Pre-GNN (Hu et al., 2020), is outdated in the context of molecular pretraining and suggests considering more recent models to showcase the significance and practical usage of the approach. The reviewer supports this claim by referencing recent works in the field, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which are cited as examples of more up-to-date pretraining models. This provides a clear rationale and specific references, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or explanations of how these newer models would enhance the authors\\' approach. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a valuable critique by pointing out that the pretraining model, Pre-GNN (Hu et al., 2020), is relatively old in the context of molecular pretraining. It encourages the authors to consider integrating more recent pretraining models to showcase the significance and practical usage of their approach. The comment supports this suggestion by referencing recent works in the field, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This feedback is clear, actionable, and provides specific examples of recent works that could enhance the paper, making it highly helpful for the authors to improve their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review point acknowledges that the model takes the difference between current object pose and target object pose as input, which can pose significant engineering challenges due to difficulties in object segmentation and pose tracking in the real world. However, it also notes that the authors have documented their approach well in Section A.3. While the comment highlights a potential challenge, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the engineering challenge or suggestions for improvement. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the engineering challenge associated with taking the difference between current object pose and target object pose as input, and acknowledges that the authors have documented their approach well in that section. This provides clear guidance on what aspect of the paper is being addressed and what needs to be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges a potential engineering challenge related to the model\\'s input, which is the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that this engineering challenge is significant. The mention of the authors\\' documentation in Sec. A.3 does not substantiate the claim about the challenge. As a result, the comment lacks sufficient evidence or justification to be fully verifiable, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges a potential engineering challenge associated with the model's input, which involves the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult, which is a valid concern. However, the comment also highlights that the authors have documented their approach well in Section A.3, which is a positive aspect. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this challenge or improve their approach. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges a potential engineering challenge related to the model's input, which involves the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult. However, the comment does not provide any explicit or implicit actions for the authors to take to address this challenge or improve their approach. There is no guidance on how to mitigate the engineering challenge or suggestions for enhancing the documentation. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to improve their draft. Therefore, it aligns with a score of 1.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential engineering challenge associated with the model\\'s input, which involves the difference between current object pose and target object pose. The comment acknowledges that object segmentation and pose tracking in the real world can be difficult but notes that the authors have documented their approach well in Section A.3. This provides clear guidance on what aspect of the paper is being addressed and what needs to be considered. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges a potential engineering challenge related to the model\\'s input, which involves the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim about the engineering challenge. While it mentions that the authors have documented their approach well in Section A.3, this does not substantiate the claim about the challenge. As a result, the comment lacks sufficient evidence or justification to be fully verifiable, making it somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more downstream performance results for their controllable text generation models, particularly in the context of real NLG applications. It encourages the authors to connect their models to specific applications like style transfer and demonstrate the advantages of their approach. While the comment implies a specific action, it does not provide detailed guidance on how to implement these suggestions or what specific results should be included. The authors are left with a general direction but without concrete steps on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the inclusion of more downstream performance results for the controllable text generation models and connecting them to real NLG applications. The suggestion to consider style transfer as a starting point is also specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance results for their controllable text generation models, particularly in the context of real NLG applications. The reviewer encourages the authors to connect their models to specific applications like style transfer and demonstrate the advantages of their approach. However, the comment lacks specific examples or references to support the claim that more downstream performance results are necessary or how they would benefit the paper. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors include more downstream performance results for their controllable text generation models. It encourages the authors to connect their models to real NLG applications and demonstrate the advantages of their approach, particularly through examples like style transfer. While the comment is clear in its suggestion, it lacks detailed guidance on how to implement these changes or what specific results should be included. The mention of addressing previous comments and suggestions is appreciated, but it does not add new value to the feedback. Overall, the comment is somewhat helpful as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should provide more downstream performance results for their controllable text generation models, particularly in the context of real NLG applications. It encourages the authors to connect their models to specific applications like style transfer and demonstrate the advantages of their approach. While the comment implies a specific action, it lacks detailed guidance on how to implement these suggestions or what specific results should be included. The authors are left with a general direction but without concrete steps on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the inclusion of more downstream performance results for the controllable text generation models and connecting them to real NLG applications. The suggestion to consider style transfer as a starting point is also specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance results for their controllable text generation models, particularly in the context of real NLG applications. It encourages the authors to connect their models to specific applications like style transfer and demonstrate the advantages of their approach. However, the comment lacks specific examples or references to support the claim that more downstream performance results are necessary or how they would benefit the paper. The mention of addressing previous comments and suggestions is appreciated, but it does not add new value to the feedback. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. This aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors include more downstream performance results for their controllable text generation models. It encourages the authors to connect their models to real NLG applications and demonstrate the advantages of their approach, particularly through examples like style transfer. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it provided additional guidance or examples on how to implement these"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the test set performance on GLUE datasets and asks if the labels for these sets are not available to the public. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this confusion. The authors can infer that they might need to clarify or provide more information about the availability of labels, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a specific concern about the test set performance on GLUE datasets, questioning whether the labels for these sets are not available to the public. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where the test set performance is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in its inquiry about the availability of labels, providing clear guidance on what aspect needs clarification. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the availability of labels for GLUE datasets, which is a factual inquiry. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific concern about the test set performance on GLUE datasets, questioning whether the labels for these sets are not available to the public. This is a relevant point that could impact the validity and reproducibility of the study. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or clarify it in their paper. While it highlights an important area for consideration, it does not offer actionable feedback or constructive advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 could be shortened because many of the equations presented are already well-known in the community and not proposed by the current work. The reviewer implies that this would allow more space to include important details that are currently missing. While the action is not explicitly stated, it is clear and concrete, as the reviewer provides a specific suggestion for improvement. The authors know exactly what needs to be done to address the comment, which makes the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.2,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that many equations in this section are not proposed by the work but are well-known in the community, and it recommends shortening the section to include important details. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 could be shortened because many of the equations presented are already well-known in the community and not proposed by the current work. This claim is somewhat verifiable as it provides a logical reasoning that the inclusion of these well-known equations could be redundant, allowing space for more important details. However, the comment lacks specific examples or references to substantiate the claim further, which would make it more robust. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending that Section 3.2 be shortened. It explains that many of the equations presented in this section are already well-known in the community and not proposed by the current work, which would allow more space to include important details. This feedback is clear and actionable, as it directly addresses a potential redundancy in the paper and suggests a way to enhance the clarity and focus of the section. However, the comment could be more helpful if it provided examples of which equations are well-known or suggested specific details that should be included. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation methods used in Figure 3, Table 3, and Figure 5, specifically asking whether the evaluation was done automatically or by humans. While the comment highlights a potential issue, it does not provide explicit guidance on what the authors should do to address it. The authors can infer that they need to clarify the evaluation methods used in these figures, but the comment lacks concrete instructions on how to implement this clarification. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures and tables (Figure 3, Table 3, and Figure 5), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the evaluation method used between automatic and human evaluation. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the evaluation methods used in specific figures and tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the evaluation methods used in Figure 3, Table 3, and Figure 5, asking whether the evaluation was done automatically or by humans. This is a relevant and precise inquiry that can help the authors clarify their methodology, which is crucial for the credibility and reproducibility of their work. However, the comment does not provide any suggestions or guidance on how to address this issue or why it is important. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound by theorem, specifically mentioning the example of 1 -> 0.9, t=5: 0.9 -> 1. The reviewer asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary corrections or additions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific time points and values, such as \"1 -> 0.9, t=5: 0.9 -> 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the average coverage rate being larger than the bound by theorem and asking for clarification or additional assumptions to achieve the desired coverage rate. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound by theorem, specifically mentioning the example of 1 -> 0.9, t=5: 0.9 -> 1. The reviewer asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment highlights a potential issue, it lacks detailed reasoning or references to support the claim that the average coverage rate is indeed larger than the bound. The absence of specific examples or detailed explanation makes it somewhat challenging for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the average coverage rate being larger than the bound by theorem, providing a detailed example to illustrate the issue. It asks for clarification or additional assumptions to achieve the desired coverage rate, which is a clear and actionable request for the authors to address. By pinpointing a specific area of concern and asking for further explanation, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it provided suggestions on how to resolve the issue or additional context to support the authors in understanding the problem. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the variability in translator choices. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as considering multiple translators or discussing the implications of this choice. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the use of a single translator per language for producing annotations. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the approach, suggesting that using a single translator may not be sufficient due to the variability in translator choices. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the variability in translator choices. However, the comment lacks specific reasoning or evidence to support why using a single translator is insufficient or how it might impact the quality of the annotations. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the use of a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the variability in translator choices. While it identifies a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable advice or examples, the authors are left with only a vague understanding of the problem, making it difficult for them to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the statement \"people wear a hat and play guitar not vice-versa,\" but it does not provide any guidance or suggestions for the authors to address this question or improve their draft. The comment lacks any explicit or implicit actions for the authors to take, leaving them without direction on how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not refer to a specific part of the paper, making it difficult for the authors to identify the context or issue being addressed. Additionally, the comment lacks specificity as it is a question without any explanation or guidance on what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for an explanation or reasoning behind a statement about people wearing a hat and playing the guitar. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about a statement in the paper, \"people wear a hat and play guitar not vice-versa,\" without providing any context or explanation. It does not identify any specific issues or suggest improvements for the authors to address. The comment lacks actionable feedback or guidance, making it not helpful at all. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the number of examples (2000) may be insufficient for the model to learn the transformation correctly. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue, such as recommending additional examples or a different approach to data collection. The action is implicit and vague, leaving the authors uncertain about how to proceed. Without concrete steps or suggestions, the authors may struggle to determine the best course of action. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the number of examples (2000) may be insufficient for the model to learn the transformation correctly. However, it does not specify which part of the paper this observation is based on, such as a particular section, figure, or experiment. The authors cannot confidently determine which part of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the transformation or model might be affected by the insufficient number of examples. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"2000 examples may be insufficient for the model to learn this transformation correctly.\" However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the dataset size, suggesting that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern, such as recommending additional data or a different approach to data collection. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about Algorithm 1, specifically asking how it differs from variational inference and what its advantages are. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete details on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the algorithm and its advantages. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed, which makes it fully grounded. It also specifies the issue by asking how Algorithm 1 differs from variational inference and what its advantages are. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the algorithm and its differences from variational inference. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about Algorithm 1, specifically inquiring about its differences from variational inference and its advantages. This feedback prompts the authors to clarify and justify their approach, which is valuable for improving the clarity and understanding of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address these questions or enhance their explanation. While it identifies an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the entailment exercise lacks basic details and that it is difficult to assess the technique\\'s efficacy based on the information provided. The reviewer explicitly recommends either removing the exercise or providing more empirical and analyzed information. This feedback provides a clear and direct action for the authors to take, specifying that they should either remove the exercise or enhance it with additional details. The suggestion is concrete, as it outlines specific steps the authors can follow to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the entailment exercise, which provides some level of grounding as it refers to a specific part of the paper. However, it does not specify which section or part of the entailment exercise is lacking details, making it weakly grounded. The comment is specific in its suggestion to either remove the exercise or provide more empirical and analyzed information, offering clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details, making it difficult to assess the technique\\'s efficacy. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand which aspects of the exercise are lacking or how to improve it. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and making it difficult to assess the technique\\'s efficacy. The reviewer suggests either removing the exercise or providing more empirical and analyzed information. This feedback is clear and actionable, as it provides a direct recommendation for improvement. However, it could be more helpful if it offered specific details or examples of what additional information should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, indicating that it is ambiguous. However, it does not provide any guidance on how to clarify or correct the expression. The authors are left without explicit instructions on what changes to make or how to improve the clarity of the expression. As a result, the comment is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 225\" and \"line 227,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the ambiguity in the mathematical expression of the Gaussian distribution. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, describing it as ambiguous. This feedback is clear and actionable, as it points out a precise area where the authors need to clarify or correct the expression. By addressing this issue, the authors can improve the clarity and accuracy of their mathematical presentation. However, the comment could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of clearer expressions. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. While the comment implies that the authors should expand their testing to include more types of responses, it does not specify which additional types should be considered or how to implement this expansion. The action is implicit and somewhat vague, as the authors know they need to broaden their testing but lack detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the need for additional types of responses, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, the comment does not provide any specific reasoning or evidence to support why these additional types of responses are necessary or how they would improve the testing. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the testing approach, noting that using only certain tokens may not be sufficient. It suggests considering additional types of responses to enhance the testing. While the comment highlights an area for improvement, it lacks specific guidance or examples on what additional types of responses should be considered or how to implement this suggestion. This limits the comment\\'s usefulness to the authors, as it provides only a vague direction for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed, actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern about the privacy protection capability, specifically noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending alternative methods or strategies for improving privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability, specifically mentioning the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the issue with the privacy protection capability and the limitations of relying on manipulating the temperature for text sanitization. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient due to the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, the comment lacks specific examples or references to support the claim that chatGPT does not guarantee the removal of privacy information. Additionally, it does not provide detailed reasoning or evidence to substantiate the assertion about the limitations of relying on temperature manipulation for text sanitization. This makes the claim somewhat verifiable, as it provides a general critique but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the privacy protection capability of the paper, specifically pointing out that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information in the rewritten text. It also highlights a potential limitation in relying solely on manipulating the temperature (T) for text privacy protection, suggesting that this approach may not effectively achieve text sanitization. While the comment effectively identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach to privacy protection. This limits the comment\\'s usefulness, as it provides valuable insight but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a concern about the privacy protection capability, specifically noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information in the rewritten text. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach to privacy protection. Without specific recommendations or actionable steps, the authors are left without a clear understanding of what changes to make to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability, specifically mentioning the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the issue with privacy protection and the limitations of the current approach, but without explicit references to sections or details, the authors may struggle to pinpoint where improvements are needed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient due to the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, the comment lacks specific examples or references to support the claim that chatGPT does not guarantee the removal of privacy information. Additionally, it does not provide detailed reasoning or evidence to substantiate the assertion about the limitations of relying on temperature manipulation for text sanitization. This makes the claim somewhat verifiable, as it provides a general critique but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the privacy protection capability of the paper, specifically pointing out that the use of chatGPT for text"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach in sentiment analysis is not significant enough, as it relies on a relatively new method of using word embeddings to define the weight of each lexicon term. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could enhance the novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the \"General Discussion\" section of the manuscript, which allows the authors to identify the part of the paper being discussed. However, it lacks specificity as it does not detail what aspects of the novelty are not significant or how the authors could improve the novelty of their approach. Without specific guidance or examples, the authors may struggle to understand what needs to be addressed or improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the approach in sentiment analysis is not significant enough, as it relies on a relatively new method of using word embeddings to define the weight of each lexicon term. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the novelty of the approach in sentiment analysis, noting that it relies on a relatively new method of using word embeddings to define the weight of each lexicon term. However, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or address this concern. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This feedback provides a clear and direct action for the authors to take, which is to include such comparisons to enhance the understanding of the proposed method\\'s advantages. The suggestion is concrete, as it specifies the type of comparison that would be beneficial. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. However, it does not specify which tasks or sections of the paper this comparison should be made in, leaving the authors to infer the relevant parts. While the suggestion is specific in terms of what could be improved, it lacks grounding as it does not explicitly mention the sections or tasks being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This claim is somewhat verifiable as it provides a logical suggestion for improvement by highlighting the potential benefits of such a comparison. However, the comment lacks specific examples or references to non-NeRF methods that could be compared, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending a comparison of the proposed method to non-NeRF methods on the mentioned tasks. This feedback is valuable as it highlights a specific area where the paper could enhance its contribution by placing it in the context of existing conventional methods. By addressing this suggestion, the authors can better demonstrate the novelty and effectiveness of their approach. However, the comment could be more helpful if it included specific non-NeRF methods or tasks that would be suitable for comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some of the lower-level tasks count as NLU or syntactic tasks, suggesting that the authors clarify this in their paper. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology used in their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether some lower-level tasks count as NLU or syntactic tasks, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the term \"NLU\" in the paper, suggesting that some lower-level tasks may not fit this category. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks detailed reasoning or examples to justify why the term \"NLU\" might be misapplied or why the tasks in question should be reconsidered. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand and address the concern. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology used in the paper, specifically questioning whether some lower-level tasks should be considered NLU or syntactic tasks. This is a relevant point that could impact the clarity and accuracy of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending alternative terminology or clarifying the definitions used. While it highlights an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of the term \"NLU\" in the paper, suggesting that some lower-level tasks may not fit this category. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the terminology. The comment lacks actionable details, such as recommending specific changes or providing examples of how to distinguish between NLU and syntactic tasks. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (178:181), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether some lower-level tasks count as NLU or syntactic tasks, providing clear guidance on what needs to be clarified. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the term \"NLU\" in the paper, suggesting that some lower-level tasks may not fit this category. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks detailed reasoning or examples to justify why the term \"NLU\" might be misapplied or why the tasks in question should be reconsidered. As a result, the claim is not verifiable due to the absence of supporting information, making it difficult for the authors to understand and address the concern. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of the term \"NLU\" in the paper, suggesting that some lower-level tasks may not fit this category. This is a relevant point that could impact the clarity and accuracy of the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the terminology used. While it highlights an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of the term \"NLU\" in the paper, suggesting that some lower-level tasks may not fit this category. However, it does not provide explicit guidance or suggestions on how the authors should"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should discuss the relationship of their work to traditional ideas in computer vision, specifically regarding motion segmentation. It provides a reference to a relevant paper, Keuper et al. (2015), which could guide the authors in understanding the context of their work. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so or provide detailed guidance on how to integrate this information into their paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to strengthen their work's theoretical and academic value. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests discussing the relationship of the authors' work to traditional ideas in computer vision, specifically regarding motion segmentation. It references a specific paper, Keuper et al. (2015), which provides a clear direction for the authors to explore. However, the comment does not specify which part of the paper should include this discussion, making it weakly grounded. The suggestion is specific, as it outlines a clear direction for the authors to strengthen their work's theoretical and academic value. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the use of long-term motion trajectories is a traditional idea in computer vision and references a specific paper to support this claim. The reviewer also recommends discussing the relationship of the authors' work to these traditional attempts, suggesting that this would enhance the paper's theoretical and academic value. The reference to a specific paper provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the authors' work relates to the referenced paper. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a valuable suggestion for improving the paper by recommending that the authors discuss the relationship of their work to traditional ideas in computer vision, specifically regarding motion segmentation. It references a specific paper, Keuper et al. (2015), which can guide the authors in understanding the context of their work. The comment acknowledges the authors' introduction of Eulerian vs. Lagrangian views as a nice addition but suggests that discussing the relationship to traditional attempts would enhance the paper's theoretical and academic value. This feedback is clear, actionable, and constructive, offering a concrete way for the authors to strengthen their work. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the task types addressed on graph data and instead focuses on formalizing challenges. The comment highlights that the purpose of this section is unclear and inconsistent with its intended purpose. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the clarity of the section. The action is implicit and vague, as the authors are left to infer that they need to clarify the task objectives and purpose of the section, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is the lack of clarity in describing the specific task types addressed on graph data and the failure to convey the author\\'s task objectives. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks clarity in describing the specific task types addressed on graph data, instead focusing on formalizing challenges. The comment suggests that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to support the assertion fully. The authors would need to make a significant effort to understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks clarity in describing the specific task types addressed on graph data. It points out that the section focuses primarily on formalizing challenges rather than conveying the author\\'s task objectives, which is inconsistent with its intended purpose. This feedback is clear and actionable, as it directs the authors to clarify the task objectives and ensure that the section aligns with its intended purpose. However, the comment could be more helpful if it provided suggestions on how to achieve this clarity or examples of what information should be included. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides some direction for the authors to enhance their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks clarity in describing the specific task types addressed on graph data and instead focuses on formalizing challenges. The comment highlights that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. However, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve clarity. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to clarify the task objectives and purpose of the section, but without clear instructions on how to do so.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is the lack of clarity in describing the specific task types addressed on graph data and the failure to convey the author\\'s task objectives. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks clarity in describing the specific task types addressed on graph data and instead focuses on formalizing challenges. The comment suggests that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks clarity in describing the specific task types addressed on graph data and instead focuses on formalizing challenges. It points out that the purpose of this section is unclear, as it fails to convey the author\\'s"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, which are valuable methods that could benefit other models. The comment explicitly suggests that conducting an ablation study would help assess the impact of these techniques and allow for a direct comparison of YOSO\\'s performance with other models. This feedback provides a clear and concrete action for the authors to take, as it specifies the need for an ablation study and its potential benefits. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014an ablation study to assess the impact of these techniques and compare YOSO\\'s performance with other models. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their impact and compare YOSO\\'s performance with other models. The comment provides a logical reasoning by highlighting the importance of an ablation study to understand the specific contributions of these techniques. However, it lacks specific examples or references to similar studies that have successfully used ablation studies to evaluate training techniques. This makes the claim somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of evaluating the impact of these techniques and comparing YOSO\\'s performance with other models that could potentially leverage these methods. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by conducting an ablation study. However, it could be more helpful if it offered additional guidance on how to implement the ablation study or examples of similar studies for reference. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights the absence of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, which are valuable methods that could benefit other models. The comment explicitly suggests that conducting an ablation study would help assess the impact of these techniques and allow for a direct comparison of YOSO\\'s performance with other models. This feedback provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014an ablation study to assess the impact of these techniques and compare YOSO\\'s performance with other models. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their impact and compare YOSO\\'s performance with other models. The comment provides a logical reasoning by highlighting the importance of an ablation study to understand the specific contributions of these techniques. However, it lacks specific examples or references to similar studies that have successfully used ablation studies to evaluate training techniques. This makes the claim somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of evaluating the impact of these techniques and comparing YOSO\\'s performance with other models that could potentially leverage these methods. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by conducting an ablation study. However, it"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues: redundant descriptions and the need for a small-scale validation experiment. The first point is somewhat actionable as it highlights the redundancy in the content, but it does not provide explicit guidance on how to address it. The second point is more actionable, as it explicitly suggests conducting a small-scale validation experiment using the datasets mentioned in the paper. However, it lacks concrete details on how to design or execute this experiment. Overall, the comment provides some actionable steps but could be more detailed in its guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (line 229 to line 272) and provides a clear reference to the content being discussed, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of redundant descriptions and suggests a specific action, namely presenting a small-scale validation experiment using the datasets mentioned in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s content is limited and redundant, specifically mentioning the two paragraphs from line 229 to line 272 as an example. However, the comment does not provide specific reasoning or evidence to support why these paragraphs are redundant or how they could be improved. Additionally, the suggestion to present a small-scale validation experiment is not fully supported by detailed reasoning or examples. The lack of explicit justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited content and redundant descriptions. It points out that the two paragraphs from line 229 to line 272 redundantly describe the motivation and work approach already covered in the introduction. This feedback is actionable as it highlights areas where the authors can streamline their content to improve clarity and conciseness. Additionally, the comment suggests conducting a small-scale validation experiment using the datasets mentioned in the paper, which is a constructive suggestion for enhancing the paper\\'s empirical validation. However, the comment could be more helpful if it provided specific guidance on how to design or execute the validation experiment. Overall, the feedback is mostly helpful as it identifies key areas for improvement and offers a clear suggestion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies two specific issues: redundant descriptions and the need for a small-scale validation experiment. The first point suggests that the content is limited and redundant, but it does not provide explicit guidance on how to address this issue. The second point is more actionable, as it suggests conducting a small-scale validation experiment using the datasets mentioned in the paper. However, it lacks detailed instructions on how to design or execute this experiment. Overall, the comment provides some actionable steps but could be more comprehensive in its guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (line 229 to line 272) and provides a clear reference to the content being discussed, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of redundant descriptions and suggests a specific action, namely presenting a small-scale validation experiment using the datasets mentioned in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s content is limited and redundant, specifically mentioning the two paragraphs from line 229 to line 272 as an example. However, the comment does not provide specific reasoning or evidence to support why these paragraphs are redundant or how they could be improved. Additionally, the suggestion to present a small-scale validation experiment is not fully supported by detailed reasoning or examples. The lack of explicit justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited content and redundant descriptions. It points out that the two paragraphs from line 229 to line 272 redundantly describe the motivation and work approach already covered in the introduction. This feedback is actionable as it highlights areas where the authors can streamline their content to improve clarity and conciseness. Additionally, the comment suggests conducting a small-scale validation experiment using the datasets mentioned in the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to re-write the section on theoretical contributions to clarify its connections with the proposed method. The feedback provides a clear action for the authors to take, which is to make the theoretical contributions more relevant and understandable in the context of the proposed method. The comment is specific and provides a direct instruction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"theoretical contributions\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical contributions, which is their perceived abstraction and lack of connection to the proposed method. The comment suggests re-writing the section to clarify its connections with the method, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclearly connected to the proposed method. The reviewer suggests that the provided theory is not directly related to EigenGuard, making it difficult to understand how it supports the method. However, the comment lacks specific examples or detailed reasoning to substantiate this claim, such as explaining how the theory is disconnected from EigenGuard or suggesting alternative connections. This makes the claim somewhat verifiable, as it provides a general critique but lacks the detailed evidence or examples needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical contributions, noting that they appear too abstract and disconnected from the proposed method. It specifically points out that the theory does not clearly explain how it supports the method, particularly in the context of EigenGuard. The comment provides a clear and actionable suggestion to re-write the section to clarify its connections with the proposed method. This feedback is mostly helpful as it directs the authors to a specific area needing improvement and offers a concrete step for enhancing the clarity and relevance of the theoretical contributions. However, it could be more helpful if it provided additional guidance or examples on how to achieve this clarity. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reproducibility of the GCN implementation due to the lack of original code, despite the detailed descriptions provided by the authors. However, it does not offer any explicit or implicit suggestions for how the authors might address this issue, such as recommending the release of the code or providing additional information in the main text. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reproducibility of the GCN implementation, specifically noting that the original code may be necessary for full reproducibility. However, it does not specify which part of the paper discusses the GCN implementation or where the authors mention the need for original code. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the GCN implementation is discussed, the comment lacks full grounding. It is specific about the issue of reproducibility but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reproducibility of the GCN implementation, suggesting that the original code may be necessary for full reproducibility. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions that the author\\'s descriptions are detailed and that more information is available in the supplement, but without further elaboration, the claim remains vague. This lack of detailed justification makes the comment borderline verifiable, as it provides some context but insufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the reproducibility of the GCN implementation, noting that the original code may be necessary for full reproducibility. While it acknowledges that the author\\'s descriptions are detailed and that more information is available in the supplement, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness in the paper but lacks actionable feedback or detailed advice on how to improve the reproducibility of the work. As a result, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the reproducibility of the GCN implementation, noting that the original code may be necessary for full reproducibility. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue, such as recommending the release of the code or providing additional information in the main text. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reproducibility of the GCN implementation, noting that the original code may be necessary for full reproducibility. However, it does not specify which part of the paper discusses the GCN implementation or where the authors mention the need for original code. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of reproducibility, it lacks full grounding due to the absence of a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reproducibility of the GCN implementation, suggesting that the original code may be necessary for full reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The comment acknowledges that the author\\'s descriptions are detailed and that more information is available in the supplement, but without further elaboration, the claim remains vague. This lack of detailed justification makes the comment borderline verifiable, as it provides some context but insufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the reproducibility of the GCN implementation, noting that the original code may be necessary for full reproducibility. While it acknowledges that the author\\'s descriptions are detailed and that more information is available in the supplement, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness in the paper but lacks actionable feedback or detailed advice on how to improve the reproducibility of the work. As a result,"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. While it implies that the authors should consider using the differential functions, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of differential functions and determine how to incorporate them into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions instead of differential functions and suggests reconsidering the choice. This provides clear guidance on what aspect of the equations needs further exploration or justification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the use of second-order Taylor expansions instead of differential functions in Equations (9) and (10). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. While it identifies a potential area for clarification or improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or why it might be beneficial to use the differential functions. The comment lacks depth and actionable advice, making it somewhat helpful as it prompts the authors to consider an alternative approach but does not fully support them in implementing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to related works, which could be relevant for understanding the context or addressing the issue. However, the comment does not explicitly instruct the authors to include the missing recall or suggest how to incorporate it into the table. The action is implicit and somewhat vague, as the authors need to infer that they should add the missing recall and consider the references for further context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing recall on lemmas/forms seen in training for the en-cs BPE to character results. Additionally, the comment provides references to related works, which could be relevant for understanding the context or addressing the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"en-cs BPE to character results are missing the recall on lemmas/forms seen in training,\" and it provides references to related works that discuss similar topics. This provides a basis for the claim, as it references existing literature that could be relevant to the issue. However, the comment does not explicitly explain why this omission is problematic or how it affects the overall analysis. The inclusion of references is a positive aspect, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to related works, which could be relevant for understanding the context or addressing the issue. This feedback is clear and actionable, as it directs the authors to a specific area that needs attention and suggests a potential source for improvement. However, the comment could be more helpful if it offered additional guidance on how to incorporate the missing recall or suggested ways to present this information effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation in Section 4. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. The comment highlights a gap in the explanation provided in Section 4, suggesting that an elaboration on this point is needed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation by pointing out that the proposed method has no impact on the MLSC setup, as shown in Table 3. The comment suggests that Section 4 should provide an explanation for this observation. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the need for an explanation, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the claim that better word-alignment improves many-to-many translation, pointing out a discrepancy between this claim and the observed lack of impact on the MLSC setup (Table 3). It suggests that Section 4 should provide an explanation for this observation, which is a valuable insight for the authors to address. However, the comment does not offer specific suggestions or guidance on how to resolve this issue or improve the explanation in Section 4. While it identifies a significant gap in the paper, it could be more helpful by providing actionable steps or examples. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the explanation. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the impact of the proposed method on the MLSC setup, given the claim that better word-alignment improves many-to-many translation. The comment highlights a gap in the explanation provided in Section 4, suggesting that an elaboration on this point is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation by pointing out that the proposed method has no impact on the MLSC setup, as shown in Table 3. It suggests that Section 4 should provide an explanation for this observation. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the need for an explanation, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the claim that better word-alignment improves many-to-many translation, pointing out a discrepancy between this claim and the observed lack of impact on the MLSC setup (Table 3). It suggests that Section 4 should provide an explanation for this observation, which is a valuable insight for the authors to address. However, the comment does not offer specific suggestions or guidance on how to resolve this issue or improve the explanation in Section 4. While it identifies an important area for clarification, it could be more helpful by providing actionable steps or examples. Therefore, the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore the applicability in an online setting. The action is implicit, as the authors can infer that they might need to consider alternative approaches or datasets, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the method, namely its restriction to an offline setting. It points out that the method requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses the offline setting, making it weakly grounded. The authors can infer that it relates to sections discussing the method or its applicability, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting, requiring pre-collected datasets and not applicable in an online setting where policies interact with the environment. This claim is somewhat verifiable as it logically explains the limitation of the method based on its design. However, the comment lacks specific examples or references to support the claim, such as comparisons with other methods or studies that address similar limitations. Providing such details would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. This feedback is valuable as it highlights a critical area that the authors need to address to broaden the applicability of their method. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or explore the applicability in an online setting. While it points out a clear weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore the applicability in an online setting. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they might need to consider alternative approaches or datasets, but the comment does not offer specific steps or examples to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific limitation of the method, namely its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The authors can infer that it relates to sections discussing the method or its applicability, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting, requiring pre-collected datasets and not applicable in an online setting. This claim is somewhat verifiable as it logically explains the limitation of the method based on its design. However, the comment lacks specific examples or references to support the claim, such as comparisons with other methods or studies that address similar limitations. Providing such details would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. This feedback is valuable as it highlights a critical area that the authors need to address to broaden the applicability of their method. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or explore the applicability in an online setting. While it points out a"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of the learned representation should include more than just the linear evaluation setting, as it is insufficient to draw a clear conclusion. It explicitly recommends considering other downstream tasks, such as fine-tuning, detection, and segmentation, which are mentioned in the literature. This feedback provides a clear and explicit action for the authors to take, specifying the types of tasks that should be included in the evaluation. The suggestion is concrete, as it outlines specific tasks that could be added to enhance the evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the learned representation, specifically pointing out that it was only evaluated on the linear evaluation setting, which is insufficient. It suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for evaluation. However, the comment does not specify which part of the paper discusses the evaluation or where these tasks are mentioned, making it weakly grounded. The comment is specific in suggesting alternative tasks for evaluation, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient, as it only uses the linear evaluation setting. The reviewer suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for evaluation. While the comment provides a logical reasoning for why the current evaluation might be insufficient, it lacks specific references or examples from the literature to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, noting that it was only evaluated on the linear evaluation setting, which may not provide a comprehensive understanding of the model\\'s performance. It suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for evaluation, as these are mentioned in the literature. This feedback is clear and actionable, as it provides specific examples of alternative tasks that could enhance the evaluation and improve the robustness of the conclusions drawn from the study. By offering a concrete suggestion for expanding the evaluation, the comment is highly helpful in guiding the authors toward a more comprehensive assessment of their model. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment criticizes the novelty of the paper, stating that stage-wise and progressive training have been used extensively and that the authors' approach does not exhibit anything novel. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The feedback lacks actionable details, such as recommending ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the novelty of the paper, specifically mentioning the use of stage-wise and progressive training, which have been used extensively. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the authors' approach lacks novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the novelty of the paper is very low, as stage-wise and progressive training have been used extensively. However, the comment lacks specific examples or references to support this claim, such as where these methods have been used elsewhere or how they have been applied in similar contexts. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The comment criticizes the novelty of the paper, stating that stage-wise and progressive training have been used extensively and that the authors' approach does not exhibit anything novel. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the novelty of their work. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is not particularly helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment criticizes the novelty of the paper, stating that stage-wise and progressive training have been used extensively and that the authors' approach does not exhibit anything novel. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty of their work or differentiate it from existing methods. Without actionable advice or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the novelty of the paper, specifically mentioning the use of stage-wise and progressive training, which have been used extensively. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the authors' approach lacks novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the novelty of the paper is very low, as stage-wise and progressive training have been used extensively. However, the comment lacks specific examples or references to where these methods have been used elsewhere, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment criticizes the novelty of the paper, stating that stage-wise and progressive training have been used extensively and that the authors' approach does not exhibit anything novel. However, it lacks specificity and does not provide any constructive feedback or suggestions on how the authors might enhance the novelty or differentiate their work from existing methods. Without actionable guidance or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is not particularly helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment criticizes the novelty of the paper, stating that stage-wise and progressive training have been used extensively and that the authors' approach does not exhibit anything novel. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty of their work or differentiate it from existing methods. Without actionable advice"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extension of the analysis to more general cases, specifically regarding the handling of more general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. While these questions imply that the authors should consider these extensions, they do not provide explicit instructions or concrete steps on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore these extensions but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the extension of the analysis to more general cases, specifically regarding the handling of more general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the extension of the analysis but does not provide detailed guidance on how to address these questions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the extension of the analysis to more general cases. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis, specifically regarding its applicability to more general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the broader implications and limitations of their work, which is valuable for expanding the scope and robustness of their analysis. However, the comment does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a general direction for improvement but without detailed actionable steps. Therefore, the comment is somewhat helpful, as it identifies areas for further exploration but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between the work discussed in the paper and a reference [19], specifically regarding the use of a Fine state automaton. It implies that the authors should clarify whether there are any differences between the two works or if they are essentially the same. However, the comment does not explicitly instruct the authors to make this clarification or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether [19] uses the same Fine state automaton or if there are any differences. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a reference [19] in the paper, specifically in section 3.1 and line 57, regarding whether it uses the same Fine state automaton or if there are any differences. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the reference [19] in the paper, noting that it is not clear whether the work uses the same Fine state automaton as discussed in section 3.1. This feedback highlights a potential gap in the clarity of the paper, prompting the authors to provide a more detailed explanation or clarification. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as by providing a comparison or additional context. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of the same Fine state automaton in the paper and reference [19]. It implies that the authors should clarify whether there are any differences between the two works or if they are essentially the same. However, the comment does not explicitly instruct the authors to make this clarification or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether [19] uses the same Fine state automaton or if there are any differences. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a reference [19] in the paper, specifically regarding whether it uses the same Fine state automaton as discussed in section 3.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the clarity of a reference [19] in the paper, particularly in section 3.1 and line 57. It questions whether the work uses the same Fine state automaton as discussed elsewhere, suggesting that there might be a need for clarification. While the comment highlights an area that requires further explanation, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of the same Fine state automaton in the paper"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, specifically mentioning that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment does not explicitly instruct the authors to address this issue or suggest specific actions to mitigate the memory requirement. The authors can infer that they might need to consider alternative approaches or optimizations, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the auto_weight scheme requires intermediate gradients for each domain, which could lead to high memory usage. Additionally, it provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the memory requirements of the auto_weight scheme in Algorithm 1, specifically mentioning that it involves intermediate gradients for each domain. The reviewer supports this claim by referencing two external works, FedGP and FLamby, which might offer insights or solutions to this issue. While the references provide some context, the comment could be strengthened by explaining how these works relate to the memory requirements or offering more detailed reasoning about the potential impact on memory usage. As it stands, the claim is mostly verifiable due to the references provided, but it could be further strengthened with more detailed reasoning or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. This feedback is somewhat helpful as it highlights a specific concern and suggests a potential area for improvement by referencing relevant literature. However, the comment could be more helpful if it offered more detailed guidance or suggestions on how to address the memory issue or incorporate the insights from the referenced works. Overall, the comment provides some direction but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, specifically mentioning that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment does not explicitly instruct the authors to address this issue or suggest specific actions to mitigate the memory requirement. The authors can infer that they might need to consider alternative approaches or optimizations, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the auto_weight scheme requires intermediate gradients for each domain, which could lead to high memory usage. Additionally, it provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the memory requirements of the auto_weight scheme in Algorithm 1, specifically mentioning that it involves intermediate gradients for each domain. The reviewer supports this claim by referencing two external works, FedGP and FLamby, which might offer insights or solutions to this issue. While the references provide some context, the comment could be strengthened by explaining how these works relate to the memory requirements or offering more detailed reasoning about the potential impact on memory usage. As it stands, the claim is mostly verifiable due to the references provided, but it could be further strengthened with more detailed reasoning or examples. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper, noting that the backbone is constrained to be the double LSTM and that popular transformers are not involved. It also mentions that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. While the comment identifies areas that need attention, it does not provide explicit guidance or suggestions on how to address these limitations or expand the application of the method. The authors are left to infer that they might need to consider incorporating transformers or expanding the model structures, but without specific instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper regarding the use of the double LSTM as the backbone, while not involving popular transformers. It also mentions that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the limited use of transformers and the need for broader application. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is limited because it only uses the double LSTM as the backbone, while popular transformers are not involved. The reviewer also notes that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. While the comment identifies specific limitations, it lacks detailed reasoning or evidence to fully substantiate the claim. The mention of \"Section 6\" suggests that the limitations are discussed there, but the comment does not provide specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides some insight but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's approach, noting that the backbone is constrained to the double LSTM and that popular transformers are not involved. It also points out that pre-trained language models are not covered as well, which could be a concern for the application of the method to more extensive model structures. The comment highlights that limitations are mentioned in Section 6 but suggests that they may not be sufficient. While the comment effectively identifies areas for improvement, it lacks specific suggestions or guidance on how the authors might address these limitations or expand the application of their method. This limits the comment's helpfulness, as it provides insight but not actionable steps for improvement. Therefore, it is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation in the paper, noting that the backbone is constrained to the double LSTM and that popular transformers are not involved. It also mentions that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. While the comment highlights areas that need attention, it does not provide specific guidance or suggestions on how the authors might address these limitations or expand the application of their method. The feedback lacks actionable steps, leaving the authors with only a general idea of what needs improvement but no clear direction on how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper regarding the use of the double LSTM as the backbone, while popular transformers are not involved. It also mentions that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the limited use of transformers and the need for broader application. Therefore, this comment is categorized as fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is limited because it only uses the double LSTM as the backbone, while popular transformers are not involved. It also notes that pre-trained language models are not covered as well and expresses concern about the application of the method to more extensive model structures. While the comment identifies specific limitations, it lacks detailed reasoning or evidence to fully substantiate the claim. The mention of \"Section 6\" suggests that the limitations are discussed there, but the comment does not provide specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides some insight but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': \""}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution and novelty of the paper are limited, as the model proposed combines existing techniques. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable details, such as recommending ways to differentiate the model or suggesting additional components or approaches that could be explored. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, stating that the model proposed combines existing techniques. However, it does not specify which sections or parts of the paper this assessment is based on, nor does it provide details on how the model combines these techniques or why it lacks novelty. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited, as the model proposed combines existing techniques. However, the comment does not provide specific examples or references to the existing techniques being combined, nor does it explain how the combination results in a lack of novelty. This lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the contribution and novelty of the paper, stating that the model proposed combines existing techniques, such as structure learning regularization (NOTEARS) and missing value imputation, along with variational inference for model parameter learning. While it identifies a potential limitation in the originality of the work, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or contribution of their research. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the performance of MSLR, which requires tuning unimodal models, to a late-fusion model with separate learning rates for each modality. It implies that the authors should conduct an experiment to compare these two approaches, especially with a similar or less compute budget. While the action is implicit, it is clear and concrete, as it specifies the type of comparison and the conditions under which it should be conducted. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the MSLR dataset and its requirements for knowing unimodal optimal learning rates in advance. It suggests comparing this approach to directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these models are discussed. The comment is specific in detailing what needs to be addressed, namely the comparison between MSLR and late-fusion models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that MSLR requires knowing the unimodal optimal learning rates in advance, which implies a trade-off between resource expenditure and model performance. The reviewer proposes an alternative approach by tuning a late-fusion model with separate learning rates for each modality, suggesting a comparison with MSLR. While the comment provides a logical reasoning for the comparison, it lacks specific examples or references to support the claim about the trade-off or the benefits of the proposed approach. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the MSLR dataset, which requires knowing the optimal learning rates in advance, and suggests an alternative approach by tuning a late-fusion model with separate learning rates for each modality. This feedback is clear and actionable, as it provides a concrete suggestion for comparison that could enhance the paper\\'s analysis. By proposing a direct comparison with a late-fusion model, the comment offers a constructive direction for the authors to explore, potentially leading to a more comprehensive evaluation of their approach. However, the comment could be more helpful if it included specific guidance on how to implement the suggested comparison or discussed the potential implications of such a comparison. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with additional detail.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests comparing the performance of MSLR, which requires tuning unimodal models, to a late-fusion model with separate learning rates for each modality. It implies that the authors should conduct an experiment to compare these two approaches, especially with a similar or less compute budget. While the action is implicit, it is clear and concrete, as it specifies the type of comparison and the conditions under which it should be conducted. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the MSLR dataset and its requirements for knowing unimodal optimal learning rates in advance. It suggests comparing this approach to directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these models are discussed. The suggestion is specific, as it provides a clear direction for comparison. However, the comment could be more grounded if it explicitly referred to a particular section or part of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the performance of MSLR, which requires tuning unimodal models, to a late-fusion model with separate learning rates for each modality. It implies that the authors should conduct an experiment to compare these two approaches, especially with a similar or less compute budget. While the comment provides a logical reasoning for the comparison, it lacks specific examples or references to support the claim about the trade-off between resource expenditure and model performance. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the MSLR dataset, which requires knowing the optimal learning rates in"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an ambiguity in the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. This feedback provides a clear and explicit action for the authors to take, which is to clarify the notation by specifying the actual inputs. The suggestion is concrete, as it directly addresses the ambiguity and offers a specific alternative. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the notation for L_{flow}(X), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the ambiguity of the notation and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the ambiguity of the notation for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. However, the comment does not provide any supporting evidence or reasoning to justify why these alternatives are more appropriate. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the notation used for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and precision of the notation in the paper. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why these alternatives are more appropriate or provided additional context on the significance of the notation. Overall, the comment is mostly helpful, as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed before. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or impact of the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of representing the input using 8 bits, referencing the use of 8-bit batch norm in previous literature. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this method is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the novelty of the approach but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of representing the input using 8 bits, referencing the use of 8-bit batch norm in previous literature. This claim is supported by a specific reference to a prior work, which provides a clear basis for the critique. The mention of a previous study helps to substantiate the claim that the current work lacks originality, making the comment mostly verifiable. However, the comment could be further strengthened by providing more detailed comparisons or analysis of the referenced work, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed before in literature. This feedback highlights a potential issue with the originality of the work, which is an important consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. While it identifies a potential weakness, it lacks actionable advice or constructive feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed before in literature. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve the novelty of their work. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of representing the input using 8 bits, referencing the use of 8-bit batch norm in previous literature. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty but lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of representing the input using 8 bits, referencing the use of 8-bit batch norm in previous literature. This claim is supported by a specific reference to a prior work, which provides a clear basis for the critique. The mention of a previous study helps to substantiate the claim that the current work lacks originality. However, the comment could be further strengthened by providing more detailed comparisons or analysis of the referenced work, which would enhance its verifiability. As it stands, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the novelty of representing the input using 8 bits, noting that 8-bit batch norm has been proposed before in literature. This feedback highlights a potential issue with the originality of the work, which is an important consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. While it identifies a potential weakness, it lacks actionable advice or constructive feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the practical relevance of their framework or what specific steps they could take to improve its applicability. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how the dominance of GNNs affects the framework\\'s practical relevance. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how it impacts the practical relevance of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While it identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern or differentiate their work from existing GNNs. Without detailed suggestions or examples, the authors are left with a general idea of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide sufficient detail to be fully actionable.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the practical relevance of their framework or what specific steps they could consider. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how the dominance of GNNs affects the framework\\'s practical relevance. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment lacks supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, it is difficult for the authors to understand the basis of the claim or how it impacts the practical relevance of their work. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or differentiate their work from existing GNNs. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the practical relevance of the proposed"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. While the comment implies that the authors should conduct an additional experiment, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete guidance on how to implement the suggested experiment. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a specific question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where $X$ is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in its request for an additional experiment to demonstrate the necessity of $X$. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an additional experiment should be conducted to demonstrate this. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it impacts the results. The lack of detailed explanation or examples makes it difficult for the authors to understand the significance of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an additional experiment should be conducted to demonstrate this. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by adding an experiment to address a potential weakness in the methodology. By doing so, the authors can strengthen their argument and provide more evidence for the necessity of $X$. However, the comment could be more helpful if it included additional guidance on how to design or conduct the experiment. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons, but it does not provide any actionable feedback or suggestions for improvement. It lacks any explicit or implicit actions for the authors to take, such as recommending changes to the analysis or providing additional context. As a result, the authors are left without guidance on how to address this observation, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment makes a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not specify which part of the paper this observation pertains to, nor does it provide any specific details or suggestions for improvement. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the comment effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a claim that \"problems involving MLPs have higher complexity than problems involving FBDDs and perceptrons.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how it relates to their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment makes a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any specific feedback or suggestions for improvement. Without identifying particular weaknesses or areas where the authors could enhance their work, the comment offers limited value to the authors in terms of improving their draft. It lacks actionable guidance or detailed insights, making it not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the generalizability of the observations, particularly those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. It provides specific examples of hyperparameters that could be considered, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling. While the comment does not explicitly instruct the authors to make these discussions, the suggestions are clear and concrete, providing a direct path for the authors to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the discussion of the generalizability of observations and the influence of various hyperparameters on implicit biases and neural representations. The comment provides clear guidance on what aspects should be considered, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the generalizability of observations, such as those in Figure 4, should be discussed, particularly in relation to various hyperparameters. The comment provides a logical reasoning by explaining how different hyperparameters could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and stages of learning. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the reasoning themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement by suggesting that the authors discuss the generalizability of the observations, particularly those in Figure 4. It highlights the potential influence of various hyperparameters on implicit biases in the algorithm, which could affect neural representations, geometric metrics, and stages of learning. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their discussion and analysis. However, the comment could be more helpful if it offered specific examples or guidance on how to address these issues, which would make it fully comprehensive. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. While the comment identifies a specific issue with terminology, it does not provide explicit guidance on how to address this problem or suggest alternative terms. The action is implicit, as the authors need to infer that they should revise the terminology, and it is somewhat vague because it lacks detailed instructions on how to implement the suggested change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of using non-standard terminology, particularly the term \"semi-honest\" and suggests using \"honest-but-curious\" instead. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. The reviewer suggests that the term \"honest-but-curious\" is more commonly used to describe the server. While the comment provides a specific example of terminology that could be improved, it lacks detailed reasoning or references to support why this terminology is problematic or how it affects the paper\\'s organization. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed justification or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and terminology used in the paper. It points out the use of non-standard terminology, such as \"semi-honest,\" and suggests that the term \"honest-but-curious\" is more commonly used to describe the server. This feedback is clear and actionable, as it provides a specific example of terminology that could be improved and suggests a more standard term. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to improve the overall organization or suggested other areas where the paper might be better structured. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the organization and terminology used in the paper, particularly the term \"semi-honest\" in section 4. It suggests using the more common term \"honest-but-curious\" to describe the server. While the comment provides a clear action to take\u2014replacing the term \"semi-honest\" with \"honest-but-curious\"\u2014it does not offer additional guidance on how to address other potential issues with the paper\\'s organization. The suggestion is explicit and concrete, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of using non-standard terminology, particularly the term \"semi-honest\" and suggests using \"honest-but-curious\" instead. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. While the comment provides a specific example of terminology that could be improved, it lacks detailed reasoning or references to support why this terminology is problematic or how it affects the paper\\'s organization. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed justification or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and terminology used in the paper. It points out the use of non-standard terminology, such as \"semi-honest,\" and suggests using the more commonly accepted term \"honest-but-curious\" to describe the server. This feedback is clear and actionable, as it provides a specific example of terminology that could be improved, helping the authors enhance the clarity"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of experimental details, specifically asking about the optimizer, initialization, and PPO-zero. While it identifies specific areas that need clarification, it does not provide explicit instructions on how to address these gaps. The authors can infer that they need to include these details in their draft, but the comment lacks concrete guidance on how to present them. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of specific experimental details, such as the optimizer, initialization, and PPO-zero. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in identifying the missing details, but without clear grounding, the authors may struggle to pinpoint where to add these details. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification on specific experimental details, such as the optimizer, initialization, and PPO-zero. These are factual inquiries seeking additional information, which do not express opinions, judgments, or suggestions. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail, namely the optimizer, initialization, and PPO-zero. By pointing out these missing details, the comment provides clear and actionable feedback that can help the authors improve the clarity and completeness of their experimental section. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their work that needs attention. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors need to conduct a detailed efficiency analysis by comparing the proposed method with existing works. It specifies the components to consider, such as the total model parameter, FLOPs, and memory, and mentions the need for a detector and LaVIT. This provides clear and concrete guidance on what the authors need to do to improve their draft. The explicit nature of the suggestion and the detailed information on what to compare make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Efficiency and Complexity\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method requiring additional components like LaVIT and Eva-CLIP, and suggests a detailed comparison in terms of efficiency analysis. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components like LaVIT and Eva-CLIP, which are not necessary in other existing works. The reviewer suggests that a detailed comparison of efficiency analysis, including total model parameters, FLOPs, and memory, is needed. This claim is somewhat verifiable as it provides a logical basis for the suggestion by highlighting the additional components required by the proposed method. However, it lacks specific examples or references to existing works that do not require these components, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the additional components required by the proposed method, such as LaVIT and Eva-CLIP, and the need for a detector in the decoding process. It suggests that a detailed efficiency analysis, including comparisons of total model parameters, FLOPs, and memory usage, would be beneficial. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and improving the comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or references to existing works that have successfully addressed similar issues. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the paper claims extrapolation error is a major issue in MARL but lacks evidence to support this claim. It also notes that the proposed techniques are for bias/variance reduction and do not seem directly related to extrapolation error. The reviewer highlights the absence of evidence that the proposed method mitigates extrapolation error, which leads to better performance. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns or what evidence they should include to support their claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence and clarify the relationship between their techniques and extrapolation error. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the paper's claim about extrapolation error being a major issue in MARL, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out the lack of evidence supporting this claim and the apparent disconnect between the proposed techniques and their relation to extrapolation error. The comment further highlights the absence of evidence that the proposed method mitigates extrapolation error, which leads to better performance. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper's assertion about extrapolation error being a major issue in MARL is not supported by evidence. It further critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The comment highlights the absence of evidence that the proposed method mitigates extrapolation error, which is crucial for the paper's claims. However, the comment lacks specific examples or references to substantiate the claim or provide a clearer understanding of how the proposed techniques relate to extrapolation error. This makes the claim somewhat verifiable, as it provides a logical critique but requires more detailed evidence or examples to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's claims regarding extrapolation error being a major issue in MARL. It points out that the authors do not provide any evidence to support this claim, which is a significant omission. Additionally, the comment critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The reviewer highlights the absence of evidence that the proposed method mitigates extrapolation error, which is crucial for the paper's claims. While the comment effectively identifies a significant gap in the paper's argumentation, it lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary evidence. This limits the comment's helpfulness, making it somewhat helpful as it points out a critical area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment provides explicit and concrete actions for the authors to take. It suggests that the authors should include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME's efficiency over conventional FFNs. Additionally, it recommends providing details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. These suggestions are clear and provide specific guidance on how to enhance the paper, making the comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as including detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, it suggests providing details on benchmark configurations, hardware, and input shapes for fair comparisons. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that SCHEME's on-device efficiency is underexplored, despite its theoretical complexity advantages. The reviewer supports this claim by noting that only limited throughput comparisons are presented in Tables 4 and 8. The suggestion to include detailed on-device results across ablation and comparison studies is logical and provides a clear rationale for why these comparisons are necessary. However, the comment could be strengthened by providing specific examples or references to similar studies that have successfully demonstrated on-device efficiency. As it stands, the claim is mostly verifiable, as it provides a reasonable basis for the suggestion but lacks detailed evidence or examples. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper regarding the on-device efficiency of SCHEME, despite its theoretical complexity advantages. It points out that only limited throughput comparisons are presented in Tables 4 and 8, suggesting that more detailed on-device results are necessary to substantiate claims about SCHEME's efficiency. The comment provides a clear and actionable suggestion to include detailed on-device results across ablation and comparison studies, which would strengthen the paper's claims. Additionally, it emphasizes the importance of providing details on benchmark configurations, hardware, and input shapes for fair comparisons. This feedback is highly helpful as it offers specific guidance on how to enhance the paper's rigor and comprehensiveness, enabling the authors to make significant improvements to their draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. While the comment implies that the authors should change the name, it does not explicitly instruct them to do so or provide guidance on how to choose a more appropriate name. The action is implicit and somewhat vague, as the authors are left to infer the need for a name change and to determine the best course of action. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. However, it does not specify which part of the paper this name appears in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the name is used, the comment lacks full grounding. It is specific about the issue with the name but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the name is misleading. The suggestion is based on a general observation rather than detailed evidence, making it somewhat verifiable. The authors would need to further explore the implications of the name choice to fully address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. While the comment identifies a potential issue with the name, it does not provide specific guidance on how to choose a more appropriate name or suggest alternative names. The feedback is somewhat helpful as it highlights a potential source of confusion, but it lacks actionable advice for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. However, it does not provide specific guidance on how to choose a more appropriate name or suggest alternative names. The action is implicit and lacks concrete details, making it somewhat vague. The authors are left to infer the need for a name change but without clear direction on how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. However, it does not specify which part of the paper this name appears in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the name is used, the comment lacks full grounding. It is specific about the issue with the name but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the name is misleading. The suggestion is based on a general observation rather than detailed evidence, making it somewhat verifiable. The authors would need to further explore the implications of the name choice to fully address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to confusion. While the comment identifies a potential issue with the name, it does not provide specific guidance or suggestions on how to choose a more appropriate name or what aspects of the name might be misleading. This lack of actionable advice limits the usefulness of the feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_r"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the proposed method is not the best performer in both robustness and fidelity, but it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their method. The feedback lacks actionable details, such as recommending specific changes to the experimental setup, alternative methods to enhance robustness and fidelity, or additional analyses that could be conducted. Without concrete steps or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the experiments show the proposed method is not the best performer in both robustness and fidelity. However, it does not specify which experiments or results are being referred to, nor does it provide details on what aspects of the method are lacking or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, based on the experimental results. However, the comment does not provide specific examples, data, or references to support this claim. Without detailed evidence or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable due to the lack of supporting information.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the proposed method is not the best performer in both robustness and fidelity, based on the experimental results. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular aspects of the method that need enhancement or offering guidance on how to address the identified issues, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the paper regarding the motivation and logical connections between the concepts of isometry, OT, and disentanglement. It explicitly states that the authors should explain these connections more clearly in the revision. The comment provides a specific expectation for the authors to address, which is to clarify the connections between these concepts. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the motivation and logical connections within the paper, specifically focusing on the concepts of isometry, OT, and disentanglement. It highlights a lack of clarity in the explanation of how these concepts are interconnected, particularly regarding the claim that adding geometrical constraints (isometry) can help disentanglement. The comment also questions the necessity of OT for isometry and suggests that the authors should clarify these connections more clearly. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the sections discussing these concepts. The comment is specific in detailing what needs to be clarified, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the motivation and logical connections in the paper, specifically regarding the concepts of isometry, OT, and disentanglement. The reviewer questions the connection between adding geometrical constraints (isometry) and disentanglement, as well as the necessity of OT for isometry. While the comment identifies specific areas of confusion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left with a general sense of dissatisfaction but without concrete guidance on how to address the issues. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires more detailed justification or evidence to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper regarding the motivation and logical connections between the concepts of isometry, OT, and disentanglement. It points out that the authors claim a connection between adding geometrical constraints (isometry) and disentanglement, but this connection is not well explained in the paper. The reviewer also questions the necessity of OT for isometry and suggests that the authors should clarify these connections more clearly in the revision. This feedback is clear and actionable, providing the authors with specific areas to address and improve in their draft. By highlighting these gaps, the comment offers valuable guidance for enhancing the clarity and coherence of the paper. Therefore, it is mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of the results on regular languages to understanding real-world language models. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their draft. There is no guidance on whether the authors should provide additional explanations, conduct further analysis, or explore how these results relate to real-world language models. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results on regular languages and questions their relevance to understanding real-world language models. However, it does not specify which part of the paper discusses these results, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where regular language results are discussed, the comment lacks full grounding. It is specific in questioning the relevance of the results but does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages to understanding real-world language models. However, it does not provide any supporting evidence, reasoning, or examples to justify why these results might not be helpful. The comment lacks specific details or references that would help the authors understand the basis of the critique or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to understand and address the concern. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the relevance of the results on regular languages to understanding real-world language models. While it identifies a potential gap in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback lacks actionable advice or detailed insights that would help the authors enhance their work. As a result, the comment is barely helpful, as it points out a potential weakness but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M proposed in the paper is the same as that in Venom [1]. While the comment highlights a potential issue with the novelty claim, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they need to clarify the differences between their work and the Venom paper, but the comment lacks concrete steps or detailed advice on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M proposed in the paper is the same as that in Venom [1]. However, it does not specify which part of the paper this question pertains to, such as the introduction, related work section, or methodology. The authors can infer that it relates to the novelty or contribution section, but this inference is not direct. The comment is specific in its inquiry about the differences between the paper and Venom [1], but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M proposed in the paper is the same as that in Venom [1]. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the paper lacks novelty or to clarify the differences between the two works. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper in relation to the Venom paper [1], specifically questioning whether the V:N:M proposed in the paper is the same as that in Venom [1]. While it highlights a potential issue with the novelty claim, it does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from the Venom paper. The comment lacks actionable feedback or detailed advice, leaving the authors with only a vague indication of a potential problem. Therefore, the comment is barely helpful, as it points out an area for consideration but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the qualitative intuition of the attribution maps, specifically noting that the attended areas of the image do not seem to be related to the actual task or lack clear semantic meaning. However, it acknowledges that the resulting analysis using the attribution maps appears to work, suggesting that there might be a quantitative value. The comment does not provide explicit guidance on how to address the issue of qualitative intuition or suggest specific actions to improve it. The feedback lacks actionable details, leaving the authors uncertain about how to enhance the qualitative aspect of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the qualitative intuition of the attribution maps, noting that the attended areas of the image do not seem to be related to the actual task or lack clear semantic meaning. The comment further acknowledges that the resulting analysis using the attribution maps appears to work, suggesting a quantitative value. However, it highlights the absence of a qualitative value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the qualitative intuition of the attribution maps, specifically noting that the attended areas of the image do not seem to be related to the actual task or lack clear semantic meaning. The reviewer acknowledges that the resulting analysis using the attribution maps appears to work, suggesting a quantitative value. However, the comment lacks specific examples or detailed reasoning to support the claim about the qualitative intuition being lacking. This makes the claim somewhat verifiable, as it provides some insight but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the attribution maps, noting that the attended areas of the image do not seem to be related to the actual task or lack clear semantic meaning. It acknowledges that the resulting analysis using the attribution maps appears to work, suggesting a quantitative value, but questions the qualitative value. This feedback is somewhat helpful as it highlights a potential weakness in the qualitative interpretation of the attribution maps, prompting the authors to consider whether their analysis adequately captures the intended meaning. However, the comment could be more helpful if it provided suggestions on how to improve the qualitative interpretation or offered examples of what constitutes a more intuitive attribution map. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it suggests that the title overclaims the contribution of the paper, as it only shows results on two language models (BERT and RoBERTa) without including results from large language models (LLMs) like Llama2-70b. The reviewer asks whether the proposed method can be scalable to LLMs and requests empirical justification if it can. Second, the reviewer points out a minor inconsistency in terminology, suggesting that the term \u201cROBERTA\u201d should be consistent throughout the paper. While the first part of the comment implies an action (to provide empirical justification for scalability), it is not explicitly stated. The second part is explicit and concrete, providing clear guidance on how to address the inconsistency in terminology. Overall, the comment is mostly actionable, as it provides a clear direction for improvement in both the content and terminology aspects of the paper.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title and specific sections of the paper, such as \"Section 3.3\" and \"Introduction,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issue with the title, questioning whether it overclaims the contribution of the paper, and suggests the need for empirical justification if the proposed method can be scalable to large language models (LLMs). Additionally, it points out a minor inconsistency in terminology regarding the term \"ROBERTA.\" Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the title\\'s overstatement, noting that the results are only shown on two language models (BERT and RoBERTa) without including results from large language models (LLMs) like Llama2-70b. The reviewer questions the scalability of the proposed method to LLMs and requests empirical justification if it can be applied. This claim is somewhat verifiable as it provides a logical basis for questioning the title\\'s claims, but it lacks specific examples or references to support the need for empirical justification. The comment also points out a minor inconsistency in terminology, which is a separate issue. Overall, the claim is supported by logical reasoning but could benefit from more detailed evidence or references to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses two main points. First, it questions the title of the paper, suggesting that it overclaims the contribution by only showing results on two language models (BERT and RoBERTa) without including results from large language models (LLMs) like Llama2-70b. The reviewer asks whether the proposed method can be scalable to LLMs and requests empirical justification if it can. This feedback is clear and actionable, providing a specific direction for the authors to consider in revising their title and methodology. Second, the comment points out a minor inconsistency in terminology, suggesting that the term \u201cROBERTA\u201d should be consistent throughout the paper. This is a straightforward and actionable suggestion for improving the paper\\'s consistency. Overall, the comment is mostly helpful as it identifies a significant issue with the title and provides a clear suggestion for improvement, while also addressing a minor formatting issue. However, it could be more helpful if it offered additional guidance on how to address the scalability concern. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not provide a specific motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should provide a more detailed explanation or justification for this choice. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the need for a more detailed explanation or justification for the choice of variables, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment mentions that the authors speculate on the possibility of spurious correlations but does not elaborate on why this speculation is insufficient or how it impacts the paper\\'s argument. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should provide a more detailed explanation or justification for this choice, which is a valuable critique. However, the comment does not offer specific guidance or examples on how the authors might address this issue, such as by discussing potential reasons for including these variables or how they might impact the study. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should provide a more detailed explanation or justification for this choice. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation but are not given concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the need for a more detailed explanation or justification for the choice of variables, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment mentions that the authors speculate on the possibility of spurious correlations but does not elaborate on why this speculation is insufficient or how it impacts the paper\\'s argument. Without additional context or justification, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should provide a more detailed explanation or justification for this choice, which is a valuable critique. However, the comment does not offer specific guidance or examples on how the authors might address this issue, such as by discussing potential reasons for including these variables or how they might impact the study. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of"}
{"generated_text": "{'actionability_rationale': \"The review comment questions the novelty of the contribution regarding exchanging channels, noting that it is achieved using batch normalization (BN). It also expresses uncertainty about the incremental nature of the contribution and suggests that Theorem 1 is based on existing work. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their draft. It lacks actionable details, such as recommending ways to clarify the contribution or suggesting additional experiments or analyses. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific point about the contribution related to exchanging channels, noting that it is achieved using batch normalization (BN). It questions the incremental nature of the contribution and suggests that Theorem 1 is based on existing work. However, the comment does not specify which part of the paper discusses exchanging channels or Theorem 1, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the concerns regarding the contribution and Theorem 1, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the contribution regarding exchanging channels, suggesting that it is achieved using batch normalization (BN) and questioning the incremental nature of the contribution. The reviewer also expresses uncertainty about the rationale of Theorem 1, suggesting it is based on existing work. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without explicit examples or references to existing work, the claim remains somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the novelty of the contribution regarding exchanging channels, noting that it is achieved using batch normalization (BN). It expresses uncertainty about the incremental nature of the contribution and suggests that the rationale of Theorem 1 is based on existing work. While the comment identifies a potential issue with the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. Without actionable feedback or detailed insights, the comment provides limited value to the authors in terms of improving their work. Therefore, it is rated as barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment questions the novelty of the contribution regarding exchanging channels, noting that it is achieved using batch normalization (BN). It also expresses uncertainty about the incremental nature of the contribution and suggests that Theorem 1 is based on existing work. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific point about the contribution related to exchanging channels, noting that it is achieved using batch normalization (BN). It questions the incremental nature of the contribution and suggests that Theorem 1 is based on existing work. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the lack of explicit references results in weak grounding. The comment is specific about the concerns regarding the contribution and Theorem 1, but without full grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the contribution regarding exchanging channels, suggesting that it is achieved using batch normalization (BN) and questioning the incremental nature of the contribution. It also expresses uncertainty about the rationale of Theorem 1, suggesting it is based on existing work. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without explicit examples or references to existing work, the claim remains somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the novelty of the contribution regarding exchanging channels, noting that it is achieved using batch normalization ("}
{"generated_text": "{'actionability_rationale': 'The review point raises two separate issues. First, it suggests that if the main contribution is to propose a practical method, then more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is an implicit suggestion that requires the authors to conduct additional studies, but it lacks concrete guidance on how to perform these studies or what specific aspects to focus on. Second, it asks for clarification on what \"K\" denotes in the paper, specifically in section 4.1, and whether \"K\" equals \"NC.\" This is a direct question that requires clarification but does not provide an action for the authors to take. Overall, the comment is mostly actionable as it provides a clear direction for additional studies but lacks concrete guidance on how to implement them, and it includes a specific question that is actionable. Therefore, it is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions \"second-order methods\" and \"K=NC,\" which could refer to specific sections or equations in the paper. However, it does not explicitly mention which part of the paper these issues pertain to, making it challenging for the authors to pinpoint the exact location. The comment is specific in its request for clarification on what \"K\" denotes and whether it equals \"NC,\" providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim that more in-depth studies are needed to establish whether the proposed method improves damping in second-order methods. However, it does not provide any supporting evidence, reasoning, or references to justify why these studies are necessary or how they would be conducted. The comment also includes a minor question about the notation \"K,\" which is not related to the main claim. Without additional context or explanation, the claim remains unverifiable, as it lacks sufficient support to guide the authors in addressing the issue. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two distinct points. First, it suggests that if the main contribution is to propose a practical method, then more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is a valuable suggestion that prompts the authors to conduct additional research to substantiate their claims. However, the comment lacks specific guidance on how to design these studies or what aspects to focus on, making it somewhat helpful. Second, the comment asks for clarification on the notation \"K,\" which first appears in section 4.1, and whether \"K\" equals \"NC.\" This is a minor point but still relevant for the authors to address. Overall, the comment provides some actionable feedback but could be more comprehensive with additional guidance on the in-depth studies. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises two separate issues. First, it suggests that if the main contribution is to propose a practical method, then more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is an implicit suggestion that requires the authors to conduct additional studies, but it lacks specific guidance on what aspects to focus on or how to design these studies. Second, the comment asks for clarification on the notation \"K,\" which first appears in section 4.1, and whether \"K\" equals \"NC.\" This is a direct question that requires clarification but does not provide an actionable suggestion for improvement. Overall, the comment is mostly actionable regarding the in-depth studies but lacks concrete guidance for the clarification question, making it a mix of actionable and non-actionable points. Therefore, it is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The review point raises two distinct issues. First, it suggests that more in-depth studies are needed to establish the effectiveness of the proposed method in improving damping in second-order methods. This is a general suggestion that lacks specificity and does not point to a particular section or aspect of the paper that needs further study. Second, it asks for clarification on the notation \"K,\" which first appears in section 4.1, and whether \"K\" equals \"NC.\" This part of the comment is specific and refers to a particular section, providing clear guidance on what needs to be clarified. Overall, the comment is partially grounded as it does not specify where the in-depth studies are needed, but it is specific in its request for clarification. Therefore, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim that more in-depth studies are needed to establish whether the proposed method improves damping in second-order methods"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically mentioning the impact of k and N on the running time. These suggestions provide explicit actions for the authors to take, making the comment highly actionable. Additionally, the minor comment about a potential mismatch between Figure 2 and the description provides a specific observation that the authors can address. Overall, the comment is clear and provides concrete guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the parameters \"k and N,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely an in-depth analysis of these parameters and the running time or complexity, including the impact of k and N on the running time. Additionally, it raises a minor comment about a potential mismatch between Figure 2 and the description. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically mentioning the impact of k and N on the running time. While the comment provides a logical reasoning for the need for additional analysis, it lacks specific examples or references to support the claim. The minor comment about a potential mismatch between Figure 2 and the description is factual and does not require verification. Overall, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting an in-depth analysis of the parameters k and N in the ablation study, which would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically mentioning the impact of k and N on the running time. This guidance is clear and constructive, offering specific areas for improvement that can significantly enhance the paper. Additionally, the minor comment about a potential mismatch between Figure 2 and the description provides a precise observation that the authors can address. Overall, the comment is highly helpful as it offers detailed and actionable suggestions for improving the draft, making it a valuable contribution to the authors\\' revision process.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the details in Appendix B regarding the averaging of results over 10 runs without indication of standard deviation. It also inquires about whether these 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. While the comment highlights areas that need clarification, it does not provide explicit instructions or suggestions on how to address these questions. The authors can infer that they need to provide additional information or justification, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the averaging of results over 10 runs and the absence of standard deviation, as well as inquiring about the nature of the 10 runs (whether they involve random hyperparameter configurations or the best selected values). This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology and results presented in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the methodology and presentation of results in the paper. It points out that the results are averaged over 10 runs but lacks information about the standard deviation, which is crucial for assessing the reliability and robustness of the findings. Additionally, the comment inquires about whether the 10 runs were conducted with random hyperparameter configurations for all baselines or with the best selected hyperparameter values. This feedback is clear and actionable, as it prompts the authors to provide additional details that would enhance the transparency and credibility of their results. By addressing these questions, the authors can improve the comprehensiveness and clarity of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more details about the task generation process in the main text, rather than just in the appendix. This provides a clear and direct action for the authors to take, ensuring that the information is accessible to readers and enhances the paper\\'s presentation. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details about the task generation process should be included in the main text, rather than just in the appendix. This provides a clear suggestion for improvement, but it does not specify which part of the main text should include these details or how they should be integrated. While the authors can infer that it relates to the section discussing the experimental setup, the comment lacks full grounding as it does not explicitly mention the section. It is specific in suggesting an improvement but not fully grounded in terms of exact placement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text, rather than just in the appendix. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper\\'s presentation. However, it lacks specific examples or references to support why this inclusion would enhance the paper. The authors might need to infer the potential benefits of this change, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that more details about the task generation process be included in the main text, rather than just in the appendix. This feedback is valuable as it highlights a specific area where the paper could be strengthened, offering readers a better understanding of the experimental setup. By addressing this point, the authors can enhance the clarity and comprehensiveness of their work, making the comment mostly helpful. However, it could be further improved by specifying which aspects of the task generation process should be detailed, which would make it more comprehensive. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the dependency of entropy on a datapoint, such as $H(p^a|x)$, to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed to enhance the clarity of the paper. The suggestion is concrete, as it outlines a specific way to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Individual-level entropy\" and \"Group-level entropy\" paragraphs, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to clarify that entropy depends on a datapoint, such as $H(p^a|x)$, to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the representation of entropy with $H$ should be clarified to indicate its dependency on a datapoint, such as $H(p^a|x)$. This claim is somewhat verifiable as it provides a logical suggestion for improving the clarity of the formulas. However, it lacks specific examples or references to support why this clarification is necessary or how it would enhance understanding. The authors might need to infer the importance of this clarification, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the clarity of the paper by suggesting that the authors clarify the dependency of entropy on a datapoint, such as $H(p^a|x)$. This feedback is specific and offers a concrete way to enhance the understanding of the formulas presented in the paper. By addressing this point, the authors can significantly improve the readability and comprehensibility of their work. However, the comment could be more helpful if it included additional context or examples to further illustrate the importance of this clarification. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a brief description of a method or approach used in the paper, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is a strength or a weakness, nor are there suggestions for improvement or further exploration. As a result, the authors are left without any actionable steps to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a method or approach used in the paper, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this observation is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of this method or approach is problematic or how it could be improved. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point describes a method or approach used in the paper, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement about the methodology used in the paper. Therefore, it fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment provides a brief description of a method or approach used in the paper, specifically mentioning the connection of tokens beyond local windows by forming new groups across previous local windows. However, it does not identify any specific weaknesses or areas for improvement, nor does it offer any guidance or suggestions for the authors to enhance their draft. Without actionable feedback or insights into how this aspect could be improved, the comment does not assist the authors in refining their work. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the relationship between the proposed DD risk and distributionally robust optimization (DRO), noting that the only difference is the use of entropy to capture distribution differences. It suggests that there are other distance metrics used in DRO literature and asks for a more comprehensive illustration of the advantages and potential benefits of the specific distance metric used. While the comment implies that the authors should provide a detailed explanation or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete steps on how to address the issue. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the relationship between the proposed DD risk and distributionally robust optimization (DRO), specifically noting the similarity in formulation and the use of entropy to capture distribution differences. It references existing works in the DRO literature that use different distance metrics and asks for a more comprehensive illustration of the advantages and potential benefits of the specific distance metric used. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the DD risk is discussed. The comment is specific in its request for a more detailed explanation of the distance metric's advantages. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the relationship between the proposed DD risk and distributionally robust optimization (DRO), noting that the only difference is the use of entropy to capture distribution differences. It references existing works in the DRO literature that use different distance metrics and asks for a more comprehensive illustration of the advantages and potential benefits of the specific distance metric used. While the comment highlights a potential gap in the paper's explanation, it does not provide specific examples or references to support the claim that the specific distance metric leads to better generalization performance. The suggestion to provide a more comprehensive illustration is logical, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises an important question about the relationship between the proposed DD risk and distributionally robust optimization (DRO), noting that the only difference is the use of entropy to capture distribution differences. It references existing works in the DRO literature that use different distance metrics and asks for a more comprehensive illustration of the advantages and potential benefits of the specific distance metric used. This feedback is clear and actionable, as it prompts the authors to provide a detailed explanation or comparison of their approach to existing methods. By addressing this question, the authors could enhance the clarity and novelty of their work. However, the comment could be more helpful if it included specific suggestions on how to present this information or examples of how other distance metrics have been used in DRO. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on annotated datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset or evaluation sections. The comment is specific in its inquiry about the dataset type and the possibility of evaluation on annotated datasets. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and an observation about the nature of the T-REx dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and seeks clarification, while the observation about the dataset type is descriptive. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset and suggests a potential improvement by evaluating their model on annotated datasets. However, the comment could be more helpful if it provided specific guidance on how to implement this evaluation or discussed the implications of using annotated datasets. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on annotated datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset or evaluation sections. The question is specific in its inquiry about the dataset type and the possibility of evaluation on annotated datasets. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and an observation about the nature of the T-REx dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and seeks clarification, making it a normal statement. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset and suggests a potential improvement by evaluating their model on annotated datasets. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this evaluation. To be more helpful, the comment could include specific recommendations or examples of how to incorporate annotated datasets into the evaluation process. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the appendix should be proofread to ensure it adheres to NeurIPS 2021 style files. Additionally, it points out specific issues in the text, such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest,\" which need to be corrected. The comment also recommends expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"P6,\" \"P9,\" and the \"appendix,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on what needs to be addressed, including the use of NeurIPS 2021 style files in the appendix, the need for proofreading, and specific issues with the text such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest.\" Additionally, it suggests expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the appendix does not use NeurIPS 2021 style files and recommends proofreading it. The comment provides specific examples of issues, such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest,\" which need to be corrected. Additionally, it suggests expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim about the style file issue or the need for proofreading. The suggestion to expand on potential negative societal impacts is also not fully supported by evidence or examples. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable pieces of feedback. It explicitly points out that the appendix does not use NeurIPS 2021 style files and recommends proofreading it, which is a clear and specific suggestion for improvement. Additionally, the comment highlights specific issues in the text, such as \"poster mean,\" \"peicewise-linear,\" and \"sugggest,\" which need to be corrected. This guidance helps the authors identify and address potential errors in their draft. Furthermore, the comment suggests expanding on the potential negative societal impacts discussed in the limitations and societal impacts section, which is a valuable suggestion for enhancing the paper\\'s comprehensiveness. Overall, the comment is mostly helpful as it provides clear and actionable feedback that can significantly improve the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should examine the training and validation curves of different losses and consider whether the model can simultaneously bring all three losses down. It also asks if there are any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to approach the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests looking at training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. However, the comment does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where these curves are discussed. This lack of explicit reference makes it weakly grounded. The comment is specific in its request for additional analysis and questions about the model\\'s performance, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should examine training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these analyses are necessary or how they would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of these suggestions or how to implement them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should examine the training and validation curves of different losses and consider whether the model can simultaneously bring all three losses down. It also asks about any tricks related to weighing these losses. While the comment identifies areas for further exploration and analysis, it lacks specific guidance or suggestions on how to conduct these analyses or what aspects to focus on. The feedback provides some direction but is somewhat vague and incomplete, making it somewhat helpful. The authors are given a general idea of what to investigate but are left without detailed instructions on how to proceed. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests examining the training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to approach the analysis or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests examining training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. While the authors might have an idea of where these aspects are discussed, the lack of explicit references leaves them uncertain. The comment is specific in its request for additional analysis and questions about the model\\'s performance, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests examining training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. However, the comment lacks any supporting evidence, reasoning, or references to justify why these analyses are necessary or how they would improve the paper. The absence of detailed justification or examples makes it difficult for the authors to understand the importance of these suggestions or how to implement them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests examining training and validation curves of different losses and questions whether the model can simultaneously bring all three losses down. It also inquires about any tricks related to weighing these losses. While the comment identifies areas for further exploration and analysis, it lacks specific guidance or suggestions on how to conduct these analyses or what specific aspects to focus on. The feedback provides some direction but is somewhat vague and incomplete, making it somewhat helpful. The authors are given a general idea of what to investigate but are left without detailed instructions on how to proceed. Therefore, the"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a lack of rigorous theoretical argument or proof for the claim that computing the GOSPA metric is NP-hard. It highlights specific issues, such as the incorrect assumption that assignment problems are NP-hard and the need for a more detailed explanation. The reviewer suggests that the paper should provide a rigorous theoretical argument or proof, which is a clear and explicit action. However, the comment does not offer specific guidance on how to achieve this, leaving the authors to infer the details of the argument or proof required. Therefore, while the action is explicit, it lacks concrete details on execution, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to the claim of NP-hardness in computing the GOSPA metric, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the claim, such as the incorrect assumption that assignment problems are NP-hard and the need for a rigorous theoretical argument or proof. The comment further specifies the potential reduction of GOSPA to an exact polynomial-time computable assignment problem and the limitation of assuming access to the optimal assignment matrix. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the claim of NP-hardness in computing the GOSPA metric, providing a logical reasoning that assignment problems are not generally NP-hard. It suggests that the paper's assumption of NP-hardness is incorrect and offers a potential reduction of GOSPA to an exact polynomial-time computable assignment problem, which would limit the applicability of the claim. The comment is mostly verifiable as it provides a clear critique of the claim but lacks specific references or detailed examples to fully substantiate the argument. Therefore, it aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's claim of NP-hardness in computing the GOSPA metric. It points out that the paper does not provide a rigorous theoretical argument or proof, merely stating that it is NP-hard due to a binary constraint. The comment further critiques the paper's assumption of NP-hardness, suggesting that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem, which would limit the applicability of the claim. This feedback is clear and actionable, as it directs the authors to provide a more robust theoretical foundation for their claim and to address the potential limitations of their assumptions. However, the comment could be more helpful if it offered specific suggestions on how to strengthen the theoretical argument or proof. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the rigor and validity of their claims.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. This direct request provides a clear action for the authors to take, which is to include a detailed algorithmic description of their solution. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper currently lacks this information, making it weakly grounded. The comment is specific in its request for an algorithmic writeup, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not provide any justification or reasoning for why this would be helpful or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. This feedback is clear and actionable, as it directly points out a specific area where the paper could be improved by providing more detailed information about the solution. However, the comment could be more helpful if it included additional context or suggestions on how to present the algorithmic writeup effectively. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off requires intelligent exploration and gradual updates during initialization, but it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify or provide additional explanations regarding the role of model averaging in their technique. However, it lacks concrete suggestions or specific actions for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is somewhat actionable, as it identifies an area for clarification but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of model averaging and its role in balancing the trade-off between KL divergence and reward. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, as it questions the effectiveness of model averaging and suggests that achieving the trade-off requires intelligent exploration and gradual updates during initialization. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off requires intelligent exploration and gradual updates during initialization, but it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the argument.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It questions the reviewer's understanding of how this trade-off is achieved, suggesting that intelligent exploration and gradual updates during initialization are necessary. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their approach. While it identifies a potential weakness, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general idea of what needs clarification but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While the action is implied, it is not explicitly stated, and the comment does not provide specific guidance on how to approach this discussion or what aspects to focus on. The authors can infer that they need to explore this topic, but the lack of concrete details makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss a different distribution for the size of the batches, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on a possible generalization with a different distribution for the size of the batches could be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of this suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While this is a relevant point that could enhance the paper by exploring alternative scenarios, the comment lacks specificity and does not provide guidance on how to approach this discussion or what specific aspects should be considered. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests discussing a possible generalization with a different distribution for the size of the batches. While it implies that the authors should include this discussion, it does not provide specific guidance on how to approach it or what aspects to focus on. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The suggestion is specific in terms of what could be discussed, but without clear grounding, the authors may struggle to identify the exact section where this discussion should be integrated. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not provide any justification, reasoning, or evidence to support why this discussion is necessary or how it would benefit the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the importance or relevance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests discussing a possible generalization with a different distribution for the size of the batches. While this is a relevant suggestion that could enhance the paper by exploring alternative scenarios, the comment lacks specificity and does not provide guidance on how to approach this discussion or what specific aspects to focus on. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests discussing a possible generalization with a different distribution for the size of the batches. While it implies that the authors should include this discussion, it does not provide specific guidance on how to approach it or what aspects to focus on. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The suggestion is specific in"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. While it highlights a potential gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The comment implies that the authors should explore the impact of different batch sizes on the initialization scale, but it lacks concrete instructions on how to conduct this exploration. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis\" and the specific aspect being addressed, which allows the authors to identify the part of the paper being discussed. It is also specific because it points out the limitation of only considering a batch size of 1 and questions how the batch size affects the effective initialization scale. This provides clear guidance on what aspect of the analysis needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the analysis. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. This feedback highlights an area where the paper could be improved by exploring the impact of different batch sizes on the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate this issue or what aspects to focus on. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. While it highlights an area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should explore the impact of different batch sizes on the initialization scale, but it lacks concrete instructions on how to conduct this exploration. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis\" and the specific aspect being addressed, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it points out the limitation of only considering a batch size of 1 and questions how the batch size affects the effective initialization scale. This provides clear guidance on what aspect of the analysis needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the analysis. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. This feedback highlights an area where the paper could be improved by exploring the impact of different batch sizes on the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects to focus on. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and questions how the batch size affects the effective initialization scale. While it highlights an area for improvement, it does not provide explicit guidance or suggestions on"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100%. However, the comment does not explicitly instruct the authors to address this observation or suggest any specific actions to clarify or explain the results. The authors can infer that they might need to provide an explanation or analysis of these results, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in Figure 7, particularly why more data leads to lower results on the ImageNet linear evaluation and provides an example of sampling 50% of the data yielding better results than sampling 100%. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the results shown in Figure 7. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100%. This feedback is somewhat helpful as it prompts the authors to clarify or explain the observed trend in their results. However, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for clarification, it does not provide actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. It explicitly suggests including FVD to enhance the paper's credibility and comparability to other video generation methods. This feedback provides a clear and direct action for the authors to take, which is to include FVD in their evaluation. The comment also points out the limited novelty and insufficient methodological depth, but these aspects are not actionable without specific guidance on how to address them. Overall, the comment is mostly actionable as it provides a concrete suggestion for improvement, but it could be more actionable if it included guidance on how to address the other issues. Therefore, it is rated as mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the lack of quantitative results on mainstream metrics like FVD, which is a specific aspect of the evaluation that the authors should address. It also references the use of VBench as the primary evaluation benchmark, allowing the authors to pinpoint the sections of the paper related to evaluation. The comment is specific in detailing what needs to be addressed, namely the inclusion of FVD to enhance credibility and comparability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. The reviewer supports this claim by suggesting that including FVD would enhance the paper's credibility and comparability to other video generation methods. This reasoning is logical and provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to studies that have successfully used FVD in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation, specifically the lack of quantitative results on mainstream metrics like FVD, which are widely recognized and robust for evaluating temporal video prediction. By suggesting the inclusion of FVD, the comment provides a clear and actionable recommendation that would enhance the paper's credibility and comparability to other video generation methods. Additionally, the comment acknowledges the paper's technical soundness but points out the limited novelty and insufficient methodological depth, which are valid concerns. However, it could be more helpful by offering specific suggestions on how to address these issues or by providing examples of how to improve the evaluation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for enhancing the paper's impact.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical details in section 2.2 are difficult to follow. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or organization of the technical details. The comment lacks explicit instructions or concrete details on what changes should be made to enhance the readability of the section. As a result, the authors are left without a clear understanding of how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"2.2,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the technical details are difficult to follow or suggest ways to improve clarity. Without specific guidance or examples, the authors may struggle to understand and address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are difficult to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the technical details in section 2.2 are difficult to follow, which is a relevant observation. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve the clarity or organization of the technical details. Without detailed feedback or examples, the authors are left without a clear path to address the issue, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises questions about the improvements offered by EVA over backbone models like OT-Flow, particularly in the context of the RFDiffusion benchmark. It asks for clarification on whether the main contribution of the work is the addition of geometry information and motif-interpolation, and whether these design choices provide benefits over prior backbones. While the comment highlights areas of potential concern, it does not provide explicit guidance or suggestions on how the authors should address these questions. The authors are left to infer that they need to provide more detailed explanations or comparisons, but the lack of concrete steps makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"an in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the improvements offered by EVA over backbone models like OT-Flow and asks for clarification on whether the main contribution is the addition of geometry information and motif-interpolation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the improvements offered by EVA over backbone models like OT-Flow, particularly in the context of the RFDiffusion benchmark. It suggests that backbone models perform better in terms of designability and success rates. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that EVA does not offer significant improvements. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the improvements offered by the work over existing backbone models, such as OT-Flow, particularly in the context of the RFDiffusion benchmark. It challenges the authors to clarify whether the main contribution of the work is the addition of geometry information and motif-interpolation, and whether these design choices provide benefits over prior backbones. This feedback is valuable as it prompts the authors to articulate the unique contributions of their work and to provide a clear rationale for their design choices. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or provided examples of how to demonstrate improvements. Overall, the comment is mostly helpful as it directs the authors' attention to a critical aspect of their work that needs clarification, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion. While it identifies a specific issue, it does not provide explicit guidance on how to address it. The authors can infer that they need to revise these sections to reduce redundancy, but the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the presence of too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not specify which sentences are identical or where these sections are located in the paper, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific about the issue of identical sentences but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand which sentences are redundant or how they could be revised. Without detailed justification or examples, the claim remains unverifiable, as it lacks the necessary evidence to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion. This feedback is valuable as it highlights a potential redundancy that could affect the clarity and flow of the paper. However, the comment lacks depth and does not provide specific guidance on how to address this issue, such as suggesting ways to rephrase or restructure these sections to avoid repetition. While it points out a problem, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. While the comment highlights a potential gap in the information provided, it does not explicitly instruct the authors to include this information or clarify the reward function. The action is implicit, as the authors can infer that they need to provide more details about the reward function, but the comment lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. However, it does not specify which part of the paper this question pertains to, such as a particular section or table where the reward function is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or improved regarding the reward function. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reward function used in the ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the reward function used in the ablation studies, asking if it is sEH. While it identifies a potential gap in the information provided, it does not offer any suggestions or guidance on how the authors might address this issue or why it is important. The comment lacks depth and actionable advice, leaving the authors with only a vague indication of what might need clarification. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the comparison between the current work and previous work, specifically regarding the use of self-generated code versus a placeholder. It suggests that the current approach, which involves sampling the model twice for each generation, may not be a fair comparison. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they should consider the fairness of their comparison but are not given concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison between the current work and previous work, particularly regarding the use of self-generated code versus a placeholder. It highlights the potential unfairness of the comparison due to the sampling of the model twice for each generation. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the comparison method, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code instead of a placeholder is not a fair comparison due to the sampling of the model twice for each generation. The reviewer provides a logical reasoning by explaining that using the placeholder code was intended in the original technique, implying that the current approach may not be a fair comparison. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the implications of this reasoning and determine how to address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the current work and previous work, specifically regarding the use of self-generated code versus a placeholder. It highlights that using the self-generated code involves sampling the model twice for each generation, which may not be a fair comparison. The comment provides a clear and actionable suggestion for improvement by pointing out the need to address this issue to ensure a fair comparison. However, it could be more helpful by offering specific guidance on how to implement this change or by suggesting alternative methods for comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and provides a starting point for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a potential issue with the fairness of the comparison between the current work and previous work, specifically regarding the use of self-generated code versus a placeholder. It points out that using the self-generated code involves sampling the model twice for each generation, which may not be a fair comparison. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative methods for comparison. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to reconsider their comparison method but without clear direction on how to do so.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the fairness of the comparison between the current work and previous work, particularly regarding the use of self-generated code versus a placeholder. It highlights the potential unfairness due to the sampling of the model twice for each generation. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the comparison method, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code instead of a placeholder is not a fair comparison due to the sampling of the model twice for each generation. The reviewer provides a logical reasoning by explaining that using the placeholder code was intended in the original technique, implying that the current approach may not be a fair comparison. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the implications of this reasoning and determine how to address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the current work and previous work, specifically regarding the use of self-generated code versus a placeholder. It highlights that using the self-generated code involves sampling the model twice for each generation, which may not be a fair comparison. The comment provides a clear and actionable suggestion"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the length and content of Sections 3 and 4, suggesting that they should be expanded to better present the main contributions of the paper. It specifically points out the absence of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. While the comment implies that the authors should expand these sections, it does not provide explicit instructions on how to do so or what specific details should be included. The action is implicit and somewhat vague, as the authors know they need to expand the sections but may not be entirely sure of the exact changes required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of these sections being squeezed into a single page and highlights the absence of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Sections 3 and 4 should be expanded to better present the main contributions of the paper, as they are currently squeezed into a single page. The comment provides a specific example of missing mathematical definitions for the quantum states in Eq (4), which makes it difficult to follow. While the comment identifies a specific issue, it lacks detailed reasoning or references to support why these sections should be expanded or how they contribute to the paper\\'s main contributions. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed justification or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Sections 3 and 4, which are crucial for presenting the main contributions, are squeezed into a single page. It highlights a particular example, the absence of precise mathematical definitions for the quantum states in Eq (4), which makes it difficult for readers to follow the content. This feedback is clear and actionable, as it provides a concrete example of where the paper could be improved to enhance clarity and comprehensiveness. However, the comment could be more helpful if it offered suggestions on how to expand these sections or what specific details should be included. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing improvement and provides some guidance on what might be missing.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated against by the recommendations of LLMs. While the comment highlights an important issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they might need to conduct an analysis or provide additional information on fairness, but the comment lacks concrete steps or specific actions to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated against by the recommendations of LLMs. However, it does not specify which part of the paper this question pertains to, such as specific sections or analyses that should address this issue. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about fairness and discrimination, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the fairness of the results with respect to under-represented groups. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated against by the recommendations of LLMs. This is a relevant concern that could impact the ethical and social implications of the research. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue in their analysis or results. While it highlights a critical area for consideration, it does not offer detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific and actionable feedback regarding the manuscript. It suggests that the paragraph describing covariance in Section 1 is too long and recommends shortening it to improve legibility. Additionally, it points out that the generation of two types of long-tailed datasets is only illustrated with two examples, suggesting that more details should be added to strengthen the paper\\'s contribution. Lastly, it mentions that the tables and figures are dense due to limited pages and recommends using more pages for the experiments on long-tailed datasets. Each of these suggestions is explicit and provides concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The review comment provides specific feedback on three distinct points. It suggests that the paragraph describing covariance in Section 1 is too long and recommends shortening it for better legibility. It also points out that the generation of two types of long-tailed datasets is only illustrated with two examples, suggesting that more details should be added to strengthen the paper\\'s contribution. Additionally, it mentions that the tables and figures are dense due to limited pages and recommends using more pages for the experiments on long-tailed datasets. Each of these points is clearly articulated and provides specific guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of minor comments and suggestions for improvement, such as shortening a paragraph and adding more details to the experiments on long-tailed datasets. These are factual observations and requests for clarification, which do not contain subjective claims or opinions that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It suggests that the paragraph describing covariance in Section 1 is too long and recommends shortening it to improve legibility. This is a clear and direct suggestion that the authors can easily implement to enhance the readability of their work. Additionally, the comment points out that the generation of two types of long-tailed datasets is only illustrated with two examples, suggesting that more details should be added to strengthen the paper\\'s contribution. This feedback is actionable and encourages the authors to provide additional information to support their claims. Lastly, the comment mentions that the tables and figures are dense due to limited pages and suggests using more pages for the experiments on long-tailed datasets. This is another actionable suggestion that can help improve the presentation of the paper. Overall, the comment is mostly helpful as it provides clear and constructive feedback that can guide the authors in enhancing their draft. However, it could be more comprehensive by offering specific examples or suggestions for how to shorten the paragraph or add more details to the illustrations. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific changes are needed or how the authors should address the issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about what aspects of EC-Diffusers need to be addressed. Without explicit references or specific guidance, the authors cannot confidently determine which sections or aspects of the paper are being questioned. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the necessary changes to make EC-Diffusers work on real-world data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on what those necessary changes might be. Without actionable feedback or detailed insights, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. While the comment implies that the authors should consider conducting a human study, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to implement such a study or what specific aspects should be evaluated. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its request for a human study to gauge efficacy, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the evaluation process and the inclusion of a human study. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reliability of the evaluation process, specifically inquiring whether there is a human study to gauge the efficacy of the evaluation protocol used in the benchmark. This feedback highlights a potential gap in the evaluation methodology, prompting the authors to consider whether their evaluation is sufficiently robust and whether additional human studies could enhance the credibility of their findings. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending particular types of human studies or methodologies to consider. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, noting that it seems somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty of their work or differentiate it from existing contributions. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not specify which parts of the paper are being compared or how the technical contribution is perceived as incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, the comment does not provide specific details or examples from the referenced works to support this claim. Without detailed comparisons or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general comparison but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the work, suggesting that it appears somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). While it identifies a potential issue with the paper\\'s contribution, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential limitation of the PromptMix approach, noting that its performance depends on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the performance of PromptMix, which depends on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the performance of PromptMix is discussed. The comment is specific in detailing what needs to be addressed, providing clear guidance on potential analyses to conduct. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential limitation of the PromptMix approach, noting that its performance depends on the quality of questions/answers generated by the LLM. The reviewer suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment identifies a relevant issue, it lacks specific examples or references to support the claim or guide the authors on how to conduct the suggested analysis. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or evidence to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the PromptMix approach, noting that its performance depends on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in order to enhance their work. By addressing this point, the authors could improve the robustness and applicability of their approach. However, the comment could be more helpful if it included specific examples or references to existing LLMs or parameter count cutoffs. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models in Section 6. While the comment implies that the authors should provide more information on the runtimes, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to include runtime data for large models. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and references \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the scalability of the approach and suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models in Section 6. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. The reviewer suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about scalability. The mention of \"appendix D.4\" provides some context, but the comment could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models. This feedback is somewhat helpful as it points out a potential issue that the authors should address, prompting them to consider the practical implications of their approach. However, the comment could be more helpful if it provided specific suggestions on how to assess or mitigate the scalability issue. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models in Section 6. While the comment implies that the authors should provide more information on the runtimes, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to include runtime data for large models. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and references \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the scalability of the approach and suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models in Section 6. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. The reviewer suggests that the authors comment on the feasibility of this approach, particularly in terms of runtimes for large models in Section 6. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about scalability. The mention of \"appendix D.4\" provides some context, but the comment could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the scalability of the submodularity approach subroutine, which uses the SATUR"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly states that the explanation of inference at test time is brief and would benefit from more details. This provides a clear and direct action for the authors to take, which is to expand on the explanation of inference at test time. The feedback is specific and actionable, as it directly instructs the authors to provide additional details, ensuring they know exactly what needs to be improved. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line number \"594,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more details on the explanation of inference at test time. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of inference at test time is brief and would benefit from more details. However, it does not provide any specific reasoning, examples, or references to support why this explanation is insufficient or how it could be improved. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more details on inference at test time. This feedback is actionable as it directs the authors to expand on this aspect, which could enhance the clarity and comprehensiveness of their work. However, the comment lacks depth and does not offer specific suggestions or examples of what additional details should be included. While it points out a clear area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the correctness and soundness of the paper, specifically regarding the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment highlights potential weaknesses but lacks actionable advice or concrete steps for improvement. As a result, the authors are left without a clear understanding of what specific changes or analyses are needed to address these concerns. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several specific issues related to the evaluation of CodeChain, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. It provides detailed feedback on each point, making it specific. However, the comment does not explicitly mention which sections of the paper these issues pertain to, such as specific experiments or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the evaluation of CodeChain, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. However, it lacks specific examples, detailed reasoning, or references to support these claims. The comment highlights potential issues but does not provide enough information for the authors to fully understand and address the concerns. As a result, the claims are not well-supported, making it difficult for the authors to verify and improve upon them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several concerns about the evaluation and effectiveness of CodeChain, specifically regarding the modality and reusability of programs generated by it, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. It highlights potential issues with the alignment of evaluation with human preference and the performance drop in the 5th iteration. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their analysis. While it identifies areas for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises several concerns about the evaluation and effectiveness of CodeChain, specifically regarding the modality and reusability of programs, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or detailed feedback that would help the authors improve their draft. As a result, the authors are left without a clear understanding of what specific changes or analyses are needed to address the concerns raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The review comment raises several concerns about the evaluation and effectiveness of CodeChain, specifically regarding the modality and reusability of programs, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. However, it does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact parts that need attention. While the comment is specific in detailing the concerns, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the evaluation and effectiveness of CodeChain, specifically regarding the modality and reusability of programs, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The mention of \"Likert scale judging by GPT-4 prompt\" provides some context, but it does not fully substantiate the claims. Without concrete evidence or detailed explanations, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several concerns about the evaluation and effectiveness of CodeChain, specifically regarding the modality and reusability of programs, the effectiveness of sub-module generation, and the analysis on the chain of self-revisions. It highlights potential issues with the alignment of evaluation with human preference and the performance drop in the 5th iteration. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of deferring classifiers based on their overall accuracy and subgroup accuracy. It suggests that the authors clarify whether the deferring classifier has higher overall accuracy at a given minimum subgroup accuracy, which could imply less fairness due to uneven error distribution across subgroups. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 306-307, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the fairness of deferring classifiers based on their overall accuracy and subgroup accuracy. The comment provides a specific inquiry into the implications of the authors\\' argument, which helps guide the authors in addressing the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the authors\\' argument regarding the fairness of deferring classifiers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the fairness implications of the authors\\' argument regarding deferring classifiers. It seeks clarification on whether the deferring classifier has higher overall accuracy at a given minimum subgroup accuracy, which could lead to less fairness due to uneven error distribution across subgroups. While the comment identifies a potential area of concern and prompts the authors to clarify their argument, it lacks specific suggestions or guidance on how to address this issue or improve the fairness of the classifier. The feedback is somewhat helpful as it encourages the authors to consider the fairness implications of their work, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report the improvement on object classification directly, in addition to the overall scene graph results. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to strengthen their paper. The comment is specific and actionable, giving the authors a concrete task to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to report the improvement on object classification directly, in addition to the overall scene graph results. This provides clear guidance on what the authors need to do to strengthen their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about the relational embedding module\\'s improvement in object classification is not supported by any results. The reviewer suggests that reporting the improvement directly on object classification would strengthen the paper. While the comment identifies a gap in the evidence provided, it lacks specific examples or references to substantiate the claim. The suggestion to report the improvement directly is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module\\'s improvement in object classification is not supported by any results. It suggests that reporting the improvement directly on object classification would strengthen the paper. This feedback is clear and actionable, providing the authors with a concrete step to take to improve their draft. By addressing this point, the authors can enhance the credibility and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to present these results or what specific metrics to use. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment provides an observation about the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small compared to the existing work. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty or scope of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment provides a critique of the paper's scope, suggesting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. It also mentions that the novelty of the manuscript is relatively small compared to the existing work. However, the comment does not specify which part of the paper this critique is based on, nor does it provide detailed guidance on how the authors might address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the scope of the paper is narrow, as it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer supports this claim by referencing the CVPR 2020 paper, providing a specific example of prior work that overlaps with the current manuscript. This reference offers a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or analysis of how the current work differs from the referenced paper, which would enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides an insightful critique of the paper's scope, noting that while the idea is interesting, the scope is relatively narrow as it combines self-supervised learning with multimodal representation learning based on hypergraph. The reviewer references a previous CVPR 2020 paper, suggesting that the novelty of the manuscript is relatively small compared to existing work. This feedback is valuable as it highlights a potential limitation in the paper's contribution and encourages the authors to consider expanding the scope or offering more innovative aspects. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or scope of the work. Overall, the comment is somewhat helpful as it identifies a key area for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment provides an observation about the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small compared to the existing work. However, the comment does not offer any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty or scope of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment provides an observation about the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. It suggests that the novelty of the manuscript is relatively small compared to the existing work. However, the comment does not specify which part of the paper this critique is based on, nor does it provide detailed guidance on how the authors might address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the scope of the paper is narrow, as it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer supports this claim by referencing the CVPR 2020 paper, providing a specific example of prior work that overlaps with the current manuscript. This reference offers"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples, specifically referencing Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a concern, a request for clarification, or a suggestion for improvement. Without any actionable advice or context, the authors are left without a clear understanding of what steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, the comment lacks specificity as it does not detail what is meant by \"intuitive attention examples\" or how they relate to Figure 4. Without further explanation or guidance on what needs to be addressed or improved, the comment remains under-specific. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a question asking for clarification about the difficulty of finding intuitive attention examples, as seen in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difficulty of finding intuitive attention examples, specifically referencing Figure 4. While it raises an interesting point about the clarity or comprehensibility of the attention examples, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue or enhance the clarity of their attention examples. As a result, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between 01 and 10 in Figure 1. While it implies that the authors should clarify this difference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. However, the comment does not specify how to address the issue, leaving the authors without concrete guidance on how to implement the change. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the difference between 01 and 10 in the figure, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a question asking for clarification about the difference between 01 and 10 in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about Figure 1, asking for clarification on the difference between 01 and 10. This feedback is somewhat helpful as it prompts the authors to provide additional information or clarification in their draft. However, the comment lacks depth and does not offer suggestions on how to improve the figure or its presentation. While it identifies a potential area for improvement, it does not provide actionable guidance or examples for the authors to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to separate the \"Related Work\" section from the \"Introduction\" section and suggests moving the three bullet points about traditional AES, deep neural AES, and pre-training AES to the \"Related Work\" section. This feedback provides a clear and direct action for the authors to take, specifying exactly what changes are needed to improve the organization of their paper. The comment is explicit and concrete, ensuring that the authors know exactly how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" and \"Related Work\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the current structure of the \"Introduction\" section is confusing, with a mix of introduction and related work content. The suggestion to move the three bullet points about traditional AES, deep neural AES, and pre-training AES to the \"Related Work\" section provides clear guidance on how to improve the organization of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current structure of the paper, with the \"Introduction\" section containing both introduction and related work content, is confusing. The reviewer recommends moving the three bullet points about traditional AES, deep neural AES, and pre-training AES to the \"Related Work\" section. While the comment provides a logical suggestion for improving the paper\\'s organization, it lacks specific reasoning or evidence to support why this change would enhance the clarity or effectiveness of the paper. The suggestion is based on a subjective assessment of the current structure, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the organization of the paper by separating the \"Related Work\" section from the \"Introduction\" section. It identifies a specific issue with the current structure, where the introduction and related work content are mixed, and suggests a more logical arrangement. By shifting the three bullet points about traditional AES, deep neural AES, and pre-training AES to the \"Related Work\" section, the authors can enhance the clarity and flow of their paper. This feedback is constructive and offers a straightforward way to improve the manuscript, making it mostly helpful. However, it could be further improved by explaining why this change is important or how it might impact the reader\\'s understanding. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a clearer presentation of the overall process and rationale for constructing the benchmark, despite already dedicating space to describing the rules and data augmentation methods. While the comment implies that the authors should improve the clarity of their explanation, it does not provide specific guidance on how to achieve this clarity or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors are left to infer the necessary improvements without concrete steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of rules and data augmentation methods used in constructing the benchmark, indicating that the overall process and rationale could be presented more clearly. However, it does not specify which sections or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these descriptions are located, the comment lacks full grounding. It is specific in suggesting that the process and rationale should be clearer, but it does not provide detailed guidance on how to achieve this clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper could benefit from a clearer presentation of the overall process and rationale for constructing the benchmark, despite already dedicating space to describing the rules and data augmentation methods. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how it could be improved. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper, specifically the clarity of the overall process and rationale for constructing the benchmark. It acknowledges that the paper already dedicates space to describing the rules and data augmentation methods, but suggests that these elements could be presented more effectively. While the comment highlights an important aspect for improvement, it lacks specific guidance or suggestions on how to enhance the clarity of the presentation. This limits the usefulness of the feedback, as the authors are left with a general idea of what needs to be improved but without detailed direction on how to achieve it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper could benefit from a clearer presentation of the overall process and rationale for constructing the benchmark, despite already dedicating space to describing the rules and data augmentation methods. However, it does not provide specific guidance on how to improve the clarity or what aspects of the process and rationale need further elaboration. The action is implicit and somewhat vague, as the authors are left to infer the necessary improvements without concrete steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the clarity of the overall process and rationale for constructing the benchmark, despite the paper already dedicating space to describing the rules and data augmentation methods. However, it does not specify which sections or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these descriptions are located, the comment lacks full grounding. It is specific in suggesting that the process and rationale should be clearer, but it does not provide detailed guidance on how to achieve this clarity. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper could benefit from a clearer presentation of the overall process and rationale for constructing the benchmark, despite already dedicating space to describing the rules and data augmentation methods. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact areas that need improvement. Without concrete evidence or examples, the claim remains vague and unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper, specifically the clarity of the overall process and rationale for constructing the benchmark. It acknowledges that the paper already dedicates space to describing the rules and data augmentation methods but suggests that these elements could be presented more effectively. However, the comment lacks specific guidance or suggestions on how to improve the clarity of the presentation. Without actionable advice or detailed feedback, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant lack of literature reviews in the paper, specifically mentioning the absence of recent advances in active learning communities, particularly in Bayesian learning. It explicitly points out the omission of the Bayesian Coreset, which is relevant to the work, and suggests that the authors should discuss how their setup is more advanced than related studies. The comment provides concrete examples of relevant literature and encourages the authors to expand their literature review to include these works. This feedback is explicit and provides clear guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of literature reviews in the paper, specifically highlighting the absence of recent advances in active learning communities, particularly in Bayesian learning. It provides specific examples, such as the Bayesian Coreset, which is relevant to the work but ignored in the literature review. Additionally, it suggests discussing how the current setup is more advanced than related studies, referencing specific works like [1] and [2]. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content, specifically mentioning the absence of literature reviews on recent advances in active learning communities, particularly in Bayesian learning. The reviewer provides a specific example, the Bayesian Coreset, which is relevant to the work but is ignored in the literature review. Additionally, the comment suggests discussing how the current setup is more advanced than related studies, referencing specific works like [1] and [2]. This provides a clear rationale and specific examples, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or additional references to fully substantiate the claim. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's literature review, specifically the lack of coverage of recent advances in active learning communities, particularly in Bayesian learning. It highlights the omission of the Bayesian Coreset, which is relevant to the work and could provide more reliable uncertainty measurements than the current approach. The comment also suggests discussing how the current setup is more advanced than related studies, referencing specific works like [1] and [2]. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. By addressing these points, the authors can enhance the comprehensiveness and relevance of their literature review, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, it does not provide any explicit or implicit suggestions on how the authors might address these issues. There is no guidance on potential modifications, alternative approaches, or specific actions that could help clarify the trends or reduce the noise. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the \"one-to-many relationship\" and the presence of noise in the plots, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment lacks specific examples or detailed reasoning to support these claims. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with Fig 2, noting that the \"one-to-many relationship\" makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. While it highlights a potential problem, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address these issues. Without specific recommendations or examples of how to improve the clarity or reduce noise in the plots, the feedback is limited in its usefulness to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, which are often not deeply optimized. It also questions whether DFSSATTEN supports training from scratch, suggesting that this aspect should be studied. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The authors are left to infer that they should consider the fairness of their comparisons and investigate DFSSATTEN's support for training from scratch. The feedback is somewhat actionable as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the comparison of DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that the comparison might be unfair due to the lack of deep optimization in these algorithms. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. The comment is fully grounded as it references specific aspects of the paper, such as the comparison with existing algorithms and the discussion on training from scratch. It is also specific because it clearly identifies the issues and questions that need to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that these algorithms are often not deeply optimized. The reviewer also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. While the comment provides logical reasoning and highlights potential issues, it lacks specific examples or references to support the claim about the lack of optimization in existing algorithms. This makes the claim somewhat verifiable, as the authors would need to further explore and verify the points raised in the comment.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important concerns about the fairness of the comparison between DFSSATTEN and existing algorithms like Performer and Reformer, noting that these algorithms may not be deeply optimized. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. The comment provides a clear and actionable suggestion for the authors to investigate and address this issue, which could significantly enhance the relevance and impact of their work. However, the comment could be more helpful if it offered specific guidance on how to conduct this analysis or suggested potential methods for comparison. Overall, the feedback is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a brief observation about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is a concern, if it needs addressing, or how the authors might improve their approach. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific method, \"VMI-SI-TI-DI-FDSM,\" and mentions its evaluation on a black-box setting when it was evaluated on a defended model. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in detailing the issue with the evaluation setting but lacks grounding as it does not clearly identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a statement about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is significant or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a brief observation about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not offer any specific feedback, suggestions, or guidance on how this observation might impact the paper or how the authors could address it. Without actionable advice or a clear explanation of the significance of this observation, the comment does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review point mentions that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when it was evaluated on a defended model. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks clarity and does not guide the authors on how to address the issue or what changes, if any, are needed. Without explicit or implicit actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific method, \"VMI-SI-TI-DI-FDSM,\" and mentions its evaluation on a black-box setting when it was evaluated on a defended model. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in detailing the issue with the evaluation setting but lacks grounding as it does not clearly identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a statement about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is significant or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and its implications for their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a brief observation about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not offer any specific feedback, suggestions, or guidance on how this observation might impact the paper or how the authors could address it. Without actionable advice or a clear explanation of the significance of this observation, the comment does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to improve the clarity of the proposed method\\'s description, but it does not provide specific details or examples of what aspects need clarification. The mention of \"questions section\" suggests that the authors should refer to additional information elsewhere in the review, but without those details, the authors are left without a clear understanding of what specific improvements are needed. The action is explicit but lacks concrete guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this description is located in. The mention of \"questions section\" implies that the authors should refer to additional information elsewhere, but without explicit references or details, the comment lacks grounding. It is specific in suggesting an area for improvement but does not provide enough detail to guide the authors on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide any specific details or examples to support this claim. The comment lacks any reasoning, evidence, or references that would help the authors understand the basis of the suggestion or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to understand and act upon the feedback. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide specific details or examples of what aspects are unclear or how they could be clarified. The mention of \"questions section\" implies that additional information is available elsewhere, but without those details, the authors are left without actionable guidance on how to enhance the clarity of their method description. This lack of specificity and actionable feedback limits the usefulness of the comment, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in a GNN, suggesting that if an edge is pruned in one layer, it should also be pruned in other layers. The reviewer asks whether there are any observations made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to investigate or explain the correlations. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of pruning strategies across different layers in a GNN, suggesting that if an edge is pruned in one layer, it should also be pruned in other layers. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the independence of pruning strategies and the potential correlations between layers, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in a GNN, suggesting that if an edge is pruned in one layer, it should also be pruned in other layers. The comment does not present an opinion or claim but rather seeks clarification or further explanation. It is a request for information and does not require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting point about the independence of pruning strategies across different layers in a GNN. It questions whether an edge pruned in one layer should also be pruned in other layers, suggesting that there might be correlations that are not being considered in the empirical evaluations. This feedback prompts the authors to reconsider their approach and potentially explore the implications of pruning strategies across layers. However, the comment lacks specific suggestions or guidance on how the authors might investigate or address this issue, making it somewhat helpful. The authors are given a direction for improvement but without detailed advice on how to proceed, which limits the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Since the action is inferred and vague, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental validation, specifically mentioning the use of CIFAR-10/100 as in-distribution data. It raises a concern about the generalizability of conclusions to other in-distribution datasets, suggesting that some datasets might need to be nuanced. However, the comment does not specify which part of the paper discusses the experimental validation or where the authors should address this concern. While the authors might infer that it relates to the experimental results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in its critique of the experimental validation approach, but without clear references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the conclusions might not generalize. The suggestion to consider other datasets is a logical point, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. It questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. This feedback is somewhat helpful as it highlights a potential limitation in the experimental setup that could affect the generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or test the generalizability of their conclusions. While it prompts the authors to consider broader validation, it lacks actionable advice, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or test the generalizability of their conclusions. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Since the action is inferred and vague, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental validation, specifically mentioning the use of CIFAR-10/100 as in-distribution data. It raises a concern about the generalizability of conclusions to other in-distribution datasets, suggesting that some datasets might need to be nuanced. However, the comment does not specify which part of the paper discusses the experimental validation, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might infer that it relates to the experimental results or discussion sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in its critique of the experimental validation approach, but without clear references to sections or details, it remains weakly grounded. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the conclusions might not generalize. The suggestion to consider other datasets is a logical point, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks concrete guidance on how to implement this suggestion or what specific insights should be derived from the gradient conflicts ratio. The authors are given a clear direction to take an additional step, but the comment could be more helpful if it included more detailed instructions on how to analyze and present the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that AlphaNets trained with alpha-divergence do not benefit from the method described in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks detailed justification or references that would help the authors understand the basis of the assertion. As a result, the claim is unverifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alpha-divergence do not seem to benefit from the method described in the paper. It suggests that showing the gradient conflicts ratio for these AlphaNets could provide insights. This feedback is somewhat helpful as it points out a specific area where the paper might be lacking and offers a suggestion for improvement. However, it could be more helpful if it provided additional context or guidance on how to analyze and present the gradient conflicts ratio. Overall, the comment provides a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks detailed guidance on how to implement this suggestion or what specific insights should be derived from the gradient conflicts ratio. The authors are given a clear direction to take an additional step, but the comment could be more helpful if it included more detailed instructions or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that AlphaNets trained with alpha-divergence do not benefit from the method described in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The suggestion to show the gradient conflicts ratio is a request for additional analysis but lacks justification for why this would provide insights. Without specific reasoning or references, the claim remains unverifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alpha-divergence do not seem to benefit from the method described in the paper. It suggests that showing the gradient conflicts ratio for these AlphaNets could provide insights. This feedback is somewhat helpful as it points out a specific area where the paper might be lacking and offers a suggestion for improvement. However, the comment could be more helpful if it provided additional context or guidance on how to analyze and present the gradient conflicts ratio. Overall, the comment provides a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks"}
{"generated_text": "{'actionability_rationale': \"The review comment questions the rationale behind the explicit SDF supervision method, specifically the inclusion of occlusion handling and view-awareness. It suggests an alternative approach of sampling a subset of the sparse point cloud and applying the loss on the 3D location without occlusion reasoning. The reviewer implies that a good reason or ablation study for the current setup is missing. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to implement the suggested approach. The action is implicit but concrete, making this comment mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Sec. 3.2,\" \"L. 165,\" and \"L. 173,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the rationale behind the explicit SDF supervision method, particularly the inclusion of occlusion handling and view-awareness. The comment suggests an alternative approach and expresses a belief that a good reason or ablation study is missing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the rationale behind the explicit SDF supervision method, particularly the inclusion of occlusion handling and view-awareness. The reviewer suggests an alternative approach and expresses a belief that a good reason or ablation study is missing. While the comment provides a logical critique of the current setup, it lacks specific examples or references to support the claim that the current approach is unnecessarily complex. The suggestion for an alternative approach is a step towards justification, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides a basis for critique but requires further elaboration to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of clarity regarding the explicit SDF supervision method, particularly in relation to occlusion handling and view-awareness. It suggests an alternative approach that seems simpler and more straightforward, questioning the necessity of the current setup. The comment also points out the absence of a good reason or ablation study for this complex setup, which is a valuable observation. While the comment highlights an area for improvement, it could be more helpful by providing specific suggestions on how to conduct the ablation study or detailing the potential benefits of the suggested approach. Overall, the feedback is somewhat helpful as it directs the authors' attention to a critical aspect of their methodology that requires clarification and improvement.\", 'helpfulness_label': '3'}"}
