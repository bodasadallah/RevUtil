{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the weak baseline models and the lack of comparison with other domain adaptation methods. It explicitly mentions the need to compare with Campos et al. (2020) and other domain adaptation methods cited in Section 8. The comment also suggests a correction in the text, changing \"The may be attributed\" to \"This may be attributed.\" While the comment clearly identifies areas for improvement, it does not provide detailed guidance on how to implement these changes or what specific aspects of the baseline models should be improved. The actions are explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"the adopted baseline models,\" \"Campos et al. (2020),\" and \"other domain adaptation methods cited in Section 8.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the need to compare with Campos et al. (2020) and other domain adaptation methods, as well as the correction in the text. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. Additionally, the comment lacks references or detailed explanations for the suggested comparisons. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without additional context or justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific weaknesses in the paper: the choice of baseline models and the lack of comparison with other relevant works. It points out that the authors do not compare their work with Campos et al. (2020), which also uses feedback in QA tasks, and that they do not compare with other domain adaptation methods, such as those cited in Section 8. Additionally, the comment suggests a correction in the text regarding the use of \"The may be attributed\" versus \"This may be attributed.\" While the comment provides clear and actionable feedback on areas for improvement, it could be more helpful by offering specific suggestions on how to enhance the comparisons or what aspects of the baseline models should be improved. Overall, the comment is mostly helpful as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies two specific issues: the weak baseline models and the lack of comparison with other domain adaptation methods. It explicitly mentions the need to compare with Campos et al. (2020) and other domain adaptation methods cited in Section 8. Additionally, it suggests a correction in the text regarding the use of \"The may be attributed\" versus \"This may be attributed.\" While the comment provides clear and explicit actions for the authors to take, it does not offer detailed guidance on how to improve the baseline models or what specific aspects of the comparison should be emphasized. The actions are concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"the adopted baseline models,\" \"Campos et al. (2020),\" and \"other domain adaptation methods cited in Section 8.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the need to compare with Campos et al. (2020) and other domain adaptation methods, as well as the correction in the text regarding the use of \"The may be attributed\" versus \"This may be attributed.\" Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. However, the comment lacks specific reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. Additionally, the suggestion to compare with other domain adaptation methods is not further elaborated, leaving the authors without clear guidance on which methods to consider. The lack of detailed justification or examples"}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific actions. First, it suggests adding a clarification about the input used in the Lample et al. Bi-LSTM-CRF model, noting that it is word embeddings, similar to the input used by Lample et al. This is an explicit and concrete suggestion, making it highly actionable. Second, it points out a potential issue with Figure 3, questioning whether the KNs are in the source language or in English, given that the mentions have been translated to English. The authors have already stated in their response that they will correct the figure, which provides a clear action for improvement. Both parts of the comment are explicit and provide concrete guidance, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed in section 2.3, suggesting the addition of a clarification about the input used in the Lample et al. Bi-LSTM-CRF model. Additionally, it raises a question about Figure 3 regarding the language of the KNs, providing a specific point for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the input used in the Lample et al. Bi-LSTM-CRF model, noting that it is word embeddings, similar to the input used by Lample et al. This is a logical suggestion for improvement, but it lacks specific reasoning or evidence to support why this clarification is necessary. The mention of Figure 3 and the question about the language of the KNs is also a request for clarification, not a claim. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify the input used in the Lample et al. Bi-LSTM-CRF model, noting that it is word embeddings, similar to the input used by Lample et al. This is a clear and direct suggestion that can help improve the clarity and accuracy of the paper. Additionally, the comment raises a question about Figure 3 regarding the language of the KNs, which the authors have stated they will correct. While the comment does not provide detailed guidance on how to address the issue with Figure 3, it still offers valuable insights and suggestions for improvement. Overall, the comment is mostly helpful as it provides actionable feedback on specific areas that need clarification, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point suggests adding a clarification about the input used in the Lample et al. Bi-LSTM-CRF model, noting that it is word embeddings, similar to the input used by Lample et al. This is an explicit and concrete suggestion, making it highly actionable. Additionally, the comment raises a question about Figure 3 regarding the language of the KNs, which the authors have stated they will correct. This part of the comment is also explicit and provides a clear action for improvement. Overall, the comment provides specific guidance on how to enhance the clarity and accuracy of the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed in section 2.3, suggesting the addition of a clarification about the input used in the Lample et al. Bi-LSTM-CRF model. Additionally, it raises a question about Figure 3 regarding the language of the KNs, providing a specific point for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the input used in the Lample et al. Bi-LSTM-CRF model, noting that it is word embeddings, similar to the input used by Lample et al. This is a logical suggestion for improvement, but it lacks specific reasoning or evidence to support why this clarification is necessary. The mention of Figure 3 and the question about the language of the KNs is also a request for clarification, not a claim. Therefore, the comment is somewhat"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or provide guidance on what kind of analysis would be appropriate. The lack of explicit instructions or concrete details leaves the authors uncertain about which claims need further analysis and how to conduct it. As a result, the comment is vague and lacks actionable guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or where in the paper these claims are located. Without specific references or detailed guidance, the authors cannot confidently determine which parts of the paper need further analysis. This lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or provide any supporting evidence or reasoning to justify why these claims need further analysis. Without specific examples or detailed explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not identify which claims are being referred to or provide guidance on what kind of analysis would be beneficial. Without clear examples or detailed suggestions, the authors are left without actionable steps to improve their draft. The feedback is vague and does not offer sufficient direction for the authors to enhance their work, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It asks for clarification on the pooling method used for embedding features (line 397) and questions the clarity of Equation (7) in line 472. The reviewer specifies that the authors need to define whether E_i represents the type or identity of AC i and notes that the LHS of the equation should be a conditional probability. These specific requests give the authors clear guidance on what needs to be addressed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"line 397\" and \"line 472,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed in each part. The comment provides detailed feedback on the pooling method used for embedding features and questions the clarity of Equation (7), including whether E_i represents the type or identity of AC i and whether the LHS of the equation should be a conditional probability. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific concerns: the clarity of Equation (7) and the pooling method used for embedding features. The comment provides detailed questions and observations, such as whether E_i represents the type or identity of AC i and whether the LHS of the equation should be a conditional probability. These points are well-supported by logical reasoning and specific examples, making the claims mostly verifiable. However, the comment could be strengthened by providing references or additional examples to fully substantiate the claims. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on two critical aspects of the paper\\'s presentation. It highlights the need for clarification regarding the pooling method used for embedding features (line 397), which is crucial for understanding the model\\'s architecture. Additionally, it questions the clarity of Equation (7) in line 472, specifically addressing whether E_i represents the type or identity of AC i and whether the LHS should be a conditional probability. These points are clear and provide the authors with precise areas to focus on for improvement, ensuring that the feedback is both actionable and valuable. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. This feedback is clear and specific, giving the authors a direct action to take\u2014adding empirical evidence to substantiate their claim. The comment provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result section. The authors can infer that it relates to the contributions or results sections, but this inference is not direct. The comment is specific in its request for empirical evidence, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to justify why this evidence is necessary or how it would strengthen the paper. The lack of supporting information makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. This feedback is clear and actionable, as it directs the authors to substantiate their claims with concrete evidence. By addressing this point, the authors can strengthen their paper by demonstrating the effectiveness of their algorithm in a specific context. However, the comment could be more helpful if it offered specific guidance on how to collect or present this evidence. Overall, the feedback is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should provide more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The reviewer provides specific examples of where the DeiT-B models do not outperform other models, suggesting that CNNs can give more consistent improvements in model capacity. However, the comment does not provide explicit guidance on how to conduct this additional analysis or what specific aspects should be focused on. While the action is implied, it lacks concrete details on how to implement the suggested analysis, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the disagreement with the authors\\' viewpoint on the performance of ViT (DeiT) models compared to CNNs, particularly in terms of increased model capacity. The comment provides specific examples and reasoning, such as the performance of DeiT-B models in APTOS2019 and ISIC2019, and the consistent improvements of CNNs with increased capacity. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the authors' viewpoint by providing specific examples and reasoning to support the claim that CNNs and ViTs do not benefit similarly from increased model capacity. The reviewer points out that DeiT-B models do not outperform DeiT-T in APTOS2019 and other datasets, and that CNNs consistently improve with increased capacity except on ISIC2019. This detailed analysis and specific examples provide a robust foundation for the claim, making it fully verifiable. The authors can clearly understand the basis of the disagreement and the need for further analysis or clarification in their paper.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment provides a specific critique of the authors' viewpoint regarding the performance of ViT (DeiT) models compared to CNNs, particularly in terms of increased model capacity. It highlights a discrepancy in the results presented in Figure 3, where the DeiT-B models do not consistently outperform other models. The reviewer offers a detailed analysis of the performance trends, pointing out that CNNs can provide more consistent improvements in model capacity. This feedback is clear and actionable, as it directs the authors to reconsider their analysis and provide a more nuanced discussion of the results. However, the comment could be more helpful if it suggested specific ways to address the identified issues or provided additional context for the authors to consider. Overall, the comment is mostly helpful, as it effectively guides the authors toward a more thorough and accurate analysis of their results.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules and mentions that the group attention design is related to ResNeSt. However, it does not provide specific guidance on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as suggesting ways to differentiate the proposed method or providing examples of how to enhance its novelty. As a result, the authors are left without clear steps to take in response to this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the novelty of the proposed method, noting its similarity to existing attentional modules and its relation to ResNeSt. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issue of limited novelty and the potential overlap with existing works, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and its relation to ResNeSt. The reviewer supports this claim by referencing specific works ([1, 2, 3, 4]) that are mentioned in the comment. However, the comment lacks detailed comparisons or specific examples from these references to fully substantiate the claim. While the references provide some support, the lack of explicit comparisons or detailed analysis makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the novelty of the proposed method, noting its similarity to existing attentional modules and its relation to ResNeSt. It highlights that the overall structure of the proposed method is similar to those in previous works, despite the mention of group attention. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing literature. While it points out a potential weakness, it does not provide actionable feedback or constructive advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules and its relation to ResNeSt. However, it does not provide specific guidance or suggestions on how the authors could address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the novelty of the proposed method, noting its similarity to existing attentional modules and its relation to ResNeSt. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issue of limited novelty and the potential overlap with existing works, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and its relation to ResNeSt. The reviewer supports this claim by referencing specific works ([1, 2, 3, 4]) that are mentioned in the comment. However, the comment lacks detailed comparisons or specific examples from these references to fully substantiate the claim. While the references provide some support, the lack of explicit comparisons or detailed analysis makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the novelty of the proposed method, noting its similarity to existing attentional modules and its relation to ResNeSt. It highlights that the overall structure of the proposed method is similar to those in previous works, despite the mention of group attention. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing literature. Without actionable feedback or constructive advice, the comment provides only a general critique, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules and its relation to ResNe"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The comment lacks specificity and does not offer a clear action for the authors to take, leaving them uncertain about how to address the confusion. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the confusion surrounding the required implicit call to the Witness oracle. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the Witness oracle is discussed, the comment lacks full grounding. It is specific about the issue of confusion but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this call is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify this aspect of their work. Without actionable feedback or detailed insights, the authors are left with only a vague understanding of the problem, making it difficult for them to address the issue effectively. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result using a \"coarse\" methodology, questioning the need for this observation to be made again. However, it does not provide any explicit or implicit suggestions for how the authors might improve their methodology or address this issue. There is no guidance on alternative approaches or specific changes that could be made to enhance the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' methodology for reproducing a well-known result in the literature, specifically the left political bias in ChatGPT and LLMs in general. It critiques the use of a \"coarse\" methodology, implying that the observation has been made repeatedly in the literature. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in its critique of the methodology but lacks grounding because it does not direct the authors to a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. The reviewer supports this claim by referencing the common knowledge that language models inherit biases from the corpora they are trained on, from word2vec to BERT to ChatGPT. This reasoning provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific references or examples of previous studies that have made similar observations, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the authors' methodology for reproducing a well-known result in the literature, specifically the left political bias in ChatGPT and LLMs in general. It questions the need for this observation to be made again using a 'coarse' methodology, implying that the result is not novel or significant. However, the comment does not provide any constructive feedback or suggestions for improvement, such as alternative methods or ways to enhance the novelty of the work. Without actionable guidance or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result using a \"coarse\" methodology, questioning the need for this observation to be made again. However, it does not provide any explicit or implicit suggestions for how the authors might improve their methodology or address this issue. There is no guidance on alternative approaches or specific changes that could be made to enhance the paper. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' methodology for reproducing a well-known result in the literature, specifically the left political bias in ChatGPT and LLMs in general. It questions the need for this observation to be made again using a \"coarse\" methodology. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is somewhat specific in its critique of the methodology but lacks detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It supports this claim by referencing the common knowledge that language models inherit biases from the corpora they are trained on, from word2vec to BERT to ChatGPT. This reasoning provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific references or examples of previous studies that have made similar observations, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the authors' methodology for reproducing a well-known result in the literature, specifically the left political bias in ChatGPT and LLMs in general. It questions the need for"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the distinction between training with weak supervision and semi-supervised training. It provides specific examples, such as renaming the column in Table 1 from \"Supervised\" to \"Fully supervised\" and suggesting the creation of two big columns for \"Mixture training data\" and \"Single source data.\" These suggestions are clear and concrete, giving the authors precise guidance on how to improve the clarity of their presentation. The comment is highly actionable as it provides specific and detailed instructions for enhancing the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"proposed framework row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as renaming the column to \"Fully supervised\" and suggesting the creation of two big columns for \"Mixture training data\" and \"Single source data.\" This provides clear guidance on how to improve the clarity of the presentation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the distinction between training with weak supervision and semi-supervised training. It provides a specific example from Table 1, where the proposed framework row is likely intended to refer to the semi-supervised version, and suggests renaming the column to \"Fully supervised.\" Additionally, it proposes a more detailed approach by specifying the data used for training and creating separate columns for \"Mixture training data\" and \"Single source data.\" This feedback is mostly verifiable as it offers a clear suggestion for improvement based on a specific observation in the table, but it could be strengthened with more detailed reasoning or examples from other parts of the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific issue with the clarity of the paper regarding the distinction between training with weak supervision and semi-supervised training. It offers a concrete suggestion to rename the column in Table 1 from \"Supervised\" to \"Fully supervised\" and proposes a more detailed approach by specifying the data used for training and creating separate columns for \"Mixture training data\" and \"Single source data.\" This guidance is precise and constructive, allowing the authors to make a significant improvement in the clarity and organization of their presentation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset and do not consider other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX for a more comprehensive evaluation. This feedback provides a clear and explicit action for the authors to take, which is to expand their experimental evaluation to include other datasets and model types. The suggestion is concrete, as it specifies the types of datasets and references that should be considered. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'experiments section' and the specific datasets CIFAR-10, LEAF, FedProx, and FedMAX, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive experimental evaluation that includes other datasets and model types from Federated learning benchmarks. The comment provides clear guidance on how to improve the paper by considering relevant works and expanding the experimental scope. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the main weakness of the paper is the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset and do not consider other datasets from Federated learning benchmarks. The reviewer supports this claim by suggesting that the authors should consider relevant works like FedProx and FedMAX for a more comprehensive evaluation. This provides a clear rationale for the claim, as it highlights the need for broader experimentation and references specific works that could be used as a basis for improvement. However, the comment could be strengthened by providing more detailed comparisons or examples from the suggested works. Overall, the claim is mostly verifiable due to the logical reasoning and references provided, aligning with a score of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset and do not consider other datasets from Federated learning benchmarks. The reviewer provides a clear and actionable suggestion by recommending that the authors consider relevant works like FedProx and FedMAX for a more comprehensive evaluation. This feedback is valuable as it guides the authors on how to expand their experimental evaluation to enhance the paper's comprehensiveness and impact. However, the comment could be more helpful if it included specific details on how to incorporate these datasets or works into the experimental design. Overall, the comment is mostly helpful, as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for their experiments, similar to the one used in \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification\" by He et al. (EMNLP 2018). The reviewer specifies that the authors should directly sample unlabeled data from millions of reviews, which provides a concrete action for the authors to take. This feedback is explicit and provides clear guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of unlabeled data from the Amazon review dataset, specifically mentioning the Blitzer version. It suggests that the dataset is perfectly balanced, which is impractical in real-world applications, and recommends using a more convincing setting similar to that used in \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification\" by He et al. (EMNLP 2018). This provides a clear suggestion for improvement. However, the comment does not specify which part of the paper discusses the use of this dataset, making it weakly grounded. The suggestion is specific, as it provides a concrete alternative approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of perfectly balanced unlabeled data from the Amazon review dataset is impractical in real-world applications. The reviewer suggests that the authors should use a more convincing setting, similar to that used in \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification\" by He et al. (EMNLP 2018), which involves sampling unlabeled data from millions of reviews. This claim is somewhat verifiable as it provides a logical reasoning for the impracticality of the current setup and references a relevant study for comparison. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of unlabeled data in the Amazon review dataset, noting that it is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, similar to that used in \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification\" by He et al. (EMNLP 2018), which involves sampling unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the realism and applicability of their experimental setup. By referencing a specific study, the comment offers a direct and constructive path for enhancing the draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies specific issues with the description of the MFDA setting in the Method Section, noting that the description is confusing and that the problem setting differs significantly from the original MFDA paper. The reviewer raises questions about the use of unlabeled data in source domains and the labeling of the target domain. While the comment highlights areas of confusion, it does not provide explicit guidance on how to clarify these points or suggest specific changes to the text. The authors can infer that they need to revise the description to align with the original MFDA paper, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the description of the MFDA setting, particularly the labeling of the target domain and the use of unlabeled data in source domains. The comment provides clear guidance on what needs to be clarified or revised, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the MFDA setting description, specifically questioning the use of \"sparse labels\" and the labeling of the target domain. It references the original MFDA paper by Yue et al. (2021a) to highlight the discrepancy in the problem setting description. The comment provides a logical reasoning by comparing the current description with the original paper, which helps the authors understand the issue. However, it could be strengthened by providing more detailed examples or specific suggestions for clarification. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the use of unlabeled data in source domains. The comment references the original MFDA paper by Yue et al. (2021a) to highlight the discrepancy in the problem setting description. This feedback is clear and actionable, as it directs the authors to clarify the description and ensure consistency with the original paper. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered specific examples of what needs to be changed. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides some context for the authors to consider.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment provides a detailed critique of the paper's contribution and the lack of citations of key baselines. It explicitly points out that the paper's contribution is incremental and suggests that it is a combination of existing works, specifically GraphRAG and GraphCare. The reviewer also highlights the absence of essential RAG algorithms, such as MedRetriever and KGRAG, which should have been introduced given the paper's focus on RAG for EHR. This feedback provides clear and concrete actions for the authors to take, including revising the contribution statement, citing relevant works, and introducing essential algorithms. The explicit nature of the suggestions and the detailed guidance on how to address them make this comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the review of the code and the article, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the contribution being incremental and a combination of existing works, such as GraphRAG and GraphCare. The comment further specifies the absence of key baselines and suggests introducing essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the contribution of the article is incremental and suggests that it is a combination of existing works, specifically GraphRAG and GraphCare. The reviewer supports this claim by referencing specific works, such as MedRetriever and KGRAG, which should have been introduced given the paper's focus on RAG for EHR. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how these works are combined or differ from the proposed approach. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed critique of the paper's contribution and the lack of citations of key baselines. It points out that the paper's contribution is incremental and suggests that it is a combination of existing works, specifically GraphRAG and GraphCare. The reviewer also highlights the absence of essential RAG algorithms, such as MedRetriever and KGRAG, which should have been introduced given the paper's focus on RAG for EHR. This feedback is clear and actionable, offering specific guidance on how the authors can improve their draft by expanding their literature review and introducing relevant algorithms. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these algorithms effectively. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides a structured approach for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly points out that some state-of-the-art references are missing in the experiment of face recognition, specifically mentioning Baidu's work. It suggests that this work uses the triplet loss and reports results on a dataset similar to Webface, with a higher accuracy of 98.65% on LFW compared to the results in Table 3. The comment provides a clear and specific action for the authors to take, which is to include this reference in their paper. The suggestion is concrete, as it identifies a particular work and its results that should be considered. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the experiment of face recognition and references a specific work, 'Targeting Ultimate Accuracy: Face Recognition via Deep Embedding', which provides a clear indication of the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not include this reference, which is relevant to the discussion of state-of-the-art methods. The comment further provides specific details about the work, such as the use of the triplet loss and the dataset used, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that some state-of-the-art references are missing in the experiment of face recognition, specifically mentioning Baidu's work. It provides a specific reference and details about the work, including the use of the triplet loss and the dataset used, which is similar to Webface. The reviewer also mentions that the VRF achieves a higher accuracy on LFW compared to the results in Table 3. This detailed information supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or comparison to the results in the paper, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment is highly helpful as it identifies a specific gap in the literature review by pointing out that some state-of-the-art references are missing, particularly Baidu's work on face recognition. It provides a detailed reference, including the URL and the specific results achieved, which the authors can incorporate into their paper to strengthen their discussion. The comment also highlights the similarity between the dataset used in Baidu's work and Webface, and it mentions that the VRF achieves a higher accuracy on LFW compared to the results in Table 3. This feedback is actionable and provides the authors with clear guidance on how to improve their draft by including relevant and impactful references. Therefore, the comment deserves a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is inspired by an example from previous work. This feedback provides a clear and direct action for the authors to take, ensuring they properly acknowledge and credit the original source. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is to cite the source of the example appropriately. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and suggests citing the source appropriately. This claim is somewhat verifiable as it points out a potential issue with source attribution, but it lacks specific references or examples of the previous work that inspired the example. The authors would need to make an effort to identify and cite the original source themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by an example from previous work. It provides a clear and actionable suggestion by instructing the authors to cite the source appropriately. This feedback is valuable as it helps the authors ensure proper attribution and avoid plagiarism, which is crucial for academic integrity. However, the comment could be more helpful if it provided additional context or examples of similar examples from previous work. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific observation about the methodology, noting that the embedding of the first subword token as the verb embedding is a common practice, as exemplified by Hewitt and Manning (2019, footnote 4). However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is a concern, if it needs to be addressed, or how the authors might incorporate this information into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of the embedding of the first subword token as the verb embedding and references a common practice of averaging subword representations, as exemplified by Hewitt and Manning (2019, footnote 4). This provides clear guidance on what aspect of the methodology is being discussed and referenced, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the common practice of averaging subword representations, referencing Hewitt and Manning (2019, footnote 4) as an example. This provides a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how this practice is commonly used in the field. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific observation about the methodology, noting that the embedding of the first subword token as the verb embedding is a common practice, as exemplified by Hewitt and Manning (2019, footnote 4). This feedback is somewhat helpful as it highlights a potential area of interest or comparison for the authors, which could be relevant to their work. However, the comment does not offer any actionable suggestions or guidance on how the authors might address this observation or incorporate it into their research. Without specific advice or recommendations, the authors are left with a general understanding of the issue but no clear path for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point provides a specific observation about the methodology, noting that the embedding of the first subword token as the verb embedding is a common practice, as exemplified by Hewitt and Manning (2019, footnote 4). However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on whether this observation is a concern, if it needs to be addressed, or how the authors might incorporate this information into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of the embedding of the first subword token as the verb embedding and references a common practice of averaging subword representations, as exemplified by Hewitt and Manning (2019, footnote 4). This provides clear guidance on what aspect of the methodology is being discussed and referenced, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the common practice of averaging subword representations, referencing Hewitt and Manning (2019, footnote 4) as an example. This provides a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how this practice is commonly used in the field. While the reference is helpful, the lack of additional context or explanation limits the full verification of the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific observation about the methodology, noting that the embedding of the first subword token as the verb embedding is a common practice, as exemplified by Hewitt and Manning (2019, footnote 4). This feedback is somewhat helpful as it highlights a potential area of interest or comparison for the authors, which could be relevant to their work. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review point provides a brief description of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not offer any specific guidance or suggestions for improvement. The comment lacks actionable details, such as recommending ways to enhance the experiments or suggesting additional experiments to address specific issues. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the experiments are being evaluated or what specific issues need addressing. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point describes the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement about the experiments conducted, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a brief description of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not identify any specific weaknesses or areas for improvement in the experiments or the paper as a whole. Without actionable feedback or suggestions for enhancement, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions in their work. The action is implicit, as the authors can infer that they might need to consider these references, but it lacks concrete guidance on how to apply this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the bounded noise assumption and its limitations in stochastic optimization literature, referencing specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the bounded noise assumption and provides references to relevant works, which helps the authors understand the context and potential improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou to support this claim. The references to these works provide a solid foundation for the claim, as they demonstrate efforts to extend noise conditions in stochastic gradient descent (SGD). This makes the claim mostly verifiable, as the authors can verify the claim by examining the referenced works. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a limitation of the bounded noise assumption in stochastic optimization literature, suggesting that it is somewhat restrictive. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou, which have made efforts to extend these noise conditions. This feedback is valuable as it directs the authors to relevant literature that could inform their work, potentially leading to more robust theoretical foundations or methodological advancements. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or address the limitations of the bounded noise assumption in the authors\\' context. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking if it refers to 100 sampled strategies. While the comment highlights a potential area of confusion, it does not provide explicit guidance on how the authors should clarify this point. The action is implicit, as the authors need to infer that they should provide clarification on the meaning of \"100 steps,\" but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what the authors need to clarify or address in their paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking if it refers to 100 sampled strategies. This feedback is somewhat helpful as it highlights a potential area of confusion in the paper that the authors need to clarify. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending ways to improve the clarity of the explanation. While it points out a specific area that needs clarification, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly instructs the authors to discuss the reason why their proposed algorithm DMLCBO does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. It also asks for a discussion on the theoretical technique differences between DMLCBO and these previous works. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed and why. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and references specific previous works, SUSTAIN and MRBO, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the proposed algorithm not achieving the same convergence rate as previous works using the double momentum technique and encourages the authors to discuss the reason and theoretical differences. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. The reviewer provides a specific comparison, stating that these previous works achieve a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$, while DMLCBO only achieves $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-4})$. This comparison provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific details or examples from the cited works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a specific and actionable critique by pointing out a potential weakness in the proposed algorithm DMLCBO. It highlights that while the double momentum technique is used, the algorithm only achieves a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-4})$, compared to the $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ achieved by previous works like SUSTAIN and MRBO. The comment encourages the authors to discuss the reason for this discrepancy and to explore the theoretical differences between DMLCBO and these previous works. This feedback is clear and provides a concrete direction for the authors to improve their draft by addressing a significant gap in their work. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the scalability of their modulator, but it lacks concrete steps or recommendations on how to investigate or mitigate potential scalability problems. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the design of the modulator, suggesting that it is heuristically designed and questioning the scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or the scalability issue, making it weakly grounded. The comment is specific in its concern about the scalability and the potential need for hyperparameter tuning, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of why scalability might be an issue, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specific guidance or suggestions on how the authors might address this scalability concern. It does not provide actionable steps or examples that could help the authors improve their work. As a result, the feedback is somewhat helpful, as it points out an area for improvement but does not offer detailed guidance for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention the use of untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their OOD experiments. It also implies that the authors should ideally compare their method with those untrained neural networks. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate this information into the paper or what aspects to focus on when comparing with the mentioned methods. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), and ideally compare with those methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the interesting aspect of the OOD experiments, where the trained network demonstrates strong generalization. It then references recent papers that have shown untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), to be effective in solving inverse problems across a wide range of images. The comment suggests that mentioning these untrained networks and comparing them with the current method would provide context and potentially enhance the paper. While the reference to the deep image prior is a relevant point, the comment lacks specific examples or detailed comparisons that would fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis for the suggestion but could benefit from more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the interesting aspect of the OOD experiments, where the trained network demonstrates strong generalization. It suggests that the authors should mention untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their work. This feedback is somewhat helpful as it provides a specific suggestion for improving the paper by placing the current method in a broader context and potentially comparing it with existing methods. However, the comment could be more helpful if it included specific guidance on how to integrate this information or what aspects of the comparison would be most beneficial. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the interesting aspect of the OOD experiments, where the trained network demonstrates strong generalization. It suggests that the authors should mention untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their work and ideally compare with those methods. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate this information into the paper or what aspects to focus on when comparing with the mentioned methods. The action is explicit but somewhat vague in terms of execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests mentioning untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), and ideally comparing with those methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the interesting aspect of the OOD experiments, where the trained network demonstrates strong generalization. It references recent papers that have shown untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), to be effective in solving inverse problems across a wide range of images. The comment suggests that mentioning these untrained networks and ideally comparing with them would provide context and potentially enhance the paper. While the reference to the deep image prior is a relevant point, the comment lacks specific examples or detailed comparisons that would fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis for the suggestion but could benefit from more detailed evidence or references.', 'verifiability_label':"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the readability of the first two sections of the paper, noting that the author stacked multiple previous approaches without clearly explaining each method. It provides examples of unclear statements, such as the line \"trivial\" in Fig 2(a) and the sentence \"our lower hierarchical layers zoom in time\" in line 96. While the comment highlights areas of confusion, it does not provide explicit guidance on how to clarify these sections or what specific changes should be made. The authors can infer that they need to improve the clarity of these sections, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues by providing examples of unclear statements, such as the line \"trivial\" in Fig 2(a) and the sentence \"our lower hierarchical layers zoom in time\" in line 96. This level of detail provides clear guidance on what needs to be clarified or improved in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are difficult to read due to the author\\'s failure to explain each method clearly. It provides specific examples of unclear statements, such as the line \"trivial\" in Fig 2(a) and the sentence \"our lower hierarchical layers zoom in time\" in line 96. These examples highlight areas where the explanation is lacking, making the claim somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the explanations could be improved. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the readability of the first two sections of the paper, noting that the author stacked multiple previous approaches without clearly explaining each method. It provides examples of unclear statements, such as the line \"trivial\" in Fig 2(a) and the sentence \"our lower hierarchical layers zoom in time\" in line 96. By highlighting these areas of confusion, the comment offers the authors clear and actionable feedback on how to improve the clarity and comprehensibility of their paper. However, it could be more helpful if it suggested ways to clarify these sections or provided examples of how to improve the explanations. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the claim that the method is a foundation model. It suggests that the authors should clarify whether the claim is about a foundation model and provide a justification for its usefulness. While the comment implies that the authors should include comparisons and justifications, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that the authors should clarify whether their claim is about a foundation model and provide a justification for its usefulness. However, the comment does not specify which part of the paper should include this clarification or justification, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the comparison and justification, but without explicit references to sections or parts of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and questions the justification for the claim that the method is a foundation model. The reviewer suggests that the authors should clarify whether their claim is about a foundation model and provide a justification for its usefulness. While the comment identifies a gap in the paper, it lacks specific examples or references to other DAS earthquake detectors, making it somewhat verifiable. The authors would need to make a significant effort to address the critique without additional guidance or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It questions the justification for the claim that the method is a foundation model and suggests that the authors clarify whether this claim is about a foundation model and provide a justification for its usefulness. This feedback is clear and actionable, as it directs the authors to address the comparison and justification aspects of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects of the existing methods should be considered. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights that similar analyses are already present in prior works, suggesting that the results may not be particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and other works. However, the comment does not offer explicit guidance or suggestions on how the authors could address this issue or differentiate their work from existing analyses. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to this critique. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a critique of the novelty of the analyses presented in the paper, suggesting that similar analyses are already present in prior works. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts and the work by RobustBench and other studies. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as specific sections or results. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the existing analyses and their relevance, but it lacks full grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and other works. This provides a clear and detailed justification for the claim, making it fully verifiable. The references to specific studies and examples offer robust evidence to support the assertion, allowing the authors to understand the basis of the critique and address it effectively. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment points out that similar analyses are already present in prior works, suggesting that the results may not be particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and other works. This feedback is somewhat helpful as it highlights a potential issue with the novelty of the paper's findings. However, it lacks actionable suggestions or guidance on how the authors might address this concern or differentiate their work from existing analyses. Without specific advice on how to enhance the originality or impact of the study, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that similar analyses are already present in prior works, suggesting that the results may not be particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and other works. However, the comment does not offer any explicit guidance or suggestions on how the authors could address this issue or differentiate their work from existing analyses. Without actionable advice or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a critique of the novelty of the analyses presented in the paper, suggesting that similar analyses are already present in prior works. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts and the work by RobustBench and other studies. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as specific sections or results. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the existing analyses and their relevance, but it lacks full grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench and other works. This provides a clear and detailed justification for the claim, making it fully verifiable. The references to specific studies and examples offer robust evidence to support the assertion, allowing the authors to understand the basis of the critique and"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two distinct issues. First, it corrects a factual error in the related work section, pointing out that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This provides a clear and explicit action for the authors to revise their statement. Second, it identifies a vague reference in the section on decentralized optimization, noting that \"it\" does not have a clear reference. This suggests that the authors should clarify the reference to \"it\" in the text. Both comments are explicit and provide concrete guidance on how to improve the draft, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the related work section, correcting a factual error about the Walkman algorithm, and in the section on decentralized optimization, it points out a vague reference that needs clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims. The first claim is that the statement \"However, these works are all based on the simple SGD for decentralized optimization\" is inaccurate because the Walkman algorithm is solved by ADMM with two versions. This claim is supported by a specific reference to the Walkman algorithm and its solution method, providing a clear and precise explanation. The second claim is that the reference to \"it\" in the section on decentralized optimization is vague. While this claim is somewhat verifiable, it lacks specific examples or references to substantiate the issue, making it less clear for the authors to address. Overall, the review point is mostly verifiable due to the first claim, but the second claim could be improved with more detailed justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues. First, it corrects a factual error in the related work section by clarifying that the Walkman algorithm is solved by ADMM, not just SGD. This is a clear and precise correction that the authors can easily implement to improve the accuracy of their paper. Second, it points out a vague reference in the section on decentralized optimization, noting that \"it\" does not have a clear reference. This feedback highlights a potential area for improvement in clarity and coherence, prompting the authors to revise the text to ensure that all references are clear and unambiguous. Both pieces of feedback are constructive and provide the authors with clear guidance on how to enhance their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It explicitly states that there are several works focusing on similar questions, such as [1, 2, 3], and recommends adding more experiments to address this. The action is clear and concrete, as it specifies the need for additional comparisons and provides a reference to existing works. This guidance gives the authors a direct path to improve their draft by expanding their experimental section. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, referencing specific works ([1, 2, 3]) that focus on similar questions. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method, as there are several works focusing on similar questions. The comment provides a specific suggestion to expand the experimental section, which is a clear and actionable recommendation. However, it does not reference specific works or provide detailed reasoning for why these additional comparisons are necessary, making it somewhat verifiable. The authors would need to make an effort to identify and incorporate these additional comparisons, but the suggestion is still valuable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental section, noting that the authors have only compared their method with two baselines. It suggests that there are other works focusing on similar questions, such as [1, 2, 3], and recommends adding more experimental comparisons to demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental validation by including additional comparisons. However, the comment could be more helpful if it offered specific suggestions on which additional works to consider or how to structure the additional experiments. Overall, the comment is mostly helpful as it guides the authors toward improving their draft by expanding the experimental section, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a lack of details regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the dataset creation process. The comment is specific and actionable, as it clearly outlines what information is missing and why it is important. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of details on the translation and filtering methodology, which is crucial for assessing the dataset quality. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking,\" suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or improvements needed. The lack of detailed justification or evidence results in the comment being classified as \"1: Unverifiable,\" as it does not provide sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the transparency and credibility of their dataset. However, the comment could be more helpful if it offered suggestions on what specific aspects of the filtering process should be included or how the authors might present this information. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods in the Related Work section, specifically focusing on long-context language models. It suggests discussing various techniques such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and provides concrete guidance on what the authors need to include to improve their draft. The authors know exactly what additional information is required to enhance the section, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be included in the related work section, such as discussing various methods like sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for the authors on how to enhance their section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"Related Work section is lacking details,\" specifically mentioning the need for a more comprehensive overview of existing methods and their limitations in the context of long-context language models. The comment provides specific examples of methods to include, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed guidance offers a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples of these methods, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the Related Work section, which is lacking in detail. It provides a clear and actionable suggestion by recommending that the paragraph on long-context language models should offer a more comprehensive overview of existing methods and their limitations. The comment specifies the types of methods that should be included, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which are relevant to the topic of very long documents. This feedback is highly helpful as it guides the authors on how to enhance the depth and comprehensiveness of their literature review, thereby improving the overall quality of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or guidance on which parts of the writing are unclear or how they could be improved. The lack of detailed feedback or actionable steps leaves the authors without clear direction on how to address the issues. As a result, the comment is vague and unactionable, making it difficult for the authors to know what specific changes to make to improve the writing. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what is unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to improve the writing or what specific issues are unclear. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to understand which parts of the writing are unclear or how to improve them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing should be improved and that some points in the paper are unclear. However, it lacks specificity and does not provide any examples or detailed feedback on which parts of the writing are unclear or how they could be improved. Without specific guidance or actionable suggestions, the authors are left without a clear understanding of what needs to be addressed or how to enhance the clarity of their writing. This lack of detail makes the comment unhelpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the synthetic experiment in a non-separable case and asking how the data distribution illustrated in Figure 1 can be inseparable from the network model. This provides clear guidance on what aspect of the experiment is problematic. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks detailed explanation or examples that would help the authors understand the issue or how to address it. As a result, the claim is unverifiable, making it difficult for the authors to understand and address the concern. Therefore, the feedback is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. While it identifies a potential issue, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. It does not provide actionable feedback or detailed insights into what aspects of the experiment or figure are problematic, leaving the authors with only a vague understanding of the issue. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the efficiency of pairwise matching is very low, which makes it difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the practical applicability of the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, indicating that it is very low, which makes it difficult to use in practical application systems. However, it does not specify which part of the paper discusses this efficiency, making it weakly grounded. The comment is specific in pointing out the issue of low efficiency and its impact on practical applications. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the efficiency of pairwise matching, suggesting that it is very low and may hinder its practical application. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out a concern about the efficiency of pairwise matching, stating that it is very low and may hinder its practical application. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. Without specific guidance or actionable steps, the authors are left without a clear understanding of what changes or improvements are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, indicating that it is very low, which makes it difficult to use in practical application systems. However, it does not specify which part of the paper discusses this efficiency, making it weakly grounded. The comment is specific in pointing out the issue of low efficiency and its impact on practical applications, but without clear references or sections, the authors may struggle to identify where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment lacks supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the efficiency of pairwise matching, noting that it is very low and may hinder its practical application. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out a concern about the efficiency of pairwise matching, stating that it is very low and may hinder its practical application. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, indicating that it is very low and may hinder its practical application. However, it does not specify which part of the"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that adding a method on top of other methods to improve transferability is a positive approach. However, it states that this cannot be considered a significant contribution. While the comment highlights a potential issue, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or improve the contribution of the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the addition of a method on top of other methods to improve transferability, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this method is discussed in, making it weakly grounded. The comment provides a specific critique by stating that this approach cannot be considered a significant contribution, but it lacks detailed guidance on how to address this issue or improve the contribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a positive approach but cannot be considered a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach is not significant. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that adding a method on top of other methods to improve transferability is a positive approach. However, it states that this cannot be considered a significant contribution, which is a vague and unhelpful statement. It lacks specificity and does not provide any actionable feedback or suggestions for improvement. The comment does not identify any particular weaknesses or areas where the authors could enhance their contribution, leaving the authors without guidance on how to address the feedback. Therefore, the comment is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a mix of explicit and implicit actions. It explicitly suggests toning down a statement about the neural network memorizing critical points, which is a clear and concrete action. Additionally, it suggests compressing the method section and correcting grammatical errors, including plurals and articles. These suggestions are specific and provide clear guidance on how to improve the draft. The comment also mentions a minor issue with the method section being wordy, but it does not provide specific suggestions for compression. Overall, the comment is mostly actionable due to the explicit and concrete nature of the suggestions, but the lack of detailed guidance on compressing the method section makes it less actionable. Therefore, it aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence, \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the statement, suggesting that it should be toned down, as the authors may not memorize exact \"critical points\" as such in TopoNet [24]. Additionally, the comment provides specific feedback on the method section, suggesting it could be compressed and offering examples of grammatical errors, such as plurals and articles. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, referencing TopoNet [24] as a source of clarification. This provides some support for the claim but lacks detailed reasoning or examples, making it somewhat verifiable. The second part of the comment is more verifiable, as it identifies grammatical errors and suggests compressing the method section, providing specific examples and guidance for improvement. Overall, the review point is a mix of claims and suggestions, with the grammatical and method section suggestions being more verifiable. Therefore, the overall score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of feedback. It suggests toning down a statement about the neural network memorizing critical points, referencing TopoNet [24] as a source of clarification. This is a specific and actionable suggestion that can help the authors refine their language and improve clarity. Additionally, the comment identifies grammatical errors and suggests compressing the method section, which are also actionable suggestions. However, the comment could be more helpful if it provided specific examples of grammatical errors or suggested ways to compress the method section. Overall, the feedback is mostly helpful as it offers clear guidance on improving the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point suggests toning down a statement about the neural network memorizing critical points, referencing TopoNet [24] as a source of clarification. This provides a clear and explicit action for the authors to take. Additionally, it suggests compressing the method section and correcting grammatical errors, including plurals and articles, which are also explicit actions. The comment is mostly actionable due to the explicit nature of the suggestions, but the lack of detailed guidance on compressing the method section makes it less actionable. Therefore, it aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence, \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the method section, suggesting it could be compressed and offering examples of grammatical errors, such as plurals and articles. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, referencing TopoNet [24] as a source of clarification. This provides some support for the claim but lacks detailed reasoning or examples, making it somewhat verifiable. The second part of the comment is more verifiable, as it identifies grammatical errors and suggests compressing the method section, providing specific examples and guidance for improvement. Overall, the review point is a mix of claims and suggestions, with the grammatical and method section suggestions being more verifiable. Therefore, the overall score is 3: Somewhat Verifiable.', 'verifiability_label': '3', '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors about the change in BPE vocabulary types and its potential impact on performance. While the comment implies that the authors should reconsider their claims and provide a rationale for the change in BPE vocabulary, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these concerns and provide additional explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron and COCO-LM, providing a specific critique that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also raises a question about the change in BPE vocabulary types and its potential impact on performance. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where these comparisons are presented. The comment is specific in detailing what needs to be addressed regarding the comparison and the change in BPE vocabulary. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is somewhat verifiable as it provides a logical reasoning by comparing the performance of COCO-LM with other models of similar sizes. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. Additionally, the question about the change in BPE vocabulary is a separate issue that does not directly relate to the claim about Megatron. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This critique prompts the authors to reconsider their claims and provides a basis for questioning the validity of their conclusions. Additionally, the comment raises a question about the change in BPE vocabulary types and its potential impact on performance, which could lead the authors to investigate and clarify this aspect of their experimental setup. While the comment identifies a potential issue and raises a relevant question, it lacks specific guidance or suggestions on how to address these concerns. Therefore, it is somewhat helpful, as it provides some insight but not comprehensive direction for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a concern about the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors about the change in BPE vocabulary types and its potential impact on performance. While the comment implies that the authors should reconsider their claims and provide a rationale for the change in BPE vocabulary, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these concerns and provide additional explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron and COCO-LM, suggesting that their performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also raises a question about the change in BPE vocabulary types and its potential impact on performance. However, the comment does not specify which part of the paper discusses these comparisons or the change in BPE vocabulary, making it weakly grounded. The comment is specific in detailing the issues with the comparison and the question about BPE, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is somewhat verifiable as it provides a logical reasoning by comparing the performance of COCO-LM with other models of similar sizes. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. Additionally, the question about the"}
{"generated_text": "{'actionability_rationale': \"The review comment critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides specific observations, such as the GS-P-50 model having a smaller class selectivity score and hypothesizing that additional context may reduce the network's dependency. However, the comment does not offer explicit guidance on how the authors can improve the analysis or what specific changes should be made. The feedback lacks actionable details, leaving the authors uncertain about how to address the critique effectively. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis is not convincing enough and provides a detailed explanation of the observation regarding the GS-P-50 model and ResNet-50. Additionally, it references specific works ([1] and [2]) that could be relevant to the analysis. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. The reviewer provides a specific observation from the histogram in Fig 3, which shows that the GS-P-50 model has a smaller class selectivity score, indicating that GS-P-50 shares more features and ResNet-50 learns more class-specific features. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. The comment is supported by references to relevant works, such as [1] and [2], which could provide further context or evidence for the authors to consider. This detailed explanation and reference to external works make the claim mostly verifiable, as it offers a clear rationale and evidence for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works, which would make it fully verifiable. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the analysis from line 128 to 149, noting that it is not convincing enough. It provides a detailed explanation of the observation, including the histogram in Fig 3 and the hypothesis regarding additional context reducing the network's dependency. The comment also references relevant works, which could guide the authors in further exploring the topic. However, while it highlights the problem, it does not offer specific suggestions or guidance on how to improve the analysis or address the issue. The inclusion of references is valuable, but the comment could be more helpful if it provided actionable steps or insights for the authors to enhance their analysis. Therefore, the comment is somewhat helpful, as it provides some direction but lacks comprehensive guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that some conclusions are not convincing and provides a specific example of a claim that is not supported by the evidence. It suggests that the results might be influenced by limited exploration of combination methods and mentions several references (R1, R2, R3) that demonstrate the effectiveness of feature-replay methods in continual learning. However, the comment does not explicitly instruct the authors on how to address this issue or provide concrete steps to strengthen their conclusions. The feedback is somewhat actionable as it highlights a specific area for improvement but lacks detailed guidance on how to implement the suggested changes. Therefore, the comment is rated as somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific conclusion in the paper, namely that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might be influenced by limited exploration of combination methods and provides references to support this claim. However, the comment does not explicitly mention which part of the paper this conclusion is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the potential influence of limited exploration and the references provided. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some conclusions are not convincing, specifically mentioning a statement about continuous learning with unlabeled data accumulating noise. The reviewer provides a logical reasoning by suggesting that the results might be influenced by limited exploration of combination methods. They support this claim by referencing several works, such as [R1], [R2], and [R3], which demonstrate the effectiveness of feature-replay methods in continual learning. This provides a robust foundation for the claim, making it fully verifiable. The references to external works strengthen the argument, allowing the authors to understand the basis of the critique and how to address it. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's conclusions, noting that they are not convincing. It provides a detailed critique by pointing out a particular claim, namely that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be influenced by limited exploration of combination methods and references several works that demonstrate the effectiveness of feature-replay methods in continual learning. This feedback is mostly helpful as it not only highlights a potential weakness in the paper but also provides a constructive suggestion for improvement by referencing relevant literature. However, the comment could be more helpful if it offered specific guidance on how to address the issue or suggested additional experiments to support the conclusions. Overall, the comment provides valuable insights and actionable steps for the authors to consider, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a specific issue with the paper's conclusions, noting that they are not convincing. It provides an example of a claim that is not supported by the evidence and suggests that the results might be influenced by limited exploration of combination methods. The comment references several works (R1, R2, R3) that demonstrate the effectiveness of feature-replay methods in continual learning, which could be relevant to the paper's claims. However, the comment does not explicitly instruct the authors on how to address this issue or provide specific guidance on how to strengthen their conclusions. While the feedback is somewhat actionable, it lacks detailed instructions, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific conclusion in the paper, namely that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might be influenced by limited exploration of combination methods and references several works (R1, R2, R3) that demonstrate the effectiveness of feature-replay methods in continual learning. However, the comment does not explicitly mention which part of the paper this conclusion is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the potential influence of limited exploration and the references provided. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some conclusions are not convincing, specifically mentioning a statement about continuous learning with unlabeled data accumulating noise. The reviewer provides a logical reasoning by suggesting that the results might be influenced by limited exploration of combination methods. They support this claim by referencing several works (R1, R2, R3) that demonstrate the effectiveness of feature-replay methods in continual learning. This provides a robust foundation for the claim, as it references external works to substantiate the critique"}
{"generated_text": "{'actionability_rationale': 'The review point makes a general observation about the potential hardware and software dependence of certain observations and design decisions. However, it does not provide any specific guidance or suggestions on how the authors should address this issue or what steps they should take to account for hardware and software dependencies. The comment lacks explicit or implicit actions, leaving the authors without direction on how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which observations or design decisions are being referred to, nor does it provide any context or details about why this might be an issue. Without specific references or examples, the authors cannot confidently determine which parts of the paper need attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it lacks specific examples, reasoning, or references to support this claim. Without concrete evidence or detailed explanation, the authors may find it challenging to understand the basis of the observation and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the paper's novelty is limited, as it appears to be a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It acknowledges that the paper proposes modifications like different penalty coefficients for users and items, but it still lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could improve, it does not provide explicit guidance on how to address these issues or suggest specific changes to enhance the novelty and insights. The feedback is somewhat actionable as it highlights areas for improvement but lacks concrete steps for the authors to follow. Therefore, the comment is rated as somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment critiques the paper's novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a particular application domain. It acknowledges the modifications made but points out the lack of insights into unique challenges of overcorrelation in recommender systems. However, the comment does not specify which sections or parts of the paper should be revised to address these issues, making it difficult for the authors to pinpoint where improvements are needed. The lack of explicit references to specific sections or elements of the paper makes it weakly grounded. The comment is specific in identifying the lack of novelty and unique insights, but without clear grounding, it aligns with a score of 2. Weakly Grounded and Specific.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a particular application domain. The reviewer supports this claim by stating that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. While the comment provides some reasoning, it lacks specific examples or detailed comparisons to substantiate the claim fully. The mention of different penalty coefficients for users and items is noted but not elaborated on, leaving the authors with a general sense of the critique without concrete guidance for improvement. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a particular application domain. It acknowledges that the paper proposes modifications like different penalty coefficients for users and items but notes that the overall contribution is limited. The comment highlights the need for more insights into the unique challenges of overcorrelation in recommender systems. While it points out a significant weakness in the paper's contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. This limits the comment's usefulness to the authors, making it somewhat helpful as it identifies a critical area for improvement but lacks actionable feedback.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the paper's novelty, stating that it appears to be a straightforward application of existing literature, specifically DeCorr, in a particular application domain. It acknowledges the modifications made but points out the lack of insights into unique challenges of overcorrelation in recommender systems. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this lack of novelty or enhance the paper's contribution. The feedback lacks actionable steps or specific recommendations, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment critiques the paper's novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a particular application domain. It acknowledges the modifications made but points out the lack of insights into unique challenges of overcorrelation in recommender systems. However, the comment does not specify which sections or parts of the paper should be revised to address these issues, making it difficult for the authors to pinpoint where improvements are needed. The lack of explicit references to specific sections or elements of the paper makes it weakly grounded. The comment is somewhat specific in identifying the lack of novelty and unique insights, but without clear grounding, it aligns with a score of 2. Weakly Grounded and Specific.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a particular application domain. The reviewer acknowledges the modifications made but points out the lack of insights into unique challenges of overcorrelation in recommender systems. While the comment provides some reasoning by referencing DeCorr and the application domain, it lacks specific examples or detailed comparisons to substantiate the claim fully. The mention of different penalty coefficients for users and"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity and accuracy of the explanation in Section 4.2 regarding the use of the question to learn attention on the image feature. It points out that the description does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3\" in the equation. The reviewer suggests clarifying these aspects and questions the numerical stability of the proposed method. While the comment provides explicit actions\u2014clarifying the equation and addressing the numerical stability concern\u2014it lacks concrete guidance on how to implement these clarifications. The authors are given a clear direction but may need to determine the exact changes themselves. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the clarity of the explanation regarding the use of the question to learn attention on the image feature. The comment points out the absence of the term \"r^q\" in the equation and questions the meaning of \"\u03c3,\" providing clear guidance on what needs to be clarified. Additionally, it raises a concern about the numerical stability of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity and accuracy of the explanation in Section 4.2 regarding the use of the question to learn attention on the image feature. The reviewer notes that the description does not match the equation, specifically pointing out the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment also questions the numerical stability of the proposed method, suggesting that multiplying two sigmoid activations might be ill-conditioned. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claims about numerical stability. This makes the comment somewhat verifiable, as it provides some evidence but requires further elaboration to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and accuracy of the explanation in Section 4.2 regarding the use of the question to learn attention on the image feature. It points out that the description does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment also raises a concern about the numerical stability of the proposed method, suggesting that multiplying two sigmoid activations might be ill-conditioned. This feedback is clear and actionable, as it provides specific areas for clarification and improvement, helping the authors to enhance the clarity and accuracy of their explanation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the explanation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the novelty of the paper from a methodology perspective, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional contributions that could enhance the paper\\'s novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper from a methodology perspective, specifically mentioning the ENCODE part and the decomposition part. However, it does not specify which sections or parts of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact areas needing attention. While the comment provides some context by referencing the ENCODE part and the decomposition part, it lacks full grounding as it does not explicitly mention the sections or figures being discussed. It is also not specific because it does not detail what aspects of the methodology are considered limited or how the authors might address this issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed or to explain why the decomposition part is considered incremental. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper from a methodology perspective, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but lacks the depth and specificity needed to be more beneficial.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or enhance the novelty of their work. Without actionable guidance or specific recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper from a methodology perspective, specifically mentioning the ENCODE part and the decomposition part. However, it does not specify which sections or parts of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact areas needing attention. While the comment provides some context by referencing the ENCODE part and the decomposition part, it lacks full grounding as it does not explicitly mention the sections or figures being discussed. It is also not specific because it does not detail what aspects of the methodology are considered limited or how the authors might address this issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed or to explain why the decomposition part is considered incremental. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper from a methodology perspective, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. The comment lacks depth and specificity, making it barely helpful. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment identifies a specific issue with the paper\\'s formatting, it does not provide any guidance on how to address this problem or suggestions for improvement. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the issue of reduced whitespace throughout the paper, specifically referring to equations being crammed together and captions being too close to the figures. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of violating the 9-page paper limit due to excessive whitespace reduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This is presented as a reason for rejection because it violates the 9-page paper limit. However, the comment lacks specific examples or detailed reasoning to support the claim that this violation is grounds for rejection. Without concrete evidence or references, the authors may find it challenging to understand the severity of the issue or how to address it. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It highlights that this violation of the 9-page paper limit is grounds for rejection. While the comment clearly identifies a critical issue, it lacks actionable suggestions or guidance on how the authors might address this problem or improve the paper\\'s formatting. Without specific recommendations, the authors are left with a general understanding of the issue but no clear path to resolve it. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment identifies a specific issue, it does not provide any guidance on how the authors might address this problem or suggestions for improvement. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the issue of reduced whitespace throughout the paper, specifically referring to equations being crammed together and captions being too close to the figures. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of violating the 9-page paper limit due to excessive whitespace reduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It argues that this violation of the 9-page paper limit is grounds for rejection. However, the comment lacks specific examples or detailed reasoning to support the claim that this violation is grounds for rejection. Without concrete evidence or references, the authors may find it challenging to understand the severity of the issue or how to address it. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment highlights a critical issue, it lacks actionable suggestions or guidance on how the authors might address this problem or improve the paper\\'s formatting. Without specific recommendations, the authors are left with a general understanding of the issue but no clear path to resolve it. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a specific issue with the paper\\'"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the technical details and formulations are limited and suggests that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to expand the technical details or formulations, nor are there suggestions for improving the novelty. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited and that the main novelty is reflected in the scheme or procedure. However, it does not specify which parts of the paper are lacking in technical details or formulations, nor does it provide specific examples or guidance on how to address these issues. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"technical details and formulations are limited\" and suggests that the main novelty is reflected in the scheme or procedure. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the technical details and formulations in the paper are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide specific examples or suggestions on how the authors might enhance the technical details or formulations to better showcase their novelty. Without actionable feedback or detailed guidance, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies an area for improvement but lacks specificity and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary across datasets. It suggests that the paper lacks cross-dataset experiments to test the generalization of the work. The comment provides a clear and explicit action for the authors to take, which is to perform cross-dataset experiments. This guidance is concrete, as it specifies exactly what the authors need to do to address the concern. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the risk of methods exploiting relationships between action units and the potential differences across datasets, such as the co-occurrence of AU6 in pain and happiness expressions. The comment further suggests a specific action\u2014performing cross-dataset experiments\u2014to test the generalization of the work. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the potential variability in relationships between action units across different datasets, using examples to illustrate the point. It suggests that the paper lacks cross-dataset experiments to test the generalization of the work. The claim is somewhat verifiable as it provides a logical reasoning based on the variability of action units across datasets, but it lacks specific references or detailed examples to fully substantiate the claim. The authors would need to further explore the implications of this variability themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant risk in methods that exploit relationships between action units, noting that these relationships can vary across datasets. It provides a specific example of AU6's co-occurrence in different expressions and datasets, highlighting the potential impact on generalization. The comment suggests that the paper lacks cross-dataset experiments, which would help test the generalization of the work. This feedback is clear and actionable, offering a concrete suggestion for improving the paper's robustness and generalizability. However, it could be more helpful if it provided additional guidance on how to conduct these cross-dataset experiments or discussed potential challenges in doing so. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point challenges the claim made in the paper that over-parametrization leads to overfitting and worse performance. It provides a counterpoint by referencing practical examples and theoretical work that demonstrate the benefits of over-parametrization. However, the comment does not explicitly instruct the authors to include this counterpoint or suggest how they might address the claim in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this counterpoint or addressing the claim in their draft. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the claim made in the paper about over-parametrization leading to overfitting and worse performance. The comment provides a counterpoint by referencing practical examples and theoretical work that demonstrate the benefits of over-parametrization. This provides clear guidance on what the authors need to address or consider in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper regarding over-parametrization and its impact on performance. It provides a counterpoint by referencing practical examples and theoretical work that demonstrate the benefits of over-parametrization. This reference to external sources and practical examples supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific studies that support the counterpoint. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment challenges a claim made in the paper regarding over-parametrization and its impact on performance. It provides a counterpoint by referencing practical examples and theoretical work that demonstrate the benefits of over-parametrization. This feedback is valuable as it prompts the authors to reconsider their claim and potentially revise their analysis or conclusions. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this counterpoint into the paper or addressed the implications of the claim. Overall, the comment is mostly helpful as it provides a clear direction for the authors to consider, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the experimental comparison, suggesting that it may be unfair due to differences in pre-training. It highlights that the proposed method was pre-trained before fine-tuning, and questions whether the compared methods were also initialized with a similar pre-trained model. The comment implies that the authors should clarify or address this issue, but it does not explicitly instruct them to do so. Additionally, it suggests that the proposed method without SSL performs inferior to most compared methods, which could be a concern for the authors. While the action is implicit, it is somewhat concrete as it points out a specific area for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning whether the compared methods were initialized with the same or similar pre-trained model as the proposed method. The comment further specifies the concern that the proposed method without SSL performs inferior to most compared methods, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair due to differences in pre-training between the proposed method and the compared methods. The reviewer provides a specific example by mentioning Table 1, where the proposed method without SSL performs inferior to most compared methods. This reasoning is based on the assumption that pre-training is a critical factor in the performance of the methods, which is a logical deduction. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. Therefore, the claim is mostly verifiable, as it provides a reasonable basis for the critique but could benefit from more detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to differences in pre-training between the proposed method and the compared methods. It highlights that the proposed method was pre-trained before fine-tuning, while it is unclear if the compared methods were also initialized with a similar pre-trained model. The comment further points out that the proposed method without SSL performs inferior to most compared methods, suggesting that this could be a significant concern for the authors. While the comment effectively identifies a critical aspect of the experimental setup that needs clarification, it lacks specific suggestions or guidance on how the authors might address this issue. This limits the comment\\'s helpfulness, making it somewhat helpful as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness due to differences in pre-training between the proposed method and the compared methods. It highlights that the proposed method was pre-trained before fine-tuning, and suggests that the compared methods may not have been initialized with a similar pre-trained model. The comment also points out that the proposed method without SSL performs inferior to most compared methods. While the comment raises important concerns, it does not provide explicit guidance or suggestions on how the authors should address these issues. The action is implicit and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning whether the compared methods were initialized with the same or similar pre-trained model as the proposed method. The comment further specifies the concern that the proposed method without SSL performs inferior to most compared methods, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair due to differences in pre-training between the proposed method and the compared methods. It provides a specific example by mentioning Table 1, where the proposed method without SSL performs inferior to most compared methods. This reasoning is based on the assumption that pre-training is a critical factor in the performance of the methods, which is a logical deduction. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness due to differences in pre-training between the proposed method and the compared methods"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider using better meta-data embeddings for zero-shot learning on the CUB dataset, referencing a specific table and paper for comparison. It provides a clear and explicit action for the authors to take, which is to update their results with better meta-data embeddings. The suggestion is concrete, as it specifies the reference and the potential improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"Table 1 in \u00e2\u20ac\u0153Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016\u00e2\u20ac\u0153,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests using better meta-data embeddings for zero-shot learning on the CUB dataset and references a specific paper for comparison. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of \"attribute\" meta-data for zero-shot learning on the CUB dataset is suitable for fair comparison but proposes that better meta-data embeddings could lead to improved performance. The reviewer references a specific table and paper for comparison, providing a clear rationale for the suggestion. However, the comment lacks detailed examples or specific metrics from the referenced paper to fully substantiate the claim. While the suggestion is based on a logical reasoning, the absence of detailed evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of better meta-data embeddings for zero-shot learning on the CUB dataset. It references a specific table and paper for comparison, which can guide the authors in making a more informed decision about their meta-data choices. The comment also acknowledges the authors\\' response to the reviews, indicating that the paper is acceptable for NIPS. While the feedback is actionable and provides a clear direction for improvement, it could be more helpful if it included specific details on what constitutes \"better\" meta-data embeddings or how to implement them. Overall, the comment is mostly helpful as it offers a concrete suggestion for enhancing the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks relevant literature on using moment matching instead of quantile regression for distributional reinforcement learning (DRL). It explicitly recommends discussing this literature when presenting various approaches to DRL. The comment provides a specific reference, \"Nguyen-Tang et al AAAI\u201921,\" which helps the authors understand what literature to include. The action is explicit and concrete, as it clearly identifies the literature to be discussed and provides a specific reference. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 22-30, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of relevant literature on using moment matching instead of quantile regression for DRL, and suggests discussing this literature when presenting various approaches to DRL. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression for DRL, specifically referencing Nguyen-Tang et al. AAAI\u201921. This claim is mostly verifiable as it provides a specific reference to an external work that could be included to enhance the discussion on DRL approaches. However, the comment could be strengthened by explaining why moment matching is relevant or how it differs from quantile regression, which would provide a clearer justification for the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the literature review regarding the use of moment matching instead of quantile regression for distributional reinforcement learning (DRL). It suggests that the paper should discuss relevant literature, such as Nguyen-Tang et al. AAAI\u201921, which proposes moment matching as an alternative to quantile regression. This feedback is clear and actionable, as it provides a concrete reference that the authors can include to enhance the comprehensiveness of their literature review. By addressing this point, the authors can improve the depth and relevance of their discussion on DRL approaches. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a gap in the literature review regarding the use of moment matching instead of quantile regression for distributional reinforcement learning (DRL). It suggests that the paper should discuss relevant literature, specifically mentioning Nguyen-Tang et al. AAAI\u201921, which proposes moment matching as an alternative to quantile regression. This feedback provides a clear and explicit action for the authors to take, which is to include this literature in their discussion. The suggestion is concrete, as it specifies the literature to be included and its relevance to the topic. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 22-30, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of relevant literature on using moment matching instead of quantile regression for DRL, and suggests discussing this literature when presenting various approaches to DRL. The comment provides a specific reference, \"Nguyen-Tang et al AAAI\u201921,\" which helps the authors understand the context and importance of the literature. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression for distributional reinforcement learning (DRL). It provides a specific reference, \"Nguyen-Tang et al AAAI\u201921,\" which supports the claim by suggesting that this literature should be discussed when presenting various approaches to DRL. This explicit reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explaining why moment matching is relevant or how it differs from quantile regression, which would enhance the justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the literature review regarding the use of moment matching instead of quantile regression for distributional reinforcement learning (DRL). It suggests that the paper should discuss relevant literature, such as Nguyen-Tang et al. AAAI\u201921, which proposes moment matching as an alternative to quantile regression. This feedback is clear and actionable, as it provides a concrete reference that"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could enhance the novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper by stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the novelty is perceived as limited. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the novelty of the paper by stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not provide any constructive feedback or suggestions on how the authors might enhance the novelty or address the perceived lack of originality. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper's results. It suggests that the authors should clarify how well the assumptions underlying PCA are met. However, the comment does not provide specific guidance on how the authors should address this concern or what additional information or analysis is needed to support their claims. The feedback is vague and lacks explicit instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper\\'s results. It suggests that the assumptions underlying PCA need to be clarified. However, the comment does not specify which part of the paper discusses PCA or the assumptions, making it weakly grounded. The comment is specific in its critique of the novelty and the need for clarification regarding assumptions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper\\'s results. It provides a logical reasoning by suggesting that PCA is a common technique used to retain maximum information with reduced dimensionality. However, the comment lacks specific examples or detailed explanations of how the assumptions underlying PCA are met in the paper. The reference to \"Dombrowski, Ann-Kathrin, Christopher J. Anders, Klaus-Robert M\u00fcller, and Pan Kessel. \"Towards robust explanations for deep neural networks.\" Pattern Recognition 121 (2022): 108194\" does not directly support the claim about the assumptions being met but rather provides a general reference. This makes the claim somewhat verifiable, as it provides some context but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the assumptions underlying PCA need to be clarified, which is a relevant point for the authors to address. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their results. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper's results. It suggests that the assumptions underlying PCA need to be clarified. However, the comment does not provide specific guidance or actionable steps for the authors to address these concerns. Without explicit instructions or detailed suggestions, the authors may find it challenging to determine how to improve their draft in response to this feedback. Therefore, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper\\'s results. It suggests that the assumptions underlying PCA need to be clarified. However, the comment does not specify which part of the paper discusses PCA or the assumptions, making it weakly grounded. The comment is somewhat specific in its critique of the novelty and assumptions, but without explicit references to sections or figures, the authors may struggle to identify the exact areas needing attention. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper\\'s results. It provides a logical reasoning by suggesting that PCA is a common technique used to retain maximum information with reduced dimensionality. However, the comment lacks specific examples or detailed explanations of how the assumptions underlying PCA are met in the paper. The reference to \"Dombrowski, Ann-Kathrin, Christopher J. Anders, Klaus-Robert M\u00fcller, and Pan Kessel. \"Towards robust explanations for deep neural networks.\" Pattern Recognition 121 (2022): 108194\" does not directly support the claim about the assumptions being met but rather provides a general reference. This makes the claim somewhat verifiable, as it provides some context but lacks detailed justification or evidence. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the novelty of using PCA to"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises questions about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The authors are left to infer that they should consider expanding the scope of their evaluation, but without specific directions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework, specifically mentioning the limitations in scope due to the restricted consideration of only three Question-Answering tasks and two language models. It raises questions about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or evaluation sections. The comment is specific in detailing the limitations and potential areas for improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. The reviewer questions the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies specific limitations, it lacks detailed reasoning or references to support the claim about the method\\'s applicability. The authors may find it challenging to understand the basis of the critique without additional context or examples. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to consider but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper\\'s scope and generalizability. However, the comment lacks specific suggestions or guidance on how the authors might address these limitations or expand their evaluation. While it points out a critical issue, it does not provide actionable steps for improvement, leaving the authors with a general direction but no detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not provide specific guidance or suggestions on how the authors might address this limitation or expand the scope of their evaluation. The feedback lacks actionable steps or detailed advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework, specifically mentioning the limitations in scope due to the consideration of only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies specific areas of concern, it does not explicitly mention a particular section of the paper, making it weakly grounded. However, the comment is specific in detailing the limitations and potential areas for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. The reviewer raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies specific limitations, it lacks detailed reasoning or evidence to support the claim about the method\\'s applicability. The authors may find it challenging to understand the basis of the critique without additional context or examples. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to consider but requires further elaboration to be fully actionable.', 'verifiability_label': '3', 'helpfulness"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests using a second y-axis or another visualization that is more physically accurate to address the issue with Figure 6C, which implies negative rates. This feedback provides a clear and concrete action for the authors to take, specifying the type of visualization that would be more appropriate. The comment is direct and provides specific guidance on how to improve the figure, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second y-axis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is \"a bit awkward\" because it implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. While the comment provides a logical reasoning for the issue with the figure, it lacks specific examples or references to support the claim fully. The suggestion to use a second y-axis or another visualization is a reasonable approach, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not the case. It provides a clear and actionable suggestion to use a second y-axis or another visualization that is more physically accurate. This feedback is helpful as it guides the authors on how to improve the clarity and accuracy of their figure, which is crucial for effectively communicating their results. However, the comment could be more helpful if it explained why the current visualization is problematic or provided additional guidance on how to implement the suggested changes. Overall, the comment is mostly helpful, as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room for improvement in the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left without clear instructions on what aspects of the algorithm's complexity need to be addressed or how to enhance it. The lack of explicit or implicit actions makes it difficult for the authors to determine what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 2,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, it lacks specificity as it does not detail what aspects of the complexity need improvement or how the authors might address this issue. Without specific guidance or examples, the authors may struggle to understand the exact nature of the problem or how to improve the algorithm. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that there is room for improvement in the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it lacks specificity and actionable guidance. It does not provide details on what aspects of the algorithm's complexity need improvement or how the authors might address this issue. Without concrete suggestions or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide specific guidance or suggestions on how to achieve this improvement. Without explicit instructions or concrete details, the authors are left without a clear understanding of what changes are needed or how to implement them. This lack of actionable feedback makes the comment unhelpful for the authors in improving their draft. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 2,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, it lacks specificity because it does not detail what aspects of the algorithm's complexity need improvement or how the authors might address this issue. Without specific guidance or examples, the authors may struggle to understand the basis of the suggestion and how to implement it. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that there is room for improvement in the complexity of Algorithm 2 but does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it lacks specificity and actionable guidance. It does not provide details on what aspects of the algorithm's complexity need improvement or how the authors might address this issue. Without concrete suggestions or examples, the authors are left without a clear understanding of what changes are needed or how to enhance their draft. This lack of specificity makes the comment barely helpful, as it identifies a potential area for improvement but does not offer sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide specific guidance or suggestions on how to achieve this improvement. Without explicit instructions or concrete details, the authors are left without a clear understanding of what aspects of the algorithm's complexity need addressing or how to enhance it. This lack of actionable feedback makes the comment unhelpful for the authors in improving their draft. Therefore, it aligns with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Algorithm 2,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, it lacks specificity because it does not detail what aspects of the algorithm\\'"}
{"generated_text": "{'actionability_rationale': 'The review point questions a statement in the supplemental section D.4, suggesting that it is questionable and not consistent with the author\\'s experience. It also points out that the baseline models may not be properly regularized and asks whether dropout is applied to the hidden states. While the comment raises important questions, it does not provide explicit instructions or concrete actions for the authors to take. The authors can infer that they need to clarify or address the issue, but the lack of specific guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for LM compared to the GAN model and suggests that this is not consistent with the author\\'s experience. The comment further specifies the need to clarify whether dropout is applied to the hidden states, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a statement in the supplemental section D.4, suggesting that it is questionable and not consistent with the author\\'s experience. The reviewer provides a specific example from Zaremba et al. 2014 to support their claim, indicating that larger models can be effectively trained without overfitting. This reference provides a clear and specific example, making the claim mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or additional references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a questionable statement in the supplemental section D.4, specifically questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It provides a counterexample from Zaremba et al. 2014, suggesting that larger models can be effectively trained without overfitting, which implies that the baseline models may not be properly regularized. The comment also raises a specific question about whether dropout is applied to the hidden states, which could be relevant to the regularization discussion. This feedback is clear and actionable, as it prompts the authors to reconsider their claims and possibly provide additional evidence or clarification. However, the comment could be more helpful if it offered suggestions on how to address the issue or improve the regularization discussion. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. While it implies that the authors should make the introduction more concise and incorporate empirical results, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors know they need to make the introduction more concise and include empirical results but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which sections or parts of the introduction need to be more concise or where empirical results should be included. This lack of explicit references makes it difficult for the authors to pinpoint the exact areas that need revision. While the authors might have an idea of where the introduction is located, the comment lacks specificity and grounding. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the introduction is too lengthy or how empirical results could enhance it. Without concrete evidence or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve this. The comment does not explain why the introduction is too lengthy or how empirical results could enhance it, leaving the authors with only a vague idea of what needs to be improved. Without actionable advice or specific examples, the feedback is limited in its usefulness, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or differentiate their work from existing standard analyses. The lack of actionable advice or detailed feedback leaves the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are being referred to, nor does it provide details on what aspects of the technical contribution are unclear or how the analysis could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or differentiate their work from existing standard analyses. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or differentiate their work from existing standard analyses. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what needs to be improved or how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are being referred to or provide details on what aspects of the technical contribution are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, it aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or differentiate their work from existing standard analyses. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or differentiate their work from existing standard analyses. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what needs to be improved or how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are being referred to or provide details on what aspects of the technical contribution are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, it aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the regularization approach used for the LN model compared to previous models, specifically mentioning the use of a cropped stimulus for regularization. It suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models, such as using L1 regularization for filters and a low-rank approximation for the spatial filter. While the comment implies that the authors should adjust their regularization approach to align with previous models, it does not provide explicit instructions on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific adjustments needed to make the comparison fair. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization approach used in the LN model and compares it to previous models, specifically mentioning the GLM presented by Pillow et al. This provides some grounding as it refers to a specific aspect of the paper related to regularization. However, the comment lacks full grounding because it does not explicitly mention which section or part of the paper discusses the regularization approach. It is specific in suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair, but it does not provide detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the regularization approach used in the LN model, comparing it to previous models like the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to the exact features that need to be reproduced or how the current approach deviates from previous models. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the regularization approach used in the LN model, noting that while the authors mention the need for regularization, they apply it to both LN models and GLMs. The reviewer references a previous model by Pillow et al. that used a different approach, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. This feedback is somewhat helpful as it points out a specific area where the authors might need to adjust their methodology to align with established practices. However, the comment lacks detailed guidance or suggestions on how to implement the suggested changes, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy in the regularization approach used for the LN model compared to previous models, specifically mentioning the use of a cropped stimulus for regularization. It suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models, such as using L1 regularization for filters and a low-rank approximation for the spatial filter. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific adjustments needed to align with previous models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization approach used in the LN model and compares it to previous models, specifically mentioning the GLM presented by Pillow et al. This provides some grounding as it refers to a specific aspect of the paper related to regularization. However, the comment lacks full grounding because it does not explicitly mention which section or part of the paper discusses the regularization approach. It is specific in suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair, but it does not provide detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the regularization approach used in the LN model, comparing it to previous models like the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to the exact features that need to be reproduced or how the current approach deviates from previous models. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including some failure cases and related discussion would be beneficial. While it explicitly states the action of including failure cases, it does not provide specific guidance on which failure cases to include or how to discuss them. The authors are left with a clear action to take but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper should include these elements. This makes it difficult for the authors to pinpoint where these additions should be made. While the suggestion is specific in terms of what is missing (failure cases and discussion), the lack of grounding in the paper's structure makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including some failure cases and related discussion would be beneficial. However, it does not provide any specific examples or reasoning to support why this inclusion would be valuable or how it would enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including some failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which failure cases to include or how to effectively discuss them. The feedback is somewhat helpful as it points out a potential enhancement, but it does not offer actionable steps or examples, leaving the authors with limited direction on how to address this suggestion. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the use of the variable \\\\epsilon in equations (10) and (11) in Section 4.1. It suggests that introducing \\\\epsilon when discussing equation (11) might improve clarity. While the comment implies that the authors should clarify the use of \\\\epsilon, it does not explicitly instruct them to make this change. However, the action is concrete, as it specifies the section and equation where the clarification should be made. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10) and (11),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the inconsistency in the use of \\\\epsilon and suggests introducing it when discussing equation (11) to improve clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the use of the variable \\\\epsilon in equations (10) and (11) in Section 4.1. It suggests that introducing \\\\epsilon when discussing equation (11) might improve clarity. This claim is somewhat verifiable as it highlights a potential inconsistency in the paper, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would need to make a significant effort to understand and address the issue without additional context or explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the variable \\\\epsilon in equations (10) and (11) in Section 4.1. It suggests that introducing \\\\epsilon when discussing equation (11) might improve clarity. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity of the manuscript. By addressing this point, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why this change is important or how it might impact the overall presentation of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the limitations of the claim about evolutional dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some low-variance units. The reviewer also mentions that Batch Normalization standardizes the variance and centers the activation, and suggests that these limitations should be discussed explicitly. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address these limitations or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it can only increase the variance of some low-variance units. It also mentions Batch Normalization as a comparison, highlighting its role in standardizing variance and centering activations. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggests discussing these limitations explicitly. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer suggests that Batch Normalization is more effective in standardizing variance and centering activations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the limitations of evolutional dropout. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim about evolutional dropout addressing internal covariate shift, noting that it can only increase the variance of some low-variance units. It suggests that Batch Normalization is more effective in standardizing variance and centering activations, and recommends that these limitations be discussed explicitly. This feedback is clear and actionable, as it directs the authors to provide a more thorough discussion of the limitations of their claim. However, the comment could be more helpful if it offered specific suggestions on how to address these limitations or provided examples of how to discuss them. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should discuss the limitations of the claim about evolutional dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some low-variance units. It also mentions Batch Normalization as a comparison, highlighting its role in standardizing variance and centering activations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address these limitations or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it can only increase the variance of some low-variance units. It also mentions Batch Normalization as a comparison, highlighting its role in standardizing variance and centering activations. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggests discussing these limitations explicitly. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer suggests that Batch Normalization is more effective in standardizing variance and centering activations, and recommends discussing these limitations explicitly. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the limitations of evolutional dropout. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim about evolutional dropout addressing internal covariate shift, noting that it can only increase the variance of some low-variance units. It also contrasts this with Batch"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add more description about the contribution of the paper. This is a clear and direct action, providing the authors with a specific task to improve their draft. However, it does not specify what aspects of the contribution should be described or how to enhance the description, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper currently lacks this description or what specific aspects of the contribution should be elaborated upon. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what additional information is needed or how it should be presented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would benefit the paper. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should provide more description about the contribution of their paper. While it identifies a potential area for improvement, it lacks specificity and does not offer detailed guidance on what aspects of the contribution should be elaborated upon or how to enhance the description. Without actionable advice or examples, the authors may struggle to determine how to address this feedback effectively. Therefore, the comment is barely helpful, as it points out a general area for improvement but does not provide sufficient detail to be fully actionable.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that in section 4, the term \"X\" should be a multiset instead of a set, and that the notation should include the multiplicities of labels in the graph. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and why. The comment is highly actionable as it gives the authors precise guidance on how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the use of \"X\" as a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be revised in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in section 4, the term \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The reviewer provides a logical reasoning for this claim, explaining that including the multiplicities of labels is necessary for an honest histogram representation. This reasoning is clear and supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to further substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation used in section 4. It suggests that the term \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and precise, offering a concrete way for the authors to improve the clarity and accuracy of their draft. By addressing this point, the authors can enhance the precision of their mathematical notation, which is crucial for the understanding and reproducibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' derivation is based on classical learning theory-based bounds, which, according to the reviewer, do not yield realistic bounds unless Bayesian considerations are taken into account. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to incorporate Bayesian considerations. The feedback lacks actionable details, such as recommending specific methods or approaches to improve the bounds. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the derivation of the authors, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this derivation is located in, making it weakly grounded. The comment is specific in its critique, as it identifies the issue with the derivation and suggests a potential solution by mentioning Bayesian-PAC based bounds. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation is based on classical learning theory-based bounds, which, according to the reviewer, do not yield realistic bounds unless Bayesian considerations are taken into account. The comment provides a logical reasoning by suggesting that Bayesian considerations could improve the bounds. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, noting that it relies on classical learning theory-based bounds, which may not yield realistic bounds unless Bayesian considerations are taken into account. This feedback highlights a specific area for improvement, suggesting that the authors should consider incorporating Bayesian considerations to enhance the realism of their bounds. However, the comment does not provide detailed guidance or specific suggestions on how to implement Bayesian considerations, which limits its helpfulness. While it points out a critical area for improvement, the lack of actionable advice makes it somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the authors\\' derivation is based on classical learning theory-based bounds, which may not yield realistic bounds unless Bayesian considerations are taken into account. However, it does not provide specific guidance or suggestions on how the authors should incorporate Bayesian considerations or improve their derivation. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the derivation of the authors, suggesting that it relies on classical learning theory-based bounds, which may not yield realistic bounds unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this derivation is located in, making it weakly grounded. The comment is specific in its critique, as it identifies the issue with the derivation and suggests a potential solution by mentioning Bayesian-PAC based bounds. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation is based on classical learning theory-based bounds, which, according to the reviewer, do not yield realistic bounds unless Bayesian considerations are taken into account. The comment provides a logical reasoning by suggesting that Bayesian considerations could improve the bounds. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, noting that it relies on classical learning theory-based bounds, which may not yield realistic bounds unless Bayesian considerations are taken into account. This feedback highlights a critical area for improvement, suggesting that the authors should consider incorporating Bayesian considerations to enhance the realism of their bounds. However, the comment lacks specific guidance or suggestions on how to implement Bayesian considerations or improve the derivation. While it points out a significant area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the authors\\' derivation is based on classical learning theory-based bounds, which may not"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the authors discuss significant differences between methods but fail to provide significance testing to support these claims. It provides a specific example from line 486, where the authors mention the conversational ability of ChatGPT and GPT-4 boosting translation quality and discourse awareness. The reviewer highlights the need for significance testing to determine whether the observed differences are statistically significant. This feedback is explicit in its request for significance testing and provides a concrete example, making it clear what the authors need to do to improve their draft. The comment is highly actionable as it gives the authors a direct action to take and provides a specific example to guide them in implementing it.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not conducting significance testing to support claims about the differences between methods. The comment provides a detailed example and highlights the need for significance testing, including checking the distribution and accounting for multiple comparisons. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the lack of significance testing to support claims about method differences. It provides a specific example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT-4 boosting translation quality and discourse awareness. The reviewer points out that the differences between these methods and others are minimal, making it difficult to determine significance without proper testing. This comment is mostly verifiable as it logically highlights the need for significance testing and provides a specific example to illustrate the issue. However, it could be strengthened by offering more detailed guidance on how to conduct the significance testing or referencing specific statistical methods. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper's methodology, specifically the lack of significance testing to support claims about method differences. It provides a specific example from the paper, highlighting the need for proper testing to determine whether the observed differences are statistically significant. This feedback is clear and actionable, as it guides the authors to conduct significance testing and provides a concrete example to illustrate the issue. By addressing this point, the authors can strengthen their claims and improve the rigor of their analysis. However, the comment could be more helpful if it offered suggestions on how to conduct the significance testing or provided references to relevant statistical methods. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to a critical area needing improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a concern about the potential regularization effects rather than distillation, given the fine-tuning setup without early-stopping. It suggests that proper ablation studies are needed to verify the claims made in the paper. While the comment identifies a specific issue and implies that the authors should conduct additional studies, it does not provide detailed guidance on how to perform these ablation studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the concern but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it addresses a specific aspect of the paper's methodology, namely the fine-tuning of the teacher model without early-stopping. This allows the authors to identify the part of the paper being discussed. The comment is also specific because it highlights a potential issue with the claim that the improvements are due to distillation rather than regularization effects. It suggests that proper ablation studies are needed to verify the claims made in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the potential regularization effects rather than distillation, given the fine-tuning setup without early-stopping. The reviewer provides a logical reasoning by pointing out that fine-tuning without early-stopping can lead to high variances, suggesting that proper ablation studies are needed to verify the claims. However, the comment lacks specific examples or references to support the claim about regularization effects, making it somewhat verifiable. The authors would need to further explore and substantiate the reasoning themselves, thus justifying a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the interpretation of the results, specifically questioning whether the improvements in the teacher's performance are due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that the fine-tuning without early-stopping could lead to high variances, suggesting that proper ablation studies are needed to verify the claims. This feedback is clear and actionable, as it guides the authors to conduct additional studies to clarify the nature of the improvements. However, the comment could be more helpful if it offered specific suggestions on how to design these ablation studies or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a critical area for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment raises a concern about the potential regularization effects rather than distillation, given the fine-tuning setup without early-stopping. It suggests that proper ablation studies are needed to verify the claims made in the paper. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how to conduct these ablation studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the concern but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it addresses a specific aspect of the paper's methodology, namely the fine-tuning of the teacher model without early-stopping. This allows the authors to accurately identify the part of the paper being discussed. The comment is also specific because it highlights a potential issue with the interpretation of the results, suggesting that proper ablation studies are needed to verify the claims made in the paper. By providing a clear rationale and a specific suggestion for further analysis, the comment offers actionable feedback. Therefore, this comment is fully grounded and specific, aligning with a score of 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the potential regularization effects rather than distillation, given the fine-tuning setup without early-stopping. The reviewer provides a logical reasoning by pointing out that fine-tuning without early-stopping can lead to high variances, suggesting that proper ablation studies are needed to verify the claims made in the paper. However, the comment lacks specific examples or references to support the claim about regularization effects, making it somewhat verifiable. The authors would need to further explore and substantiate the reasoning themselves, thus justifying a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the interpretation of the results, specifically questioning whether the improvements in the teacher's performance are due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that the fine-tuning without early-st"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the paper. The comment lacks actionable details, such as recommending ways to enhance the contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution and approach of the paper, suggesting that it appears limited and incremental. However, it does not specify which parts of the paper are being evaluated or which aspects of the contribution or approach are considered limited or incremental. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper appears limited and that the proposed model is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s opinion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific feedback or suggestions on how the authors might address these concerns or improve the paper. Without actionable advice or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific guidance or suggestions on how the authors might address these concerns or improve the paper. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution and approach of the paper, suggesting that it appears limited and incremental. However, it does not specify which parts of the paper are being evaluated or which aspects of the contribution or approach are considered limited or incremental. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, it aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper appears limited and that the proposed model is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s opinion and address it effectively. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific feedback, suggestions, or examples to help the authors understand the basis of this opinion or how they might address it. Without actionable guidance or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific guidance or suggestions on how the authors might address these concerns or improve the paper. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution and approach of the paper, suggesting that it appears limited and incremental. However, it lacks specificity and does not provide any details or examples to support this opinion. Without clear references or guidance on what aspects of the contribution or approach are considered limited or incremental, the authors cannot effectively address the feedback. As a result, the comment"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It suggests that this approach may contradict the claim of the paper that it is a \"general-purpose neural network model.\" However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The feedback lacks actionable details, such as recommending alternative approaches or providing specific steps to test or mitigate the potential negative transfer. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining based on the prediction of homo-lumo gap, which may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks other than homo, lumo, and gap, suggesting a contradiction with the paper\\'s claim of being a \"general-purpose neural network model.\" However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to sections discussing the model\\'s performance or the claim of being a general-purpose model, but this inference is not direct. The comment is specific in detailing the potential contradiction and the example provided, making it specific. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It provides an example of Transformer-M performing poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper being a \"general-purpose neural network model.\" The comment is mostly verifiable as it logically explains the potential issue and provides a specific example to support the claim. However, it could be strengthened by referencing additional studies or providing more detailed evidence of negative transfer in similar contexts. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It points out that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which may contradict the paper\\'s claim of being a \"general-purpose neural network model.\" This feedback is somewhat helpful as it identifies a specific issue that could affect the paper\\'s claims and suggests that the authors consider this potential negative transfer. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or provide evidence to support their claims. To be more helpful, the comment could include specific recommendations or examples of how to mitigate the negative transfer or clarify the model\\'s capabilities. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It suggests that this approach may contradict the claim of the paper being a \"general-purpose neural network model.\" However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. It lacks actionable details, such as recommending alternative approaches or providing specific steps to test or mitigate the potential negative transfer. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It suggests that this approach may contradict the paper\\'s claim of being a \"general-purpose neural network model.\" However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. While it provides a specific example of Transformer-M performing poorly on most tasks other than homo, lumo, and gap, it lacks detailed guidance or suggestions for improvement. This makes it challenging for the authors to identify and address the specific concerns raised. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on"}
{"generated_text": "{'actionability_rationale': \"The review point identifies several issues with the experimental evaluation, specifically mentioning the lack of ablation for the 'picking' step and the unconvincing comparison on CIFAR. It highlights that the continual learning literature has extensive experiments on CIFAR and suggests that the paper should compare to more approaches and use the same setup as in the DEN paper to ensure fairness. The comment provides explicit actions for the authors to take, such as conducting ablations and comparing to multiple approaches, and it offers concrete guidance on how to improve the experimental setup. This level of detail and clarity makes the comment highly actionable, as it gives the authors clear steps to follow to enhance their draft.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Experimental Evaluation 2.1,\" \"Ablations 2.1.1,\" \"Experiments on CIFAR,\" and \"2.2.1\" and \"2.2.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the experimental evaluation, including the lack of ablation for the \"picking\" step, the unconvincing comparison on CIFAR, and the need for a more extensive comparison to multiple approaches in the continual learning literature. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the experimental evaluation, specifically regarding the lack of ablation for the 'picking' step and the unconvincing comparison on CIFAR. The reviewer highlights that the continual learning literature has extensive experiments on CIFAR and suggests that the paper should compare to multiple approaches and use the same setup as in the DEN paper to ensure fairness. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that the comparison is unconvincing or that the approach is not ablated. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several specific issues with the experimental evaluation, particularly in the ablation of the 'picking' step and the comparison on CIFAR. It points out that the paper claims a distinction in the 'picking' step but does not provide an ablation study to support this claim. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and suggests that the comparison is not convincing. The reviewer provides actionable feedback by recommending that the authors conduct ablation studies and compare to multiple approaches, including using the same setup as in the DEN paper to ensure fairness. This detailed and constructive feedback is highly helpful as it guides the authors on how to strengthen their experimental evaluation and improve the robustness of their claims.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a trade-off between computation time and the richness of the search space, specifically comparing the proposed method to another work ([10]). It questions the extent to which information about DAGs is encoded in ancestral graphs, implying that this is the price paid for better performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their method. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to this observation. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s trade-off between computation time and the richness of the search space, comparing it to another work ([10]). It questions the extent to which information about DAGs is encoded in ancestral graphs, implying that this is the price paid for better performance. However, the comment does not specify which part of the paper discusses the proposed method or the comparison to [10], making it weakly grounded. The comment is specific in detailing the trade-off and the question about information encoding, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method reduces computation time by narrowing the search space to ancestral graphs, which results in a less informative output compared to methods that consider DAGs. The reviewer supports this claim by referencing another work ([10]) and questioning the extent of information lost in the process. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim. While the reasoning is logical, the absence of explicit evidence or references makes the claim somewhat verifiable. The authors would need to further explore the comparison to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a critical analysis of the proposed method's trade-off between computation time and the richness of the search space. It highlights that the method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to methods that consider DAGs. The comment raises an important question about the information encoded in ancestral graphs, which is relevant to understanding the method's limitations. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their method. While it identifies a significant concern, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a trade-off between computation time and the richness of the search space, comparing the proposed method to another work ([10]). It questions the extent to which information about DAGs is encoded in ancestral graphs, implying that this is the price paid for better performance. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. Without actionable steps or concrete advice, the authors are left without a clear path forward. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the trade-off between computation time and the richness of the search space, comparing the proposed method to another work ([10]). It questions the extent to which information about DAGs is encoded in ancestral graphs, implying that this is the price paid for better performance. However, the comment does not specify which part of the paper discusses these comparisons or the trade-off, making it weakly grounded. The authors might infer that it relates to sections discussing the proposed method or comparisons to [10], but this is not explicitly stated. The comment is specific in detailing the trade-off and the question about information encoding, but without clear grounding, it aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to methods that consider DAGs. The reviewer supports this claim by referencing another work ([10]) and questioning the extent of information lost in the process. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim. While the reasoning is logical, the absence of explicit evidence or references makes the claim somewhat verifiable. The authors would need to further explore the comparison to fully understand and address the critique, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a trade-off between computation time and the richness of the search space, comparing the proposed method to another work ([10]). It questions the"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet, and questions the motivations behind the use of RepPoints. The reviewer suggests that the authors clarify this issue, indicating that the motivations are not solid enough if they cannot address it. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so or offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 1' and discusses the definitions of anchor-based regression and RepPoints in RetinaNet and ATSS. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the confusion about the differences between the two methods and questions the motivations behind using RepPoints. It provides a clear rationale for why the authors should clarify this issue, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet and ATSS. The reviewer questions the motivations behind using RepPoints, suggesting that the regression methods are similar and that the direct regression of [w, h] to the center point is sufficient. The comment provides some logical reasoning by referencing the literature on ATSS, which suggests that regression methods do not significantly influence performance. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore and clarify the differences themselves to address the reviewer's concerns effectively.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific concern about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet and ATSS. It questions the motivations behind using RepPoints and suggests that the regression methods may not significantly influence performance. The reviewer provides a logical reasoning by referencing the literature on ATSS, which supports the claim that regression methods do not significantly impact performance. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and motivations in their paper. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional context. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area needing clarification, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors clarify whether the Fourier modes being discussed are real or complex numbers. This is a direct and concrete action that the authors can take to improve their draft. By providing this specific guidance, the comment offers clear direction on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion about Fourier modes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: whether the Fourier modes are real or complex numbers. This provides clear guidance on what aspect of the discussion requires clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the nature of Fourier modes (real or complex). It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By asking the authors to clarify whether the Fourier modes are real or complex numbers, the reviewer is guiding the authors to address a potential source of confusion in their work. This feedback is clear and directly impacts the readability and understanding of the paper, making it mostly helpful. However, it could be further improved by explaining why this clarification is important or how it might affect the reader\\'s comprehension. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific error in the manuscript, pointing out that \"on line 205, it should be Fig. 1 instead of Fig. 5.1.\" It also provides a concrete suggestion for how to resolve the issue by recommending the use of the LaTeX command \"\\label\" after \"\\caption.\" This guidance is clear and actionable, as it directly instructs the authors on what needs to be corrected and how to do so. The authors know exactly what changes to make to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205\" and \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure reference and provides a concrete suggestion for resolving it by using the LaTeX command \"\\label\" after \"\\caption.\" This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the manuscript, specifically identifying that \"Fig. 1\" should be used instead of \"Fig. 5.1.\" The comment provides a clear and specific suggestion for correcting the error, which is straightforward and does not require any additional justification or evidence. Therefore, the claim is fully verifiable, as it is based on a direct observation and correction of a typographical error. This aligns with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable correction to a typographical error in the manuscript. By identifying the incorrect reference to Fig. 5.1 as Fig. 1, the reviewer helps the authors ensure the accuracy and clarity of their figures. Additionally, the comment offers a concrete suggestion for resolving the issue by recommending the use of the LaTeX command \"\\label\" after \"\\caption.\" This guidance is clear and straightforward, allowing the authors to easily implement the correction and improve the overall quality of their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}\""}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include case studies and error studies to better demonstrate the effectiveness of each proposed component. It provides an example of a case study related to graph pre-training for AMR parsing and generation. While the comment implies that the authors should include such studies, it does not explicitly instruct them to do so or provide detailed guidance on how to conduct these studies. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Element-level Graph Pre-training. It provides an example of a case study related to graph pre-training for AMR parsing and generation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results sections where the proposed components are introduced. The comment is specific in suggesting a method to improve the paper by including case studies and error studies. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness in demonstrating the proposed components\\' benefits. It provides an example of a case study related to graph pre-training for AMR parsing and generation, which supports the claim. However, the comment lacks detailed reasoning or evidence on how these studies would improve the paper, making it somewhat verifiable. The authors would need to further develop the suggestion themselves to fully understand and implement it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include case studies and error studies to better demonstrate the effectiveness of each proposed component. It provides a specific example of a case study related to graph pre-training for AMR parsing and generation, which could serve as a reference for the authors. This feedback is actionable and offers a clear direction for enhancing the paper by illustrating the practical implications of the proposed components. However, the comment could be more helpful if it provided additional guidance on how to conduct these studies or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies a valuable area for improvement and provides some direction, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should include case studies and error studies to better demonstrate the effectiveness of each proposed component. It provides an example of a case study related to graph pre-training for AMR parsing and generation. While the comment implies that the authors should include such studies, it does not explicitly instruct them to do so or provide detailed guidance on how to conduct these studies. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Element-level Graph Pre-training. It provides an example of a case study related to graph pre-training for AMR parsing and generation. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. The suggestion is specific in terms of what could be included to improve the paper, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness in demonstrating the effectiveness of each proposed component. It provides an example of a case study related to graph pre-training for AMR parsing and generation, which supports the claim. However, the comment lacks detailed reasoning or evidence on how these studies would improve the paper, making it somewhat verifiable. The authors would need to further develop the suggestion themselves to fully understand and implement it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include case studies and error studies to better demonstrate the effectiveness of each proposed component. It provides a specific example of a case study related to graph pre-training for AMR parsing and generation, which could serve as a reference for the authors. This feedback is actionable and offers a clear direction for enhancing the paper by illustrating the practical implications of the proposed components. However, the comment could be more helpful if it provided additional guidance on how to conduct these studies or what specific aspects to focus on. Overall, the comment is mostly"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used several times without being defined in the same section. This is a clear and explicit action for the authors to take, as they need to define the notation where it is used. The comment provides specific guidance on what needs to be addressed, making it highly actionable. The authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to define the notation where it is used. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used several times without being defined. This is a factual observation about the paper\\'s notation, which does not require verification or evidence. It is a statement of fact rather than an opinion or suggestion, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the notation \\\\( \\\\mathcal{P} \\\\) with a subscript is used several times without being defined in the same section. This is a clear and actionable point that the authors can address to improve the clarity and readability of their work. By pointing out this omission, the reviewer provides the authors with a concrete step to enhance the quality of their draft. However, the comment could be more helpful if it suggested how the authors might define the notation or provided examples of how to do so. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It corrects a spelling error in the text (\"known\" instead of \"know\") and requests a definition for a specific term (\\u03b3_0^{***}). Additionally, it explicitly instructs the authors to specify the meaning of the colors in Figure 1 both in the caption and the text. These actions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (l148 and l156) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as correcting a spelling error, defining a term, and specifying the meaning of colors in Figure 1. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of corrections for spelling and punctuation errors, as well as a request for clarification regarding a specific term and the meaning of colors in a figure. These are factual observations and requests for clarification, which do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying and correcting a spelling error (\"known\" instead of \"know\") and requesting a definition for a specific term (\\u03b3_0^{***}). Additionally, it suggests specifying the meaning of the colors in Figure 1 both in the caption and the text. This level of detail helps the authors make precise improvements to their draft, ensuring clarity and accuracy. The feedback is clear and directly addresses the issues, making it highly helpful for the authors to enhance their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses questions about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. While the questions imply that the authors should provide explanations for these choices, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the rationale behind having a separate timbre encoder module and why SADTW takes outputs of the content encoder instead of the timbre encoder. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind certain design choices in Figure 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. This feedback is somewhat helpful as it prompts the authors to clarify and justify their design choices, which could improve the comprehensibility and transparency of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address these questions, limiting its helpfulness. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not provide specific guidance on how to improve it. The authors are left without clear instructions on what aspects of the writing or presentation are problematic or how to address them. Without explicit or implicit suggestions for improvement, the authors are unable to determine what changes to make to enhance the clarity and coherence of their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not specify which parts of the paper are problematic or provide any details on what aspects of the writing or presentation are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"a bit jumbled,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand which parts of the writing or presentation are problematic. As a result, the claim is unverifiable, as it lacks the necessary support to guide the authors in addressing the issue.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular sections or issues that need clarification or reorganization, the authors are left without a clear path to address the concern. This lack of detail makes the comment unhelpful, as it does not assist the authors in enhancing the clarity and coherence of their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not provide specific guidance or suggestions on how to improve the clarity or organization of the content. Without explicit instructions or examples, the authors are left without a clear understanding of what needs to be addressed or how to make improvements. This lack of actionable feedback makes the comment unhelpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not specify which parts of the paper are problematic or provide any details on what aspects of the writing or presentation are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, it aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"a bit jumbled,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, it is difficult for the authors to understand which parts of the writing or presentation are problematic or how to address them. As a result, the claim is unverifiable, as it lacks the necessary support to guide the authors in improving their draft.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular sections or issues that need clarification or reorganization, the authors are left without a clear understanding of what needs to be addressed. This lack of detail makes the comment unhelpful, as it does not assist the authors in enhancing the clarity and coherence of their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not provide specific guidance or suggestions on how to improve the clarity or organization of the content. Without explicit instructions or examples, the authors are left without a clear understanding of what needs to be addressed or how to make improvements. This lack of actionable feedback makes the comment unhelpful for the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is somewhat jumbled, but it does not specify which parts of the paper are"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment highlights an area of interest, it does not provide explicit guidance or suggestions for the authors to address this concern. The authors can infer that they might need to analyze and compare computational complexity, but the comment lacks concrete instructions on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were used on a mobile device. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its inquiry about computational complexity and power demand, providing clear guidance on what aspect to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and a speculative statement about the potential power demand if the Woodbury flow were used on a mobile device. It does not present an opinion, judgment, or suggestion that requires verification. The question is factual and seeks clarification, while the speculative statement is based on a hypothetical scenario. Therefore, the review point is factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were used on a mobile device, which is a relevant consideration for practical applications. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or provide a comparison. The feedback is somewhat helpful as it prompts the authors to consider the computational efficiency of their method, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were used on a mobile device. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors might infer that they need to analyze and compare computational complexity, but the comment lacks concrete instructions on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it points out an area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were used on a mobile device. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its inquiry about computational complexity and power demand, providing clear guidance on what aspect to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and a speculative statement about the potential power demand if the Woodbury flow were used on a mobile device. It does not present an opinion, judgment, or suggestion that requires verification. The comment is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were used on a mobile device, which is a relevant consideration for practical applications. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or provide a comparison. The feedback prompts the authors to consider computational efficiency, but it could be more helpful with additional details or actionable advice. Therefore,"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific error in the authors\\' description of the base IOI circuit, stating that the Induction, Duplicate Token, and Previous Token heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear correction, allowing the authors to accurately revise their description. The comment is concrete, as it directly identifies the incorrect statement and provides a specific reference to correct it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the sentence \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token.\" This allows the authors to accurately identify the part of the paper being critiqued. The comment is also specific because it clearly specifies what is incorrect in the statement, namely that the heads are active at the S2 token but do not primarily attend to it. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' statement about the Induction, Duplicate Token, and Previous Token heads attending to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to an external source, which provides a clear basis for the critique. The mention of Section 3 of Wang et al., 2023, offers a precise reference that the authors can consult to verify the accuracy of their statement. This level of detail and external reference makes the claim fully verifiable, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable correction regarding the authors\\' description of the base IOI circuit. It points out a factual error in the paper, stating that the Induction, Duplicate Token, and Previous Token heads are active at the S2 token but do not primarily attend to it. By referencing a specific section of Wang et al., 2023, the reviewer offers a clear and precise correction that the authors can implement to improve the accuracy of their work. This feedback is highly helpful as it directs the authors to a specific area of their paper that requires revision, ensuring they can make a meaningful improvement to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the comment on line 15 is vague and references specific literature and a leaderboard to provide clarity. Additionally, it critiques the reinforcement learning/agent analogy as being out-of-place and suggests that the authors should focus on generalization capabilities, which are better illustrated by examples later in the paper. The feedback is clear and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on what needs to be improved. The comment critiques the vagueness of the RNNs' performance claim and references specific literature and a leaderboard to provide clarity. Additionally, it critiques the reinforcement learning/agent analogy and suggests that the authors focus on generalization capabilities, which are better illustrated by examples later in the paper. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and references to specific literature and a leaderboard. It does not contain subjective opinions, judgments, or suggestions that require verification. The references to the literature and the leaderboard provide a basis for the claims, making the comment factual and verifiable. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by addressing two distinct issues. First, it points out that the comment on line 15 is vague and suggests referencing specific literature and a leaderboard to provide clarity. This guidance is clear and actionable, helping the authors improve the precision of their claims. Second, it critiques the reinforcement learning/agent analogy as being out-of-place and suggests that the authors focus on generalization capabilities, which are better illustrated by examples later in the paper. This feedback is constructive and offers a clear direction for refining the paper. Overall, the comment is mostly helpful as it provides detailed and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the statement in the paper that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example of a limitation, namely that RBF kernels cannot be represented by neural networks due to their infinite-dimensional RKHS. The reviewer suggests that this limitation should be made more clear in the paper. While the comment does not explicitly instruct the authors to make this clarification, the action is implicit and concrete, as it specifies the issue and provides a clear example. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement that every kernel can be described by a feature space parameterized by a neural network, providing a specific example of the limitation with RBF kernels. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, specifically that every kernel can be described by a feature space parameterized by a neural network. The reviewer provides a counterexample by discussing the limitations of neural networks in representing infinite-dimensional RKHSs, such as those associated with RBF kernels. This reasoning is clear and supported by a specific example, making the claim mostly verifiable. However, the comment could be strengthened by providing additional references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example of the limitation by discussing the infinite-dimensional RKHS of RBF kernels, which cannot be represented by a neural network with finite width. The comment suggests that this limitation should be made more clear in the paper. This feedback is clear and actionable, as it directs the authors to clarify a potentially misleading statement in their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and accuracy of their paper.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example of the limitation, specifically mentioning RBF kernels and their infinite-dimensional RKHSs. The comment suggests that this limitation should be made more clear in the paper. While the action is implicit, it is concrete as it specifies the issue and provides a clear example. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement that every kernel can be described by a feature space parameterized by a neural network, providing a specific example of the limitation with RBF kernels. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, specifically that every kernel can be described by a feature space parameterized by a neural network. The reviewer provides a counterexample by discussing the limitations of neural networks in representing infinite-dimensional RKHSs, such as those associated with RBF kernels. This reasoning is clear and supported by a specific example, making the claim mostly verifiable. However, the comment could be strengthened by providing additional references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example of the limitation by discussing the infinite-dimensional RKHS of RBF kernels, which cannot be represented by a neural network with finite width. The comment suggests that this limitation should be made more clear in the paper, offering a clear direction for improvement. This feedback is actionable and helps the authors clarify a potentially misleading statement in their work, making it mostly helpful. However,"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the proposed method is not well-positioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides specific examples of previous works, such as the original denoising score matching objective and score-interpolation, which use this property. The reviewer suggests that the authors conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not explicitly instruct them to do so or provide specific guidance on how to conduct it. The action is implicit but concrete, as the authors can infer that they need to review the literature to address the issue. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment critiques the proposed method's positioning in the literature, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides specific examples, such as the original denoising score matching objective and score-interpolation, to support this claim. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as the literature review section or the methodology section. The authors can infer that it relates to the literature review or methodology, but this inference is not direct. The comment is specific in identifying the key idea and providing examples, but it lacks full grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method is not well-positioned in the literature, specifically noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. The reviewer supports this claim by referencing the original denoising score matching objective and score-interpolation, which are examples of works that use this property. This provides a clear and specific reference to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to additional works that utilize this property. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides valuable feedback by pointing out that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It references specific examples, such as the original denoising score matching objective and score-interpolation, to support this claim. The comment suggests that the authors conduct a thorough literature review to identify additional works that utilize this property, which is a clear and actionable recommendation. This feedback is mostly helpful as it guides the authors to enhance the novelty and context of their work by situating it within the existing literature. However, it could be more helpful if it provided specific guidance on how to integrate this literature review into the paper. Overall, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment points out that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides specific examples, such as the original denoising score matching objective and score-interpolation, to support this claim. The reviewer suggests that the authors conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not explicitly instruct them to do so or provide specific guidance on how to conduct it. The action is implicit but concrete, as the authors can infer that they need to review the literature to address the issue. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment critiques the proposed method's positioning in the literature, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides specific examples, such as the original denoising score matching objective and score-interpolation, to support this claim. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as the literature review or methodology sections. While the authors can infer that it relates to these sections, the lack of explicit grounding makes it challenging to pinpoint the exact area needing attention. The comment is specific in identifying the key idea and providing examples, but it lacks full grounding. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their technical contribution. The comment lacks actionable guidance, leaving the authors without direction on how to enhance their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it lacks significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment criticizes the technical contribution of the paper, stating that it lacks significant innovation or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide specific examples or suggestions on how the authors might enhance their technical contribution or address the perceived limitations. Without actionable feedback or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the components of the approach are not novel, specifically mentioning that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before, and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. It also notes that the results of WeakNAS are similar to BRP-NAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their approach. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to enhance the novelty or effectiveness of the approach. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 in Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the components of the approach are not novel, mentioning the weak predictors used (MLP, Regression Tree, and Random Forest) and the sampling strategy, which is similar to epsilon-greedy and BRP-NAS. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the components of the approach are not novel, specifically mentioning that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. The comment provides references to previous works ([2,3,7] and BRP-NAS) to support the claim, which makes the comment mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the components of the approach, specifically pointing out that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before, and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. It also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS. This feedback is somewhat helpful as it highlights areas where the paper may lack originality and provides a basis for potential improvements. However, the comment could be more helpful if it offered suggestions on how to differentiate the approach or enhance its novelty. Without specific guidance or actionable advice, the authors are left with a general understanding of the issue but no clear path to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the components of the approach are not novel, specifically mentioning that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before, and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. It also notes that the results of the proposed WeakNAS are almost the same as BRP-NAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their approach. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to enhance the novelty or effectiveness of the approach. As a result, the comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 in Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the components of the approach are not novel, mentioning the weak predictors used (MLP, Regression Tree, and Random Forest) and the sampling strategy, which is similar to epsilon-greedy and BRP-NAS. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the components of the approach are not novel, specifically mentioning that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. The comment supports this claim by referencing previous works ([2,3,7"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two specific questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection. The comment implies that the authors should provide AUC results for comparisons, which is a concrete suggestion. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to include AUC results, but the comment could be more explicit in stating this requirement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper related to the calculation of precision, recall, and F1-score for a 4-class classification of breast density and the reporting of AUC with sensitivity and specificity for breast cancer detection. It provides clear guidance on what needs to be addressed, specifically the calculation and reporting of precision, recall, and F1-score for the 4-class classification and the inclusion of AUC results for comparison. However, the comment does not explicitly mention which sections of the paper these aspects are discussed in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests that researchers typically report AUC with sensitivity and specificity for breast cancer detection. The comment provides a logical basis for its claims by referencing common practices in the field, which supports the suggestion to include AUC results for comparison. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the literature to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two specific questions about the methodology used in the paper. It asks how the precision, recall, and F1-score were calculated for a 4-class classification of breast density and suggests that researchers typically report AUC with sensitivity and specificity for breast cancer detection. The comment also recommends providing AUC results for comparisons. This feedback is clear and actionable, as it guides the authors to clarify their methodology and potentially enhance the comprehensiveness of their results by including additional performance metrics. However, the comment could be more helpful if it provided specific guidance on how to calculate the AUC or suggested ways to present the results. Overall, the comment is mostly helpful as it directs the authors to improve their draft by addressing specific methodological aspects.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the creation of the dataset is optional and suggests using the Kialo dataset, which is well-studied and cleaner than the dataset created in the paper. However, it does not explicitly instruct the authors to use the Kialo dataset or provide guidance on how to incorporate it into their work. The suggestion is implicit and lacks concrete details on how to apply it, leaving the authors to infer the action. Since the comment is vague and does not offer specific steps for implementation, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset and suggests using the Kialo dataset instead, which is well-studied and cleaner. However, it does not specify which part of the paper discusses the creation of the dataset, making it weakly grounded. The comment is specific in suggesting an alternative dataset but lacks detailed guidance on how to incorporate this suggestion into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and proposes using the Kialo dataset instead, which is cleaner and more studied. The comment provides a logical reasoning by comparing the Kialo dataset to the one created in the paper, suggesting that the latter is less optimal. However, the comment lacks specific examples or references to support the claim about the cleanliness or superiority of the Kialo dataset. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the creation of the dataset, suggesting that the authors could use the well-established Kialo dataset instead. This feedback is somewhat helpful as it points out an alternative that could simplify the dataset creation process and potentially improve the quality of the dataset. However, the comment lacks specific guidance on how to integrate the Kialo dataset into the paper or what benefits it might offer beyond being \"cleaner.\" Additionally, it does not provide detailed suggestions on how to address the issue of dataset creation or what specific improvements could be made to the dataset created in the paper. Therefore, while it offers some insight, the feedback could be more actionable and comprehensive to be fully helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests using the Kialo dataset instead of the dataset created in the paper, as the Kialo dataset is cleaner and more studied. However, it does not explicitly instruct the authors to use the Kialo dataset or provide guidance on how to incorporate it into their work. The suggestion is implicit and lacks concrete details, making it barely actionable. The authors can infer that they might consider using the Kialo dataset, but the comment does not offer specific steps or rationale for doing so.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset and suggests using the Kialo dataset instead, which is well-studied and cleaner. However, it does not specify which part of the paper discusses the creation of the dataset, making it weakly grounded. The comment is specific in suggesting an alternative dataset but lacks detailed guidance on how to incorporate this suggestion into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and proposes using the Kialo dataset instead, which is cleaner and more studied. The comment provides a logical reasoning by comparing the Kialo dataset to the one created in the paper, suggesting that the latter is less optimal. However, the comment lacks specific examples or references to support the claim about the cleanliness or superiority of the Kialo dataset. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the creation of the dataset, suggesting that the authors could use the well-established Kialo dataset instead. This feedback is somewhat helpful as it points out an alternative that could simplify the dataset creation process and potentially improve the quality of the dataset. However, the comment lacks specific guidance on how to incorporate the Kialo dataset into the paper or what benefits it might offer beyond being \"cleaner.\" Additionally, it does not provide detailed suggestions on how to address the issue of dataset creation or what specific improvements could be made to the dataset created in the paper. Therefore, while it offers some insight, the feedback could be more actionable and comprehensive to be fully helpful.', 'helpfulness_label': '"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the novelty of using a transformer in the field of NLP and vision tasks, noting that the cross-layer modification does not bring significant insight in machine learning. It also questions the significance of the improvements in the ablation study, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how the authors might enhance the novelty or significance of their work or suggest alternative approaches. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of using a transformer in NLP and vision tasks, noting that the cross-layer modification does not bring significant insight in machine learning. It also critiques the ablation study, specifically mentioning table 4 and 5, where the self-cross attention brings limited improvement. The comment is specific in pointing out the lack of significant improvement and questioning the significance of the proposed modification. However, it does not explicitly mention which part of the paper these specific tables are located in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point critiques the novelty of using a transformer in NLP and vision tasks, noting that the cross-layer modification does not bring significant insight in machine learning. It also questions the significance of the improvements in the ablation study, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. The comment provides some logical reasoning by comparing the transformer's novelty and the limited improvement in the ablation study. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of using a transformer in NLP and vision tasks, noting that the cross-layer modification does not bring significant insight in machine learning. It also questions the significance of the improvements in the ablation study, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. While the comment identifies a potential issue with the novelty and significance of the work, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to discuss a previous work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment' from ICML 2019, and to illustrate the relationship between that work and the proposed method. It also suggests that the authors should explain why their proposed method is better. This feedback provides clear and concrete actions for the authors to take, including specific references to include and a rationale for their proposed method. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim made by the authors regarding the lack of research on joint error for UDA and references a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML 2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely discussing the relationship between the referenced work and the proposed method, and explaining why the proposed method is better. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the authors' claim that there is no research focusing on the joint error for UDA by referencing a specific work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,' from ICML 2019. This provides a clear and specific reference to support the claim, making it fully verifiable. The comment also suggests that the authors discuss the relationship between their work and the referenced one, which adds depth to the critique. Therefore, the comment is classified as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA and provides a counterpoint by referencing a previous work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,' from ICML 2019. It suggests that the authors discuss this work and illustrate the relationship between their proposed method and the referenced one, as well as explain why their method is better. This feedback is clear and actionable, offering a concrete way for the authors to strengthen their argument and situate their work within the existing literature. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate this discussion into the paper. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment explicitly instructs the authors to discuss a specific previous work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,' from ICML 2019, and to illustrate the relationship between that work and the proposed method. It also suggests that the authors explain why their proposed method is better. This feedback provides clear and concrete actions for the authors to take, making it highly actionable. The explicit nature of the suggestions and the detailed guidance on how to implement them ensure that the authors know exactly what steps to take to improve their draft.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim made by the authors regarding the lack of research on joint error for UDA and references a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML 2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely discussing the relationship between the referenced work and the proposed method, and explaining why the proposed method is better. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point challenges the authors' claim by referencing a specific work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,' from ICML 2019, which has already studied the problem of arbitrarily increased joint error. This provides a clear and specific reference to support the claim, making it fully verifiable. The comment also suggests that the authors discuss the relationship between their work and the referenced one, which adds depth to the critique. Therefore, the comment is classified as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA and challenges it by referencing a previous work, 'Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,' from ICML 2019. It suggests that the authors discuss this work and illustrate the relationship between their"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting ways to ensure a fair comparison or proposing alternative datasets for comparison. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. This provides a clear context for the issue being raised. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the potential unfairness of the comparison due to dataset size differences, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. The reviewer provides a specific example, mentioning GEM's use of only 20M unlabeled data, to illustrate the potential impact of dataset size on accuracy. This reasoning is logical and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by referencing additional studies or datasets to further substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the scale of the dataset rather than the method itself. This feedback is valuable as it highlights a potential limitation in the evaluation and encourages the authors to consider the impact of dataset size on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as proposing alternative datasets for comparison or discussing the implications of dataset size on the results. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as proposing alternative datasets for comparison or discussing the implications of dataset size on the results. The feedback lacks actionable steps, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. It provides a specific example, mentioning GEM's use of only 20M unlabeled data, to illustrate the potential impact of dataset size on accuracy. However, the comment does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the issue of dataset size impact on accuracy, but without clear grounding, it is challenging for the authors to pinpoint where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer provides a specific example, mentioning GEM's use of only 2"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the need for designing a new curriculum learning method for text graphs is not justified, and it highlights the lack of discussion on the research gap, such as why existing methods cannot be applied. While the comment identifies an area that requires further exploration, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the existing methods should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the need for a new method and discuss the limitations of existing approaches. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification for designing a new curriculum learning method for text graphs and the discussion of the research gap, such as why existing methods cannot be applied. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the need for a new curriculum learning method for text graphs, suggesting that existing methods could be applied. However, the comment does not provide specific examples or references to existing methods that might be applicable or discuss why they are not suitable for text graphs. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the need for a new curriculum learning method for text graphs and highlighting the lack of discussion on the research gap. It points out that existing methods could be applied, suggesting that the authors should provide a rationale for the necessity of a new approach. This feedback is clear and actionable, as it directs the authors to address the justification for their proposed method and to discuss why existing methods are insufficient. However, the comment could be more helpful if it provided examples of existing methods or suggested ways to explore the research gap. Overall, the comment is mostly helpful as it effectively guides the authors toward a meaningful revision of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of the simplest n-gram features. This comment provides a clear and explicit action for the authors to take, specifying the use of pre-trained models and the comparison of transfer parts. The suggestion is concrete, as it outlines a specific approach for the authors to follow to improve their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to use pre-trained models and compare transfer parts, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using powerful pre-trained language models like BERT and XLNet can overcome domain-shift problems in NLP. It recommends using these models as the base encoder for all methods and comparing the efficacy of the transfer parts instead of the simplest n-gram features. While the comment provides a logical reasoning for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors might find it challenging to understand the full context without additional details. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for all methods. It suggests comparing the efficacy of the transfer parts instead of the simplest n-gram features. This feedback is clear and offers a concrete direction for the authors to enhance their work by leveraging pre-trained models, which could significantly impact the results and methodology. However, the comment could be more helpful if it included additional details or examples on how to implement this suggestion effectively. Overall, the comment is mostly helpful as it provides valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of the simplest n-gram features. This feedback provides a clear and explicit action for the authors to take, offering a specific approach to improve their methodology. The suggestion is concrete, as it outlines a particular strategy for enhancing the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides a specific suggestion for improvement, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of the simplest n-gram features. While the comment provides a logical reasoning for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors might find it challenging to understand the full context without additional details. Therefore, the comment is somewhat verifiable, as it offers a reasonable suggestion but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for all methods. It suggests comparing the efficacy of the transfer parts instead of the simplest n-gram features. This feedback is clear and offers a concrete direction for the authors to enhance their work by leveraging pre-trained models, which could significantly impact the results and methodology. However, the comment could be more helpful if"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority to competitors. The reviewer explicitly asks if it is possible to conduct a quantitative comparison on the final outputs. This direct request provides a clear and concrete action for the authors to take, which is to include a quantitative comparison of final outputs. The comment is explicit and provides specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the quantitive evaluation results, noting that they only reflect middle outputs rather than final outputs, and suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority to competitors. The comment also asks if it is possible to conduct a quantitative comparison on the final outputs, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than final outputs. The reviewer suggests that this lack of final output evaluation makes the current evaluations insufficient to confirm ModelAngelo\\'s superiority to competitors. The comment provides a logical reasoning by pointing out the discrepancy between middle and final outputs, which is a valid concern. However, it lacks specific examples or references to support the claim that the current evaluations are insufficient. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitive evaluation results presented in Figure 3, noting that they only reflect middle outputs rather than final outputs. It highlights that Figure 4 illustrates the comparison of final results with a single data sample, suggesting that the current evaluations may not be convincing enough to confirm ModelAngelo\\'s superiority to competitors. The comment raises a valid concern and provides a clear suggestion for improvement by asking if it is possible to conduct a quantitative comparison on the final outputs. This feedback is actionable and encourages the authors to enhance the robustness of their evaluation results, making it mostly helpful. However, it could be further improved by offering specific guidance on how to implement this suggestion or by providing examples of how to present the final output comparisons. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, and the fixed radius with different scales. The reviewer provides a list of specific questions that need to be addressed, such as how to achieve shape invariance. While the comment does not explicitly instruct the authors on how to address these issues, the detailed nature of the questions provides clear guidance on what needs to be clarified. The authors know exactly what information is missing and can work on providing the necessary details. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, specifically the sparsification process and the generation of landmarks. It also raises questions about the number of landmarks used, the type of image features, and the fixed radius with different scales. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it challenging for the authors to pinpoint the exact areas that need revision. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of areas where detail is missing, such as the sparsification process, the generation of landmarks, and the number of landmarks used. These examples provide a clear indication of what is missing, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the importance of these aspects. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting a lack of detail regarding the techniques used, which makes it difficult to reproduce the results. It provides specific examples of areas where detail is missing, such as the sparsification process, the generation of landmarks, and the number of landmarks used. The comment also raises questions about the type of image features and the fixed radius with different scales, as well as the achievement of shape invariance. This feedback is clear and actionable, offering the authors a detailed list of areas to address and improve in their draft. By addressing these points, the authors can enhance the reproducibility and clarity of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the utility-based approach used in FIITED, suggesting that it might introduce biases by favoring recent chunks over older, potentially valuable ones. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the potential biases. The comment lacks concrete details on how to implement changes or improve the approach, leaving the authors uncertain about the steps to take. As a result, the comment is vague and unactionable, making it difficult for the authors to know how to apply the feedback effectively.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED to determine chunk significance, which is a specific aspect of the paper. However, it does not explicitly mention a particular section or part of the paper, making it weakly grounded. The comment does specify the potential issue with basing eviction decisions purely on utility scores, which could introduce biases. This provides some level of specificity regarding the concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the utility-based approach used in FIITED, suggesting that it might introduce biases. The comment provides a logical reasoning by explaining how recent chunks might gain a temporary high utility, potentially leading to premature evictions of valuable chunks. However, the claim lacks specific examples or references to support the assertion about the potential biases. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to address the concern effectively.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically regarding the determination of chunk significance. It raises a concern that basing eviction decisions purely on utility scores might introduce biases, such as favoring recent chunks over older, potentially valuable ones. This feedback is somewhat helpful as it highlights a potential weakness in the methodology that the authors should consider. However, the comment lacks specific suggestions or guidance on how to address this issue or mitigate the potential biases. To be more helpful, the comment could provide examples of alternative approaches or strategies to ensure fairness in eviction decisions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically regarding the determination of chunk significance. It raises a concern about the possibility of introducing biases, such as favoring recent chunks over older, potentially valuable ones. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the potential biases. Without specific actions or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the utility-based approach used in FIITED to determine chunk significance. It raises a concern about the potential for introducing biases by basing eviction decisions purely on utility scores. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment does provide some level of specificity by highlighting the potential issue with recent chunks gaining a temporary high utility, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the utility-based approach used in FIITED, suggesting that it might introduce biases. The comment provides a logical reasoning by explaining how recent chunks might gain a temporary high utility, potentially leading to premature evictions of valuable chunks. However, the claim lacks specific examples or references to support the assertion about the potential biases. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore and substantiate the claim themselves to address the concern effectively.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically regarding the determination of chunk significance. It raises a concern that basing eviction decisions purely on utility scores might introduce biases, such as favoring recent chunks over older, potentially valuable ones. This feedback is somewhat helpful as it highlights a potential weakness in the methodology that the authors should consider. However, the comment lacks specific suggestions or guidance on how to address this issue or mitigate the potential biases. Without actionable advice or examples, the authors may find"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first paragraph of the Introduction, which is entirely devoted to a general introduction of DNNs, is not central to the paper\\'s focus on detecting drift types and drift magnitude. The reviewer believes that this paragraph provides little valuable information to readers. However, the comment does not explicitly instruct the authors to remove or revise this paragraph. While the action is implied, it is not directly stated, and the authors may need to infer that they should make changes to the introduction. The lack of specific guidance on how to address this issue makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of relevance of the DNN-related introduction to the paper\\'s core focus on detecting drift types and drift magnitude. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction, which is devoted to a general introduction of DNNs, is not central to the paper\\'s focus on detecting drift types and drift magnitude. The reviewer believes that this paragraph provides little valuable information to readers. While the comment provides a logical reasoning by highlighting the lack of relevance to the paper\\'s core focus, it does not offer specific examples or references to support this claim. This makes the comment somewhat verifiable, as the authors would need to infer the specific issues and provide further details to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift. The reviewer argues that this introduction is not central to the paper\\'s focus on detecting drift types and drift magnitude, suggesting that it provides little valuable information to readers. This feedback is clear and actionable, as it directs the authors to reconsider the content and structure of the introduction to better align with the paper\\'s core focus. However, the comment could be more helpful if it provided suggestions on how to integrate the DNN-related content more effectively or offered examples of how to address the issue. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of clarity regarding how different parts of the framework contribute to the final result and suggests the need for either quantitative experiments or detailed explanations. It also mentions the absence of comparisons between selection of algorithms. While the comment identifies areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should conduct quantitative experiments or provide detailed explanations, but without specific guidance on how to implement these changes, the action remains vague. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"result section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of quantitative experiments, comparisons between algorithms, and detailed explanations on the framework\\'s performance and individual parts. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks clarity on how different parts of the framework contribute to the final result, despite showing promising visual stimuli results. The reviewer suggests the need for quantitative experiments or detailed explanations to clarify the framework's performance and individual parts' contributions. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific areas needing improvement, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper regarding the clarity of how different parts of the framework contribute to the final result. It points out the lack of quantitative experiments or detailed explanations, which is crucial for understanding the framework's performance and individual parts' contributions. The comment also highlights the need for comparisons between selection of algorithms, providing a clear direction for improvement. However, while it effectively identifies areas for enhancement, it could be more helpful by offering specific suggestions or examples on how to conduct these experiments or comparisons. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas needing clarification and improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a lack of clarity regarding how different parts of the framework contribute to the final result and suggests the need for either quantitative experiments or detailed explanations. While it points out the absence of comparisons between selection of algorithms, it does not provide explicit instructions on how to address these issues. The comment implies that the authors should conduct quantitative experiments or provide detailed explanations, but it lacks specific guidance on how to implement these changes. This makes the comment somewhat actionable, as the authors have a general idea of what needs to be done but lack detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"result section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of quantitative experiments, comparisons between algorithms, and detailed explanations on the framework\\'s performance and individual parts. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks clarity on how different parts of the framework contribute to the final result, despite showing promising visual stimuli results. It suggests the need for either quantitative experiments or detailed explanations to clarify the framework's performance and individual parts' contributions. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific areas needing improvement, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper regarding the clarity of how different parts of the framework contribute to the final result. It points out the lack of quantitative experiments or detailed explanations, which is crucial for understanding the framework's performance and individual parts' contributions. The comment also highlights the absence of comparisons between selection of algorithms, providing a clear direction for improvement. However, while it effectively identifies areas needing clarification, it could be more helpful by offering specific suggestions or examples on how to conduct these experiments or comparisons. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas needing improvement, but it could be more comprehensive with additional guidance.\","}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their captioning experiment results with those on the official COOC leader board, specifically on the blind test set. It references specific works, such as [5,17], that have won the challenge and been evaluated on the blind challenge set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. This feedback provides clear and concrete actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, ensuring full clarity and specificity.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to compare results on the official COOC leader board and the blind test set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its captioning experiment results with those on the official COOC leader board, specifically on the blind test set. It references specific works, such as [5,17], that have won the challenge and been evaluated on the blind challenge set, providing a clear rationale for the claim. Additionally, it mentions that several other approaches have been proposed since then and significantly improved, suggesting that the paper should at least compare to those where corresponding publications are available. This detailed justification and reference to external works make the claim mostly verifiable, as it provides a solid basis for the suggestion but could be strengthened with more explicit references or examples. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors compare their captioning experiment results with those on the official COOC leader board, specifically on the blind test set. It references specific works, such as [5,17], that have won the challenge and been evaluated on the blind challenge set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. This feedback is highly helpful as it directs the authors to a specific benchmark and provides a clear path for enhancing the validity and relevance of their results. By following this advice, the authors can significantly improve the impact and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the term \"wrong\" used in line 248 and suggests that it would be helpful to clarify what is meant by a good/bad/wrong explanation before using those concepts. While the comment implies that the authors should provide a clearer definition of these terms, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to clarify the terminology. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of the term \"wrong\" and suggests clarifying what is meant by a good/bad/wrong explanation before using those concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the use of the term \"wrong\" in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of the term \"wrong\" in the paper, suggesting that it would be helpful to clarify what is meant by a good/bad/wrong explanation before using those concepts. This feedback is somewhat helpful as it identifies a potential area of confusion for the reader and prompts the authors to provide clearer definitions or explanations. However, the comment could be more helpful if it offered specific suggestions on how to clarify these terms or examples of what constitutes a good or bad explanation. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that there is only an experimental comparison between ELF (the author's method) and the baseline without Mid Vision Feedback (MVF), without comparing with the image classification result of Mid Vision Feedback (MVF). The comment implies that the authors should include a comparison with the image classification result of MVF to substantiate their claim. While the action is implicit, it is clear and concrete, as it specifies exactly what needs to be added to the experimental demonstration. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically pointing out the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental demonstration, namely a comparison with the image classification result of MVF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment provides a logical reasoning by pointing out that the comparison between ELF and the baseline without MVF does not prove that the schema searched by ELF is better than that of MVF. However, the comment could be strengthened by providing specific examples or references to similar studies that have successfully demonstrated their contributions through comparisons. As it stands, the claim is mostly verifiable, as it logically outlines the issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the experimental demonstration of the paper's contribution points. It points out that while there is an experimental comparison between the author's method (ELF) and a baseline without Mid Vision Feedback (MVF), there is no comparison with the image classification result of MVF. This lack of comparison makes it difficult to substantiate the claim that the schema searched by ELF is better than that of MVF. The comment is clear and actionable, as it provides a specific direction for the authors to enhance their experimental demonstration by including a comparison with the image classification result of MVF. This feedback is mostly helpful as it guides the authors on how to strengthen their experimental validation, although it could be more comprehensive by suggesting additional comparisons or analyses. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or differentiate their work from the existing study. The comment lacks actionable details, such as recommending ways to enhance originality or suggesting specific areas for innovation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which parts of the article are similar or how the current work differs from the referenced study. This lack of specific references or detailed feedback makes it difficult for the authors to identify the exact areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate the claim that the current work is merely an extension of the previous study. Without concrete evidence or references to the similarities, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension of the previous study or introduces novel contributions. While the comment identifies a potential issue with originality, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from the existing study. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which parts of the article are similar or how the current work differs from the referenced study. This lack of specific references or detailed feedback makes it difficult for the authors to identify the exact areas needing improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate the claim that the current work is merely an extension of the previous study. Without concrete evidence or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension of the previous study or introduces novel contributions. However, the comment lacks specific examples or detailed comparisons to substantiate the claim, making it difficult for the authors to address the concern effectively. Without actionable feedback or guidance on how to differentiate their work, the comment provides limited value to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from the existing study. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the discussion regarding the regret and the method\\'s performance. It questions whether the authors intended to discuss the prediction error over the entire horizon T rather than the regret. While the comment identifies a potential misunderstanding, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their discussion, and it is somewhat vague because it lacks specific instructions on how to resolve the discrepancy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between discussing how regret cannot be sublinear and proceeding to prove that the method achieves T^{1/2} regret. The comment questions whether the authors meant to discuss the prediction error over the entire horizon T. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the consistency in the discussion regarding regret and the method\\'s performance. It suggests that the authors may have intended to discuss the prediction error over the entire horizon T rather than the regret. However, the comment does not provide any supporting evidence or references to substantiate this claim. The reasoning is based on a logical assumption, but without explicit examples or references, the claim remains somewhat verifiable. The authors would need to infer the basis of the reviewer\\'s concern, making it challenging to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the discussion regarding regret and the method\\'s performance. It questions whether the authors intended to discuss the prediction error over the entire horizon T rather than the regret. This feedback is somewhat helpful as it points out a possible misunderstanding or inconsistency in the paper, prompting the authors to clarify their discussion. However, the comment does not provide specific guidance on how to address this issue or suggest ways to improve the clarity of the discussion. While it highlights an area for improvement, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential inconsistency in the discussion regarding regret and the method\\'s performance. It questions whether the authors intended to discuss the prediction error over the entire horizon T rather than the regret. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify their discussion. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between discussing how regret cannot be sublinear and proceeding to prove that the method achieves T^{1/2} regret. The comment questions whether the authors intended to discuss the prediction error over the entire horizon T rather than the regret. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the consistency in the discussion regarding regret and the method\\'s performance. It suggests that the authors may have intended to discuss the prediction error over the entire horizon T rather than the regret. However, the comment does not provide any supporting evidence or references to substantiate this claim. The reasoning is based on a logical assumption, but without explicit examples or references, the claim remains somewhat verifiable. The authors would need to infer the basis of the reviewer\\'s concern, making it challenging to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the discussion regarding regret and the method\\'s performance. It questions whether the authors intended to discuss the prediction error over the entire horizon T rather than the regret. This feedback is somewhat helpful as it points out a possible misunderstanding or inconsistency in the paper, prompting the authors to clarify their discussion. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending a clearer explanation or"}
{"generated_text": "{'actionability_rationale': \"The review comment acknowledges the importance of learning long-range dependencies for powerful predictors and notes that this is evident in the example of semantic segmentation, as seen in the visualizations in Table 3. However, it expresses uncertainty about whether this is fully required and suggests a need for a discussion on this topic. The reviewer also raises a concern about the lack of encoding of locality in the graph structure, which could affect prediction. While the comment implies that the authors should include a discussion on the importance of learning long-range dependencies and the role of locality in graph structures, it does not provide explicit guidance on how to conduct this discussion or what specific aspects to focus on. The action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the paper's opening statement about learning long-range dependencies and references the example of semantic segmentation, specifically mentioning Table 3. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it raises a question about the necessity of learning long-range dependencies and suggests a discussion on this topic, particularly in relation to the graph structure and image size. This provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point acknowledges the importance of learning long-range dependencies for powerful predictors and provides an example from the paper's visualizations in Table 3. However, it expresses uncertainty about whether this is fully required and suggests a need for a discussion on this topic. The reviewer also raises a concern about the lack of encoding of locality in the graph structure, which could affect prediction. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the importance of learning long-range dependencies for powerful predictors and provides an example from the paper's visualizations in Table 3. It raises a question about whether this is fully required and suggests a need for a discussion on this topic. The comment also highlights a potential issue with the lack of encoding of locality in the graph structure, which could affect prediction. While the comment identifies areas for improvement and provides some insight into potential weaknesses, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider these aspects and encourages further exploration, but it could be more actionable with additional detail or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges the importance of learning long-range dependencies for powerful predictors and notes that this is evident in the example of semantic segmentation, as seen in the visualizations in Table 3. However, it expresses uncertainty about whether this is fully required and suggests a need for a discussion on this topic. The reviewer also raises a concern about the lack of encoding of locality in the graph structure, which could affect prediction. While the comment implies that the authors should include a discussion on the importance of learning long-range dependencies and the role of locality in graph structures, it does not provide explicit guidance on how to conduct this discussion or what specific aspects to focus on. The action is implicit and somewhat vague, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the paper's opening statement about learning long-range dependencies and references the example of semantic segmentation, specifically mentioning Table 3. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it raises a question about the necessity of learning long-range dependencies and suggests a discussion on this topic, particularly in relation to the graph structure and image size. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with a score of 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point acknowledges the importance of learning long-range dependencies for powerful predictors and provides an example from the paper's visualizations in Table 3. However, it expresses uncertainty about whether this is fully required and suggests a need for a discussion on this topic. The reviewer also raises a concern about the lack of encoding of locality in the graph structure, which could affect prediction. While the comment provides some reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. The suggestion for a discussion is based on an observation rather than"}
{"generated_text": "{'actionability_rationale': \"The review point raises several concerns about the theoretical results, specifically mentioning the dependence on the diameter $M$ and the performance shown in Figure 1. However, it does not provide explicit guidance on how the authors should address these issues or improve their draft. The comment lacks actionable details, such as suggesting specific changes to the theoretical analysis or proposing ways to mitigate the identified weaknesses. As a result, the authors are left without clear direction on how to proceed, making the comment unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the theoretical results, particularly the exponential dependence on the diameter $M$ and the performance shown in Figure 1. The comment provides specific details about the weaknesses of the proposed approaches, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the theoretical results, specifically the dependence on the diameter $M$ and the performance shown in Figure 1. It claims that the results have an exponential dependence on $M$, which affects the constant factor of the required feature size. The comment provides some logical reasoning by comparing the results to standard random features and suggesting that this dependence may indicate a weakness in the proposed approaches. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore and verify the claims themselves, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several specific issues with the theoretical results presented in the paper. It points out the exponential dependence on the diameter $M$ of the domain, which affects the constant factor of the required feature size. The comment also highlights that this dependence does not increase as the required amount of error $\\\\varepsilon$ decreases, which may indicate a weakness in the proposed approaches. Additionally, it references Figure 1, which shows a more rapid decline in performance compared to standard random features. This feedback is clear and provides actionable insights for the authors to consider, such as revising the theoretical analysis or exploring alternative approaches to address the identified weaknesses. However, the comment could be more helpful if it offered specific suggestions or guidance on how to improve the theoretical results or address the identified issues. Overall, the comment is mostly helpful, as it provides valuable insights but lacks comprehensive guidance for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their modeling ability. The comment lacks actionable details, such as recommending specific methods or experiments to mitigate oversmoothing or suggesting ways to enhance long-range modeling. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs and mentions oversquashing, vanishing/exploding gradients, and oversmoothing as potential issues. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the potential causes of poor performance but lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. The comment provides a reference to a specific phenomenon, \"oversmoothing,\" which is observed in very deep graph networks. This reference adds a level of verifiability to the claim, as it provides a basis for understanding the issue. However, the comment could be strengthened by including more detailed explanations or examples of how these phenomena affect DGNs. As it stands, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive detail. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific phenomenon, oversmoothing, which is observed in very deep graph networks, providing a relevant context for the authors to consider. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their modeling ability. While it points out a relevant area for improvement, it does not offer specific steps or recommendations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their modeling ability. The comment lacks actionable details, such as recommending methods or experiments to mitigate oversmoothing or enhance long-range modeling. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs and mentions oversquashing, vanishing/exploding gradients, and oversmoothing as potential issues. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is somewhat specific in identifying the potential causes of poor performance but lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific phenomenon, \"oversmoothing,\" which is observed in very deep graph networks, providing a logical basis for the claim. However, the comment lacks detailed evidence or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reference to fully understand and address the issue. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific phenomenon, oversmoothing, which is observed in very deep graph networks, providing a relevant context for the authors to consider. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The authors are left without clear instructions on how to address the issue, making it difficult for them to know what changes to make. The lack of explicit or concrete actions leaves the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact areas needing clarification. While the authors might have an idea of where these sections are located, the comment lacks full grounding. It is specific in identifying the issue of unclear formulation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks depth and does not provide detailed guidance or suggestions on how to improve the clarity of the formulation. Without actionable advice or specific examples, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to make significant improvements to their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. While it implies that the authors should explore this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion or why it might be beneficial. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the choice of quantization methods, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of quantization methods. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization methods, specifically questioning why finer grouping is not considered instead of per-tensor and per-channel. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might explore finer grouping or why it might be beneficial. Without actionable feedback or detailed reasoning, the authors are left with a vague understanding of the issue, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the paper, specifically asking if it is used on top of the proposed strategy. While the comment highlights a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to clarify the use of epsilon-greedy exploration in their work, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" and whether it is used on top of the proposed strategy, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the use of \"epsilon-greedy\" in the context of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of the paper, specifically asking whether it is used on top of the proposed strategy. This is a relevant point that could help clarify the methodology and ensure that the authors have accurately described their approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area of confusion, it lacks actionable feedback or specific advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential limitations of dynamic precision control during training, suggesting that it may only show meaningful performance gains on bit-serial accelerators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or explore alternative scenarios. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the potential limitations of dynamic precision control during training, specifically mentioning its relevance to bit-serial accelerators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation of the proposed methodology in relation to existing ML accelerators, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that dynamic precision control during training may only show meaningful performance gains on bit-serial accelerators, which are less common in existing ML accelerators. This claim is somewhat verifiable as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the assertion that most existing ML accelerators use bit-parallel fixed-point numbers. Additionally, it does not provide detailed evidence or studies that demonstrate the limitations of the proposed methodology in other contexts. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training may only show meaningful performance gains on bit-serial accelerators, which are less common in existing ML accelerators. This insight is valuable as it highlights a potential gap in the applicability of the proposed methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative scenarios. While it provides a useful point for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential limitation of the proposed methodology, suggesting that dynamic precision control during training may only show meaningful performance gains on bit-serial accelerators, which are less common in existing ML accelerators. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or explore alternative scenarios. Without specific guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the potential limitations of dynamic precision control during training, specifically mentioning its relevance to bit-serial accelerators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation and its implications, but without clear references or detailed guidance, the authors may struggle to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that dynamic precision control during training may only show meaningful performance gains on bit-serial accelerators, which are less common in existing ML accelerators. This claim is somewhat verifiable as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the assertion that most existing ML accelerators use bit-parallel fixed-point numbers. Additionally, it does not provide detailed evidence or studies that demonstrate the limitations of the proposed methodology in other contexts. Therefore, the claim requires further elaboration to be fully substantiated, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training may only show meaningful performance gains on bit-serial accelerators, which are less common in existing ML accelerators. This insight is valuable as it highlights a gap in the applicability of the proposed methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative scenarios. While it provides a useful point for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies Eq. 12 as confusing and asks for clarification on where the reward comes from at each trial. It suggests that one of the r_i might be taken from Eq. 11, prompting the authors to provide a clearer explanation. Additionally, the comment recommends explaining the network model in Sec. 4.2 with equations to improve clarity. The reviewer provides specific references to related work, which could guide the authors in enhancing their explanation. The feedback is explicit and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning where the reward comes from at each trial and suggesting that the network model in Sec. 4.2 should be explained with equations to improve clarity. The comment further provides references to related work, which could guide the authors in enhancing their explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation 12 is confusing and questions the origin of the reward at each trial. The reviewer suggests that one of the r_i might be taken from Equation 11, and recommends explaining the network model in Section 4.2 with equations to improve clarity. The comment provides a specific example of where the confusion lies and suggests a potential solution, which is a clear and logical reasoning. However, it lacks detailed examples or references to support the claim further, making it mostly verifiable. The inclusion of references to related work could strengthen the claim, but the current feedback is still mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that one of the r_i might be taken from Equation 11. It provides a clear and actionable suggestion to improve clarity by explaining the network model in Section 4.2 with equations. The comment also includes references to related work, which could guide the authors in enhancing their explanation. This feedback is highly helpful as it not only points out a specific area of confusion but also offers a concrete solution and additional resources for improvement. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or improve the complexity of their approach. The comment lacks actionable details, such as recommending ways to increase the novelty or suggesting alternative methods or metrics. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the idea, mentioning that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper these claims are based on, nor does it provide details on how the novelty could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is insufficient, stating that both the new metric and method are relatively straightforward. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the novelty of the idea is insufficient, suggesting that both the new metric and method are relatively straightforward. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or improve the complexity of their approach. Without actionable feedback or detailed insights, the authors are left without a clear path to address the critique. Therefore, the comment is not particularly helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding. It also recommends including a notation table to clarify the use of symbols. While the comment provides explicit actions for improvement, it lacks specific guidance on how to structure the generative process or what specific symbols should be included in the notation table. The authors are given clear directions on what needs to be improved but are left without detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the generative process and the use of symbols. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding. It is specific about what could be improved, such as presenting the generative process in separate steps and using a notation table, but without clear grounding, it is challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to clarify the use of symbols. While the comment provides a general suggestion for improvement, it lacks specific examples or detailed reasoning to support why these changes would enhance understanding. The claim is somewhat verifiable as it points out potential areas for improvement, but it lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the model description. It suggests presenting the generative process in separate steps for better understanding and recommends using a notation table to clarify the use of symbols. These suggestions are clear and provide the authors with concrete steps to enhance the clarity and comprehensibility of their model description. However, the comment could be more helpful if it offered examples of how to structure the generative process or what specific symbols should be included in the notation table. Overall, the feedback is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should better motivate the \"Why\" aspect, implying that the authors should provide a clearer rationale for their work. However, it does not specify what aspects of the motivation should be improved or how the authors should address this issue. The action is implicit and vague, leaving the authors uncertain about how to effectively implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should better motivate the \"Why\" aspect, implying that the authors should provide a clearer rationale for their work. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should better motivate the \"Why\" aspect, implying that the authors should provide a clearer rationale for their work. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from better motivation of the \"Why\" aspect, implying that the authors should provide a clearer rationale for their work. However, the comment lacks specificity and does not provide detailed guidance or examples on how the authors might improve this aspect. Without actionable feedback or specific suggestions, the authors are left with a vague understanding of what needs to be addressed. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to effectively enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance and highlights a trade-off between head and tail categories in Table 5. It suggests that the authors should investigate this trade-off for the baselines by changing hyper-parameters in Decouple [Kang et al.] to improve tail accuracy while slightly decreasing head accuracy. The comment provides a clear and explicit action for the authors to take, which is to investigate the trade-off for the baselines and provide a detailed analysis. This guidance is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and refers to the proposed approach\\'s performance compared to Decouple [Kang et al.]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue with the proposed approach not outperforming or even being worse than Decouple [Kang et al.] and suggests investigating the trade-off between head and tail categories for the baselines. It provides a clear direction for improvement by recommending a specific analysis for the baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also suggests that the trade-off between head and tail categories has not been fully investigated for the baselines, using an example of how Decouple [Kang et al.] could improve tail accuracy. The comment provides a logical reasoning by comparing the performance of the proposed approach with Decouple [Kang et al.] and suggesting a potential trade-off analysis for the baselines. However, it lacks specific references or detailed examples to fully substantiate the claim, making it mostly verifiable. The authors would need to further explore the suggestion to fully address the feedback.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's claims, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that the authors should explore this trade-off by changing hyper-parameters in Decouple [Kang et al.] to improve tail accuracy while slightly decreasing head accuracy. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct this analysis. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear path for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples of issues, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment does not explicitly instruct the authors on how to address these issues or provide concrete steps for improvement. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate the realism of the tweets and the generation process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It provides specific examples, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the evaluation of weak supervision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the evaluation of weak supervision, specifically regarding the realism of the evaluated tweets and the generation process. It provides examples of unrealistic elements, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the unrealistic nature of the evaluation. While it raises valid concerns, the lack of explicit evidence or examples makes it somewhat verifiable. The authors would need to further explore and verify these claims themselves, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation of weak supervision, particularly in the context of the evaluation of tweets. It questions the realism of the evaluated tweets and the generation process, providing specific examples of unrealistic elements, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. This feedback is clear and actionable, as it directs the authors to consider the realism of their evaluation criteria and the generation process. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of more realistic evaluation methods. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the evaluation of weak supervision.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment does not explicitly instruct the authors on how to address these issues or provide concrete steps for improvement. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate the realism of the tweets and the generation process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It provides specific examples, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the evaluation of weak supervision. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the evaluation of weak supervision, specifically regarding the realism of the evaluated tweets and the generation process. It provides specific examples, such as the prompt requiring all structured elements to be present in the generated tweets and the unrealistic generation of authors. However, the comment lacks detailed reasoning or references to support the claim about the unrealistic nature of the evaluation. While it raises valid concerns, the absence of explicit evidence or examples makes it somewhat verifiable. The authors would need to further explore and verify these claims themselves, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation of weak supervision, particularly in the context of the evaluation of tweets. It questions the realism of the evaluated tweets and the generation process, providing specific examples of unrealistic elements, such as the prompt requiring all structured elements to be present in"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This is an explicit suggestion, providing a clear action for the authors to take. However, while it specifies the type of comparison to be made, it does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. Therefore, the comment is mostly actionable, as it gives a clear direction but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results section where the performance of the proposed model is evaluated. The suggestion is specific, as it provides a clear direction for comparison with existing models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment provides a logical reasoning for the comparison, it lacks specific examples or detailed justification for why this comparison is necessary or how it would enhance the paper. The suggestion is somewhat verifiable, as it offers a direction for further analysis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests a specific comparison to be made between the proposed model and existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by comparing their model's performance with relevant existing models. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This is an explicit suggestion, providing a clear action for the authors to take. However, while it specifies the type of comparison to be made, it does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. Therefore, the comment is mostly actionable, as it gives a clear direction but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results section where the performance of the proposed model is evaluated. The suggestion is specific, as it provides a clear direction for comparison with existing models. However, the comment lacks explicit grounding, as it does not pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed model with existing models where answers are also used as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment provides a logical reasoning for the comparison, it lacks specific examples or detailed justification for why this comparison is necessary or how it would enhance the paper. The suggestion is somewhat verifiable, as it offers a direction for further analysis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests a specific comparison to be made between the proposed model and existing models where answers are also used as inputs, such as Revisiting Visual Question Answering"}
{"generated_text": "{'actionability_rationale': 'The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative design choices. The comment implies that the authors should reconsider this design choice, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, given the nature of the question model as a bag of words. The comment provides a clear rationale for why this choice might be odd, suggesting that it is not expensive to encode longer sequences. This level of detail helps the authors understand what aspect of the design choice is being questioned and why. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. The comment provides a logical reasoning by pointing out the contradiction between the design choice and the nature of the question model. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. This feedback is somewhat helpful as it identifies a potential issue with the design choice and prompts the authors to reconsider this aspect of their work. However, the comment lacks depth and does not provide specific suggestions or alternatives for improvement. While it highlights a potential weakness, it does not offer actionable guidance, leaving the authors with a general direction for consideration rather than a concrete path to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or providing specific reasoning for the design choice. As a result, the authors are left without clear direction on how to proceed, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. The comment provides a clear rationale for why this choice might be odd, suggesting that it is not expensive to encode longer sequences. This level of detail helps the authors understand the issue and its implications, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. The comment provides a logical reasoning by pointing out the contradiction between the design choice and the nature of the question model. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. This feedback identifies a potential issue with the design choice, prompting the authors to reconsider this aspect of their work. However, the comment lacks depth and does not provide specific suggestions or alternatives for improvement. While it highlights a potential weakness, it does not offer actionable guidance"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of \"$\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$\" in Equation (2). While it identifies a specific element in the equation that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the meaning of this term, but it remains vague because it lacks concrete guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"$\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$,\" providing a clear indication of what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the meaning of a specific equation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, pointing out that the meaning of \"$\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$\" in Equation (2) is unclear. This feedback is valuable as it highlights a potential area of confusion for readers, prompting the authors to clarify this aspect of their work. However, the comment does not provide suggestions on how to improve the clarity or offer alternative explanations, which would make it more actionable. While it directs the authors to an important area needing clarification, it lacks depth and specificity in its guidance. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive direction for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific lines in the paper that should be corrected and suggests that they be moved to the supplementary material. It provides clear instructions on which lines to change and where to place them, making the action concrete and directly actionable. The authors know exactly what changes to make and where to implement them, ensuring a clear path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"L502,\" \"L507,\" and \"L509,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lines that should be in green SuppMat and the references to \u03f5 \u03b8, (4), and (1) that should be corrected. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the color of lines in the paper, specifically mentioning that two lines should be in green SuppMat. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two lines in the paper that should be corrected and moved to the supplementary material. It clearly specifies the lines that need to be changed and where they should be placed, offering precise guidance to the authors on how to improve their draft. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make direct and effective improvements to their work. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that important references are missing and encourages the authors to include a comprehensive comparison with the works of GFF and EfficientFCN. It provides specific references to these works, which are cited in the comment itself. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The authors know exactly which references to include and how to incorporate them into their comparison, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely a comprehensive comparison with these works, and provides the exact references for the authors to consider. Additionally, it mentions the societal impact, which is shown on the last page of the manuscript. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer suggests that the authors should include a comprehensive comparison with these works. The comment provides specific references, which supports the claim by offering concrete examples of relevant literature. This makes the claim mostly verifiable, as the authors can understand the basis of the suggestion and the need for inclusion of these references. However, the comment could be strengthened by explaining why these references are particularly relevant or how they would enhance the paper. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the literature review by pointing out that important references are missing. It specifically mentions GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, providing the exact references for the authors to consider. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers concrete examples of relevant literature. By addressing this point, the authors can enhance the depth and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment explicitly suggests that important references are missing and encourages the authors to include a comprehensive comparison with the works of GFF and EfficientFCN. It provides specific references, which are cited in the comment itself, allowing the authors to understand exactly what needs to be added to their draft. This feedback is clear and provides concrete guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely a comprehensive comparison with these works, and provides the exact references for the authors to consider. Additionally, it mentions the societal impact, which is shown on the last page of the manuscript. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer suggests that the authors should include a comprehensive comparison with these works. The comment provides specific references, which supports the claim by offering concrete examples of relevant literature. This makes the claim mostly verifiable, as the authors can understand the basis of the suggestion and the need for inclusion of these references. However, the comment could be strengthened by explaining why these references are particularly relevant or how they would enhance the paper. Therefore, the comment aligns with a label of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the literature review by pointing out that important references are missing. It specifically mentions GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, providing the exact references for the authors to consider. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers concrete examples of relevant literature. By addressing this"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a concern about the practical performance of the proposed algorithms, specifically highlighting the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer suggests that the paper would be more convincing if the authors could provide experimental results to support their claims. While the comment identifies a potential issue and suggests a course of action (providing experimental results), it does not offer specific guidance on how to conduct these experiments or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Algorithm 1' and the use of a Vandermonde matrix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the numerical stability of the algorithm, particularly for large $n$ and small $\\\\alpha$, and suggests that experimental results could enhance the paper's convincingness. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the practical performance of the proposed algorithms, specifically highlighting the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a specific concern about the numerical stability of the algorithm, particularly for small $\\\\alpha$, which can be as small as $1/k^2L^2$. This claim is supported by logical reasoning and common knowledge about the properties of Vandermonde matrices. However, the comment could be strengthened by providing more detailed examples or references to studies that have addressed similar issues. As it stands, the claim is mostly verifiable, as it is based on established knowledge but could benefit from additional evidence or references. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific concern about the practical performance of the proposed algorithms, particularly regarding the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer highlights a potential issue with the algorithm's stability, especially for small values of $\\\\alpha$, which can be as small as $1/k^2L^2$. This feedback is valuable as it points out a critical weakness that the authors need to address to enhance the credibility of their work. The comment also suggests that providing experimental results could help substantiate the claims made in the paper. While the comment is clear in identifying the issue, it could be more helpful by offering specific guidance on how to conduct the experiments or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors' attention to a significant concern and suggests a potential improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, particularly when applied to large-scale datasets like ImageNet. It questions whether there is a solution to address the scalability issue and suggests that the practical contribution of the paper may be reduced if this issue is not addressed. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how to address the scalability issue. The authors are left to infer that they need to find a solution to the scalability problem, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of the proposed NC measure, specifically mentioning that it takes the whole training and test datasets as input. This provides some grounding, as the authors can infer that it relates to the methodology or results sections. However, the comment does not specify which part of the paper discusses the NC measure or scalability, making it weakly grounded. The comment is specific in its concern about the scalability issue and suggests a potential solution, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large-scale datasets like ImageNet. The reviewer suggests that the practical contribution of the paper may be reduced if this scalability issue is not addressed. However, the comment lacks specific reasoning, examples, or references to support the claim about scalability or suggest potential solutions. This makes the claim somewhat verifiable, as the authors would need to further explore and address the scalability issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the scalability of the proposed NC measure, particularly when applied to large-scale datasets like ImageNet. It questions the practicality of the method and suggests that the paper's contribution may be reduced if this issue is not addressed. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address the scalability issue. The feedback prompts the authors to consider the practical implications of their work, but it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, particularly when applied to large-scale datasets like ImageNet. It questions whether there is a solution to address the scalability issue and suggests that the practical contribution of the paper may be reduced if this issue is not addressed. However, the comment does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their work. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of the proposed NC measure, specifically mentioning that it takes the whole training and test datasets as input. This provides some grounding, as the authors can infer that it relates to the methodology or results sections. However, the comment does not specify which part of the paper discusses the NC measure or scalability, making it weakly grounded. The comment is specific in its concern about the scalability issue and suggests a potential solution, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large-scale datasets like ImageNet. The comment suggests that the practical contribution of the paper may be reduced if this scalability issue is not addressed. However, the claim lacks specific reasoning, examples, or references to support the assertion about scalability. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered somewhat verifiable, as it provides a general concern but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the scalability of the proposed NC measure, particularly when applied to large-scale datasets like ImageNet. It questions the practicality of the method and suggests that the paper's contribution may be reduced if this scalability issue is not addressed. This feedback is somewhat helpful as it"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a concern about the proposed PSA method requiring more computation than baselines and suggests that the comparison of computation complexity should be included in the experiment part. This provides a clear and direct action for the authors to take, which is to conduct a comparison of computation complexity in their experiments. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and the \"comparison of computation complexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the PSA method requiring more computation than baselines and suggests that the comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. This claim is somewhat verifiable as it provides a specific observation about the computational requirements of the PSA method. However, it lacks detailed reasoning or evidence to fully substantiate the claim, such as comparisons with the baselines or specific computational complexity metrics. The authors would need to further explore and verify this claim themselves. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than the baselines. It provides a clear and actionable suggestion by recommending that the comparison of computation complexity should be included in the experiment part. This feedback is valuable as it guides the authors to address a potential weakness in their methodology and provides a concrete step for improvement. However, the comment could be more helpful if it offered additional insights or suggestions on how to effectively compare computation complexity. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a mix of explicit and implicit actions. It explicitly suggests that fonts in figures 1 and 2 should be larger and that the \"CTRL\" long form explanation should be included. Additionally, it implies that the lack of details on epochs and number of parameters in the comparison with other state-of-the-art Transformer designs should be addressed. The comment also suggests presenting the data in a \"table\" manner to emphasize the results. While the actions are clear, the comment could be more concrete by specifying which fonts should be larger or providing examples of how to present the data in a table format. Overall, the comment is mostly actionable as it provides specific guidance on what needs to be improved, but it could be more detailed in some areas.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The review comment provides specific feedback on the figures and fonts used in the paper. It explicitly mentions \"fig 1\" and \"fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed, which makes it fully grounded. The comment also specifies what needs to be addressed, such as increasing the size of fonts and providing a \"CTRL\" long form explanation, as well as suggesting that the font in figure 2 is too small. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a mix of factual observations and suggestions for improvement. The factual observations about the figures and fonts are descriptive and do not contain claims or opinions that require verification. The suggestion to include a \"table\" manner for comparison with other state-of-the-art Transformer designs is also factual. Therefore, the overall comment is a mix of factual statements and suggestions, with no claims or opinions that require verification. The factual nature of the observations makes it appropriate to label the comment as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures and fonts used in the paper. It suggests that the fonts in figures 1 and 2 should be larger, and it points out that the words in the grey box and the terms \"V_mem,\" \"Th_i,\" and \"U_i^t\" are too small. Additionally, it recommends including a \"CTRL\" long form explanation and notes that the font in figure 2 is too small. These suggestions are clear and provide the authors with concrete steps to improve the clarity and readability of their figures. However, the comment could be more helpful if it included additional suggestions or examples for improving the comparison with other state-of-the-art Transformer designs, such as specifying the details of the comparison (e.g., epochs and number of parameters) or suggesting how to present this information in a more effective manner. Overall, the comment is mostly helpful as it provides actionable feedback on specific aspects of the figures and fonts, but it could be more comprehensive with additional guidance on the comparison aspect.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is a bit better than FP according to the results in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison. The suggestion is concrete, as it specifies exactly what needs to be added to the comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including \"ATA\" in the comparison, as it is a bit better than FP according to the results in Table 1. This provides clear guidance on what needs to be added to the comparison, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is a bit better than FP according to the results in Table 1. The claim is based on the observation that \"ATA\" is better than FP, which is supported by the results presented in Table 1. However, the comment does not provide specific data or detailed reasoning to fully substantiate the claim that \"ATA\" is better than FP. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that in Table 2, the proposed method should be compared to \"ATA\" in addition to \"+LFP,\" as the results in Table 1 indicate that \"ATA\" is a bit better than \"FP.\" This feedback is clear and constructive, as it guides the authors on how to enhance the comprehensiveness and robustness of their comparison. By including \"ATA\" in the comparison, the authors can strengthen the validity of their findings and provide a more convincing evaluation of their method. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is a bit better than FP according to the results in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison. The suggestion is concrete, as it specifies exactly what needs to be added to the comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including \"ATA\" in the comparison, as it is a bit better than FP according to the results in Table 1. This provides clear guidance on what needs to be added to the comparison, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is a bit better than FP according to the results in Table 1. The claim is based on the observation that \"ATA\" is better than FP, which is supported by the results presented in Table 1. However, the comment does not provide specific data or detailed reasoning to fully substantiate the claim that \"ATA\" is better than FP. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that in Table 2, the proposed method should be compared to \"ATA\" in addition to \"+LFP,\" as the results in Table 1 indicate that \"ATA\" is a bit better than FP. This feedback is clear and constructive, as it guides the authors on how to enhance the comprehensiveness and robustness of their comparison. By including \"ATA\" in the comparison, the authors can strengthen the validity of their findings and provide a more convincing evaluation of their method. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label':"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of mathematical definition for architectural details, specifically mentioning multi-head attention and the split arrow in Figure 2. It explicitly asks for a formal definition of these elements to help readers understand the model architecture better. The comment provides a clear and direct action for the authors to take, which is to include a formal definition of the architectural details. This guidance is specific and actionable, ensuring the authors know exactly what needs to be added to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, particularly the multi-head attention and the split arrow in Figure 2. The comment provides specific questions and suggestions for clarification, such as asking about the inputs for the attention layer and whether the same vectors are used for keys and values. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of mathematical definition for architectural details, specifically mentioning multi-head attention and the split arrow in Figure 2. It questions the clarity of the figure and suggests that a formal definition would aid readers in understanding the model architecture. While the comment identifies specific areas of confusion, it does not provide detailed reasoning or references to support the claim that these details are lacking. The authors are left to infer the importance of these details and the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of mathematical definition for architectural details, particularly multi-head attention. It provides a clear example of a figure element that requires clarification, specifically the split arrow in Figure 2. The comment suggests that a formal definition of these architectural details would greatly aid readers in understanding the model architecture. This feedback is actionable and provides a concrete suggestion for improvement, making it mostly helpful. However, it could be further improved by offering more detailed guidance on how to present this information or by suggesting specific aspects of the architecture that need clarification. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the presentation of the paper is difficult for the reviewer to follow, but it does not provide any specific guidance or suggestions on how the authors can improve the clarity or organization of their presentation. Without explicit instructions or concrete details on what aspects need to be addressed or how to enhance the presentation, the authors are left without a clear path forward. The lack of actionable advice or specific examples makes it difficult for the authors to know how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation of the paper is difficult for the reviewer to follow, but it does not specify which parts of the paper are problematic or provide any details on what aspects of the presentation are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is difficult to follow, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors may find it challenging to understand the basis of the reviewer\\'s difficulty in following the presentation. As a result, the comment lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the presentation of the paper is difficult for the reviewer to follow, but it does not provide any specific details or suggestions on how the authors might improve the clarity or organization of their presentation. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation are problematic or how to address them. This lack of specificity and actionable advice makes the comment unhelpful for the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include and compare their work to existing literature, specifically mentioning works by Li and He. It also recommends discussing how their work differs from other chatbox research. While the comment provides specific references to include, it does not explicitly instruct the authors to make these comparisons or discuss the differences. The action is implicit but concrete, as the authors can infer that they need to incorporate these references and comparisons into their work. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including and comparing the work of Li and He with the authors\\' own research, which provides some grounding as it relates to the literature review section. However, it does not specify which part of the paper should include these comparisons or where the discussion on differences from other chatbox research should be placed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact sections that need revision. The comment is specific in suggesting which works to include and compare, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the work should include and compare it to existing literature, specifically mentioning works by Li and He. This claim is somewhat verifiable as it provides references to specific works that could be relevant for comparison. However, the comment lacks detailed reasoning or explanation on why these works are particularly important or how they relate to the current study. Additionally, it does not provide specific examples of how the authors\\' work differs from these references, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by recommending that the authors include and compare their work to existing literature, specifically mentioning works by Li and He. This guidance helps the authors situate their research within the broader context of task-oriented recommendation and chatbox research. Additionally, the comment suggests a general discussion on how their work differs from other chatbox research, which could enhance the paper\\'s contribution and originality. While the comment is mostly helpful, it could be further improved by offering more detailed guidance on how to effectively incorporate these comparisons and discussions into the paper. Overall, the feedback is clear and provides valuable direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should include and compare their work to existing literature, specifically mentioning works by Li and He. It also recommends discussing how their work differs from other chatbox research. While the comment provides specific references to include, it does not explicitly instruct the authors to make these comparisons or discuss the differences. The action is implicit but concrete, as the authors can infer that they need to incorporate these references and comparisons into their work. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including and comparing the work of Li and He with the authors\\' own research, which provides some grounding as it relates to the literature review section. However, it does not specify which part of the paper should include these comparisons or where the discussion on differences from other chatbox research should be placed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact sections that need revision. The comment is specific in suggesting specific works to include and compare, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including and comparing the work of Li and He with the authors\\' own research, providing specific references to relevant literature. This provides a clear basis for the claim, making it somewhat verifiable. However, the comment could be strengthened by offering more detailed reasoning or examples on how these works relate to the authors\\' research or what specific aspects should be compared. As it stands, the comment provides a starting point for the authors but lacks comprehensive justification, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by recommending that the authors include and compare their work to existing literature, specifically mentioning works by Li and He. This guidance helps the authors situate their research within the broader context of task-oriented recommendation and chatbox research. Additionally, the comment suggests a general discussion on how their work differs from other chatbox research, which could enhance the paper\\'s contribution and originality. While the comment is mostly helpful, it could be further improved by offering more detailed guidance on how"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which the authors can reference to understand the distinction better. This feedback is clear and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the meta solvers being centralized controllers and suggests clarifying the difference between the meta solvers and centralized RL, where agents share weights. It provides a reference to a specific work, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which helps ground the comment. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to clarify the difference is specific, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the meta solvers seem to be centralized controllers and suggests clarifying the difference between them and centralized RL, where agents share weights. The comment provides a reference to a specific work, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which could help the authors understand the context and potential differences. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The inclusion of a reference provides some support, but the authors may need to further explore the reference to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this distinction, providing a reference to a relevant work by Foester et al. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs clarification and offers a reference for further exploration. By addressing this point, the authors can improve the clarity and accuracy of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which the authors can use to understand the distinction better. This feedback is clear and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this difference and provides a reference to a relevant work, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which can help in understanding the context. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it points out a particular area for clarification. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the meta solvers seem to be centralized controllers and suggests clarifying the difference between them and centralized RL, where agents share weights. It provides a reference to a specific work, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which could help in understanding the distinction. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference is a step towards verification, the absence of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this distinction, providing a reference to a relevant work by Foester et al. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs clarification and offers a reference for further exploration"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This comment implies that the authors should clarify this point in their draft. While the action is not explicitly stated, it is clear that the reviewer is asking for clarification, making the comment mostly actionable. The authors know they need to address this confusion, but the comment could be more explicit about how to resolve it.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion about the phrase \"non-sequential information such as chunks\" and whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding a specific phrase in the paper, \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This feedback is somewhat helpful as it identifies a potential area of confusion for the reader. However, it lacks depth and does not provide suggestions on how the authors might clarify this point in their draft. While it prompts the authors to address a potential issue, it does not offer actionable guidance or examples on how to resolve it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, suggesting that the output patches might not be cropped parts of the input image but rather masked versions with most pixels black. The reviewer asks if this interpretation is correct and points out that Figure 1 might be misleading. Additionally, the comment suggests that zooming on the region of interest using bilinear sampling could provide better results. While the comment raises important questions and provides a potential solution, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address the discrepancy. The action is implicit but concrete, as the authors can infer that they need to clarify the discrepancy and potentially revise Figure 1 and the explanation in Equation 9. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the discrepancy between the equation and the figure, suggesting that the output patches might not be cropped parts of the input image but rather masked versions with most pixels black. The comment further provides a potential solution by suggesting that zooming on the region of interest using bilinear sampling could provide better results. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between Equation 9 and Figure 1, suggesting that the output patches might not be cropped parts of the input image but rather masked versions with most pixels black. The reviewer questions the accuracy of Figure 1 and suggests that zooming on the region of interest using bilinear sampling could provide better results. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the discrepancy or the suggested improvement. The reasoning is somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches as masked versions of the input image with most pixels black. It suggests that Figure 1 might be misleading and proposes an alternative approach by zooming on the region of interest using bilinear sampling. This feedback is clear and actionable, as it points out a potential issue with the current representation and offers a specific suggestion for improvement. By addressing this discrepancy and considering the proposed alternative, the authors can enhance the clarity and accuracy of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches as masked versions of the input image with most pixels black. It suggests that Figure 1 might be misleading and proposes an alternative approach by zooming on the region of interest using bilinear sampling. While the comment raises important points and provides a potential solution, it does not explicitly instruct the authors to address the discrepancy or make changes to Figure 1. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider the suggested alternative. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the interpretation of the output patches as masked versions of the input image with most pixels black, suggesting that Figure 1 might be misleading. The comment further provides a potential solution by suggesting that zooming on the region of interest using bilinear sampling could provide better results. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between Equation 9 and Figure 1, suggesting that the output patches might not be cropped parts of the input image but rather masked versions with most pixels black. The reviewer questions the accuracy of Figure 1 and proposes an alternative approach by suggesting that zooming on the region of interest using bilinear sampling could provide better results. While the comment identifies a potential issue, it lacks specific evidence or references to fully substantiate the claim about the discrepancy. The suggestion for an alternative approach is logical but not directly supported by the comment. Therefore, the claim is somewhat verifiable, as it provides a basis for questioning but"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks technical novelty and suggests comparing it with two specific papers (Xing and Tsang, 2022a, b). It highlights that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects they should focus on to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to differentiate their work from the referenced papers but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks technical novelty and compares it to two specific papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper is being evaluated for novelty or how the co-attention mechanism and architecture are similar to the referenced papers. This makes it difficult for the authors to pinpoint the exact areas that need revision or improvement. The comment is weakly grounded because it does not specify the sections or elements being addressed, and it is not specific because it lacks detailed guidance on how to address the issue of limited technical novelty. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty by comparing it to two specific papers (Xing and Tsang, 2022a, b). The comment suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the referenced works. However, the comment does not provide specific details or examples from the referenced papers to support the claim of similarity. This makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a lack of technical novelty in the paper by comparing it to two specific papers (Xing and Tsang, 2022a, b). It highlights that the idea, co-attention mechanism, and architecture of the paper are similar to those in the referenced works. While the comment identifies a potential issue with the paper\\'s originality, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work. The feedback is somewhat helpful as it prompts the authors to consider the novelty of their work in relation to existing literature, but it lacks actionable advice for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of technical novelty in the paper by comparing it to two specific papers (Xing and Tsang, 2022a, b). It highlights that the idea, co-attention mechanism, and architecture of the paper are similar to those in the referenced works. However, the comment does not provide explicit guidance on how the authors should address this issue or differentiate their work from the referenced papers. The feedback lacks actionable steps or suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of technical novelty in the paper by comparing it to two specific papers (Xing and Tsang, 2022a, b). However, it does not specify which parts of the paper are being compared or how the co-attention mechanism and architecture are similar to the referenced works. This lack of detail makes it difficult for the authors to identify the exact areas needing improvement. The comment is weakly grounded because it does not specify the sections or elements being addressed, and it is not specific because it lacks detailed guidance on how to address the issue of limited technical novelty. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty by comparing it to two specific papers (Xing and Tsang, 2022a, b). The comment suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the referenced works. However, the comment does not provide specific details or examples from the referenced papers to support the claim of similarity. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation.', 'verifiability_label"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct a fair comparison by comparing CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF\\'s innovative pre-training module design. This feedback provides a clear and specific action for the authors to take, making it highly actionable. The comment is direct and provides concrete guidance on how to improve the fairness of the comparison, ensuring that the authors know exactly what changes to make to their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and specific lines (529-534), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lack of fairness in the comparison between CPEF and PMEF, and suggests a more fair comparison by recommending the inclusion of another pre-trained model, such as ExpertBert. This provides clear guidance on how to improve the fairness of the comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pre-training module. The reviewer suggests a more fair comparison by recommending the inclusion of another pre-trained model, such as ExpertBert. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a potential solution. However, it lacks specific examples or references to support the claim or demonstrate the advantage of ExpertBert. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison presented in Figure 3, where CPEF is compared with PMEF. It points out that PMEF lacks a pre-training module, which makes the comparison unfair. The comment provides a clear and actionable suggestion to ensure fairness by recommending the comparison of CPEF with another pre-trained model, such as ExpertBert. This feedback is highly helpful as it guides the authors on how to improve the fairness and validity of their comparisons, thereby enhancing the rigor and credibility of their work. The detailed and constructive nature of the feedback makes it highly beneficial for the authors to improve their draft.', 'helpfulness_label': '5'}"}
