{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests that the authors should compare their work to specific baseline models, namely Campos et al. (2020) and other domain adaptation methods cited in Section 8. Additionally, it points out a grammatical error in the text. These suggestions are clear and actionable, giving the authors specific guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, such as \\\"Line 277\\\" and \\\"Section 8,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the baseline models, including the lack of comparison to Campos et al. (2020) and other domain adaptation methods. Additionally, it points out a grammatical error. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the adopted baseline models are weak and suggests that the authors should compare their work to specific models, such as Campos et al. (2020) and other domain adaptation methods. The comment provides specific references to other works, which supports the claim by indicating the need for additional comparisons. However, the comment does not provide detailed reasoning or evidence to fully substantiate why these comparisons are necessary or how they would improve the paper. While the references are specific, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the baseline models used in the paper, suggesting that they are weak and lacking in comparison to relevant works. It specifically points out the absence of comparison to Campos et al. (2020) and other domain adaptation methods, which are cited in Section 8. Additionally, it highlights a grammatical error in the text. This feedback is clear and actionable, providing the authors with specific areas to address in order to improve the rigor and comprehensiveness of their work. By suggesting comparisons to relevant literature and correcting a grammatical error, the comment offers valuable guidance for enhancing the paper's quality. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests adding information about the input being word embeddings, similar to Lample et al., and clarifies the source language or language of the KNs in Figure 3. These instructions are clear and specific, giving the authors precise guidance on how to improve their draft. The mention of the authors' response to correct the figure indicates that the authors have already addressed this point, but the review still provides actionable feedback for the authors to consider. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 2.3\\\" and \\\"Figure 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the source language or language of the KNs in Figure 3. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should clarify the input used in their model, specifically mentioning that it might be beneficial to add information about using word embeddings, similar to Lample et al. The comment also questions the source language or language of the KNs in Figure 3, given that mentions have been translated to English. While the comment provides some guidance, it lacks detailed reasoning or references to support the suggestion about word embeddings. The mention of the authors' response to correct the figure indicates that the authors have already addressed this point, but the initial comment itself is somewhat verifiable due to the lack of comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by suggesting that the authors clarify the input used in their model, specifically mentioning the use of word embeddings, similar to Lample et al. Additionally, it questions the source language or language of the KNs in Figure 3, given that mentions have been translated to English. The comment also notes that the authors have already addressed this point in their response. This feedback is clear and constructive, guiding the authors on how to improve the clarity and completeness of their paper. However, it could be more helpful if it included additional suggestions or examples of how to present this information effectively. Overall, the comment is mostly helpful as it provides actionable guidance, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims need more analysis or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to perform more analysis but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to, nor does it provide details on what aspects of the analysis are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively identify the parts of the paper that need attention or improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not provide specific examples of which claims are lacking depth or how they could be improved. Without detailed reasoning or examples, the claim remains vague and lacks sufficient support, making it difficult for the authors to understand which aspects need more analysis. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not identify which claims are lacking depth or how the authors could enhance their analysis. Without detailed guidance or examples, the authors are left without clear direction on how to improve their draft. This lack of actionable feedback makes the comment barely helpful, as it points out an area for improvement but does not provide sufficient detail to guide the authors in making those improvements.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete actions for the authors to take. It asks for clarification on the pooling method used for embedding features, specifically referencing line 397. Additionally, it points out that Equation (7) in line 472 is unclear and requests clarification on whether E_i represents the type or identity of AC i, as well as its modeling. The comment also suggests that the left-hand side of the equation might be a conditional probability. These requests are clear and specific, giving the authors direct guidance on what needs to be clarified or defined in their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (397 and 472) and equations, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including whether E_i represents the type or identity of AC i and whether the left-hand side of the equation should be a conditional probability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises two specific concerns: the pooling method used for embedding features and the clarity of Equation (7). The reviewer questions the definition of E_i in Equation (7) and suggests that the left-hand side of the equation might be a conditional probability. While the comment identifies areas of potential confusion, it lacks detailed reasoning or references to support the claims. The authors would need to make an effort to understand and address these issues without additional context or explanation. Therefore, the comment is somewhat verifiable, as it provides some direction but requires more detailed justification to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two key areas of the paper's presentation: the pooling method used for embedding features and the clarity of Equation (7). It asks for clarification on the definition of E_i in Equation (7), whether it represents the type or identity of AC i, and suggests that the left-hand side of the equation might be a conditional probability. This feedback is clear and directs the authors to specific areas where improvements are needed, offering a concrete path for enhancing the clarity and precision of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing these issues. Overall, the comment is mostly helpful as it identifies critical areas for improvement and offers a clear direction for the authors to follow.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. While the action is explicit, it lacks concrete details on how to present this evidence or what specific aspects should be highlighted. The authors are given a clear direction to include empirical evidence but are left without detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests showing empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this contribution is located in, making it weakly grounded. The comment is specific in its request for empirical evidence, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should provide empirical evidence to support their claim about the proposed algorithm's effectiveness in the Column Subset Selection problem. However, the comment does not provide any specific reasoning, examples, or references to substantiate why this evidence is necessary or how it would strengthen the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include additional evidence to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on how to present this evidence or what aspects to focus on. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that more analysis and comments are needed on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The comment provides specific observations from Figure 3, such as the DeiT-B models not outperforming DeiT-T and DeiT-S on certain datasets, and suggests that CNNs might show more consistent improvements. However, while the comment identifies areas for further analysis, it does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis and determine the specific areas to address. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) and disagrees with the authors' viewpoint regarding the benefits of increased model capacity. The comment further specifies the discrepancies observed in the performance of DeiT models compared to CNNs on various datasets. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the authors' claim that both CNNs and ViTs benefit similarly from increased model capacity. It provides specific observations from Figure 3, noting that DeiT-B does not outperform DeiT-T and DeiT-S on certain datasets, while CNNs show more consistent improvements. This detailed analysis and comparison with specific datasets (APTOS2019, ISIC2019, and CheXpert) offers a robust basis for the claim, making it fully verifiable. The comment effectively supports its argument with precise data and comparisons, providing clear evidence for the authors to consider.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed analysis of the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3, offering specific observations and comparisons with CNNs. It challenges the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, pointing out discrepancies in the performance of DeiT models on certain datasets. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of their results and reconsider their claims. The comment is mostly helpful, as it not only identifies areas for improvement but also provides a specific example of how to address the issue, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. However, it does not provide specific guidance on how the authors could address this issue or differentiate their work from the cited works. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the novelty of their method. As a result, the comment is vague and unactionable, as it does not offer a clear path for the authors to follow. Therefore, it aligns with a score of 1.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It mentions specific works [1, 2, 3] and [4] that are relevant to the discussion. However, it does not specify which part of the paper should address these similarities or how the authors might differentiate their work. While the comment provides some context by referencing specific works, it lacks explicit references to sections or figures in the paper, making it weakly grounded. The comment is specific in its critique of the novelty and the similarity to existing methods but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. The reviewer supports this claim by referencing specific works [1, 2, 3] and [4], which are relevant to the discussion. However, the comment does not provide detailed comparisons or examples of how the proposed method differs from these existing works, which would strengthen the claim. The lack of explicit comparisons or detailed reasoning makes the claim somewhat verifiable, as the authors would need to further explore the references to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant concern regarding the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It highlights the lack of discussion on the group attention design and its relation to ResNeSt, which could impact the perceived originality of the work. While the comment points out a critical issue, it does not provide specific suggestions or guidance on how the authors might differentiate their method or address the concerns about novelty. This limits the comment's usefulness, as it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the call or what specific changes should be made to improve understanding. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment identifies a specific issue with the paper, namely the confusion surrounding the required implicit call to the Witness oracle. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the confusion, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the \\\"required implicit call to the Witness oracle is confusing.\\\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this call is confusing or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific issue with the paper, namely the confusion surrounding the required implicit call to the Witness oracle. This feedback highlights a potential area of confusion that the authors need to address to improve the clarity of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to clarify this aspect. Without actionable advice or examples, the authors may struggle to understand how to resolve the confusion. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in addressing it.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point questions the necessity of reproducing a well-known result using the authors' \\\"coarse\\\" methodology, given that similar observations have been made in previous steps of language model evolution. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their work. There is no guidance on whether the authors should consider alternative methodologies, provide additional analysis, or clarify the novelty of their approach. As a result, the comment lacks actionability, leaving the authors without direction on how to proceed. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the authors' approach by questioning the novelty of reproducing a well-known result about political bias in language models using a \\\"coarse\\\" methodology. It references the observation that language models reproduce biases from corpora, which has been noted in previous steps of model evolution. However, the comment does not specify which part of the paper this critique is based on, nor does it provide detailed guidance on how the authors might address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to act on this feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the authors' reproduction of a well-known result about political bias in language models using a \\\"coarse\\\" methodology is unnecessary, as similar observations have been made in previous steps of model evolution. The comment provides some reasoning by referencing the evolution of models from word2vec to BERT to ChatGPT, but it lacks specific examples or references to support the claim that the observation is not novel. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment questions the novelty of the authors' approach by pointing out that the observation about political bias in language models has been made in previous steps of model evolution. It suggests that the authors' methodology is not novel and questions the need to reproduce this observation again. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete actions for the authors to take. It suggests renaming a column in Table 1 to accurately reflect the training method used, and proposes a more detailed approach by specifying the data used to train different parts of each model. The comment clearly outlines the changes needed, such as renaming the column and creating two columns for 'Mixture training data' and 'Single source data.' This level of detail ensures that the authors know exactly what steps to take to improve their draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1\\\" and suggests renaming a column to \\\"Fully supervised\\\" from \\\"Supervised,\\\" providing a clear reference point for the authors. It also offers specific suggestions for improving clarity by specifying the data used to train different parts of each model and proposing two columns: \\\"Mixture training data\\\" and \\\"Single source data.\\\" This provides detailed guidance on how to enhance the paper's clarity. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should clarify the distinction between weak and semi-supervised training in their proposed method. It provides a specific example by mentioning Table 1 and suggesting a renaming of the column to \\\"Fully supervised\\\" from \\\"Supervised.\\\" Additionally, it proposes a more detailed approach by specifying the data used to train different parts of each model. While the comment provides a clear suggestion for improvement, it lacks detailed reasoning or references to support why this distinction is important or how it impacts the paper's conclusions. Therefore, the claim is somewhat verifiable, as it provides a logical suggestion but requires more detailed justification to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides clear and actionable feedback by identifying a specific area of confusion in the paper, namely the distinction between weak and semi-supervised training. It suggests renaming a column in Table 1 to accurately reflect the training method used, which is a straightforward and practical suggestion. Additionally, the comment proposes a more detailed approach by specifying the data used to train different parts of each model, suggesting two columns: 'Mixture training data' and 'Single source data.' This feedback is highly helpful as it offers concrete steps for the authors to improve the clarity and accuracy of their presentation, ensuring that readers can easily understand the methodology and its implications. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section, which only considers the CIFAR-10 dataset and does not include evaluations on other datasets from federated learning benchmarks. The reviewer explicitly suggests that the authors should consider additional datasets, such as those available in the LEAF benchmark, and references relevant works like FedProx and FedMAX for guidance on datasets and model types. This feedback provides a clear and concrete action for the authors to take, specifying which datasets to consider and offering references to help them expand their experimental evaluation. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experiments section\\\" and the \\\"CIFAR-10 dataset,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited scope of the experiments section, and suggests considering additional datasets from federated learning benchmarks like LEAF. The comment further provides references to relevant works (FedProx and FedMAX) for details on different datasets and model types. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the main weakness of the paper is the limited scope of the experiments section, which only considers the CIFAR-10 dataset and does not include evaluations on other datasets from federated learning benchmarks. The reviewer supports this claim by suggesting the inclusion of datasets from the LEAF benchmark and references relevant works like FedProx and FedMAX for guidance on datasets and model types. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more specific examples or detailed comparisons with the suggested datasets, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section, which only considers the CIFAR-10 dataset. It suggests that the authors should broaden their experimental evaluation to include other datasets from federated learning benchmarks, such as those available in the LEAF benchmark. Additionally, the comment provides references to relevant works (FedProx and FedMAX) that could guide the authors in selecting appropriate datasets and model types for their experiments. This feedback is clear, actionable, and offers specific suggestions for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should use a more convincing setting for their experiments, specifically by directly sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al., EMNLP 2018. This feedback provides a clear and explicit action for the authors to take, which is to adopt a different approach for handling unlabeled data. The suggestion is concrete, as it specifies a particular method to implement, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"preprocessed Amazon review dataset (Blitzer version)\\\" and the \\\"2000 unlabeled data,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of a more convincing setting for unlabeled data by directly sampling from millions of reviews, as done in a specific reference. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the use of unlabeled data from the Blitzer version of the Amazon review dataset is impractical in real-world applications due to its balanced nature. The reviewer suggests that a more convincing setting, as used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al., EMNLP 2018, should be adopted. This claim is supported by a reference to a specific paper, providing a logical basis for the suggestion. However, the comment could be strengthened by explaining why the balanced dataset is problematic or how the suggested approach would improve the study. Despite this, the reference to an external work makes the claim mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the use of unlabeled data from the Blitzer version of the Amazon review dataset, noting that it is perfectly balanced and impractical for real-world applications. It suggests that the authors should consider a more convincing setting, as demonstrated in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing a specific direction for the authors to enhance the practicality and relevance of their experimental setup. By referencing a relevant work, the comment offers a concrete example of how to improve the draft, making it highly helpful for the authors. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a confusing aspect of the description of the MFDA setting in the Method Section, specifically regarding the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The reviewer points out that the problem setting description differs from the original MFDA paper (Yue et al., 2021a) and questions the use of unlabeled data in source domains during training. While the comment highlights a specific issue, it does not provide explicit guidance on how to address it or clarify the notation. The authors are left to infer that they need to revise the description to align with the original paper and clarify the use of unlabeled data. The action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first paragraph of the Method Section,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the description of the MFDA setting, particularly the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The comment questions the discrepancy with the original MFDA paper (Yue et al., 2021a) and requests clarification on the use of unlabeled data during training. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the confusing description of the MFDA setting in the Method Section, specifically regarding the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) to highlight the discrepancy, which provides a basis for the claim. However, the comment lacks detailed reasoning or specific examples from the original paper to fully substantiate the claim. While the reference to the original paper adds some support, the comment could be strengthened with more explicit comparisons or detailed explanations. Therefore, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the description of the MFDA setting in the Method Section, noting that the notation for the target domain \\\\(\\\\tau\\\\) is unlabeled, which contrasts with the original MFDA paper (Yue et al., 2021a). It questions the use of unlabeled data in source domains during training and highlights the discrepancy between the current description and the original paper. This feedback is clear and actionable, as it directs the authors to clarify and align their description with the original work. By addressing this issue, the authors can improve the consistency and accuracy of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve the discrepancy or offered additional context from the original paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful revision.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights several issues with the paper, including the perceived immense workload, incremental contribution, and lack of citations for key baselines. It suggests that the authors should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment provides specific examples of missing citations and suggests what should be included, it does not explicitly instruct the authors to make these changes. The action is implicit but concrete, as the authors can infer that they need to address these issues by adding the suggested references and algorithms. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it refers to specific elements of the paper, such as the code and details in the article, and mentions specific works like GraphRAG, GraphCare, MedRetriever, and KGRAG. It provides clear guidance on what needs to be addressed, including the incremental contribution of the article, the lack of citations for key baselines, and the need to introduce essential RAG algorithms. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand the specific issues that need to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the contribution of the article is incremental and suggests that it is essentially a combination of GraphRAG and GraphCare. The reviewer also points out the lack of citations for key baselines and suggests specific algorithms that should have been included, such as MedRetriever and KGRAG. This claim is supported by logical reasoning and references to specific works, providing a clear basis for the critique. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from the suggested baselines. Overall, the claim is mostly verifiable due to the logical reasoning and references provided, but it could benefit from additional detail to fully substantiate the argument.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed critique of the paper, identifying several areas for improvement. It acknowledges the reviewer's observation about the immense workload but points out that the contribution is incremental. The comment also highlights the lack of citations for key baselines and suggests specific algorithms that should have been included, such as MedRetriever and KGRAG. This feedback is clear and actionable, offering the authors specific guidance on how to enhance the comprehensiveness and relevance of their work. By addressing these points, the authors can significantly improve the quality and impact of their paper. Therefore, the comment is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies missing state-of-the-art references in the face recognition experiment, specifically mentioning \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\\\"\\\" and its reported results. The reviewer provides specific details about the work's findings, such as the use of triplet loss and the achieved accuracy on the LFW dataset. This feedback is highly actionable because it directly instructs the authors to include these references and compare their results with those reported in the mentioned work. The explicit nature of the suggestion and the detailed information provided make it clear what the authors need to do to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experiment of face recognition\\\" and provides specific references, such as \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\\\"\\\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing references and compares the results with those reported in the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that certain state-of-the-art references are missing in the face recognition experiment, specifically mentioning \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\\\" The reviewer provides specific details about the work's findings, including the use of triplet loss and the reported accuracy on the LFW dataset, which is better than the results in Table 3 of the paper. This detailed comparison and reference to a specific work provide a robust basis for the claim, making it fully verifiable. The authors can clearly understand the basis of the critique and address it by incorporating the suggested references and comparisons.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the literature review by pointing out the absence of state-of-the-art references in the face recognition experiment. It provides a concrete example of a missing reference, \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\\\"\\\" and highlights its relevance to the paper's findings. The comment also references a specific result from the mentioned work, which is better than the result reported in Table 3 of the paper. This feedback is clear, actionable, and provides the authors with a specific reference to include in their work, which can enhance the comprehensiveness and credibility of their literature review. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to cite the source of the rock-paper-scissors example appropriately. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"rock-paper-scissors example,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the appropriate citation of the source of the example. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the rock-paper-scissors example is inspired by previous work and suggests that the authors should cite the source appropriately. However, the comment does not provide any specific references or examples of previous work that inspired the example, making it difficult for the authors to verify the claim or understand which sources should be cited. This lack of detailed justification results in the comment being classified as \\\"1: Unverifiable,\\\" as it does not provide sufficient evidence or reasoning to support the claim.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and advising the authors to cite the source appropriately. This feedback is clear and actionable, as it directly points out the need for proper attribution, which is crucial for academic integrity and originality. By addressing this comment, the authors can improve the credibility and scholarly rigor of their work. However, the comment could be more helpful if it provided specific examples of previous work that inspired the example or suggested where the authors might find these sources. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a specific observation about the method described in line 490, noting that it is common practice to average over subword representations, as exemplified by a reference. However, it does not offer any explicit or implicit suggestions for improvement or clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue or enhance their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions line 490, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that it is common practice to average over subword representations, as exemplified by a reference. This provides clear guidance on what aspect of the method is being critiqued. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes a claim that it is common practice to average over subword representations, as exemplified by a specific reference. This provides a clear and specific example to support the claim, making it fully verifiable. The reference to Hewitt and Manning (2019, footnote 4) offers a concrete basis for the claim, allowing the authors to understand and potentially address the issue. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides a specific observation about the method described in line 490, noting that it is common practice to average over subword representations, as exemplified by a reference. This feedback is valuable as it points out a potential oversight or area for improvement in the paper. However, the comment does not offer suggestions on how the authors might address this issue or improve their approach. While it identifies a specific point that could be clarified, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point summarizes the authors' efforts to validate the efficacy of CATER in different settings, such as architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this validation could be improved, expanded, or addressed further. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment provides a summary of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper this summary is based on, nor does it provide details on what aspects of the experiments are particularly effective or could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point is a factual statement summarizing the authors' efforts to validate the efficacy of CATER in various settings. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the authors' efforts in conducting comprehensive experiments to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not identify any specific weaknesses or areas for improvement in the experimental design or results. Without constructive feedback or suggestions for enhancing the analysis or presentation of the results, the comment provides limited value to the authors in terms of guiding them to improve their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two works that have extended these noise conditions, suggesting that the authors consider these extensions. However, the comment does not provide explicit guidance on how the authors should incorporate these references or extend their work. The action is implicit and somewhat vague, as the authors need to infer that they should consider these extensions but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment discusses the bounded noise assumption and references specific works that have extended these noise conditions in stochastic optimization literature. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where the bounded noise assumption is discussed. The authors might infer that it relates to the theoretical or methodological aspects of the paper, but this inference is not direct. The comment is specific in suggesting the need for better theory for SGD in the nonconvex world, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two specific works that have extended these noise conditions, providing a clear and precise justification for the claim. The inclusion of specific references to external works supports the claim, making it fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two specific works that have extended these noise conditions, suggesting that the authors consider these extensions. This feedback is somewhat helpful as it provides a direction for the authors to enhance their theoretical framework by referencing relevant literature. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these extensions or discussed their potential impact on the paper's findings. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the meaning of \\\"100 steps\\\" in the context of search models comparison. While it implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Search models comparison 5.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the meaning of \\\"100 steps\\\" in this context, asking whether it refers to 100 sampled strategies. This provides the authors with a clear understanding of what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the meaning of \\\"100 steps\\\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making \\\"No\\\" the correct label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about the meaning of \\\"100 steps\\\" in the context of search models comparison. This question highlights a potential area of confusion or lack of clarity in the paper, prompting the authors to provide a clearer explanation of their methodology. However, the comment does not offer any suggestions or guidance on how to address this issue, such as recommending a specific way to clarify the term or providing additional context. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to discuss the reasons why the proposed algorithm DMLCBO does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ as seen in previous works like SUSTAIN and MRBO. It also encourages the authors to explore the theoretical technique differences between DMLCBO and these works. This feedback provides a clear and specific action for the authors to take, including what aspects to focus on in their discussion. The explicit nature of the request and the detailed guidance on what to address make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and its reliance on the double momentum technique. It also references specific previous works, SUSTAIN and MRBO, which allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely, the reason why DMLCBO does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ and the theoretical technique differences between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed algorithm DMLCBO does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ as seen in previous works like SUSTAIN and MRBO. The reviewer supports this claim by referencing specific works and their convergence rates, providing a clear comparison. Additionally, the comment encourages the authors to discuss the theoretical differences between DMLCBO and these works, which adds depth to the justification. This detailed reasoning and reference to external works make the claim fully verifiable, as it provides a robust foundation for the critique. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the proposed algorithm DMLCBO, noting that it does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ as seen in previous works like SUSTAIN and MRBO. It encourages the authors to discuss the reasons behind this discrepancy and to explore the theoretical differences between DMLCBO and these works. This feedback is clear and actionable, as it provides a specific area for the authors to investigate and address in their paper. By prompting a discussion on the theoretical differences and the reasons for the performance gap, the comment offers valuable guidance for improving the draft. However, it could be more helpful if it suggested potential theoretical approaches or methodologies to bridge this gap. Overall, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a concern about the heuristic design of the modulator and the potential scalability issues that might arise from hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment lacks actionable details, such as recommending specific methods for improving scalability or suggesting alternative approaches to avoid hyperparameter tuning. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the design of the modulator and raises concerns about scalability issues and the need for hyperparameter tuning. However, it does not specify which part of the paper discusses the modulator or where these issues are mentioned, making it weakly grounded. The comment is specific in identifying the potential scalability issues and the need for hyperparameter tuning, providing some guidance on what might be problematic. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the modulator is heuristically designed and raises concerns about scalability issues and the need for tedious hyperparameter tuning. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or a clear explanation of how these issues arise, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the heuristic design of the modulator, specifically mentioning the scalability issues and the need for tedious hyperparameter tuning. This feedback is somewhat helpful as it highlights a critical area that the authors need to address, which is the scalability and robustness of their method. However, the comment lacks specific suggestions or guidance on how the authors might improve the modulator's design or address the scalability concerns. Without actionable advice or detailed insights, the authors are left with a general idea of the problem but no clear path to resolve it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should mention recent findings on untrained neural networks (NNs) that can solve inverse problems across a wide range of images, specifically referencing the work by Ulyanov et al. (CVPR 2018). It also implies that the authors should compare their current method with these approaches. While the comment provides a clear direction for improvement, it does not specify how to integrate this information into the paper or what specific comparisons should be made. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"OOD experiments\\\" and \\\"untrained NNs,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests mentioning recent findings on untrained NNs and comparing the current method with these approaches, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper should mention recent findings on untrained neural networks (NNs) that can solve inverse problems across a wide range of images, specifically referencing the work by Ulyanov et al. (CVPR 2018). This claim is somewhat verifiable as it provides a specific reference to an external work that supports the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how these untrained NNs relate to the current method's context. The inclusion of a specific reference to Ulyanov et al. (CVPR 2018) adds some credibility, but the lack of further elaboration on the relevance or comparison leaves room for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the interesting aspect of the OOD experiments and the strong generalization ability of the trained network. It suggests that the paper should mention recent findings on untrained neural networks (NNs) that can solve inverse problems across a wide range of images, specifically referencing the work by Ulyanov et al. (CVPR 2018). The comment provides a clear and actionable suggestion to place the current method in context and ideally compare it with these methods. This feedback is valuable as it guides the authors to enhance the paper's relevance and comprehensiveness by situating their work within the broader landscape of recent advancements in neural networks. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides concrete examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. The reviewer explicitly asks for clarification on these points, providing clear guidance on what needs to be addressed. This feedback is explicit and concrete, giving the authors a clear understanding of where and how to improve the clarity of their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. The comment clearly specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the first two sections of the paper are difficult to read due to unclear explanations of previous approaches. It provides specific examples, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. These examples offer a detailed critique of the explanation, making the claim mostly verifiable. However, the comment could be strengthened by providing more context or references to similar issues in other works, which would help the authors understand the basis of the critique more fully. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies specific areas where the paper's clarity is lacking, particularly in the first two sections. It provides detailed examples of unclear explanations, such as the conversion of a stacked LSTM to a sequential LSTM and the confusing sentences in lines 43 and 96. By pinpointing these specific issues, the comment offers clear and actionable feedback that can help the authors improve the clarity and readability of their draft. The detailed examples and specific questions guide the authors on where to focus their revisions, making this feedback highly helpful. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises concerns about the paper's goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. While the comment identifies areas for improvement, it lacks explicit instructions or concrete steps on how to address these concerns. The authors are left to infer that they need to include comparisons and justify their method against existing work, as well as clarify the foundation model claim and demonstrate future applications. The action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises concerns about the paper's goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. However, the comment does not specify which part of the paper these concerns pertain to, such as the introduction, methodology, or results sections. While the authors might infer that it relates to the discussion of the paper's contributions or the experimental results, the lack of explicit references makes it weakly grounded. The comment is specific in detailing what needs to be addressed regarding comparisons and justifications, but without clear grounding, it aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the paper's goal, specifically questioning the need for a comparison with existing DAS earthquake detectors like PhaseNet-Das. The reviewer acknowledges the existence of such detectors and suggests that a comparison or justification against them is necessary. However, the comment lacks specific references or detailed reasoning to support the claim that a comparison is needed. While it provides a logical basis for the suggestion, the absence of concrete examples or references makes the claim somewhat verifiable. The authors would need to further explore the suggestion to fully address the concern, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical concern regarding the paper's goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. This feedback is clear and actionable, as it provides specific areas for improvement, such as including comparisons and justifying the method's benefits against existing approaches. However, the comment could be more helpful if it offered suggestions on how to structure these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful, as it guides the authors toward enhancing the rigor and clarity of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR-10 models' robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should acknowledge these prior works, compare their results, or make any modifications to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR-10 models' robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. However, it does not specify which part of the paper these analyses are discussed in, nor does it provide detailed guidance on how the authors should address this feedback. The authors can infer that it relates to sections discussing robustness or adversarial training, but the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the need to acknowledge prior work and compare results, but without clear guidance on how to do so, it remains under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR-10 models' robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. The comment provides specific examples and references to support its claim, making it fully verifiable. The detailed references and examples allow the authors to understand the basis of the claim and how it relates to their work, ensuring that the authors can address the feedback effectively. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR-10 models' robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. It highlights that the results are not particularly surprising, which suggests that the authors may be overemphasizing the novelty of their findings. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or improve their work. It lacks actionable feedback or constructive advice, making it difficult for the authors to make meaningful improvements based on this comment alone. Therefore, the comment is not particularly helpful, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides specific feedback on two distinct issues. First, it critiques the accuracy of a statement in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to describe it as solely based on SGD. This feedback implies that the authors should revise this statement to reflect the actual methods used. Second, it points out a lack of clarity in Section 3, where the term \\\"it\\\" is used without a clear reference, which could lead to confusion. While the feedback is explicit in identifying areas for improvement, it lacks concrete guidance on how to address these issues, such as suggesting specific changes or references. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement the changes.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The review comment is fully grounded as it explicitly mentions specific sections of the paper, namely \\\"Page 2, second paragraph in Related Work\\\" and \\\"Section 3, first paragraph.\\\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it provides detailed feedback on the inaccuracies in the statements regarding the Walkman algorithm and the reference to \\\"it\\\" in Section 3. It suggests that the authors should revise their statements to accurately reflect the methods used and clarify the reference. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the accuracy of a statement in the Related Work section regarding the Walkman algorithm, suggesting that it is not solely based on SGD. The reviewer provides specific details about the two versions of the algorithm, one involving local optimization and the other involving gradient approximation, which supports the claim that the statement is inaccurate. Additionally, the comment points out a lack of clarity in Section 3, where the term \\\"it\\\" is used without a clear reference, making it difficult to understand. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claims. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two distinct issues. First, it challenges the accuracy of a statement in the Related Work section regarding the Walkman algorithm, pointing out that it is not solely based on SGD but involves two versions of solving optimization problems. This feedback encourages the authors to revise their statement for accuracy. Second, it highlights a lack of clarity in Section 3, where the term \\\"it\\\" is used without a clear reference, which could lead to confusion. The comment suggests that the authors should clarify this reference to improve the clarity of their writing. Overall, the feedback is mostly helpful as it identifies specific areas for improvement and provides clear guidance on how to address them, but it could be more comprehensive by offering suggestions on how to revise the statements. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It explicitly mentions that there are several works focusing on the same questions and provides examples of these works. This feedback is explicit and provides a clear action for the authors to take, which is to expand their experimental comparisons. However, it does not specify which additional baselines should be included or how to structure these comparisons. While the action is clear, the lack of detailed guidance on execution makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experimental section,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare the proposed method with more baselines, particularly those focusing on the same questions as mentioned in references [1, 2, 3]. This provides clear guidance on what additional experiments should be conducted. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method, as there are several works focusing on the same questions. The comment provides a specific example of works that should be considered, which adds some level of verifiability. However, it lacks detailed reasoning or references to these works, making it somewhat verifiable. The authors would benefit from more explicit guidance on which specific works to include and why they are relevant, thus justifying the need for additional comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the experimental section, noting that the authors only compared their method with two baselines. It suggests that there are other works focusing on the same questions and recommends adding more experimental comparisons to demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental section. However, it could be more helpful if it included suggestions on which additional baselines to consider or how to structure the new comparisons. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their experimental evaluation.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. This feedback provides a clear and direct action for the authors to take, specifying what additional information is required to improve the draft. The comment is specific and actionable, as it outlines the exact area needing more detail and how to address it. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"filtering process used to create the Arabic climate change QA dataset,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of details on the translation and filtering methodology required to assess the dataset quality. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that details about the filtering process used to create the Arabic climate change QA dataset are lacking, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. While the comment identifies a specific area where more information is required, it does not provide any supporting evidence or examples to substantiate the claim. The lack of detailed reasoning or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it highlights a potential gap but lacks sufficient justification or evidence.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the transparency and credibility of their dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of what kind of details are necessary. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a direction for the authors to enhance their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically focusing on long-context language models. It suggests discussing specific methods such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and provides concrete guidance on what the authors need to include to improve their draft. The explicit nature of the suggestion and the detailed list of methods to be discussed make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"Related Work section\\\" and the paragraph on \\\"long-context language models,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be included, such as discussing sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear direction on how to improve the section. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the Related Work section lacks details and suggests providing a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. The comment supports this claim by listing specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which should be discussed. This detailed list of methods provides a robust foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by providing references or examples of how these methods have been applied, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it provides specific and actionable feedback on the Related Work section. It identifies a clear gap in the current draft, noting that the section lacks details and a comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. The comment suggests specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, that should be discussed. This detailed guidance empowers the authors to significantly improve their draft by expanding the Related Work section with relevant and important information. The comment is clear, precise, and provides a clear path for enhancing the paper, making it highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which points are unclear or provide guidance on how to improve the writing. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what specific changes are needed to enhance clarity. As a result, the comment is vague and lacks actionable details, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which points or sections are unclear, making it difficult for the authors to identify the exact areas that need revision. Additionally, the comment lacks specificity regarding what aspects of the writing are unclear or how they could be improved. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"the writing should be improved\\\" and that \\\"some points in the paper are unclear.\\\" However, it does not provide any specific examples or detailed reasoning to support these claims. Without concrete examples or explanations of which points are unclear, the authors may find it challenging to understand and address the issues. Therefore, the comment lacks verifiability and is rated as \\\"1: Unverifiable.\\\"\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it lacks specificity and does not provide any guidance or examples on which points are unclear or how the writing could be improved. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative explanations or modifications to the experiment. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"synthetic experiment in a non-separable case\\\" and refers to \\\"Figure 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the inseparability of the data distribution from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what aspect of the experiment is problematic and what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This feedback highlights a potential issue with the experimental setup or interpretation, prompting the authors to reconsider their approach or provide a clearer explanation. However, the comment lacks specific suggestions or guidance on how to address this concern, such as proposing alternative explanations or modifications to the experiment. While it identifies a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a concern about the efficiency of pairwise matching, noting that it is difficult to be used in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance efficiency. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the efficiency of pairwise matching, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the problem of low efficiency and its impact on practical applications, providing some guidance on what the authors might need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the efficiency of pairwise matching, noting that it is difficult to be used in practical application systems. This is a relevant observation that could impact the applicability and usability of the method described in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable feedback or detailed advice, the authors are left with only a general understanding of the problem but no clear path to resolve it. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this addition should be implemented, what specific improvements are expected, or how the authors can demonstrate the significance of their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what aspects of the method or contribution are being questioned. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks any supporting evidence, reasoning, or references to justify why this addition is not considered a significant contribution. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their contribution. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests toning down a specific statement about the neural network memorizing critical points, which is a clear and actionable recommendation. Additionally, it advises compressing the method section to focus on essential definitions, which is another concrete suggestion. The comment also mentions the need to double-check for grammatical errors, particularly with plurals and articles, providing a specific area for improvement. Each of these points is clear and actionable, giving the authors direct guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific phrase \\\"to force the neural network to memorize them\\\" and references a particular work, [24], which helps the authors identify the context of the critique. It also provides specific feedback on the method section, suggesting that it could be compressed and that there are grammatical errors to be checked. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the statement \\\"to force the neural network to memorize them\\\" is overstated, referencing TopoNet [24] as evidence. However, the comment does not provide specific details or examples from TopoNet to support this claim, making it difficult for the authors to fully understand the basis of the critique. Additionally, the comment mentions grammatical errors but does not specify which ones, further limiting its verifiability. Therefore, the claim is somewhat verifiable, as it provides a general critique but lacks detailed justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper. It suggests toning down a particular statement about the neural network memorizing critical points, referencing a specific work [24] to support this suggestion. This is a clear and constructive critique that can help the authors refine their language and improve the accuracy of their claims. Additionally, the comment points out that the method section is wordy and suggests compressing it to focus on essential definitions, offering a practical suggestion for streamlining the paper. The comment also identifies grammatical errors, particularly with plurals and articles, which is a valuable piece of feedback for improving the paper's clarity and professionalism. Overall, the comment is highly helpful as it provides detailed and actionable advice that can significantly enhance the quality and clarity of the draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point critiques the claim of parameter efficiency for COCO-LM by suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It raises a question about the experimental setup, specifically why the authors switched the types of BPE vocabulary (uncased and cased) and whether this change affects the variance of performance. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need to address these questions and may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the comparison with Megatron and COCO-LM, suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency and asks for clarification on the experimental setup, specifically regarding the switch in BPE vocabulary types. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its critique and questions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides examples of these related works to support the claim, which helps in understanding the context and validity of the critique. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies that demonstrate the similarity in performance. As it stands, the claim is mostly verifiable due to the inclusion of examples, but it lacks comprehensive evidence or detailed reasoning, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment critiques the claim of parameter efficiency for COCO-LM by suggesting that its performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the validity of the claim, which is a relevant point for the authors to address. The comment also raises a question about the experimental setup, specifically regarding the switch in BPE vocabulary types and its potential impact on performance variance. This feedback is somewhat helpful as it prompts the authors to reconsider their claims and provides a specific area for further exploration. However, it could be more helpful if it offered suggestions on how to address these concerns or provided additional context for the comparison. Overall, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the analysis from line 128 to 149, noting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, explaining that the GS-P-50 model has smaller class selectivity scores, implying that GS-P-50 shares more features while ResNet-50 learns more class-specific features. The reviewer also references two external works that could provide additional context or support for the analysis. While the comment highlights areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more convincing explanation and potentially reference the provided works. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the analysis, explaining the observation about the GS-P-50 model having smaller class selectivity scores and its implications for feature sharing and representation learning. The comment further references external works, which can guide the authors in understanding and potentially addressing the critique. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. The reviewer provides specific observations from the histogram in Fig 3, explaining that the GS-P-50 model has smaller class selectivity scores, implying that GS-P-50 shares more features while ResNet-50 learns more class-specific features. The reviewer further supports this claim by referencing external works that could provide additional context or support for the analysis. This detailed explanation and reference to external sources make the claim mostly verifiable, as it provides a solid foundation for the critique. However, the comment could be further strengthened by including more specific examples or detailed reasoning from the referenced works. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from line 128 to 149 is not convincing enough. It provides a detailed explanation of the observation, stating that the GS-P-50 model has smaller class selectivity scores, which implies that GS-P-50 shares more features while ResNet-50 learns more class-specific features. The reviewer further hypothesizes that additional context may allow the network to reduce its dependency and references external works that could provide additional context or support for the analysis. This feedback is clear and actionable, as it guides the authors to reconsider and strengthen their analysis by providing a more convincing explanation and potentially referencing relevant literature. However, the comment could be more helpful if it offered specific suggestions on how to improve the analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward enhancing the robustness of their analysis.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises concerns about the conclusions drawn in the paper, specifically questioning the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might stem from limited exploration of combination methods and provides references to recent works that employ feature-replay methods, such as [R1] and [R2], as well as a more recent work [R3]. However, the comment does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve their conclusions or explore alternative methods. The action is implicit and somewhat vague, as the authors need to infer that they should consider the suggestions and references provided. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific conclusion in the paper, allowing the authors to identify the part of the paper being addressed. It also provides specific examples of recent works that employ feature-replay methods, such as [R1] and [R2], and a more recent work [R3], which helps the authors understand the context and potential improvements. This level of detail provides clear guidance on what needs to be addressed or improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the conclusions drawn in the paper, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works, such as [R1] and [R2], which employ feature-replay methods and have shown great potential in continual learning and category discovery, respectively. Additionally, the reviewer mentions a more recent work [R3] that also employs feature replay to continually adjust the feature space. This provides a robust foundation for the claim, making it fully verifiable. The inclusion of specific references and examples strengthens the argument, allowing the authors to understand and address the critique effectively.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific concern regarding the conclusions drawn in the paper, particularly the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It provides a detailed critique by suggesting that the results might stem from limited exploration of combination methods. The comment further supports its point by referencing recent works, such as [R1] and [R2], which employ feature-replay methods and have shown great potential in continual learning and category discovery, respectively. Additionally, it mentions a more recent work [R3] that also uses feature replay to continually adjust the feature space. This feedback is mostly helpful as it not only identifies a weakness in the paper but also offers specific references and examples of alternative approaches that could be considered. However, it could be more helpful if it provided actionable suggestions on how to address the identified issue or how to incorporate the referenced works into the paper. Overall, the comment provides valuable insights and direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not provide any specific guidance or suggestions on how the authors should address this observation or what actions they should take to mitigate any potential issues. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to apply this information to improve their draft. Since the action is implicit and vague, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how to address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the observation or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular areas where this dependence might be an issue or offering guidance on how to address it, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the paper's novelty is limited, as it appears to be a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It acknowledges that the paper transposes DeCorr's insights into graph collaborative filtering but notes that it lacks sufficient insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance or suggestions on how the authors could enhance the novelty or address the identified gaps. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the paper's novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It mentions the transposition of DeCorr's insights into graph collaborative filtering and acknowledges modifications like different penalty coefficients for users and items. However, the comment does not specify which sections or parts of the paper are being addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. While the comment provides some context about the paper's content, it lacks grounding as it does not direct the authors to specific sections or issues. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.\",\n    \"grounding_specificity_label\": \"2\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, to a specific application domain. The reviewer supports this claim by mentioning that the paper transposes DeCorr's insights into graph collaborative filtering and acknowledges modifications like different penalty coefficients for users and items. However, the comment does not provide specific examples or detailed reasoning to substantiate the claim of limited novelty. The lack of explicit references or detailed explanations makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as somewhat verifiable, as it provides some support but lacks comprehensive evidence or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a lack of novelty in the paper, suggesting that it appears to be a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It acknowledges the paper's contribution as the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones, and mentions modifications like different penalty coefficients for users and items. However, the comment notes that the paper lacks sufficient insights into the unique challenges of overcorrelation in recommender systems. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their work. This limits the comment's usefulness, making it somewhat helpful as it points out an area for improvement but lacks actionable feedback.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific issues with Section 4.2, particularly the mismatch between the description and the equation, and the unclear meaning of \\u03c3 in the equation. It explicitly asks for clarification on how the question is used to learn an attention on the image feature and suggests that the authors should clarify the equation and the meaning of \\u03c3. The comment provides concrete actions for the authors to take, such as clarifying the description and the equation, and questioning the use of sigmoid activations. This level of detail gives the authors clear guidance on how to improve their draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Sec. 4.2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in Section 4.2, pointing out the lack of a term for r^q and the unclear meaning of \\u03c3. The comment further suggests clarifying the use of the question in learning attention and questions the potential numerical instability due to the use of sigmoid activations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the clarity of the methodology in Section 4.2, specifically questioning how the question is used to learn an attention on the image feature. The reviewer points out a mismatch between the description and the equation, noting the absence of a term for r^q and the unclear meaning of \\u03c3 in the equation. The comment suggests that the use of sigmoid activations might be ill-conditioned and numerically unstable. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claims about the mismatch and potential instability. This makes the claim somewhat verifiable, as the authors would need to further investigate and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it identifies specific issues with the clarity and consistency of the methodology described in Section 4.2. It points out a mismatch between the description and the equation, specifically mentioning the absence of a term for r^q and the unclear meaning of \\u03c3 in the equation. The comment also questions the potential numerical instability due to the use of sigmoid activations. By highlighting these areas of confusion, the reviewer provides clear and actionable feedback that can help the authors improve the clarity and accuracy of their manuscript. The detailed nature of the feedback ensures that the authors know exactly what needs to be clarified or corrected, making this comment highly beneficial for enhancing the draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or enhance the novelty of their work. There is no guidance on potential improvements, alternative approaches, or additional contributions that could be made to strengthen the paper's novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. However, it does not specify which sections or parts of the paper these aspects are discussed in, making it weakly grounded. The comment does specify the issue of limited novelty and the incremental contribution, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. This claim is somewhat verifiable as it provides a reference to an existing work ([10]) and highlights the incremental nature of the contribution. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the decomposition part is novel or how it differs from existing methods. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment points out a perceived limitation in the novelty of the paper, specifically noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. While this feedback identifies a potential weakness in the paper's originality, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The comment lacks actionable advice or constructive feedback, leaving the authors with only a general understanding of the problem without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It concludes that this reduction in whitespace effectively violates the 9-page paper limit, justifying rejection. The comment provides a clear and direct action for the authors to take, which is to address the whitespace issue to comply with the page limit. The feedback is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, specifically pointing out that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the layout and how it violates the 9-page paper limit. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This reduction in whitespace is presented as a violation of the 9-page paper limit. However, the comment does not provide specific examples or detailed reasoning to support the claim of whitespace reduction or how it affects the layout. Without such evidence or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the layout of the paper, noting that the authors have reduced whitespace, causing equations to be crammed together and captions to be too close to the figures. This observation is significant as it directly relates to the paper's adherence to the 9-page limit. By highlighting this issue, the comment provides clear and actionable feedback that can help the authors make necessary adjustments to improve the readability and formatting of their paper. However, the comment could be more helpful if it offered suggestions on how to address the whitespace issue or provided examples of better layout practices. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the technical details and formulations are limited and suggests that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance on what aspects are lacking or how the authors could enhance the technical details and formulations. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the feedback. Since the action is implicit and vague, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the technical details and formulations are limited and that the main novelty lies in the scheme or procedure. However, it does not specify which sections or parts of the paper are lacking in detail or novelty. Without explicit references to specific sections, figures, or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"technical details and formulations are limited\\\" and suggests that the main novelty lies in the scheme or procedure. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out that the technical details and formulations in the paper are limited, suggesting that the main novelty lies in the scheme or procedure. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the technical details or formulations. Without concrete guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a significant risk associated with methods that exploit relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, such as AU6 occurring in both pain and happiness expressions, and illustrates how this difference can be observed in Figure 1. The reviewer suggests that cross-dataset experiments would be a good way to test the generalization of such work, noting that the paper lacks this. The comment provides a clear and explicit action for the authors to take\\u2014conducting cross-dataset experiments\\u2014and offers a concrete example of how to implement it. This level of detail makes the comment highly actionable, as it gives the authors a clear path to improve their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of differing relationships between action units across datasets and suggests a solution by performing cross-dataset experiments. The comment provides a clear example of how the relationships can vary and how this affects the generalization of the work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the risk of methods exploiting relationships between action units, noting that these relationships can vary significantly across datasets. The reviewer provides a specific example, such as AU6 occurring in both pain and happiness expressions, and illustrates how this difference can be observed in Figure 1. The suggestion to perform cross-dataset experiments is a logical recommendation to test the generalization of the work. This claim is mostly verifiable as it provides a clear example and reasoning, but it could be strengthened with more detailed references or examples from the literature. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, such as AU6 occurring in both pain and happiness expressions, and illustrates how this difference can be observed in Figure 1. The comment suggests a practical solution by recommending cross-dataset experiments to test the generalization of the work, which is a valuable and actionable piece of feedback. This guidance empowers the authors to address a critical issue in their methodology and improve the robustness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the statement regarding over-parameterization and its impact on performance, suggesting that over-parameterization can be beneficial in practice. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or incorporate additional information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 47 - 48,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement about over-parameterization and its impact on performance, suggesting that over-parameterization can be beneficial in practice. Additionally, the comment references theoretical work showing the benefits of over-parameterization, providing a specific context for the critique. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the statement that \\\"over-parameterization invariably overfits the data and results in worse performance.\\\" It counters this claim by suggesting that over-parameterization can be beneficial in practice and references theoretical work that supports its benefits. This provides a counter-argument and supports the reviewer's claim with logical reasoning and references to theoretical work, making the comment fully verifiable. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment challenges a statement in the paper regarding over-parameterization and its impact on performance. It points out that over-parameterization can be beneficial in practice and references theoretical work that supports its benefits. This feedback is valuable as it encourages the authors to reconsider their statement and potentially revise it to align with more accurate understanding and evidence. However, the comment could be more helpful if it provided specific suggestions on how to revise the statement or incorporated the referenced theoretical work into the paper. Overall, the comment is somewhat helpful as it identifies a potential issue and provides some direction for improvement, but it lacks detailed guidance for the authors.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that if the compared methods were not initialized with the same pre-trained model, the proposed method's performance without SSL might be inferior. However, the comment does not provide explicit guidance on how the authors should address this issue, such as recommending a specific approach to ensure fair comparisons or suggesting additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust their experimental setup. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the experimental comparison with other methods, specifically questioning the fairness of the comparison due to the proposed method's pre-training before fine-tuning. It references Table 1 to support the claim that the proposed method without SSL performs inferior to most compared methods. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the experimental results or comparisons section. Therefore, the comment is weakly grounded but specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. The comment provides a logical reasoning by referencing Table 1, which shows that the proposed method without SSL performs inferior to most compared methods. This reference to a specific table provides some support for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or examples of how the initialization of the compared methods might differ. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It highlights a potential issue with the proposed method's performance without SSL, suggesting that the comparison might be unfair. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue, such as recommending a standardized initialization or additional experiments to ensure a fair comparison. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point acknowledges the use of \\\"attribute\\\" as meta-data for zero-shot learning on the CUB dataset, which is considered fair for comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing a specific paper. The reviewer also acknowledges the authors' response and concludes that the paper is acceptable for NIPS. The comment provides a clear and explicit action for the authors to consider, specifically testing their method with better meta-data embeddings, and references a relevant paper for guidance. This makes the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3 page 7\\\" and the \\\"CUB dataset,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the performance of the proposed method with better meta-data embeddings, referencing a specific paper for guidance. This provides clear guidance on what needs to be addressed or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that while the use of \\\"attribute\\\" as meta-data is fair for comparison, better meta-data embeddings options are available. It references a specific paper, \\\"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\\\" to support the claim that better embeddings could improve performance. This reference provides a solid foundation for the suggestion, making the claim mostly verifiable. However, the comment could be further strengthened by providing more detailed examples or comparisons from the referenced paper. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the use of \\\"attribute\\\" as meta-data for zero-shot learning on the CUB dataset, which is considered fair for comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing a specific paper for guidance. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work by considering alternative meta-data embeddings. The comment also acknowledges the authors' response and concludes that the paper is acceptable for NIPS, indicating that the feedback has been addressed. This level of detail and constructive suggestion makes the comment highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a specific area in the paper where relevant literature on using moment matching for distributional reinforcement learning (DRL) is lacking. It suggests that this should be discussed when talking about various approaches to DRL, even though the paper currently uses quantile regression. The comment provides a clear and concrete action for the authors to take, which is to include a discussion of the mentioned literature. This guidance is specific and actionable, as it gives the authors a clear direction on how to enhance their draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific paragraph from lines 22-30, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of relevant literature on using moment matching for distributional reinforcement learning (DRL) and suggests discussing this in the context of various approaches to DRL. The comment provides a specific reference to external work (Nguyen-Tang et al AAAI\u201921) and suggests that this should be included in the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing Nguyen-Tang et al. (AAAI\u201921) as an example. This claim is supported by providing a specific reference to external work, which helps substantiate the assertion. However, the comment could be strengthened by explaining how this literature is relevant to the paper's discussion on various approaches to DRL. Despite this, the inclusion of a specific reference makes the claim mostly verifiable, as it provides a clear basis for the critique. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the paper's literature review regarding the use of moment matching for distributional reinforcement learning (DRL). It points out the absence of relevant literature, such as the work by Nguyen-Tang et al. (AAAI\u201921), which discusses moment matching in DRL. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the paper currently uses quantile regression. This feedback is clear and actionable, as it provides a specific reference and guidance on how to enhance the paper's literature review and discussion of DRL approaches. By addressing this point, the authors can improve the comprehensiveness and depth of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point criticizes the novelty of the paper, stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance the originality of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the novelty of the paper by stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the approach are considered lacking in novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, references, or detailed explanation to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a perceived limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper's results. It suggests that the assumptions underlying the use of PCA might not be well-met and asks for clarification on this aspect. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve the paper. The feedback is somewhat vague, as it lacks concrete suggestions for enhancing the paper's novelty or significance. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed instructions on how to achieve it.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the novelty of using PCA to reduce the interaction count and questions the significance of the paper's results. It provides a specific reference to a paper by Dombrowski et al. (2022) that discusses robust explanations for deep neural networks, which could be relevant to the discussion. However, the comment does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper's results. The reviewer provides a reference to a paper by Dombrowski et al. (2022) that discusses robust explanations for deep neural networks, which could be relevant to the discussion. However, the comment lacks a detailed explanation or specific examples from the referenced work that would substantiate the claim about the assumptions being met. While the reference provides some context, the comment could be strengthened with more explicit reasoning or examples to fully support the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some support but requires further elaboration to be fully verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper's results. It suggests that the assumptions underlying the use of PCA might not be well-met and asks for clarification on this aspect. The comment also references a relevant work by Dombrowski et al. (2022) that could provide context for the discussion. While the comment identifies a potential weakness in the paper's approach and provides a reference for further exploration, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is somewhat helpful as it prompts the authors to consider the assumptions and significance of their approach, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. The reviewer expresses reservations about the method's broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models remains uncertain. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or expand the framework. The feedback lacks concrete steps or actionable advice, leaving the authors uncertain about how to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the evaluative framework, specifically mentioning the limitation in scope due to the restriction to three Question-Answering tasks and two language models. It raises concerns about the method's broader applicability and suggests considering more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The comment is specific in detailing the limitations and potential areas for improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the evaluative framework is limited in scope, restricted to only three Question-Answering tasks and two language models. The reviewer expresses reservations about the method's broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. The suggestion to consider more advanced models like vicunna or alpaca adds some depth but still requires more detailed justification. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive evidence or references.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method's broader applicability and its potential to generalize to other reasoning or generation tasks or more advanced models. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the framework's scope. The feedback provides some insight into the issue but does not offer actionable steps for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity in its guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that Figure 6C is awkward because it implies negative rates, which is not the case. The reviewer provides a specific suggestion to use a second y-axis or another visualization that is more physically accurate. This feedback is explicit and provides concrete guidance on how to improve the figure, making it highly actionable. The authors know exactly what changes to make to address the issue.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 6C,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The suggestion to use a second y-axis or another visualization is a clear and actionable recommendation for improvement. Therefore, this comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that Figure 6C is awkward because it implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization for better clarity. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use a second y-axis or another visualization is logical, but the comment could be strengthened with more detailed justification or examples of how the current figure misrepresents the data. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional detail to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. The reviewer provides a clear and actionable suggestion to use a second y-axis or another visualization that is more physically accurate. This feedback is precise and offers a concrete way for the authors to improve the clarity and accuracy of their figure, making it highly helpful. The comment provides valuable guidance that can significantly enhance the presentation of the results in the paper.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that there is still room to improve the complexity of Algorithm 2, but it does not provide specific guidance or suggestions on how to achieve this improvement. The comment lacks explicit instructions or concrete details on what aspects of the algorithm's complexity could be enhanced or how the authors might address this issue. As a result, the authors are left without a clear understanding of what steps to take to improve the complexity of the algorithm. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that there is still room to improve the complexity of Algorithm 2, but it does not specify which part of the paper this refers to or provide details on what aspects of the algorithm's complexity could be improved. Without explicit references to sections, figures, or specific elements of Algorithm 2, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that there is still room to improve the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that there is still room to improve the complexity of Algorithm 2, but it lacks specificity and actionable guidance. It does not provide details on what aspects of the algorithm's complexity could be improved or how the authors might address this issue. Without specific suggestions or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions a statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for the LM compared to the GAN model is questionable. The reviewer provides an example from Zaremba et al. (2014) to challenge the statement. Additionally, the reviewer asks whether dropout is applied to the hidden states, implying that this information is missing or unclear in the paper. The comment provides a clear action for the authors to take, which is to verify and clarify the statement in D.4 and provide additional details about the regularization methods used. The feedback is explicit and concrete, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"supplemental section D.4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about smaller architectures being necessary for the LM compared to the GAN model, providing a counterexample from Zaremba et al. (2014) and asking for clarification on whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions a statement in the supplemental section D.4, suggesting that smaller architectures are necessary for the LM compared to the GAN model to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) to challenge this claim, indicating that the baseline models may not be properly regularized. The comment also asks whether dropout is applied to the hidden states, implying a need for clarification. This critique is mostly verifiable as it provides a specific counterexample and a request for clarification, allowing the authors to address the issue. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment questions a statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for the LM compared to the GAN model is questionable. It provides a counterexample from Zaremba et al. (2014) to challenge the statement, indicating that the baseline models may not be properly regularized. The comment also asks whether dropout is applied to the hidden states, implying a need for clarification in the paper. This feedback is mostly helpful as it identifies a potential issue with the paper's claims and encourages the authors to provide additional details or clarification. However, it could be more helpful if it offered specific suggestions on how to address the issue or improve the explanation. Overall, the comment provides valuable insights and direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. While it provides a general direction for improvement, it lacks specific guidance on how to make the introduction more concise or what specific empirical results should be included. The action is implicit and vague, leaving the authors with a general idea of what needs to be improved but without concrete steps to follow. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which sections or parts of the introduction need to be revised, making it difficult for the authors to pinpoint the exact areas that require improvement. Additionally, the comment lacks specificity regarding what aspects of the introduction should be made more concise or what empirical results should be included. This lack of detail and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how to achieve this conciseness or what specific empirical results should be included. Without actionable suggestions or examples, the authors may struggle to understand the exact changes needed to improve their draft. Therefore, the comment is barely helpful, as it points out a general area for improvement but does not offer sufficient detail to be fully actionable.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment states that the technical contribution is unclear and that most of the analysis is quite standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or improve the analysis. The feedback lacks actionable details, such as recommending ways to enhance the technical contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are being referred to or provide details on what aspects of the analysis are considered standard. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"the technical contribution is unclear\\\" and that \\\"most of the analysis are quite standard.\\\" However, it does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or justification, the authors may find it difficult to understand and address the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a lack of clarity in the technical contribution of the paper and suggests that most of the analysis is standard. However, it does not provide specific details or examples to help the authors understand what aspects of the analysis are considered standard or how they could enhance the technical contribution. Without actionable feedback or constructive suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should reproduce the main features of previous models to ensure a fair comparison. It implies that the current approach of applying regularization to both LN models and GLMs might not be the most appropriate way to compare the models. However, the comment does not provide explicit instructions on how to reproduce the main features of previous models or which specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the issue of regularization applied to both LN models and GLMs, suggesting that the comparison might not be fair. It references the work of pillow et al. and mentions specific features like L1 regularization and low rank approximation, providing a clear direction for the authors to consider. However, the comment does not explicitly mention which part of the paper discusses the regularization or the models, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed regarding the comparison and the features of previous models. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the fairness of the comparison between the LN model and the GLM by noting that the GLM presented by pillow et al. did not use cropping but instead employed L1 regularization and a low-rank approximation. The reviewer suggests that reproducing the main features of previous models would make the comparison fairer. This claim is somewhat verifiable as it references specific features of a previous model and suggests a potential adjustment to the current approach. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, requiring the authors to infer the details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the methodology, specifically the application of regularization to both LN models and GLMs, which may not be fair for comparison. It references the work of pillow et al. to highlight a discrepancy in the features used in previous models. The comment suggests that reproducing the main features of previous models would make the comparison fairer. While the feedback is clear in pointing out a potential flaw in the experimental setup, it lacks specific guidance on how to address this issue or what features should be reproduced. This limits the comment's helpfulness, as the authors are informed of a problem but not provided with detailed, actionable steps to resolve it. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should include some failure cases and related discussion in their paper. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which specific failure cases to discuss or how to structure the discussion. The authors are given a clear direction but are left without detailed guidance on execution. Therefore, the comment is somewhat actionable, as it provides an explicit action but lacks concrete details on how to execute it.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this suggestion pertains to. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in terms of what it suggests\\u2014including failure cases and discussion\\u2014but lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests including some failure cases and related discussion, but it does not provide any specific reasoning or examples to support why this would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of including failure cases and how it would improve the paper. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests including some failure cases and related discussion in the paper. This feedback is somewhat helpful as it provides a clear direction for improvement, indicating that the authors should consider presenting scenarios where their method or findings fail and discussing these cases. However, the comment lacks depth and does not provide specific guidance on how to incorporate these failure cases or what aspects to focus on in the discussion. While it offers a general suggestion, it does not fully support the authors in making the improvements, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the introduction of \\\\(\\\\epsilon\\\\) should be clarified when discussing equation (11), as it is not used in equation (10). This feedback provides a clear and explicit action for the authors to take, which is to introduce \\\\(\\\\epsilon\\\\) when discussing equation (11). The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the section. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 4.1\\\" and \\\"equation (10)\\\" and \\\"equation (11),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of \\\\(\\\\epsilon\\\\) when discussing equation (11). This provides clear guidance on how to improve the clarity of the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the introduction of \\\\(\\\\epsilon\\\\) should be clarified when discussing equation (11), as it is not used in equation (10). This claim is based on a logical reasoning that the introduction of a variable should be consistent and clear throughout the paper. However, the comment does not provide specific examples or detailed reasoning to support why this clarification is necessary, making it somewhat verifiable. The authors would need to infer the importance of this clarification themselves, which limits the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the variable \\\\(\\\\epsilon\\\\) is not used in equation (10) but is introduced in equation (11), suggesting that introducing \\\\(\\\\epsilon\\\\) when discussing equation (11) would enhance clarity. This feedback is clear and directly addresses a potential issue with the presentation of the equations, offering a concrete step for the authors to take to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the claim about evolutional dropout addressing internal covariate shift is limited, specifically noting that it can only increase the variance of some low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. While the comment provides a clear direction for the authors to address the limitations of the claim, it does not offer specific guidance on how to incorporate this discussion into the paper. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment critiques the claim about evolutional dropout addressing internal covariate shift, suggesting that it can only increase the variance of some low-variance units. It also mentions Batch Normalization as a method that standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggesting a discussion on these limitations. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, specifically stating that it can only increase the variance of some low-variance units. The reviewer supports this claim by contrasting it with Batch Normalization, which standardizes variance and centers activation. This comparison provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific limitation in the claim about evolutional dropout addressing internal covariate shift, noting that it can only increase the variance of some low-variance units. It suggests that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, as it provides a specific area for improvement by highlighting a potential weakness in the paper's claims and suggesting a way to address it. However, the comment could be more helpful if it offered additional guidance on how to effectively discuss these limitations or provided examples of how to present this information. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification and improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to add more description about the contribution of their paper. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not provide specific guidance on what aspects of the contribution should be elaborated upon or how to effectively present this information. While the action is explicit, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the authors should add more description about the contribution of their paper. However, it does not specify which part of the paper this description should be added to or which aspects of the contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need additional description. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should add more description about the contribution of their paper. However, it does not provide any specific reasoning, examples, or references to support why this addition is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that the authors should add more description about the contribution of their paper. While it identifies a specific area for improvement, it lacks depth and does not provide detailed guidance or examples on what aspects of the contribution should be elaborated upon. This limits the utility of the feedback, as the authors are left with a general suggestion without actionable steps to enhance their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that in section 4, \\\"X\\\" should be a multiset instead of a set, as it is necessary to include the multiplicities of labels in the graph to accurately represent repeated vertex or edge labels. This feedback provides a clear and explicit action for the authors to take, specifying the change needed to improve the accuracy of their representation. The suggestion is concrete, as it outlines exactly what needs to be done to address the issue. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the correction of \\\"X\\\" to a multiset and the clarification of the set notation. The comment provides a detailed explanation of why this change is necessary, enhancing the specificity of the feedback. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that in section 4, \\\"X\\\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning by explaining that including the multiplicities of labels is necessary for the histogram to correctly represent such graphs. This explanation is clear and provides a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or external sources that support this reasoning, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion regarding the content of section 4. It identifies a potential error in the description of \\\"X\\\" and suggests that it should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and constructive, offering the authors a precise way to improve the accuracy and clarity of their work. By addressing this point, the authors can enhance the precision of their representation, which is crucial for the integrity of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the authors' derivation is based on classical learning theory-based bounds, which may not yield realistic bounds without considering Bayesian considerations, such as Bayesian-PAC based bounds. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their derivation. There is no guidance on potential modifications, alternative approaches, or additional considerations that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the authors' derivation, stating that it falls into classical learning theory-based bounds, which may not yield realistic bounds without considering Bayesian considerations. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the derivation are problematic or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the authors' derivation is based on classical learning theory-based bounds, which may not yield realistic bounds without considering Bayesian considerations. The reviewer supports this claim by stating that Bayesian-PAC based bounds are a more realistic approach. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. The authors would need to further explore the comment to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the authors' derivation, noting that it is based on classical learning theory-based bounds, which may not yield realistic bounds without considering Bayesian considerations. This feedback is somewhat helpful as it points out a theoretical limitation that the authors should consider. However, it lacks specific suggestions or guidance on how the authors might address this issue or incorporate Bayesian considerations into their work. Providing more detailed feedback or actionable steps would make the comment more helpful for the authors. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of significance testing to support the claims made about the differences between certain methods. It provides specific examples, such as the comparison between \\\"zh->en ChatGPT\\\" and \\\"GPT-4,\\\" and explains why significance testing is necessary to validate the claims. The comment explicitly instructs the authors to conduct significance testing, including checking the distribution and accounting for multiple comparisons. This feedback is clear and provides concrete guidance on how to address the issue, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 486,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking significance testing to support the claims about the differences between methods, providing examples and explaining why significance testing is necessary. The comment suggests conducting significance testing, including checking the distribution and accounting for multiple comparisons, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point highlights a lack of significance testing to support claims about the differences between methods, such as the conversational ability of ChatGPT and GPT-4. The reviewer provides specific examples, including the d-BLEU and humeval scores for different methods, to illustrate the minimal differences and the need for proper testing. This detailed explanation and the inclusion of specific data points make the claim fully verifiable, as it provides a clear rationale and evidence for the need for significance testing. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it identifies a critical gap in the paper's analysis: the lack of significance testing to support claims about the differences between methods. It provides specific examples, such as the comparison between \\\"zh->en ChatGPT\\\" and \\\"GPT-4,\\\" and explains why significance testing is necessary to validate the claims. The comment also suggests conducting significance testing, including checking the distribution and accounting for multiple comparisons, offering clear and actionable guidance for the authors to improve their draft. This level of detail and constructive feedback empowers the authors to make significant improvements to their work, making the comment highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the potential influence of regularization effects on the observed improvements in the teacher's performance, suggesting that the improvements might not be solely due to distillation. It implies that the authors should conduct ablation studies to verify their claims, particularly regarding the fine-tuning process. While the comment suggests a specific action\\u2014conducting ablation studies\\u2014it does not provide detailed guidance on how to perform these studies or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific aspect of the paper, namely the study of knowledge distillation and its impact on the teacher's performance. It highlights a potential issue with the claim that improvements are solely due to distillation, suggesting that regularization effects might be at play. The comment also points out the need for proper ablation studies to verify the findings, particularly regarding the fine-tuning process without early-stopping. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing the potential issue and suggesting a way to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the potential influence of regularization effects on the observed improvements in the teacher's performance, suggesting that the improvements might not be solely due to distillation. The reviewer provides some reasoning by noting that all fine-tuning is performed for 10 epochs without early-stopping, which typically leads to high variances in fine-tuning on GLUE without validation. However, the comment lacks specific examples or references to support the claim about regularization effects or to illustrate the need for proper ablation studies. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the paper's claim that improvements in the teacher's performance are solely due to distillation. It suggests that the observed improvements might be influenced by regularization effects rather than the distillation process itself. The comment highlights the need for proper ablation studies to verify the claim, particularly regarding the fine-tuning process without early-stopping. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to validate their claims. However, it could be more helpful if it provided specific suggestions on how to design these ablation studies or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward a critical area for further investigation and validation.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the contribution of their work. The comment lacks actionable details, such as recommending ways to enhance the model's contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered incremental or how the contribution is limited. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point makes a claim that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or suggestions on how the authors might address these concerns or improve the contribution of their work. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential issue with supervised pretraining based on the prediction of the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of how Transformer-M performs poorly on most tasks other than homo, lumo, and gap in downstream experiments, which could contradict the paper's claim of a \\\"general-purpose neural network model.\\\" However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or improve their model. The feedback lacks actionable steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific issue related to supervised pretraining based on the prediction of the homo-lumo gap, which could lead to negative transfer. It provides an example of how Transformer-M performs poorly on most tasks other than homo, lumo, and gap in downstream experiments, which contradicts the paper's claim of a \\\"general-purpose neural network model.\\\" However, the comment does not explicitly mention which part of the paper discusses these experiments or the homo-lumo gap, making it weakly grounded. The comment is specific in detailing the issue and providing an example, but without explicit grounding, it is challenging for the authors to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that supervised pretraining based on the prediction of the homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M's poor performance on most tasks other than homo, lumo, and gap in downstream experiments. This claim is supported by a specific example from the QM9 dataset, which provides a clear and logical basis for the assertion. The reference to the homo-lumo gap and the performance of Transformer-M offers a concrete example that helps substantiate the claim. However, the comment could be strengthened by providing additional references or detailed explanations of the homo-lumo gap's implications. Overall, the claim is mostly verifiable due to the clear reasoning and specific example provided, but it could benefit from further elaboration. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the supervised pretraining approach based on the prediction of the homo-lumo gap, suggesting that it might lead to negative transfer. It provides a specific example from the QM9 dataset, where Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which could contradict the paper's claim of a \\\"general-purpose neural network model.\\\" This feedback is somewhat helpful as it highlights a potential weakness in the methodology and provides a concrete example to illustrate the issue. However, it lacks detailed guidance or suggestions on how the authors might address this problem or improve their model to achieve a more general-purpose capability. Therefore, the comment is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It highlights specific areas where the paper's experimental evaluation could be improved, such as the lack of ablation for the \\\"picking\\\" step and the need for more convincing comparisons on the CIFAR dataset. The reviewer suggests using the same setup as in the DEN paper to ensure a fair and correct comparison. These points offer clear guidance on how to enhance the paper, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The review comment is fully grounded as it explicitly mentions specific sections of the paper, such as \\\"Experimental Evaluation 2.1. Ablations 2.1.1\\\" and \\\"Experiments on CIFAR. 2.2.1\\\" and \\\"2.2.2.\\\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the experimental evaluation, such as the lack of ablation for the \\\"picking\\\" step and the need for more convincing comparisons on the CIFAR dataset. It suggests using the same setup as in the DEN paper for a fairer comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the experimental evaluation, specifically questioning the claim about the \\\"picking\\\" step and the comparison on the CIFAR dataset. It suggests that the comparison is not convincing due to the lack of ablation for the \\\"picking\\\" step and the limited scope of comparisons on CIFAR. The reviewer provides specific references to the continual learning literature and the DEN paper, which can help the authors understand the basis of their critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how the comparisons could be improved. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and references to external sources, but it could benefit from additional detail.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It highlights two main issues: the lack of ablation for the \\\"picking\\\" step and the unconvincing comparison on the CIFAR dataset. The comment suggests that the authors should include an ablation study for the \\\"picking\\\" step to substantiate their claim. Additionally, it points out that the comparison on CIFAR is limited, as it only compares to one approach (DEN), and suggests using the same setup as in the DEN paper for a fairer comparison. This feedback is clear and provides concrete suggestions for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the trade-off between computation time and information content in the proposed method compared to a baseline. It highlights the reduction in search space to ancestral graphs and the resulting loss of information compared to the baseline's richer search space (DAGs). However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. It lacks actionable details, such as recommending ways to mitigate the information loss or suggesting additional experiments to explore the impact of this trade-off. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the trade-off between computation time and information content in the proposed method compared to a baseline. It mentions the reduction in search space to ancestral graphs and the resulting loss of information compared to the baseline's richer search space (DAGs). However, it does not specify which part of the paper discusses this trade-off, making it weakly grounded. The comment is specific in detailing the issue of information loss and the price paid for better performance, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the baseline method that uses a richer search space (DAGs). The comment provides a logical reasoning by explaining the trade-off between computation time and information content. However, it lacks specific examples or references to substantiate the claim about the information loss in ancestral graphs. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment highlights a trade-off between computation time and information content in the proposed method compared to a baseline. It points out that while the method achieves faster computation by reducing the search space to ancestral graphs, it results in less information compared to the baseline's richer search space (DAGs). The comment raises an important question about the information encoded in an ancestral graph, which could prompt the authors to further explore or justify this aspect of their method. However, the comment lacks specific suggestions or guidance on how the authors might address this trade-off or improve their draft. While it identifies a relevant issue, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and the regression in RepPoints. The reviewer provides some context by mentioning RetinaNet and ATSS, suggesting that the regression methods do not significantly influence the results. The comment explicitly asks the authors to clarify this issue and suggests that the motivations behind the methods might not be solid enough. While the comment clearly identifies the need for clarification, it does not provide specific guidance on how to address the issue or what aspects to focus on for clarification. The action is explicit but somewhat vague, as the authors know they need to clarify the definitions but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definitions in Table 1, particularly the difference between anchor-based regression and the regression in RepPoints, and provides context by referencing RetinaNet and ATSS. The comment suggests that the motivations behind the methods might not be solid enough and requests clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and the regression in RepPoints. The reviewer provides some context by mentioning RetinaNet and ATSS, suggesting that the regression methods do not significantly influence the results. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that there is no obvious difference between the two methods. While the reviewer offers some logical reasoning, the absence of concrete evidence or references makes the claim somewhat verifiable. The authors would need to further explore the provided context to fully understand and address the concern, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the definitions in Table 1, specifically questioning the difference between anchor-based regression and the regression in RepPoints. It provides some context by mentioning RetinaNet and ATSS, suggesting that the regression methods do not significantly influence the results. The reviewer also expresses a desire for clarification, indicating that the motivations behind the methods might not be solid enough. This feedback is somewhat helpful as it identifies a potential area of confusion and encourages the authors to clarify their definitions. However, it lacks specific suggestions or guidance on how to address the issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers when discussing them as numbers. This is an explicit and concrete action, as it clearly identifies what needs to be clarified in the paper. The authors know exactly what information is missing and how to address it, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its request for clarification, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. It is a factual observation and request for information, so \\\"No\\\" is the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion to clarify whether the Fourier modes are real or complex numbers when discussing them as numbers. This feedback is clear and directly addresses a potential ambiguity in the paper, which can help the authors improve the clarity and precision of their writing. By offering a concrete suggestion, the comment empowers the authors to make a straightforward improvement to their draft. Therefore, the comment is rated as mostly helpful, consistent with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to correct a specific error in the text, where it mentions that \\\"on line 205, it should be Fig. 1 instead of Fig. 5.1.\\\" Additionally, it provides a concrete suggestion for LaTeX formatting, recommending that the label be placed after the caption. This feedback is clear and provides specific guidance on how to correct the error and improve the formatting. The authors know exactly what changes to make, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 205\\\" and \\\"Fig. 1\\\" and \\\"Fig. 5.1,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the incorrect figure reference, and provides a concrete suggestion for LaTeX formatting. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual corrections regarding figure references and LaTeX formatting. It does not contain any subjective opinions, judgments, or suggestions that require verification or justification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by correcting a factual error in the manuscript, where it points out that \\\"on line 205, it should be Fig. 1 instead of Fig. 5.1.\\\" Additionally, it offers a clear suggestion for LaTeX formatting, recommending that the label be placed after the caption to solve a bug. This feedback is precise and directly addresses a minor but important issue, ensuring that the manuscript is accurate and well-formatted. The comment is highly helpful as it empowers the authors to make these corrections, improving the overall quality and professionalism of their draft. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors include case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of a case study from another paper, which can serve as a reference for the authors. The comment explicitly states the need for case studies and provides a concrete example, making it clear what the authors should do to improve their draft. The action is explicit and concrete, providing the authors with a clear direction on how to enhance their work. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests including case studies and error studies to demonstrate the effectiveness of the proposed components. It provides a specific example of a case study from another paper, which can serve as a reference for the authors. However, the comment does not explicitly mention which part of the paper should include these case studies, making it weakly grounded. The suggestion is specific, as it outlines a particular approach to enhance the paper's credibility. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that including case studies and error studies would strengthen the paper by demonstrating the effectiveness of the proposed components. The reviewer provides a specific example of a case study from another paper, which serves as a reference for the authors. This example helps to substantiate the claim that case studies are necessary to substantiate the effectiveness of the proposed components. However, the comment could be strengthened by providing more detailed reasoning or additional examples of how these studies would enhance the paper. As it stands, the claim is mostly verifiable due to the reference to an external example, but it lacks comprehensive justification. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a constructive suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of the proposed components. It acknowledges the paper's mention of the Element-level Graph Pre-training and highlights the need for empirical evidence to substantiate its claims. The comment offers a specific example of a case study from another paper, which can serve as a reference for the authors. This feedback is clear and actionable, guiding the authors on how to strengthen their work by providing empirical evidence. However, it could be more helpful if it included additional guidance on how to design or implement these case studies. Overall, the comment is mostly helpful, as it provides valuable direction for enhancing the paper's credibility and impact.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the notation \\u03c0 with a subscript is used multiple times in the same section without being defined. This implies that the authors should define this notation to ensure clarity and avoid confusion. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to improve the draft. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the section where the notation \\u03c0 with a subscript is used multiple times without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of definition for the notation \\u03c0 with a subscript. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment points out that the notation \\u03c0 with a subscript is used multiple times in the same section without being defined. This is a factual observation about the lack of definition, and it does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the manuscript, noting that the notation \\u03c0 with a subscript is used multiple times in the same section without being defined. This is a clear and actionable piece of feedback that can help the authors improve the clarity and comprehensibility of their work. By defining the notation, the authors can ensure that readers understand the meaning of the symbols used, which is crucial for the accuracy and readability of the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to define the notation effectively. Overall, the comment is mostly helpful as it highlights a specific area for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It points out specific grammatical errors, such as the incorrect use of \\\"know\\\" instead of \\\"known\\\" at line 148. It also requests a definition for the symbol \\\\(\\\\gamma_0^{***}\\\\) at line 156 and asks for clarification on the meaning of colors in Figure 1, both in the caption and the text. These instructions are clear and leave no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (l148, l156) and the figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: correcting a grammatical error, defining a symbol, and clarifying the meaning of colors in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual corrections and requests for clarification, such as correcting a grammatical error and defining a symbol. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback, addressing multiple areas that need improvement. It points out a grammatical error at line 148, where \\\"known\\\" should be used instead of \\\"know.\\\" It also requests a definition for the symbol \\\\(\\\\gamma_0^{***}\\\\) at line 156, which is a clear and direct request for clarification. Additionally, it suggests specifying the meaning of colors in Figure 1, both in the caption and the text, which is a helpful suggestion for improving the clarity and accessibility of the figure. These specific and actionable comments empower the authors to make targeted improvements to their draft, making the feedback mostly helpful. However, the comment could be more helpful if it provided additional context or examples for the grammatical correction or the symbol definition. Therefore, it is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the rationale behind specific design choices in Figure 1, such as the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these questions or improve their draft based on this feedback. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the rationale behind two specific design choices: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the rationale behind specific design choices in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it identifies areas that may need clarification, it does not provide suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is somewhat helpful as it prompts the authors to consider and justify their design choices, but it lacks depth and actionable feedback that would guide the authors in making improvements. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing and presentation are \\\"a bit jumbled at times,\\\" but it does not provide specific guidance on how to improve the clarity or organization of the text. Without explicit suggestions or concrete details on what aspects are jumbled or how they should be revised, the authors are left without a clear understanding of what actions to take to address the issue. The lack of actionable details makes this comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing and presentation are \\\"a bit jumbled at times,\\\" but it does not specify which parts of the paper or sections are particularly jumbled. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the writing and presentation are \\\"a bit jumbled at times,\\\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the writing and presentation are \\\"a bit jumbled at times,\\\" but it does not provide specific examples or detailed feedback on which parts of the paper are unclear or disorganized. Without actionable suggestions or guidance, the authors are left without a clear understanding of how to improve the clarity and organization of their draft. This lack of specificity and actionable advice makes the comment not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to analyze and compare the computational complexity, but it remains vague because it lacks concrete steps or specific recommendations on how to conduct this analysis. Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure where computational complexity is discussed. While the authors might have an idea of where computational complexity is addressed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about computational complexity or power demand. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment raises an important question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions. It highlights a potential concern regarding power demand if the method is applied on a mobile device. While the comment identifies a relevant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is somewhat helpful as it prompts the authors to consider the computational efficiency of their method, but it could be more beneficial with additional details or recommendations. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out an inaccuracy in the authors' description of the base IOI circuit, specifically regarding the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token. The reviewer explicitly states that this is incorrect according to Section 3 of Wang et al., 2023, and provides a correction by clarifying that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear action for the authors to correct their description, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the specific claim made by the authors regarding the base IOI circuit and the attention of certain heads to the S2 token. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is incorrect in the authors' description, pointing out that the heads are active at the S2 token but do not primarily attend to it. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the authors' statement about the base IOI circuit, specifically regarding the primary attention of certain heads to the S2 token. The reviewer provides a reference to Section 3 of Wang et al., 2023, which supports the claim that the heads are active at the S2 token but do not primarily attend to it. This reference provides a clear and specific basis for the claim, making it fully verifiable. The detailed explanation and external reference allow the authors to understand and address the issue effectively.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific inaccuracy in the authors' description of the base IOI circuit, pointing out that the Induction, Duplicate Token, and Previous Token heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their description based on the evidence provided in Wang et al., 2023. By addressing this specific issue, the authors can improve the accuracy and credibility of their work. The comment is highly helpful as it provides a precise and constructive suggestion for revision, empowering the authors to make significant improvements to their draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides specific feedback on the vagueness of certain statements in the paper, particularly regarding the use of RNNs for natural language reasoning tasks and the reinforcement learning-agent analogy. It suggests that the authors should clarify these points and consider using examples from the literature on natural language inference or the SNLI leaderboard to support their claims. Additionally, it advises the authors to reconsider the reinforcement learning-agent analogy and focus on generalization capabilities illustrated by later examples in the paper. While the comment provides explicit suggestions for improvement, it could be more actionable if it included detailed guidance on how to implement these changes. Overall, the comment is mostly actionable as it gives clear directions for improvement, but it could be more detailed in its execution.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) and provides context by referencing the literature on natural language inference and the SNLI leaderboard. It also specifies the issue with the reinforcement learning-agent analogy, suggesting that it seems out-of-place and that generalization capabilities are better illustrated by later examples. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand the specific issues that need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the vagueness of certain statements regarding RNNs and their application to natural language reasoning tasks, referencing the literature on natural language inference and the SNLI leaderboard as evidence. This provides a clear and specific reference to support the claim, making it mostly verifiable. However, the comment could be further strengthened by providing more detailed examples or explanations of how the literature supports the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies two specific issues with the paper. First, it points out that the statement about RNNs working well for certain natural language reasoning tasks is too vague and suggests that the authors should reference the literature on natural language inference and the SNLI leaderboard for more precise information. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity and specificity of their claims. Second, the comment critiques the reinforcement learning-agent analogy as being out-of-place and suggests that the paper should focus on generalization capabilities illustrated by later examples. This feedback is also actionable, as it provides a constructive suggestion for improving the coherence and focus of the paper. Overall, the comment is mostly helpful as it offers specific and actionable feedback that can guide the authors in refining their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a specific issue with the statement about kernels being described by a feature space parameterized by a neural network, noting that this is not trivially true. It provides a detailed explanation using the example of RBF kernels and their infinite-dimensional RKHS, suggesting that the limitation should be made clearer. The comment explicitly instructs the authors to address this issue, providing a clear and concrete action for them to take. The feedback is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions line \\\"104,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels being described by a feature space parameterized by a neural network, providing a clear explanation of the limitation and suggesting that this should be made more explicit. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the statement that every kernel can be described by a feature space parameterized by a neural network, providing a counterexample with RBF kernels and their infinite-dimensional RKHS. The reviewer explains that this limitation should be made clearer, offering a logical reasoning based on the properties of RBF kernels and their RKHS. This detailed explanation and the use of a specific example make the claim mostly verifiable, as it provides a robust foundation for the critique. However, the comment could be further strengthened by referencing specific literature or studies that discuss this limitation, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the statement in the paper regarding the description of kernels using a feature space parameterized by a neural network. It provides a clear and detailed explanation of why this statement is not trivially true, using the example of RBF kernels and their infinite-dimensional RKHS. The comment suggests that the limitation should be made more explicit, offering valuable insight into the theoretical underpinnings of the paper. This feedback is actionable and provides the authors with a concrete direction to improve the clarity and accuracy of their work. However, it could be more helpful if it included suggestions on how to address this limitation or examples of how to present it more effectively. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the proposed method is not well-positioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It provides specific examples, such as the original denoising score matching objective and score-interpolation, and recommends a thorough literature review. The comment explicitly instructs the authors to conduct a literature review, providing a clear action and concrete guidance on how to address the issue. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment critiques the positioning of the proposed method in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It provides specific references, such as the original denoising score matching objective and score-interpolation, to support its claim. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the literature review. Therefore, the comment is weakly grounded but specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the proposed method is not well-positioned in the literature, specifically noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by providing specific references to the original denoising score matching objective and score-interpolation, suggesting that this property is used in many more works. This detailed reference to existing literature provides a robust foundation for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the positioning of the proposed method in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already well-known and has been used in previous works, such as the original denoising score matching objective and score-interpolation. The comment suggests that the authors conduct a thorough literature review to acknowledge and differentiate their work from existing literature. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by situating their work within the existing body of knowledge. However, the comment could be more helpful if it offered specific suggestions on how to conduct the literature review or which works to consider. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment states that the technical contribution is limited and lacks significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a perceived limitation in the technical contribution of the paper, suggesting that it lacks significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not provide specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or detailed critique, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point critiques the novelty of the approach's components, noting that the weak predictor used (MLP, Regression Tree, or Random Forest) and the sampling strategy are not novel, as they have been used in previous works. It also mentions that the results of the proposed WeakNAS are similar to those of BRP-NAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or performance of the proposed method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor used (MLP, Regression Tree, or Random Forest) and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by comparing the proposed approach to previous works, such as [2,3,7] and BRP-NAS[5], and notes that the results are similar. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the components of the approach are not novel, specifically mentioning the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used in previous works. It also notes that the sampling strategy is similar to epsilon-greedy and exactly the same as that in BRP-NAS. The comment further supports its claim by referencing specific works ([2,3,7] and BRP-NAS[5]) and comparing the results of the proposed WeakNAS to those of BRP-NAS. This detailed comparison and reference to existing literature provide a robust foundation for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment points out that the components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It specifically mentions that the weak predictor is similar to those used in NAS performance prediction and that the sampling strategy is the same as in BRP-NAS. Additionally, it notes that the results of the proposed WeakNAS are almost the same as BRP-NAS. This feedback is somewhat helpful as it identifies a lack of novelty in the approach and provides references to previous works, which could guide the authors in understanding and addressing the issue. However, it does not offer specific suggestions or actionable steps for the authors to enhance the novelty or differentiate their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests that AUC results should be provided for breast cancer detection comparisons. While the comment implies that the authors should provide AUC results, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to calculate the precision, recall, and F1-score for the 4-class classification. The action is implicit and somewhat vague, as the authors need to infer that they should include AUC results and understand the calculation process. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises questions about the calculation of precision, recall, and F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection comparisons. However, it does not specify which part of the paper these calculations or results are discussed in, making it weakly grounded. The comment is specific in its request for additional information, such as AUC results, which would enhance the paper's comprehensiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of questions and suggestions regarding the calculation of precision, recall, and F1-score for a 4-class classification of breast density, and suggests providing AUC results for breast cancer detection comparisons. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions and suggestions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the methodology used to calculate precision, recall, and F1-score for a 4-class classification of breast density. It also suggests that for breast cancer detection, researchers typically report AUC with sensitivity and specificity at different operating points for model performance comparison. The comment provides a specific suggestion to include AUC results, which could enhance the comprehensiveness of the paper. However, the comment could be more helpful by explaining why AUC is a more informative metric in this context or by providing examples of how to present these results. Overall, the feedback is somewhat helpful as it identifies an area for improvement and offers a suggestion, but it lacks depth and detailed guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, it does not provide explicit guidance on how to incorporate the Kialo dataset into the paper or how to use it as extra data for learning. The action is implicit, as the authors need to infer that they should consider using the Kialo dataset, and it is vague because it lacks concrete steps on how to implement this suggestion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests using the Kialo dataset as an alternative to the dataset created by the authors, highlighting its suitability due to its cleanliness and lack of automatic processes. However, it does not specify which part of the paper discusses the dataset creation or its potential impact, making it difficult for the authors to pinpoint the exact section that needs revision. While the suggestion is specific in terms of recommending an alternative dataset, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is well-studied and cleaner. The claim is supported by logical reasoning, as the Kialo dataset is described as providing pairs of short claims and their counters, making it suitable for the authors' needs. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would benefit from more detailed justification or references to fully understand the basis of the suggestion.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment suggests an alternative dataset, the Kialo dataset, which is well-studied and cleaner than the dataset created by the authors. It acknowledges that the dataset creation is optional and provides a rationale for using the Kialo dataset as an alternative. However, the comment does not offer specific guidance on how to integrate the Kialo dataset into the paper or how it might enhance the study. While it provides a useful suggestion, the lack of actionable steps or detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers insight but not comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the novelty of using a transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also points out that the modification made by the authors, specifically the cross-layer aspect, does not provide significant insight into machine learning. Additionally, the comment notes that the self-cross attention in the ablation study (table4 and 5) brings only limited improvement (<1%), suggesting that the main improvements come from using a naive transformer rather than the proposed modification. While the comment provides a critique of the paper's contributions, it does not offer explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or significance of the work, nor are there suggestions for alternative approaches or improvements. As a result, the comment lacks actionability, leaving the authors without clear steps to follow to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections, namely \\\"ablation study (table4 and 5),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the use of Transformer in the context of NLP and vision tasks, the limited improvement from self-cross attention, and the suggestion that the main improvements come from using a naive transformer rather than the proposed modification. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the use of Transformer in NLP and vision tasks is no longer novel and that the modification made by the authors does not provide significant insight into machine learning. It also critiques the ablation study, noting that self-cross attention brings limited improvement. The comment provides some reasoning by stating that the main improvements come from using a naive transformer rather than the proposed modification. However, it lacks specific examples or references to support the claim about the limited improvement or the lack of novelty. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a critical evaluation of the paper's approach, highlighting the lack of novelty in using Transformers for NLP and vision tasks. It points out that the modification made by the authors, specifically the cross-layer aspect, does not offer significant insight into machine learning. Additionally, the comment notes that the self-cross attention in the ablation study brings only limited improvement, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. This feedback is somewhat helpful as it identifies areas where the paper's contributions may be lacking and provides a rationale for questioning the significance of the proposed modification. However, it could be more helpful if it offered specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to discuss and illustrate the relationship between their work and a specific previous study, \\\"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\\\" from ICML2019. It also suggests that the authors should explain why their proposed method is better. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed and how to do so. The comment is highly actionable as it offers detailed guidance on how to improve the draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly refers to the claim made by the authors regarding the lack of research on joint error for UDA and suggests discussing a specific work, \\\"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\\\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need to discuss and illustrate the relationship between the mentioned work and the proposed method, and why the proposed method is better. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the authors' claim that there is no research on joint error for UDA, suggesting that this problem has been studied in previous works, specifically mentioning \\\"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\\\" from ICML2019. The reviewer provides a specific reference to support the claim, which makes it fully verifiable. By referencing a particular work, the comment offers a clear and robust basis for the claim, allowing the authors to understand and address the critique effectively. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment is mostly helpful as it identifies a specific gap in the literature that the authors have overlooked, namely the study on joint error for UDA in \\\"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\\\" from ICML2019. It provides a clear and actionable suggestion for the authors to discuss this work and illustrate its relationship with their proposed method. By doing so, the authors can better position their work within the existing literature and highlight the novelty or improvements of their approach. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion into the manuscript or what aspects of the previous work should be compared. Overall, the feedback is clear and constructive, providing a valuable direction for the authors to enhance their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods due to the use of a newly collected large-scale dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset scale. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting a comparison with methods using similar dataset sizes or recommending a specific approach to ensure a fair evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should consider dataset size as a factor in their evaluation. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the fairness of the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset and comparing it to existing methods that use smaller datasets, such as GEM with 20M unlabeled data. This provides a clear indication of the part of the paper being addressed, making it fully grounded. The comment also specifies the issue, which is the potential impact of dataset scale on accuracy, and suggests that the superior performance might be due to the larger dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods due to the use of a newly collected large-scale dataset, while existing methods use smaller datasets. The reviewer provides a specific example, mentioning that GEM employs only 20M unlabeled data, to illustrate the potential impact of dataset scale on accuracy. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific studies or datasets that have used similar scales, which would provide more robust evidence. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the fairness of the comparison with state-of-the-art (SOTA) methods. It points out that the proposed method's superior performance might be attributed to the use of a newly collected large-scale dataset, while existing methods use smaller datasets. This is a critical observation that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as conducting additional experiments with similar dataset sizes or providing a more detailed analysis of the dataset's impact on performance. While the feedback highlights an important consideration, it could be more helpful with additional guidance on how to address the concern. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that several curriculum learning methods have been discussed in Section 1 but questions the need for designing a new method for text graphs. It also notes that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment highlights areas that need further exploration, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to justify the necessity of a new method and discuss the research gap, but without specific instructions or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on the research gap, such as why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, and it highlights the lack of discussion on the research gap, such as why existing methods cannot be applied. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is somewhat verifiable, as it points out a logical gap in the argument but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that while several curriculum learning methods have been discussed, the need for a new method is not adequately justified, and the research gap, such as why existing methods cannot be applied, is not addressed. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to provide a clearer rationale and discussion on the necessity and potential benefits of their proposed method. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the comment is somewhat helpful, as it provides insight into an area needing further development but lacks detailed guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should use powerful pre-trained language models like BERT or XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest n-gram features. This comment provides a clear and explicit action for the authors to take, specifying the use of pre-trained models and the focus on comparing transfer parts. The suggestion is concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests using powerful pre-trained language models like BERT or XLNet as the base encoder for all methods and then comparing the efficacy of the transfer parts instead of using the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the domain adaptation or transfer learning sections, but this inference is not direct. The comment is specific in suggesting a particular approach to improve the paper, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that using powerful pre-trained language models like BERT or XLNet as the base encoder can help overcome the domain-shift problem in NLP. The claim is supported by logical reasoning, as these models are known to perform well in various NLP tasks and can adapt to different domains. However, the comment lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. The authors would benefit from more detailed evidence or references to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of powerful pre-trained language models like BERT or XLNet as the base encoder for all methods. It suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. This feedback is specific and offers a concrete direction for enhancing the paper's methodology and potentially improving its performance. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it might be beneficial. Overall, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the quantitative evaluation results, noting that they only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo's superiority over competitors. The reviewer explicitly asks whether a quantitative comparison on the final outputs is possible. This direct question implies that the authors should consider conducting such a comparison to strengthen their evaluation. The action is explicit and concrete, as it clearly directs the authors to perform a specific analysis to address the concern. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3\\\" and \\\"Figure 4,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs, and suggests that a quantitative comparison on the final outputs would be more convincing. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the validity of the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs. The reviewer suggests that a comparison on final outputs would be more convincing. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the current evaluations are insufficient. The suggestion for a comparison on final outputs is logical, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than the final outputs. It also points out that Figure 4 only compares final results with a single data sample, which may not be sufficient to confirm ModelAngelo's superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a more comprehensive evaluation. However, it could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and provides a clear path for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies several specific areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It explicitly points out the need for clarification on the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. Each of these points provides a clear action for the authors to take, making the comment highly actionable. The explicit nature of the feedback and the detailed guidance on what needs to be clarified make it easy for the authors to address the issues raised in the comment.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the lack of detail regarding the techniques used in the paper, allowing the authors to identify the specific areas that need clarification. It is also specific because it details several unresolved questions, such as the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks detail regarding the techniques used, making it difficult to reproduce the results. It provides specific examples of areas where more information is needed, such as the sparsification process, landmark generation, and the selection of landmark features. However, the comment does not provide references or detailed explanations to support these claims, leaving the authors to infer the importance of these details. While the comment identifies specific gaps, it lacks comprehensive justification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several specific areas where the paper lacks detail, which is crucial for reproducibility. It highlights the need for clarification on the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. By pinpointing these gaps, the comment provides clear and actionable feedback that can guide the authors in expanding their manuscript to include the necessary details for reproducibility. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information might be needed. Overall, the comment is mostly helpful as it directs the authors to critical areas needing clarification, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential issue with the FIITED approach, specifically the reliance on utility scores for determining chunk significance. It suggests that this approach might introduce biases, such as premature evictions of valuable chunks due to recent chunks having temporarily high utility scores. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or mitigate the potential biases. The feedback lacks concrete steps or recommendations, leaving the authors uncertain about how to improve their draft in response to this concern. Therefore, the comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the core of the FIITED approach, specifically the utility-based approach for determining chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, suggesting that this could introduce biases. However, the comment does not specify which part of the paper discusses the utility-based approach or where the potential biases are introduced, making it weakly grounded. The comment is specific in identifying the issue with the utility-based approach and the potential for premature evictions, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the FIITED approach, specifically the utility-based method for determining chunk significance. It suggests that relying solely on utility scores could introduce biases, such as premature evictions of valuable chunks due to recent ones having temporarily high utility. However, the comment lacks specific examples or references to support the claim of potential biases. While it provides a logical reasoning for the concern, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the FIITED approach, specifically the reliance on utility scores for determining chunk significance. It highlights a concern that this approach might introduce biases, such as premature evictions of valuable chunks due to recent ones having temporarily high utility scores. While the comment raises an important point about the potential for bias, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential biases. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the first paragraph of the Introduction for being too general and not relevant to the paper's core focus on detecting drift types and magnitude. It suggests that the DNN-related introduction is not central and provides little value to readers. However, the comment does not offer specific guidance on how the authors should revise this paragraph to better align with the paper's focus. It lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. Since the comment is vague and does not provide actionable steps, it is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first paragraph of the Introduction,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the paragraph is too general and not relevant to the paper's core focus on detecting drift types and magnitude. The comment provides a clear critique of the content and suggests that it does not align with the paper's main contribution. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the first paragraph of the Introduction is too general and not relevant to the paper's core focus on detecting drift types and magnitude. The reviewer supports this claim by stating that the paragraph does not align with the paper's main contribution, suggesting that it provides little value to readers. However, the comment lacks specific examples or detailed reasoning to substantiate why the DNN-related introduction is not central to the paper's focus. This makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the introduction section, noting that the first paragraph is too general and does not align with the paper's core focus on detecting drift types and magnitude. It suggests that the DNN-related introduction is not central to the paper and provides little value to readers. This feedback is clear and actionable, as it directs the authors to reconsider the content and structure of the introduction to better align with the paper's main contribution. However, the comment could be more helpful if it offered suggestions on how to integrate the DNN-related content more effectively or provided examples of how to better align the introduction with the paper's focus. Overall, the comment is mostly helpful, as it provides valuable insight into a structural issue that the authors can address to improve their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of clarity regarding the performance and contribution of different parts of the framework, both in terms of methodology and experimental results. It points out the absence of quantitative experiments, comparisons between algorithms, or detailed explanations of the framework's components. The comment implies that the authors should provide more information to clarify the performance of the framework and its individual parts. While the action is implicit, it is concrete because it specifies what is missing\\u2014quantitative experiments, comparisons, and detailed explanations. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment addresses the clarity of the framework's performance and contribution, both in terms of methodology and experimental results. It points out the lack of quantitative experiments, comparisons between algorithms, or detailed explanations of the framework's components. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing\\u2014quantitative experiments, comparisons, and detailed explanations\\u2014providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the clarity of the framework's performance and contribution, noting the absence of quantitative experiments, comparisons between algorithms, or detailed explanations. The comment suggests that the lack of these elements makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific areas that require more detail, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the paper regarding the clarity of the framework's performance and contribution. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the framework's components. This feedback is valuable as it highlights areas where the authors can improve their draft by providing more comprehensive experimental analysis and detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or comparisons. Overall, the feedback is somewhat helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take regarding the captioning experiment. It specifies that the final results should be compared on the official COOC leader board using the blind test set, referencing specific resources and challenges. The comment also suggests comparing the results to other approaches that have improved since the paper's publication, as listed on the leaderboard. This guidance is clear and detailed, giving the authors a specific path to follow to enhance their draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"captioning experiment\\\" and the need to compare results on the official COOC leader board using the blind test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides detailed guidance on what needs to be addressed, including the need to compare results with specific related work and to consider other approaches that have improved since the paper's publication. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper's captioning experiment should be compared to related work on the official COOC leader board using the blind test set. The reviewer provides specific references to the COOC challenge and mentions that several other approaches have improved since then, suggesting that the paper should at least compare to these. This claim is supported by external references and logical reasoning, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific comparisons, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback regarding the captioning experiment. It highlights the need to compare the results with related work on the official COOC leader board using the blind test set, referencing specific resources and challenges. The comment also suggests comparing the results to other approaches that have improved since the paper's publication, as listed on the leaderboard. This guidance is clear and constructive, offering the authors a concrete path to enhance their draft by aligning their experimental comparisons with established benchmarks and methodologies. The detailed nature of the feedback makes it highly helpful, as it empowers the authors to significantly improve their work.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out a lack of clarity in the use of terms like \\\"wrong\\\" and suggests that the authors clarify what these terms mean before using them. This feedback is explicit in its request for clarification and provides a clear action for the authors to take, which is to define these terms in the context of their paper. The comment is specific and provides a concrete direction for improvement, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L248,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \\\"wrong\\\" and suggesting that the authors clarify what is meant by \\\"good/bad/wrong explanation\\\" before using these terms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the use of the term \\\"wrong\\\" in the context of an explanation, suggesting that the authors clarify what is meant by \\\"good/bad/wrong explanation.\\\" While the comment identifies a potential issue with terminology, it does not provide specific examples or references to support the claim that the term \\\"wrong\\\" is unclear or misused. The suggestion to clarify the terms is logical, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a direction for improvement but lacks detailed justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the use of the term \\\"wrong\\\" in the paper, suggesting that the authors clarify what is meant by \\\"good/bad/wrong explanation\\\" before using these terms. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their language, which could improve the clarity and precision of their writing. By providing a specific area for clarification, the comment empowers the authors to enhance the quality of their draft. However, it could be more helpful if it offered suggestions on how to clarify these terms or provided examples of better phrasing. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity of their manuscript.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer implies that such a comparison is necessary to substantiate the claim that the schema searched by ELF (the author's method) is better than the schema in MVF. While the comment identifies a specific area that needs attention, it does not provide explicit instructions on how to conduct this comparison or what specific aspects should be focused on. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with MVF's image classification results. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\\u2014a comparison with the image classification results of MVF\\u2014and how this would help substantiate the claim that the schema searched by ELF is better than the schema in MVF. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by pointing out the lack of a direct comparison, which would be necessary to substantiate the claim that the schema searched by ELF is better than the schema in MVF. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the experimental demonstration of the paper's contribution points. It highlights the lack of a comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for substantiating the claim that the schema searched by ELF (the author's method) is better than the schema in MVF. This feedback is clear and actionable, as it directs the authors to include a comparison with MVF's results to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the originality of the article's reasoning and writing logic, noting similarities to a previous study. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or differentiate their work from the previous study. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance originality. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment raises concerns about the originality of the article's reasoning and writing logic, comparing it to a previous study. However, it does not specify which parts of the article are similar to the referenced work, making it difficult for the authors to identify the specific areas that need attention. Additionally, the comment lacks specificity regarding what aspects of the originality concerns should be addressed or how the authors might differentiate their work. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point raises a concern about the originality of the article's reasoning and writing logic, suggesting similarities to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The lack of explicit references or detailed reasoning makes it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is borderline verifiable, as it provides some indication of a potential issue but lacks sufficient evidence or detail to fully support the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The comment raises a concern about the originality of the article's reasoning and writing logic, noting similarities to a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. While this feedback highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work. The lack of actionable advice limits the comment's usefulness to the authors, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the discussion on regret, specifically questioning whether the prediction error over the entire horizon T cannot be sublinear. While the comment implies that the authors should clarify their discussion on regret, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to clarify their discussion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"lines 32 - 37,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the discussion on regret and the proof of achieving T^{1/2} regret, prompting the authors to clarify whether the prediction error over the entire horizon T cannot be sublinear. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question seeking clarification about the discussion on regret. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the discussion on regret, specifically questioning whether the prediction error over the entire horizon T cannot be sublinear. This feedback prompts the authors to clarify their discussion on regret, which is a critical aspect of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area of confusion, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper should include a discussion about the necessity of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer implies that there should be a discussion about the potential trade-offs or complexities involved. However, the comment does not provide explicit guidance on how to conduct this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the example of semantic segmentation and refers to \\\"table 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of learning long-range dependencies for powerful predictors and suggests a discussion about the potential trade-offs or complexities involved, particularly regarding the encoding of locality in the graph structure. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the necessity of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but expresses uncertainty about whether it is fully required. The reviewer suggests that the truth might lie somewhere between the extremes and proposes a discussion about the potential trade-offs or complexities involved. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The suggestion to discuss the encoding of locality in the graph structure is a starting point but not fully developed. Therefore, the comment is somewhat verifiable, as it provides an initial rationale but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the importance of learning long-range dependencies for powerful predictors, as demonstrated in the example of semantic segmentation. However, it expresses uncertainty about whether this is fully required and suggests that the truth might lie somewhere between the extremes. The comment implies that there should be a discussion about the necessity of learning long-range dependencies and the potential trade-offs or complexities involved. While the comment identifies an area for improvement, it lacks specific guidance or suggestions on how to address this issue or what aspects of the discussion should be focused on. This limits the comment's helpfulness, as the authors are left with a general idea of what needs to be explored but without detailed direction. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns about the theoretical results presented in the paper, specifically regarding the exponential dependence on the diameter $M$ of the domain of data. It questions the validity of the proposed approaches and theoretical results, noting that the performance worsens more quickly than standard random features. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable details, such as recommending specific changes or clarifications to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. (3),\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and discusses the exponential dependence on the diameter $M$ of the domain of data, as well as the impact on the constant factor of the required feature size. The comment further provides context by referencing Corollaries 1, 2, and 3, Theorem 4, and Figure 1, which helps the authors understand the specific issues being raised. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the theoretical results presented in the paper, specifically regarding the exponential dependence on the diameter $M$ of the domain of data. The reviewer provides logical reasoning by explaining how this dependence affects the constant factor of the required feature size and notes that the performance worsens more quickly than standard random features. This explanation is supported by references to specific results (Corollaries 1, 2, and 3, Theorem 4) and a figure (Figure 1), which collectively provide a robust foundation for the claim. The detailed analysis and references make the claim fully verifiable, as it is supported by clear reasoning and evidence.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed analysis of the theoretical results presented in the paper, specifically focusing on the exponential dependence on the diameter $M$ of the domain of data. It questions the validity of the proposed approaches and theoretical results, noting that the performance worsens more quickly than standard random features. This feedback is valuable as it highlights a potential weakness in the paper's theoretical framework and suggests that the authors should address this issue. However, the comment could be more helpful if it offered specific suggestions on how to mitigate this weakness or improve the theoretical analysis. Despite this, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to focus on. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential issue with the explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing rather than oversquashing and vanishing/exploding gradients. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting additional experiments, analyses, or discussions. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the issue of poor long-range modelling ability in DGNs, suggesting that it might be due to oversmoothing rather than oversquashing and vanishing/exploding gradients. It references a specific phenomenon observed in deep graph networks and cites a relevant work. However, the comment does not specify which part of the paper discusses the long-range modelling ability of DGNs, making it weakly grounded. The comment is specific in identifying the potential cause of the issue and providing a reference to support the claim. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the poor long-range modelling ability of DGNs could be due to oversmoothing, referencing a phenomenon observed in deep graph networks. The comment supports this claim by referencing a specific work, \\\"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, In AAAI'18,\\\" which provides a basis for the assertion. This reference offers a clear and specific example, making the claim mostly verifiable. However, the comment could be further strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing rather than oversquashing and vanishing/exploding gradients. It references a specific phenomenon observed in deep graph networks and cites a relevant work, which could help the authors understand and address the issue. However, the comment does not provide detailed guidance or suggestions on how to incorporate this insight into the paper or how to explore oversmoothing in their analysis. While it offers a valuable insight, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify these aspects or what particular elements are unclear. The authors are left to infer that they need to improve the clarity of their problem formulation, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these examples are in. Without explicit references to sections, figures, or specific examples, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific details or examples to support this claim, nor does it explain why the formulation is unclear or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks depth and does not provide actionable guidance or suggestions on how the authors might improve the clarity of their problem formulation. Without specific examples or detailed feedback, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is barely helpful, aligning with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the choice of grouping for quantization, suggesting that finer grouping might be considered instead of per-tensor and per-channel. While the comment implies that the authors should explore finer grouping, it does not explicitly instruct them to do so or provide guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider finer grouping and may not be entirely sure of the best approach to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about the choice of grouping for quantization, suggesting that finer grouping might be considered instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the grouping strategy is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for clarification on a specific aspect of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the choice of grouping for quantization, suggesting that finer grouping might be considered instead of per-tensor and per-channel. This feedback prompts the authors to reconsider their approach to quantization, potentially leading to improvements in their methodology. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement finer grouping or why it might be beneficial. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the meaning of \\\"epsilon-greedy\\\" in the context of training, specifically whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the term \\\"epsilon-greedy.\\\" Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Just before Appendix D.2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \\\"epsilon-greedy\\\" in the context of training and whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the use of \\\"epsilon-greedy\\\" in the training process. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the meaning of \\\"epsilon-greedy\\\" in the context of training, specifically whether it is used in addition to the proposed strategy. This feedback is somewhat helpful as it identifies a potential area of confusion in the manuscript. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect. The comment could be more helpful if it offered a suggestion on how to improve the clarity of the explanation or provided examples of similar strategies. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. It also notes that most existing ML accelerators use bit-parallel fixed-point numbers, which could limit the implications of the proposed methodology. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their methodology in light of these observations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the applicability of dynamic precision control during training, specifically mentioning bit-serial accelerators and contrasting them with the bit-parallel fixed-point numbers used in most existing ML accelerators. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential limitations of the proposed methodology due to the mismatch between the accelerator architecture and the methodology's requirements. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. It contrasts this with the common use of bit-parallel fixed-point numbers in existing ML accelerators, implying that this could limit the implications of the proposed methodology. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim fully. While it provides a logical basis for the concern, the absence of concrete evidence or examples makes it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bit-serial accelerators. It points out that most existing ML accelerators use bit-parallel fixed-point numbers, which could limit the implications of the proposed methodology. While the comment identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it highlights a critical consideration for the authors, but it lacks actionable advice or detailed insights that would empower the authors to make significant improvements to their draft. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a confusing aspect of the paper, specifically Eq. 12, and asks for clarification on the source of the reward at each trial. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. Additionally, it provides references to external sources, which could be relevant for the authors to consider. The comment is explicit in its request for clarification and provides concrete suggestions for improvement, such as using equations to explain the network model. The inclusion of references also offers a potential direction for further exploration. Therefore, the comment is highly actionable as it provides clear guidance on how to enhance the clarity and comprehensiveness of the paper.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. 12,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the confusion regarding the source of the reward at each trial and the need for an explanation of the network model in Sec. 4.2 with equations. Additionally, the comment provides references to external sources, which could be relevant for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that \\\"Eq. 12 is confusing\\\" and questions the source of the reward at each trial. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific reasoning or examples to support why Eq. 12 is confusing or how the suggested explanation would clarify it. The inclusion of references to external sources does not directly address the confusion about Eq. 12. As a result, the claim is somewhat verifiable, as it provides a general suggestion but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Eq. 12, noting that the source of the reward at each trial is unclear. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity, providing a clear and actionable recommendation for the authors. Additionally, the comment includes references to external sources, which could be relevant for the authors to consider. This feedback is mostly helpful as it directly addresses a specific area of confusion and offers a constructive suggestion for improvement. However, it could be more helpful if it provided more detailed guidance on how to clarify the reward source or suggested specific ways to integrate the references. Overall, the comment is rated as mostly helpful, consistent with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment criticizes the novelty of the idea, stating that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or address the limitations mentioned. The feedback lacks actionable details, such as recommending ways to make the metric and method more innovative or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the novelty of the idea and suggests that both the new metric and method are straightforward. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint where improvements are needed. Additionally, the comment lacks specificity regarding what aspects of the metric and method are considered straightforward or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment criticizes the novelty of the idea, stating that both the new metric and method are straightforward. However, it does not provide specific examples or detailed feedback on what aspects of the metric and method are considered straightforward, nor does it suggest ways to enhance the novelty or innovation of the work. Without actionable guidance or constructive suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to enhance clarity. While the feedback provides explicit actions for the authors to take, it lacks concrete details on how to implement these changes, such as specific examples of where to break down the process or how to structure the notation table. The authors are given a general direction but without detailed guidance on execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests improvements to the model description, specifically mentioning the generative process and the use of too many symbols and a notation table. However, it does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in suggesting that the generative process should be presented in separate steps and that a notation table could improve clarity. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table. While the comment provides some reasoning for the suggestion, it lacks specific examples or detailed justification for why these changes would enhance understanding. The claim is somewhat verifiable, as it offers a general direction for improvement but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific areas for improvement in the model description, suggesting that the generative process should be presented in separate steps to enhance understanding. It also points out the excessive use of symbols and the need for a notation table to improve clarity. While the comment provides actionable feedback, it lacks detailed guidance or examples on how to implement these changes effectively. The authors are given a general direction for improvement, but the feedback could be more comprehensive and specific to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper could improve by first motivating the \\\"why\\\" behind the research question, i.e., why the authors are interested in what they are presenting. However, it does not provide specific guidance on how to incorporate this motivation or what aspects should be emphasized. The action is implicit, as the authors need to infer that they should add a motivational section, and it is vague because it lacks concrete details on how to implement this suggestion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the paper could improve by motivating the \\\"why\\\" behind the research question, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine the exact section or context where this motivation is lacking, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the motivation are missing or how the authors could address this issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.\",\n    \"grounding_specificity_label\": \"2\",\n    \"verifiability_rationale\": \"The review point suggests that the paper could improve by motivating the \\\"why\\\" behind the research question, but it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that the paper could improve by providing a clearer motivation for the research question, specifically addressing why the authors are interested in the topic being presented. However, it lacks specificity and does not offer detailed guidance or examples on how to effectively motivate the research question. Without concrete suggestions or actionable advice, the authors may struggle to understand how to enhance their draft based on this feedback. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides a critique of the paper's performance compared to Decouple [Kang et al.], noting that the proposed approach does not outperform or is even worse in overall performance. It also highlights the trade-off between head and tail categories, suggesting that similar trade-offs have not been fully investigated for the baselines. The reviewer encourages the authors to continue this line of work for future submission. While the comment provides some context and suggests a direction for improvement, it lacks explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the trade-offs for baselines and potentially adjust hyper-parameters. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"3)\\\" and \\\"Table 5,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the proposed approach not outperforming or being worse than Decouple [Kang et al.] for overall performance, and it highlights the trade-off between head and tail categories. The comment further suggests that similar trade-offs have not been fully investigated for the baselines and provides an example of how changing hyper-parameters could improve the tail accuracy while slightly decreasing the head accuracy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also mentions that Table 5 shows a trade-off between head and tail categories but notes that similar trade-offs have not been fully investigated for the baselines. The reviewer suggests that by adjusting hyper-parameters in Decouple [Kang et al.], the trade-off could be improved. This claim is supported by logical reasoning and a specific example, providing a clear rationale for the critique. However, the comment could be strengthened by providing more detailed evidence or references to support the claim about the trade-off. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a critical evaluation of the paper's performance, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights the trade-off between head and tail categories, suggesting that similar trade-offs have not been fully investigated for the baselines. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies a significant weakness in the paper's performance and suggests a direction for improvement, it lacks specific guidance or actionable steps for the authors to address these issues. The feedback is somewhat helpful as it points out areas for improvement but could be more beneficial with detailed suggestions or examples. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it notes that the generation of authors is not realistic, as their embeddings are initialized by averaging corresponding artificial tweets. While the comment provides some insight into potential issues, it does not offer explicit guidance on how to address these concerns or improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to enhance the evaluation. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the evaluation of weak supervision and raises concerns about the realism of the evaluated tweets and the generation process. It provides specific examples, such as the requirement for \\\"all of the structured elements for perspectives to be present in the generated tweets\\\" and the initialization of \\\"author\\\" embeddings by averaging corresponding artificial tweets. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the concerns about realism and the generation process, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises concerns about the realism of the evaluation in the context of weak supervision. It critiques the prompt's requirement for all structured elements to be present in generated tweets and the initialization of \\\"author\\\" embeddings by averaging artificial tweets. While the comment provides some reasoning, it lacks specific examples or references to substantiate the claims about realism. The authors would need to further explore these points to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional detail to be fully substantiated.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it notes that the generation of authors is not realistic, as their embeddings are initialized by averaging corresponding artificial tweets. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how to address these issues or improve the evaluation process. The feedback provides some insight into potential weaknesses but does not offer actionable steps for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to compare their proposed model with existing models where answers are also used as inputs, specifically mentioning \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" This direct request provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests comparing the proposed model with existing models where answers are used as inputs, specifically mentioning \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to compare with existing models, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that ternary potential is a key factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the evaluation. The suggestion lacks detailed justification or examples, making it somewhat verifiable. The authors would need to infer the importance of this comparison and its potential impact, which limits the utility of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a key factor in the performance improvement of the proposed model, which is the use of ternary potential. It suggests that the authors compare their model with existing models that also use answers as inputs, specifically referencing \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by conducting a comparative analysis. By addressing this suggestion, the authors can better position their work within the existing literature and potentially demonstrate the unique contributions of their model. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out an odd design choice in the paper, specifically the trimming of questions after the first 10, and suggests that this choice is questionable, especially since the question model is a bag of words and not expensive to encode longer sequences. However, the comment does not provide explicit guidance on how the authors should address this issue or what alternative approaches might be considered. The action is implicit, as the authors need to infer that they should reconsider or justify this design choice, and it is vague because it lacks concrete suggestions or steps for improvement. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L254,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. This provides clear guidance on what aspect of the design choice is problematic. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words and not expensive to encode longer sequences. This claim is somewhat verifiable as it provides a logical reasoning based on the nature of the question model. However, it lacks specific examples or references to support the claim further, such as detailing why longer sequences might be beneficial or providing evidence of similar practices in other contexts. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific design choice in the paper, namely the trimming of questions after the first 10, and questions its rationale, especially in the context of a bag-of-words question model. This feedback is somewhat helpful as it prompts the authors to reconsider or justify this design choice, which could lead to improvements in the paper's methodology. However, the comment lacks depth and does not provide suggestions or alternative approaches for addressing the issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about the meaning of a specific expression in Equation (2), which implies that the authors should clarify this aspect in their paper. While the comment does not explicitly instruct the authors to make changes, it clearly identifies a specific area that requires clarification. The action is implicit but concrete, as it points to a particular part of the paper that needs further explanation. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Equation (2),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the meaning of the expression \\\"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$\\\" in Equation (2). This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the meaning of a specific expression in Equation (2). It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and descriptive, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the meaning of a specific expression in Equation (2), which is \\\"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$\\\". This question highlights a potential area of confusion or lack of clarity in the paper. By identifying this specific expression, the reviewer points out a possible point of misunderstanding that the authors need to address. However, the comment does not provide any suggestions or guidance on how the authors might clarify this expression or improve the explanation. While it identifies a specific issue, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies specific lines in the SuppMat that need to be corrected, providing clear and concrete actions for the authors to take. It specifies the exact lines and the correct color, symbol, and reference for each correction. This level of detail ensures that the authors know exactly what changes to make, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, such as L502, L507, and L509, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, such as changing the color of lines, symbols, and references. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual observations about the content of the SuppMat, specifically pointing out discrepancies in line numbers and symbols. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by identifying discrepancies in the SuppMat, such as incorrect color, symbols, and references. It clearly points out which lines need correction, offering the authors a precise way to improve the accuracy and clarity of their supplementary material. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make targeted improvements to their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies missing references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works. The comment provides clear and concrete actions for the authors to take, such as adding these references and conducting a comparison. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the missing references, GFF[1] and EfficientFCN[2], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment provides specific references and suggests a comparison, which supports the claim by offering concrete examples and guidance. However, it could be further strengthened by explaining why these references are relevant or how they relate to the paper's content. As it stands, the claim is mostly verifiable due to the explicit references and suggestions provided, but it could benefit from additional reasoning or context. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant omission in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, which is a clear and actionable suggestion. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript, which could be expanded upon. This feedback is mostly helpful as it provides specific guidance on how to enhance the paper's literature review and comparison, but it could be more helpful if it offered additional suggestions on how to integrate these references into the manuscript. Overall, the comment is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the practical performance of the proposed algorithms, specifically noting the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer expresses concern that the algorithm may fail in practice, especially for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. While the comment identifies a potential issue and suggests a way to address it, it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental results. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1\\\" and discusses the use of a Vandermonde matrix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the algorithm's practical performance due to the ill-conditioned nature of the Vandermonde matrix, especially for large $n$ and small $\\\\alpha$. The comment further suggests providing experimental results to support the paper's claims, offering clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the practical performance of the proposed algorithms, specifically questioning the use of a Vandermonde matrix in Algorithm 1. The reviewer provides a logical reasoning by explaining that the Vandermonde matrix is known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\\\alpha$. The concern is further substantiated by the mention that $\\\\alpha$ can be as small as $1/k^2L^2$, which could lead to potential failures in practice. The comment suggests that providing experimental results would strengthen the paper, offering a clear direction for improvement. While the claim is well-supported by logical reasoning and specific examples, it could be further strengthened with references to studies on the numerical stability of Vandermonde matrices. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the practical performance of the proposed algorithms, specifically questioning the use of a Vandermonde matrix in Algorithm 1. It highlights the known issues with the Vandermonde matrix being ill-conditioned and numerically unstable, especially for large $n$ and small $\\\\alpha$. The reviewer expresses worry that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that providing experimental results would strengthen the paper, offering a clear and actionable recommendation for improvement. This feedback is mostly helpful as it identifies a critical area for improvement and provides a specific suggestion for addressing the concern. However, it could be more helpful if it included specific guidance on how to conduct these experiments or what aspects to focus on. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper's practical contribution. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how to address the scalability challenge. The authors are left to infer that they need to consider scalability improvements, but without specific advice on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper's practical contribution. However, the comment does not explicitly mention which part of the paper discusses the NC measure, making it weakly grounded. The comment is specific in identifying the scalability issue and its potential impact on the paper's contribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions how this method can be learned and applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper's practical contribution. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The suggestion to address scalability is logical, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant concern regarding the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets like ImageNet, suggesting that addressing the scalability issue is crucial for the paper's practical contribution. While the comment highlights an important limitation, it does not provide specific suggestions or guidance on how to address the scalability challenge. The feedback prompts the authors to consider this issue, but without actionable advice, it remains somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that the proposed PSA method requires more computation than baselines and suggests that the comparison of computational complexity should be included in the experiment part. While the comment implies that the authors should add a comparison of computational complexity, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1\\\" and the specific issue of computational complexity, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computational complexity in the experiment part. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed PSA method requires more computation than baselines and suggests that a comparison of computational complexity should be included in the experiment part. However, the comment lacks specific examples or detailed reasoning to support the claim about the increased computational requirements. Without such evidence or references, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides an initial rationale but lacks sufficient detail to be fully verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than the baselines. It highlights a particular aspect of the method, namely the calculation of all flipped previous layer outputs into the current layer, and suggests that a comparison of computational complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their method by providing a comparison of computational complexity. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable insight into an area that needs attention but could be expanded with more detailed guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests specific changes to the figures, such as increasing the font size for certain elements like V_mem, Th_i, U_i^t, and the words in the grey box. It also recommends using a table to better emphasize the data and justify the improved accuracy. Additionally, it points out the lack of details comparison with other state-of-the-art Transformer designs, such as epochs and the number of parameters. Each of these suggestions is clear and actionable, providing the authors with specific guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific figures (Fig 1 and Fig 2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the fonts and the size of certain words, as well as the lack of details comparison with other state-of-the-art Transformer designs. The comment provides clear guidance on what needs to be addressed, including the use of a table to emphasize data and justify improved accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes several claims regarding the figures and the lack of details comparison with other state-of-the-art Transformer designs. The first part of the comment is somewhat verifiable as it suggests specific issues with the font sizes in figures, which could be addressed by increasing them. However, the second part of the comment about the lack of details comparison is not supported by specific examples or references, making it difficult for the authors to understand the basis of the claim. The suggestion to use a table for better emphasis is a logical suggestion but lacks detailed justification. Overall, the comment is somewhat verifiable due to the lack of comprehensive evidence and examples for the claims made.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on the presentation of figures, suggesting improvements such as increasing font sizes for certain elements and using a table to better emphasize data. It also points out the lack of details comparison with other state-of-the-art Transformer designs, which is a critical area for improvement. The comment is clear and constructive, offering concrete suggestions that can help the authors enhance the clarity and comprehensiveness of their paper. However, it could be more helpful if it included additional guidance on how to effectively use the table or more detailed suggestions on the lack of comparison. Overall, the comment is mostly helpful, as it provides valuable insights and directions for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the proposed method should be compared to \\\"ATA\\\" in Table 2, as it is reported to be better than \\\"FP\\\" in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include \\\"ATA\\\" in the comparison. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2\\\" and the \\\"leave one out setting,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of \\\"ATA\\\" in the comparison with \\\"+LFP.\\\" This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the proposed method should be compared to \\\"ATA\\\" in Table 2, as it is reported to be better than \\\"FP\\\" in Table 1. This claim is somewhat verifiable as it provides a logical reasoning based on the results presented in Table 1. However, the comment lacks specific examples or detailed reasoning to fully substantiate why including \\\"ATA\\\" would enhance the comparison. The authors would need to make a significant effort to understand and address the suggestion without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the paper. It points out that the proposed method is only compared to \\\"+LFP\\\" in Table 2, while \\\"ATA\\\" is reported to be better than \\\"FP\\\" in Table 1. The comment suggests including \\\"ATA\\\" in the comparison to make the results more convincing. This feedback is clear and directly addresses a potential gap in the experimental evaluation, offering a concrete step for the authors to enhance the robustness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a specific area where the paper lacks mathematical definition, particularly regarding the multi-head attention mechanism. It questions the presence of a split arrow in Figure 2 and asks for clarification on whether the same vectors are used for keys and values. The reviewer explicitly suggests providing a formal definition to aid readers in understanding the architecture. This feedback is explicit and provides concrete guidance on what needs to be clarified, making it highly actionable. The authors know exactly what information is missing and how to address it, ensuring they can make the necessary improvements to their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2 right, bottom right,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and questions the presence of a split arrow in the figure. The comment further asks for clarification on whether the same vectors are used for keys and values, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a question about the architectural details of the model, specifically regarding the multi-head attention mechanism. It points out the lack of mathematical definition and questions the presence of a split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. While the comment highlights areas that need clarification, it does not provide a subjective claim or opinion that requires verification. It is more of a request for additional information, making it a factual observation. Therefore, it should be labeled as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the paper lacks clarity, particularly in the mathematical definition of architectural details such as multi-head attention. It points out a particular element in Figure 2 that requires clarification, specifically the split arrow and its relation to the query, keys, and values in the attention layer. The comment also asks for clarification on whether the same vectors are used for keys and values, which is a crucial aspect for understanding the model's architecture. By highlighting these specific issues, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, it could be more helpful if it offered suggestions on how to present this information more effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and provides a basis for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific guidance or suggestions on how to improve the clarity or organization of the paper. Without explicit instructions or concrete details on what aspects of the presentation are problematic or how they could be improved, the authors are left without a clear path forward. The lack of actionable advice makes this comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are problematic or provide details on what aspects are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point states that \\\"the presentation of this paper is hard to follow for the reviewer.\\\" However, it does not provide any specific examples, reasoning, or suggestions to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how to improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. This lack of specificity and actionable advice makes the comment unhelpful, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should include and compare their work with specific related studies, such as the one by Li et al. (2017) on end-to-end task-completion neural dialogue systems and the one by He et al. (2015) on deep reinforcement learning with a natural language action space. The comment provides explicit actions by recommending the inclusion and comparison of these works, which helps the authors understand what needs to be done. However, it does not provide detailed guidance on how to integrate these comparisons into the paper or what specific aspects to focus on. Therefore, while the action is explicit, it is somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests including and comparing the current work with specific related studies, such as Li et al. (2017) and He et al. (2015), which are important for contextualizing the research. It also mentions the need for a general discussion on how the work differs from other chatbox research works. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the literature review or discussion sections. The suggestion is specific, as it outlines particular works to consider and the need for a comparative discussion. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the work should include and compare with specific related studies, such as Li et al. (2017) and He et al. (2015), to provide a more comprehensive context. The comment is somewhat verifiable as it provides specific references to works that could be relevant for comparison, but it lacks detailed reasoning or explanation on why these comparisons are necessary or how they would enhance the paper. The authors would need to further explore these references to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a clear and actionable suggestion by recommending the inclusion and comparison of the current work with specific related studies, such as Li et al. (2017) and He et al. (2015). This feedback is valuable as it guides the authors to situate their work within the broader context of existing research, particularly in the area of task-oriented recommendation and chatbox research. By suggesting specific works to compare with, the comment offers a concrete way for the authors to enhance the depth and relevance of their paper. However, the comment could be more helpful if it provided additional guidance on how to integrate these comparisons into the manuscript or what specific aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors clarify the difference between the meta solvers and centralized reinforcement learning (RL) where agents share weights. It provides a specific reference to Foester et al., which can guide the authors in understanding the context and potentially addressing the issue. While the comment does not explicitly instruct the authors to make this clarification, it provides a concrete example and a direction for improvement. The action is implicit but concrete, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment addresses the meta solvers and their relation to centralized reinforcement learning (RL), suggesting that the authors clarify the differences. It provides a specific reference to Foester et al., which can guide the authors in understanding the context. However, the comment does not explicitly mention which part of the paper discusses the meta solvers, making it weakly grounded. The authors can infer that it relates to sections discussing the methodology or results, but this inference is not direct. The comment is specific in suggesting a clarification and providing a reference, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the meta solvers are centralized controllers and recommends clarifying the difference between them and centralized reinforcement learning (RL) where agents share weights. The reviewer provides a specific reference to Foester et al., which is a well-known work in the field, to support the claim. This reference offers a concrete example that can help the authors understand the context and potentially address the issue. However, the comment could be strengthened by providing more detailed reasoning or examples of how the clarification would impact the paper. As it stands, the claim is mostly verifiable due to the reference provided, but it could benefit from additional explanation. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the clarity of the paper regarding the meta solvers and their relation to centralized reinforcement learning (RL). It suggests that the authors clarify the differences between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al., which can guide the authors in understanding the context and potentially addressing the issue. While the comment is clear and actionable, it could be more helpful if it included additional guidance on how to effectively clarify this distinction in the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing improvement and provides a reference for further exploration.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the phrase \\\"non-sequential information such as chunks,\\\" specifically questioning whether chunks are still considered sequential information. While the comment highlights a potential point of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the terminology, but it is vague because it lacks concrete steps on how to resolve the confusion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Line 285,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \\\"non-sequential information such as chunks,\\\" suggesting that the authors need to clarify whether chunks are still considered sequential information. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the terminology used in the paper. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks additional information, so \\\"No\\\" is the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific point of confusion regarding the terminology used in the paper, specifically questioning whether \\\"chunks\\\" are considered sequential information. This feedback is valuable as it highlights a potential misunderstanding or ambiguity in the manuscript that the authors need to address. However, the comment does not provide suggestions or guidance on how the authors might clarify this point, which limits its helpfulness. While it points out an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. The reviewer suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes using bilinear sampling to zoom in on the region of interest for better results. This feedback provides a clear and explicit action for the authors to take, specifically addressing the discrepancy and suggesting a potential improvement. The comment is concrete, as it outlines the issue and offers a specific solution, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"eq. 9\\\" and \\\"Figure 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or just masked versions. The comment further suggests a potential improvement by proposing the use of bilinear sampling to zoom in on the region of interest. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a claim about a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. The reviewer provides a logical reasoning by explaining the potential issue with Figure 1 being misleading if the output patches are indeed masked versions. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The suggestion to use bilinear sampling for better results is a logical suggestion but not a claim requiring verification. Therefore, the comment is classified as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It provides a clear and actionable suggestion by proposing that if the output patches are indeed masked versions, Figure 1 is misleading. The comment further suggests using bilinear sampling to zoom in on the region of interest for better results. This feedback is highly helpful as it not only points out a potential issue but also offers a specific and constructive suggestion for improvement, empowering the authors to address the discrepancy and enhance the clarity of their work. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out a lack of technical novelty in the paper, noting that the ideas, co-attention mechanism, and architecture are similar to previous works by Xing and Tsang (2022a, b). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or differentiate their work. There is no guidance on potential improvements, alternative approaches, or additional experiments that could enhance the technical novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the technical novelty of the paper by comparing it to two specific papers by Xing and Tsang (2022a, b). However, it does not specify which part of the paper this comparison should be made, nor does it provide details on how the ideas, co-attention mechanism, and architecture are similar to the previous works. This lack of grounding makes it difficult for the authors to identify where the comparison should be made or what specific aspects need to be addressed. Additionally, the comment lacks specificity regarding how the authors might address the issue of limited technical novelty. Therefore, this comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks technical novelty by comparing it to two previous works by Xing and Tsang (2022a, b). The comment suggests that the ideas, co-attention mechanism, and architecture are similar to those in the previous papers. However, the comment does not provide specific details or examples from the mentioned papers to substantiate the claim of similarity. This lack of detailed comparison or references makes the claim somewhat verifiable, as the authors would need to further investigate the cited works to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment points out a lack of technical novelty in the paper, noting that the ideas, co-attention mechanism, and architecture are similar to those in previous works by Xing and Tsang (2022a, b). While it identifies a potential issue, the comment does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a specific issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It suggests that the comparison is unfair because PMEF lacks a pre-training module, and recommends comparing CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF's innovative pre-training module design. This feedback provides a clear and explicit action for the authors to take, which is to include an additional comparison with a pre-trained model. The suggestion is concrete, as it specifies which model to use for the comparison and what aspect of the comparison is being questioned. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3\\\" and the specific lines \\\"line 529-lin534,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a fair comparison between CPEF and PMEF due to PMEF's lack of a pre-training module. The comment suggests a specific alternative for comparison, ExpertBert, to ensure fairness. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the fairness of the comparison between CPEF and PMEF, noting that PMEF lacks a pre-training module. The reviewer suggests that to ensure fairness, CPEF should be compared with another pre-trained model, such as ExpertBert. This claim is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or references to substantiate the claim fully. The suggestion to compare with ExpertBert is a reasonable suggestion, but the comment could be strengthened with more detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pre-training module, which makes the comparison unfair. The comment provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF's innovative pre-training module design. This feedback is highly helpful as it not only highlights a specific weakness but also offers a concrete solution for the authors to improve the fairness and validity of their comparisons. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
