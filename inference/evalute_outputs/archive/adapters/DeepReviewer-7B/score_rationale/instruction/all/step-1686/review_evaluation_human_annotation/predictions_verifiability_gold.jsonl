{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims need more analysis or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to perform more analysis but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to, nor does it provide details on what aspects of the analysis are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively identify the parts of the paper that need attention or improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not provide specific examples of which claims are lacking depth or how they could be improved. Without detailed reasoning or examples, the claim remains vague and lacks sufficient support, making it difficult for the authors to understand which aspects need more analysis. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it lacks specificity and does not identify which claims are lacking depth or how the authors could enhance their analysis. Without detailed guidance or examples, the authors are left without clear direction on how to improve their draft. This lack of actionable feedback makes the comment 2, as it points out an area for improvement but does not provide sufficient detail to guide the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It asks for clarification on the pooling method used for embedding features, specifically referencing line 397. Additionally, it points out that Equation (7) in line 472 is unclear and requests clarification on whether E_i represents the type or identity of AC i, as well as its modeling. The comment also suggests that the lefthand side of the equation might be a conditional probability. These requests are clear and specific, giving the authors direct guidance on what needs to be clarified or defined in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) and equations, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including whether E_i represents the type or identity of AC i and whether the lefthand side of the equation should be a conditional probability. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific concerns: the pooling method used for embedding features and the clarity of Equation (7). The reviewer questions the definition of E_i in Equation (7) and suggests that the lefthand side of the equation might be a conditional probability. While the comment identifies areas of potential confusion, it lacks detailed reasoning or references to support the claims. The authors would need to make an effort to understand and address these issues without additional context or explanation. Therefore, the comment is 3, as it provides some direction but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two key areas of the paper\"s presentation: the pooling method used for embedding features and the clarity of Equation (7). It asks for clarification on the definition of E_i in Equation (7), whether it represents the type or identity of AC i, and suggests that the lefthand side of the equation might be a conditional probability. This feedback is clear and directs the authors to specific areas where improvements are needed, offering a concrete path for enhancing the clarity and precision of their work. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing these issues. Overall, the comment is 4 as it identifies critical areas for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. While the action is explicit, it lacks concrete details on how to present this evidence or what specific aspects should be highlighted. The authors are given a clear direction to include empirical evidence but are left without detailed guidance on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests showing empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this contribution is located in, making it weakly grounded. The comment is specific in its request for empirical evidence, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim about the proposed algorithm\"s effectiveness in the Column Subset Selection problem. However, the comment does not provide any specific reasoning, examples, or references to substantiate why this evidence is necessary or how it would strengthen the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include additional evidence to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on how to present this evidence or what aspects to focus on. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. However, it does not provide specific guidance on how the authors could address this issue or differentiate their work from the cited works. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the novelty of their method. As a result, the comment is vague and 1, as it does not offer a clear path for the authors to follow. Therefore, it aligns with a score of 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It mentions specific works [1, 2, 3] and [4] that are relevant to the discussion. However, it does not specify which part of the paper should address these similarities or how the authors might differentiate their work. While the comment provides some context by referencing specific works, it lacks explicit references to sections or figures in the paper, making it weakly grounded. The comment is specific in its critique of the novelty and the similarity to existing methods but does not provide detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and ResNeSt. The reviewer supports this claim by referencing specific works [1, 2, 3] and [4], which are relevant to the discussion. However, the comment does not provide detailed comparisons or examples of how the proposed method differs from these existing works, which would strengthen the claim. The lack of explicit comparisons or detailed reasoning makes the claim 3, as the authors would need to further explore the references to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the novelty of the proposed method, noting its similarity to existing attentional modules and ResNeSt. It highlights the lack of discussion on the group attention design and its relation to ResNeSt, which could impact the perceived originality of the work. While the comment points out a critical issue, it does not provide specific suggestions or guidance on how the authors might differentiate their method or address the concerns about novelty. This limits the comment\"s usefulness, as it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights several issues with the paper, including the perceived immense workload, incremental contribution, and lack of citations for key baselines. It suggests that the authors should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment provides specific examples of missing citations and suggests what should be included, it does not explicitly instruct the authors to make these changes. The action is implicit but concrete, as the authors can infer that they need to address these issues by adding the suggested references and algorithms. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it refers to specific elements of the paper, such as the code and details in the article, and mentions specific works like GraphRAG, GraphCare, MedRetriever, and KGRAG. It provides clear guidance on what needs to be addressed, including the incremental contribution of the article, the lack of citations for key baselines, and the need to introduce essential RAG algorithms. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand the specific issues that need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental and suggests that it is essentially a combination of GraphRAG and GraphCare. The reviewer also points out the lack of citations for key baselines and suggests specific algorithms that should have been included, such as MedRetriever and KGRAG. This claim is supported by logical reasoning and references to specific works, providing a clear basis for the critique. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from the suggested baselines. Overall, the claim is 4 due to the logical reasoning and references provided, but it could benefit from additional detail to fully substantiate the argument.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It acknowledges the reviewer\"s observation about the immense workload but points out that the contribution is incremental. The comment also highlights the lack of citations for key baselines and suggests specific algorithms that should have been included, such as MedRetriever and KGRAG. This feedback is clear and actionable, offering the authors specific guidance on how to enhance the comprehensiveness and relevance of their work. By addressing these points, the authors can significantly improve the quality and impact of their paper. Therefore, the comment is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point provides a specific observation about the method described in line 490, noting that it is common practice to average over subword representations, as exemplified by a reference. However, it does not offer any explicit or implicit suggestions for improvement or clarification. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue or enhance their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 490, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that it is common practice to average over subword representations, as exemplified by a reference. This provides clear guidance on what aspect of the method is being critiqued. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that it is common practice to average over subword representations, as exemplified by a specific reference. This provides a clear and specific example to support the claim, making it 5. The reference to Hewitt and Manning (2019, footnote 4) offers a concrete basis for the claim, allowing the authors to understand and potentially address the issue. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment provides a specific observation about the method described in line 490, noting that it is common practice to average over subword representations, as exemplified by a reference. This feedback is valuable as it points out a potential oversight or area for improvement in the paper. However, the comment does not offer suggestions on how the authors might address this issue or improve their approach. While it identifies a specific point that could be clarified, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two works that have extended these noise conditions, suggesting that the authors consider these extensions. However, the comment does not provide explicit guidance on how the authors should incorporate these references or extend their work. The action is implicit and somewhat vague, as the authors need to infer that they should consider these extensions but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment discusses the bounded noise assumption and references specific works that have extended these noise conditions in stochastic optimization literature. However, it does not specify which part of the paper this critique is based on, such as a particular section or discussion where the bounded noise assumption is discussed. The authors might infer that it relates to the theoretical or methodological aspects of the paper, but this inference is not direct. The comment is specific in suggesting the need for better theory for SGD in the nonconvex world, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two specific works that have extended these noise conditions, providing a clear and precise justification for the claim. The inclusion of specific references to external works supports the claim, making it 5. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment acknowledges the bounded noise assumption as common but notes its restrictiveness in stochastic optimization literature. It references two specific works that have extended these noise conditions, suggesting that the authors consider these extensions. This feedback is 3 as it provides a direction for the authors to enhance their theoretical framework by referencing relevant literature. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these extensions or discussed their potential impact on the paper\"s findings. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the heuristic design of the modulator and the potential scalability issues that might arise from hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment lacks actionable details, such as recommending specific methods for improving scalability or suggesting alternative approaches to avoid hyperparameter tuning. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the design of the modulator and raises concerns about scalability issues and the need for hyperparameter tuning. However, it does not specify which part of the paper discusses the modulator or where these issues are mentioned, making it weakly grounded. The comment is specific in identifying the potential scalability issues and the need for hyperparameter tuning, providing some guidance on what might be problematic. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and raises concerns about scalability issues and the need for tedious hyperparameter tuning. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or a clear explanation of how these issues arise, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential issue with the heuristic design of the modulator, specifically mentioning the scalability issues and the need for tedious hyperparameter tuning. This feedback is 3 as it highlights a critical area that the authors need to address, which is the scalability and robustness of their method. However, the comment lacks specific suggestions or guidance on how the authors might improve the modulator\"s design or address the scalability concerns. Without actionable advice or detailed insights, the authors are left with a general idea of the problem but no clear path to resolve it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides concrete examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. The reviewer explicitly asks for clarification on these points, providing clear guidance on what needs to be addressed. This feedback is explicit and concrete, giving the authors a clear understanding of where and how to improve the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are difficult to read due to unclear explanations of previous approaches. It provides specific examples, such as the conversion of a stacked LSTM to a sequential LSTM and the unclear sentences in lines 43 and 96. These examples offer a detailed critique of the explanation, making the claim 4. However, the comment could be strengthened by providing more context or references to similar issues in other works, which would help the authors understand the basis of the critique more fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific areas where the paper\"s clarity is lacking, particularly in the first two sections. It provides detailed examples of unclear explanations, such as the conversion of a stacked LSTM to a sequential LSTM and the confusing sentences in lines 43 and 96. By pinpointing these specific issues, the comment offers clear and actionable feedback that can help the authors improve the clarity and readability of their draft. The detailed examples and specific questions guide the authors on where to focus their revisions, making this feedback 5. Therefore, the comment deserves a score of 5, indicating it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the paper\"s goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNetDas, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. While the comment identifies areas for improvement, it lacks explicit instructions or concrete steps on how to address these concerns. The authors are left to infer that they need to include comparisons and justify their method against existing work, as well as clarify the foundation model claim and demonstrate future applications. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises concerns about the paper\"s goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNetDas, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. However, the comment does not specify which part of the paper these concerns pertain to, such as the introduction, methodology, or results sections. While the authors might infer that it relates to the discussion of the paper\"s contributions or the experimental results, the lack of explicit references makes it weakly grounded. The comment is specific in detailing what needs to be addressed regarding comparisons and justifications, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal, specifically questioning the need for a comparison with existing DAS earthquake detectors like PhaseNetDas. The reviewer acknowledges the existence of such detectors and suggests that a comparison or justification against them is necessary. However, the comment lacks specific references or detailed reasoning to support the claim that a comparison is needed. While it provides a logical basis for the suggestion, the absence of concrete examples or references makes the claim 3. The authors would need to further explore the suggestion to fully address the concern, thus justifying a score of 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the paper\"s goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNetDas, is necessary. It also implies that if the claim is to establish a foundation model, the authors should clarify this and demonstrate future applications. This feedback is clear and actionable, as it provides specific areas for improvement, such as including comparisons and justifying the method\"s benefits against existing approaches. However, the comment could be more helpful if it offered suggestions on how to structure these comparisons or what specific aspects to focus on. Overall, the comment is 4, as it guides the authors toward enhancing the rigor and clarity of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR10 models\" robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should acknowledge these prior works, compare their results, or make any modifications to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR10 models\" robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. However, it does not specify which part of the paper these analyses are discussed in, nor does it provide detailed guidance on how the authors should address this feedback. The authors can infer that it relates to sections discussing robustness or adversarial training, but the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the need to acknowledge prior work and compare results, but without clear guidance on how to do so, it remains underspecific. Therefore, this comment is weakly grounded and underspecific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR10 models\" robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. The comment provides specific examples and references to support its claim, making it 5. The detailed references and examples allow the authors to understand the basis of the claim and how it relates to their work, ensuring that the authors can address the feedback effectively. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment acknowledges that similar analyses have been conducted in prior works, specifically mentioning the study on CIFAR10 models\" robustness on distribution shifts in RobustBench and the evaluation of adversarially trained models in references [A, B]. It highlights that the results are not particularly surprising, which suggests that the authors may be overemphasizing the novelty of their findings. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or improve their work. It lacks actionable feedback or constructive advice, making it difficult for the authors to make meaningful improvements based on this comment alone. Therefore, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, noting that it is difficult to be used in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance efficiency. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the problem of low efficiency and its impact on practical applications, providing some guidance on what the authors might need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the efficiency of pairwise matching, noting that it is difficult to be used in practical application systems. This is a relevant observation that could impact the applicability and usability of the method described in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their method. Without actionable feedback or detailed advice, the authors are left with only a general understanding of the problem but no clear path to resolve it. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this addition should be implemented, what specific improvements are expected, or how the authors can demonstrate the significance of their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what aspects of the method or contribution are being questioned. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks any supporting evidence, reasoning, or references to justify why this addition is not considered a significant contribution. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their contribution. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim of parameter efficiency for COCOLM by suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It raises a question about the experimental setup, specifically why the authors switched the types of BPE vocabulary (uncased and cased) and whether this change affects the variance of performance. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need to address these questions and may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and COCOLM, suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency and asks for clarification on the experimental setup, specifically regarding the switch in BPE vocabulary types. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its critique and questions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides examples of these related works to support the claim, which helps in understanding the context and validity of the critique. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies that demonstrate the similarity in performance. As it stands, the claim is 4 due to the inclusion of examples, but it lacks comprehensive evidence or detailed reasoning, aligning with a score of 4.", "helpfulness_rationale": "The review comment critiques the claim of parameter efficiency for COCOLM by suggesting that its performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the validity of the claim, which is a relevant point for the authors to address. The comment also raises a question about the experimental setup, specifically regarding the switch in BPE vocabulary types and its potential impact on performance variance. This feedback is 3 as it prompts the authors to reconsider their claims and provides a specific area for further exploration. However, it could be more helpful if it offered suggestions on how to address these concerns or provided additional context for the comparison. Overall, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the analysis from line 128 to 149, noting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, explaining that the GSP50 model has smaller class selectivity scores, implying that GSP50 shares more features while ResNet50 learns more classspecific features. The reviewer also references two external works that could provide additional context or support for the analysis. While the comment highlights areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more convincing explanation and potentially reference the provided works. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the analysis, explaining the observation about the GSP50 model having smaller class selectivity scores and its implications for feature sharing and representation learning. The comment further references external works, which can guide the authors in understanding and potentially addressing the critique. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. The reviewer provides specific observations from the histogram in Fig 3, explaining that the GSP50 model has smaller class selectivity scores, implying that GSP50 shares more features while ResNet50 learns more classspecific features. The reviewer further supports this claim by referencing external works that could provide additional context or support for the analysis. This detailed explanation and reference to external sources make the claim 4, as it provides a solid foundation for the critique. However, the comment could be further strengthened by including more specific examples or detailed reasoning from the referenced works. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from line 128 to 149 is not convincing enough. It provides a detailed explanation of the observation, stating that the GSP50 model has smaller class selectivity scores, which implies that GSP50 shares more features while ResNet50 learns more classspecific features. The reviewer further hypothesizes that additional context may allow the network to reduce its dependency and references external works that could provide additional context or support for the analysis. This feedback is clear and actionable, as it guides the authors to reconsider and strengthen their analysis by providing a more convincing explanation and potentially referencing relevant literature. However, the comment could be more helpful if it offered specific suggestions on how to improve the analysis or what aspects to focus on. Overall, the comment is 4, as it effectively directs the authors toward enhancing the robustness of their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the conclusions drawn in the paper, specifically questioning the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It suggests that the results might stem from limited exploration of combination methods and provides references to recent works that employ featurereplay methods, such as [R1] and [R2], as well as a more recent work [R3]. However, the comment does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve their conclusions or explore alternative methods. The action is implicit and somewhat vague, as the authors need to infer that they should consider the suggestions and references provided. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific conclusion in the paper, allowing the authors to identify the part of the paper being addressed. It also provides specific examples of recent works that employ featurereplay methods, such as [R1] and [R2], and a more recent work [R3], which helps the authors understand the context and potential improvements. This level of detail provides clear guidance on what needs to be addressed or improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the conclusions drawn in the paper, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works, such as [R1] and [R2], which employ featurereplay methods and have shown great potential in continual learning and category discovery, respectively. Additionally, the reviewer mentions a more recent work [R3] that also employs feature replay to continually adjust the feature space. This provides a robust foundation for the claim, making it 5. The inclusion of specific references and examples strengthens the argument, allowing the authors to understand and address the critique effectively.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the conclusions drawn in the paper, particularly the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. It provides a detailed critique by suggesting that the results might stem from limited exploration of combination methods. The comment further supports its point by referencing recent works, such as [R1] and [R2], which employ featurereplay methods and have shown great potential in continual learning and category discovery, respectively. Additionally, it mentions a more recent work [R3] that also uses feature replay to continually adjust the feature space. This feedback is 4 as it not only identifies a weakness in the paper but also offers specific references and examples of alternative approaches that could be considered. However, it could be more helpful if it provided actionable suggestions on how to address the identified issue or how to incorporate the referenced works into the paper. Overall, the comment provides valuable insights and direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not provide any specific guidance or suggestions on how the authors should address this observation or what actions they should take to mitigate any potential issues. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to apply this information to improve their draft. Since the action is implicit and vague, this comment is barely actionable.", "grounding_specificity_rationale": "The comment makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how to address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the observation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular areas where this dependence might be an issue or offering guidance on how to address it, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper\"s novelty is limited, as it appears to be a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It acknowledges that the paper transposes DeCorr\"s insights into graph collaborative filtering but notes that it lacks sufficient insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance or suggestions on how the authors could enhance the novelty or address the identified gaps. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It mentions the transposition of DeCorr\"s insights into graph collaborative filtering and acknowledges modifications like different penalty coefficients for users and items. However, the comment does not specify which sections or parts of the paper are being addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. While the comment provides some context about the paper\"s content, it lacks grounding as it does not direct the authors to specific sections or issues. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, to a specific application domain. The reviewer supports this claim by mentioning that the paper transposes DeCorr\"s insights into graph collaborative filtering and acknowledges modifications like different penalty coefficients for users and items. However, the comment does not provide specific examples or detailed reasoning to substantiate the claim of limited novelty. The lack of explicit references or detailed explanations makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as 3, as it provides some support but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, suggesting that it appears to be a straightforward application of existing literature, specifically DeCorr, to a specific application domain. It acknowledges the paper\"s contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones, and mentions modifications like different penalty coefficients for users and items. However, the comment notes that the paper lacks sufficient insights into the unique challenges of overcorrelation in recommender systems. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their work. This limits the comment\"s usefulness, making it 3 as it points out an area for improvement but lacks actionable feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or enhance the novelty of their work. There is no guidance on potential improvements, alternative approaches, or additional contributions that could be made to strengthen the paper\"s novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. However, it does not specify which sections or parts of the paper these aspects are discussed in, making it weakly grounded. The comment does specify the issue of limited novelty and the incremental contribution, providing some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. This claim is 3 as it provides a reference to an existing work ([10]) and highlights the incremental nature of the contribution. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the decomposition part is novel or how it differs from existing methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a perceived limitation in the novelty of the paper, specifically noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. While this feedback identifies a potential weakness in the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The comment lacks actionable advice or constructive feedback, leaving the authors with only a general understanding of the problem without clear direction on how to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It concludes that this reduction in whitespace effectively violates the 9page paper limit, justifying rejection. The comment provides a clear and direct action for the authors to take, which is to address the whitespace issue to comply with the page limit. The feedback is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, specifically pointing out that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the layout and how it violates the 9page paper limit. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This reduction in whitespace is presented as a violation of the 9page paper limit. However, the comment does not provide specific examples or detailed reasoning to support the claim of whitespace reduction or how it affects the layout. Without such evidence or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the layout of the paper, noting that the authors have reduced whitespace, causing equations to be crammed together and captions to be too close to the figures. This observation is significant as it directly relates to the paper\"s adherence to the 9page limit. By highlighting this issue, the comment provides clear and actionable feedback that can help the authors make necessary adjustments to improve the readability and formatting of their paper. However, the comment could be more helpful if it offered suggestions on how to address the whitespace issue or provided examples of better layout practices. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. It suggests that if the compared methods were not initialized with the same pretrained model, the proposed method\"s performance without SSL might be inferior. However, the comment does not provide explicit guidance on how the authors should address this issue, such as recommending a specific approach to ensure fair comparisons or suggesting additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust their experimental setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental comparison with other methods, specifically questioning the fairness of the comparison due to the proposed method\"s pretraining before finetuning. It references Table 1 to support the claim that the proposed method without SSL performs inferior to most compared methods. This provides a clear indication of what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the experimental results or comparisons section. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. The comment provides a logical reasoning by referencing Table 1, which shows that the proposed method without SSL performs inferior to most compared methods. This reference to a specific table provides some support for the claim, making it 4. However, the comment could be strengthened by providing more detailed evidence or examples of how the initialization of the compared methods might differ. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pretrained models as the proposed method. It highlights a potential issue with the proposed method\"s performance without SSL, suggesting that the comparison might be unfair. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue, such as recommending a standardized initialization or additional experiments to ensure a fair comparison. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a specific area in the paper where relevant literature on using moment matching for distributional reinforcement learning (DRL) is lacking. It suggests that this should be discussed when talking about various approaches to DRL, even though the paper currently uses quantile regression. The comment provides a clear and concrete action for the authors to take, which is to include a discussion of the mentioned literature. This guidance is specific and actionable, as it gives the authors a clear direction on how to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of relevant literature on using moment matching for distributional reinforcement learning (DRL) and suggests discussing this in the context of various approaches to DRL. The comment provides a specific reference to external work (NguyenTang et al AAAI\u201921) and suggests that this should be included in the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing NguyenTang et al. (AAAI\u201921) as an example. This claim is supported by providing a specific reference to external work, which helps substantiate the assertion. However, the comment could be strengthened by explaining how this literature is relevant to the paper\"s discussion on various approaches to DRL. Despite this, the inclusion of a specific reference makes the claim 4, as it provides a clear basis for the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper\"s literature review regarding the use of moment matching for distributional reinforcement learning (DRL). It points out the absence of relevant literature, such as the work by NguyenTang et al. (AAAI\u201921), which discusses moment matching in DRL. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the paper currently uses quantile regression. This feedback is clear and actionable, as it provides a specific reference and guidance on how to enhance the paper\"s literature review and discussion of DRL approaches. By addressing this point, the authors can improve the comprehensiveness and depth of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the novelty of the paper, stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance the originality of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper by stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the approach are considered lacking in novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, references, or detailed explanation to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a perceived limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper\"s results. It suggests that the assumptions underlying the use of PCA might not be wellmet and asks for clarification on this aspect. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve the paper. The feedback is somewhat vague, as it lacks concrete suggestions for enhancing the paper\"s novelty or significance. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce the interaction count and questions the significance of the paper\"s results. It provides a specific reference to a paper by Dombrowski et al. (2022) that discusses robust explanations for deep neural networks, which could be relevant to the discussion. However, the comment does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper\"s results. The reviewer provides a reference to a paper by Dombrowski et al. (2022) that discusses robust explanations for deep neural networks, which could be relevant to the discussion. However, the comment lacks a detailed explanation or specific examples from the referenced work that would substantiate the claim about the assumptions being met. While the reference provides some context, the comment could be strengthened with more explicit reasoning or examples to fully support the claim. Therefore, the comment is categorized as 3, as it provides some support but requires further elaboration to be 5.", "helpfulness_rationale": "The review comment questions the novelty of using PCA to reduce the interaction count and expresses uncertainty about the significance of the paper\"s results. It suggests that the assumptions underlying the use of PCA might not be wellmet and asks for clarification on this aspect. The comment also references a relevant work by Dombrowski et al. (2022) that could provide context for the discussion. While the comment identifies a potential weakness in the paper\"s approach and provides a reference for further exploration, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the assumptions and significance of their approach, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. The reviewer expresses reservations about the method\"s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models remains uncertain. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or expand the framework. The feedback lacks concrete steps or actionable advice, leaving the authors uncertain about how to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning the limitation in scope due to the restriction to three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests considering more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The comment is specific in detailing the limitations and potential areas for improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, restricted to only three QuestionAnswering tasks and two language models. The reviewer expresses reservations about the method\"s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. The suggestion to consider more advanced models like vicunna or alpaca adds some depth but still requires more detailed justification. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability and its potential to generalize to other reasoning or generation tasks or more advanced models. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the framework\"s scope. The feedback provides some insight into the issue but does not offer actionable steps for the authors to enhance their work. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is still room to improve the complexity of Algorithm 2, but it does not provide specific guidance or suggestions on how to achieve this improvement. The comment lacks explicit instructions or concrete details on what aspects of the algorithm\"s complexity could be enhanced or how the authors might address this issue. As a result, the authors are left without a clear understanding of what steps to take to improve the complexity of the algorithm. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that there is still room to improve the complexity of Algorithm 2, but it does not specify which part of the paper this refers to or provide details on what aspects of the algorithm\"s complexity could be improved. Without explicit references to sections, figures, or specific elements of Algorithm 2, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is still room to improve the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is still room to improve the complexity of Algorithm 2, but it lacks specificity and actionable guidance. It does not provide details on what aspects of the algorithm\"s complexity could be improved or how the authors might address this issue. Without specific suggestions or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. While it provides a general direction for improvement, it lacks specific guidance on how to make the introduction more concise or what specific empirical results should be included. The action is implicit and vague, leaving the authors with a general idea of what needs to be improved but without concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which sections or parts of the introduction need to be revised, making it difficult for the authors to pinpoint the exact areas that require improvement. Additionally, the comment lacks specificity regarding what aspects of the introduction should be made more concise or what empirical results should be included. This lack of detail and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and includes empirical results. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on how to achieve this conciseness or what specific empirical results should be included. Without actionable suggestions or examples, the authors may struggle to understand the exact changes needed to improve their draft. Therefore, the comment is 2, as it points out a general area for improvement but does not offer sufficient detail to be fully actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reproduce the main features of previous models to ensure a fair comparison. It implies that the current approach of applying regularization to both LN models and GLMs might not be the most appropriate way to compare the models. However, the comment does not provide explicit instructions on how to reproduce the main features of previous models or which specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of regularization applied to both LN models and GLMs, suggesting that the comparison might not be fair. It references the work of pillow et al. and mentions specific features like L1 regularization and low rank approximation, providing a clear direction for the authors to consider. However, the comment does not explicitly mention which part of the paper discusses the regularization or the models, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed regarding the comparison and the features of previous models. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the fairness of the comparison between the LN model and the GLM by noting that the GLM presented by pillow et al. did not use cropping but instead employed L1 regularization and a lowrank approximation. The reviewer suggests that reproducing the main features of previous models would make the comparison fairer. This claim is 3 as it references specific features of a previous model and suggests a potential adjustment to the current approach. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, requiring the authors to infer the details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the application of regularization to both LN models and GLMs, which may not be fair for comparison. It references the work of pillow et al. to highlight a discrepancy in the features used in previous models. The comment suggests that reproducing the main features of previous models would make the comparison fairer. While the feedback is clear in pointing out a potential flaw in the experimental setup, it lacks specific guidance on how to address this issue or what features should be reproduced. This limits the comment\"s helpfulness, as the authors are informed of a problem but not provided with detailed, actionable steps to resolve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include some failure cases and related discussion in their paper. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which specific failure cases to discuss or how to structure the discussion. The authors are given a clear direction but are left without detailed guidance on execution. Therefore, the comment is 3, as it provides an explicit action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this suggestion pertains to. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in terms of what it suggests\u2014including failure cases and discussion\u2014but lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including some failure cases and related discussion, but it does not provide any specific reasoning or examples to support why this would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of including failure cases and how it would improve the paper. As a result, the claim is 1.", "helpfulness_rationale": "The review comment suggests including some failure cases and related discussion in the paper. This feedback is 3 as it provides a clear direction for improvement, indicating that the authors should consider presenting scenarios where their method or findings fail and discussing these cases. However, the comment lacks depth and does not provide specific guidance on how to incorporate these failure cases or what aspects to focus on in the discussion. While it offers a general suggestion, it does not fully support the authors in making the improvements, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the claim about evolutional dropout addressing internal covariate shift is limited, specifically noting that it can only increase the variance of some lowvariance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. While the comment provides a clear direction for the authors to address the limitations of the claim, it does not offer specific guidance on how to incorporate this discussion into the paper. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the claim about evolutional dropout addressing internal covariate shift, suggesting that it can only increase the variance of some lowvariance units. It also mentions Batch Normalization as a method that standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the limitations of the claim and suggesting a discussion on these limitations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, specifically stating that it can only increase the variance of some lowvariance units. The reviewer supports this claim by contrasting it with Batch Normalization, which standardizes variance and centers activation. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutional dropout addressing internal covariate shift, noting that it can only increase the variance of some lowvariance units. It suggests that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, as it provides a specific area for improvement by highlighting a potential weakness in the paper\"s claims and suggesting a way to address it. However, the comment could be more helpful if it offered additional guidance on how to effectively discuss these limitations or provided examples of how to present this information. Overall, the comment is 4, as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to add more description about the contribution of their paper. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not provide specific guidance on what aspects of the contribution should be elaborated upon or how to effectively present this information. While the action is explicit, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of their paper. However, it does not specify which part of the paper this description should be added to or which aspects of the contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need additional description. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of their paper. However, it does not provide any specific reasoning, examples, or references to support why this addition is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should add more description about the contribution of their paper. While it identifies a specific area for improvement, it lacks depth and does not provide detailed guidance or examples on what aspects of the contribution should be elaborated upon. This limits the utility of the feedback, as the authors are left with a general suggestion without actionable steps to enhance their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" derivation is based on classical learning theorybased bounds, which may not yield realistic bounds without considering Bayesian considerations, such as BayesianPAC based bounds. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their derivation. There is no guidance on potential modifications, alternative approaches, or additional considerations that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, stating that it falls into classical learning theorybased bounds, which may not yield realistic bounds without considering Bayesian considerations. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the derivation are problematic or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" derivation is based on classical learning theorybased bounds, which may not yield realistic bounds without considering Bayesian considerations. The reviewer supports this claim by stating that BayesianPAC based bounds are a more realistic approach. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. The authors would need to further explore the comment to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" derivation, noting that it is based on classical learning theorybased bounds, which may not yield realistic bounds without considering Bayesian considerations. This feedback is 3 as it points out a theoretical limitation that the authors should consider. However, it lacks specific suggestions or guidance on how the authors might address this issue or incorporate Bayesian considerations into their work. Providing more detailed feedback or actionable steps would make the comment more helpful for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential influence of regularization effects on the observed improvements in the teacher\"s performance, suggesting that the improvements might not be solely due to distillation. It implies that the authors should conduct ablation studies to verify their claims, particularly regarding the finetuning process. While the comment suggests a specific action\u2014conducting ablation studies\u2014it does not provide detailed guidance on how to perform these studies or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the study of knowledge distillation and its impact on the teacher\"s performance. It highlights a potential issue with the claim that improvements are solely due to distillation, suggesting that regularization effects might be at play. The comment also points out the need for proper ablation studies to verify the findings, particularly regarding the finetuning process without earlystopping. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing the potential issue and suggesting a way to address it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential influence of regularization effects on the observed improvements in the teacher\"s performance, suggesting that the improvements might not be solely due to distillation. The reviewer provides some reasoning by noting that all finetuning is performed for 10 epochs without earlystopping, which typically leads to high variances in finetuning on GLUE without validation. However, the comment lacks specific examples or references to support the claim about regularization effects or to illustrate the need for proper ablation studies. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that improvements in the teacher\"s performance are solely due to distillation. It suggests that the observed improvements might be influenced by regularization effects rather than the distillation process itself. The comment highlights the need for proper ablation studies to verify the claim, particularly regarding the finetuning process without earlystopping. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to validate their claims. However, it could be more helpful if it provided specific suggestions on how to design these ablation studies or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward a critical area for further investigation and validation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the contribution of their work. The comment lacks actionable details, such as recommending ways to enhance the model\"s contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered incremental or how the contribution is limited. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point makes a claim that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1.", "helpfulness_rationale": "The comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or suggestions on how the authors might address these concerns or improve the contribution of their work. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tradeoff between computation time and information content in the proposed method compared to a baseline. It highlights the reduction in search space to ancestral graphs and the resulting loss of information compared to the baseline\"s richer search space (DAGs). However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. It lacks actionable details, such as recommending ways to mitigate the information loss or suggesting additional experiments to explore the impact of this tradeoff. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the tradeoff between computation time and information content in the proposed method compared to a baseline. It mentions the reduction in search space to ancestral graphs and the resulting loss of information compared to the baseline\"s richer search space (DAGs). However, it does not specify which part of the paper discusses this tradeoff, making it weakly grounded. The comment is specific in detailing the issue of information loss and the price paid for better performance, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method reduces computation time by reducing the search space to ancestral graphs, which results in less information compared to the baseline method that uses a richer search space (DAGs). The comment provides a logical reasoning by explaining the tradeoff between computation time and information content. However, it lacks specific examples or references to substantiate the claim about the information loss in ancestral graphs. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a tradeoff between computation time and information content in the proposed method compared to a baseline. It points out that while the method achieves faster computation by reducing the search space to ancestral graphs, it results in less information compared to the baseline\"s richer search space (DAGs). The comment raises an important question about the information encoded in an ancestral graph, which could prompt the authors to further explore or justify this aspect of their method. However, the comment lacks specific suggestions or guidance on how the authors might address this tradeoff or improve their draft. While it identifies a relevant issue, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of a case study from another paper, which can serve as a reference for the authors. The comment explicitly states the need for case studies and provides a concrete example, making it clear what the authors should do to improve their draft. The action is explicit and concrete, providing the authors with a clear direction on how to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including case studies and error studies to demonstrate the effectiveness of the proposed components. It provides a specific example of a case study from another paper, which can serve as a reference for the authors. However, the comment does not explicitly mention which part of the paper should include these case studies, making it weakly grounded. The suggestion is specific, as it outlines a particular approach to enhance the paper\"s credibility. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including case studies and error studies would strengthen the paper by demonstrating the effectiveness of the proposed components. The reviewer provides a specific example of a case study from another paper, which serves as a reference for the authors. This example helps to substantiate the claim that case studies are necessary to substantiate the effectiveness of the proposed components. However, the comment could be strengthened by providing more detailed reasoning or additional examples of how these studies would enhance the paper. As it stands, the claim is 4 due to the reference to an external example, but it lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of the proposed components. It acknowledges the paper\"s mention of the Elementlevel Graph Pretraining and highlights the need for empirical evidence to substantiate its claims. The comment offers a specific example of a case study from another paper, which can serve as a reference for the authors. This feedback is clear and actionable, guiding the authors on how to strengthen their work by providing empirical evidence. However, it could be more helpful if it included additional guidance on how to design or implement these case studies. Overall, the comment is 4, as it provides valuable direction for enhancing the paper\"s credibility and impact."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to analyze and compare the computational complexity, but it remains vague because it lacks concrete steps or specific recommendations on how to conduct this analysis. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure where computational complexity is discussed. While the authors might have an idea of where computational complexity is addressed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand but does not provide detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also mentions the potential impact on power demand if the method is applied on a mobile device. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about computational complexity or power demand. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions. It highlights a potential concern regarding power demand if the method is applied on a mobile device. While the comment identifies a relevant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is 3 as it prompts the authors to consider the computational efficiency of their method, but it could be more beneficial with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an inaccuracy in the authors\" description of the base IOI circuit, specifically regarding the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token. The reviewer explicitly states that this is incorrect according to Section 3 of Wang et al., 2023, and provides a correction by clarifying that these heads are active at the S2 token but do not primarily attend to it. This feedback is explicit and provides a clear action for the authors to correct their description, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific claim made by the authors regarding the base IOI circuit and the attention of certain heads to the S2 token. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is incorrect in the authors\" description, pointing out that the heads are active at the S2 token but do not primarily attend to it. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the authors\" statement about the base IOI circuit, specifically regarding the primary attention of certain heads to the S2 token. The reviewer provides a reference to Section 3 of Wang et al., 2023, which supports the claim that the heads are active at the S2 token but do not primarily attend to it. This reference provides a clear and specific basis for the claim, making it 5. The detailed explanation and external reference allow the authors to understand and address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific inaccuracy in the authors\" description of the base IOI circuit, pointing out that the Induction, Duplicate Token, and Previous Token heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their description based on the evidence provided in Wang et al., 2023. By addressing this specific issue, the authors can improve the accuracy and credibility of their work. The comment is 5 as it provides a precise and constructive suggestion for revision, empowering the authors to make significant improvements to their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the vagueness of certain statements in the paper, particularly regarding the use of RNNs for natural language reasoning tasks and the reinforcement learningagent analogy. It suggests that the authors should clarify these points and consider using examples from the literature on natural language inference or the SNLI leaderboard to support their claims. Additionally, it advises the authors to reconsider the reinforcement learningagent analogy and focus on generalization capabilities illustrated by later examples in the paper. While the comment provides explicit suggestions for improvement, it could be more actionable if it included detailed guidance on how to implement these changes. Overall, the comment is 4 as it gives clear directions for improvement, but it could be more detailed in its execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) and provides context by referencing the literature on natural language inference and the SNLI leaderboard. It also specifies the issue with the reinforcement learningagent analogy, suggesting that it seems outofplace and that generalization capabilities are better illustrated by later examples. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand the specific issues that need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the vagueness of certain statements regarding RNNs and their application to natural language reasoning tasks, referencing the literature on natural language inference and the SNLI leaderboard as evidence. This provides a clear and specific reference to support the claim, making it 4. However, the comment could be further strengthened by providing more detailed examples or explanations of how the literature supports the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the statement about RNNs working well for certain natural language reasoning tasks is too vague and suggests that the authors should reference the literature on natural language inference and the SNLI leaderboard for more precise information. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity and specificity of their claims. Second, the comment critiques the reinforcement learningagent analogy as being outofplace and suggests that the paper should focus on generalization capabilities illustrated by later examples. This feedback is also actionable, as it provides a constructive suggestion for improving the coherence and focus of the paper. Overall, the comment is 4 as it offers specific and actionable feedback that can guide the authors in refining their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method is not wellpositioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It provides specific examples, such as the original denoising score matching objective and scoreinterpolation, and recommends a thorough literature review. The comment explicitly instructs the authors to conduct a literature review, providing a clear action and concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment critiques the positioning of the proposed method in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It provides specific references, such as the original denoising score matching objective and scoreinterpolation, to support its claim. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the literature review. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, specifically noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by providing specific references to the original denoising score matching objective and scoreinterpolation, suggesting that this property is used in many more works. This detailed reference to existing literature provides a robust foundation for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the positioning of the proposed method in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already wellknown and has been used in previous works, such as the original denoising score matching objective and scoreinterpolation. The comment suggests that the authors conduct a thorough literature review to acknowledge and differentiate their work from existing literature. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by situating their work within the existing body of knowledge. However, the comment could be more helpful if it offered specific suggestions on how to conduct the literature review or which works to consider. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is limited and lacks significant technical contribution and extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contribution and extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a perceived limitation in the technical contribution of the paper, suggesting that it lacks significant technical contribution and extension based on a typical model for the crossdomain recommendation setting. However, it does not provide specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or detailed critique, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the approach\"s components, noting that the weak predictor used (MLP, Regression Tree, or Random Forest) and the sampling strategy are not novel, as they have been used in previous works. It also mentions that the results of the proposed WeakNAS are similar to those of BRPNAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or performance of the proposed method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor used (MLP, Regression Tree, or Random Forest) and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by comparing the proposed approach to previous works, such as [2,3,7] and BRPNAS[5], and notes that the results are similar. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the components of the approach are not novel, specifically mentioning the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used in previous works. It also notes that the sampling strategy is similar to epsilongreedy and exactly the same as that in BRPNAS. The comment further supports its claim by referencing specific works ([2,3,7] and BRPNAS[5]) and comparing the results of the proposed WeakNAS to those of BRPNAS. This detailed comparison and reference to existing literature provide a robust foundation for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment points out that the components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It specifically mentions that the weak predictor is similar to those used in NAS performance prediction and that the sampling strategy is the same as in BRPNAS. Additionally, it notes that the results of the proposed WeakNAS are almost the same as BRPNAS. This feedback is 3 as it identifies a lack of novelty in the approach and provides references to previous works, which could guide the authors in understanding and addressing the issue. However, it does not offer specific suggestions or actionable steps for the authors to enhance the novelty or differentiate their work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. However, it does not provide explicit guidance on how to incorporate the Kialo dataset into the paper or how to use it as extra data for learning. The action is implicit, as the authors need to infer that they should consider using the Kialo dataset, and it is vague because it lacks concrete steps on how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using the Kialo dataset as an alternative to the dataset created by the authors, highlighting its suitability due to its cleanliness and lack of automatic processes. However, it does not specify which part of the paper discusses the dataset creation or its potential impact, making it difficult for the authors to pinpoint the exact section that needs revision. While the suggestion is specific in terms of recommending an alternative dataset, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is wellstudied and cleaner. The claim is supported by logical reasoning, as the Kialo dataset is described as providing pairs of short claims and their counters, making it suitable for the authors\" needs. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would benefit from more detailed justification or references to fully understand the basis of the suggestion.", "helpfulness_rationale": "The review comment suggests an alternative dataset, the Kialo dataset, which is wellstudied and cleaner than the dataset created by the authors. It acknowledges that the dataset creation is optional and provides a rationale for using the Kialo dataset as an alternative. However, the comment does not offer specific guidance on how to integrate the Kialo dataset into the paper or how it might enhance the study. While it provides a useful suggestion, the lack of actionable steps or detailed advice limits its helpfulness. Therefore, the comment is 3, as it offers insight but not comprehensive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected largescale dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset scale. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting a comparison with methods using similar dataset sizes or recommending a specific approach to ensure a fair evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should consider dataset size as a factor in their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the fairness of the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset and comparing it to existing methods that use smaller datasets, such as GEM with 20M unlabeled data. This provides a clear indication of the part of the paper being addressed, making it fully grounded. The comment also specifies the issue, which is the potential impact of dataset scale on accuracy, and suggests that the superior performance might be due to the larger dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected largescale dataset, while existing methods use smaller datasets. The reviewer provides a specific example, mentioning that GEM employs only 20M unlabeled data, to illustrate the potential impact of dataset scale on accuracy. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or datasets that have used similar scales, which would provide more robust evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods. It points out that the proposed method\"s superior performance might be attributed to the use of a newly collected largescale dataset, while existing methods use smaller datasets. This is a critical observation that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as conducting additional experiments with similar dataset sizes or providing a more detailed analysis of the dataset\"s impact on performance. While the feedback highlights an important consideration, it could be more helpful with additional guidance on how to address the concern. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT or XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest ngram features. This comment provides a clear and explicit action for the authors to take, specifying the use of pretrained models and the focus on comparing transfer parts. The suggestion is concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT or XLNet as the base encoder for all methods and then comparing the efficacy of the transfer parts instead of using the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the domain adaptation or transfer learning sections, but this inference is not direct. The comment is specific in suggesting a particular approach to improve the paper, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that using powerful pretrained language models like BERT or XLNet as the base encoder can help overcome the domainshift problem in NLP. The claim is supported by logical reasoning, as these models are known to perform well in various NLP tasks and can adapt to different domains. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would benefit from more detailed evidence or references to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of powerful pretrained language models like BERT or XLNet as the base encoder for all methods. It suggests comparing the efficacy of the transfer parts instead of using the simplest ngram features. This feedback is specific and offers a concrete direction for enhancing the paper\"s methodology and potentially improving its performance. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it might be beneficial. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several specific areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It explicitly points out the need for clarification on the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. Each of these points provides a clear action for the authors to take, making the comment 5. The explicit nature of the feedback and the detailed guidance on what needs to be clarified make it easy for the authors to address the issues raised in the comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail regarding the techniques used in the paper, allowing the authors to identify the specific areas that need clarification. It is also specific because it details several unresolved questions, such as the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail regarding the techniques used, making it difficult to reproduce the results. It provides specific examples of areas where more information is needed, such as the sparsification process, landmark generation, and the selection of landmark features. However, the comment does not provide references or detailed explanations to support these claims, leaving the authors to infer the importance of these details. While the comment identifies specific gaps, it lacks comprehensive justification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several specific areas where the paper lacks detail, which is crucial for reproducibility. It highlights the need for clarification on the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. By pinpointing these gaps, the comment provides clear and actionable feedback that can guide the authors in expanding their manuscript to include the necessary details for reproducibility. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information might be needed. Overall, the comment is 4 as it directs the authors to critical areas needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the FIITED approach, specifically the reliance on utility scores for determining chunk significance. It suggests that this approach might introduce biases, such as premature evictions of valuable chunks due to recent chunks having temporarily high utility scores. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or mitigate the potential biases. The feedback lacks concrete steps or recommendations, leaving the authors uncertain about how to improve their draft in response to this concern. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the core of the FIITED approach, specifically the utilitybased approach for determining chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, suggesting that this could introduce biases. However, the comment does not specify which part of the paper discusses the utilitybased approach or where the potential biases are introduced, making it weakly grounded. The comment is specific in identifying the issue with the utilitybased approach and the potential for premature evictions, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the FIITED approach, specifically the utilitybased method for determining chunk significance. It suggests that relying solely on utility scores could introduce biases, such as premature evictions of valuable chunks due to recent ones having temporarily high utility. However, the comment lacks specific examples or references to support the claim of potential biases. While it provides a logical reasoning for the concern, the absence of detailed evidence or examples makes the claim 3. The authors would need to further explore and substantiate the claim themselves, justifying a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the FIITED approach, specifically the reliance on utility scores for determining chunk significance. It highlights a concern that this approach might introduce biases, such as premature evictions of valuable chunks due to recent ones having temporarily high utility scores. While the comment raises an important point about the potential for bias, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential biases. The feedback provides some insight into a potential weakness but does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance and contribution of different parts of the framework, both in terms of methodology and experimental results. It points out the absence of quantitative experiments, comparisons between algorithms, or detailed explanations of the framework\"s components. The comment implies that the authors should provide more information to clarify the performance of the framework and its individual parts. While the action is implicit, it is concrete because it specifies what is missing\u2014quantitative experiments, comparisons, and detailed explanations. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the clarity of the framework\"s performance and contribution, both in terms of methodology and experimental results. It points out the lack of quantitative experiments, comparisons between algorithms, or detailed explanations of the framework\"s components. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing\u2014quantitative experiments, comparisons, and detailed explanations\u2014providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the framework\"s performance and contribution, noting the absence of quantitative experiments, comparisons between algorithms, or detailed explanations. The comment suggests that the lack of these elements makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the specific areas that require more detail, thus justifying a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contribution. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the framework\"s components. This feedback is valuable as it highlights areas where the authors can improve their draft by providing more comprehensive experimental analysis and detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or comparisons. Overall, the feedback is 3 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer implies that such a comparison is necessary to substantiate the claim that the schema searched by ELF (the author\"s method) is better than the schema in MVF. While the comment identifies a specific area that needs attention, it does not provide explicit instructions on how to conduct this comparison or what specific aspects should be focused on. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with MVF\"s image classification results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014a comparison with the image classification results of MVF\u2014and how this would help substantiate the claim that the schema searched by ELF is better than the schema in MVF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by pointing out the lack of a direct comparison, which would be necessary to substantiate the claim that the schema searched by ELF is better than the schema in MVF. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It highlights the lack of a comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for substantiating the claim that the schema searched by ELF (the author\"s method) is better than the schema in MVF. This feedback is clear and actionable, as it directs the authors to include a comparison with MVF\"s results to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the originality of the article\"s reasoning and writing logic, noting similarities to a previous study. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or differentiate their work from the previous study. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance originality. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article\"s reasoning and writing logic, comparing it to a previous study. However, it does not specify which parts of the article are similar to the referenced work, making it difficult for the authors to identify the specific areas that need attention. Additionally, the comment lacks specificity regarding what aspects of the originality concerns should be addressed or how the authors might differentiate their work. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the originality of the article\"s reasoning and writing logic, suggesting similarities to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The lack of explicit references or detailed reasoning makes it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is 2, as it provides some indication of a potential issue but lacks sufficient evidence or detail to fully support the claim.", "helpfulness_rationale": "The comment raises a concern about the originality of the article\"s reasoning and writing logic, noting similarities to a previous study. It questions whether the work is merely an extension of that study or if it introduces novel contributions. While this feedback highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work. The lack of actionable advice limits the comment\"s usefulness to the authors, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify these aspects or what particular elements are unclear. The authors are left to infer that they need to improve the clarity of their problem formulation, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these examples are in. Without explicit references to sections, figures, or specific examples, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific details or examples to support this claim, nor does it explain why the formulation is unclear or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks depth and does not provide actionable guidance or suggestions on how the authors might improve the clarity of their problem formulation. Without specific examples or detailed feedback, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bitserial accelerators. It also notes that most existing ML accelerators use bitparallel fixedpoint numbers, which could limit the implications of the proposed methodology. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their methodology in light of these observations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of dynamic precision control during training, specifically mentioning bitserial accelerators and contrasting them with the bitparallel fixedpoint numbers used in most existing ML accelerators. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential limitations of the proposed methodology due to the mismatch between the accelerator architecture and the methodology\"s requirements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bitserial accelerators. It contrasts this with the common use of bitparallel fixedpoint numbers in existing ML accelerators, implying that this could limit the implications of the proposed methodology. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim fully. While it provides a logical basis for the concern, the absence of concrete evidence or examples makes it 3. The authors would need to further explore the reasoning themselves to fully understand and address the critique.", "helpfulness_rationale": "The review comment raises a concern about the applicability of dynamic precision control during training, suggesting that it might only show meaningful performance gains on bitserial accelerators. It points out that most existing ML accelerators use bitparallel fixedpoint numbers, which could limit the implications of the proposed methodology. While the comment identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it highlights a critical consideration for the authors, but it lacks actionable advice or detailed insights that would empower the authors to make significant improvements to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment criticizes the novelty of the idea, stating that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or address the limitations mentioned. The feedback lacks actionable details, such as recommending ways to make the metric and method more innovative or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the idea and suggests that both the new metric and method are straightforward. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint where improvements are needed. Additionally, the comment lacks specificity regarding what aspects of the metric and method are considered straightforward or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment criticizes the novelty of the idea, stating that both the new metric and method are straightforward. However, it does not provide specific examples or detailed feedback on what aspects of the metric and method are considered straightforward, nor does it suggest ways to enhance the novelty or innovation of the work. Without actionable guidance or constructive suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to enhance clarity. While the feedback provides explicit actions for the authors to take, it lacks concrete details on how to implement these changes, such as specific examples of where to break down the process or how to structure the notation table. The authors are given a general direction but without detailed guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the generative process and the use of too many symbols and a notation table. However, it does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in suggesting that the generative process should be presented in separate steps and that a notation table could improve clarity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table. While the comment provides some reasoning for the suggestion, it lacks specific examples or detailed justification for why these changes would enhance understanding. The claim is 3, as it offers a general direction for improvement but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the model description, suggesting that the generative process should be presented in separate steps to enhance understanding. It also points out the excessive use of symbols and the need for a notation table to improve clarity. While the comment provides actionable feedback, it lacks detailed guidance or examples on how to implement these changes effectively. The authors are given a general direction for improvement, but the feedback could be more comprehensive and specific to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies missing references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works. The comment provides clear and concrete actions for the authors to take, such as adding these references and conducting a comparison. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, GFF[1] and EfficientFCN[2], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment provides specific references and suggests a comparison, which supports the claim by offering concrete examples and guidance. However, it could be further strengthened by explaining why these references are relevant or how they relate to the paper\"s content. As it stands, the claim is 4 due to the explicit references and suggestions provided, but it could benefit from additional reasoning or context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, which is a clear and actionable suggestion. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript, which could be expanded upon. This feedback is 4 as it provides specific guidance on how to enhance the paper\"s literature review and comparison, but it could be more helpful if it offered additional suggestions on how to integrate these references into the manuscript. Overall, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how to address the scalability challenge. The authors are left to infer that they need to consider scalability improvements, but without specific advice on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. However, the comment does not explicitly mention which part of the paper discusses the NC measure, making it weakly grounded. The comment is specific in identifying the scalability issue and its potential impact on the paper\"s contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions how this method can be learned and applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The suggestion to address scalability is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet, suggesting that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights an important limitation, it does not provide specific suggestions or guidance on how to address the scalability challenge. The feedback prompts the authors to consider this issue, but without actionable advice, it remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests specific changes to the figures, such as increasing the font size for certain elements like V_mem, Th_i, U_i^t, and the words in the grey box. It also recommends using a table to better emphasize the data and justify the improved accuracy. Additionally, it points out the lack of details comparison with other stateoftheart Transformer designs, such as epochs and the number of parameters. Each of these suggestions is clear and actionable, providing the authors with specific guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Fig 1 and Fig 2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the fonts and the size of certain words, as well as the lack of details comparison with other stateoftheart Transformer designs. The comment provides clear guidance on what needs to be addressed, including the use of a table to emphasize data and justify improved accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the figures and the lack of details comparison with other stateoftheart Transformer designs. The first part of the comment is 3 as it suggests specific issues with the font sizes in figures, which could be addressed by increasing them. However, the second part of the comment about the lack of details comparison is not supported by specific examples or references, making it difficult for the authors to understand the basis of the claim. The suggestion to use a table for better emphasis is a logical suggestion but lacks detailed justification. Overall, the comment is 3 due to the lack of comprehensive evidence and examples for the claims made.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the presentation of figures, suggesting improvements such as increasing font sizes for certain elements and using a table to better emphasize data. It also points out the lack of details comparison with other stateoftheart Transformer designs, which is a critical area for improvement. The comment is clear and constructive, offering concrete suggestions that can help the authors enhance the clarity and comprehensiveness of their paper. However, it could be more helpful if it included additional guidance on how to effectively use the table or more detailed suggestions on the lack of comparison. Overall, the comment is 4, as it provides valuable insights and directions for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include and compare their work with specific related studies, such as the one by Li et al. (2017) on endtoend taskcompletion neural dialogue systems and the one by He et al. (2015) on deep reinforcement learning with a natural language action space. The comment provides explicit actions by recommending the inclusion and comparison of these works, which helps the authors understand what needs to be done. However, it does not provide detailed guidance on how to integrate these comparisons into the paper or what specific aspects to focus on. Therefore, while the action is explicit, it is somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests including and comparing the current work with specific related studies, such as Li et al. (2017) and He et al. (2015), which are important for contextualizing the research. It also mentions the need for a general discussion on how the work differs from other chatbox research works. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the literature review or discussion sections. The suggestion is specific, as it outlines particular works to consider and the need for a comparative discussion. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the work should include and compare with specific related studies, such as Li et al. (2017) and He et al. (2015), to provide a more comprehensive context. The comment is 3 as it provides specific references to works that could be relevant for comparison, but it lacks detailed reasoning or explanation on why these comparisons are necessary or how they would enhance the paper. The authors would need to further explore these references to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by recommending the inclusion and comparison of the current work with specific related studies, such as Li et al. (2017) and He et al. (2015). This feedback is valuable as it guides the authors to situate their work within the broader context of existing research, particularly in the area of taskoriented recommendation and chatbox research. By suggesting specific works to compare with, the comment offers a concrete way for the authors to enhance the depth and relevance of their paper. However, the comment could be more helpful if it provided additional guidance on how to integrate these comparisons into the manuscript or what specific aspects to focus on. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors clarify the difference between the meta solvers and centralized reinforcement learning (RL) where agents share weights. It provides a specific reference to Foester et al., which can guide the authors in understanding the context and potentially addressing the issue. While the comment does not explicitly instruct the authors to make this clarification, it provides a concrete example and a direction for improvement. The action is implicit but concrete, making this comment 4.", "grounding_specificity_rationale": "The comment addresses the meta solvers and their relation to centralized reinforcement learning (RL), suggesting that the authors clarify the differences. It provides a specific reference to Foester et al., which can guide the authors in understanding the context. However, the comment does not explicitly mention which part of the paper discusses the meta solvers, making it weakly grounded. The authors can infer that it relates to sections discussing the methodology or results, but this inference is not direct. The comment is specific in suggesting a clarification and providing a reference, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the meta solvers are centralized controllers and recommends clarifying the difference between them and centralized reinforcement learning (RL) where agents share weights. The reviewer provides a specific reference to Foester et al., which is a wellknown work in the field, to support the claim. This reference offers a concrete example that can help the authors understand the context and potentially address the issue. However, the comment could be strengthened by providing more detailed reasoning or examples of how the clarification would impact the paper. As it stands, the claim is 4 due to the reference provided, but it could benefit from additional explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper regarding the meta solvers and their relation to centralized reinforcement learning (RL). It suggests that the authors clarify the differences between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al., which can guide the authors in understanding the context and potentially addressing the issue. While the comment is clear and actionable, it could be more helpful if it included additional guidance on how to effectively clarify this distinction in the paper. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement and provides a reference for further exploration."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review comment points out a lack of technical novelty in the paper, noting that the ideas, coattention mechanism, and architecture are similar to previous works by Xing and Tsang (2022a, b). However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or differentiate their work. There is no guidance on potential improvements, alternative approaches, or additional experiments that could enhance the technical novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the technical novelty of the paper by comparing it to two specific papers by Xing and Tsang (2022a, b). However, it does not specify which part of the paper this comparison should be made, nor does it provide details on how the ideas, coattention mechanism, and architecture are similar to the previous works. This lack of grounding makes it difficult for the authors to identify where the comparison should be made or what specific aspects need to be addressed. Additionally, the comment lacks specificity regarding how the authors might address the issue of limited technical novelty. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty by comparing it to two previous works by Xing and Tsang (2022a, b). The comment suggests that the ideas, coattention mechanism, and architecture are similar to those in the previous papers. However, the comment does not provide specific details or examples from the mentioned papers to substantiate the claim of similarity. This lack of detailed comparison or references makes the claim 3, as the authors would need to further investigate the cited works to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a lack of technical novelty in the paper, noting that the ideas, coattention mechanism, and architecture are similar to those in previous works by Xing and Tsang (2022a, b). While it identifies a potential issue, the comment does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
