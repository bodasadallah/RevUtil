{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: the lack of comparison with Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It also points out a grammatical error. The comment provides explicit actions for the authors to take, such as comparing with Campos et al. (2020) and other domain adaptation methods, and correcting the grammatical error. These actions are clear and concrete, giving the authors specific guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the baseline models, Campos et al. (2020), and Section 8, allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the baseline models, including the lack of comparison with Campos et al. (2020) and other domain adaptation methods, and provides a correction for a grammatical error. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak, providing two reasons for this assertion. First, it notes the absence of a comparison with Campos et al. (2020), which also uses feedback in QA tasks, suggesting that this omission weakens the evaluation. Second, it points out the lack of comparison with other domain adaptation methods, such as those cited in Section 8. These reasons provide a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the domain adaptation methods mentioned in Section 8. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the adopted baseline models are weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This feedback is actionable as it provides a clear direction for the authors to strengthen their evaluation by including a relevant comparison. Second, the comment notes the absence of comparison with other domain adaptation methods, such as those cited in Section 8, which is another actionable point for improvement. Additionally, the comment corrects a grammatical error, which is a minor but helpful detail. Overall, the comment is mostly helpful as it provides clear and actionable feedback on areas for improvement, though it could be more comprehensive by offering more detailed suggestions on how to address the identified weaknesses. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests adding a clarification about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model, which is an explicit and concrete action. Second, it questions whether the KNs in Figure 3 are in the source language or English, and notes that the authors have already stated they will correct the figure. While the first part is explicit and actionable, the second part is implicit and lacks detailed guidance on how to address the issue. Overall, the comment is mostly actionable as it provides clear actions for the authors to take.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: adding a clarification about the input being word embeddings and clarifying whether the KNs in Figure 3 are in the source language or English. The comment also acknowledges that the authors have already stated they will correct the figure, which provides additional context. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a clarification about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. This is a request for clarification and does not contain an opinion or judgment that requires verification. The second part of the comment is a factual observation about the figure, which does not constitute a claim. Therefore, the review point consists of normal statements and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests adding a clarification about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model, which is a specific and actionable recommendation that can enhance the clarity of the paper. Second, it questions whether the KNs in Figure 3 are in the source language or English, and notes that the authors have already stated they will correct the figure. This part of the comment is also actionable, as it highlights a potential issue that needs to be addressed. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are in question or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims need further examination and how to proceed with the analysis. Without explicit instructions or examples, the authors may struggle to determine the exact steps needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or provide details on what aspects of the analysis are lacking. This makes it difficult for the authors to identify the specific parts of the paper that need attention. The comment is not grounded as it does not point to a particular section, figure, or table, and it is not specific because it lacks detailed guidance on what kind of analysis is needed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a number of claims from this paper would benefit from more in-depth analysis.\" However, it does not specify which claims are being referred to or provide any reasoning or examples to support this assertion. Without specific details or evidence, the authors may find it challenging to understand which claims need further analysis and why. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that several claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not identify which claims are in question or provide guidance on how to conduct this analysis. Without concrete examples or detailed suggestions, the authors are left without actionable feedback to improve their draft. The lack of clarity and actionable advice makes the comment barely helpful, as it does not effectively guide the authors in enhancing their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas that need improvement in the presentation of the model. It explicitly asks for clarification on the pooling method used for embedding features and questions the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i. The reviewer also suggests that the left-hand side (LHS) of Equation (7) should be a conditional probability. These explicit questions and suggestions provide clear and concrete actions for the authors to take, ensuring they know exactly what needs to be clarified or revised in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and equations (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and defining the terms in Equation (7). The comment provides detailed guidance on what aspects of the presentation are unclear and how they can be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific issues: the need for clarification on the pooling method used for embedding features and the ambiguity in Equation (7). The comment provides explicit questions and observations, suggesting that the authors clarify these aspects. While the comment identifies areas of confusion, it does not provide detailed reasoning or examples to fully substantiate the claims. The suggestion to clarify the pooling method and the nature of E_i is logical, but the lack of detailed justification or references makes the claims somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas in the presentation of the model that require improvement. It asks for clarification on the pooling method used for embedding features, which is a critical aspect of the model\\'s architecture. Additionally, it questions the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i, and suggests that the left-hand side of the equation should be a conditional probability. This feedback is clear and actionable, providing the authors with precise guidance on where to focus their efforts to improve the clarity and comprehensibility of their work. By addressing these points, the authors can enhance the reader\\'s understanding of their model and its components. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as stated in the third contribution of the paper. While the comment explicitly states the need for empirical evidence, it does not specify what kind of evidence or analysis should be included or how to present it. The action is explicit but somewhat vague, as the authors know they need to provide evidence but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests showing empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of empirical evidence is needed or how it should be presented. This lack of explicit reference to a specific section or detailed guidance makes it difficult for the authors to identify the exact area needing improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem. However, the comment does not specify which part of the paper makes this claim or provide any reasoning or evidence to support the need for additional empirical evidence. This lack of detail makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it directly addresses a specific claim made in the paper and encourages the authors to substantiate it with empirical evidence. By doing so, the authors can strengthen the credibility and validity of their work. However, the comment could be more helpful if it provided guidance on how to present this evidence or suggested specific metrics or analyses to consider. Overall, the comment is mostly helpful, as it identifies a clear area for improvement and provides a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity.\" The reviewer provides specific observations about the performance of DeiT models compared to CNNs, suggesting that CNNs provide more consistent model improvements as capacity increases. This feedback is explicit and provides concrete guidance on what additional analysis and comments are needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment disagrees with the authors\\' viewpoint and provides specific observations about the performance of DeiT models compared to CNNs, suggesting that CNNs provide more consistent model improvements as capacity increases. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by providing specific observations and data from Figure 3. It notes that DeiT-B models do not outperform DeiT-T in APTOS2019 and DeiT-S on APTOS2019, ISIC2019, and CheXpert, suggesting that CNNs provide more consistent model improvements as capacity increases. This detailed analysis and comparison provide a robust basis for the reviewer\\'s claim, making it fully verifiable. The comment is supported by specific examples and observations, which helps the authors understand the basis of the critique and potentially address it in their work. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\\' viewpoint that \"Both CNNs and ViTs seem to benefit similarly from increased model capacity\" by providing specific observations and data from Figure 3. The comment highlights that DeiT-B models do not outperform DeiT-T in APTOS2019 and DeiT-S on APTOS2019, ISIC2019, and CheXpert, suggesting that CNNs provide more consistent model improvements as capacity increases. This feedback is clear and constructive, offering the authors a concrete direction for enhancing their analysis and potentially revising their conclusions. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules in previous works. It also mentions that the group attention design is related to ResNeSt but is not discussed in the paper. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the novelty of their work. It lacks specific suggestions or actions for the authors to take, such as recommending ways to differentiate their method from existing ones or suggesting how to discuss the similarities and differences with ResNeSt. As a result, the comment is vague and does not offer actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method by comparing it to existing attentional modules in previous works and mentioning the similarity to ResNeSt. However, it does not specify which part of the paper discusses these comparisons or where the group attention design is discussed, making it weakly grounded. The comment is specific in detailing the similarities between the proposed method and existing works, but without clear references to specific sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules in previous works. It provides specific references to these works, which helps substantiate the claim. Additionally, it mentions that the group attention design is related to ResNeSt but is not discussed in the paper, further supporting the argument. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from these existing modules. Despite this, the claim is mostly verifiable due to the references and logical reasoning provided, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to existing attentional modules in previous works. It specifically mentions the group attention design and its relationship to ResNeSt, which is not discussed in the paper. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might differentiate their work or address the similarity concerns. The feedback is somewhat helpful as it points out a key weakness but does not provide actionable steps for improvement, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the required implicit call to the Witness oracle, describing it as confusing. However, it does not provide any guidance or suggestions on how to clarify this aspect or what specific changes should be made to improve the clarity. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Since the feedback is vague and does not offer a clear path for improvement, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"required implicit call to the Witness oracle,\" which provides some context but does not specify where in the paper this issue is discussed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what exactly is confusing about the call to the Witness oracle. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this call is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. However, it does not provide any further explanation or suggestions on how to clarify this aspect or what specific changes could be made to improve the clarity. Without additional context or guidance, the authors are left with only a vague understanding of the problem, limiting the usefulness of the feedback. Therefore, the comment is rated as barely helpful, as it points out an issue but lacks actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the necessity of using a \"coarse\" methodology to make this observation, noting that the observation has been made at each step of the evolution of language models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their methodology. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the necessity of using a \"coarse\" methodology to make this observation, noting that the observation has been made at each step of the evolution of language models. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on how the methodology could be improved or what specific issues need addressing. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the necessity of using a \"coarse\" methodology to make this observation, noting that the observation has been made at each step of the evolution of language models. The comment provides a logical reasoning by referencing the historical context of similar observations across different language models, suggesting that the current observation is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the historical context and the novelty of their methodology to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the necessity of using a \"coarse\" methodology to make this observation, noting that the observation has been made at each step of the evolution of language models. While the comment identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this critique or improve their methodology. Without specific advice or examples, the feedback is limited in its usefulness to the authors. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to clarify the distinction between when their proposed method is trained using only weak supervision and when it is semi-supervised trained. It provides a specific example by suggesting that the authors rename the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect the semi-supervised nature of the proposed framework. Additionally, the reviewer suggests a more comprehensive approach by specifying the data used to train each model and proposing two big columns to differentiate between mixture and single-source data. This feedback is explicit and provides concrete guidance on how to improve the clarity and presentation of the results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training, and suggests a renaming of the column in Table 1. Additionally, it provides a suggestion for a more comprehensive presentation of the data used to train each model. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training in their proposed method. It provides a specific example by pointing out that the proposed framework row in Table 1 refers to the semi-supervised version of the method, and suggests renaming the column to \"Fully supervised\" from \"Supervised.\" The comment also proposes a more comprehensive approach to presenting the data used for training. While the suggestion is logical and provides a clear direction for improvement, it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the suggestion but could benefit from additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific area where the paper could be improved: the distinction between weak supervision and semi-supervised training. It suggests renaming a column in Table 1 to reflect the semi-supervised nature of the proposed framework and proposes a more comprehensive approach to presenting the data used for training. This feedback is detailed and offers concrete suggestions that can help the authors enhance the clarity and comprehensiveness of their presentation. By addressing these points, the authors can significantly improve the clarity and transparency of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific weakness in the paper, namely the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. It suggests that the authors should consider additional datasets from the Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for guidance on different datasets and model types. The comment provides explicit actions for the authors to take, including expanding the experimental evaluation and referencing relevant literature. The guidance is clear and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and the use of the CIFAR-10 dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the limited scope of the experiments and suggests considering additional datasets from Federated learning benchmarks, such as LEAF, and referencing relevant works like FedProx and FedMAX. This provides clear guidance on how to improve the experimental evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s main weakness lies in the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. The reviewer suggests that the authors should consider additional datasets from Federated learning benchmarks and references relevant works like FedProx and FedMAX for guidance. This claim is mostly verifiable as it provides specific examples of datasets and references that could be used to expand the experimental evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional datasets would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR-10 dataset. It suggests that the authors should consider additional datasets from Federated learning benchmarks, such as LEAF, and references relevant works like FedProx and FedMAX for guidance on different datasets and model types. This feedback is clear and actionable, providing the authors with specific directions to expand their experimental evaluation and improve the comprehensiveness of their work. By addressing this point, the authors could significantly enhance the impact and relevance of their paper. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for their unlabeled data, similar to the approach used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al. (2018). The reviewer explicitly recommends using unlabeled data directly sampled from millions of reviews, providing a clear and concrete action for the authors to take. This guidance is specific and actionable, as it outlines a particular method that the authors should consider implementing to improve their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the label distribution being perfectly balanced, which is impractical in real-world applications. The comment further suggests using a more convincing setting, referencing a specific work by He et al. (2018), providing clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of perfectly balanced unlabeled data from the Amazon review dataset is impractical in real-world applications. The reviewer supports this claim by suggesting that the authors should use a more convincing setting, as in the work by He et al. (2018), which directly samples unlabeled data from millions of reviews. This provides a logical reasoning and a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of perfectly balanced unlabeled data from the Amazon review dataset, noting that this is impractical in real-world applications. It suggests that the authors should use a more convincing setting, similar to the approach used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al. (2018), which involves directly sampling unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve their methodology and make it more applicable to real-world scenarios. The reference to a specific work further supports the suggestion, making the comment highly helpful for the authors in refining their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, noting that the notation for the target domain is unlabeled and that the problem setting differs significantly from the original MFDA paper. The reviewer asks questions about the use of unlabeled data in source domains and whether they are used during training, as in the original paper. While the comment highlights areas of confusion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the notation and problem setting, but without specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references the \"MFDA setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the description of the MFDA setting, particularly the notation for the target domain and the use of unlabeled data in source domains. The comment further questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the MFDA setting description in the paper, specifically questioning the use of unlabeled data in source domains and its alignment with the original MFDA paper. The reviewer provides specific references to the original MFDA paper by Yue et al. (2021a) to support their claim, which adds a level of verifiability. However, the comment could be strengthened by providing more detailed examples or explanations of the confusion, such as specific sections or paragraphs where the notation is unclear. Despite this, the reference to the original paper provides a solid foundation for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the paper. It points out specific areas of confusion, such as the use of unlabeled data in source domains and the notation for the target domain, which differ from the original MFDA paper. The comment raises important questions about the problem setting and its alignment with the original work, prompting the authors to clarify these aspects. By highlighting these discrepancies, the comment provides actionable feedback that can help the authors improve the clarity and accuracy of their description. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to clarify the notation. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the paper, noting that the contribution is incremental and essentially a combination of existing methods. It also points out the omission of key baselines and suggests that essential RAG algorithms should have been introduced, such as MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should include these references and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions reviewing the code and the details in the article, allowing the authors to identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as the incremental nature of the contribution, the omission of key baselines, and the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides the authors with clear direction on how to improve their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the article is incremental, essentially a combination of existing methods like GraphRAG and GraphCare. It also points out the omission of key baselines and suggests that essential RAG algorithms should have been introduced. The comment is mostly verifiable as it provides specific references to external works (GraphRAG, GraphCare, MedRetriever, and KGRAG) that could support the claim of incremental contribution. However, it lacks detailed reasoning or examples to fully substantiate the claim, such as how the article's contribution differs from these existing methods. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper, noting that the contribution is incremental and essentially a combination of existing methods like GraphRAG and GraphCare. It also points out the omission of key baselines and suggests that essential RAG algorithms should have been introduced, such as MedRetriever and commonly used GraphRAG algorithms like KGRAG. This feedback is clear and actionable, as it identifies specific areas where the paper could be improved by including relevant references and algorithms. By addressing these points, the authors can enhance the comprehensiveness and originality of their work. However, the comment could be more helpful if it offered suggestions on how to integrate these references or algorithms into the paper. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a missing state-of-the-art reference in the experiment of face recognition, specifically mentioning Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also notes that the VRF achieves a better result on LFW compared to the result in Table 3 of the paper. The comment implies that the authors should include this reference and compare their results to those reported in the mentioned work. While the action is implicit, it is clear and concrete, as the authors know exactly what reference to include and how to compare their results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific state-of-the-art work by Baidu, providing a link to the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing, namely the inclusion of a particular reference and its comparison with the results in Table 3. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" The reviewer provides a link to the work and notes that it uses the triplet loss and reports results on a dataset similar to Webface. The comment further states that the VRF achieves a better result on LFW compared to the results in Table 3 of the paper. This claim is mostly verifiable as it provides a specific reference and comparison to support the assertion. However, it could be strengthened by providing more detailed comparisons or additional context from the referenced work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific gap in the literature review or references section of the paper, noting the absence of a state-of-the-art reference related to face recognition. It provides a specific reference, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" which is relevant to the experiment discussed. Additionally, the comment highlights that the VRF achieves a better result on LFW compared to the results reported in the paper. This feedback is clear and actionable, as it guides the authors to include a relevant reference and potentially update their results section to reflect the comparison. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this reference into the paper. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and provides a concrete reference to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is inspired by an example from previous work. This direct request provides a clear and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete and actionable, as it leaves no ambiguity about the necessary change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to cite the source of the example, which is inspired by previous work. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and requests appropriate citation. However, it does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without detailed evidence or references, the authors may find it challenging to address the comment effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and requests appropriate citation. This feedback is clear and actionable, as it directs the authors to provide proper attribution to the source of the example, which is crucial for academic integrity and avoiding plagiarism. By addressing this comment, the authors can improve the transparency and credibility of their work. However, the comment could be more helpful if it suggested additional sources or provided context on why this citation is important. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific line in the paper where the authors mention taking the embedding of the first subword token as the verb embedding. It suggests that it is also common to average over subword representations, as demonstrated in a cited work. However, the comment does not provide explicit guidance on whether the authors should adopt this approach or how it should be implemented. While it implies that the authors might consider averaging over subword representations, the action is not directly stated, and the suggestion is not concrete. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an alternative approach to handling subword representations, referencing a specific work by Hewitt and Manning (2019). This provides clear guidance on what the authors could consider to improve their methodology. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach to handling subword representations, referencing a specific work by Hewitt and Manning (2019). This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how this alternative approach might improve the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the methodology by referencing an alternative approach to handling subword representations. It points out a common practice in the field, as demonstrated by a cited work, which could enhance the clarity and robustness of the paper. This feedback is actionable and offers a concrete direction for the authors to consider, making it mostly helpful. However, it could be more comprehensive by explaining why this alternative approach might be beneficial or how it could impact the results. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit suggestions for improvement or areas where the authors could enhance their work. There is no guidance on potential modifications, additional experiments, or analyses that could be included to further strengthen the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment does not provide specific details or suggestions for improvement, such as what aspects of the experiments could be further explored or strengthened. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not express any subjective opinions, judgments, or suggestions that require verification. It is a factual statement describing the scope of the experiments, which is consistent with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific feedback or suggestions for improvement. Without identifying any weaknesses or areas that need attention, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and mentions that there have been efforts to extend these noise conditions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue in their paper. The comment lacks actionable details, such as recommending specific methods or approaches to consider or suggesting how the authors might incorporate these extensions into their work. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in that it mentions the commonness of the assumption and references efforts to extend these noise conditions, providing examples of relevant literature. This specificity helps the authors understand the issue and potential areas for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and references two specific works by A. Khaled and P. Richt\u00b4arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or examples from these works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the bounded noise assumption, which is considered somewhat restrictive in the stochastic optimization literature. It acknowledges that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\u00b4arik, and R. Gower, O. Sebbouh, and N. Loizou. This feedback is valuable as it highlights an area where the paper could be improved by considering more general noise conditions. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these extensions or discussed their implications for the paper\\'s conclusions. Overall, the comment is somewhat helpful as it points out a limitation and provides references for further exploration, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides the authors with a precise area to address and clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically asking whether it refers to 100 sampled strategies. While this question highlights a potential area of confusion or lack of clarity in the manuscript, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The comment is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully understand or address the issue. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss the reason why the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works like SUSTAIN and MRBO, which use the double momentum technique. It also suggests that the authors should explore the theoretical differences between DMLCBO and these previous works. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be discussed and the theoretical aspect that should be explored. The guidance is concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed algorithm DMLCBO\" and the \"double momentum technique,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the reason why DMLCBO does not achieve the same convergence rate as previous works like SUSTAIN and MRBO, and the theoretical differences between DMLCBO and these works. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. The reviewer supports this claim by stating that these previous works achieve a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$, while DMLCBO only achieves $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-4})$. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to specific sections of the cited works, which would make the claim fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm, DMLCBO, which is based on the double momentum technique. It points out that previous works, such as SUSTAIN and MRBO, have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ using the same technique, while DMLCBO only achieves $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-4})$. The comment encourages the authors to discuss the reason for this discrepancy and the theoretical differences between DMLCBO and the previous works. This feedback is clear and actionable, as it directs the authors to explore and clarify the theoretical aspects of their algorithm, which could significantly enhance the paper\\'s contribution. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that its heuristic design might lead to issues with hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to mitigate the scalability issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the modulator, which is a specific element of the paper, providing some grounding. However, it does not specify which part of the paper discusses the modulator or how the scalability issue is currently addressed, making it weakly grounded. The comment raises a concern about the scalability of the modulator and the potential need for tedious hyperparameter tuning, but it lacks specificity regarding what aspects of the modulator design or implementation need attention or improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the modulator is heuristically designed, which could lead to scalability issues requiring tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation without sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a concern about the scalability of the modulator, suggesting that its heuristic design might lead to issues with hyperparameter tuning for diverse training data. This is a relevant point that could impact the practical applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of their modulator. Without actionable advice or detailed feedback, the authors are left with a general concern but no clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the interest in the OOD experiments and notes that the trained network demonstrates strong OOD generalization. It then suggests that the authors should mention recent papers that show untrained NNs can solve inverse problems across a wide range of images. The comment implies that the authors should compare their method with these untrained NNs, providing a clear and explicit action for the authors to take. However, it does not specify which specific papers should be mentioned or how the comparison should be conducted, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention recent papers that demonstrate the effectiveness of untrained NNs in solving inverse problems across a wide range of images. The comment further suggests comparing the current method with these untrained NNs, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the interest in the OOD experiments and notes the strong OOD generalization of the trained network. However, it suggests that the authors should mention recent papers showing that untrained NNs can solve inverse problems across a wide range of images. The comment implies that the current method should be placed in context and compared with these untrained NNs. While the suggestion is logical, it lacks specific references or detailed examples of the papers mentioned, making it somewhat verifiable. The authors would need to identify and incorporate these references themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the interest in the OOD experiments and notes the strong OOD generalization of the trained network. It then suggests that the authors should mention recent papers that demonstrate the effectiveness of untrained NNs in solving inverse problems across a wide range of images. The comment further recommends placing the current method in context and ideally comparing it with these untrained NNs. This feedback is mostly helpful as it provides a clear direction for the authors to situate their work within the existing literature and consider comparisons that could enhance the paper\\'s contribution. However, it could be more helpful if it included specific references to the papers mentioned or detailed guidance on how to conduct the comparison. Overall, the comment offers valuable insights and actionable suggestions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the readability of the first two sections of the paper, particularly regarding the explanation of previous approaches and the clarity of certain sentences. It provides examples of unclear sections, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers zooming in time. By highlighting these specific areas, the comment offers explicit and concrete guidance on where the authors need to improve their explanations. The authors can directly address these issues to enhance the clarity and readability of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of unclear explanations, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers zooming in time. These examples offer clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are difficult to read due to the lack of clear explanations of previous approaches. It provides specific examples, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers zooming in time, to illustrate the issues. This detailed critique, supported by specific examples, makes the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to standard practices in the field, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the readability and clarity of the first two sections of the paper. It provides detailed examples of where the explanations are unclear, such as the stacked LSTM in Figure 2 and the sentence about lower hierarchical layers zooming in time. By highlighting these specific areas, the comment offers actionable feedback that can help the authors improve the clarity and coherence of their paper. However, the comment could be more helpful if it included suggestions on how to clarify these sections or provided examples of how to improve the explanations. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the paper\\'s goal, specifically questioning the lack of comparison or justification for the proposed method against existing DAS earthquake detectors like PhaseNet-Das. It suggests that if the paper claims to be a foundation model, it should clarify its purpose and demonstrate or justify future applications. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The authors are left to infer that they need to clarify their claims and demonstrate the benefits of their method, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically questioning the lack of comparison or justification for the proposed method against existing DAS earthquake detectors like PhaseNet-Das. It suggests that if the paper claims to be a foundation model, it should clarify its purpose and demonstrate future applications. However, the comment does not explicitly mention which part of the paper discusses the goal or comparison, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the paper\\'s goal and comparison to existing work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s goal, specifically questioning the lack of comparison or justification for the proposed method against existing DAS earthquake detectors like PhaseNet-Das. The reviewer suggests that if the paper claims to be a foundation model, it should clarify its purpose and demonstrate future applications. While the comment identifies a gap in the paper\\'s justification, it lacks specific examples or references to existing work that could provide a basis for comparison. This makes the claim somewhat verifiable, as it highlights an area for improvement but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the paper\\'s goal, specifically questioning the lack of comparison or justification for the proposed method against existing DAS earthquake detectors like PhaseNet-Das. It suggests that if the paper claims to be a foundation model, it should clarify its purpose and demonstrate or justify future applications. This feedback is clear and actionable, as it guides the authors to address the gap in their work by either comparing their method to existing detectors or providing a clear rationale for its novelty and potential applications. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a key area for improvement and provides a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses have been conducted in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench, and the evaluation of robustness by [A, B]. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their work. It lacks actionable steps or suggestions for the authors to enhance their contribution or differentiate their findings. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment references prior works and specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench, and the evaluation of robustness by [A, B]. However, it does not explicitly mention which part of the paper these comparisons are relevant to, making it weakly grounded. The comment is specific in detailing the similarities and the lack of novelty in the results, but without clear grounding, the authors may struggle to identify where these issues are discussed in their paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analyses presented in the paper are not particularly surprising, as similar studies have been conducted in prior works, such as RobustBench. It supports this claim by referencing specific examples, such as the robustness of CIFAR-10 models on distribution shifts and the evaluation of robustness by [A, B]. This provides a clear and specific reference to external sources, making the claim fully verifiable. The detailed references and examples offer robust evidence for the reviewer\\'s assertion, ensuring that the authors can understand and address the critique effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights a potential issue with the novelty of the analyses presented in the paper, noting that similar studies have been conducted in prior works, often on a smaller scale. It references specific examples, such as the robustness of CIFAR-10 models on distribution shifts, which were studied in RobustBench, and the evaluation of robustness by [A, B]. This feedback is somewhat helpful as it alerts the authors to the need to differentiate their work from existing literature. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as by highlighting unique aspects of their analysis or proposing new angles for exploration. Overall, the comment offers some insight but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It corrects an inaccurate statement about the Walkman algorithm in the Related Work section, clarifying that it uses ADMM with two versions, one solving a local optimization problem and the other a gradient approximation. This feedback is specific and actionable, as it guides the authors to revise the statement to reflect the correct information. Additionally, it points out an unclear reference in Section 3, suggesting that the authors need to clarify the \"it\" in the sentence. This feedback is also explicit and actionable, as it directs the authors to identify and correct the ambiguous reference. Both parts of the comment provide clear guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the inaccuracies in the text regarding the Walkman algorithm and the unclear reference in Section 3. The comment suggests corrections and clarifications, offering clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: one regarding the accuracy of the statement about the Walkman algorithm in the Related Work section and another about the unclear reference in Section 3. The first claim is supported by specific references to the Walkman algorithm and its versions, providing a clear basis for the reviewer\\'s assertion. The second claim is also supported by pointing out the lack of a clear reference, which helps the authors understand the issue. Both claims are well-supported and provide specific guidance for improvement, making them fully verifiable. Therefore, the review point is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues. First, it corrects an inaccurate statement in the Related Work section regarding the Walkman algorithm, clarifying that it uses ADMM with two versions, one solving a local optimization problem and the other a gradient approximation. This correction is important for the accuracy of the paper\\'s literature review. Second, it points out an unclear reference in Section 3, where the pronoun \"it\" lacks a clear reference, which could lead to confusion for readers. By identifying these specific issues, the comment helps the authors improve the clarity and accuracy of their draft. The feedback is clear, actionable, and directly addresses areas that need correction, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that there are several works that focus on the same questions, implying that these should be included in the comparison. However, the comment does not specify which additional works should be considered or how the authors should incorporate them into their experimental section. While the action is clear\u2014adding more experiments\u2014the lack of concrete guidance on which works to include or how to structure the additional experiments makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experiments to demonstrate the effectiveness of the proposed method by comparing it with additional baselines, such as those mentioned in references [1, 2, 3]. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method by comparing it with additional baselines. The claim is somewhat verifiable as it references specific works ([1, 2, 3]) that focus on similar questions, implying that these works should be considered for comparison. However, the comment lacks detailed reasoning or examples of how these additional comparisons would enhance the paper, making it difficult for the authors to fully understand the necessity of these additions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental section, noting that the authors only compare their work with two baselines. It suggests that additional experiments should be conducted to demonstrate the effectiveness of the proposed method by including comparisons with other relevant works. This feedback is clear and actionable, providing a specific direction for the authors to enhance their experimental validation. However, the comment could be more helpful if it included specific references to the additional works that should be considered or provided guidance on how to structure these additional experiments. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of details regarding the filtering process used to create the Arabic climate change QA dataset, specifically mentioning the need for more information on the translation and filtering methodology. While the comment identifies an area that requires clarification, it does not provide specific guidance on what aspects of the methodology should be detailed or how the authors should present this information. The action is implicit and somewhat vague, as the authors know they need to provide more details but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of details regarding the filtering process used to create the Arabic climate change QA dataset, specifically mentioning the need for more information on the translation and filtering methodology. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in identifying what is missing\u2014details on the translation and filtering methodology\u2014but without clear grounding, the authors may struggle to pinpoint where to add this information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking\" and suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. The lack of detailed justification or evidence renders the claim borderline verifiable, as it provides a general direction for improvement but lacks the specificity needed for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for understanding the dataset\\'s reliability and validity. However, the comment could be more helpful if it offered specific suggestions on what aspects of the methodology should be elaborated upon. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and provides concrete guidance on what needs to be added to the draft. The authors know exactly which topics to cover and can follow the suggested structure to improve their Related Work section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section and the paragraph on \"long-context language models,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be addressed, including a comprehensive overview of existing methods and their limitations, and specific examples of approaches to discuss, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for improvement, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section lacks details and suggests that the paragraph on long-context language models should provide a more comprehensive overview of existing methods and their limitations. The reviewer supports this claim by listing specific types of methods that should be discussed, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed list provides a clear direction for the authors to improve their Related Work section, making the claim mostly verifiable. However, the comment could be strengthened by providing examples or references to these methods, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the Related Work section, noting that it lacks details and does not provide a comprehensive overview of existing methods and their limitations. It suggests that the authors should include a more detailed discussion of long-context language models, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is clear and actionable, providing the authors with a concrete direction to improve their draft by expanding the Related Work section. However, the comment could be more helpful if it offered additional guidance on how to integrate these methods into the discussion or suggested specific references. Overall, the comment is mostly helpful as it effectively directs the authors toward enhancing their Related Work section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the writing are unclear or provide guidance on how to improve the clarity. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what specific changes are needed to enhance the clarity of their writing. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or how the writing could be improved. Without specific references to sections, figures, or specific content, the authors cannot effectively identify the areas needing improvement. The lack of detail and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"the writing should be improved\" and that \"some points in the paper are unclear.\" However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or examples of what is unclear or how the writing could be improved, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the writing in the paper is unclear and should be improved. However, it lacks specificity and does not provide any guidance or examples of what aspects of the writing are unclear or how they could be improved. Without detailed feedback or actionable suggestions, the authors are left without a clear path to enhance their draft. This lack of specificity and actionable advice makes the comment not helpful at all, as it does not provide the authors with any meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or modifications to clarify the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific experiment involving a non-separable case and mentions Figure 1, which provides full grounding as it allows the authors to identify the exact part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the experiment is problematic or how the authors should address the issue of data distribution being inseparable from the network model. Without specific guidance or suggestions, the authors may struggle to understand what changes are needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides an initial observation but lacks the necessary support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This feedback highlights a critical area for clarification or further explanation in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the low efficiency of pairwise matching, suggesting that it may be difficult to use in practical applications. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the efficiency of pairwise matching, suggesting it may be difficult to use in practical applications. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in identifying the issue of low efficiency but does not provide detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"the efficiency of such pairwise matching is very low, making it difficult to be used in practical application systems.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the efficiency of pairwise matching, suggesting that it may be difficult to use in practical application systems. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the addition of a method to improve transferability as a positive aspect but downplays its significance as a contribution. However, it does not provide any specific guidance or suggestions on how the authors could enhance the contribution or address the perceived lack of significance. The comment lacks actionable details, such as recommending ways to strengthen the contribution or suggesting additional experiments or analyses. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the addition of a method to improve transferability as a positive aspect but downplays its significance as a contribution. However, it does not specify which part of the paper this addition is discussed in, making it weakly grounded. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered insignificant or how it could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that adding a method to improve transferability is a positive aspect but does not consider it a significant contribution. However, the comment lacks any supporting evidence, reasoning, or references to justify why this addition is not significant. Without further elaboration or examples, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the addition of a method to improve transferability as a positive aspect but downplays its significance as a contribution. However, it does not provide any specific feedback or suggestions on how the authors could enhance the contribution or address the perceived lack of significance. Without actionable advice or detailed guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as the reviewer believes this is not accurate based on their understanding of TopoNet. Additionally, it advises compressing the method section to focus on essential definitions and suggests double-checking for grammatical errors, particularly with plurals and articles. Each of these points is specific and provides clear guidance on how to improve the draft. The authors know exactly what changes to make and how to implement them, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"34\" and the phrase \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as toning down the statement about memorization and compressing the method section to focus on essential definitions. Additionally, it points out grammatical errors, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests toning down the statement about the neural network memorizing critical points, referencing TopoNet [24] as a basis for this suggestion. However, the comment does not provide specific reasoning or evidence from TopoNet to support the claim that the neural network does not memorize critical points. Additionally, the comment mentions grammatical errors and suggests compressing the method section, but these points are not substantiated with examples or detailed explanations. The lack of specific references or detailed reasoning makes the claim somewhat verifiable, as the authors would need to infer the basis of the suggestion and address the grammatical errors without explicit guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable pieces of feedback. It suggests toning down a statement about the neural network memorizing critical points, which is based on the reviewer\\'s understanding of TopoNet [24]. This feedback is specific and could help the authors refine their claims. Additionally, the comment points out that the method section is wordy and could be compressed to focus on essential definitions, which is a clear and actionable suggestion for improvement. The mention of grammatical errors and the need to double-check them is also helpful, as it directs the authors to a specific area for improvement. Overall, the comment is mostly helpful as it offers detailed and constructive suggestions for enhancing the clarity and accuracy of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which have similar sizes. It implies that if the authors claim COCO-LM is parameter-efficient, the conclusion should also apply to these other models. Additionally, it raises questions about the experimental setup, specifically why the authors switched the types of BPE vocabulary and whether this change affects performance. While the comment raises valid questions and suggests a reconsideration of the comparison, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron and questions the overrating of its performance. It provides specific examples of other approaches, such as RoBERTa, ELECTRA, and DeBERTa, which have similar sizes as COCO-LM. This allows the authors to understand the context of the issue. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The comment is specific in questioning the experimental setup and the impact of switching BPE vocabulary types. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron, suggesting that its performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This claim is somewhat verifiable as it provides a logical comparison with other models of similar size, but it lacks specific data or references to substantiate the claim fully. The reviewer also raises questions about the experimental setup, which adds some level of justification but does not provide detailed evidence or examples. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the overrating of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which have similar sizes. This feedback is somewhat helpful as it prompts the authors to reconsider their claims about the parameter efficiency of COCO-LM. Additionally, the comment raises questions about the experimental setup, specifically why the authors switched the types of BPE vocabulary and whether this change affects performance. These questions provide the authors with a direction for further exploration and clarification, which could enhance the robustness of their findings. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the experimental setup. Overall, the feedback is somewhat helpful as it identifies areas for improvement and prompts the authors to consider their claims and experimental design more critically.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, noting that the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features and ResNet-50 learns more class-specific features. The comment also mentions the authors\\' hypothesis that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the analysis. While it raises valid concerns, it lacks concrete suggestions for improvement, leaving the authors uncertain about how to enhance their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific line range \"from line 128 to 149\" and references Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the convincing nature of the analysis and providing specific observations from the histogram regarding the class selectivity score and feature sharing. Additionally, it raises a question about the hypothesis regarding additional context and its implications for learning better representations. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, noting that the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features and ResNet-50 learns more class-specific features. The comment also references two external works to support the claim. This provides a logical basis for the critique, as it uses specific observations and references to substantiate the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works. Overall, the claim is mostly verifiable due to the supporting evidence and references, but it could be further improved with more detailed explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the analysis from line 128 to 149, questioning its convincing nature. It references specific observations from the histogram in Fig 3, noting that the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features and ResNet-50 learns more class-specific features. The comment also raises a question about the hypothesis that additional context may allow the network to reduce its dependency. By referencing external works, the reviewer provides a basis for their critique and encourages the authors to further explore and justify their observations. This feedback is mostly helpful as it identifies a specific area of concern and suggests a direction for improvement, but it could be more comprehensive by offering specific suggestions on how to address the critique. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the validity of certain conclusions, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It suggests that the results might be due to limited exploration of combination methods and points to specific works that have shown potential in rehearsal-free continual learning, such as feature-replay methods like [R1], [R2], and [R3]. While the comment implies that the authors should consider these works and their findings, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate these references into their work. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take, such as comparing their results with these works or discussing their implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific conclusions in the paper, particularly the claim about continuous learning with unlabeled data accumulating noise. It suggests that the results might be due to limited exploration of combination methods and references specific works in rehearsal-free continual learning, such as [R1], [R2], and [R3]. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the conclusions or discussion sections. The comment is specific in detailing what needs to be addressed, namely the exploration of combination methods and the potential of feature-replay methods. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of certain conclusions, specifically regarding the claim about continuous learning with unlabeled data accumulating noise. The reviewer provides a rationale by suggesting that the results might be due to limited exploration of combination methods and references specific works in rehearsal-free continual learning, such as feature-replay methods like [R1], [R2], and [R3]. This provides a logical basis for the claim, as it highlights alternative approaches that have shown potential in the field. However, the comment could be strengthened by providing more detailed comparisons or examples from these referenced works. Overall, the claim is mostly verifiable due to the logical reasoning and references provided, but it could benefit from additional detail to fully substantiate the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the validity of certain conclusions in the paper, specifically regarding the claim about continuous learning with unlabeled data accumulating noise. It suggests that the results might be due to limited exploration of combination methods and references specific works in rehearsal-free continual learning, such as feature-replay methods like [R1], [R2], and [R3]. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s conclusions and provides references to related works that could be considered for comparison or further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or integrate the referenced works into the paper. Overall, the feedback provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential hardware and software dependency of some observations and design decisions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to make the observations and decisions more hardware and software independent. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding which observations or design decisions are in question and how they might be dependent. Without clear references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, examples, or reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the potential hardware and software dependency of some observations and design decisions. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but notes that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance or suggestions on how the authors could address these issues or enhance the novelty of their work. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It mentions the contribution as being the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also points out modifications like different penalty coefficients for users and items but notes the lack of insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not specify which sections or parts of the paper these observations pertain to, making it weakly grounded. The comment is specific in detailing what aspects of the paper are lacking in terms of novelty and insights. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer provides some reasoning by mentioning the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. However, the comment lacks specific examples or detailed comparisons to substantiate the claim of limited novelty. Additionally, it does not provide references to the existing literature or specific insights that are missing, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but notes that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies a potential weakness in the paper\\'s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. The feedback is somewhat helpful as it highlights areas for improvement but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the description in Section 4.2, particularly regarding the use of the question to learn an attention on the image feature and the meaning of the term \\\\(\\\\sigma\\\\) in the equation. The reviewer suggests clarifying these points, which provides a clear and explicit action for the authors to take. Additionally, the comment raises a concern about the potential ill-conditioning and numerical instability of multiplying two sigmoid activations, which is a concrete suggestion for improvement. The feedback is explicit and provides concrete guidance on how to address the issues, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in that section, particularly the absence of the term \\\\(r^q\\\\) in the equation and the unclear meaning of \\\\(\\\\sigma\\\\). The comment provides clear guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the description in Section 4.2, specifically regarding the use of the question to learn an attention on the image feature and the meaning of the term \\\\(\\\\sigma\\\\) in the equation. The reviewer suggests that the equation does not include a term for \\\\(r^q\\\\), which is the question representation, and questions the meaning of \\\\(\\\\sigma\\\\). This feedback is somewhat verifiable as it highlights specific issues with the clarity of the description and the equation, but it lacks detailed explanations or references to support the claim. The authors would need to further investigate these points themselves to address the concerns, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and coherence of the paper, particularly in Section 4.2. It points out that the description does not match the equation, highlighting the absence of the term \\\\(r^q\\\\) in the equation, which is crucial for understanding the method. Additionally, it questions the meaning of \\\\(\\\\sigma\\\\) in the equation and raises a concern about the potential ill-conditioning and numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides the authors with specific areas to clarify and address in their draft. By doing so, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the paper appears to be limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or enhance the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to differentiate the paper from existing work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which section of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the novelty as limited and pointing out the existing work in [10] and the incremental contribution in the decomposition part. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment does not provide specific details or references to substantiate this claim, such as which aspects of the decomposition are considered incremental or how they differ from existing work. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further investigate the referenced work to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a potential issue with the novelty of the paper, specifically noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. While it points out a weakness, the feedback lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It also mentions that this is grounds for rejection due to violating the 9-page paper limit. The comment provides a clear and direct action for the authors to take, which is to increase the whitespace in their paper to comply with the formatting guidelines. The feedback is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, specifically noting that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of violating the 9-page paper limit due to the lack of whitespace, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This is presented as grounds for rejection due to violating the 9-page paper limit. However, the comment lacks specific examples or detailed reasoning to support the claim that this violation is significant enough to warrant rejection. Without concrete evidence or references to standards, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It emphasizes that this violation of formatting guidelines is grounds for rejection, as it effectively exceeds the 9-page paper limit. While the comment clearly identifies a problem, it does not provide constructive suggestions on how to address the issue or improve the formatting. The feedback is somewhat helpful as it highlights a critical area for improvement, but it lacks actionable guidance, making it challenging for the authors to make significant improvements to their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details and formulations are limited and suggests that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance on how to address this issue or what aspects of the technical details and formulations need improvement. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to enhance the technical details and formulations. As a result, the comment is vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited and implies that the main novelty lies in the scheme or procedure. However, it does not specify which parts of the paper are lacking in detail or provide examples of what is missing. This makes it difficult for the authors to identify the specific sections that need improvement. The comment is not grounded as it does not refer to any particular part of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"technical details and formulations are limited\" and suggests that the main novelty lies in the scheme or procedure. However, the comment lacks specific examples or detailed reasoning to support the claim about the limitations in technical details and formulations. Without concrete evidence or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer sufficient direction for the authors to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a major risk associated with methods that exploit relationships between action units, specifically highlighting the potential differences in relationships across datasets. It suggests that cross-dataset experiments could be a good way to test the generalization of such work, which the paper currently lacks. The comment provides a clear and explicit action for the authors to take\u2014conducting cross-dataset experiments to assess the generalizability of their methods. However, it does not provide detailed guidance on how to design or implement these experiments, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the risk of different relationships between action units across datasets and suggests performing cross-dataset experiments to test generalization. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a potential risk in methods that exploit relationships between action units, specifically highlighting the variability in these relationships across datasets. The reviewer provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and how this co-occurrence might differ across datasets like SEMAINE and UNBC pain. This reasoning is supported by a reference to Figure 1, which illustrates the varying co-occurrences of AU1 and AU12. The suggestion to perform cross-dataset experiments to test generalization is a logical and actionable recommendation. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have successfully implemented cross-dataset experiments. Overall, the claim is mostly verifiable, as it provides a solid basis for the argument but could benefit from additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the potential variability in these relationships across datasets. It provides a specific example of how AU6 can occur in different contexts, such as pain and happiness, and how this co-occurrence might differ across datasets like SEMAINE and UNBC pain. The comment suggests a good way to test the generalization of such work by performing cross-dataset experiments, which the paper currently lacks. This feedback is clear and actionable, offering a concrete suggestion for improving the paper by addressing a critical aspect of its methodology. However, it could be more helpful if it provided additional guidance on how to design and implement these cross-dataset experiments. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a contradiction between the statement in the paper and the reviewer\\'s observation regarding over-parameterization. The reviewer acknowledges that over-parameterization is beneficial in practice and references theoretical works supporting this claim. However, the comment does not provide explicit guidance on how the authors should address this contradiction or suggest any specific actions to improve the draft. The feedback lacks actionable details, such as recommending a revision or clarification of the statement in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the statement about over-parametrization and provides a counter-argument with references to theoretical works that support the benefits of over-parametrization. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim made in the paper regarding over-parametrization, suggesting that it is beneficial in practice and supported by theoretical works. The reviewer provides a counter-argument and references a specific example, \"[1],\" which supports their claim. This provides a robust foundation for the reviewer\\'s argument, making it fully verifiable. The inclusion of a reference to theoretical works adds credibility to the claim, allowing the authors to understand the basis of the critique and potentially address it in their work. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment addresses a specific claim made in the paper regarding over-parametrization and its impact on performance. It challenges the statement by providing a counter-argument that over-parametrization is beneficial in practice and references theoretical works that support this claim. This feedback is valuable as it prompts the authors to reconsider their assertion and potentially revise their argument. However, the comment could be more helpful if it offered suggestions on how to integrate this counter-argument into the paper or provided additional references for further exploration. Overall, the comment is somewhat helpful as it identifies a potential weakness and provides some direction for improvement, but it lacks detailed guidance or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that if the compared methods were not pre-trained, the results in Table 1 might be misleading. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting ways to ensure fairness in the comparison or recommending specific actions to clarify the experimental setup. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pre-training conditions for the compared methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unfairness in the experimental comparison, questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. This provides clear guidance on what aspect of the experimental setup needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair because the proposed method was pre-trained before fine-tuning, while it is unclear if the compared methods were initialized with the same or similar pre-trained models. This claim is somewhat verifiable as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to substantiate the claim fully. The authors would need to investigate the details of the pre-training and initialization processes to address the concern, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. This is an important point that could affect the validity of the results presented in Table 1. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the experimental setup. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant concern but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings, referencing a particular study for guidance. It explicitly instructs the authors to consider the performance of their proposed method with better metadata embeddings, providing a clear and concrete action to take. The comment also acknowledges the authors\\' response to the reviews and expresses acceptance of the paper for NIPS. This level of detail and explicit guidance makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and the \"meta-data used here are \u00e2\u0080\u009cattribute\u00e2\u0080\u009d,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using better metadata embeddings and references a specific study, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" to support the suggestion. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the meta-data used in the zero-shot learning results on the CUB dataset are limited to \"attribute,\" which is suitable for fair comparison but may not lead to the best performance. The reviewer references a specific study by Reed et al. to suggest that better metadata embeddings could be used for improved performance. This provides a logical basis for the claim, as it references an external source that could potentially enhance the results. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study. As it stands, the claim is mostly verifiable, as it offers a direction for improvement but lacks comprehensive evidence or detailed explanation. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by recommending the use of better metadata embeddings, referencing a particular study for guidance. This feedback is valuable as it not only identifies a potential area for enhancement but also offers a concrete direction for the authors to explore, which could lead to improved performance. Additionally, the comment acknowledges the authors\\' response to the reviews and expresses acceptance of the paper for NIPS. This combination of constructive feedback and positive acknowledgment makes the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the use of moment matching instead of quantile regression in distributional reinforcement learning (DRL), as most DRL methods use quantile regression. It references a specific paper (Nguyen-Tang et al AAAI\u201921) and suggests that this discussion should be included when discussing various approaches to DRL. The comment provides a clear and explicit action for the authors to take, which is to incorporate a discussion on moment matching in their paper. The suggestion is concrete, as it specifies the type of discussion that should be added and references a relevant paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (22-30) and the topic of distributional reinforcement learning (DRL), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the paper should discuss the use of moment matching instead of quantile regression, as most DRL methods use quantile regression, and references a specific paper (Nguyen-Tang et al AAAI\u201921) for further context. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL), as most DRL methods use quantile regression. The reviewer references a specific paper (Nguyen-Tang et al AAAI\u201921) to support this claim, providing a clear and specific reference that the authors can use to address the critique. This detailed reference and the logical reasoning behind the suggestion make the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the discussion on distributional reinforcement learning (DRL) should include relevant literature on using moment matching instead of quantile regression, as most DRL methods use quantile regression. The comment references a specific paper (Nguyen-Tang et al AAAI\u201921) and provides a clear rationale for why this discussion is important, even though the paper still uses quantile regression. This feedback is actionable and provides a concrete suggestion for enhancing the paper by incorporating a discussion on moment matching. However, it could be more helpful if it offered additional guidance on how to integrate this discussion into the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a reference for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the work is limited, specifically mentioning that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not provide any guidance or suggestions on how the authors could enhance the novelty of their work or propose alternative approaches. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Since the comment is vague and does not offer a concrete path for action, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work by stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the novelty could be improved or what specific aspects of the work are lacking in terms of novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the work is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a perceived limitation in the novelty of the work, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. While this feedback identifies a potential weakness in the paper, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific advice or examples, the authors are left with only a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. The reviewer asks how well the assumptions underlying PCA are met, but does not provide specific guidance on how the authors should address this concern or improve their draft. The comment implies that the authors should provide more information on the assumptions and their fulfillment, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the assumptions and their impact on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive. It also raises a concern about how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper discusses the use of PCA or where these assumptions are addressed, making it weakly grounded. The comment is specific in its critique of the novelty and assumptions related to PCA, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive. The reviewer provides a reference to a paper by Dombrowski et al. (2022) to support the claim that PCA aims to retain the maximum information in the data with reduced dimensionality. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the paper being reviewed to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It raises a valid concern about the assumptions underlying PCA and asks how well these assumptions are met. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve the clarity of their work. While it identifies a potential weakness, it lacks actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance or suggestions on how the authors could expand the scope of their framework or address these concerns. The feedback lacks actionable details, such as recommending specific tasks or models to include or suggesting ways to demonstrate broader applicability. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework\\'s scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. It raises concerns about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not explicitly mention which part of the paper discusses the evaluative framework, making it weakly grounded. The comment is specific in detailing the limitations of the framework and suggesting areas for further exploration, such as broader applicability. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, considering only three Question-Answering tasks and two language models. The comment suggests that this limitation raises concerns about the method\\'s broader applicability and its potential to generalize to other reasoning or generation tasks or more advanced models. However, the comment lacks specific examples or references to support the claim about the limited scope or the need for broader applicability. This makes the claim somewhat verifiable, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the method\\'s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models remains a subject of inquiry. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might expand the scope of their framework or address these concerns. The feedback is somewhat helpful as it points out a limitation but does not provide actionable steps for improvement, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a second y-axis or another visualization to make figure 6C more physically accurate, as it currently implies negative rates when this is not the case. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed to improve the draft. The suggestion is concrete, as it outlines a specific modification that could enhance the clarity and accuracy of the figure. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when this is not the case, and suggests using a second y-axis or another visualization to make it more physically accurate. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C implies negative rates, which is not the case, and suggests using a second y-axis or another visualization for accuracy. While the comment identifies a potential issue with the figure, it lacks specific reasoning or evidence to support why the current visualization is misleading or how a second y-axis would improve accuracy. The suggestion is based on logical reasoning but lacks detailed justification or examples, making it somewhat verifiable. The authors would need to infer the exact nature of the issue and how to address it, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when this is not the case. It provides a clear and actionable suggestion to use a second y-axis or another visualization to make the figure more physically accurate. This feedback is valuable as it directly addresses a potential misunderstanding in the presentation of data, offering a concrete way for the authors to improve the clarity and accuracy of their figures. By suggesting a specific change, the comment empowers the authors to enhance the quality of their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. The action is implicit and vague, as the authors are left to infer that they need to enhance the algorithm\\'s complexity but without any concrete steps or examples to follow. This lack of specificity makes the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to \"Algorithm 2,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspects of the algorithm\\'s complexity need improvement or how it could be enhanced. Without specific guidance or examples, the authors may struggle to understand the exact changes needed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that there is room for improvement in the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential area for improvement by suggesting that the complexity of Algorithm 2 could be enhanced. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might achieve this improvement. Without detailed feedback or actionable advice, the authors are left with a vague direction for enhancing their work. Therefore, the comment is barely helpful, as it points out a general area for improvement but does not offer concrete steps for the authors to follow.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized. Additionally, the reviewer asks whether dropout is applied to the hidden states. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so. The action is implicit but concrete, as it provides a clear direction for the authors to investigate and clarify their statement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs), provides a counterexample from Zaremba et al. (2014), and asks whether dropout is applied to the hidden states. This level of detail provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. Additionally, the reviewer asks whether dropout is applied to the hidden states, which further questions the methodology. The comment is mostly verifiable as it provides a specific counterexample and logical reasoning to support the claim, but it could be strengthened with more detailed references or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LMs) compared to generative adversarial networks (GANs). It provides a counterexample from Zaremba et al. (2014) to challenge the claim, suggesting that the baseline models may not be properly regularized. Additionally, the comment asks whether dropout is applied to the hidden states, which could be relevant to the regularization discussion. This feedback is mostly helpful as it identifies a potential issue with the claim and prompts the authors to clarify or revise their statement. However, it could be more helpful if it offered suggestions on how to address the issue or provided additional context for the authors to consider. Overall, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. While the comment provides a general direction for improvement, it lacks specific guidance on how to achieve this conciseness or what specific empirical results should be included. The authors are left to infer the necessary actions without concrete instructions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which parts of the introduction are overly verbose or which empirical results should be included. This lack of specificity makes it difficult for the authors to identify the exact areas needing improvement. Additionally, the comment does not provide grounding as it does not mention specific sections, figures, or tables, leaving the authors to infer where these changes might be applied. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part, particularly the introduction, could be more concise and should include empirical results. However, it does not provide any specific reasoning, examples, or references to support why the current content is considered overly verbose or how the inclusion of empirical results would improve the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies areas for improvement, the comment lacks specificity and actionable guidance. It does not provide details on what aspects of the introduction are overly verbose or how the authors might condense the content. Additionally, it does not specify which empirical results should be included or how they should be integrated into the paper. This lack of clarity and actionable advice limits the comment\\'s usefulness to the authors, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors can clarify or enhance their technical contribution. The comment lacks actionable details, such as recommending ways to make the contribution more clear or suggesting alternative approaches or analyses. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the analysis are considered standard or unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might clarify or enhance their technical contribution. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but does not offer sufficient direction for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the regularization approach between the LN model and the GLM, noting that the GLM did not crop the image but used L1 regularization and a low rank approximation. The reviewer suggests that to make the comparison fair, it is important to reproduce the main features of previous models. However, the comment does not provide explicit instructions on how to implement this suggestion or what specific changes should be made to the regularization approach. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the regularization method for the LN model to match the GLM. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper discusses the regularization of the LN model and the GLM. It mentions the need to reproduce the main features of previous models, but without explicit references to sections or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. The comment is specific in its suggestion to try to reproduce the main features of previous models, particularly regarding the regularization approach. However, the lack of explicit grounding makes it challenging for the authors to pinpoint where these changes should be implemented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the fairness of the comparison between the LN model and the GLM, noting that the GLM did not crop the image but used L1 regularization and a low rank approximation. The reviewer suggests that to make the comparison fair, it is important to reproduce the main features of previous models. However, the comment lacks specific references or detailed explanations of how the GLM was implemented by pillow et al., making it difficult for the authors to fully understand the basis of the suggestion. This lack of detailed justification or references results in the comment being somewhat verifiable, as it provides a general direction but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the LN model and the GLM, noting that the GLM did not crop the image but used L1 regularization and a low rank approximation. The reviewer suggests that to make the comparison fair, it is important to reproduce the main features of previous models. This feedback is somewhat helpful as it points out a discrepancy in the experimental setup and suggests a way to improve the fairness of the comparison. However, the comment lacks specific guidance on how to implement these suggestions or what exactly needs to be changed in the regularization approach. While it provides a direction for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include failure cases and related discussion in their paper. While the action is explicit, it lacks concrete details on what constitutes a failure case or how the discussion should be structured. The authors are given a clear direction to add this information, but without specific guidance on what aspects to focus on or how to present it, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including failure cases and related discussion, but it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what constitutes a failure case or how the discussion should be structured. Without clear guidance, the authors may struggle to determine how to implement this suggestion effectively. Therefore, the comment is weakly grounded and not specific, aligning with label 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that including failure cases and related discussion would be beneficial. However, it does not provide any specific reasoning or examples to support why this addition would be valuable or necessary. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests including failure cases and related discussion, which could provide valuable insights into the robustness and limitations of the proposed method. However, it lacks specificity and does not provide guidance on what constitutes a failure case or how the discussion should be structured. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a potential issue with the clarity of the paper regarding the use of \\\\( \\\\epsilon \\\\) in equations (10) and (11). It suggests that introducing \\\\( \\\\epsilon \\\\) when discussing equation (11) might improve clarity. This feedback provides a clear and specific action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and equations \"(10)\" and \"(11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of \\\\( \\\\epsilon \\\\) in the equations and suggests introducing it when discussing equation (11). This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction of \\\\( \\\\epsilon \\\\) when discussing equation (11) might improve clarity, as it is not used in equation (10). This is a logical suggestion based on the observed inconsistency in the paper. However, the comment does not provide specific reasoning or evidence to support why this change would enhance clarity, nor does it reference any standards or practices that would justify this suggestion. As a result, the claim is somewhat verifiable, as it provides a reasonable suggestion but lacks detailed justification or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, noting that \\\\( \\\\epsilon \\\\) is not introduced when discussing equation (11), despite being used in equation (10). This feedback is clear and actionable, as it suggests a straightforward improvement that would enhance the reader\\'s understanding of the paper. By addressing this point, the authors can improve the clarity and coherence of their manuscript. However, the comment could be more helpful if it provided additional context or examples of how this inconsistency affects the overall understanding of the paper. Overall, the comment is mostly helpful, as it effectively directs the authors toward a specific enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the limitations of the claim about evolutionary dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some low-variance units. It also mentions that Batch Normalization standardizes the variance and centers the activation, implying that these aspects should be discussed explicitly. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address these limitations or what additional information should be included. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutionary dropout addressing internal covariate shift, suggesting that its effectiveness is limited to increasing the variance of some low-variance units. It also mentions Batch Normalization as a comparison, implying that its limitations should be discussed explicitly. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The authors might infer that it relates to sections discussing evolutionary dropout or Batch Normalization, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the limitations of the claim, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, stating that it can only increase the variance of some low-variance units. The reviewer contrasts this with Batch Normalization, which standardizes the variance and centers the activation. While the comment provides a logical reasoning by comparing the two methods, it lacks specific examples or references to support the claim fully. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it can only increase the variance of some low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. The comment suggests that these limitations should be discussed explicitly, providing a clear direction for the authors to improve their draft by addressing the limitations of their claim. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or provided examples of how to integrate this information into the paper. Overall, the feedback is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution need more detail or how the authors should expand on them. The action is explicit in that it instructs the author to add more description, but it lacks concrete guidance on how to implement this suggestion. As a result, the comment is somewhat actionable, as it provides a clear action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects need to be elaborated on. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts need improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution are lacking or how the current description is insufficient. Without specific examples or detailed reasoning, the claim is not verifiable. The authors may struggle to understand what changes are needed to improve the description of the contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how the authors might enhance their description. Without detailed feedback or actionable suggestions, the authors are left with a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, as it points out a general area for enhancement but does not provide sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set, as it is necessary to include the multiplicities of labels in the graph for the histogram to accurately represent graphs with repeated vertex or edge labels. This feedback provides a clear and explicit action for the authors to take, specifying the change needed to improve the draft. The comment is concrete, as it outlines the exact modification required to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion that \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. This provides clear guidance on what needs to be revised in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Section 4, the term \"X\" should be a multiset rather than a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning by explaining that the histogram should include the multiplicities of labels to honestly represent such graphs. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the necessity of using multisets in this context. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the terminology used in Section 4. It proposes that the term \"X\" should be a multiset rather than a set, as this would better represent graphs with repeated vertex or edge labels. This feedback is clear and offers a concrete way for the authors to improve the accuracy and precision of their work. By addressing this point, the authors can enhance the clarity and rigor of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their derivation. The comment lacks actionable details, such as recommending specific Bayesian considerations or alternative approaches to enhance the realism of the bounds. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' derivation and its relation to classical learning theory-based bounds. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by mentioning that the bounds are not realistic unless Bayesian considerations are taken into account, which could guide the authors in refining their approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. The reviewer provides a logical reasoning by suggesting that Bayesian-PAC based bounds could offer more realistic bounds. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and evidence provided to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, noting that it falls into classical learning theory-based bounds, which are not considered realistic unless Bayesian considerations are taken into account. This feedback highlights a specific area where the authors might need to reconsider their approach to achieve more realistic bounds. However, the comment lacks detailed guidance or suggestions on how the authors might incorporate Bayesian considerations or alternative approaches to improve their derivation. While it points out a relevant concern, the feedback could be more actionable and constructive to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, noting that the authors make claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that ChatGPT and GPT-4 significantly improve translation quality and discourse awareness. The reviewer points out that the differences in scores are minimal and suggests that proper testing, including distribution checks and multiple comparisons, is necessary to determine significance. This feedback is explicit and provides concrete guidance on what the authors need to do to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing to support claims about the differences between methods, particularly in the context of translation quality and discourse awareness. The comment provides specific examples of the scores and methods involved, offering clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the paper for not conducting significance testing to support claims about the differences between methods. It provides specific examples from line 486, comparing the scores of different models, and argues that the differences are minimal and not significant without proper testing. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific statistical methods or standards for significance testing, which would provide a more robust justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a critical issue with the paper: the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors make a claim about the significant improvement in translation quality and discourse awareness, and highlights the need for proper testing to determine the significance of these differences. The comment also suggests checking the distribution and accounting for multiple comparisons, offering clear and actionable guidance for the authors to improve their draft. This level of detail and specificity empowers the authors to make significant improvements to their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for regularization effects to be mistaken for distillation improvements, particularly due to the lack of early-stopping during fine-tuning. It suggests that proper ablation studies are needed to verify these claims. While the comment implies that the authors should conduct additional experiments to address this issue, it does not provide specific guidance on how to design these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to conduct ablation studies but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the study of distillation, where the student distills knowledge to the teacher, and the potential for regularization effects to be mistaken for distillation improvements. It mentions the lack of early-stopping during fine-tuning and the high variances in fine-tuning on GLUE without validation. However, the comment does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proper ablation studies to verify the claims. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for regularization effects to be mistaken for distillation improvements, particularly due to the lack of early-stopping during fine-tuning. The reviewer provides a logical reasoning by pointing out that fine-tuning on GLUE without validation early-stopping often leads to high variances, suggesting that proper ablation studies are needed to verify the claims. This reasoning is based on common knowledge in the field of machine learning, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to studies that support this claim, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that improvements in the teacher\\'s performance are due to distillation rather than regularization effects. It points out that the lack of early-stopping during fine-tuning and the high variances in fine-tuning on GLUE without validation could lead to misleading results. The comment suggests that proper ablation studies are needed to verify these claims. While the feedback highlights a critical area for improvement, it lacks specific guidance on how to conduct these ablation studies or what specific aspects to focus on. This limits the comment\\'s helpfulness, as the authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve their work. There is no explicit or implicit action for the authors to take, leaving them without direction on how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this opinion is based on, nor does it provide details on what aspects of the contribution or model are considered limited or incremental. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement or clarification. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references to what aspects of the contribution are considered limited or how the model is incremental, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular weaknesses or offering guidance on how the authors might enhance their work, the comment does not assist the authors in improving their draft. As a result, it is rated as not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative transfer from supervised pretraining based on the prediction of homo-lumo gap, specifically mentioning the poor performance of Transformer-M on most tasks other than homo, lumo, and gap on QM9. It also questions the claim of the model being \"general-purpose\" in light of these findings. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to respond effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of supervised pretraining based on the prediction of homo-lumo gap and its impact on downstream experiments, specifically on QM9. It also references the claim of the model being \"general-purpose,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details the issue of negative transfer and provides an example of poor performance on most tasks other than homo, lumo, and gap. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, providing an example from QM9 experiments where Transformer-M performs poorly on most tasks other than homo, lumo, and gap. This claim is somewhat verifiable as it references specific tasks and performance metrics, but it lacks detailed evidence or references to substantiate the claim fully. The authors would need to further explore the reasoning behind the negative transfer and the implications for the \"general-purpose\" claim, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the potential negative transfer from supervised pretraining based on the prediction of homo-lumo gap. It provides a specific example from QM9 experiments where Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the model being \"general-purpose.\" This feedback is valuable as it highlights a potential flaw in the paper\\'s claims and suggests that the authors should reconsider their approach or provide further justification for their claims. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or references to support the claim. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides some insight into the problem, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take regarding the experimental evaluation. It points out that the \"picking\" step, which is claimed as a distinction of the approach, is not ablated, suggesting that this aspect should be included in the ablation study. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and questions whether DEN is correctly used or evaluated. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. These points are explicit and provide concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Experimental Evaluation,\" \"Ablations,\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the ablation study, the comparison on CIFAR, and the use of the DEN approach. The comment provides clear guidance on what needs to be addressed, such as including the \"picking\" step in the ablation study, using a fairer comparison setup, and clarifying the evaluation of DEN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the experimental evaluation, specifically questioning the validity of the ablation study and the comparison on CIFAR. It points out that the paper claims a distinction in the \"picking\" step but does not ablate this aspect. Additionally, it notes that the comparison on CIFAR is not convincing, as the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper. The comment provides logical reasoning by highlighting the lack of comprehensive comparison and the need for fair evaluation, which supports the claim. However, it could be strengthened by providing specific examples or references to the DEN paper's setup. Overall, the comment is mostly verifiable, as it provides a reasonable basis for the critique but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides detailed and actionable feedback on the experimental evaluation section of the paper. It points out specific issues, such as the lack of ablation for the \"picking\" step, which is claimed as a distinction of the approach, and the insufficient comparison on CIFAR. The comment suggests that the authors should include more extensive comparisons to other approaches in the continual learning literature and use the same setup as in the DEN paper to ensure a fair comparison. This feedback is clear and constructive, offering the authors specific directions to improve the validity and comprehensiveness of their experimental evaluation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a trade-off in the proposed method, noting that while it reduces computation time, it does so by limiting the search space to ancestral graphs, which results in less information compared to the output of a richer search space, such as DAGs. The reviewer poses a question about how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies an area of concern and raises a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore or address the trade-off between computation time and information richness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the proposed method, namely the reduction in computation time achieved by limiting the search space to ancestral graphs. It contrasts this with the richer search space of DAGs in [10], suggesting a trade-off in terms of information loss. However, the comment does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in detailing the issue of information loss and the trade-off involved, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method reduces computation time by limiting the search space to ancestral graphs, resulting in less information compared to the output of a richer search space, such as DAGs. The reviewer questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment provides a logical reasoning about the trade-off between computation time and information richness, it lacks specific examples or references to support the claim. The question posed is more of a request for clarification rather than a direct critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a trade-off in the proposed method, noting that while it significantly reduces computation time, it does so by limiting the search space to ancestral graphs, which results in less information compared to the output of a richer search space, such as DAGs. The comment highlights the potential loss of information and the price paid for improved performance. However, it does not provide specific suggestions or guidance on how the authors might address this trade-off or mitigate the information loss. While it raises an important point, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises doubts about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It also mentions that RetinaNet and ATSS use similar regression methods, suggesting that the method of directly regressing [w, h] to the center point is sufficient. The reviewer requests clarification on this issue and implies that the motivations may not be solid if the differences are not clear. While the comment identifies areas of confusion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises doubts about the definitions in Table 1, particularly the differences between anchor-based regression and the regression in RepPoints, and compares it to similar methods in RetinaNet and ATSS. The comment suggests that the method of directly regressing [w, h] to the center point is sufficient and questions the motivations if the differences are not clear. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It references similar methods in RetinaNet and ATSS, suggesting that the method of directly regressing [w, h] to the center point is sufficient. The reviewer provides logical reasoning by comparing the methods and their effects, which supports the claim that the differences may not be significant. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies that support the claim. As it stands, the claim is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the definitions in Table 1, specifically questioning the differences between anchor-based regression and the regression in RepPoints. It references similar methods in RetinaNet and ATSS, suggesting that the method of directly regressing [w, h] to the center point is sufficient. The reviewer also expresses doubts about the motivations if the differences are not clear. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper and encourages the authors to clarify their definitions and motivations. However, it lacks specific suggestions or guidance on how to address these issues, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify whether the Fourier modes are real or complex when discussing them as numbers. This is an explicit suggestion, as it directly instructs the authors to provide additional clarification. However, it does not specify how this clarification should be incorporated into the text or what specific details should be included. While the action is clear, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests clarifying whether the Fourier modes are real or complex when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed in, making it weakly grounded. The comment is specific in its request for clarification on the nature of the Fourier modes, but without explicit references to sections or specific elements of the paper, the authors may struggle to pinpoint where this clarification is necessary. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are real or complex when discussing them as numbers. However, it does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the paper. The comment lacks detailed explanation or examples, making it difficult for the authors to understand the importance of this clarification. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should clarify whether the Fourier modes are real or complex when discussing them as numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their manuscript. By addressing this point, the authors can enhance the understanding of their readers, particularly those unfamiliar with the mathematical details of Fourier analysis. However, the comment could be more helpful if it provided additional context or examples of how this clarification might be integrated into the text. Overall, the feedback is mostly helpful as it identifies a clear area for improvement and offers a concrete suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete guidance on how to correct a specific error in the manuscript. It instructs the authors to change \"Fig. 5.1\" to \"Fig. 1\" on line 205 and suggests adding a label after the caption in LaTeX to fix the issue. This feedback is clear and actionable, as it gives the authors precise steps to take to address the problem. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be corrected, including changing \"Fig. 5.1\" to \"Fig. 1\" and suggesting the correct placement of the label in LaTeX. This level of detail helps the authors understand exactly what needs to be revised, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the manuscript. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable piece of feedback regarding a typographical error in the manuscript. It identifies the incorrect reference to \"Fig. 5.1\" on line 205 and suggests the correct reference to \"Fig. 1.\" Additionally, it offers a technical suggestion for fixing the issue in LaTeX by placing the label after the caption. This feedback is clear, precise, and directly addresses a specific error, allowing the authors to make a straightforward correction. The comment is highly helpful as it empowers the authors to improve the accuracy and professionalism of their manuscript.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include case studies and error studies to highlight the effectiveness of each proposed component. It provides a specific example of how the paper could be improved by discussing the Element-level Graph Pre-training, which abandons the strategy of capturing complex structure and focuses on core elements. The reviewer also references a specific example of a case study from another paper, which provides a concrete direction for the authors to follow. This feedback is explicit and offers clear guidance on how to enhance the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Element-level Graph Pre-training. It provides a specific example of what could be discussed, such as the focus on core elements rather than complex structure. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, leaving the authors to infer that it relates to the discussion of the Element-level Graph Pre-training. This makes the comment weakly grounded, as the authors cannot confidently determine the exact section being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed regarding case studies and error studies. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies would enhance the paper\\'s effectiveness in demonstrating the benefits of each proposed component. The reviewer provides a specific example of how the Element-level Graph Pre-training could be better understood by abandoning the strategy of capturing complex structure and focusing on core elements. This example is supported by a reference to another paper, \"Graph pre-training for AMR parsing and generation,\" which provides a concrete example of a case study. The inclusion of this reference and the logical reasoning behind the suggestion make the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. It specifically mentions the Element-level Graph Pre-training and suggests that discussing its focus on core elements rather than complex structure would be more convincing with a case study. The comment also references an example of a case study from another paper, which offers a concrete direction for the authors to follow. This feedback is detailed and constructive, guiding the authors on how to enhance the clarity and persuasiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies an issue with the notation \\\\({\\\\cal P}\\\\) with a subscript being used multiple times without being defined. This feedback provides a clear and explicit action for the authors to take, which is to define the notation \\\\({\\\\cal P}\\\\) with a subscript. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"same section\" where the notation \\\\({\\\\cal P}\\\\) with a subscript is used, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the notation not being defined, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the paper, noting that the notation \\\\({\\\\cal P}\\\\) with a subscript is used multiple times without being defined. This is a factual observation about the paper\\'s content, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the notation \\\\({\\\\cal P}\\\\) with a subscript is used multiple times without being defined. This feedback is clear and actionable, as it directly points out a lack of clarity in the manuscript that the authors need to address. By highlighting this oversight, the comment provides the authors with a precise area to improve, ensuring that their draft is more coherent and understandable. However, the comment could be more helpful if it suggested where in the text the notation should be defined or provided additional context on its usage. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It corrects a spelling error (\"known\" instead of \"know\") at line 148, requests a definition for \\\\(\\\\gamma_0^{***}\\\\) at line 156, and asks for the meaning of the colors in Figure 1 to be specified in both the caption and the text. Each of these points is clear and actionable, giving the authors specific guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as correcting a spelling error, defining a term, and specifying the meaning of colors in the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and requests for clarification, such as correcting a spelling error and defining a term. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying minor errors in spelling and terminology, as well as a request for clarification regarding the meaning of colors in a figure. These points are straightforward and easy for the authors to address, improving the clarity and professionalism of the manuscript. However, the comment could be more helpful if it included suggestions on how to enhance the overall presentation or content of the paper. Despite this, the feedback is mostly helpful as it directly addresses specific issues that can be easily corrected, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses questions about the experimental setup and design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. While these questions imply that the authors should provide explanations or justifications for these design decisions, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. However, the comment does not provide concrete guidance on how to present these explanations or what specific information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by asking for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs of the content encoder (and not the timbre encoder) as input. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the experimental setup and design choices in Figure 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the experimental setup and design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. By asking for the main rationales behind these decisions, the comment prompts the authors to provide a clearer explanation of their methodology. This feedback is somewhat helpful as it identifies areas where the authors can improve the clarity and justification of their work. However, it lacks specific suggestions or guidance on how to address these questions, which would make the feedback more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the writing or presentation is \"jumbled at times,\" but it does not provide specific examples or guidance on how to improve the clarity or organization of the text. Without concrete suggestions or detailed feedback, the authors are left without a clear understanding of what needs to be done to address the issue. The comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the writing or presentation is \"jumbled at times,\" but it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This lack of detail makes it difficult for the authors to identify and address the issues effectively. The comment is not grounded as it does not refer to specific sections, figures, or examples, and it is not specific because it does not provide clear guidance on what needs to be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. The lack of supporting information makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to justify the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the writing or presentation is \"jumbled at times,\" but it does not provide specific examples or detailed feedback on where the issues lie or how they could be improved. Without actionable suggestions or guidance, the authors are left without a clear understanding of what needs to be addressed to enhance the clarity and coherence of their draft. This lack of specificity and actionable advice makes the comment not helpful at all, as it does not provide the authors with a meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand if the Woodbury flow were to be implemented on a mobile device. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what specific steps they should take to evaluate or improve the computational complexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand if the Woodbury flow were to be implemented on a mobile device. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about computational complexity and potential power demands, but without clear grounding, the authors may struggle to identify where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the computational complexity of the method compared to other methods, such as emerging convolutions, and a speculative observation about potential power demands if the Woodbury flow were to be implemented on a mobile device. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, such as emerging convolutions, and speculates on the potential power demand if the Woodbury flow were to be implemented on a mobile device. While it identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address this issue or provide additional information in their paper. The comment is somewhat helpful as it prompts the authors to consider the computational complexity and power demands of their method, but it does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It provides a specific correction based on the findings in Section 3 of Wang et al., 2023. This feedback is clear and actionable, as it directly instructs the authors to correct their statement to accurately reflect the findings of the referenced work. The authors know exactly what needs to be changed and can easily implement this correction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, \"In the base IOI circuit,\" and references Section 3 of Wang et al., 2023. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads, and provides a correction based on the findings in the referenced work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads is incorrect, as supported by Section 3 of Wang et al., 2023. The comment provides a specific reference to an external source, which allows the authors to verify the claim by consulting the referenced work. This detailed reference and the clear explanation of the discrepancy make the claim fully verifiable, as it provides a robust basis for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the authors\\' statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It provides a clear and actionable correction based on the findings in Section 3 of Wang et al., 2023. This feedback is highly helpful as it directly addresses a factual inaccuracy in the paper, allowing the authors to correct their statement and improve the accuracy of their work. By pointing out this error and providing a reference to the correct information, the comment empowers the authors to make a precise and meaningful improvement to their draft. Therefore, it deserves a score of 5, indicating it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that the statement in line 15 is too vague and recommends referencing specific literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. Additionally, it critiques the reinforcement learning/agent analogy in lines 16-18, suggesting that it is out of place and that generalization capabilities are better illustrated by examples later in the paper. The comment offers concrete guidance on how to improve the draft by referencing specific literature and examples, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the vagueness of the statement in line 15 and suggests referencing specific literature on natural language inference. Additionally, it critiques the reinforcement learning/agent analogy and suggests that generalization capabilities are better illustrated by examples later in the paper. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: one about the vagueness of the statement in line 15 and another about the reinforcement learning/agent analogy being out of place. The first claim is supported by a reference to specific literature on natural language inference and a link to a leaderboard, providing a clear direction for the authors to improve their statement. The second claim is supported by logical reasoning, suggesting that generalization capabilities are better illustrated by examples later in the paper. Both claims are well-supported, making the review point mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claims. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues. First, it points out that the statement in line 15 is too vague and suggests referencing specific literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/, which could help clarify the context. Second, it critiques the reinforcement learning/agent analogy in lines 16-18, suggesting that it is out of place and that generalization capabilities are better illustrated by examples later in the paper. This feedback is clear and offers concrete guidance on how to improve the draft, making it highly helpful for the authors. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the statement that \"every kernel can be described by a feature space parameterized by a neural network,\" noting that this is not true for RBF kernels due to their infinite-dimensional RKHS. The reviewer suggests that the limitation should be made more clear. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors know they need to clarify the statement but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, providing a clear explanation of why the claim is incorrect and suggesting that the limitation should be made more clear. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"every kernel can be described by a feature space parameterized by a neural network\" by providing a specific counterexample: the RBF kernel, which has an infinite-dimensional RKHS. This reasoning is logical and based on common knowledge in the field, providing a clear explanation of why the claim is incorrect. The comment suggests that the limitation should be made more clear, which is a constructive critique. However, it could be further strengthened by referencing specific works or studies that discuss this limitation. Overall, the claim is mostly verifiable due to the logical reasoning and specific example provided, but it could be more robust with additional references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim that \"every kernel can be described by a feature space parameterized by a neural network,\" pointing out that this is not true for RBF kernels due to their infinite-dimensional RKHS. The reviewer provides a clear explanation of why the claim is incorrect and suggests that the limitation should be made more clear. This feedback is actionable as it directs the authors to clarify or revise their statement to ensure accuracy and avoid misleading claims. However, the comment could be more helpful if it offered suggestions on how to present this clarification or additional context. Overall, the comment is mostly helpful as it provides valuable insight into a potential weakness in the paper and guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not well-positioned in the literature and suggests that the authors conduct a thorough literature review to situate their work better. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known and has been used in various works, such as denoising score matching and score-interpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to identify relevant works or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the positioning of the proposed method in the literature, specifically mentioning the representation of the marginal score as the expectation of scores of distributions conditioned on inputs. It references specific works, such as denoising score matching and score-interpolation, to illustrate that this idea is not novel. The comment suggests that the authors conduct a thorough literature review to better situate their work. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the literature review or methodology sections. The comment is specific in detailing what needs to be addressed, namely the need for a literature review to situate the work better. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. The reviewer supports this claim by referencing specific works, such as denoising score matching and score-interpolation, which use similar concepts. This provides a clear and specific reference to external sources, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to other works where this idea is used, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it is not well-positioned in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known and has been used in various works, such as denoising score matching and score-interpolation. The comment suggests that the authors conduct a thorough literature review to better situate their work within the existing body of knowledge. This feedback is clear and actionable, providing a specific direction for the authors to improve their draft by situating their work more effectively within the existing literature. However, the comment could be more helpful if it included specific references or examples of works to consider, which would provide even more detailed guidance. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the technical contribution is limited, indicating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could enhance their technical contribution or what specific aspects need improvement. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed to address the concern. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contributions or extensions based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are considered limited. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a perceived limitation in the technical contribution of the paper, stating that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this limitation or enhance their technical contribution. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It also notes that the results of WeakNAS are similar to those of BRP-NAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or originality of the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy, which are compared to existing methods. It also references Table 2 in Appendix C, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific because it details the similarities between the proposed approach and existing methods, providing clear guidance on what aspects need to be addressed or differentiated. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It supports this claim by referencing specific methods (MLP, Regression Tree, Random Forest) and comparing the sampling strategy to epsilon-greedy and BRP-NAS. Additionally, it mentions that the results of WeakNAS are similar to those of BRP-NAS, as shown in Table 2 in Appendix C. This detailed comparison and reference to existing literature provide a robust foundation for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies specific components of the approach that are not novel, such as the use of weak predictors like MLP, Regression Tree, or Random Forest, which have been used in previous NAS performance prediction studies. It also points out that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS, and notes that the results of WeakNAS are nearly identical to those of BRP-NAS. While the comment highlights a lack of novelty in the approach, it does not provide constructive suggestions or guidance on how the authors might address this issue or differentiate their work. The feedback is somewhat helpful as it alerts the authors to a potential weakness in their approach, but it lacks actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for 4-class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should clarify their methodology and include additional metrics, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to provide more details and results. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of precision, recall, and F1-score for 4-class classification of breast density, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of AUC results for breast cancer detection, providing clear guidance on what additional information could be beneficial. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for 4-class classification of breast density, suggesting that providing AUC results would be more informative. While the comment highlights a potential gap in the presentation of results, it does not provide specific reasoning or evidence to support why AUC results are more informative or how they would enhance the analysis. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of AUC results themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it raises a specific question about the calculation of precision, recall, and F1-score for a 4-class classification of breast density. It also suggests providing AUC results for breast cancer detection, which is a common practice in the field. This feedback is actionable and provides clear guidance on how the authors can enhance the presentation of their results, making it easier for readers to compare model performance. However, the comment could be more helpful if it included additional suggestions or examples of how to present the AUC results effectively. Overall, the comment provides valuable insights and direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the creation of the dataset is optional, as the Kialo dataset already provides what the authors need. It suggests that the dataset created in the paper could serve as additional data for learning. However, the comment does not provide explicit guidance on how the authors should address this observation, such as whether they should use the Kialo dataset instead or how to integrate their dataset with the existing one. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset, specifically mentioning the Kialo dataset as an alternative that is well-studied in the community. It highlights that the Kialo dataset provides pairs of short claims and their counters, which are cleaner than the dataset created in the paper. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in detailing the issue with the dataset and suggesting an alternative, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the creation of the dataset is optional, as the Kialo dataset already provides what the authors need. It supports this claim by stating that the Kialo dataset is well-studied and cleaner than the dataset created in the paper, as it does not rely on automatic processes. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by pointing out that the creation of the dataset is optional, as the Kialo dataset already provides what the authors need. It highlights that the Kialo dataset is well-studied and cleaner than the dataset created in the paper, suggesting that the authors could use the existing dataset instead. Additionally, it acknowledges that the dataset created in the paper could still serve as additional data for learning. This feedback is constructive and offers a practical alternative that could enhance the paper\\'s contribution. However, it could be more helpful if it included specific guidance on how to integrate the Kialo dataset into the paper. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the novelty of the proposed modification to the transformer, noting that it does not bring significant insight in terms of machine learning. It also questions the significance of the improvement brought by the self-cross attention in the ablation study. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these concerns or improve their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the novelty or significance of the proposed method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed modification to the transformer, specifically mentioning the cross-layer modification and the limited improvement brought by the self-cross attention in the ablation study (table4 and 5). This provides full grounding as it explicitly mentions the relevant sections of the paper, allowing the authors to accurately identify the parts being addressed. The comment is also specific, as it details the issue with the novelty of the proposed modification and the limited improvement observed in the ablation study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed modification to the transformer, specifically the cross-layer modification, does not bring significant insight in terms of machine learning. It supports this claim by pointing out that the self-cross attention in the ablation study brings limited improvement (<1%) and suggests that the main improvements come from using a na\u00efve transformer rather than the proposed modification. While the comment provides some reasoning and specific examples from the ablation study, it lacks detailed evidence or references to substantiate the claim fully. The authors might need more information to fully understand and address the critique. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some support but requires additional detail for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the novelty of the proposed modification to the transformer, suggesting that it does not bring significant insight in terms of machine learning. It also questions the significance of the improvement brought by the self-cross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer rather than the proposed modification. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or actionable feedback on how the authors might address these concerns or enhance the novelty of their work. The comment provides some insight into the perceived limitations but does not offer detailed guidance for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" and to illustrate the relationship between that work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, including discussing a specific previous work and comparing it to their own. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the lack of research focusing on the joint error for UDA and references a specific previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" published in ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: discussing the relationship between the proposed method and the referenced work and explaining why the proposed method is better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim about the lack of research on the joint error for UDA by referencing a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" published in ICML2019. This reference provides a specific example of existing research on the topic, which supports the reviewer\\'s claim that the problem has been studied. The comment suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method, providing a clear rationale for why the claim is not valid. This detailed reference and logical reasoning make the claim mostly verifiable, as it provides a solid basis for the reviewer\\'s argument. However, the comment could be further strengthened by providing more detailed comparisons or examples of how the proposed method differs from the referenced work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a potential issue with the authors\\' claim regarding the novelty of their work. It points out that the problem of arbitrarily increased joint error has been studied in a previous work, providing a specific reference. The comment suggests that the authors should discuss this previous work and clarify the relationship between it and their proposed method, as well as explain why their method is better. This feedback is clear and actionable, guiding the authors to address a critical aspect of their paper\\'s originality and positioning. However, it could be more helpful if it offered specific suggestions on how to effectively integrate this discussion into the paper. Overall, the comment provides valuable direction for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a newly collected dataset of 209M, while existing methods use smaller datasets. It implies that the authors should consider the impact of dataset scale on the accuracy and potentially adjust their claims or comparisons. However, the comment does not explicitly instruct the authors to make any specific changes or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and possibly provide additional analysis or context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a newly collected dataset of 209M compared to existing methods using smaller datasets, such as GEM with only 20M unlabeled data. This provides a clear indication of the part of the paper being discussed, allowing the authors to identify the relevant section. The comment is also specific, as it highlights the potential impact of dataset scale on the accuracy and suggests that the superiority of the proposed method may be due to the new large-scale dataset. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a newly collected dataset of 209M, while existing methods use smaller datasets. The reviewer provides a specific example, GEM, which uses only 20M unlabeled data. This comparison highlights the potential impact of dataset scale on accuracy, suggesting that the superiority of the proposed method may be due to the new large-scale dataset. The comment is mostly verifiable as it provides a logical reasoning and specific examples to support the claim, but it could be further strengthened with additional references or detailed comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the paper\\'s performance against state-of-the-art (SOTA) methods. It points out that the paper\\'s performance is based on a newly collected dataset of 209M, while existing methods use smaller datasets, such as GEM with only 20M unlabeled data. The comment highlights the significant impact of dataset scale on accuracy, suggesting that the superiority of the proposed method may be due to the new large-scale dataset rather than the method itself. This feedback is mostly helpful as it provides a clear and actionable insight into a potential bias in the comparison, prompting the authors to reconsider their claims or provide additional context. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to fairly compare performance across different dataset scales. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment highlights a gap in the justification and discussion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide a justification and discussion of the research gap. However, the comment lacks concrete details on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for designing a new curriculum learning method for text graphs is not justified, and the research gap, such as why existing methods cannot be applied, is not discussed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to existing methods or research gaps, making it difficult for the authors to understand the basis of the claim. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide sufficient support for the authors to address the critique effectively. Therefore, the comment is rated as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing a clearer rationale for the proposed approach. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or what aspects of the existing methods should be considered. To be more helpful, the comment could include examples or references to existing methods that could be applied or suggest ways to justify the need for a new method. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that powerful pre-trained language models like BERT and XLNet should be used as the base encoder for all methods, rather than relying on the simplest n-gram features. This implies a specific action for the authors to take: to use these models as the base encoder and compare the efficacy of the transfer parts. However, the comment does not provide detailed guidance on how to implement this change or what specific aspects of the transfer parts should be compared. While the action is clear, the lack of concrete instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, rather than relying on the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the experimental setup or methodology, but this inference is not direct. The comment is specific in suggesting a change in the approach to domain adaptation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that powerful pre-trained language models like BERT and XLNet can overcome the domain-shift problem to some extent. This claim is supported by logical reasoning, as these models are known for their ability to adapt to different domains. However, the comment lacks specific references or detailed evidence to fully substantiate the claim, such as studies or experiments demonstrating the effectiveness of these models in domain adaptation. While the reasoning is sound, the absence of explicit references or examples makes the claim somewhat verifiable, as the authors would need to further explore the evidence themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the methodology of the paper by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for all methods. This suggestion is actionable and could significantly enhance the paper\\'s experimental setup, potentially leading to more robust and meaningful comparisons. However, the comment could be more helpful if it included additional details or examples of how to implement this change or why it would be beneficial. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that Figure 4 illustrates a comparison of final results with a single data sample, which raises doubts about the current evaluations. The reviewer implicitly suggests that a quantitative comparison on the final outputs would be more convincing. While the comment identifies an issue and hints at a potential solution, it does not explicitly instruct the authors to make the comparison or provide detailed guidance on how to implement it. The action is inferred and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitative evaluation results in Figure 3 only reflect middle outputs, rather than the final outputs, and suggests that Figure 4 illustrates a comparison of final results with a single data sample. The comment further questions whether a quantitative comparison on the final outputs is possible, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that Figure 4 provides a comparison of final results with a single data sample, which raises doubts about the current evaluations. The reviewer implies that a quantitative comparison on the final outputs would be more convincing. However, the comment lacks specific examples or references to support the claim that the current evaluations are insufficient. While it provides a logical reasoning for the critique, it does not offer detailed evidence or comparisons to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it requires more detailed justification to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results presented in the paper, noting that they only reflect middle outputs rather than the final outputs. It points out that Figure 4 illustrates a comparison of final results with a single data sample, which raises concerns about the validity of the current evaluations. The comment suggests that a quantitative comparison on the final outputs would be more convincing in confirming ModelAngelo\\'s superiority over competitors. This feedback is clear and actionable, providing the authors with a specific direction for improving their evaluation methodology. However, it could be more helpful if it offered additional guidance on how to conduct such a comparison or suggested specific metrics to use. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear suggestion for enhancing the paper\\'s evaluation section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. While the comment identifies multiple areas that need clarification, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to provide more detailed explanations in these areas, but the lack of specific guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it provides detailed questions about the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, generation of landmarks, number of landmarks used, type of image features, fixed radius with different scales, and achieving shape invariance. These detailed questions and examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or experiments where these details are lacking, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail regarding the techniques used, which makes it difficult to reproduce the results. It provides specific questions about the sparsification process, the generation of landmarks, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. These questions highlight critical areas where the paper is lacking in clarity and detail, providing the authors with clear guidance on what needs to be addressed to improve the reproducibility and comprehensiveness of their work. The comment is mostly helpful as it offers specific areas for improvement, but it could be more helpful if it included suggestions on how to address these issues. Overall, the feedback is actionable and constructive, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential biases introduced by basing eviction decisions purely on utility scores, specifically mentioning the possibility of premature evictions of valuable chunks due to temporary high utility scores. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or mitigate the biases. The comment lacks actionable guidance, such as recommending alternative approaches or methods to ensure fair eviction decisions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the FIITED approach, namely the utility-based approach to determine chunk significance. It raises a concern about potential biases introduced by basing eviction decisions purely on utility scores, providing an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The authors can infer that it relates to sections discussing the FIITED methodology, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in detailing the potential issue with the utility-based approach, providing a clear critique. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential biases introduced by basing eviction decisions purely on utility scores, specifically mentioning the possibility of premature evictions due to temporary high utility scores. This claim is somewhat verifiable as it provides a logical reasoning for the potential issue, but it lacks specific examples or references to substantiate the claim further. The authors would need to make a significant effort to understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the FIITED approach, specifically the utility-based method for determining chunk significance. It highlights a concern that basing eviction decisions solely on utility scores might introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores. This feedback is valuable as it points out a critical aspect of the methodology that could impact the overall effectiveness of the approach. However, the comment does not provide specific suggestions or alternatives for addressing this issue, such as proposing additional criteria or methods to mitigate the biases. While it raises an important point, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first paragraph of the Introduction is not relevant to the paper\\'s focus on detecting drift types and magnitude, as it is entirely devoted to a general introduction of DNNs. The reviewer implies that this paragraph should be revised or removed to better align with the paper\\'s core content. However, the comment does not provide explicit instructions on how to revise or remove this content, leaving the authors to infer the necessary changes. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paragraph, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The comment suggests that this introduction is not central to the paper and provides little valuable information to readers. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs, which is irrelevant to the paper\\'s focus on detecting drift types and magnitude. The reviewer suggests that this introduction provides little valuable information to readers. However, the comment lacks specific examples or references to support the claim that the DNN-related introduction is not central to the paper. Without detailed justification or evidence, the claim remains somewhat vague, making it challenging for the authors to fully understand and address the critique. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and focus of this introductory paragraph to better align with the paper\\'s main contributions. However, the comment could be more helpful if it provided suggestions on how to restructure or refine the paragraph to better integrate with the paper\\'s content. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It suggests that the authors should include quantitative experiments and comparisons between algorithms, as well as more detailed explanations of the presented algorithms. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The feedback is somewhat actionable because it provides a clear direction for improvement but lacks specific guidance on how to implement the suggested changes. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental aspect of the paper, specifically questioning the clarity of how different parts of the framework contribute to the final result. It mentions the lack of quantitative experiments and comparisons between algorithms, as well as a need for more detailed explanations. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. While the authors might infer that it relates to the results or methodology sections, the comment lacks explicit grounding. It is specific about the need for more detailed explanations and quantitative comparisons but does not provide detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the experimental results, specifically questioning the performance of different parts of the framework and their contribution to the final outcome. The reviewer notes the lack of quantitative experiments and comparisons between algorithms, as well as a need for more detailed explanations. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claim that the current results are insufficient. This makes the claim somewhat verifiable, as it highlights gaps but lacks detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the experimental section regarding the performance of different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons between algorithms, as well as detailed explanations of the presented algorithms. This feedback is somewhat helpful as it highlights specific areas where the paper could be improved, such as including quantitative analyses and detailed explanations. However, it could be more helpful if it provided specific suggestions on how to conduct these analyses or what aspects to focus on. Overall, the comment offers valuable insights but lacks comprehensive guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare their results on the official COOC leader board on the blind test set, referencing a specific URL and mentioning that several approaches have improved since the paper was published. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it specifies the action and provides a clear direction for implementation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leader board on the blind test set, providing a specific URL for reference. It also specifies the issue by pointing out that the paper only compares to related work on some not official test set or dev set, and suggests that the authors should compare to approaches that have won the challenge and have been evaluated on the blind challenge set. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s comparison to related work is limited to unofficial test sets, suggesting that the final results should be compared on the official COOC leader board on the blind test set. The reviewer supports this claim by referencing specific approaches that have won the challenge and been evaluated on the blind test set, as well as mentioning that several other approaches have improved since the paper was published. This provides a clear and specific reference to external sources, making the claim fully verifiable. The inclusion of specific examples and references to the COOC leader board and the approaches that have won the challenge strengthens the justification, aligning with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors compare their results on the official COOC leader board on the blind test set. It references specific examples of approaches that have won the challenge and been evaluated on the blind test set, as well as mentioning that several other approaches have improved since the paper was published. This feedback is highly helpful as it guides the authors to enhance the credibility and relevance of their results by aligning them with the official evaluation standards. The comment is specific and provides a clear direction for improvement, making it highly beneficial for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify the meaning of \"wrong\" in the context of the paper, suggesting that they should define what constitutes a good, bad, or wrong explanation before using these terms. This feedback provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be clarified in their draft. The comment is specific and actionable, as it guides the authors on how to improve their manuscript by providing a concrete step to enhance clarity. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the term \"wrong\" and the need to define what constitutes a good, bad, or wrong explanation before using those concepts. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the term \"wrong\" used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by clarifying the meaning of the term \"wrong\" in the context of the paper. It suggests that the authors should define what constitutes a good, bad, or wrong explanation before using these concepts, which would enhance the clarity and understanding of the paper for readers. This feedback is clear and actionable, providing the authors with a direct suggestion on how to improve their draft. However, it could be more helpful if it included examples or further guidance on how to effectively define these terms. Overall, the comment is mostly helpful as it highlights a specific area for improvement and offers a constructive suggestion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the experimental demonstration of the contribution points, noting that there is only a comparison between ELF and the baseline without Mid Vision Feedback (MVF), but no comparison with the image classification result of MVF. This implies that the authors should include a comparison with MVF to demonstrate the superiority of their method. While the comment identifies a clear action, it does not provide detailed guidance on how to conduct this comparison or what specific aspects should be focused on. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental comparison between ELF and the baseline without Mid Vision Feedback (MVF), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with the image classification result of Mid Vision Feedback (MVF) to prove the superiority of the schema searched by ELF. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This claim is somewhat verifiable as it highlights a gap in the experimental analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this comparison and how it impacts the paper\\'s claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the experimental demonstration of the paper\\'s contribution points. It points out that the paper lacks a comparison with the image classification result of Mid Vision Feedback (MVF), which is crucial for proving the superiority of the schema searched by the authors\\' method, ELF. This feedback is clear and actionable, as it provides a direct suggestion for improving the experimental section by including a comparison with MVF. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should clarify the novelty of their contributions, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, specifically mentioning similarities in reasoning and writing logic to a previous study. However, it does not specify which parts of the article are similar or how they compare to the previous study. This lack of detail makes it difficult for the authors to identify the exact sections that need attention or improvement. While the comment suggests a potential issue, it does not provide enough grounding or specificity to guide the authors effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, suggesting similarities in reasoning and writing logic to a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The lack of explicit references or detailed reasoning makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of a potential issue but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension of the previous study or if it introduces novel contributions. While this feedback highlights a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work. The comment prompts the authors to consider the novelty of their contributions but does not provide actionable steps or examples to help them improve their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' discussion of regret and their proof of achieving T^{1/2} regret. It asks whether the prediction error over the entire horizon T cannot be sublinear. While the comment highlights a potential inconsistency or misunderstanding in the paper, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their discussion or proof, and it is vague because it lacks concrete steps for improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the discussion about regret and the proof of achieving T^{1/2} regret, asking whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the authors\\' discussion of regret and their proof of achieving T^{1//2} regret. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the paper, specifically questioning the authors\\' discussion of regret and their proof of achieving T^{1/2} regret. It asks whether the prediction error over the entire horizon T cannot be sublinear, which suggests a need for clarification or correction in the paper. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might address this inconsistency or improve their explanation. The feedback is somewhat helpful as it points out a potential problem, but it lacks depth and actionable advice, leaving the authors with only a partial understanding of what needs to be clarified or corrected. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s claim about the importance of learning long-range dependencies for powerful predictors. It suggests that the authors should discuss the necessity of this requirement and the implications of not encoding locality in the graph structure. While the comment implies that the authors should address these concerns, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the necessity of learning long-range dependencies for powerful predictors and suggests that the authors should discuss this further. The comment provides a clear direction for improvement by questioning the requirement of locality in the graph structure and its implications on prediction. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that this is evident in the visualizations in Table 3 but questions whether it is fully required. The comment suggests that the truth might lie somewhere in between and implies a need for further discussion. However, the claim lacks specific examples or references to support the assertion that locality is not fully required. The reasoning is somewhat logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the necessity of learning long-range dependencies for powerful predictors. It acknowledges that this is evident in the visualizations in Table 3 but questions whether it is fully required. The comment suggests that the truth might lie somewhere in between and implies that a discussion on this topic is missing. Additionally, it raises a concern about the implications of not encoding locality in the graph structure, suggesting that prediction might depend on image size. This feedback is somewhat helpful as it points out a specific area for improvement and encourages the authors to address the discussion on the necessity of long-range dependencies. However, it could be more helpful by providing specific suggestions on how to explore this topic or what aspects to consider in the discussion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the notation in Equation (3) and discusses the exponential dependence of corollaries and theorems on the diameter $M$ of the domain of data. It also mentions that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending ways to improve the theoretical results or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, corollaries, and a theorem, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the diameter $M$ and its impact on the required feature size, providing clear guidance on what needs to be addressed. Additionally, it references Figure 1, which further grounds the comment. The comment is specific in detailing the issues with the theoretical results and their implications for the proposed approaches. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the exponential dependence of corollaries and theorems on the diameter $M$ of the domain of data, which affects the required feature size. It provides a logical reasoning by explaining how this dependence impacts the performance, particularly in Figure 1, where the performance is worse than standard random features. The comment suggests that this may indicate a weakness in the proposed approaches. While the reasoning is clear, it could be strengthened with specific examples or references to similar studies. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the theoretical results presented in the paper, specifically focusing on the exponential dependence on the diameter $M$ of the domain of data. It highlights the impact of this dependence on the required feature size and its implications for the performance of the proposed approaches. The comment also references Figure 1, which shows that the performance is worse than standard random features, suggesting a potential weakness in the theoretical results. This feedback is mostly helpful as it identifies a critical issue with the theoretical foundation of the paper and provides a clear direction for the authors to address it. However, it could be more helpful if it offered specific suggestions on how to mitigate or address the identified weaknesses. Overall, the comment provides valuable insights but lacks comprehensive guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit, as the authors need to infer that they should consider oversmoothing as a potential cause and possibly explore it further. The lack of concrete steps or specific recommendations makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It suggests that oversmoothing could also be a contributing factor, referencing a specific paper for context. However, the comment does not explicitly mention which part of the paper discusses DGNs or long-range modeling, making it weakly grounded. The authors can infer that it relates to sections discussing DGNs or modeling, but the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in identifying potential causes for poor performance, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients. The reviewer supports this claim by referencing a specific paper, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,\" which discusses oversmoothing in the context of very deep graph networks. This reference provides a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It suggests that oversmoothing could also be a contributing factor, referencing a specific paper for context. This feedback is valuable as it provides the authors with a new perspective on the potential causes of their model\\'s performance issues. However, the comment could be more helpful if it offered specific suggestions on how to address oversmoothing or provided additional references or examples to further explore this aspect. Overall, the comment is somewhat helpful as it highlights an area for further investigation but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. Since the comment is vague and does not offer a clear path for action, it is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear or provide details on what aspects need clarification. This lack of specificity makes it difficult for the authors to identify and address the issue effectively. Additionally, the comment does not mention specific sections or examples, making it challenging for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide detailed guidance or suggestions on how to improve the clarity. Without concrete examples or specific feedback, the authors are left with a general indication of an issue but no clear direction on how to address it. This limits the usefulness of the feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about why finer grouping for quantization is not considered instead of per-tensor and per-channel. While it implies that the authors should consider this alternative, it does not provide explicit guidance or suggestions on how to implement it or what specific aspects should be considered. The action is implicit and vague, leaving the authors without clear steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where quantization methods are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests an alternative approach, it does not provide specific details or examples of how this finer grouping could be implemented or why it might be beneficial. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question asking for clarification on the choice of quantization method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization method, specifically asking why finer grouping is not considered instead of per-tensor and per-channel. While this question prompts the authors to reconsider their approach, it lacks depth and does not provide specific guidance or suggestions on how to implement finer grouping or what benefits it might offer. The comment is somewhat helpful as it encourages the authors to explore an alternative method, but it does not offer actionable steps or detailed insights that would significantly enhance the draft. Therefore, the comment aligns with a score of 3, indicating it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"For training we used an epsilon-greedy ...\" and asks whether it refers to epsilon-greedy exploration on top of the proposed strategy. While the comment highlights a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this part of the text. However, the comment lacks concrete details on how to clarify the meaning, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the location \"Just before Appendix D.2\" and the specific phrase \"For training we used an epsilon-greedy ...\", allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"epsilon-greedy\" and whether it refers to exploration on top of the proposed strategy. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the meaning of a specific phrase in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, questioning the meaning of \"For training we used an epsilon-greedy ...\" and whether it refers to epsilon-greedy exploration on top of the proposed strategy. This feedback is clear and actionable, as it prompts the authors to clarify this aspect of their methodology. By addressing this point, the authors can improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided suggestions on how to clarify this section or offered examples of how to present this information more clearly. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control might only show meaningful performance gains on bit-serial accelerators, which are less common than bit-parallel fixed-point numbers used in most existing ML accelerators. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or explore the implications of their methodology on different accelerator types. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the topic of dynamic precision control during training and its implications for bit-serial accelerators. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment does provide some specificity by mentioning the potential limitations of the proposed methodology on bit-parallel fixed-point numbers, which could restrict its implications. However, it lacks detailed guidance on how to address this limitation or improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that dynamic precision control might only show meaningful performance gains on bit-serial accelerators, which are less common than bit-parallel fixed-point numbers used in most existing ML accelerators. This claim is somewhat verifiable as it provides a logical reasoning based on the common use of bit-parallel fixed-point numbers in existing accelerators. However, the comment lacks specific examples or references to support the claim fully, such as studies or data showing the performance differences between bit-serial and bit-parallel accelerators. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, specifically noting that dynamic precision control might only show meaningful performance gains on bit-serial accelerators, which are less common than bit-parallel fixed-point numbers used in most existing ML accelerators. This observation highlights a critical aspect that the authors need to consider in terms of the applicability and implications of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore the implications further. While it points out an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights confusion regarding Eq. 12, specifically questioning where the reward comes from at each trial and whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides explicit actions for the authors to take, namely clarifying the equation and using equations to explain the network model. However, it does not provide detailed guidance on how to clarify the equation or which equations should be used to explain the network model. While the actions are explicit, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Eq. 12, questioning the source of the reward and whether it is derived from Eq. 11. Additionally, it suggests that explaining the network model in Section 4.2 with equations would improve clarity. The comment provides specific guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Eq. 12, specifically questioning the source of the reward at each trial and whether it is derived from Eq. 11. The reviewer suggests that explaining the network model in Section 4.2 with equations would improve clarity. However, the comment does not provide specific reasoning or examples to support why the current explanation is confusing or how the suggested approach would enhance clarity. The inclusion of external references does not directly address the issue with Eq. 12, making the claim somewhat verifiable. The authors would need to infer the specific issues and how to address them, thus justifying a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Eq. 12, questioning the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Section 4.2 with equations would improve clarity, providing a clear and actionable suggestion for improvement. Additionally, the comment includes references to external sources that could be relevant for the authors to consider, which could further enhance the paper. However, the comment could be more helpful if it provided more detailed guidance on how to clarify the equation or suggested specific equations to use in the explanation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and offers a potential solution, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the idea is insufficient and mentions that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or complexity of their work. The comment lacks actionable details, such as recommending ways to improve the novelty or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the idea and mentions that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper discusses these elements, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the novelty are insufficient or how the metric and method could be improved. Without clear references or detailed feedback, the authors cannot effectively address the concerns raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is insufficient, stating that both the new metric and method are relatively straightforward. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a perceived lack of novelty in the idea presented in the paper, noting that both the new metric and method are relatively straightforward. However, it does not provide specific examples or suggestions on how the authors could enhance the novelty or complexity of their work. Without actionable feedback or detailed guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. While it provides a general direction for improvement, it lacks specific guidance on how to implement these suggestions or which parts of the description should be revised. The authors are left with a vague understanding of what changes are needed, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning that the generative process could be better understood if presented in separate steps and that too many symbols and a notation table could be beneficial. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure where the model description is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting improvements to the model description. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and by including a notation table. However, it does not provide specific examples or detailed reasoning to support why these changes would enhance understanding. The comment lacks explicit evidence or references to substantiate the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient detail.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the model description. It suggests that the generative process could be better understood if presented in separate steps and that a notation table could be beneficial. This feedback is clear and actionable, providing the authors with a concrete way to enhance the clarity and comprehensibility of their model description. However, the comment could be more helpful if it included specific examples or guidance on how to structure the model description or what symbols to include in the notation table. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should better motivate the \"Why\" aspect, which refers to the importance or relevance of the topic being presented. However, it does not provide specific guidance on how to achieve this motivation or what aspects should be highlighted to make the motivation clearer. The action is implicit and vague, as the authors are left to infer that they need to add a section or discussion on the motivation but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should better motivate the \"Why\" aspect, which refers to the importance or relevance of the topic being presented. However, it does not specify which part of the paper lacks this motivation or provide details on what aspects should be addressed to improve the motivation. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should better motivate the \"Why\" aspect, which refers to the importance or relevance of the topic being presented. However, the comment does not provide any specific reasoning, examples, or references to support why this motivation is lacking or how it could be improved. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should better motivate the \"Why\" aspect, which refers to the importance or relevance of the topic being presented. While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable guidance on how the authors might improve this aspect. Without detailed suggestions or examples, the authors are left with a general idea of what needs to be addressed but without clear steps to take. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient direction for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also notes that Table 5 shows a trade-off between head and tail categories but suggests that this trade-off has not been fully investigated for the baselines. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or what changes should be made to the paper. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and references the work of \"Kang et al.,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance and that the trade-off between head and tail categories has not been fully investigated for the baselines. The comment also suggests that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It supports this claim by referencing Table 5, which shows a trade-off between head and tail categories. The reviewer suggests that similar trade-offs have not been fully investigated for the baselines, implying that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This reasoning is somewhat verifiable, as it provides a logical basis for the claim but lacks specific examples or detailed comparisons to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a critical area for improvement and provides a direction for further exploration. However, the comment could be more helpful by offering specific suggestions on how to address these issues or by providing examples of hyper-parameter changes that could be tested. Overall, the comment is mostly helpful as it directs the authors to a key area needing attention and encourages them to continue their work for future submission, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved, specifically by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic. Additionally, it mentions that the generation of authors is not realistic, as author embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to enhance the realism of the evaluation. The feedback is somewhat actionable as it highlights potential weaknesses but lacks concrete steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the prompt requirements. It mentions the need for all structured elements for perspectives to be present in the generated tweets, which is not the most realistic, and points out that the generation of authors is not realistic due to the initialization of author embeddings by averaging artificial tweets. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the evaluation of weak supervision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of the evaluated tweets and the prompt requirements, suggesting that they may not be the most realistic. The comment provides specific examples, such as the need for all structured elements for perspectives to be present in the generated tweets and the unrealistic generation of authors. This detailed critique supports the claim with logical reasoning and specific examples, making it mostly verifiable. However, the comment could be further strengthened by referencing external sources or studies that support the notion of unrealistic prompts or generations. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of weak supervision, questioning the realism of the evaluated tweets and the prompt requirements. It points out that the prompt may not be the most realistic, as it requires all structured elements for perspectives to be present in the generated tweets. Additionally, it mentions that the generation of authors is not realistic, as author embeddings are initialized by averaging artificial tweets. This feedback is clear and actionable, as it provides the authors with specific areas to consider for improving the realism and validity of their evaluation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of more realistic prompts. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their evaluation process.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This is an explicit suggestion, as it directly instructs the authors to conduct a specific comparison. However, while the action is clear, it lacks detailed guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" However, it does not explicitly mention which part of the paper this comparison should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation or comparison of the proposed model, but this inference is not as direct as it could be. The comment is specific in suggesting a particular comparison, but it is weakly grounded because it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). The claim about the ternary potential is not supported by specific evidence or detailed reasoning, making it somewhat verifiable. The suggestion to compare with existing models is logical but lacks a clear explanation of how this comparison would support the claim about the ternary potential. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by comparing their proposed model with a relevant benchmark. By suggesting a comparison with a specific model, the comment offers a straightforward way for the authors to validate and improve their findings. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design choice. The comment lacks actionable guidance, such as recommending alternative approaches or providing a rationale for the current choice. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10, providing a clear rationale for why this might be an odd choice, especially since the question model is a bag of words. This provides the authors with clear guidance on what aspect of their design choice is being questioned. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. The comment provides a logical reasoning by pointing out the potential inefficiency of the design choice, which is based on the understanding that longer sequences are not inherently costly to process. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice given that the question model is a bag of words, which is not expensive to encode longer sequences. This feedback highlights a potential inconsistency or inefficiency in the design, prompting the authors to reconsider their approach. However, the comment lacks specific suggestions or alternatives for addressing this issue, which limits its helpfulness. While it identifies a potential area for improvement, it does not provide actionable guidance or detailed advice on how to resolve the problem. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of a specific expression in Equation (2), \"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$.\" This implies that the authors should clarify or provide an explanation for this expression. While the action is implicit, it is clear and concrete, as it directly points to a specific part of the paper that needs clarification. The authors can infer that they need to address this expression in their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of a particular expression, \"$:\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$,\" within that equation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the meaning of a specific expression in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific expression in Equation (2), indicating a potential lack of clarity in the manuscript. This feedback is somewhat helpful as it prompts the authors to clarify or provide an explanation for the expression in question. However, the comment does not offer suggestions on how to address the issue or provide additional context that would make it more actionable. While it points out a potential area for improvement, it lacks depth and specificity, leaving the authors with only a partial understanding of what needs to be clarified. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete instructions for the authors, specifying that two lines in red should be changed to green in the Supplementary Material. It also provides specific line numbers and references to equations, tables, and algorithms that need to be updated. This feedback is clear and actionable, as it gives the authors precise guidance on what changes to make to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the Supplementary Material (SuppMat, L502, L507, and L509) and references equations, tables, and algorithms, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the color of the lines and the references to equations, tables, and algorithms. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements regarding the color of lines and references in the Supplementary Material. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two lines in the Supplementary Material that need to be changed from red to green. It also specifies the exact line numbers and references to equations, tables, and algorithms that need to be updated. This level of detail is highly helpful as it guides the authors precisely on what changes to make to improve the accuracy and clarity of their draft. The comment is clear, actionable, and directly addresses a specific issue, making it highly helpful for the authors to enhance their manuscript.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include important references, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what references to include and why. Additionally, the comment suggests a specific area for improvement, which is to conduct a comprehensive comparison with these works. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the references \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment is fully verifiable as it provides specific references to external works, which can guide the authors in addressing the critique. The inclusion of these references provides a clear basis for the claim, making it easy for the authors to understand and act upon the feedback. Therefore, the comment is classified as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation methods in an encode-decoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, providing clear and actionable feedback. Additionally, the comment acknowledges the societal impact discussed in the manuscript, which is a positive note. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these references or suggestions on specific aspects to compare. Overall, the feedback is mostly helpful as it directs the authors to an important area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer suggests that the paper would be more convincing if it included experimental results for the proposed algorithms. While the comment identifies a potential issue and suggests a way to address it, it does not provide specific guidance on how to conduct the experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to provide experimental results but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and the use of a \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the practical performance of the proposed algorithms, particularly highlighting the issue of the Vandermonde matrix being ill-conditioned and numerically unstable. The comment further specifies the concern by mentioning the specific conditions under which the algorithm might fail, such as small $\\\\alpha$ and moderate $n$, $k$, and $L$. Additionally, it suggests that the paper would be more convincing if experimental results were provided. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a logical reasoning by explaining the conditions under which the algorithm might fail, such as small $\\\\alpha$ and moderate $n$, $k$, and $L$. This reasoning is supported by common knowledge about the properties of Vandermonde matrices. However, the comment could be strengthened by providing specific examples or references to studies that have demonstrated these issues in practice. As it stands, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a significant concern about the practical performance of the proposed algorithms, specifically highlighting the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a specific example of how the algorithm might fail in practice, given certain conditions, and suggests that the paper would be more convincing if it included experimental results for the proposed algorithms. This feedback is clear and actionable, as it identifies a potential weakness in the paper and offers a concrete suggestion for improvement. By addressing this concern, the authors can enhance the credibility and practical relevance of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions whether there is a solution to address the scalability issue, particularly for large datasets like ImageNet. While the comment implies that the authors should consider addressing this scalability issue, it does not provide explicit guidance or suggestions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore solutions for scalability but without concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of the proposed NC measure, specifically mentioning that it takes the entire training and test datasets as input. However, it does not specify which part of the paper discusses this measure, making it weakly grounded. The comment is specific in its concern about scalability and the potential reduction in practical contribution if the issue is not addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. The reviewer questions whether there is a solution to address the scalability issue, particularly for large datasets like ImageNet. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The suggestion for addressing scalability is a logical one, but the absence of supporting evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions the practicality of the method for large-scale datasets like ImageNet and suggests that addressing this scalability issue is crucial for the paper\\'s practical contribution. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address the scalability issue. Providing examples or methodologies for scaling the method would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed PSA method requires more computation than baselines and suggests that a comparison of computation complexity should be included in the experiment part. While the comment implies that the authors should provide this comparison, it does not explicitly instruct them to do so. Additionally, it does not specify how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a computation complexity comparison and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and the specific aspect of computation complexity in the proposed PSA method. It clearly identifies the part of the paper being addressed, allowing the authors to pinpoint the relevant section. The comment is also specific because it details the issue of computation complexity and suggests that a comparison should be included in the experiment part. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of all flipped previous layer outputs in algorithm 1. This claim is somewhat verifiable as it provides a specific example of the computational complexity involved in the PSA method. However, it lacks detailed comparisons or references to substantiate the claim fully. The suggestion to include a comparison of computation complexity in the experiment part is a reasonable recommendation, but the initial claim could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computational complexity involved in the PSA method, specifically mentioning the calculation of all flipped previous layer outputs during the feed-forward process. The comment suggests that a comparison of computation complexity should be included in the experimental section, which is a clear and actionable recommendation. This feedback is valuable as it directs the authors to address a potential weakness in their method and provides a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete suggestions for improving the figures and tables in the paper. It specifies that the fonts in Figure 1 could be larger, that the words in the grey box should be larger, and that V_mem, Th_i, U_i^t are too small. It also suggests adding a long form explanation for \"CTRL\" and notes that the font in Figure 2 is too small. Additionally, it recommends including details such as epochs and number of parameters for comparison with other state-of-the-art Transformer designs, suggesting a \"table\" format to emphasize the data. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures and elements within the figures, such as \"fig 1,\" \"grey box,\" \"V_mem, Th_i, U_i^t,\" and \"figure 2.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed suggestions for improving the figures, such as increasing font size, making words in the grey box larger, and adding a long form explanation for \"CTRL.\" It also suggests including details like epochs and number of parameters for comparison with other state-of-the-art Transformer designs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific feedback on the presentation of figures, suggesting improvements such as increasing font size, making words in the grey box larger, and addressing the size of elements like V_mem, Th_i, U_i^t. It also mentions that the font in Figure 2 is too small. These suggestions are based on logical reasoning and common knowledge about readability and presentation standards in academic papers. However, the comment does not provide specific examples or references to support the claim that these changes would improve the paper. Therefore, the claim is mostly verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the suggestions.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the presentation of figures and tables in the paper. It suggests increasing the font size in Figure 1, making the words in the grey box larger, and enlarging elements like V_mem, Th_i, U_i^t. It also points out that the font in Figure 2 is too small and recommends adding a long form explanation for \"CTRL.\" Additionally, the comment highlights a lack of detail in the comparison with other state-of-the-art Transformer designs, suggesting a \"table\" format to emphasize the data and justify the improved accuracy. This feedback is clear, constructive, and offers specific guidance on how to improve the visual presentation and content of the paper, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include the ATA method in the comparison under the leave-one-out setting in Table 2, as it is shown to be better than FP in Table 1. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be added to the comparison. The suggestion is concrete, as it identifies a specific method to include in the analysis. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the ATA method in the comparison under the leave-one-out setting. This provides clear guidance on what the authors need to do to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to ATA in addition to \"+LFP\" under the leave-one-out setting, as ATA is shown to be better than FP in Table 1. This claim is somewhat verifiable as it references specific results from Table 1 to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples from Table 2 to illustrate why the comparison is necessary. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave-one-out setting. It suggests that including the ATA method in the comparison would be more convincing, given that it is shown to be better than FP in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the robustness and credibility of their results. By addressing this point, the authors can improve the comprehensiveness and validity of their analysis. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of mathematical definition for architectural details, such as multi-head attention, and questions the use of a split arrow in Figure 2. It suggests that a formal definition would aid readers in understanding the model. While the comment implies that the authors should provide a mathematical definition, it does not explicitly instruct them to do so. The action is concrete but stated implicitly, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 right, bottom right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and asks specific questions about the split arrow in Figure 2. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of mathematical definition for architectural details, such as multi-head attention, and seeks clarification on the use of a split arrow in Figure 2. The comment suggests that the split arrow might represent inputs for the attention layer, namely query, keys, and values. It requests a formal definition to aid understanding. While the comment raises valid points and suggests a specific area for improvement, it lacks detailed reasoning or references to support the claim. The authors are left to infer the importance of the issue and how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the mathematical definition of architectural details such as multi-head attention. It questions the use of a split arrow in Figure 2 and seeks clarification on whether the same vectors are used for keys and values. The comment provides a clear and actionable suggestion for improvement by recommending a formal definition to aid readers in understanding the model. This feedback is valuable as it directs the authors to enhance the comprehensibility of their work, making it mostly helpful. However, it could be further improved by offering more detailed guidance on how to present the mathematical definitions or by suggesting specific resources for reference. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation of the paper is difficult to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors can improve the clarity or organization of their paper. Without explicit instructions or concrete details, the authors are left without a clear understanding of what changes are needed to make the paper more accessible. As a result, the comment is unactionable, as it lacks actionable steps or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are problematic or what aspects make it hard to follow. Without specific references to sections, figures, or specific content, the authors cannot effectively identify the areas needing improvement. Additionally, the comment lacks specificity regarding what exactly is unclear or how the presentation could be improved. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is difficult to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment indicates that the presentation of the paper is difficult to follow, which is a relevant concern for the authors to address. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might improve the clarity or organization of their paper. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies an issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include and compare their work to specific works, such as Li et al. (2017) and He et al. (2015), which are relevant to the task-oriented recommendation perspective. It also recommends discussing how their work differs from other chatbox research works. While the comment provides explicit actions, it lacks detailed guidance on how to incorporate these references or what specific aspects to focus on in the comparison or discussion. The authors know they need to include these references and discuss differences, but the lack of concrete instructions on how to do so makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including and comparing the work to specific references, such as Li et al. (2017) and He et al. (2015), which are relevant to the task-oriented recommendation perspective. It also recommends discussing how the current work differs from other chatbox research works. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the literature review or discussion sections. The suggestion is specific, as it provides clear guidance on what references to include and how to differentiate the work from others. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that works such as Li et al. (2017) and He et al. (2015) are important to include and compare to, as they relate to the task-oriented recommendation perspective. The comment provides specific references to external works, which helps substantiate the claim that these works are relevant for comparison. However, the comment could be strengthened by explaining how these works relate to the current study or what specific aspects should be compared. Despite this, the inclusion of references provides a solid foundation for the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by recommending the inclusion and comparison of the current work with specific references, such as Li et al. (2017) and He et al. (2015), which are relevant to the task-oriented recommendation perspective. It also suggests discussing how the current work differs from other chatbox research works. This feedback is valuable as it guides the authors to situate their work within the existing literature and to highlight its unique contributions. By following this advice, the authors can enhance the context and relevance of their work, making the comment mostly helpful. However, it could be more comprehensive by offering specific aspects to focus on in the comparison or discussion, which would elevate it to a highly helpful comment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example from Foester et al., which can guide the authors in understanding the distinction and how to address it in their paper. The comment is explicit in its request for clarification and provides a concrete reference to help the authors implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the concept of \"meta solvers\" and suggests that they are centralized controllers. It implies that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al., which could help the authors understand the distinction better. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification and provides a reference, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between them and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al., which could help the authors understand the distinction better. This reference adds a level of verifiability to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the paper itself to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting that they might be centralized controllers. It advises the authors to clarify the distinction between meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al., which could help the authors understand the concept better. This feedback is clear and actionable, offering a concrete suggestion for improvement by pointing out a specific area where clarification is needed. However, it could be more helpful if it included additional guidance on how to address the issue or provided more detailed examples. Overall, the comment is mostly helpful, as it directs the authors to a critical area for clarification and provides a reference for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. While the comment highlights a potential confusion in the manuscript, it does not provide explicit guidance on how the authors should address this issue. The authors can infer that they need to clarify the meaning of \"chunk\" in the context of sequential information, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the phrase \"non-sequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This feedback highlights a potential confusion in the manuscript that the authors need to address. However, the comment does not provide any suggestions or guidance on how to clarify this point or improve the manuscript. While it points out an area of confusion, it lacks actionable advice or specific recommendations for improvement. Therefore, the comment is somewhat helpful, as it prompts the authors to reconsider their phrasing but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions of the input image with most pixels black. It also suggests that if the latter is correct, using bilinear sampling to zoom on the region of interest might provide better results. The comment implies that the authors should clarify the nature of the output patches and consider an alternative approach if necessary. While the action is implicit, it is concrete in suggesting a potential improvement by zooming on the region of interest. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the nature of the output patches and the potential misleading aspect of Figure 1. Additionally, it suggests an alternative approach using bilinear sampling. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions of the input image with most pixels black. The reviewer suggests that if the latter is correct, Figure 1 might be misleading. The comment provides a logical reasoning by contrasting the description in Equation 9 with the visual representation in Figure 1, prompting the authors to clarify the nature of the output patches. However, it lacks specific references or detailed explanations to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the issue to address the concern effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions of the input image with most pixels black. It suggests that if the latter is correct, Figure 1 might be misleading. The comment also provides a constructive suggestion by asking whether zooming on the region of interest using bilinear sampling could provide better results. This feedback is clear and actionable, as it directs the authors to clarify the nature of the output patches and consider an alternative approach for better visualization. However, it could be more helpful if it included specific guidance on how to implement the suggested approach. Overall, the comment is mostly helpful, as it effectively points out a potential issue and offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b) that focus on graph-based approaches. However, it does not provide specific guidance on how the authors could address this issue or suggest ways to differentiate their work from the previous papers. The comment lacks actionable details, such as recommending how the authors might enhance the novelty of their work or suggesting specific aspects to focus on for differentiation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical novelty of the paper by comparing it to two specific papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper this comparison should be made, such as a particular section or discussion. The authors can infer that it relates to the novelty and originality of the work, but the lack of explicit grounding makes it challenging to pinpoint the exact area needing attention. The comment is specific in its critique of the similarity to previous work but lacks grounding in terms of identifying the specific sections or elements of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two previous works (Xing and Tsang, 2022a, b) that focus on graph-based approaches. The reviewer suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to the previous works. However, the comment does not provide specific details or examples from the two mentioned papers to substantiate the claim of similarity. This lack of detailed comparison or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a general comparison but lacks the necessary depth to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a perceived lack of technical novelty in the paper, comparing it to two previous works (Xing and Tsang, 2022a, b) that focus on graph-based approaches. It suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to the previous works. While this feedback highlights a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or differentiate their work from the previous studies. The comment lacks actionable advice or detailed critique, making it somewhat helpful as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a lack of fairness in the comparison presented in Figure 3, specifically noting that the comparison between CPEF and PMEF is unjustified due to the absence of a pre-training module in PMEF. The reviewer suggests a specific action: comparing CPEF with another pre-trained model, such as ExpertBert, to highlight the advantages of the innovative pre-training module design of CPEF. This feedback provides a clear and concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and specific lines (529-534), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of unfair comparison between CPEF and PMEF and provides a clear recommendation to compare CPEF with another pre-trained model, such as ExpertBert, to highlight the advantages of the pre-training module design. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the absence of a pre-training module in PMEF. The reviewer suggests a fairer comparison with another pre-trained model, such as ExpertBert, to highlight the advantages of CPEF\\'s pre-training module design. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the current comparison and suggests a potential solution. However, the comment lacks specific examples or references to support the claim fully, such as data or studies that demonstrate the advantages of pre-trained models. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison presented in Figure 3, noting that the advantages of CPEF are overstated due to the lack of a pre-training module in PMEF. The reviewer provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert, to highlight the advantages of CPEF\\'s innovative pre-training module design. This feedback is highly helpful as it offers a concrete step for the authors to improve the fairness and validity of their comparisons, allowing them to enhance the credibility and impact of their findings. Therefore, the comment deserves a score of 5.', 'helpfulness_label': '5'}"}
