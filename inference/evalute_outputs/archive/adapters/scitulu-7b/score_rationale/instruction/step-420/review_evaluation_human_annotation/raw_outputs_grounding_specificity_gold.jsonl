{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of operators used in the paper, specifically asking about the reasons for not considering the \"and\" operator or element-wise max. While the comment implies that the authors should provide a rationale for their choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of operators and asking for clarification on why the ones chosen were better options. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of operators used in the paper, specifically asking about the reasons for not considering the \"and\" operator or element-wise max. The comment seeks clarification on why the authors chose certain options over others, implying that the current choices are unclear or inadequate. However, the comment does not provide specific examples or references to support the claim that the \"and\" operator or element-wise max would be more appropriate. This lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or element-wise max were not considered. This feedback is clear and actionable, as it prompts the authors to provide a rationale for their choices, which could help clarify the paper\\'s methodology and enhance its clarity. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how the \"and\" operator or element-wise max might be incorporated. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between lines 226-238 and 242-244, suggesting that the authors may have selected sentences from raw data sources that already have syntactic information. The reviewer also suggests that the description could be revised by mentioning Li et al. (2019a) earlier to clarify the source of the data. While the comment identifies a potential issue and provides a specific suggestion for revision, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 226-238 and 242-244, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the description, noting that the data may be a subset of Li et al. (2019a)\u2019s dataset and suggesting a revision to mention Li et al. (2019a) earlier for clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the description of the data sources, suggesting that the authors may have selected sentences from raw data sources that already have syntactic information. The reviewer questions whether the data is a subset of Li et al. (2019a)\u2019s dataset and suggests revising the description to clarify the source. This claim is somewhat verifiable as it provides a logical reasoning for the potential discrepancy and suggests a specific revision to improve clarity. However, the comment lacks detailed evidence or references to fully substantiate the claim, such as specific examples or references to similar studies. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential discrepancy in the description of the data sources, suggesting that the authors may have selected sentences from raw data sources that already have syntactic information. It also points out that the data may be a subset of Li et al. (2019a)\u2019s dataset and suggests revising the description to clarify the source. This feedback is clear and actionable, as it provides specific guidance on how to revise the description to make it more precise and accurate. By addressing this issue, the authors can improve the clarity and transparency of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional information but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This is a factual inquiry seeking clarification rather than an opinion or claim that requires verification. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the purpose of the average duration reported in Table 1 and highlights the lack of an explanation regarding its inclusion. It prompts the authors to clarify whether this duration includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it directs the authors to provide a necessary explanation or clarification to enhance the transparency and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what additional context might be beneficial. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlap between Baseline and NVSB for Chinese and English MOS-V. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide additional explanation or clarification, but the comment lacks concrete guidance on what specific changes are needed. Therefore, the comment is somewhat actionable, as it implies an action but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific results shown in Table 3, providing detailed feedback on the interpretation of certain findings. It specifies the parts of the table that need clarification, such as the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlap between Baseline and NVSB for Chinese and English MOS-V. This level of detail allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific in detailing what needs to be clarified, providing clear guidance on how to improve the interpretation of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions about the interpretation of results in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlap between Baseline and NVSB for Chinese and English MOS-V. While the comment identifies areas that need clarification, it does not provide specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need further explanation, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the formatting of some items in Tables 2 and 3, noting that some have spaces between accuracy and standard deviation, while others do not. This comment explicitly points out a formatting inconsistency that affects the presentation of the tables. However, it does not provide any guidance on how to address this issue, such as suggesting a standard formatting approach or offering specific suggestions for improvement. As a result, the authors are left with a clear issue to address but without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the formatting of these tables, noting the inconsistency in the spacing between accuracy and standard deviation. This provides clear guidance on what needs to be addressed to improve the presentation of the tables. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the inconsistent spacing between accuracy and standard deviation in some items of Tables 2 and 3 affects the \"beauty\" of the presentation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistencies in the spacing between accuracy and standard deviation. This feedback is clear and actionable, as it directs the authors to a specific area that needs attention to improve the presentation of their tables. By addressing this issue, the authors can enhance the clarity and professionalism of their work. However, the comment could be more helpful if it provided suggestions on how to standardize the formatting or offered examples of best practices. Despite this, the feedback is mostly helpful as it highlights a critical aspect of the paper\\'s presentation that can be improved.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the missing antecedent in the sentence \"both tasks\" and the need to check references for format, specifically capitalization and bibliographic details. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should check the references for formatting and capitalization. However, the comment does provide some guidance by specifying the types of issues to look for, which makes it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the formatting of references, particularly capitalization and bibliographic details. It mentions \"both tasks\" and \"the references,\" allowing the authors to accurately identify the parts of the paper being addressed. However, the comment does not specify which references are missing or how they should be formatted, making it weakly grounded. The specificity of the comment is high, as it clearly outlines the issues with capitalization and bibliographic details, but it lacks detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific formatting issue with references, noting that the antecedent is missing in the sentence \"both tasks\" and suggesting that the references should be checked for capitalization, bibliographic details, and formatting consistency. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples or guidance on how to address these issues. Nonetheless, the feedback is mostly helpful as it directs the authors to a specific area needing attention and provides a clear path for improvement. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature and recommends organizing the section into separate paragraphs dedicated to each of the lexical features and sentence-level features. This feedback provides a clear and explicit action for the authors to take, which is to restructure the section for improved clarity. The suggestion is concrete and specific, offering a clear path for the authors to enhance the organization and readability of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on how to improve the organization and clarity of the explanations for features in this section. The comment suggests separating the explanations into separate paragraphs dedicated to lexical features and sentence-level features, providing clear instructions on how to restructure the section for better readability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a specific recommendation to organize the section into separate paragraphs dedicated to each of the lexical features and sentence-level features. This suggestion is supported by a logical reasoning that separating the explanations would improve clarity and coherence. However, the comment could be strengthened by providing examples or references to similar sections that have been successfully organized in this manner. Despite this, the claim is mostly verifiable, as it offers a clear and actionable suggestion for improvement.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2, noting that the intertwined nature of the content makes it confusing. It provides a clear and actionable suggestion to improve the organization by recommending separate paragraphs for each of the lexical features and sentence-level features. This feedback is valuable as it directly addresses a weakness in the paper\\'s presentation, offering a concrete way for the authors to enhance the clarity and coherence of their draft. However, the comment could be more helpful if it included specific examples or additional guidance on how to structure the sections. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract is well-written and invokes intrigue, but it also provides a specific suggestion for improvement. The reviewer recommends adding an example of the inconsistency between evaluating with gold answers and human evaluation, such as how models are ranked differently. This feedback is explicit and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be added to enhance their abstract.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending an example of the inconsistency between evaluating with gold answers and human evaluation, such as how models are ranked differently. This provides a clear direction for the authors to enhance their abstract. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract is well-written and invokes intrigue, but it provides a specific suggestion for improvement. The reviewer recommends adding an example of the inconsistency between evaluating with gold answers and human evaluation, such as how models are ranked differently. This suggestion is based on logical reasoning and provides a clear example to support the claim. Therefore, the comment is mostly verifiable, as it offers a concrete suggestion for improvement.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the abstract is well-written and invokes intrigue, which is a positive observation. It also provides a specific suggestion for improvement by recommending an example of the inconsistency between evaluating with gold answers and human evaluation, such as how models are ranked differently. This feedback is actionable and constructive, as it guides the authors on how to enhance their abstract by providing a concrete example to illustrate the inconsistency. By addressing this suggestion, the authors can improve the clarity and effectiveness of their abstract, making the comment mostly helpful. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit instructions for the authors to discuss the results for the task of inferring knowledge on objects and includes specific suggestions for model (B) and terminology consistency. It also questions the omission of objects in the discussion of \"latent in verbs.\" The feedback is clear and provides concrete actions for the authors to take, such as discussing results for model (B) and using consistent terminology in tables. The explicit nature of these instructions makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it points out the inconsistency in terminology for model B in Tables 1 and 2. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple requests and suggestions, including discussing results for the task of inferring knowledge on objects, using consistent terminology in tables, and addressing the omission of objects in the discussion of \"latent in verbs.\" While the comment provides some guidance, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors are given direction but may need to infer the full extent of the issues themselves. Therefore, the comment is somewhat verifiable, as it provides a starting point but requires further elaboration for full understanding and action.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out the inconsistency in terminology for model B in Tables 1 and 2 and questions the omission of objects in the discussion of \"latent in verbs.\" This feedback is clear and directs the authors to specific areas for improvement, offering a concrete path for enhancing the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific sentence in line 212 that is incorrect and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the sentence (\"We train a GRU that encodes a source sentence into a single vector\") and suggests a correction (\"you do a bidirectional encoder that encodes the source sentence into a set of vectors\"). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is incorrect and suggests a correction. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the original sentence is incorrect or how the suggested correction is more accurate. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the sentence in line 212, noting that it is incorrect and suggesting a correction. It provides a clear and actionable suggestion by suggesting that the authors should say they do a bidirectional encoder instead of a GRU. Additionally, the comment references Figure 2, which could help the authors verify the correctness of the suggestion. This feedback is valuable as it directly addresses a mistake in the paper and offers a specific correction, making it highly helpful for the authors to improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the baseline models: (1) the lack of comparison to Campos et al. (2020), which also uses feedback in QA tasks, and (2) the absence of comparison with other domain adaptation methods, specifically mentioning those in Section 8. The reviewer suggests that these comparisons should be included to strengthen the paper. While the comment explicitly identifies the missing comparisons, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues by pointing out the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods, such as those mentioned in Section 8. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline models are weak and suggests that the authors should compare them to Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. (2020) or other domain adaptation methods to fully substantiate the claim. The reasoning is somewhat verifiable, as it highlights a potential gap in the comparison but does not provide detailed evidence or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the weakness of the baseline models used. It points out the lack of comparison to Campos et al. (2020), which also uses feedback in QA tasks, and the absence of comparison with other domain adaptation methods, such as those mentioned in Section 8. This feedback is clear and actionable, as it directs the authors to include these comparisons to enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action that the authors can easily implement, providing them with a concrete way to improve their draft. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a specific change to the y-axis label, recommending that it use \"Exact Match ratio\" directly. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific issue with the figure, suggesting that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and accuracy of their figure. However, the comment could be more helpful if it explained why this change is necessary or how it would enhance the figure\\'s interpretation. Overall, the comment offers valuable guidance but could be more comprehensive with additional context or reasoning. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in [1]. However, it does not provide explicit instructions or concrete guidance on how to include these baselines or justify their inclusion. The authors are left to infer that they need to include these baselines and justify their inclusion, but without specific details on what to include or how to justify it, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies a potential area for improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in [1]. The comment provides a clear direction for improvement by suggesting the inclusion of additional baselines and justifies the need for this by referencing a specific work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in [1]. However, the comment does not provide any specific examples or references to support the claim that these baselines are necessary or how they would enhance the analysis. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully support the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that Table 3 should include many strong baselines that are not currently compared. It specifically mentions a reference [1] that lists additional baselines that could be included. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting the inclusion of additional baselines. However, the comment could be more helpful if it offered further guidance on how to justify the inclusion of these baselines or how they might impact the analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a starting point for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also asks about the KNs in source language or English in Figure 3, noting that the mentions have been translated to English. The comment provides explicit actions for the authors to take, such as adding information about the input and clarifying the KNs in the figure. The feedback is concrete and specific, giving the authors clear guidance on what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be added, such as information about the input being word embeddings and clarifying the KNs in the figure. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also questions the KNs in Figure 3, noting that the mentions have been translated to English. The comment provides a logical reasoning for the suggestion, as it highlights the need for clarity in the input and the KNs. However, it lacks specific examples or references to support the claim, which would make it more fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors use the Lample et al. Bi-LSTM-CRF model without mentioning that the input is word embeddings. It also raises a question about the KNs in Figure 3, noting that they have been translated to English. The comment provides clear and actionable feedback by suggesting that the authors should add information about the input and clarify the KNs in the figure. This feedback is valuable as it helps the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar models have been presented. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that lines 102-106 are misleading, as they refer to \"such distribution\" but do not align with the discussion in the previous section. However, it does not provide explicit guidance on how the authors should correct this issue or clarify the misleading statement. The comment lacks actionable details, such as suggesting specific changes or clarifications that the authors should make to improve the clarity of their draft. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and how it does not align with the discussion in the previous section. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading, specifically mentioning that \"such distribution\" cannot refer to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, pointing out that lines 102-106 are misleading due to the use of \"such distribution.\" It highlights a potential confusion caused by the lack of alignment between the discussion in the previous section and the statement in these lines. However, the comment does not provide any suggestions or guidance on how the authors might clarify or correct this issue. While it identifies a potential problem, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from more in-depth analysis of its claims. However, it does not provide specific claims or examples that need further exploration, nor does it offer guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to conduct more in-depth analysis without knowing which claims or aspects require it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a number of claims from the paper would benefit from more in-depth analysis, but it does not specify which claims or parts of the paper are being referred to. This makes it difficult for the authors to identify the exact areas that need further exploration. Additionally, the comment lacks specificity regarding what aspects of the claims need more analysis or how to conduct this analysis. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more in-depth analysis of its claims. However, it does not provide specific claims or examples that need further exploration, nor does it offer any supporting evidence or reasoning to substantiate this suggestion. Without detailed examples or references, the claim remains vague and lacks verifiability, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from more in-depth analysis of its claims. However, it does not provide specific claims or examples that need further exploration, nor does it offer guidance on how to conduct this analysis. Without detailed feedback or actionable suggestions, the authors are left with a general suggestion that lacks depth and specificity. This makes the comment barely helpful, as it provides some insight but not enough to fully support the authors in improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It explicitly asks for clarification on what is used for embedding features and clarifies the meaning of E_i in Equation (7). Additionally, it suggests that the LHS of Equation (7) should be a conditional probability. These questions provide clear and explicit actions for the authors to take, such as revisiting the relevant sections and providing additional clarification. The feedback is concrete and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the presentation of the model, including the pooling method used for embedding features and the clarity of Equation (7). The comment provides clear guidance on what needs to be improved, making it specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two specific issues with the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). It questions the meaning of E_i in Equation (7) and suggests that the LHS should be a conditional probability. The reviewer provides logical reasoning by pointing out that both the type and identity of AC i are modeled, which adds clarity to the claim. However, the comment could be strengthened by providing specific references or examples to support the clarity of Equation (7. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the presentation of the model, particularly regarding the pooling method used for embedding features and the clarity of Equation (7). It raises questions about the meaning of E_i in Equation (7) and suggests that the LHS should be a conditional probability. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the clarity and accuracy of their presentation. By addressing these points, the authors can significantly improve the comprehensibility and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of exploration or discussion of the two hypotheses raised about multilinguality and country/language-specific bias. It points out that the hypotheses are not tested or discussed further, which is misleading. The comment suggests that the paper should delve deeper into these topics, at least to some extent. While the action is explicit in asking for a more thorough exploration of the hypotheses, it lacks specific guidance on how to achieve this. The authors know they need to address the issue but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 078-086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, namely that the hypotheses about multilinguality and country/language-specific bias are not tested or discussed further, despite being raised. The comment suggests that the paper should delve deeper into these topics, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not test or discuss them further. The reviewer suggests that the hypotheses are valuable but not fully explored. However, the comment lacks specific examples or detailed reasoning to support why the hypotheses are not tested or discussed, making it somewhat verifiable. The authors would need to infer the specific issues and potential solutions, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the hypotheses about multilinguality and country/language-specific bias are raised but not tested or discussed further. It points out that this lack of exploration is misleading and suggests that the paper should delve deeper into these topics. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it identifies a critical gap in the paper but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that for each PCFG with rank r, the authors should add a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The comment provides a clear and concrete action for the authors to take, specifying which parameters should be directly parameterized and how they should be set. This level of detail makes the action explicit and leaves no ambiguity about what the authors need to do to address the suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. However, it does not specify which parameters should be parameterized or where in the paper this suggestion should be implemented. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the authors might have an idea of where this suggestion fits, the lack of specificity and grounding makes it challenging to address the feedback effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that for each PCFG with rank r, the authors should add a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The comment provides a logical reasoning for this suggestion, explaining that this would allow for a more direct comparison of perplexity. However, the comment lacks specific examples or references to support the claim that this change would improve the comparison. While the suggestion is logical, the lack of detailed justification or evidence makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending the addition of a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This suggestion is actionable and offers a clear path for the authors to address a potential issue with the comparison of perplexity. However, the comment could be more helpful if it provided additional context or examples of how this change would impact the comparison or what specific parameters should be parameterized. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement and offers a clear action to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that is clearly stated and provides a specific direction for the authors to take. The comment is concrete, as it specifies the exact information that needs to be included in the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or table where this information is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion, as it clearly identifies what needs to be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any reasoning, evidence, or examples to support why this information is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help the authors improve the transparency and reproducibility of their work. By including this information, the authors can provide a clearer understanding of the data collection process and the variability in task completion across annotators. However, the comment could be more helpful if it explained why this information is important or how it would enhance the paper\\'s credibility. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, providing them with a specific step to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding the hard prompt baseline to Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of the hard prompt baseline, but without full grounding, it is difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. However, it does not provide any reasoning, evidence, or examples to support why this inclusion is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that can help the authors improve the presentation of their results. By including the hard prompt baseline, the authors can provide a more comprehensive comparison of their methods, allowing readers to better understand the performance improvements. However, the comment could be more helpful if it explained why this inclusion is important or how it would enhance the understanding of the results. Overall, the comment is mostly helpful as it directs the authors to a specific improvement that can enhance the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While the comment implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\\'s curiosity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that numerical results are necessary or how they could be applied. The comment lacks specificity and does not provide a clear rationale for the need for numerical results, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of numerical results in the paper. It expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is clear and actionable, as it directs the authors to include numerical results to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided specific suggestions on which algorithms to consider or how to structure the numerical results. Overall, the comment is mostly helpful as it effectively guides the authors on a meaningful enhancement to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental comparisons are not sufficient and recommends including results with wider backbones like ResNet50 (2x) and ResNet50 (4x). While the comment implies that the authors should conduct additional experiments with these wider backbones, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental comparisons are not sufficient and recommends including results with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or the results section. The authors can infer that it relates to the experimental comparisons, but this inference is not direct. The comment is specific in its suggestion to include results with wider backbones, but it lacks full grounding as it does not explicitly mention the section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental comparisons are not sufficient and recommends including results with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence or reasoning to justify why these additional comparisons are necessary or how they would improve the study. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). It suggests that including these comparisons would be interesting and could provide valuable insights. While the comment highlights an area for improvement, it lacks specific guidance on how to implement these additional experiments or what specific aspects to focus on. The feedback is somewhat helpful as it points out a potential gap in the experimental analysis but does not offer detailed instructions or suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it notes that the figure 6 callout is not directing properly. These actions are clear and concrete, providing the authors with direct guidance on what to change to improve their draft. The comment is highly actionable, as it offers specific and detailed instructions on how to correct the references.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these references. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s references, noting that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. This feedback is clear and actionable, providing the authors with direct guidance on how to correct their references. By addressing these issues, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it included suggestions on how to improve the clarity or directness of the figure 6 callout. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant concern with the paper\\'s experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper only reports self-comparisons and does not explain why this is the case, which contributes to a poor motivation problem. The comment provides a clear and direct action for the authors to take, which is to include comparisons with other models to enhance the motivation and credibility of their work. The suggestion is concrete and specific, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely the lack of comparisons with other models and the absence of an explanation for this limitation. The comment suggests including comparisons with SketchRNN to enhance the motivation and credibility of the work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s experiments are a significant concern due to the lack of comparisons with other models and the absence of an explanation for this limitation. The comment suggests that including comparisons with SketchRNN could enhance the motivation and credibility of the work. While the comment identifies a specific issue with the experiments, it lacks detailed reasoning or references to support why this limitation is problematic or how it affects the overall paper. The suggestion to include comparisons is logical but could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks comprehensive evidence or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the paper\\'s experiments, specifically the lack of comparisons with other models and the absence of an explanation for this limitation. It suggests that including comparisons with SketchRNN could enhance the motivation and credibility of the work. While the comment highlights a critical area for improvement, it does not provide detailed guidance on how to address this issue or what specific comparisons should be made. The feedback is somewhat helpful as it points out a significant gap in the paper, but it could be more beneficial with additional suggestions or examples on how to improve the experiments. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\\' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, pointing out specific instances where DeiT-B models do not outperform DeiT-S. The comment provides a clear direction for additional analysis and suggests that the authors reconsider their viewpoint. However, it does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) and disagreeing with the authors\\' viewpoint. The comment provides specific examples of where DeiT-B models do not outperform DeiT-S, which adds clarity to the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims and observations, including disagreeing with the authors\\' viewpoint and providing specific examples to support the critique. The comment references the Figure 3 and provides detailed comparisons between different models, such as DeiT-B and DeiT-S, in terms of performance trending. This level of detail and specificity supports the claims, making the comment mostly verifiable. However, the comment could be further strengthened by providing additional references or detailed analysis to fully substantiate the critique. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the authors\\' claims regarding the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors\\' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, pointing out specific instances where DeiT-B models do not outperform DeiT-S. The comment also suggests additional analysis and comments on the performance trending, which could help the authors better understand and interpret their results. While the comment identifies specific areas for improvement and provides some guidance, it could be more helpful if it offered more detailed suggestions or examples of how the authors might conduct the additional analysis. Overall, the comment is mostly helpful as it provides valuable insights and actionable feedback for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests making a distinction between hard prompt work updates to the frozen model (such as those by Schick and Sch\u00fctez) and those that don\\'t. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The action is implicit and somewhat vague, as the authors need to infer that they should make a distinction but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests making a distinction between hard prompt work updates to the frozen model (such as those by Schick and Sch\u00fctez) and those that don\\'t. However, it does not specify which line or section of the paper this distinction should be made in, leaving the authors to infer that it relates to the discussion or results section. The comment is specific in suggesting a distinction but lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests making a distinction between hard prompt work updates to the frozen model (such as those by Schick and Sch\u00fctez) and those that don\\'t. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or beneficial. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests making a distinction between hard prompt work updates to the frozen model (such as those by Schick and Sch\u00fctez) and those that don\\'t. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to implement this distinction or why it is important. The comment is somewhat helpful as it points out a potential area for clarification, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment to analyze the performance of ATT(+H) in figure 4 left, specifically by considering the relevance of attention retrieval from the attention memory. While the comment provides a clear action to conduct an ablation study and suggests a specific experiment to conduct, it does not explicitly instruct the authors on how to conduct these studies or what specific aspects to focus on. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment to analyze the performance of ATT(+H) in figure 4 left, specifically by considering the relevance of attention retrieval from the attention memory. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the experimental results and methodology sections. The suggestion to conduct an ablation study is specific, and the request for an experiment with ATT(+H) is also clear. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment to analyze the performance of ATT(+H) in figure 4 left, specifically by considering the relevance of attention retrieval from the attention memory. While the comment provides a logical reasoning for conducting these experiments, it lacks specific examples or references to support the claim that these experiments would be beneficial. The suggestion is somewhat verifiable, as it provides a clear direction for improvement but could be strengthened with more detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment to analyze the performance of ATT(+H) in figure 4 left, specifically by considering the relevance of attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft, providing them with a specific path to enhance the robustness and validity of their work. However, the comment could be more helpful if it included suggestions on how to conduct the ablation study or what specific aspects to focus on in the ATT(+H) experiment. Overall, the comment is mostly helpful as it guides the authors toward meaningful enhancements to their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should attempt to explain why WPA works, specifically by examining the np.ones input and exploring the model's predictions. It also questions the effectiveness of Gaussian noise input compared to WPA and points out that the authors have not provided insights into how WPA works, which is crucial for future research directions. While the comment provides a clear direction for the authors to explore and explain the underlying mechanisms of WPA, it does not explicitly instruct them to do so. The action is implicit but concrete, as it specifies what the authors should investigate and why. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the effectiveness of Gaussian noise input compared to WPA. The comment provides a clear direction for the authors to improve their draft by offering insights into the model's predictions and the underlying mechanisms of WPA. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the effectiveness of WPA and suggests that the authors should provide insights into how WPA works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the authors have not provided useful insights into the mechanisms of WPA, which is crucial for future research directions. While the comment identifies a gap in the paper\\'s explanation and suggests a direction for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for further exploration is logical but not fully developed, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper\\'s explanation of the WPA method, specifically questioning why it works and what the model is predicting with np.ones input. It also points out that Figure 2 suggests Gaussian noise input does not work as well as WPA, and questions why this is the case. The comment highlights the importance of understanding the mechanisms of WPA for future research directions. While it provides a clear direction for improvement by suggesting the authors explore these questions, it lacks specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it identifies a critical area for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two important parameters/thresholds (minimum cluster size and conductance threshold) that are not discussed in the experimental section. It explicitly states that the experimental section should mention and discuss how these parameters are set and how sensitive the performance is with respect to these parameters. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed: the absence of discussion on how the minimum cluster size and conductance threshold are set and how sensitive the performance is to these parameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental section does not discuss how the parameters (minimum cluster size and conductance threshold) are set or how sensitive the performance is to these parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of discussion on how the minimum cluster size and conductance threshold are set and how sensitive the performance is to these parameters. This is a significant oversight that could impact the reproducibility and robustness of the experimental results. The comment provides clear and actionable feedback, directing the authors to include this discussion in the experimental section. By addressing this issue, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to discuss these parameters or provided examples of how similar studies have addressed this issue. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The comment implies that the authors should consider the potential weaknesses of using reinforcement learning, but it lacks concrete steps or detailed advice on how to mitigate these issues. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, it does not specify which part of the paper this critique pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential weaknesses of using reinforcement learning, but it lacks grounding as it does not explicitly mention where in the paper this issue is discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed explanations of why reinforcement learning might be less efficient or challenging for this task. As a result, the claim is somewhat verifiable, as it provides a general idea but lacks the necessary evidence or justification to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. While the comment identifies a potential issue, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern. It does not offer guidance on how to mitigate the potential weakness or improve the approach. As a result, the comment is barely helpful, as it points out a potential problem but does not provide the authors with concrete steps to improve their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the implementation of the billinear layer and its differences from other approaches. It suggests clarifying how the billinear layer is different from other approaches, specifically questioning whether the dimensionality of embeddings is the primary difference. The reviewer also asks about the swap-out of the billinear layer with other approaches, such as the hadarmard product and MCB, and whether the compression of the representations using Equation (3) is still done in this case. These questions provide clear guidance on what aspects need clarification, offering the authors explicit actions to take. The feedback is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implementation of the billinear layer and its differences from other approaches, including the dimensionality of embeddings and the compression of representations using Equation (3). The comment provides clear guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where clarification is needed regarding the implementation of the billinear layer and its differences from other approaches. It raises questions about the dimensionality of embeddings and the compression of representations using Equation (3). This feedback is clear and actionable, as it prompts the authors to clarify these aspects of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these questions or offered examples of how other approaches handle similar issues. Despite this, the feedback is mostly helpful as it directs the authors to important areas for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, which is currently hidden in Fig. 3 e. This feedback is explicit and provides a clear action for the authors to take, namely, to include the results of the latter loss term in the figure. The comment is specific about what needs to be added, making it highly actionable. Authors can easily understand and implement the suggested change, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, which is currently hidden in Fig. 3 e. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, which is currently hidden in Fig. 3 e. This is a suggestion for improvement rather than a claim or opinion. It does not contain subjective judgments, opinions, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Fig. 3 e, noting that the preactivation values of two networks are the same membrane potentials, which could lead to high cosine similarity in their outputs. The comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, which is currently hidden in Fig. 3 e. This feedback is clear and actionable, providing the authors with a specific suggestion for improving the clarity and completeness of their results. By addressing this point, the authors can enhance the transparency and understanding of their work. Therefore, the comment is mostly helpful, as it offers a concrete direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper\\'s analysis by noting the absence of a comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that a comparison should be made based on experimental results to address the issue of robustness in video action recognition. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific comparison to be made and how to present it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with test-time adaptation (TTA) methods, such as [A-B]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. The reviewer suggests that such a comparison should be made based on experimental results to address the issue of robustness in video action recognition. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper\\'s focus. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the relevance and applicability of TTA methods to their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It highlights the importance of such a comparison in addressing the issue of robustness in video action recognition. The comment suggests that a comparison based on experimental results could help prove the superiority of data processing over model parameter adjustment. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for enhancement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific error in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This is an explicit correction, as it directly identifies the issue and provides a clear action for the authors to take: correcting the expression. The comment is also concrete, as it specifies the exact correction needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), noting that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J (\u03b8) is incorrect, stating that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this correction is necessary. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This is a clear and actionable feedback that the authors can easily address to correct their draft. However, the comment could be more helpful if it provided additional context or explanation about why this correction is necessary or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction, which is valuable for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple observations and suggestions, each of which is explicit and concrete. The reviewer identifies specific issues with capitalization in references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. Additionally, the reviewer points out that Dusenberry et al. (2020) was published in ICML 2020, Osawa et al. (2019) was published in NeurIPS 2019, and Swiatkowski et al. (2020) was published in ICML 2020. These observations and suggestions are clear and provide specific guidance on how to improve the paper by ensuring proper capitalization and referencing. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"s/expensive approaches2) allows/expensive approaches,2) allows/ p.8: s/estimates3) is/estimates, and3) is/ In the references,\" and \"Various words in many of the references need capitalization, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many of the papers, and \"Advances in neural information processing systems\" in several of the papers.\" This provides clear guidance on what needs to be addressed, allowing the authors to pinpoint the exact sections that require attention. The comment is also specific, as it details the capitalization issues and provides examples of specific references. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple observations and suggestions, each of which is factual and descriptive. It does not contain any subjective claims, opinions, or judgments that require verification. The comment provides specific examples of capitalization issues in references and suggests corrections, which are factual statements that do not require justification or evidence. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides multiple pieces of feedback that are mostly actionable. It identifies specific capitalization issues in references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. This is a clear and specific observation that the authors can easily address to improve the presentation of their work. Additionally, the comment suggests that various words in the references need capitalization, which is a helpful suggestion for maintaining consistency and professional standards. However, the comment could be more helpful if it provided additional guidance on how to address these capitalization issues or offered suggestions for improving the references overall. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides actionable feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the absence of specific parameter values, particularly for task 1 and the Boltzmann policy. It asks for clarification on how the parameters were chosen, suggesting that the authors might have used maximum likelihood estimates. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should provide more detailed information about the parameter choices, but the feedback lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the absence of specific parameter values, particularly for task 1 and the Boltzmann policy. It asks for clarification on how the parameters were chosen, suggesting that the authors might have used maximum likelihood estimates. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its request for clarification on the parameter choices, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific parameter values and the methodology used to choose them. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual in nature, seeking information that is necessary for understanding the paper. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the absence of specific parameter values and the methodology used to choose them. It specifically inquires about the model parameters for task 1 and the Boltzmann policy, as well as how the parameters were chosen. By asking for clarification on the parameter choices, the comment prompts the authors to provide more detailed information about their methodology. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar parameters were chosen in other works. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing clarification, which can help improve the clarity and comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the performance of GuessWhat?! when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4, as opposed to only layers 3 and 4. It suggests that the authors might have a specific hypothesis about why this change in application affects performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to investigate it further. The action is implicit and somewhat vague, as the authors need to infer that they should explore the reasons behind the performance change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the performance of GuessWhat?! when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4, suggesting that this might be different from when CBN is applied only to layers 3 and 4. The comment provides a clear direction for the authors to explore the reasons behind the performance change. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance for GuessWhat?! compared to when CBN is applied to layers 4 and 3 only. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the observation. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the performance of GuessWhat?! when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4, as opposed to only layers 3 and 4. It suggests that the authors might have a hypothesis about why this change in application affects performance. However, the comment does not provide any guidance or suggestions on how the authors might investigate or address this issue. While it identifies a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are left with a vague understanding of the issue but without clear steps to resolve it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It references Chen et al. (2017) and Gu et al. (2019) as examples of this phenomenon. The reviewer suggests that a few training examples with such triggers could have a significant impact on the trained model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the impact of these spurious features. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific steps to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the issue with the spurious features being similar to backdoor triggers and provides examples from other works. This level of detail helps the authors understand the problem and how to address it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns that only appear a few times in the training set. The reviewer supports this claim by referencing Chen et al. (2017) and Gu et al. (2019), both of which use random noise patterns and single-pixel triggers, respectively, as examples. This provides a logical basis for the claim, as it highlights the known impact of such triggers on the trained model. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Overall, the claim is mostly verifiable, as it is supported by relevant references but could be more comprehensive with additional evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a similarity between the spurious features in Sections 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It provides examples from other works, such as Chen et al. (2017) and Gu et al. (2019), to support its claim. This feedback is somewhat helpful as it highlights a potential issue with the paper\\'s methodology and suggests that the authors should address this similarity. However, the comment lacks specific guidance on how the authors should address this issue or what steps they should take to mitigate the impact of these spurious features. While it points out a potential problem, it does not provide actionable advice, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the authors should clarify the distinction between when the proposed method is trained using only weak supervision and when it is semi-supervised trained. The reviewer provides specific guidance by suggesting that the authors rename the column in Table 1 to \"Fully supervised\" and propose a better idea of specifying the data used to train each part of the model. This feedback is clear and actionable, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training. The comment provides a detailed suggestion to rename the column in Table 1 and proposes a better approach for labeling the data used for training. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training, specifically in Table 1. The reviewer provides a specific example of renaming the column to \"Fully supervised\" and proposes a better approach for labeling the data used for training. This feedback is supported by logical reasoning and specific suggestions, making the claim mostly verifiable. The authors can understand the need for clarification and the proposed changes, but the comment could be strengthened by providing more detailed reasoning or references to similar practices in the field. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors clarify the distinction between weak supervision and semi-supervised training. It offers a specific example by proposing to rename the column in Table 1 to \"Fully supervised\" and suggests a better approach for labeling the data used for training. This feedback is detailed and constructive, empowering the authors to make significant improvements to their draft by ensuring clarity in their methodology. By addressing these points, the authors can enhance the clarity and comprehensibility of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the ablation experiment results, specifically noting that the performance without reinforcement learning dropped lower than without dependency tree. It also highlights the absence of tables listing cases where dependency tree and RL are not used. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific tables should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the results and include relevant tables, but the comment lacks concrete details on how to implement these changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"dependency tree,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the results, noting that the performance without reinforcement learning dropped lower than without dependency tree. Additionally, it highlights the absence of tables listing cases where dependency tree and RL are not used, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance without reinforcement learning dropped lower than without dependency tree in the ablation experiment. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It also mentions the absence of tables listing cases where dependency tree and RL are not used, but this information alone is insufficient to verify the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. This is a significant finding that could impact the interpretation of the results and the conclusions drawn. Additionally, the comment points out the absence of tables listing cases where dependency tree and RL are not used, which is a relevant consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional analyses might be needed. While it highlights a potential problem, it does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the main weakness of the paper as the lack of consideration of other datasets from the Federated learning benchmarks, specifically mentioning CIFAR-10 and LEAF. It suggests that the authors should review relevant works, such as FedProx and FedMAX, for details on different datasets and model types. While the comment implies that the authors should expand their experimental evaluation, it does not provide explicit instructions on how to do so or which datasets to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of consideration of other datasets from Federated learning benchmarks, and suggests that the authors should review relevant works for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main weakness of the paper is the lack of consideration of other datasets from Federated learning benchmarks, specifically mentioning CIFAR-10 and LEAF. The reviewer suggests that the authors should review relevant works, such as FedProx and FedMAX, for details on different datasets and model types. This claim is somewhat verifiable as it provides a logical reasoning for the need to expand the experimental evaluation, but it lacks specific examples or references to fully substantiate the claim. The authors would need to conduct further research to understand the full extent of the issue and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of consideration of other datasets from Federated learning benchmarks, such as CIFAR-10 and LEAF. It suggests that the authors should review relevant works, like FedProx and FedMAX, to gain insight into different datasets and model types. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance their experimental evaluation to make their paper more comprehensive and competitive. However, the comment could be more helpful if it offered suggestions on which datasets to include or how to incorporate these additional datasets into the existing experimental design. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the authors construct images for a clean exemplar manifold for a non-stochastic network, specifically questioning the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue with the clarity of the manuscript, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the construction of the images and the denominator computation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 182-183,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of images for a clean exemplar manifold and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of images for a clean exemplar manifold in a non-stochastic network, specifically questioning the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is somewhat verifiable as it seeks clarification on a specific aspect of the paper, but it lacks detailed reasoning or references to support the claim. The authors would need to provide additional context or explanation to fully address the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the construction of images for a clean exemplar manifold in a non-stochastic network, particularly regarding the computation of the denominator in Figure 2.c for the ResNet50 and ATResNet50 networks. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their work that could impact the reader\\'s understanding. By addressing this question, the authors can improve the clarity and accuracy of their manuscript. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, noting that it lacks sufficient information. However, it does not provide explicit guidance on how the authors should address this issue or what additional information should be included. The comment implies that more explanation is needed, but it does not specify what that explanation should entail. As a result, the authors are left with a vague understanding of what needs to be improved, making the action implicit and somewhat vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning the confusion caused by the explicit split. However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in detailing what needs clarification, namely the meaning of S and Xt. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning the lack of information about S and Xt. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this notation is confusing or how it could be improved. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, noting that it lacks sufficient information. It highlights the need for clarification on what S and Xt represent, indicating that this confusion may impact the readability and comprehension of the paper. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this confusion or improve the clarity of their notation. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not clear and lacks explicit justification. It suggests that the paper should provide more motivation for this specific form. While the comment identifies a gap in the explanation, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more motivation for the choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ is not clear and lacks motivation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity and motivation behind the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3. It claims that the paper states the choice is empirical but lacks detailed motivation for this specific form. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for more detailed motivation and potentially conduct additional research to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper claims the choice is empirical but lacks detailed motivation for this specific form. This feedback is somewhat helpful as it highlights a gap in the explanation that the authors need to address to improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to enhance the motivation or offered examples of alternative forms that could be considered. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a missing ablation study and suggests specific aspects that could be analyzed, such as the role of the \\sigma in the RBF kernel and the effects of \\eta and \\tau in equation (7) on performance. While the comment provides explicit actions for the authors to take, such as conducting an ablation study and analyzing specific aspects, it does not provide detailed guidance on how to conduct these analyses or what specific experiments to conduct. The authors are left with a clear understanding of what needs to be addressed but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"equation (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an analysis of the \\sigma in the RBF kernel and the effects of \\eta and \\tau in equation (7) on performance. The comment provides clear guidance on what aspects need to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some ablation studies are missing, which could lead to confusion and extra experimentation for practitioners. It provides specific examples, such as the \\sigma in the RBF kernel and the effects of \\eta and \\tau in equation (7) on performance. These examples are supported by logical reasoning and specific references to the figures and equations, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the importance of these analyses. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of ablation studies, which could lead to confusion and additional experimentation for practitioners. It provides specific examples of aspects that could be analyzed, such as the role of the \\sigma in the RBF kernel and the effects of \\eta and \\tau in equation (7) on performance. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft. However, the comment could be more helpful if it included suggestions on how to conduct these analyses or what specific experiments to conduct. Overall, the comment is mostly helpful as it provides valuable insights and guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claim in section 2, \"Finally, INRs operate on a per-data-instance basis, meaning that one time-series instance is required to train an INR,\" is true but not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what changes they should consider to enhance the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, stating that it is true but not an advantage due to the limitation of only being able to handle a single time-series instance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claim in section 2, \"Finally, INRs operate on a per-data-instance basis, meaning that one time-series instance is required to train an INR,\" is true but not an advantage. However, the comment lacks any supporting evidence, reasoning, or references to justify why this claim is not an advantage. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim in the paper regarding the operation of INRs on a per-data-instance basis, which is true but not considered an advantage. However, the comment does not provide any further explanation or justification for why this claim is not an advantage, nor does it offer suggestions for improvement or alternative perspectives. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address this issue or enhance their draft. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the experiments, specifically the narrow focus on RoBERTa-base and the need to investigate generalizability to other models. It suggests that the authors should consider investigating differences in model size, objective function, and architecture, and provides a specific example of GPT-2. The comment also suggests including more analysis and discussion for GPT-2. While the action is explicit, it is somewhat vague as it does not provide detailed guidance on how to conduct these experiments or analyze the results. The authors are given a clear direction but may need to infer more specifics to fully implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"RoBERTa-base,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate generalizability to other models, differences in model size, objective function, and architecture, and the inclusion of more analysis and discussion for GPT-2. This provides clear guidance on what the authors should focus on to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the limited scope of experiments, specifically the use of RoBERTa-base and the need to investigate generalizability to other models. It suggests that the authors should consider differences in model size, objective function, and architecture, and provides an example of GPT-2. The comment is somewhat verifiable as it logically presents a valid point about the need for broader experimentation, but it lacks specific examples or references to support the claim about generalizability. The suggestion to include more analysis and discussion for GPT-2 is a helpful addition, but the overall claim could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically the narrow focus on RoBERTa-base and the need to investigate generalizability to other models. It suggests that the authors should consider differences in model size, objective function, and architecture, and provides a specific example of GPT-2. The comment also encourages the inclusion of more analysis and discussion for GPT-2. This feedback is clear and actionable, as it directs the authors to expand their experiments and analysis to enhance the generalizability and comprehensiveness of their work. However, it could be more helpful if it included suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should explore the generalizability of their method beyond transformers in vision. While the comment implies that the authors should attempt to apply their method to these other areas, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should attempt to apply the method to other areas. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs), and suggests that the authors should explore the generalizability of their method beyond transformers in vision. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should explore the generalizability of their method beyond transformers in vision. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the model is limited to image data and ViT. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the need for broader applicability based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should explore the generalizability of their method beyond transformers in vision, which could enhance the method\\'s value and broader impact. While the comment identifies a potential limitation and provides a direction for improvement, it lacks specific suggestions or guidance on how to address this issue. The authors are given a clear idea of what needs to be improved but are not provided with actionable steps or detailed advice. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, such as WILDS [9], to strengthen the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include additional experiments on natural distribution shifts. However, the comment does not specify which specific TTA methods should be evaluated or how the results should be presented, leaving some room for interpretation. Therefore, while the action is clear, it is somewhat vague in terms of implementation details. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests evaluating TTA methods on more conditions of natural distribution shift, such as WILDS [9], to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an additional evaluation that could enhance the paper, but without explicit references to sections or specific experiments, the authors may struggle to identify the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using non-standard benchmarks breaks popular TTA methods, which is an interesting observation. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this observation or how it relates to their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies an interesting observation about the performance of TTA methods under non-standard benchmarks, suggesting that using natural distribution shifts like WILDS could strengthen the paper. This feedback is somewhat helpful as it points out a potential area for improvement and provides a specific suggestion for enhancing the paper\\'s contribution. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of the TTA methods should be evaluated. To be more helpful, the comment could provide additional context or examples of how the authors might incorporate this suggestion into their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for training, similar to that used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. However, the comment does not explicitly instruct the authors to adopt this approach or provide detailed guidance on how to implement it. While the suggestion is clear, the lack of explicit instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and the \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018\" reference, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the unbalanced data and suggests a more convincing setting for training, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer suggests that the authors should use a more convincing setting, like that in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to a relevant work, which supports the claim by offering a practical example of a more convincing setting. This makes the claim mostly verifiable, as it provides a clear rationale and evidence for the suggestion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the unbalanced data in the preprocessed Amazon review dataset, noting that the perfectly balanced data is impractical in real-world applications. It suggests a more convincing setting, like that used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their dataset and training process. However, the comment could be more helpful if it explained why this specific setting is more convincing or how it might impact the results. Overall, the comment is mostly helpful as it directs the authors to a specific improvement area but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the contribution of different modalities in different instances and suggests that Equation 3 directly removes the modal subset of all instances. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable steps or concrete advice, leaving the authors uncertain about what specific changes or improvements are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of different modalities in different instances and questions how to deal with the problem of directly removing the modal subset of all instances. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with Equation 3 and suggesting how to address it, but without explicit references to specific sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the contribution of different modalities in different instances and questions the removal of the modal subset in Equation 3. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution is different for each modality. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the contribution of different modalities in different instances, specifically questioning the direct removal of the modal subset in Equation 3. It raises a concern about the implications of this action and suggests that the authors should address this problem. However, the comment lacks specific guidance or suggestions on how to deal with this issue, such as providing alternative approaches or discussing potential consequences. While it highlights an important area for consideration, the feedback is incomplete and does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out confusion in the description of the MFDA setting, specifically regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed information or examples. However, it does not explicitly instruct the authors to make these changes or offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they need to clarify the notation and provide more context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the notation for target domain \\u03c4 and the use of sparse labels, as well as the mention of unlabeled data in source domains. The comment further questions whether these unlabeled data are used during training, similar to the original MFDA paper. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the description of the MFDA setting, specifically regarding the notation for target domain \\u03c4 and the use of sparse labels. The reviewer questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper. The comment is somewhat verifiable as it provides a logical basis for the confusion, referencing the original MFDA paper for comparison. However, it lacks specific examples or references to support the claim that the description is confusing or inaccurate. The authors would need to make a concerted effort to understand and address the issue, which is not fully supported by the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper, and points out that the problem setting description is confusing and deferred. This feedback is clear and actionable, as it highlights a critical area where the authors need to improve the clarity and coherence of their work. By addressing these issues, the authors can enhance the readability and comprehensibility of their paper. Therefore, the comment is highly helpful, as it provides a clear path for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that epoch-wise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It suggests that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it proposes that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear suggestion for an additional analysis, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that epoch-wise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. The suggestion is specific, as it outlines a potential area for further investigation, but the lack of grounding makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that epoch-wise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. The comment provides a logical reasoning by explaining how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms. However, the comment lacks specific examples or references to support the claim that epoch-wise analysis would be beneficial. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It suggests that epoch-wise analysis, particularly in finite sum settings, could be beneficial for understanding the behavior of optimization algorithms. The comment highlights the potential benefits of such an analysis, including investigating the effect of batch size or different sampling strategies on the progress of algorithms and aiding comparative analysis of deterministic and stochastic methods. This feedback is clear and provides a concrete direction for the authors to enhance their analysis and understanding of their results. However, it could be more helpful if it included specific examples or references to similar studies that have employed epoch-wise analysis. Overall, the comment is mostly helpful as it offers a valuable suggestion for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the distinction between three classes of extreme speech, specifically questioning the classification of certain instances. It points out that the authors included definitions but still find it challenging to differentiate between derogatory and exclusionary extreme speech. The reviewer questions the annotation of a specific instance and seeks clarification on the local regulation over speech and its impact on zero-shot cross-country classification. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the classes and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the specific section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example of an instance that is difficult to classify. The comment further asks for clarification on the local regulation over speech and its impact on zero-shot cross-country classification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the distinction between three classes of extreme speech, specifically questioning the classification of certain instances. It references the \"Paper Summary\" and provides an example of an instance that is difficult to categorize as derogatory or exclusionary extreme speech. The reviewer also questions the annotation of this instance and seeks clarification on the local regulation over speech and its impact on zero-shot cross-country classification. While the comment identifies a specific issue and seeks clarification, it lacks detailed reasoning or references to support the claim that the distinction between the classes is unclear. This makes the comment somewhat verifiable, as it provides a starting point for the authors to address the issue but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the classification of extreme speech, particularly the distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the paper\\'s sample data file, questioning why an instance is classified as exclusionary extreme speech but not derogatory. This feedback is valuable as it highlights a clear area for improvement in the paper\\'s classification methodology. Additionally, the comment raises questions about the local regulation over speech and its impact on zero-shot cross-country classification, prompting the authors to clarify their methodology and provide more detailed explanations. While the comment could be more helpful if it offered suggestions on how to address these issues, it still provides actionable feedback that can guide the authors in improving their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to implement the suggested study. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the study of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is important to study the effect of noise accumulation in the context of homomorphic encryption, which is a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this limitation or how it affects the study. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study of sequential ensembling in the context of homomorphic encryption. It points out that the accumulation of noise in homomorphic encryption prevents the use of even single deep neural networks on encrypted data. This is a valuable observation that highlights an important aspect of the study that the authors may not have considered. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it provides a clear direction for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding a learning curve for a model without mean teacher or pi regularization to compare the effect of these regularization techniques. This is an explicit action, as it clearly specifies what needs to be added to the figure. The comment provides a concrete detail on how to implement the suggestion, making it highly actionable. Authors know exactly what to do to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a learning curve for a model without mean teacher or pi regularization to compare the effect of these regularization techniques. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors might infer that it relates to Figure 3, but this inference is not direct. The comment is specific in suggesting what needs to be added, but it lacks full grounding as it does not explicitly mention the figure or section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare the effect of these regularization techniques. However, the comment does not provide any reasoning, evidence, or references to support why this comparison is necessary or how it would contribute to the paper. Without additional context or explanation, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare the effect of these regularization techniques. This suggestion is clear and offers a concrete way to enhance the analysis and understanding of the model\\'s performance. By including this additional information, the authors can better demonstrate the impact of different regularization techniques on learning. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the overall understanding of the paper. Overall, the comment is mostly helpful as it provides a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proposed objective in Eq. 2, noting that it requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. It also highlights the lack of discussion on the effect of this optimization on the number of parameters compared to prior work, such as AlignFlow. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the effect on the number of parameters and compare it to prior work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the objective requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters compared to prior work, such as AlignFlow, is not discussed clearly. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective in Eq. 2 requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters compared to prior work, such as AlignFlow, is not discussed clearly. However, the comment lacks specific examples or references to support the claim about the number of parameters or the comparison to prior work. The reasoning is based on a general observation, which makes it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, as it does not provide enough detail or evidence to substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective in Eq. 2, noting that it requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. This is a critical observation that could impact the efficiency and scalability of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or discuss the effect on the number of parameters compared to prior work, such as AlignFlow. While the comment highlights an important area for improvement, it does not offer actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also points out that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or explanation to address the concerns raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and pointing out that the improvement of the designed solutions in Table 5 is not significant, particularly on the OfficeHome dataset. The comment provides specific examples of the marginal improvement in the OfficeHome dataset, which adds clarity to the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also points out that the improvement of the designed solutions in Table 5 is not significant, providing specific examples of marginal improvements on the OfficeHome dataset. This claim is somewhat verifiable as it provides some logical reasoning and examples to support the suggestion that the improvements are not significant. However, it could be strengthened by providing more detailed evidence or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also points out that the improvement of the designed solutions in Table 5 is not significant, providing specific examples of marginal improvements on the OfficeHome dataset. This feedback is somewhat helpful as it highlights a potential issue with the paper\\'s analysis and suggests that the authors might need to reconsider their approach. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or improve the analysis. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific omission in the experiment of face recognition, noting the absence of certain state-of-the-art references, such as Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also mentions that this work used the triplet loss and achieved better results on a similar dataset. The comment implies that the authors should include these references and potentially compare their results with those from the mentioned work. While the action is implicit, it is concrete because it specifies the missing references and provides a specific comparison to guide the authors. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and provides specific details about the missing references, such as \"Baidu\\'s work\" and the reported results. It also mentions the triplet loss used in the referenced work and compares it to the results in Table 3 of the paper. This level of detail allows the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what is missing (the references) and provides a comparison to the results in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the experiment of face recognition, specifically mentioning Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and its reported results. The reviewer provides a specific reference to the work, which supports the claim by allowing the authors to verify the existence and relevance of the missing references. This level of detail and specificity makes the claim mostly verifiable, as it provides clear evidence and context for the authors to understand and address the issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific omission in the experimental section, noting the absence of certain state-of-the-art references, such as Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also provides a detailed comparison to the results in Table 3 of the paper, highlighting that the VRF achieved a higher accuracy in a similar dataset. This feedback is clear and actionable, as it directs the authors to include relevant references and potentially improve their results by benchmarking against existing work. By addressing these points, the authors can enhance the rigor and comprehensiveness of their experimental section. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to discuss the conditions for DICE and consider how sparsification affects the range of ID and OOD. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims: first, that the range of ID and OOD does not change much with sparsification, and second, that Lemma 2 requires an identical mean as the assumption. These claims are somewhat verifiable as they are based on observations from Figure 4 and a specific assumption in the paper. However, the comment lacks detailed reasoning or references to support these claims, making it somewhat verifiable. The authors would need to further explore the data or assumptions to fully understand and address the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas where the paper could be improved: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. It highlights crucial aspects that need further exploration and discussion, which is valuable feedback for the authors. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered specific guidance on how to ensure DICE meets the discussed conditions. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to important aspects that need further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the integration of the update over all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider breaking up the text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reorganize the text to make it more readable. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the integration of the update over all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the integration of the update or the formatting of the text. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the integration of the update over all possible environments and suggests that it might be for space reasons. The reviewer also suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment provides a logical reasoning for the suggestion to break up the text, it lacks specific examples or references to support the claim about the integration of the update. The suggestion about formatting is more straightforward, but the lack of detailed justification for the integration issue makes the claim somewhat verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the integration of the update over all possible environments, suggesting that it might be due to space constraints. It also points out that the bolded sections in page 6 are currently a large wall of text and should be broken out into paragraphs for better readability. While the comment identifies a potential issue with the formatting of the paper, it lacks specific suggestions or guidance on how to address these concerns. The feedback is somewhat helpful as it highlights areas that need attention, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the experimental setup, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations or societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should consider using default settings for baselines, include missing baselines, and discuss limitations and societal impacts. The feedback is somewhat actionable as it highlights areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations or societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying areas for improvement, such as using default settings for baselines and including missing baselines, but it lacks grounding as it does not specify where these issues are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims and questions, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations or societal impacts. While the comment identifies areas for improvement, it lacks specific examples, references, or detailed reasoning to support these claims. The authors would need to infer the need for changes and make connections themselves, making the comment somewhat verifiable. The authors would need to make a significant effort to understand and address the issues raised, which justifies a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations or societal impacts. It provides specific feedback on each of these points, suggesting that the authors consider using default settings for baselines and include missing baselines, as well as discussing limitations and societal impacts. While the comment highlights important areas for improvement, it could be more helpful by offering concrete suggestions or examples on how to address these issues. Overall, the feedback is somewhat helpful as it provides clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This feedback provides a clear and concrete action for the authors to take, ensuring that they either include the temperature parameter or acknowledge its absence in the derivation. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, in the derivation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the validity of the derivation. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the derivation in the paper, noting that the temperature parameter, \u03c4, is missing in the transition from Equation 3 to Equation 4. This feedback is clear and actionable, as it provides the authors with a concrete step to address the issue by either including the missing parameter or acknowledging its absence. By addressing this point, the authors can ensure the rigor and accuracy of their derivation, which is crucial for the credibility of their work. Therefore, the comment is mostly helpful, as it offers a direct and meaningful suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific recommendation for enhancing the paper\\'s credibility and referencing practices, ensuring that the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual suggestion that does not involve an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for improving the paper. By recommending the inclusion of a citation on differential privacy, the reviewer offers a clear and concise way for the authors to enhance the credibility and comprehensiveness of their work. This feedback is direct and easy to implement, guiding the authors on how to improve their draft by adding a relevant reference. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. It provides a specific example by pointing out that the additional assumption of drawing the test set from the same distribution as the query set is natural in many machine learning settings. The reviewer also notes an issue with the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and address the inequality issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that the methodology requires significant additional assumptions, suggesting that this assumption is natural in many machine learning settings. The comment further provides specific feedback by pointing out an inequality issue on line 310 and suggesting that Theorem 4 might not be useful if this assumption is too hard to satisfy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the methodology requires significant additional assumptions, suggesting that the additional assumption of drawing the test set from the same distribution as the query set is natural in many machine learning settings. The reviewer provides a logical reasoning by comparing this assumption to those typically made in machine learning settings. However, the comment lacks specific examples or references to support the claim that this assumption is too extreme. While it provides some justification, it could be strengthened with additional evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but lacks detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme by implying that the additional assumption of drawing the test set from the same distribution as the query set is natural in many machine learning settings. The reviewer offers a logical reasoning by comparing this assumption to those typically made in machine learning settings, which is a helpful observation. Additionally, the comment points out an inequality issue on line 310 and suggests that Theorem 4 might not be useful if this assumption is too hard to satisfy. This feedback is clear and actionable, as it directs the authors to reconsider their claim and address the inequality issue. However, it could be more helpful if it provided specific guidance on how to address these concerns or suggested alternative approaches. Overall, the comment is mostly helpful as it offers valuable insights and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out severe writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the writing or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies specific issues with the writing, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it weakly grounded. The comment is specific in detailing the types of writing issues, but without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights specific areas that need improvement, it does not provide actionable guidance or suggestions on how to address these issues. The comment lacks depth and does not offer detailed feedback or examples of how to improve the writing, making it somewhat helpful. The authors are aware of the issues but are not given specific steps to take, which limits the comment\\'s usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It instructs them to run the corresponding experiments for untrained networks and add them to the figures and Table 1. Additionally, it clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. These explicit and detailed actions make the comment highly actionable, as the authors know exactly what steps to take to address the issues raised.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding them to the figures and Table 1. The comment also provides detailed questions about the random data in Figures 3c and 3, clarifying whether the network was trained on random data or unaltered data, and whether the data was normalized. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple requests for clarification and additional information. It does not contain any subjective opinions, judgments, or suggestions that require verification. Instead, it seeks clarification on specific aspects of the figures and data, such as the training process and data normalization. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also provides a detailed request to include examples of random data in the appendix. While the comment is clear and actionable, it could be more helpful if it offered suggestions on how to present the additional information or provided examples of how to address the issues. Overall, the feedback is valuable but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. The authors are left without any guidance on how to respond to the comment or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the meaning of \"100 steps\" in the context of the search models comparison, providing clear guidance on what needs clarification. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify this issue or improve the explanation. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. It also recommends that the authors consider rejecting the paper due to the limited novelty and marginal improvement. While the comment provides explicit actions and concrete details on how to proceed, it could be more helpful if it offered specific guidance on how to conduct the statistical analysis or what statistical tests to use. Nonetheless, the action is clear, and the authors know exactly what steps to take to address the reviewer\\'s concerns. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the improvement over previous methods, specifically mentioning that it is small, about 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as repeating the experiments and conducting statistical significance analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis on the numbers. This claim is somewhat verifiable as it provides a logical reasoning for the need to repeat the experiments and conduct statistical analysis, but it lacks specific examples or references to support the claim about the size of the improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the limited improvement over previous methods, which is estimated to be around 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis on the numbers to address this concern. Additionally, the comment suggests that due to the limited novelty and marginal improvement, the paper may not be suitable for publication. This feedback is clear and actionable, providing the authors with specific steps to improve their draft and guidance on whether the paper\\'s contribution is significant enough for publication. However, it could be more helpful if it offered suggestions on how to conduct the statistical analysis or what statistical tests to use. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment identifies a missing section and provides a suggestion for its inclusion, it does not offer specific guidance on how to integrate the information into the main paper or what content should be included in the approach section. The action is implicit and somewhat vague, as the authors need to infer the details of how to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the approach section, and suggests that the supplementary material should be used as additional information rather than an extension to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment lacks specific examples or references to support the claim about the approach section being missing or to justify the suggestion about the supplementary material. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the main paper, noting the absence of the approach section. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment provides a clear direction for improvement, it lacks specific guidance on how to integrate the approach section into the main paper or what content should be included in the approach section. The feedback is somewhat helpful as it highlights a critical gap in the paper but could be more beneficial with additional details or suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the statement in the introduction regarding the biological plausibility of backpropagation may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the statement. It lacks concrete suggestions or specific actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the widely accepted view that backpropagation is biologically implausible. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, as it suggests that the plausibility remains a subject of debate. However, the comment lacks specific evidence or references to support this claim, such as examples of widely accepted beliefs or scientific literature that challenge the plausibility of backpropagation. Without such evidence, the claim remains unverifiable, as it does not provide a clear rationale for the assertion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak, as it suggests that the plausibility remains a subject of debate, when in fact it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it encourages the authors to reconsider and strengthen their statement to accurately reflect the current understanding in the field. However, the comment could be more helpful if it provided specific suggestions on how to strengthen the statement or references to support the claim. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the connection between the necessary conditions for overparameterization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization might not lead to robust generalization. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The authors are left to infer that they need to clarify the connection between necessary conditions and generalization bounds, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the connection between necessary conditions for overparameterization and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization might not lead to robust generalization. However, it does not specify which part of the paper this concern is related to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connection between necessary conditions for overparameterization and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization might not lead to robust generalization. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the necessary conditions might have stronger implications for generalization bounds. This lack of supporting evidence or detailed explanation makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the connection between necessary conditions for overparameterization and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization might not lead to robust generalization. While the reviewer acknowledges that the authors acknowledge this in the conclusion, the comment identifies a potential weakness in the paper that could impact its overall robustness and generalizability. However, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their analysis. The feedback is somewhat helpful as it points out a potential issue but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added, but it is somewhat vague in terms of how to implement the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work on untrained NNs and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors mention recent work on untrained NNs for inverse problems in imaging, specifically referencing the paper by Ulyanov et al. (CVPR 2018). The comment provides a logical reasoning by pointing out that this work is relevant to the current study, as it demonstrates the potential of untrained networks for solving inverse problems. However, the comment lacks specific examples or references to the methods mentioned in the Ulyanov et al. paper, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by pointing out that the authors should mention recent work on untrained NNs for inverse problems in imaging, specifically referencing the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with other methods in this class. This feedback is actionable and offers a clear direction for the authors to enhance the context and relevance of their work. By incorporating these suggestions, the authors can strengthen the novelty and significance of their contribution. However, the comment could be more helpful if it provided specific examples or references to the methods mentioned in the Ulyanov et al. paper, which would further guide the authors in their comparisons. Overall, the comment is mostly helpful as it offers valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation of Algorithm 1 is unclear due to the reformulation of the prox-linear subproblem using the conjugate function, which makes it equivalent to the subproblem in Algorithm 1. The reviewer implies that the authors should clarify the motivation for Algorithm 1 in light of this equivalence. However, the comment does not provide explicit instructions or concrete steps on how to address this issue, such as suggesting specific changes to the motivation section or explaining the implications of the equivalence. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without detailed guidance on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1 due to the reformulation of the prox-linear subproblem using the conjugate function, which makes the motivation unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of Algorithm 1 is unclear due to the reformulation of the prox-linear subproblem using the conjugate function, which makes it equivalent to the subproblem in Algorithm 1. The reviewer suggests that this equivalence makes the motivation unclear. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation highlights a potential confusion in the paper\\'s rationale, which could affect the clarity and effectiveness of the presented work. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or clarify the motivation for Algorithm 1. While it points out a potential problem, it lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant information. This is a clear and direct request, giving the authors a specific action to take. The comment is explicit and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why performance degrades when using additional information about missing, wrong, or redundant information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant information. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant information. It prompts the authors to provide an explanation for this phenomenon, which is a clear and actionable request. This feedback is valuable as it encourages the authors to clarify their results and potentially improve the robustness of their findings. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for understanding the performance degradation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. However, the comment does not explicitly instruct the authors on how to improve the clarity of these explanations or provide guidance on what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify these points but may not know exactly how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of specific examples and questions about the clarity of the explanations in the paper. It highlights specific lines and figures where the authors have not adequately explained their methods, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. By providing these examples, the reviewer offers a clear rationale for their claim that the explanations are unclear. This makes the comment mostly verifiable, as it provides a detailed basis for the critique. However, it could be further strengthened by referencing specific literature or standards that expect more detailed explanations. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and comprehensiveness of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, which are not adequately explained. By highlighting these areas, the comment offers actionable feedback that can help the authors improve the clarity and effectiveness of their explanations. However, the comment could be more helpful if it suggested ways to enhance the clarity or provided additional guidance on how to address these issues. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It points out that minimizing the averaged loss across noise-injected models does not guarantee the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noise-injected models after training to support their claim. This feedback is explicit and provides a clear action for the authors to take, namely conducting the requested analysis to ensure the flatness of the minima. The comment is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (3)\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an analysis of the losses of the noise-injected models after training to support the claim about the flatness of the minima. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis about the flatness of the minima is missing, specifically mentioning that minimizing the averaged loss across noise-injected models does not ensure the flatness of the minima. The comment provides a logical reasoning by explaining the importance of analyzing the losses of the noise-injected models after training to support the claim about the flatness of the minima. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the reasoning or provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the analysis of the proposed method, specifically regarding the flatness of the minima. It points out that minimizing the averaged loss across noise-injected models does not guarantee the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noise-injected models after training to support their claim. This feedback is clear and actionable, as it directs the authors to a specific area where their analysis is lacking and provides a concrete suggestion for improvement. By addressing this feedback, the authors can enhance the rigor and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the presentation of the model in Section 4. It suggests that the model is somewhat complicated and recommends careful reading, potentially with reference to the supplement. The reviewer also provides specific guidance on how to improve the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These detailed actions are clear and provide the authors with a clear path to enhance their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation of the model, suggesting that the natural language descriptions be replaced with notation and that breakout diagrams be added to illustrate the attention mechanisms. This level of detail provides the authors with a clear understanding of what needs to be addressed to improve the presentation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model is somewhat complicated and recommends careful reading, potentially with reference to the supplement. It also provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are supported by logical reasoning and specific examples, making the claim mostly verifiable. The comment provides a clear rationale for the need to improve the presentation, which is a valuable contribution to the authors. However, it could be further strengthened by providing more detailed examples or references to similar approaches. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the presentation of the model in Section 4. It acknowledges that the model is somewhat complicated and recommends careful reading, potentially with reference to the supplement. The comment suggests that the natural language descriptions be replaced with notation and that breakout diagrams be added to illustrate the attention mechanisms. This detailed guidance offers the authors a clear path to improve the clarity and accessibility of their presentation, making the comment highly helpful. By addressing these specific suggestions, the authors can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies an area that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information or clarification, but it lacks concrete guidance on what specific details should be included or how to present them. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the origin of the red line and whether there is a ground truth for the test data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. This is a specific and relevant question that could help the authors clarify their experimental setup and methodology. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the goal of the paper, specifically mentioning the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the need for a justification of the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate its usefulness in future applications. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically mentioning the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the need for a justification of the benefits of the proposed method over these existing methods. It also suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate its usefulness in future applications. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or methodology sections. The comment is specific in detailing what needs to be addressed, such as the need for a comparison and justification of the benefits. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the goal of the paper, specifically mentioning the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the need for a justification of the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate its usefulness in future applications. This claim is somewhat verifiable as it provides a logical reasoning for the need of comparison and justification, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the goal of the paper, noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the need for a justification of the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate its usefulness in future applications. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how to address these concerns. The authors are given a general direction but are not provided with actionable steps or detailed advice on how to improve their draft. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCT-pair) and why there is no mention of the ablation studies of MCT without the adaptive metrics. While these questions are clear, they do not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to investigate the discrepancy between the results and align them, but the comment lacks concrete guidance on how to do so. Similarly, the mention of ablation studies without the adaptive metrics is a request for clarification, but it does not offer specific steps for conducting these studies. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the discrepancy between the results of Table 6 and Table 1 and requests clarification on the ablation studies of MCT without adaptive metrics. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, without making any subjective claims or suggestions. It does not contain an opinion, judgment, or statement that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s content and methodology. First, it questions the discrepancy between the results of Table 6 and Table 1 (MCT-pair), which could indicate a potential issue with the experimental setup or results. This is a valuable point that prompts the authors to investigate and clarify the discrepancy. Second, it asks about the ablation studies of MCT without the adaptive metrics, which could be an important area for further exploration. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their work. While it points out areas for potential improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the inclusion of AccNet as part of a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to consider this, but it lacks specific guidance or actionable advice for the authors. While it prompts the authors to consider a potential integration, it does not provide detailed reasoning or examples of how this could be beneficial or how to implement it. The comment is somewhat helpful as it encourages the authors to explore a new direction, but it could be more beneficial with additional context or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the paper, namely that some abbreviations are not defined, such as \"NE\" on L73, and that the superscript notation in Equation 6 is not defined until much later, which hinders understanding in an initial read. The reviewer provides specific examples of these issues by referencing specific lines and equations. Additionally, the comment suggests that the authors should define these abbreviations and notation earlier in the paper to improve clarity. This feedback is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L73\" and \"L166,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the abbreviation \"NE\" not being defined and the superscript notation in Equation 6 not being defined until later, which hinders understanding in an initial read. The comment also references external works, providing specific examples of how these issues affect the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the paper, namely that some abbreviations and notation are not defined, which hinders understanding in an initial read. The reviewer provides specific examples, such as \"NE\" on L73 and the superscript notation in Equation 6, which are not defined until later. Additionally, the comment references external works to support the claim, citing specific references to relevant literature. This provides a clear and robust basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that some abbreviations and notation are not defined, which hinders understanding in an initial read. The reviewer provides specific examples, such as \"NE\" on L73 and the superscript notation in Equation 6, which are not defined until later. Additionally, the comment references external works to support the claim, citing specific references to relevant literature. This feedback is clear and actionable, as it directs the authors to define these abbreviations and notation earlier in the paper to improve clarity. By addressing this issue, the authors can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: first, it challenges the claim that \"these works are all based on the simple SGD for decentralized optimization,\" suggesting that the Walkman algorithm uses ADMM instead; second, it points out that the phrase \"it\" in Section 3 lacks a clear reference. While the first issue is explicit and provides a clear action for the authors to reconsider their claim, the second issue is implicit and lacks specific guidance on how to address the lack of clarity in the reference. The first action is concrete, but the second is vague. Therefore, the comment is mostly actionable, as it provides explicit guidance on the first issue but lacks detail on the second.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about the Walkman algorithm, noting that it is solved by ADMM and not SGD, and it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization,\" by pointing out that the Walkman algorithm uses ADMM instead. This is a factual correction that does not require an opinion or judgment. The second part of the comment questions the clarity of the reference to \"it\" in Section 3, which is a request for clarification. Therefore, the comment is factual and does not contain subjective claims or opinions that require verification. It is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific and actionable pieces of feedback. First, it challenges a claim made in the paper regarding the use of SGD for decentralized optimization, noting that the Walkman algorithm uses ADMM instead. This is a clear and important correction that the authors should address to ensure the accuracy of their claims. Second, it points out a lack of clarity in the reference to \"it\" in Section 3, which could be improved for better understanding. While the comment identifies specific areas for improvement, it could be more helpful by providing suggestions on how to clarify the references or rephrase the claims. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing attention and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback provides a clear and explicit action for the authors to take, which is to include these results in the paper. The suggestion is specific and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not present convincing results due to the reporting of best results on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it provides a logical reasoning for why the current results are insufficiently convincing. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s presentation of results, suggesting that the authors should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper\\'s presentation of results. By addressing this point, the authors can enhance the credibility and persuasiveness of their findings. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the paper\\'s conclusions. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement that can strengthen their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors provide more values of the parameter \\u03b1, specifically suggesting values of 1e-2 and 1e-3. This feedback is clear and provides concrete guidance on what additional values should be included in the ablation study. The authors know exactly what changes are needed to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient ablation study on \\u03b1 and recommends providing more values of \\u03b1, such as 1e-2 and 1e-3. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study on \\u03b1 is insufficient, as it only considers values of 1e-4, 1e-1, and 5e-1 with a large gap between 1e-4 and 1e-1. The reviewer recommends providing more values, specifically 1e-2 and 1e-3. This claim is somewhat verifiable as it provides a logical reasoning for why additional values are needed, but it lacks specific examples or references to support the argument. The authors can understand the need for more values but may need to conduct additional experiments to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the insufficient ablation study on the parameter \\u03b1. It points out that the current study only considers values of 1e-4, 1e-1, and 5e-1 with a large gap between 1e-4 and 1e-1. The reviewer recommends providing more values, specifically 1e-2 and 1e-3, to better understand the impact of \\u03b1 on the results. This feedback is clear and actionable, as it directly guides the authors on how to enhance their experimental design and analysis. By addressing this suggestion, the authors can significantly improve the robustness and comprehensiveness of their study. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test and the number of vocabulary words. While the questions are explicit, the comment does not provide specific guidance on how to address these issues. The authors know what information is missing but may not be sure how to incorporate it into their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test and the number of vocabulary words. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific, as they ask for detailed information about the dataset, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test and the number of vocabulary words. While the questions are relevant and could guide the authors in improving their draft, the comment lacks specific suggestions or actionable advice on how to address these issues. The authors are given direction but not detailed guidance on how to implement the feedback. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator co-adapts with the generator, potentially leading to a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the potential issue of the discriminator getting stuck at a local optimum. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator co-adapts with the generator, potentially leading to a local optimum. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the claim and explains the difference between the two figures. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the reduction in exposure bias is occurring. The reviewer explains the difference between this approach and Figure 4, noting that the discriminator co-adapts with the generator, potentially leading to a local optimum. This feedback is valuable as it offers a specific method for evaluating the claim and highlights a potential pitfall in the approach. However, the comment could be more helpful if it provided additional guidance on how to address the issue of the discriminator getting stuck at a local optimum. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear suggestion for evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the organization or suggest alternative ways to present the prompts. As a result, the authors are left without a clear understanding of what changes they should make to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the organization of the prompts, noting that all sentences are squeezed together. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the style design is clean but that the prompts in Tables 6 and 7 are not well-organized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is somewhat helpful as it highlights a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the organization. While it points out a problem, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between three sub-figures is unclear. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the lack of concrete steps or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the clarity of the figures, such as the confusion between sub-figures and the lack of labeling for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion between sub-figures. It also notes that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This claim is somewhat verifiable as it provides specific examples of the issues, which allows the authors to understand the problem. However, the comment lacks detailed reasoning or references to support why these issues are problematic or how they impact the overall understanding of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between three sub-figures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it provides the authors with specific areas to improve the clarity and labeling of their figures. By addressing these issues, the authors can enhance the readability and comprehension of their paper. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar issues have been addressed in other works. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of perplexity as a measure of the model retaining semantic information after fine-tuning, questioning whether it accounts for domain drift and catastrophic forgetting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider domain drift and catastrophic forgetting when evaluating their model. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of perplexity as a measure of the model retaining semantic information after fine-tuning, questioning whether it accounts for domain drift and catastrophic forgetting. However, it does not specify which part of the paper this concern is related to, such as a particular section or figure where perplexity is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about domain drift and catastrophic forgetting, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of perplexity as a measure of the model retaining semantic information after fine-tuning, suggesting that it does not account for domain drift and catastrophic forgetting. While the comment raises a valid concern, it lacks specific examples or references to support the claim that perplexity is insufficient for measuring these factors. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of perplexity as a measure of the model retaining semantic information after fine-tuning, questioning whether it accounts for domain drift and catastrophic forgetting. While it identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or control these factors. The comment highlights a critical aspect of the model evaluation but lacks actionable advice, making it somewhat helpful. The authors are left with a clear direction for improvement but without detailed guidance on how to implement it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, particularly regarding long-context language models. It specifies that this should include discussions on sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and provides concrete details on what needs to be added to the Related Work section, making it highly actionable. The authors know exactly what information is missing and how to incorporate it into their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work section\" and the \"paragraph on long-context language models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comprehensive details on existing methods and their limitations in the context of long-context language models. The comment provides a detailed list of specific methods that should be included, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section is lacking details, particularly regarding the long-context language models. The comment suggests that the paragraph should provide a more comprehensive overview of existing methods and their limitations, including specific references to sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is somewhat verifiable as it provides a list of potential areas to expand upon, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to conduct additional research or provide more detailed explanations to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the Related Work section of the paper. It identifies a specific area of lacking detail, namely the long-context language models, and suggests that the paragraph should provide a more comprehensive overview of existing methods and their limitations. The comment offers a detailed list of potential topics to include, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is highly helpful as it guides the authors on how to enhance their Related Work section, ensuring that the paper is more comprehensive and up-to-date. By addressing these points, the authors can significantly improve the clarity and depth of their discussion. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or guidance on how to improve the writing or clarify the unclear points. The feedback lacks actionable details, such as suggestions for rephrasing or clarifying specific sections, making it difficult for the authors to know exactly what changes to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of specific areas that need clarification. Without explicit references to sections or examples of unclear points, the authors cannot confidently determine which parts of the paper need improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or reasoning to support these claims, making it difficult for the authors to understand the exact areas that need improvement. Without detailed feedback or references to specific sections, the authors are left without a clear understanding of what needs to be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or guidance on how to improve the writing or clarify the unclear points. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of what needs to be addressed or how to enhance their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance or suggestions on how the authors could improve them. The comment lacks actionable details, such as recommending specific changes or improvements to the writing style or annotations. Without concrete suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Poor writing and annotations,\" indicating that the authors should address issues with writing and annotations. However, it does not specify which parts of the paper are affected by these issues, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the writing and annotations, noting that they are difficult to follow. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might improve the clarity or organization of their work. Without detailed feedback or examples, the authors are left without a clear understanding of what changes they need to make to enhance the readability of their draft. Therefore, the comment is not helpful, as it does not offer any constructive feedback for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results presented in Table 2, specifically questioning why the proposed method achieves the best overall F1 score while not achieving the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a detailed explanation or analysis to clarify this discrepancy. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score while not achieving the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results presented in Table 2, specifically questioning why the proposed method achieves the best overall F1 score while not achieving the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific concern about the results presented in Table 2, questioning why the proposed method achieves the best overall F1 score while not achieving the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. This feedback is somewhat helpful as it identifies a potential inconsistency in the results, prompting the authors to clarify or explain this discrepancy. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the results more clearly. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a specific area needing clarification, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the proposed solution. As a result, the authors are left without any clear direction on how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this comment pertains to, making it weakly grounded. The comment is specific in suggesting minor improvements, such as providing more details on the relaxation proposed by Guzman et al. This provides some level of specificity, but the lack of full grounding makes it challenging for the authors to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or constructive criticism, the authors are left without a clear path for enhancing their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific suggestions for improving the presentation of results, such as labeling the y-axis in Figures 2 and 3 and using a scatter plot with x/y axes being runtime/performance. It also recommends highlighting the best results in tables. These explicit actions and concrete details give the authors clear guidance on how to enhance their results presentation, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as labeling the y-axis and using a scatter plot to better represent runtime and performance. The comment provides clear guidance on how to enhance the results presentation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the y-axis more clearly and using a scatter plot with x/y axes being runtime/performance. While the comment provides a specific suggestion for improvement, it lacks detailed reasoning or examples to fully substantiate why the current labeling is ambiguous or ineffective. The suggestion to use a scatter plot is a logical one, but the comment could be strengthened with additional justification or examples. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed reasoning or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies an issue with the labeling of the y-axis in Figures 2 and 3, which is ambiguous, and suggests using a scatter plot with x/y axes being runtime/performance to clarify the results. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for enhancing the clarity and interpretability of the results. The comment is clear and provides concrete steps for improvement, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer questions whether this adaptation process is truly unsupervised since the training set also requires annotations. While the comment identifies an issue with the labeling process, it does not provide explicit guidance on how to address this concern or suggest specific improvements. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their labeling process to ensure it aligns with the definition of unsupervised adaptation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the labeling process in the setting of Unsupervised Online Adaptation, suggesting that the adaptation is not truly unsupervised due to the requirement of annotations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the labeling process in the setting of Unsupervised Online Adaptation, suggesting that it is not truly unsupervised due to the requirement of annotations. The comment provides a logical reasoning by pointing out that the training set includes documents, queries, and labels, which implies a supervised process. However, the comment lacks specific examples or references to support the claim that the adaptation process is not unsupervised. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels. This observation questions the definition of unsupervised adaptation, as the training set requires annotations. While the comment highlights a potential inconsistency, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation of the adaptation process. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results are presented in a convoluted manner, specifically mentioning that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the presentation or clarify the reasoning behind the results. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" and the \"safety violations of the agent in the first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the presentation of results, namely that they disregard safety violations in the first 1000 episodes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard safety violations of the agent in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. This feedback highlights a potential weakness in the paper\\'s presentation, which could impact the reader\\'s understanding of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the presentation. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not provide any guidance on how to correct these errors or suggest improvements. The authors are left to infer that they should correct these errors and add a title, but without explicit instructions or concrete details, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific errors in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This level of detail provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are writing errors in the paper, specifically mentioning \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any further explanation or justification for why these errors are problematic or how they impact the paper\\'s clarity or credibility. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas where the paper\\'s presentation could be improved. However, the comment could be more helpful if it provided suggestions on how to correct these errors or improve the overall writing quality. Despite this, the feedback is somewhat helpful as it directs the authors\\' attention to areas needing improvement, which can guide them in enhancing the clarity and professionalism of their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests elaborating on the reasoning behind the statement on line 134, which relates to the theorem on the maximum slope. It provides a specific suggestion to elaborate on why the theorem holds, particularly by explaining the intuition behind the convergence of the RNN compared to the URNN. This feedback is explicit and provides a clear direction for the authors to improve their draft by elaborating on the rationale behind the theorem. The action is concrete, as it specifies exactly what needs to be added to the main text. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the theorem. The comment provides a clear direction for improvement by suggesting that the authors elaborate on the intuition behind the convergence of the RNN compared to the URNN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical reasoning by explaining that the RNN converges to the nearest FP, unlike the URNN, which supports the claim. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It points out that the statement on line 134, regarding the theorem on the maximum slope, could be elaborated upon to provide more insight into the intuition behind the convergence of the RNN compared to the URNN. This feedback is clear and directs the authors to a specific area where they can enhance their explanation, which is valuable for improving the clarity and depth of their work. However, the comment could be more helpful if it included examples or additional details on how to elaborate on this point. Overall, the comment is mostly helpful, as it offers a concrete direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a problem and suggests that the method may be difficult to apply in practice, it does not provide explicit guidance on how the authors should address this issue or improve their method. The action is implicit and somewhat vague, as the authors can infer that they need to consider the generalizability of their method in real-world scenarios but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the plan-based method, specifically mentioning that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also compares the learned plan methods with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections. The comment is specific in detailing the issue with the plan-based method and its limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method is unrealistic in real-world scenarios because it requires manually designing a plan based on the ground truth in advance. It also compares the learned plan methods with pre-defined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. The comment provides some logical reasoning by pointing out the limitations of the plan-based method, but it lacks specific examples or references to support the claim. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide sufficient evidence or detailed reasoning to fully substantiate the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also compares the learned plan methods with pre-defined plans, indicating that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. This feedback highlights a critical limitation of the method and suggests that the authors should consider ways to address this issue to improve the generalizability of their approach. However, the comment could be more helpful if it provided specific suggestions or examples on how to overcome this limitation. Overall, the comment is somewhat helpful as it points out a significant weakness but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using multiple train/test splits or folds instead of reporting results for a single held-out test set. While the comment implies that this would provide a more accurate illustration of the method's performance, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using multiple train/test splits or folds instead of reporting results for a single held-out test set, which is a specific suggestion for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as specific sections or experiments where this change could be implemented. The authors can infer that it relates to the experimental section, but the lack of explicit mention makes the comment weakly grounded. The suggestion is specific, as it details what needs to be addressed, but it lacks full grounding due to the absence of explicit references. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider using multiple train/test splits or folds instead of reporting results for a single held-out test set, which is a common practice in the field. The reviewer provides a logical reasoning for this suggestion, noting that it would provide a more accurate illustration of the method's performance. However, the comment lacks specific examples or references to support the claim that using multiple splits or folds is standard practice. This makes the claim somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental design by suggesting that the authors should consider using multiple train/test splits or folds instead of reporting results for a single held-out test set. This feedback is actionable and constructive, as it provides a clear direction for improving the accuracy and comprehensiveness of the results. However, the comment could be more helpful if it offered specific examples or guidance on how to implement this change, such as which splits or folds might be most appropriate or how to handle the increased computational complexity. Despite this, the comment provides valuable insight into a potential area for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section or methodology. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. Additionally, while the comment suggests a potential simplification, it does not provide specific guidance on how to achieve this simplification or what aspects of the method are overly complex. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any specific feedback or suggestions on how the authors might simplify the method or what aspects of the method are overly complex. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of \"s_t\" instead of \"s_n\" in Algorithm 1 on Line 8 and suggests that the authors might want to use \"s_n\" instead. It also poses a question about the asymptotic performance of the proposed method and requests average return results with more env steps. While the comment implies that the authors should make a change to the algorithm and provide additional results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of \"s_t\" instead of \"s_n\" and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the use of \"s_t\" instead of \"s_n\" in Algorithm 1 Line 8 and a request for additional results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the use of \"s_t\" instead of \"s_n\" in Algorithm 1 Line 8, which is a minor but important detail that could affect the accuracy of the results. It also poses a question about the asymptotic performance of the proposed method and suggests providing average return results with more env steps. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a direction for enhancing the paper\\'s clarity and comprehensiveness. However, the comment could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the language used in the paper, suggesting that the statement \"to force the neural network to memorize them\" should be toned down. It also suggests that the method section could be compressed and provides specific guidance on grammatical errors, such as plurals and articles. This feedback is clear and actionable, as it directs the authors to make specific changes to their language and structure. Additionally, the reviewer provides specific examples of grammatical errors, which further clarifies the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests ways to improve the method section, such as compressing it and addressing grammatical errors. The comment also highlights specific grammatical errors, providing detailed feedback on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a critique of the language used in the paper, specifically the statement \"to force the neural network to memorize them.\" The reviewer suggests that this statement is misleading, as the neural network does not memorize exact \"critical points\" as in TopoNet [24]. The comment also mentions that the method section is wordy and suggests it could be compressed. Additionally, it points out specific grammatical errors, such as plurals and articles, and requests a double-check. While the comment provides some reasoning and examples, it lacks detailed evidence or references to fully substantiate the claim about the neural network's memorization. Therefore, the comment is somewhat verifiable, as it provides some justification but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the language used in the paper, suggesting that the statement \"to force the neural network to memorize them\" is misleading and should be toned down. It also points out that the method section is wordy and could be compressed, offering a suggestion for improvement. Additionally, it identifies specific grammatical errors, such as plurals and articles, and requests a double-check. This feedback is actionable and provides clear guidance for the authors to revise their draft, making it mostly helpful. However, it could be more helpful if it included suggestions on how to rephrase the statement or improve the method section. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and that upon observing data, beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. While the comment provides a clear suggestion for clarification, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of uncertainty by suggesting that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This provides a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. The reviewer provides a clear explanation of the proposed clarification, which is based on logical reasoning and common knowledge about the nature of uncertainty in models. This makes the claim mostly verifiable, as it provides a clear and logical explanation for the suggested change. However, the comment could be strengthened by referencing specific examples or references to further support the reasoning. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for clarifying the description of uncertainty in the paper. It suggests updating the statement to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear and constructive, as it offers a precise correction to the language used in the paper. By making this change, the authors can improve the clarity and accuracy of their description of uncertainty, which is crucial for understanding and interpreting their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the comparison with Megatron, suggesting that it is overrated and that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer questions the claim of COCO-LM being parameter-efficient and suggests that if this is true, the conclusion could apply to these other works as well. The comment also asks specific questions about the experimental setup, particularly the change in BPE vocabulary, and whether this change could affect performance variance. While the comment identifies areas for improvement and questions that need clarification, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with Megatron and questions the claim of COCO-LM being parameter-efficient. It also specifies the comparison with other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size to COCO-LM. This provides clear guidance on what aspects of the paper are being addressed. The comment is specific in questioning the validity of the claim and suggesting that the conclusion could apply to other works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides a logical reasoning by pointing out that these other approaches are of similar size to COCO-LM, which supports the claim that the comparison with Megatron is overrated. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison made between COCO-LM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the basis of their comparison and potentially reevaluate their conclusions. Additionally, the comment raises a question about the change in BPE vocabulary and its potential impact on performance variance, prompting the authors to clarify their experimental setup. While the comment does not provide specific suggestions for improvement, it offers actionable insights that can guide the authors in refining their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of convincing evidence in the analysis from lines 128 to 149, specifically questioning the claim that GS-P-50 learns better representation. It references Fig 3 and suggests that the smaller class selectivity score of GS-P-50 indicates that it shares more features with ResNet-50, which may explain why the network is less dependent on additional context. The reviewer also references external works to provide additional context. However, the comment does not explicitly instruct the authors on how to address this issue or improve their analysis. While it points out a potential weakness, it lacks explicit guidance on how to improve the analysis or what specific changes should be made. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128 to 149\" and \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the convincing evidence in the analysis and referencing external works to provide context. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the convincing evidence in the analysis from lines 128 to 149, specifically regarding the class selectivity score of the GS-P-50 model compared to ResNet-50. The reviewer references external works, such as [1] and [2], to provide context and support their claim. However, the comment does not provide detailed reasoning or examples from the analysis to substantiate the claim. While the references offer some support, the comment lacks sufficient explanation or evidence to fully justify the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, particularly regarding the class selectivity score of the GS-P-50 model compared to ResNet-50. It questions the claim that GS-P-50 learns better representation and references external works to provide context and support its argument. This feedback is somewhat helpful as it points out a potential weakness in the analysis and suggests that additional context may be needed to fully understand the results. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve their analysis. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of convincing evidence in the paper's conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that this might be due to the limited exploration of combination methods and points to recent works that have shown the potential of feature-replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the need for exploring combination methods and determine which methods to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as [R1], [R2], and [R3], to support the critique. This provides clear guidance on what part of the paper is being addressed and what needs to be addressed. The comment is specific because it details the issue with the conclusions and suggests exploring combination methods as a potential solution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature-replay methods in continual learning, such as [R1], [R2], and [R3]. These references provide a basis for the claim, but the comment could be strengthened by further elaboration on why these works are relevant or how they support the critique. Overall, the claim is mostly verifiable, as it provides some evidence but lacks detailed reasoning or specific examples. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the paper\\'s conclusions, noting that some conclusions are not convincing. It provides a detailed example by referencing recent works that have shown the potential of feature-replay methods in continual learning, such as [R1], [R2], and [R3]. This feedback is clear and actionable, as it suggests that the authors should explore combination methods to strengthen their conclusions and provide more robust evidence for their claims. By pointing out specific works that have successfully applied feature-replay methods, the comment offers a concrete direction for improvement, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete actions for the authors to take. It suggests that the authors should provide more explanations for the bit operations, address the issue with Fig. 5a, and clarify how they dealt with DVS input when the input is in AER format. Additionally, it recommends analyzing energy consumption as in reference [15] to make the paper more solid. While the comment identifies areas for improvement, it lacks specific guidance on how to implement these changes. The authors are left to infer the actions they need to take, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to Fig. 5a and the handling of DVS input when the input is in AER format. It also suggests analyzing energy consumption as in reference [15]. However, the comment does not explicitly mention which section of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the need for more explanations and the suggestion to analyze energy consumption. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of several questions and suggestions for improvement, rather than making a claim or expressing an opinion. It seeks clarification on specific aspects of the paper, such as the handling of bit operations, the strange appearance of Fig. 5a, and the treatment of DVS input when the input is in AER format. The reviewer also suggests analyzing energy consumption as in reference [15]. These requests for clarification and suggestions are factual and do not require verification, as they are based on logical reasoning and common knowledge. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the paper, including the handling of bit operations, the strange appearance of Fig. 5a, and the treatment of DVS input when the input is in AER format. It also suggests analyzing energy consumption as in reference [15] to make the paper more solid. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions or examples on how to address these issues or improve the analysis. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first two bullets about contributions at the end of the introductory section can be combined together. While the suggestion is explicit, it lacks concrete guidance on how to combine the bullets or what specific changes should be made. The authors are left with a clear action to take but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the first two bullets about contributions at the end of the introductory section can be combined together. However, it does not specify which part of the paper this suggestion pertains to, such as the end of the introductory section or the bulleted list itself. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what changes should be made or how the combined bullets should be structured. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the first two bullets about contributions at the end of the introductory section can be combined together. However, it does not provide any reasoning, evidence, or examples to support why this suggestion is valid or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to implement the suggested change. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the first two bullets about contributions at the end of the introductory section can be combined together. While this feedback is somewhat helpful as it identifies an area for potential simplification or streamlining, it lacks depth and does not provide specific guidance on how to combine the bullets or what the combined content should entail. The comment does not offer suggestions on how to rephrase or restructure the content, leaving the authors with a general idea but without detailed instructions on how to implement the suggested change. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not provide comprehensive guidance for the authors to enhance their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define the dashed lines in figures 2A-B and 4B. This is a clear and direct action that the authors can easily follow, providing them with a specific task to improve their draft. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig. 2A-B\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the definition of the dashed lines in figures 2A-B and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it directly addresses a specific issue by requesting the definition of the dashed lines in figures 2A-B and 4B. This is a clear and actionable suggestion that can help the authors improve the clarity and understanding of their figures. By providing this feedback, the reviewer helps the authors ensure that their figures are properly labeled and explained, which is crucial for effective communication of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the action to take, it lacks specific guidance on how to integrate this discussion into the main paper. The authors are given a clear direction to focus on the pretraining method but are not provided with detailed instructions on how to structure or present this information. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed discussion on the unsupervised pretraining method in the main paper. The comment suggests focusing more on this method, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in the performance gain, based on data from Table 4. However, the comment lacks specific evidence or detailed reasoning to support this claim, such as specific data or comparisons with other methods. The suggestion to focus more on the pretraining method is logical but not fully substantiated by evidence or detailed analysis. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of detailed discussion on the unsupervised pretraining method in the main paper. It suggests that this method is a key factor in performance gain, as evidenced by data in Table 4. The comment provides a clear and actionable suggestion for the authors to focus more on the pretraining method in the main paper. This feedback is valuable as it directs the authors to a critical aspect of their work that needs further exploration and explanation. However, the comment could be more helpful if it included specific guidance on how to integrate this discussion into the main paper or provided examples of how other papers have effectively discussed similar topics. Overall, the comment is mostly helpful as it highlights a significant area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific guidance on how to achieve this simplification or which parts of the writing are particularly challenging. The action is implicit and vague, as the authors are left to infer that they need to simplify the writing but without concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific examples or references, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s writing, noting that it is difficult to follow in many places. While it suggests simplifying the writing, it does not provide specific examples or guidance on how to achieve this simplification. The comment lacks depth and actionable advice, leaving the authors without a clear understanding of what changes to make or where to focus their efforts. As a result, the feedback is not helpful, as it does not offer meaningful insights or direction for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more intuition and examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition for the proof and inquires about the ease of determining $f^*$ for different distributions of $P^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. The reviewer does not provide specific examples or references to support these claims, making the comment somewhat verifiable. The authors would need to infer the need for additional explanation and examples to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. This feedback is valuable as it prompts the authors to consider the clarity and depth of their explanations, particularly regarding the proof of a key theorem. However, the comment could be more helpful if it provided specific suggestions or examples on how to enhance the explanation or intuition. Overall, the comment is mostly helpful as it directs the authors to consider important aspects of their draft that need further development, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of notation in equations (7) and (10), specifically noting that one uses X and the other H^(1). However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks actionable guidance or advice on how the authors might clarify or justify this notation choice. Without any direction on how to respond, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, specifically noting that one uses X and the other H^(1). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation of the notation choices in equations (7) and (10). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the notation used in equations (7) and (10), specifically noting that one uses X and the other H^(1). This feedback highlights a potential inconsistency in the notation, which could be confusing for readers. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or clarify the notation. While it points out a potential problem, it does not offer actionable advice or insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between the description in Section 4.2 and the equation presented, specifically regarding the question representation and the use of r^q. It suggests clarifying the question representation and providing more information on what \\sigma means in the equation. Additionally, it raises a concern about the stability of the computation involving two sigmoid activations. While the comment provides explicit actions to clarify the question representation and the meaning of \\sigma, it does not offer specific guidance on how to address the numerical stability issue. The actions are concrete but could be more detailed, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the description and equation in Section 4.2, such as the lack of a term for r^q, which is the question representation, and the unclear meaning of \\sigma in the equation. The comment provides detailed guidance on what needs to be clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the question representation in Section 4.2, noting that the equation does not include a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and suggests that multiplying two sigmoid activations might be ill-conditioned and numerically unstable. The comment provides a logical reasoning for the concern, pointing out the discrepancy between the description and the equation. However, it lacks specific examples or references to support the claim about numerical stability, which would strengthen the verifiability. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could benefit from more detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the question representation in Section 4.2, noting that the equation does not include a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and suggests that multiplying two sigmoid activations might be ill-conditioned and numerically unstable. This feedback is clear and actionable, as it provides the authors with specific guidance on how to clarify the question representation and the meaning of \\sigma in the equation. By addressing these points, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to address the numerical stability issue or provided examples of how to improve the clarity. Overall, the comment is mostly helpful, as it effectively directs the authors to specific areas for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027. The reviewer suggests that taking Z\\u0027 to be the empty set would imply that x and y are independent given W, but Eq. (7) suggests otherwise. However, the comment does not provide explicit guidance on how the authors should address this conflict or resolve the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the definition of Z\\u0027 and potentially revise the equation accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the second rule in Lemma 2, Eq. (7), and the definition of Z\\u0027, highlighting a potential conflict between the two. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027. The reviewer provides a logical explanation by taking Z\\u0027 to be the empty set and demonstrating that this would lead to a contradiction with Eq. (7). This reasoning is clear and provides a solid basis for the claim, making the comment mostly verifiable. However, the comment could be strengthened by referencing specific equations or sections of the paper to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027. It provides a logical explanation by taking Z\\u0027 to be the empty set and demonstrating that this would lead to a contradiction with Eq. (7). This feedback is clear and actionable, as it highlights a specific issue that the authors need to address to resolve the conflict. However, the comment could be more helpful if it suggested ways to resolve the conflict or provided additional context or references to similar works. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and offers a starting point for addressing the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify this aspect of the algorithm. While the comment identifies a potential area for improvement, it lacks concrete guidance on how to address the issue or what specific changes should be made. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses Algorithm 2, specifically mentioning the coreset C and the query Q consisting of the archetypes z_1, \u00e2\u0080\u00a6, z_k initialized with the FurthestSum procedure. However, it does not specify which part of the paper discusses this algorithm, making it weakly grounded. The comment is specific in asking for clarification on how the archetype positions are updated after initialization. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of how the archetype positions are updated after initialization in Algorithm 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the initialization of archetype positions in Algorithm 2. It asks the authors to clarify how these positions are updated after initialization, which is a crucial aspect of the algorithm. This feedback is clear and actionable, as it prompts the authors to provide additional explanation or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how the authors might address this issue. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. While the comment explicitly states what needs to be added or clarified, it does not provide specific guidance on how to implement these changes. The actions are concrete but somewhat vague, as the authors know what needs to be added but may not have a clear understanding of the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the missing information, such as recording parameters, preprocessing steps, and the condition under which the resting-state was recorded. Additionally, it suggests a brief explanation of the harmonization technique and the number of regions in the parcellation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims about the missing information in the empirical study, such as recording parameters, preprocessing steps, and the condition under which the resting-state was recorded. It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation. While the comment identifies specific areas that need clarification, it lacks detailed justification or references to support these claims. The authors would need to infer the importance of these details and the need for clarification, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, as it directs the authors to specific areas that need clarification or expansion. By addressing these points, the authors can improve the transparency and comprehensibility of their study. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it guides the authors toward significant improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks cross-dataset experiments, which would test the generalization of the work. While the comment highlights an important area for improvement, it does not provide explicit guidance on how to conduct these experiments or what specific aspects of the paper should be tested. The action is implicit and somewhat vague, as the authors need to infer that they should conduct cross-dataset experiments to address the risk. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the risk of methods that exploit relationships between action units, noting that the relationships can differ across datasets. The comment further suggests that cross-dataset experiments are needed to test the generalization of the work, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential risk of methods that exploit relationships between action units, noting that these relationships can differ across datasets. It provides an example by pointing out the co-occurrence of AU1 and AU12 in Figure 1, which demonstrates the difference in correlation across datasets. The comment suggests that cross-dataset experiments are necessary to test the generalization of the work. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the differences in co-occurrences across datasets. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a potential issue with the generalization of such work, as demonstrated by the co-occurrence of AU1 and AU12 in Figure 1. The comment suggests that cross-dataset experiments are necessary to test the generalization of the work. While the comment provides a clear direction for improvement, it lacks specific suggestions on how to conduct these experiments or what aspects of the paper should be tested. This limits the comment\\'s helpfulness, as it points out an important area for improvement but does not offer detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should reconsider their statement about over-parameterization leading to worse performance, as it appears to be beneficial in practice. The reviewer provides a specific reference to a theoretical work that supports the benefits of over-parameterization. However, the comment does not explicitly instruct the authors to revise their statement or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their position. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific lines in the paper, \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being discussed. It also provides a specific critique of the statement about over-parameterization leading to worse performance, suggesting that it is not accurate based on practical experience and theoretical work. The comment references a specific theoretical work, which adds further context and specificity to the critique. However, it does not provide detailed guidance on how to address this issue or improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim about over-parameterization leading to worse performance, suggesting that it is beneficial in practice. The reviewer provides some support by referencing a theoretical work, which is cited as [1]. However, the comment lacks detailed reasoning or specific examples from the theoretical work to fully substantiate the claim. While the reference provides some context, it does not fully address the critique, leaving the authors with a need for more detailed justification or examples to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim about over-parameterization leading to worse performance, suggesting that it is beneficial in practice. The reviewer provides some support by referencing a theoretical work, which could be helpful for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or reframe their argument. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, which is a clear and direct action. Additionally, it asks for clarification on the correspondence between the learning curves and M-PHATE in Figure 3, specifically questioning why the authors want the readers to look at the learning curves and whether worse-performing models always result in structural collapse. The comment also seeks clarification on the accuracy number for the last task or average. These questions provide clear guidance on what the authors need to address to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as explaining the experimental setting for continual learning and clarifying the correspondence between the learning curves and M-PHATE. The comment also raises questions about the accuracy number for the last task or average, which further specifies the areas that need clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the draft. It suggests adding a few more sentences to explain the experimental setting for continual learning, which is a clear and direct improvement. Additionally, it raises specific questions about the correspondence between the learning curves and M-PHATE in Figure 3, prompting the authors to clarify why they want readers to focus on the learning curves and whether worse-performing models always result in structural collapse. The comment also seeks clarification on the accuracy number for the last task or average, which is a helpful point for improving the draft. Overall, the comment is mostly helpful as it provides clear and actionable feedback that can significantly enhance the clarity and comprehensiveness of the paper. However, it could be more helpful if it offered additional guidance or examples to support the authors in addressing these questions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. It also points out that the proposed method without SSL performs inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly adjust the experimental setup to ensure fairness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental comparison with other methods\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the fairness of the experimental comparison, questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. The comment further specifies that the proposed method without SSL performs inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods. It questions whether the proposed method was initialized with the same or similar pre-trained model as the compared methods, and notes that the proposed method without SSL performs inferior to most of the compared methods, as shown in Table 1. While the comment identifies a potential issue with the experimental setup, it lacks specific examples or references to support the claim that the comparison is unfair. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. It points out that the comparison may be unfair if the compared methods were not initialized with the same or similar pre-trained model. The comment also highlights a specific observation from Table 1, where the proposed method without SSL performs inferior to most of the compared methods. This feedback is somewhat helpful as it raises a critical concern about the experimental setup and suggests a potential area for improvement. However, it lacks specific guidance on how the authors should address this issue or improve the experimental comparison. To be more helpful, the comment could provide suggestions on how to ensure fairness in the comparison or how to interpret the results from Table 1. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion and provides a concrete example of what the authors could do to improve their work. However, it does not explicitly instruct the authors to implement this change, leaving a somewhat actionable comment.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 on page 7\" and \"Table 1 in \\\"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016\\\",\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. The comment provides a clear suggestion for improvement and references a specific work, making it highly specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" This provides a clear and concrete basis for the claim, as it offers a specific example of a better approach that could be applied. However, the comment could be strengthened by providing more detailed reasoning or references to further substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better performance. This feedback is actionable and provides a clear direction for the authors to enhance their results. However, the comment could be more helpful if it included additional details or guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include a plot with sparsity on the x-axis and performance on the y-axis to compare the flexibility of SGC with LoRA. This explicit action provides a clear and concrete step for the authors to take, ensuring that they understand exactly what needs to be done to address the issue. The comment is specific about the type of visualization needed and how it could be used to demonstrate the practical benefits of SGC. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Limited Applicability\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending a plot to compare the flexibility of SGC with LoRA. This plot should include sparsity on the x-axis and performance on the y-axis, which would more intuitively demonstrate the practical benefits of SGC. The comment is detailed and provides a specific action for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim about SGC offering a more flexible, fine-grained tradeoff is not fully supported by the limited applicability of PEFT methods. The reviewer suggests that a plot comparing SGC with LoRA would be beneficial to demonstrate the flexibility of SGC. This suggestion is somewhat verifiable as it provides a logical reasoning for why a visualization is needed, but it lacks specific examples or references to support the claim about the limited applicability of PEFT methods. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s claim about the flexibility and performance of SGC. It suggests that the authors include a plot to demonstrate the flexibility of SGC compared to LoRA, which could help illustrate the practical benefits of SGC at different sparsity levels. This feedback is clear and actionable, providing a specific suggestion for improving the paper\\'s presentation and substantiating the claims made. By addressing this point, the authors can enhance the clarity and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the training time difference between the German and Law school dataset and Independent in the experiments. It suggests that the shorter training time for Gerrymandering in the German and Law school dataset is unexpected, given that the main advantage of the Independent dataset is its faster computation time. The reviewer also suggests that it would be beneficial to publish the code to further explore this observation. While the comment implies that the authors should address this issue by providing more information or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or publish the code to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the training time difference between the German and Law school dataset and Independent, suggesting that the shorter training time for Gerrymandering is unexpected given the faster computation time of the Independent dataset. The comment further suggests that publishing the code could be beneficial. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training time difference between the German and Law school dataset and Independent in the experiments. It suggests that the shorter training time for Gerrymandering in the German and Law school dataset is unexpected, given that the main advantage of the Independent dataset is its faster computation time. The comment also suggests that publishing the code could be beneficial. While the comment identifies a potential inconsistency in the results and suggests a possible explanation, it lacks specific examples or references to support the claim about the training time difference. The suggestion to publish the code is logical but not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the training time difference between the German and Law school dataset and Independent in the experiments. It suggests that the shorter training time for Gerrymandering in the German and Law school dataset is unexpected, given that the main advantage of the Independent dataset is its faster computation time. The comment also suggests that publishing the code could be beneficial to further explore this observation. While the comment identifies a potential inconsistency in the results and provides a suggestion for further investigation, it lacks specific guidance or actionable steps for the authors to address this issue. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed instructions or examples on how to proceed. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the human baseline, noting that it only closely follows 1 hour of speech recordings, making it considerably weaker than the model baseline. It also highlights that the abstract statement about beating the human performance is misleading due to the limited human data. While the comment identifies a specific issue with the human baseline, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or clarify the human baseline in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"human baseline\" and the \"1 hour vs. 15 hours\" of speech recordings, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the human baseline, namely that it is considerably weaker due to the limited data, and it points out that the abstract statement about beating the human performance is misleading. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The reviewer supports this claim by pointing out that the human baseline only closely follows 1 hour of speech recordings, while the model baseline is evaluated on 15 hours. The comment also highlights that the abstract statement about beating the human performance is misleading due to the limited human data. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or data where the human baseline is evaluated, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the human baseline, noting that it only closely follows 1 hour of speech recordings rather than the full 15 hours, making it considerably weaker than the model baseline. It also points out that the abstract statement about beating the human performance is misleading due to the limited human data. This feedback is clear and actionable, as it highlights a critical weakness in the human baseline and suggests that the authors should clarify or adjust their evaluation methodology to provide a more accurate comparison. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the evaluation methodology. Overall, the comment is mostly helpful as it provides valuable insights and guidance for the authors to enhance the robustness and accuracy of their evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests clarification on the model used and suggests adding it to the appendix. While the comment implies that the authors should provide examples and clarify the model, it does not explicitly instruct them to do so. The actions are somewhat vague, as the authors need to infer that they should provide examples and clarify the model, but the feedback is concrete enough to guide the authors in making improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"synthetic data\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for examples of \"support data\" and \"predicted training count data,\" clarifies the meaning of \"support data\" and \"predicted training count data,\" and suggests adding the model used to the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and examples, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also seeks clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1. Additionally, it suggests adding the model used to the appendix for further clarity. This feedback is clear and actionable, as it prompts the authors to provide examples and clarify their methodology, which could enhance the transparency and understandability of their work. However, the comment could be more helpful if it provided specific suggestions on how to present the model or examples, which would make it fully comprehensive. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and completeness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, such as expanding the explanation or including additional information in the paper. The explicit nature of the recommendation and the specific suggestions for improvement make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots during the EEG token quantization process. The comment suggests that the authors should elucidate this procedure in greater detail and clarify whether the spatial arrangement of the EEG sensors played a role in the process. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 presents ambiguous EEG topography plots during the EEG token quantization process, which leads to confusion in interpretation. The reviewer suggests that the authors should clarify this procedure in greater detail, specifically by addressing whether the spatial arrangement of the EEG sensors played a role in the process. This claim is somewhat verifiable as it provides a logical reasoning for the need to clarify the procedure, but it lacks specific examples or references to support the ambiguity or the suggested improvements. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of ambiguity in the paper, specifically regarding the interpretation of EEG topography plots in Figure 3. It suggests that the authors should clarify this procedure in greater detail, particularly by addressing whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, providing the authors with a concrete step to improve the clarity and understanding of their work. By addressing this suggestion, the authors can enhance the transparency and comprehensibility of their results, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should make to improve their approach. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' approach to addressing the complexity of checking the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table where this complexity is discussed. The authors can infer that it relates to the discussion of the Witness oracle, but the lack of explicit mention makes it weakly grounded. The comment is specific in detailing the issue with the complexity of checking the Witness oracle, but without full grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not address the problem directly by leveraging the complexity of checking the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the authors\\' approach to addressing the complexity of checking the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. This feedback highlights a potential weakness in the authors\\' methodology, as it suggests that they may not be directly addressing the problem. However, the comment does not provide specific suggestions or guidance on how the authors might improve their approach or what aspects of the complexity should be addressed. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment also offers a specific reference to a relevant work, which further guides the authors on what to include. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (lines 22-30) and discusses the use of moment matching in distributional RL, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on using moment matching instead of quantile regression for distributional RL. This provides clear guidance on what the authors should add to their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This claim is somewhat verifiable as it provides a specific reference to a relevant work, which supports the suggestion that the paper should discuss this approach. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial or relevant to the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks relevant literature, specifically on the use of moment matching instead of quantile regression for distributional RL. It provides a specific reference to a relevant work (Nguyen-Tang et al AAAI\\u002721) that discusses this approach. This feedback is clear and actionable, as it directs the authors to include this discussion in their paper to enhance its comprehensiveness and relevance. By addressing this gap, the authors can improve the depth and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the modelled curves and their relation to tumour growth. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the discussion of modelling curves is not immediately clear and suggests that it relates to tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue in the introduction, specifically noting that the second paragraph discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. This feedback is somewhat helpful as it points out a specific area where the introduction could be improved by providing more clarity. However, the comment lacks depth and does not offer suggestions on how to clarify the content or improve the explanation. To be more helpful, the comment could provide guidance on how to better articulate the modelled curves and their relation to tumour growth. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper only analyzed, under which cases will the Algorithm 1 converges to permutations as local minima,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of the local minima, including the approximation ratio under certain assumptions. This provides clear guidance on what additional analysis is needed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should analyze the quality of local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting an analysis of the quality of local minima, including the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft. By addressing this suggestion, the authors could significantly improve the depth and rigor of their analysis. However, the comment could be more helpful if it included specific examples or references to similar studies that have explored this aspect. Overall, the comment is mostly helpful, as it offers a valuable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and questions the claim about the robustness of Cans largely coming from information redundancy. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or concerns. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification regarding the implementation of information redundancy and the robustness of their design. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms and questions the claim about the robustness of Cans largely coming from information redundancy. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the methods or results sections, but this inference is not direct. The comment is specific in its questioning of the claim, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implementation of information redundancy in the Fill, Propagate, Decode algorithms and the claim about the robustness of Cans largely coming from information redundancy. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms and questions the claim about the robustness of Cans largely coming from information redundancy. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and provide additional context or explanation regarding the role of information redundancy in their design. However, the comment lacks specific suggestions or guidance on how to address these questions or improve the clarity of the paper. While it points out areas for improvement, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include experimental results of excluding the mixup technique from the proposed method in order to demonstrate its pure contribution. This feedback is clear and provides a specific action for the authors to take, ensuring that they know exactly what is expected of them. The comment is concrete, as it specifies the exact experiment to be conducted and the desired outcome, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there should be experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to enhance the clarity and robustness of their experimental results. By addressing this suggestion, the authors can better demonstrate the novelty and significance of their work. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial calibration steps and suggests that an error might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should investigate or address this issue, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about an error in the initial calibration steps that might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about an error in the initial calibration steps that might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the suggestion, making it difficult for the authors to understand or address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about an error in the initial calibration steps that might explain the speed disparities observed between the RSPs and FDs. While it identifies a potential area for investigation, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or investigate further. The comment is incomplete and does not offer actionable feedback, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from. It implies that the authors should clarify this information, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information about the dataset labels, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the labels for each dataset, including \"cas-peal-r1\" and \"mugshot.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from. This is a relevant point as it could help the authors clarify the origin of the dataset labels, which is important for transparency and reproducibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and questions how \u03bb is calculated. It also points out that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but do not fully clarify what this means. The reviewer provides references to related work, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the calculation of \u03bb and the explanation of ELLA\\'s sample efficiency. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (Page 9, lines 310-313 and Page 8 lines 281-285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the calculation of \u03bb and the explanation of ELLA\\'s sample efficiency in a COMBO environment. The references to external works provide additional context and support for the comment. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but do not fully clarify the meaning. The reviewer provides references to related work, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claims, making it somewhat verifiable. The references provide some context but do not fully substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that performance and sample efficiency are sensitive to \u03bb parameters and questioning how \u03bb is calculated. It also points out that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but do not fully clarify the meaning. The reviewer provides references to related work, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it highlights areas for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not provide detailed guidance for addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. It also notes that the algorithm may overestimate the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure2\" and \"WizardOfWor, Zaxxon RoadRunner, and BattleZone,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of lower bound double q-learning, particularly in terms of performance and convergence. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of lower bound double q-learning is doubtful, based on observations from Figure 2 and the convergence of algorithms in other environments. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of \"Clipped DDQN\" and \"overestimate the true maximum value\" adds some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some context but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the effectiveness of the lower bound double q-learning algorithm, specifically noting that it may overestimate the true maximum value and converge to similar solutions in different environments. This feedback is somewhat helpful as it points out a potential weakness in the methodology, which the authors could address by providing additional evidence or analysis to support the algorithm's effectiveness. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending alternative approaches or providing detailed analysis of the results. Therefore, the comment is somewhat helpful, as it provides insight but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN, specifically questioning why the former's performance worsens when lambda becomes small. The reviewer expects the DNN+MMA to approach vanilla methods from above but from below. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance dynamics but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of DNN+MMA compared to vanilla DNN, particularly when lambda becomes small. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance of DNN+MMA compared to vanilla DNN, specifically regarding the behavior of lambda. The reviewer expects the former to approach vanilla methods from above but from below. However, the comment lacks specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the observation. Without additional context or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN, specifically questioning why the former's performance worsens when lambda becomes small. The reviewer expects the DNN+MMA to approach vanilla methods from above but from below. This feedback identifies a potential issue in the paper\\'s explanation or results, prompting the authors to clarify or address this discrepancy. However, the comment lacks specific suggestions or guidance on how to resolve this issue, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper by noting that it does not compare the results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so in the author response. The reviewer suggests that the authors should compare their results with \"Those systems are not state-of-the-art\" and provides an example of a system from 2016 that performed worse. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the comparison or which specific systems to compare with. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with earlier research work and the need to compare results with systems that performed worse. This provides clear guidance on what the authors need to improve. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer supports this claim by referencing the authors\\' response, which mentions that those systems are not state-of-the-art. Additionally, the comment provides an example of a system from 2016 that performed worse, suggesting that the comparison could be made with these systems. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting that it does not compare the results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer provides a specific example of a system from 2016 that performed worse, suggesting that the comparison could be made with these systems. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their paper that could enhance its credibility and comprehensiveness. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific systems to compare with. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides a direction for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors elaborate on the Hoeffding's bound and its implications for stochastic algorithms. While it implies that the authors should provide more detail or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 124-125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding's bound and its implications for stochastic algorithms. The comment provides a clear direction for improvement by suggesting that the authors elaborate on this topic. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Hoeffding's bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate, further guaranteeing the Hoeffding inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where the authors could provide more detail or elaboration. It points out that the Hoeffding's bound and its implications for stochastic algorithms are not fully explained, suggesting that the authors should elaborate on this topic. While the comment highlights an important aspect of the paper that could be expanded, it lacks specific suggestions or guidance on how to improve the explanation or what additional information should be included. This limits the comment\\'s helpfulness, as it provides a general direction for improvement but does not offer actionable steps. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include these models in their comparison, but it lacks concrete instructions on how to do so or what specific aspects to consider. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what is missing in the comparison, namely the inclusion of these models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by including these models in the comparison. However, the comment could be more helpful if it provided suggestions on how to incorporate these models or what aspects to consider when comparing them. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts: a request for sensitivity testing with hyper-parameters and minor comments on language usage. The first part explicitly asks for sensitivity testing, providing a specific area to focus on. However, it does not specify which hyper-parameters should be tested or how to conduct the tests. The second part consists of minor comments on language usage, which are not actionable as they do not provide guidance on how to improve the language. Overall, the comment is somewhat actionable as it identifies a specific area for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. However, the comment lacks specificity regarding the sensitivity testing requested, as it does not detail what specific hyper-parameters should be tested or how to conduct the tests. Therefore, this comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of two parts: a request for sensitivity testing with hyper-parameters and minor comments on language usage. The first part requests sensitivity testing, but it does not provide any reasoning or evidence to support why this is necessary or how it would improve the paper. The second part consists of minor comments on language usage, such as \"we typically considers\" and \"two permutation,\" which are not particularly relevant to the main argument or contribution of the paper. The lack of supporting evidence or reasoning makes it difficult for the authors to understand the importance of these comments. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment consists of two parts: a request for sensitivity testing with hyper-parameters and minor comments on language usage. The first part is somewhat helpful as it identifies a specific area for improvement by requesting sensitivity testing with hyper-parameters. However, it lacks detail on which hyper-parameters should be tested or how to conduct the tests, leaving the authors with a general suggestion. The second part consists of minor comments on language usage, which are not actionable and do not provide specific guidance on how to improve the language. Overall, the comment provides some direction but lacks depth and actionable steps, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, specifically noting that it is restricted to only three Question-Answering tasks and two language models. It also raises concerns about the method's applicability to other reasoning or generation tasks or more advanced models. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or broaden the scope of their framework. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the scope of their framework. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluative framework\" and the specific limitations in its scope, such as being restricted to three Question-Answering tasks and two language models. It also raises concerns about the method's broader applicability and potential to generalize to other reasoning or generation tasks or more advanced models. This provides clear guidance on what aspects of the framework need attention. The comment is specific in detailing the limitations and potential areas for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, restricted to only three Question-Answering tasks and two language models, and questions its broader applicability. The comment provides some justification by mentioning the potential for the method to generalize to other reasoning or generation tasks or more advanced models, such as vicunna or alpaca. However, the comment lacks specific examples or references to support the claim that the framework's applicability is limited. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This feedback highlights a potential limitation in the method's broader applicability, as it does not address other reasoning or generation tasks or more advanced models. The comment raises a subject of inquiry regarding the method's generalizability, which is valuable for the authors to consider. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might expand the scope of their framework. Overall, the comment is somewhat helpful as it points out a potential limitation but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are not sufficient and suggests that more empirical experiments or toy experiments are needed to show the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or referencing relevant works. The explicit nature of the suggestions and the detailed guidance on what needs to be done makes this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simplified self-attention model\" and \"theoretical analysis,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also references the need to cite the result in Kaplan et al. 2020, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are not sufficient and suggests the need for more empirical experiments or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references the result in Kaplan et al. 2020 as a potential source of validation. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential area for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, namely that the experiments are not sufficient to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this issue. Additionally, it references the result in Kaplan et al. 2020 as a potential source of validation. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to design and conduct these additional experiments. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a reference for further exploration, but it lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests presenting the performance as a function of the distance of initialization, M^0, to the ground-truth, M^*. It proposes a method of randomly sampling a matrix M^0 within a specified distance range, and then reporting the performance accordingly. This feedback provides a clear and concrete action for the authors to take, as it specifies a specific method for evaluating the performance of the initialization. The authors know exactly what steps to follow to implement this suggestion, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests presenting the performance as a function of the distance of initialization, M^0, to the ground-truth, M^*. It provides a specific suggestion for how to evaluate the performance, by proposing a method of randomly sampling a matrix M^0 within a specified distance range and reporting the performance accordingly. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests presenting the performance as a function of the distance of initialization, M^0, to the ground-truth, M^*. It provides a specific method for evaluating the performance by proposing a random sampling approach. This suggestion is supported by a logical reasoning and a clear explanation of how the performance would be affected by the distance of initialization. However, the comment could be strengthened by providing examples or references to similar studies that have used this approach. Overall, the claim is mostly verifiable, as it provides a clear and actionable suggestion for improving the paper.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of results. It suggests presenting the performance as a function of the distance of initialization, M^0, to the ground-truth, M^*, by proposing a method of randomly sampling a matrix M^0 within a specified distance range and reporting the performance accordingly. This feedback is clear and constructive, as it offers a concrete way for the authors to evaluate the performance of their initialization method. By following this suggestion, the authors can enhance the clarity and comprehensiveness of their results, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, namely to remove the absolute value operation. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or removed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides the authors with a direct and specific correction to make in their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it included a rationale or explanation for why the absolute value operation is unnecessary, which would further empower the authors to understand and address the issue. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use DinoV2 Frechet Distances in addition to the widely used FID metric for evaluating their work. This explicit suggestion provides a clear action for the authors to take, ensuring that they consider an alternative metric for their evaluations. The comment is concrete, as it specifies the additional metric to use and provides a rationale for its use. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for evaluations. However, it does not specify which part of the paper discusses the use of FIDs or the Inception network. The authors can infer that it relates to the evaluation section, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the use of DinoV2 Frechet Distances, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is not accompanied by an explanation of why this alternative metric is preferable or how it addresses the flaws mentioned. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for evaluations. This feedback is somewhat helpful as it provides a specific suggestion for improving the evaluation methodology by introducing an alternative metric. However, the comment lacks depth and does not explain why DinoV2 Frechet Distances are preferable or how they might address the flaws associated with FIDs and the Inception network. To be more helpful, the comment could provide a rationale or comparison between the two metrics, which would guide the authors in making a more informed decision. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not accurate. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors on how to implement this suggestion, such as by providing specific guidance on which visualization to use or how to label the y-axis. The action is concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests a more accurate visualization using a second y-axis or another method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not accurate. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. However, the comment lacks specific reasoning or examples to support why Figure 6C is awkward or why the current representation is inaccurate. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not accurate. The reviewer suggests a solution by recommending the use of a second y-axis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete direction to improve the accuracy of their visual representation. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a questionable statement in the supplemental section D.4, specifically regarding the claim that smaller architectures are necessary for LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample from their own experience, suggesting that larger models can be trained effectively. The comment also raises a question about the application of dropout to both embeddings and hidden states. While the comment identifies a potential issue and questions the claim, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should reevaluate the claim and potentially revise their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in the supplemental section, providing a counterexample and suggesting that the baseline models may not be properly regularized. The comment also raises a question about the application of dropout to both embeddings and hidden states, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a specific claim made in the supplemental section D.4, specifically regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample from their own experience, suggesting that larger models can be trained effectively. This provides a logical basis for the claim, as it challenges the validity of the original statement. However, the comment could be strengthened by providing more detailed examples or references to support the counterexample. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim in the supplemental section D.4 that the reviewer finds questionable, suggesting that the statement is not accurate based on their own experience. The reviewer provides a counterexample from a well-known work, Zaremba et al. (2014), which trained 1500-dimensional LSTMs on PTB, challenging the claim that smaller architectures are necessary for LM compared to GAN models to avoid overfitting. Additionally, the comment raises a question about the application of dropout to both embeddings and hidden states, which could be an area for further exploration or clarification. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. Therefore, the comment is somewhat helpful, as it points out a potential problem but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-though. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their draft or what specific changes they should make to address this comparison. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment compares the contribution of multilingual chain-of-thought to the villa chain-of-though, but it does not specify which part of the paper this comparison is made in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in its comparison, but without explicit references or detailed guidance, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-though. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand or address the claim effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment compares the contribution of multilingual chain-of-thought to the villa chain-of-though, suggesting that the former is incremental. However, it does not provide any specific insights or suggestions for improvement, nor does it offer guidance on how the authors might address this comparison or enhance their contribution. Without actionable feedback or detailed analysis, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern regarding the comparability of G-effect values across various unlearning objectives and approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should consider the implications of studying G-effects in isolation, but it lacks concrete steps or recommendations for improvement. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of G-effect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across various unlearning objectives and approaches. It does not present any claims or opinions but rather expresses a concern based on the methodology described in the paper. Therefore, it is classified as \"No\" because it does not contain any subjective elements that require verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the comparability of G-effect values across various unlearning objectives and approaches. It points out that studying these effects in isolation could lead to misleading conclusions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it highlights an important consideration, the feedback is incomplete and does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the consistency of the advantages of UNIFORM over other procedures, particularly in the 1-shot setting. It suggests that the authors should clarify their theory for why the method is not as effective in this setting. The comment also appreciates the clarity and well-designed experiments, but it does not provide specific guidance on how to address the issue with the 1-shot setting. While the action is implicit, it is clear that the authors need to provide a theoretical explanation or further experiments to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"UNIFORM\" and \"the 1-shot setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the consistency of UNIFORM's advantages over other procedures, particularly in the 1-shot setting, and suggests that the authors should clarify their theory for why the method is not as effective in this setting. The comment also appreciates the clarity and well-designed experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the consistency of the advantages of UNIFORM over other procedures, particularly in the 1-shot setting. It suggests that the authors should clarify their theory for why the method is not as effective in this setting. The comment also appreciates the clarity and well-designed experiments, which provides some context for the claim. However, the comment lacks specific examples or references to support the claim about the consistency of UNIFORM's advantages. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the consistency of the advantages of UNIFORM over other procedures, particularly in the 1-shot setting. It raises a question about the authors\\' theory for why the method is not as effective in this setting. This feedback is valuable as it prompts the authors to consider the robustness of their method and its limitations, which could lead to further exploration and potential improvements. Additionally, the comment acknowledges the clarity and well-designed experiments, providing constructive feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue or clarify their theory. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides some guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason why information value is considered a stronger predictor for dialogue, suggesting that the authors should consider existing linguistic theories that might explain this phenomenon. The reviewer implies that adding this information could enhance the paper\\'s strength. While the comment implies that the authors should explore this topic, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this area further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it raises a question about the reason why information value is considered a stronger predictor for dialogue and suggests exploring existing linguistic theories to explain this phenomenon. This provides clear guidance on what the authors should consider adding to their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reasoning behind the claim that information value is a stronger predictor for dialogue. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reasoning behind the claim that information value is a stronger predictor for dialogue, suggesting that the authors should consider existing linguistic theories to explain this phenomenon. By asking for clarification and suggesting an expansion of the paper, the comment provides a clear and actionable direction for the authors to enhance their draft. However, it could be more helpful if it offered specific examples of existing theories or provided guidance on how to integrate this information into the paper. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by revising their draft to ensure consistency in the presentation of their work. The comment provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the definition of T_a(t) and suggests that it should be defined earlier in the paper. This provides clear guidance on what needs to be addressed to improve the consistency of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly related to the structure and organization of the paper. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the definition of T_a(t), which is used in Section 3.1 but only defined in Section 4. This feedback is clear and actionable, as it points out a specific inconsistency that the authors need to address to maintain consistency in their presentation. By addressing this issue, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve this inconsistency, such as suggesting a reorganization of the sections or offering guidance on how to present the definition earlier. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also suggests that the authors explain why these adjustments enhance the model's performance. While the comment provides a clear direction for improvement, it does not specify how the authors should provide this clarification or what specific details should be included. The action is explicit but somewhat vague, as it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the empirical analysis and the adjustments made to the input series and forecasting target based on the Frequency Stability score. The comment also requests additional clarification on the effectiveness of these adjustments and suggests specific references to similar work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment is somewhat verifiable as it provides a logical basis for the concern, but it lacks specific examples or references to support the claim. The authors would need to provide more detailed explanations to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity of the empirical analysis in Figure 3, particularly regarding the adjustments made to the input series and forecasting target based on the Frequency Stability score. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which could be improved. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a clear direction for enhancing the clarity and coherence of their work, but the feedback could be more comprehensive with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. This is a clear and direct action for the authors to take, as it provides a specific recommendation for inclusion in the experiments. The comment also provides a rationale for why this comparison is necessary, making it easy for the authors to understand and implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CoCoOp,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of CoCoOp in the experiments. This provides clear guidance on what the authors should include in their analysis. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work, CoCoOp, should be compared in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper\\'s contribution. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the recent related work, CoCoOp, has not been compared in the experiments. This is a clear and actionable feedback that highlights a gap in the experimental analysis, suggesting that the authors should include a comparison with CoCoOp to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it would contribute to the paper\\'s contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to make these changes or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to Fig. 1, specifically regarding the processing pipeline, which includes prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. However, it does not specify which part of the figure or the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what needs to be improved, such as the inclusion of ground truth scores and model training optimization. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. However, the comment lacks specific examples or references to support the claim that these additions would improve the figure. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient justification or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests improvements to Fig. 1 by providing more detailed information about the processing pipeline, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. This feedback is clear and actionable, as it specifies specific areas that could be enhanced to better illustrate the processing pipeline. However, the comment could be more helpful if it provided examples or detailed guidance on how to implement these improvements. Overall, the comment is mostly helpful as it directs the authors to enhance the clarity and comprehensiveness of their figure, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This feedback is clear and provides a direct action for the authors to take, ensuring that the comment is highly actionable. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors should change to improve the clarity of their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that abbreviations like \"MoCo\" should not appear in section headers, as readers might not know what it means. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that readers might not understand the abbreviation. The comment could be strengthened by providing more context or examples to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations like \"MoCo\" in section headers. It suggests that these abbreviations might not be familiar to readers, which could lead to confusion. This feedback is clear and actionable, as it provides the authors with a concrete suggestion to improve the clarity of their paper by removing such abbreviations from section headers. However, the comment could be more helpful if it offered additional guidance on how to address this issue, such as suggesting alternative ways to present the abbreviations or explaining why they are important. Overall, the comment is mostly helpful, as it provides a valuable insight that the authors can use to enhance the readability and accessibility of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any explicit or implicit actions for the authors to take to clarify the technical contribution or suggest improvements. There is no guidance on how to enhance the analysis or what specific aspects should be addressed to make the contribution clearer. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The lack of grounding and specificity makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or justification, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide specific feedback or guidance on how the authors might clarify the technical contribution or enhance the analysis. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be considered substantial or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, it does not specify which part of the paper discusses the TACTiS approach or how the authors can provide more substantial evidence or arguments. Without explicit references to sections or specific examples, the authors cannot confidently determine which parts of the paper need improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contribution, suggesting that the primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach. However, it does not provide specific guidance or suggestions on how the authors might substantiate this claim or what additional evidence or arguments would be needed to establish it as a significant contribution. While the comment highlights a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer detailed guidance on how to address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are needed to explain why the number of parameters does not change. While the comment identifies a potential issue with the explanation, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to provide more details, but the comment lacks specific suggestions on what aspects of the explanation are unclear or how to improve it. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the S2D structure and its parameters, specifically questioning why the number of parameters does not change despite an increase in depth. It suggests that more details are needed to explain this aspect. However, the comment does not specify which part of the paper discusses the S2D structure or the parameters, making it weakly grounded. The authors can infer that it relates to the structure or parameters mentioned in the context of the S2D structure, but this inference is not direct. The comment is specific in its request for more details on the parameters, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the number of parameters in the S2D structure and suggests that more details are needed to explain why the number does not change. The reviewer provides a logical reasoning by pointing out that an increase in depth would result in more parameters, but this reasoning is not fully developed or substantiated with specific examples or references. The comment identifies a potential area for improvement but lacks detailed justification or evidence to support the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the explanation of the S2D structure, specifically questioning why the number of parameters does not change despite an increase in depth. It acknowledges that the efficiency could be improved, but suggests that more details are needed to clarify this aspect. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or provide additional details. The feedback is somewhat helpful as it points out a gap in the explanation but does not offer actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should reiterate the reasons why the GPC (benchmark) is performing better than BPC (their method). It provides a specific action for the authors to take, which is to clarify the reasons behind the performance difference. The comment is clear and provides concrete guidance on how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (their method). The comment provides a clear direction for improvement by suggesting that the authors should reiterate the reasons behind the performance difference, which is a specific and actionable suggestion. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study does not provide a favorable comparison between the GPC (benchmark) and BPC (the authors\\' method). It suggests that the authors should reiterate the reasons for the GPC\\'s superior performance, specifically attributing it to the bandit feedback and not using information about the form of the cost function. The comment provides a logical reasoning for the claim, suggesting that the authors should clarify the basis for the performance difference. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact reasons for the performance difference themselves, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate the reasons behind this performance difference, specifically attributing it to the bandit feedback and not using information about the form of the cost function. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft by clarifying the basis for the performance difference. However, the comment could be more helpful if it offered additional suggestions or examples on how to effectively communicate this information. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors to quantify or clarify the claim, nor does it provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should quantify and clarify the claim, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. However, the comment does not specify which part of the paper this claim is made in, nor does it provide detailed guidance on how to quantify or clarify the claim. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed, and it is not specific in terms of what needs to be clarified or quantified. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. The reviewer references the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. This reference provides some context for the claim but does not offer specific examples or detailed reasoning to fully substantiate the claim. The comment is somewhat verifiable, as it suggests a potential area for improvement but lacks detailed evidence or examples to fully support the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolutional layers. This reference provides some context for the claim, but the comment does not offer specific guidance on how to quantify or clarify the claim. While it identifies a potential area for improvement, the lack of detailed suggestions or actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between high perplexity and better BLEU scores. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to provide more information about the perplexity calculation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the reported perplexities being over 30, which contradicts better BLEU scores, and questions how perplexity was calculated. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reported perplexities in Figure 1, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. The reviewer provides a personal experience as a basis for their observation, but lacks specific references or detailed reasoning to support the claim that high perplexity contradicts better BLEU scores. While the comment raises a valid point, it could be strengthened by providing more detailed evidence or examples to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It suggests that this high perplexity contradicts better BLEU scores, which is an important observation that could impact the interpretation of the results. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or clarify their methodology. Providing more detailed feedback on how to reconcile the discrepancy between perplexity and BLEU scores would make the comment more helpful. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 95-97 and 308-310. While the comment implies that the authors should elaborate on the smoothness of neural models and its impact on consistency, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide more explanations regarding the consistency between training and inference, specifically mentioning lines 95-97 and 308-310. However, it does not specify which parts of the paper these lines are located in, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its suggestion for additional explanations but lacks grounding as it does not provide exact references to the lines in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanations regarding the consistency between training and inference, specifically mentioning lines 95-97 and 308-310. However, the comment does not provide any reasoning, evidence, or examples to support why these lines are problematic or where the explanations are lacking. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference. It highlights specific lines in the paper where this issue is discussed and suggests that additional explanations are needed. While the comment provides a clear direction for improvement, it lacks depth and does not offer specific suggestions or examples of what additional explanations could be included. This limits the comment\\'s helpfulness, as it provides a general direction but does not fully guide the authors on how to address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should consider adding this information, it does not provide specific guidance on how to incorporate these elements into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and discussions, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be beneficial to include failure cases and related discussions. However, it does not specify which part of the paper should include these elements, such as a particular section or aspect. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what needs to be added, but without explicit references or detailed guidance, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include failure cases and related discussions. However, it does not provide any reasoning, evidence, or examples to support why this addition would be valuable or necessary. Without specific justification or references, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be beneficial to include failure cases and related discussions. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to incorporate these elements into the paper. The feedback is somewhat helpful as it points out a potential enhancement, but it does not offer detailed suggestions or examples on how to effectively integrate these elements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed for clarity. This feedback provides a clear and concrete action for the authors to take, specifying exactly where the issue is and how to address it. The authors know exactly what needs to be done to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed for clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \\u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \\u03b4 when (11) is discussed for clarity. This claim is somewhat verifiable as it provides a specific observation about the inconsistent use of \\u03b4 in equations, which could be considered a logical point for clarification. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that \\u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \\u03b4 when (11) is discussed for clarity. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the clarity of their equations. By addressing this issue, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it included additional context or examples to further explain the importance of introducing \\u03b4. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"counting homomorphisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for explicit bounds of counting and potential elaboration on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms. It suggests that the paper should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. However, the comment lacks specific examples or references to support the claim that the current discussion is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper, namely by discussing the computational complexity of counting homomorphisms. It points out that the current discussion is brief and lacks explicit bounds or elaboration on empirical runtimes. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft. By addressing this issue, the authors can improve the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it offered suggestions on how to present these bounds or elaborated on the potential impact of the computational complexity. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific errors in the text: a missing character in \"we fixed the form of\" and an extra period in a sentence. These are explicit corrections that the authors can directly address. Additionally, the reviewer raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question provides a clear direction for the authors to consider, but it does not offer specific guidance on how to address the issue. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the missing \"g\" in \"we fixed the form of\" and the extra period in a sentence. Additionally, it raises a question about the baseline MCL with deep learning, which is relevant but not directly related to the identified errors. This adds some level of specificity to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims: a correction regarding a missing character in a sentence and a question about the baseline MCL with deep learning. The first claim is verifiable as it provides a specific example of a typographical error, which is clearly stated and easy to correct. The second claim is somewhat verifiable as it raises a question about the methodology, but it lacks specific examples or detailed reasoning to fully substantiate the concern about the ensemble performance. Therefore, the comment is mostly verifiable, as it provides some evidence but could be strengthened with additional context or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific errors in the text, such as a missing character in \"we fixed the form of\" and an extra period in a sentence. This level of detail allows the authors to make precise corrections to their draft. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This is a relevant and insightful question that could prompt the authors to consider their methodology and potential sources of variability. However, the comment could be more helpful if it provided additional guidance or examples on how to address this concern. Overall, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a mathematical error in Theorem A.3 proof, specifically regarding the input x having two indices when it is a vector. It also points out a potential mistake in the equation involving the sum of k(Wk(2))^2. The comment implies that the authors should clarify this error and correct the equation. While the action is implicit, it is concrete because it specifies the exact issue that needs to be addressed and provides a clear direction for the authors to make the necessary corrections. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a mathematical error regarding the input x having two indices when it is a vector, and it questions the equation involving the sum of k(Wk(2))^2. This provides clear guidance on what needs to be corrected in the proof. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions about the mathematical content of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific mathematical error in the proof of Theorem A.3, pointing out that the input x is a vector and not a matrix, and that the equation involving the sum of k(Wk(2))^2 should be corrected to \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it provides the authors with precise guidance on how to correct a mistake in their mathematical derivation. By addressing this issue, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it offered additional context or explanation about why this error occurred or how it affects the overall understanding of the theorem. Overall, the comment is mostly helpful as it directs the authors to a specific area needing correction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in achieving high accuracy. It suggests that the authors should address this concern by explaining how they ensure that the plugged-in entities and relationships are correct, especially when no ground truth is available. While the comment implies that the authors should provide more detailed information about their methodology, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description, questioning the effectiveness of beam search in achieving high accuracy. The comment suggests that the authors should address this concern by explaining how they ensure that the plugged-in entities and relationships are correct, especially when no ground truth is available. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description of beam search, questioning the effectiveness of this method. The reviewer suggests that even with beam search, only 77% of the result lists contain the ground truth logical forms, and asks how the authors ensure that the plugged-in entities/relationships are correct. The comment is somewhat verifiable as it provides a specific example of the issue (77% accuracy) and raises a logical question about the method's effectiveness. However, it lacks detailed evidence or references to support the claim that beam search is ineffective. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the use of terms like \"somewhat\" and \"good generative ability\" in the description of beam search, questioning the effectiveness of this method. It raises a valid point about the low accuracy of beam search, noting that only 77% of the result lists contain the ground truth logical forms. The comment also questions how the authors ensure that the plugged-in entities and relationships are correct, especially when no ground truth is available. This feedback is clear and actionable, as it prompts the authors to address the limitations of their methodology and provide more detailed explanations of their approach. However, the comment could be more helpful if it offered suggestions on how to improve the method or provided examples of alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional improvements or specific areas that need attention. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of FedPCL and its reliance on pre-trained models, specifically mentioning Table 4. This provides some grounding as it allows the authors to identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspects of the performance are problematic or how the authors addressed these issues. It does not provide specific suggestions for improvement or examples of how the framework could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance of FedPCL is sensitive to the selection of pre-trained models, which limits its applicability to a wide range of areas. The comment supports this claim by referencing Table 4, which shows the model accuracy being affected by different pre-trained models. However, the comment does not provide further details or examples of how this limitation affects the performance or applicability of FedPCL. While the reference to Table 4 provides some evidence, the comment could be strengthened by offering more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models. However, the comment does not provide specific feedback or suggestions on how the authors could further improve their work or address the limitations mentioned. It lacks actionable guidance or detailed insights into potential enhancements, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is barely helpful, as it identifies a limitation but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several suggestions for improving the paper. It recommends separating the introduction of two types of attention for deep VAEs into a separate section, which would help clarify the main contributions. Additionally, it suggests describing the generative and inference models after introducing the attention mechanisms. The comment also recommends organizing tricks like normalization or feature scaling into a separate section. While these suggestions are explicit and provide concrete actions, they could be more detailed in terms of how to implement these changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the paper, such as separating the introduction of two types of attention for deep VAEs into a separate section and describing the generative and inference models after introducing the attention mechanisms. It also suggests organizing tricks like normalization or feature scaling into a separate section. While the comment does not explicitly mention specific sections, it provides clear guidance on where these changes should be made, making it fully grounded. The suggestions are specific, providing clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several suggestions and comments that are primarily focused on improving the organization and clarity of the paper. It does not contain any subjective opinions, judgments, or claims that require verification. The suggestions are factual and provide clear guidance for improvement, making the comment purely descriptive and not requiring verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It recommends separating the introduction of two types of attention for deep VAEs into a separate section, which would help clarify the main contributions of the paper. This suggestion is specific and offers a clear action for the authors to take. Additionally, the comment suggests describing the generative and inference models after introducing the attention mechanisms, which would improve the organization and flow of the paper. The comment also recommends organizing tricks like normalization or feature scaling into a separate section, which would help maintain consistency and clarity. These suggestions are clear and actionable, providing the authors with a concrete path to enhance the clarity and organization of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to honestly represent a graph with repeated vertex or edge labels. While the comment provides a clear rationale for the change, it does not explicitly instruct the authors on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should change \"X\" to a multiset. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current representation of \"X\" as a set and suggests that it should be a multiset to accurately represent graphs with repeated vertex or edge labels. This provides clear guidance on what needs to be addressed in this section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that \"X\" should be a multiset instead of a set in Section 4, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning for the change, explaining why the current representation is insufficient. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the necessity of the change themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the representation of \"X\" in Section 4, suggesting that it should be a multiset instead of a set. The reviewer provides a clear and logical reasoning for this change, explaining that including the multiplicities of the labels in the graph is necessary to accurately represent a graph with repeated vertex or edge labels. This feedback is actionable and provides the authors with a clear direction for improving their draft. However, the comment could be more helpful if it included specific examples or references to support the reasoning. Overall, the comment is mostly helpful, as it effectively guides the authors on how to enhance the accuracy of their representation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the organization and clarity of the paper, noting that the writing could be improved and suggesting the addition of a table to compare different CoT prompting methods across different dimensions. It also raises questions about the selection criteria in section 4.2, specifically questioning why certain criteria were chosen and why questions with more than 60 tokens and rationales with more than 5 reasoning steps were excluded. While the comment provides explicit actions (adding a table and clarifying the selection criteria), it lacks detailed guidance on how to implement these improvements. The authors are given a clear direction but may need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"writing\" and \"content,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the writing, suggesting improvements like adding a table to compare different CoT prompting methods across different dimensions and questioning the selection criteria in section 4.2. The comment also raises specific questions about the assumptions made and the criteria used, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions, each of which requires some level of justification or evidence to be considered verifiable. The first claim is that the paper is well-organized, which is a subjective opinion that lacks specific reasoning or examples. The second claim suggests that the writing could be improved, but it does not provide detailed guidance on how to improve it. The third claim questions the selection criteria in section 4.2, suggesting that the criteria are not clear and providing a specific example of why certain questions and rationales were excluded. This part of the comment is somewhat verifiable as it raises a valid point but lacks detailed justification or examples. Overall, the review point contains multiple claims without sufficient evidence or reasoning to fully substantiate them, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides multiple pieces of feedback that can help the authors improve their draft. First, it acknowledges that the paper is well-organized and the writing is good, which is a positive observation. However, it also identifies areas for improvement, such as suggesting the addition of a table to compare different CoT prompting methods across different dimensions. This is a specific and actionable suggestion that can help the authors enhance the clarity and comprehensiveness of their work. Additionally, the comment raises questions about the selection criteria in section 4.2, specifically questioning why certain criteria were chosen and why questions with more than 60 tokens and rationales with more than 5 reasoning steps were excluded. This feedback is also specific and provides a clear direction for the authors to address. Overall, the comment is mostly helpful as it identifies areas for improvement and offers actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by readers and recommends that it be fixed before publication. The reviewer also acknowledges that official NIPS reviewers are not required to review supplementary material, due to time constraints, and expresses concern about the lack of sufficient peer review. While the comment identifies a specific issue and provides a clear action for the authors to take, it does not offer detailed guidance on how to address the omission or improve the draft. The action is explicit but somewhat vague, as the authors need to determine the exact changes required to rectify the issue. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of explaining that the results are for unsupervised random forests. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by readers. The reviewer suggests that this is a serious issue that needs to be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant issue. While the reviewer acknowledges the time constraints of the review process, the lack of detailed justification for the claim makes it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, which is not fully supported by the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This is a critical issue that could lead to incorrect conclusions by readers. The reviewer suggests that this omission must be fixed before publication, providing a clear and actionable piece of feedback. However, the comment could be more helpful if it offered suggestions on how to effectively communicate this information in the paper or provided examples of how similar omissions have been addressed in other works. Despite this, the comment is mostly helpful as it highlights a significant oversight and directs the authors to make a crucial correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness, but no significance testing is conducted to substantiate this claim. The comment implies that the authors should conduct significance testing to support their claims, but it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct significance testing but may not be entirely sure how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim about the significance of the differences between methods, pointing out that no significance testing is conducted and suggesting that the authors should conduct such testing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. The reviewer provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer questions the significance of these claims without proper testing, suggesting that the authors should conduct significance testing to substantiate their claims. This feedback is mostly verifiable as it provides a clear example and logical reasoning for the claim, but it could be strengthened by referencing specific statistical tests or methods for conducting significance testing. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness, but no significance testing is conducted to substantiate this claim. The comment highlights the importance of conducting significance testing to support such claims, which is a crucial aspect of scientific research. By pointing out this gap in the paper, the comment offers a clear and actionable suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to conduct significance testing or suggested specific statistical tests to use. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for English-centric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the baselines presented. Additionally, it suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also critiques the authors for focusing solely on English-centric datasets, implying that they should extend their work to other languages. The comment provides some reasoning by pointing out the limitations of the current study and suggesting a potential direction for future work. However, it lacks specific examples or references to support the claim about the difficulty of comprehending Figure 5, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the two baselines presented in the figure are needed. It also critiques the authors for focusing solely on English-centric datasets, suggesting that they should extend their work to other languages. This feedback is clear and actionable, as it provides a concrete direction for improvement by recommending the inclusion of more detailed information about the baselines and the expansion of the study to other languages. However, the comment could be more helpful if it offered specific suggestions on how to present the additional details or which aspects of the baselines should be highlighted. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should improve the literature review, it does not specify how to do so or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the literature review but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the lack of clarity in the main contribution and distinction from existing work. The comment provides guidance on how to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review is unclear, specifically regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the specific areas that need clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the literature review, specifically noting that it is unclear about the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a crucial aspect of any literature review. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their literature review. However, it could be more helpful if it provided specific examples or suggestions on how to improve the analysis. Overall, the comment is mostly helpful as it effectively guides the authors on how to strengthen their literature review.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative sections to include or how to integrate the information elsewhere. The comment lacks specific guidance on how to address the suggestion, leaving the authors uncertain about what steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or how it relates to the distribution. Without explicit references to specific sections or paragraphs, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the section are problematic or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, the comment does not provide any reasoning, evidence, or examples to support why this section is unnecessary or how it relates to the distribution. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide any reasoning or justification for why this section is unnecessary or how it might detract from the paper. The comment lacks depth and does not offer any constructive feedback or suggestions for improvement, making it barely helpful. The authors are left without actionable guidance on how to enhance their draft, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning \"\\\\$\\\\ell_{BCE}\\\\$.\" This feedback is clear and concrete, as it directly tells the authors what information is missing and how to address it. The action is specific, as it specifies the exact details that need to be included, such as the formula's definition or specific examples. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula \"\\\\$\\\\ell_{BCE}\\\\$,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing more details about the formula in the text. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula in the text, specifically mentioning \"\\\\$\\\\ell_{BCE}\\\\$.\" However, the comment does not provide any reasoning, examples, or references to support why this detail is important or how it would enhance the clarity of the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It highlights the need for more details about the formula in the text, particularly mentioning \"\\\\$\\\\ell_{BCE}\\\\$.\" This feedback is clear and direct, guiding the authors on how to enhance the clarity and comprehensibility of their work. By addressing this point, the authors can ensure that their readers understand the mathematical basis of their methodology more effectively. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides explicit actions to take, such as labeling the subfigures and making the link between IP and terms more prominent, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the link between IP and the terms/equations and the inclusion of labels for subfigures in Figures 3 and 4. This provides clear guidance on how to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support why this explanation is necessary or how it could be improved. Additionally, the comment requests the inclusion of labels for subfigures in Figures 3 and 4, but it does not explain why this is necessary or how it would enhance the clarity of the figures. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations should be explained more explicitly and prominently. It also provides a clear and actionable suggestion by requesting the inclusion of labels for subfigures in Figures 3 and 4, rather than just mentioning them in the captions. This feedback is valuable as it directs the authors to enhance the clarity and accessibility of their figures, which can improve the overall understanding and impact of their work. However, the comment could be more helpful if it included additional context or examples on how to effectively explain the link between IP and the terms/equations. Overall, the comment is mostly helpful as it provides clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct ablation experiments to validate the model performance, specifically mentioning the modifications mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments to validate the model performance. The comment also specifies the section where the modifications are discussed, making it concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation experiments to validate the model performance, specifically mentioning the modifications mentioned in Section 3.4. This provides a clear reference to the part of the paper being addressed, making it fully grounded. The comment is also specific in detailing what needs to be addressed, namely the need for ablation experiments to validate the model performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting ablation experiments to validate the model performance, specifically mentioning the modifications mentioned in Section 3.4. This claim is somewhat verifiable as it provides a logical reasoning for conducting these experiments, which is to validate the model performance. However, the comment lacks specific examples or references to support the claim, such as which modifications are most relevant for ablation experiments or how they might impact the model performance. This makes the claim somewhat verifiable, as it provides a clear direction but requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting ablation experiments to validate the model performance, specifically mentioning the modifications mentioned in Section 3.4. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments to validate the model performance. By suggesting ablation experiments, the reviewer highlights an area where the authors could enhance the robustness and reliability of their results. However, the comment could be more helpful if it included suggestions on which modifications to focus on or how to design these experiments. Overall, the comment is mostly helpful as it provides a clear and constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, namely that Appendix A is left blank and the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. Additionally, the authors\\' so-called \u201cproof\u201d is missing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it points out areas that need improvement but does not offer detailed instructions on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the paper, such as the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. The comment also questions the purpose of the \"proof\" and points out that the concept is well-known in machine learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The comment also notes the absence of a proof, which is a significant concern. However, the comment lacks specific examples or references to support the claim that the purpose is unclear or that the proof is missing. Without detailed evidence or examples, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It questions whether the purpose is merely to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. Additionally, the comment points out the absence of a proof, which is a significant concern. While the comment highlights important areas that need clarification and improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the approximations introduced by the authors (i-iii) and suggests that the possible vulnerability due to the assumption of attacks being in the feasible set needs to be expanded to reassure readers. However, it does not provide explicit guidance on how to address this issue or what specific details should be included to alleviate concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and their implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (i.e., lines 107-110) where the assumption of attacks being in the feasible set is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the possible vulnerability due to the assumption and the need to expand on this issue to reassure readers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction of approximations (i-iii) leaves loose ends, and that the possible vulnerability due to the assumption of attacks being in the feasible set needs to be expanded to reassure readers. The reviewer provides some reasoning by mentioning lines 107-110, suggesting that the assumption could be a concern. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it highlights a potential issue, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the introduction of approximations (i-iii) in the paper, noting that this may leave loose ends. It specifically points out the possible vulnerability due to the assumption of attacks being in the feasible set, which is discussed in lines 107-110. The comment suggests that this vulnerability needs to be expanded to reassure readers that it is not a real concern. While the comment highlights an important area for improvement, it lacks specific guidance on how to address the issue or what additional information should be included to alleviate concerns. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses a subjective opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution of the paper, suggesting that it is limited and that the proposed model seems incremental in its approach. However, it does not specify which part of the paper this assessment is based on, such as specific sections, figures, or experiments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in detailing the perceived limitations of the contribution and approach, but without grounding, it lacks actionable guidance for the authors to address these concerns. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any specific reasoning or evidence to support this claim, nor does it offer suggestions for improvement or areas where the authors could enhance their work. Without actionable feedback or guidance, the comment does not assist the authors in understanding how to address the perceived limitations or improve their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the two sets of benchmarks presented in Figure 4 and Figure 5. However, it does not provide explicit guidance on how the authors should address this issue or what specific comments they should include. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional comments on the differences between the two sets of evaluation methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of inconsistent metrics across different OPE methods in the two sets of benchmarks presented. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the consistency of metrics used for different OPE methods in the experimental part of the paper. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods. However, the comment does not provide specific examples or detailed reasoning to support why these differences are problematic or how they affect the conclusions of the paper. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are inconsistent across the two sets of benchmarks presented in Figure 4 and Figure 5. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the evaluation methods should be compared. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed guidance or actionable steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and direct action for the authors to take, specifying exactly what information needs to be included in the paper. The comment is specific and concrete, giving the authors a clear understanding of what steps to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the iteration cost (computational budget) of the proposed method should be discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it with other methods, including baseline methods. While the comment highlights a potential area for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The suggestion is logical and reasonable, but without detailed evidence or examples, it is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it with other methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the comprehensiveness and rigor of their evaluation. By addressing this point, the authors can ensure that their method is evaluated in a comprehensive manner, which could significantly improve the quality and impact of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed iteration costs. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their evaluation that can significantly enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides three specific actions for the authors to take. First, it suggests reporting average results over multiple runs to make the results more robust. This is an explicit action that the authors can directly implement. Second, it requests a discussion on the decision boundaries in the toy dataset, which is also explicit. Finally, it asks for clarification on the information in Fig. 9, which is a concrete request for clarification. Each of these actions is clear and provides specific guidance, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experimental section\" and provides specific references to \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by suggesting reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple requests for clarification or suggestions for improvement. It does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improving the experimental section of the paper. It highlights the need to report average results over multiple runs to make the results more robust, which is a clear and important point. Additionally, it requests a discussion on the decision boundaries in the toy dataset, which could help clarify the results and their implications. Finally, it asks for clarification on the information in Fig. 9, which could enhance the clarity of the presentation. These suggestions are clear and actionable, providing the authors with concrete steps to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' use of center correlation as a metric for discriminating model defenses, noting that they claim it is not insightful but then use it in figures 4A&B. The reviewer is seeking clarification on why the center correlation is considered useful in one context but not in another. This feedback is explicit in its request for an explanation or clarification, providing a clear action for the authors to take. However, it does not specify how the authors should address this issue or what changes should be made to the paper. Therefore, the comment is somewhat actionable, as it identifies an area for clarification but lacks detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 80-82,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' use of center correlation as a metric for discriminating model defenses, asking for clarification on why it is considered useful in one context but not in another. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' use of center correlation as a metric for discriminating model defenses, noting that they claim it is not insightful but then use it in figures 4A&B. This is a factual observation that highlights a discrepancy in the authors\\' claims and actions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should clarify this inconsistency. As a result, the claim is borderline verifiable, as it lacks detailed justification or examples to fully substantiate the critique. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' claims regarding the usefulness of center correlation as a metric for discriminating model defenses. It questions why the authors found it insightful in one context but not in another, and seeks clarification on the statement made on lines 80-82. This feedback is clear and actionable, as it prompts the authors to address the inconsistency in their claims and provide a rationale for their use of center correlation in specific contexts. By addressing this issue, the authors can improve the coherence and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to clarify the statement or improve the explanation provided. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for a specific aspect and the need for more convincing comparisons on CIFAR. It suggests that the authors should clarify the \"picking\" step and use the same setup as in the DEN paper to make the comparison fair and correct. While the comment provides explicit actions (e.g., ablate the \"picking\" step and use the same setup as in the DEN paper), it does not specify how to implement these actions or provide detailed guidance on what specific aspects need to be addressed. The feedback is mostly actionable, as it clearly outlines what the authors need to do to improve their draft, but it lacks concrete details on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR 2.2.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the experimental evaluation, such as the lack of ablation for a specific aspect and the need for more convincing comparisons on CIFAR. The comment suggests that the authors should clarify the \"picking\" step and use the same setup as in the DEN paper to make the comparison fair and correct. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks ablation for a specific aspect and that the comparison on CIFAR is not convincing. It suggests that the authors should clarify the \"picking\" step and use the same setup as in the DEN paper to make the comparison fair and correct. The comment provides some reasoning by pointing out the extensive experiments in the continual learning literature and the need for a more comprehensive comparison. However, it lacks specific examples or references to support the claim about the lack of ablation or the need for a more convincing comparison on CIFAR. The suggestion to use the same setup as in the DEN paper is somewhat vague, as it does not specify how this would improve the comparison. Overall, the claim is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for a specific aspect and the need for more convincing comparisons on CIFAR. It suggests that the authors should clarify the \"picking\" step and use the same setup as in the DEN paper to make the comparison fair and correct. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their draft by addressing these issues. However, the comment could be more helpful if it offered additional suggestions or examples on how to implement these improvements. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer implies that the former is more intuitive, but does not provide explicit guidance on how the authors should revise their language or presentation. The comment lacks concrete instructions or specific suggestions for improvement, leaving the authors uncertain about how to address the issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"above/below diagonal,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the term \"above/below 45 degree\" is less intuitive and suggests using \"above/below diagonal\" instead. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning by comparing the terms and their interpretations, but the comment lacks specific examples or references to support the claim. While the reasoning is clear, the lack of detailed evidence or references makes it somewhat verifiable. The authors would need to make a concerted effort to understand and address the issue, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the terminology used in the paper, suggesting that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree.\" The reviewer offers a logical reasoning for why the former term is more intuitive, which can help the authors improve the clarity of their presentation. However, the comment lacks depth and does not provide suggestions on how to revise the terminology or improve the explanation. While it identifies a potential issue, it does not offer actionable guidance or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior task-optimized approaches. It specifically questions whether the model is a prototype approximation to non-linear RNN models that exhibit emergent behavior, and whether the work provides any further explanation of how these nonlinear models attain solutions purely through optimization on a task. While the comment identifies a potential gap in the explanation and understanding of the model, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the model's relationship to non-linear RNN models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior task-optimized approaches, and it highlights the lack of clarity regarding the relationship between the model and non-linear RNN models. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the scientific insight provided by the model and formalism over prior task-optimized approaches, specifically questioning whether the model is a prototype approximation to non-linear RNN models that exhibit emergent behavior. The comment suggests that the work does not provide further explanation of how these nonlinear models attain solutions purely through optimization on a task. However, the comment lacks specific examples or references to support the claim that the model does not provide any further explanation. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the scientific insight provided by the model and formalism over prior task-optimized approaches. It questions whether the model is a prototype approximation to non-linear RNN models that exhibit emergent behavior, and whether the work provides any further explanation of how these nonlinear models attain solutions purely through optimization on a task. This feedback is valuable as it highlights a critical area where the authors need to provide more detailed explanations or evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or provided examples of how other models have successfully explained emergent behavior. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the definition of O_{up} in the supplementary material and questions how the ground truths are built. It suggests that O_{up} should contain the offset for every keypoint with respect to the center of the upper part. The reviewer implies that the current definition might not be accurate and provides a potential explanation for how the network parts might predict all keypoints. However, the comment does not explicitly instruct the authors to make changes or provide specific guidance on how to address the issue. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what needs to be done. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of O_{up} and suggesting that it should contain the offset for every keypoint with respect to the center of the upper part. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the definition of O_{up} in the supplementary material and questions how the ground truths are built. It suggests that O_{up} should contain the offset for every keypoint with respect to the center of the upper part. The reviewer provides a logical reasoning by pointing out that the current definition might not be accurate, as it only considers keypoints that are not farther than a distance \"r\" to the center of the corresponding part. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the definition of O_{up} in the supplementary material, suggesting that it should contain the offset for every keypoint with respect to the center of the upper part. It questions how the ground truths are built and how the network parts responsible for each part can predict all keypoints of the pose. While the comment highlights a potential problem, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the size of figures, the lack of clarity regarding how equation 5 follows from equation 4, the unclear explanation of \\theta^{t+1/2}, and the improper definition of S^{*} and S^{~}. While the comment highlights specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to clarify the figures, equations, and definitions, but without detailed guidance on how to do so. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the size of figures, the lack of clarity regarding equation 5, the unclear explanation of \\theta^{t+1/2}, and the improper definition of S^{*} and S^{~}. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing what needs to be addressed, such as the need for clarification on equations and definitions, but it lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the clarity and completeness of the paper. It mentions that the figures are small and almost unreadable, which suggests that the figures may not be easily interpretable. The comment also points out that equation 5 does not follow from equation 4 and that the explanation of \\theta^{t+1/2} is unclear. Additionally, it highlights the importance of S^{*} and S^{~} parameters and notes that they are not properly defined, with S^{~} being cyclic. These claims are somewhat verifiable as they provide specific examples and observations that can be addressed by the authors. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas of concern in the paper, including the size of figures, the lack of clarity regarding how equation 5 follows from equation 4, the unclear explanation of \\theta^{t+1/2}, and the improper definition of S^{*} and S^{~}. It also points out that S^{*} and S^{~} are important parameters but not properly defined. While the comment provides specific feedback on areas that need improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify and improve these aspects, but without specific guidance, the feedback is somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also provides specific guidance on font size, suggesting that the captions and legend font in Figures 2 and 3 should be larger. This feedback is clear and concrete, providing the authors with direct actions to take to improve the readability of their figures. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"texts in legends and axis labels\" and \"Captions and legend's font,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it clearly specifies what needs to be addressed, including making the texts in legends and axis labels larger and changing \"Proposition (1)\" to \"Proposition 1\" in the caption. This provides clear guidance on how to improve the readability of the figures. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the legibility of texts in legends and axis labels, suggesting that they should be larger to improve readability. The comment provides a specific example by mentioning \"Proposition (1)\" and \"Equation 1,\" which helps to clarify the issue. However, the comment lacks detailed reasoning or references to support the claim, such as explaining why larger font sizes are necessary or providing examples from other works. This makes the claim somewhat verifiable, as it provides some evidence but could benefit from more detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying issues with the legibility of texts in legends and axis labels. It suggests that these texts should be larger, similar to the text size, to improve readability. Additionally, it points out a confusion between \"Proposition (1)\" and \"Equation 1\" and recommends changing the former to \"Proposition 1.\" The comment also provides specific guidance on font size, suggesting that captions and legend fonts in Figures 2 and 3 should be larger. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and accessibility of their figures. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that for the counterfactual experiments, a comparison against Journey TRAK would be beneficial. Specifically, it mentions a particular step in the sampling trajectory where such a comparison could be made. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact step where the comparison should be made, but it is somewhat vague due to the lack of detailed guidance on how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"counterfactual experiments\" and suggests a specific comparison against Journey TRAK, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the particular step in the sampling trajectory where the comparison should be made, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a comparison against Journey TRAK would be beneficial for the counterfactual experiments. However, it does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the results. The mention of Journey TRAK and Figure 2 is vague, as it does not explain how this reference relates to the current work or why it would be relevant for the comparison. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of the suggested comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the counterfactual experiments by recommending a comparison against Journey TRAK at a particular step in the sampling trajectory. This feedback is actionable and constructive, as it suggests a clear way to enhance the experimental analysis by including a comparison that could provide valuable insights. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the results. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It also points out that Table 3 shows ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment does not provide explicit guidance on how the authors should analyze or comment on this aspect of the technique. While it implies that the authors should address this issue, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3\" and \"ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue with the placement of adaptive convolutions and suggests that the analysis or comments on this aspect of the technique are missing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on experimental results. It provides specific evidence from Table 3, where ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. This claim is supported by the comparison of experimental results, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that support this observation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It also points out that Table 3 shows ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment does not provide any analysis or suggestions on how the authors might address this issue or explore the implications of this observation. While it highlights a relevant aspect of the technique, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions the extent to which the information encoded in DAGs is lost when reduced to ancestral graphs. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of reducing the search space and potentially explore ways to maintain information while improving performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions the extent to which the information encoded in DAGs is lost when reduced to ancestral graphs. However, it does not specify which part of the paper this trade-off is discussed in, making it weakly grounded. The comment is specific in its inquiry about the information loss and the implications of reducing the search space. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions whether the information encoded in DAGs is lost when reduced to ancestral graphs. The comment is somewhat verifiable as it provides a logical reasoning for the trade-off and raises a valid question about the implications of the reduction in search space. However, it lacks specific examples or references to support the claim that the loss of information is significant. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions whether the information encoded in DAGs is lost when reduced to ancestral graphs, highlighting a potential issue with the method. While the comment identifies a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their method. The feedback is somewhat helpful as it prompts the authors to consider the implications of their approach, but it could be more beneficial with additional actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a brief discussion on the empirical motivation for a time-varying Q ^ t and S t , specifically addressing the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when these variables vary with time. While the comment implies that the authors should provide this discussion, it does not explicitly instruct them to do so. The action is concrete, as it specifies the topic to be addressed, but it is somewhat vague in terms of how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a brief discussion on the empirical motivation for a time-varying Q ^ t and S t , including the potential effects on the volatility of \u03b1 t and the average lengths of predictive intervals. This provides clear guidance on what the authors should consider adding to their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a discussion on the empirical motivation for a time-varying Q ^ t and S t , specifically addressing the effect on the volatility of \u03b1 t and the average lengths of predictive intervals. The comment provides a logical reasoning for why this discussion might be beneficial, but it lacks specific examples or references to support the claim. While the suggestion is reasonable, the lack of detailed evidence or examples makes it somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include a brief discussion on the empirical motivation for a time-varying Q ^ t and S t . It highlights the potential effects on the volatility of \u03b1 t and the average lengths of predictive intervals when these variables vary with time. This feedback is clear and offers a concrete direction for the authors to enhance their discussion section, providing a valuable opportunity for improvement. However, the comment could be more helpful if it included examples or references to support the rationale behind the suggestion. Overall, the comment is mostly helpful, as it provides a clear and actionable path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the definitions in Table 1 and questions the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions that ATSS has shown that regression methods do not significantly impact performance. The reviewer suggests that the authors clarify this issue and provides a specific suggestion to clarify the difference between the two methods. However, the comment does not explicitly instruct the authors to make these clarifications or provide guidance on how to do so. While the action is implicit, it is clear and concrete, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the definitions in Table 1, particularly the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions ATSS and its findings regarding the impact of regression methods. The comment is fully grounded as it explicitly mentions \"Table 1\" and provides specific details about the definitions and the methods being compared. It is also specific because it clearly specifies the issues with the definitions and the need for clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. The reviewer references ATSS, which has shown that regression methods do not significantly impact performance. The comment suggests that the authors clarify these differences and provides a rationale for why the motivations might not be solid without such clarification. This feedback is mostly verifiable as it provides logical reasoning and references to external sources, making it clear why the clarification is needed. However, the comment could be strengthened by including specific examples or references to the literature that support the differences between the methods. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises important questions about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions ATSS and its findings regarding the impact of regression methods, suggesting that the authors clarify these differences to strengthen the motivations of their work. The comment provides a clear and actionable suggestion for the authors to clarify the definitions and their implications, which is crucial for the clarity and robustness of the paper. However, the comment could be more helpful if it offered specific guidance on how to clarify these differences or provided examples of how other works have addressed similar issues. Overall, the comment is mostly helpful as it identifies a critical area for clarification and provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It also provides specific guidance on how to resolve the issue by adding the \"\\label\" command after the \"\\caption\" in LaTeX. This feedback is clear and concrete, leaving no ambiguity about what needs to be done to address the issue. The action is direct and the authors know exactly how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of Fig. 1 instead of Fig. 5.1 and provides guidance on how to resolve the issue by adding \"\\label\" after \"\\caption\" in LaTeX. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It provides a clear and specific instruction on how to correct the issue, such as adding \"\\label\" after \"\\caption\" in LaTeX. This comment is purely factual and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It provides clear and actionable guidance on how to correct this issue by instructing the authors to add \"\\label\" after \"\\caption\" in LaTeX. This feedback is direct and precise, enabling the authors to make a straightforward correction to their draft. However, the comment could be more helpful if it explained why this error occurred or offered suggestions for preventing similar errors in the future. Overall, the comment is highly helpful as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it recommends adding references next to baseline names in tables, specifying that the citation should be placed next to the name if it refers to a paper method. This is a clear and concrete action that the authors can directly implement. Second, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, but notes that it is not difficult to infer its meaning. This feedback is also explicit and provides a specific suggestion for clarification. Therefore, the comment is highly actionable, as it provides clear and concrete guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables\" and \"Corollary 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely adding references next to baseline names in tables and clarifying the definition of $\\\\Omega$ in Corollary 1. The comment is detailed and actionable, making it highly specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims: one about adding references next to baseline names in tables and another about the lack of explicit definition of $\\\\Omega$ in Corollary 1. The first claim is somewhat verifiable as it suggests a specific improvement (adding references) but lacks detailed explanation or examples of how this would enhance the clarity of the paper. The second claim is more verifiable as it points out a specific omission (the lack of an explicit definition for $\\\\Omega$) but could be strengthened by providing a rationale or example of why this is important. Overall, the comment is somewhat verifiable, as it provides some guidance but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it recommends adding references next to baseline names in tables, specifying that the citation should be placed next to the name if it refers to a paper method. This is a clear and actionable suggestion that can help improve the clarity and transparency of the paper. Second, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, though it is not difficult to infer its meaning. This feedback is also somewhat helpful as it identifies a potential area for clarification. However, the comment could be more helpful by suggesting how the authors might clarify the definition or provide additional context. Overall, the comment is mostly helpful as it offers actionable suggestions for improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the caption for Figure 7, noting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to correct the caption. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, from \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what the authors need to address in order to improve the accuracy of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the caption for Figure 7 is incorrect and should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how it affects the paper\\'s content. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the caption for Figure 7, noting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy of their paper. However, the comment does not provide additional context or explanation about why this correction is necessary or how it affects the overall understanding of the paper. While it is helpful in pointing out a specific error, it could be more beneficial if it included more detailed guidance on the significance of the caption or how it impacts the paper\\'s message. Therefore, the comment is rated as somewhat helpful, as it provides a clear action but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be addressed to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared with the baseline. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation after multiple experiments is not provided and that the improvement brought by SoRA is limited, possibly due to random fluctuations. The comment suggests that the authors should clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. While the comment provides a logical reasoning for the need to clarify these aspects, it lacks specific examples or references to support the claim about the limited improvement. This makes the claim somewhat verifiable, as it provides a clear direction but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental section of the paper, noting that the standard deviation after multiple experiments is not provided. It also points out that the improvement brought by the SoRA method compared to the baseline is limited, which may be due to random fluctuations. The comment suggests that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and actionable, providing the authors with a concrete step to address the issue of standard deviation and improve the clarity of their experimental results. However, it could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the organization and layout of the paper, including font size, figure clarity, and incorrect placement of a table. It provides explicit actions for the authors to take, such as increasing font size, improving figure clarity, and repositioning the table. The feedback is concrete and provides clear guidance on how to address these issues, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the organization, layout, and clarity of these parts, such as font size, figure clarity, and table placement. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and provides specific examples, such as the font size of some annotations being too small and figures not being drawn explicitly enough. It also mentions the incorrect placement of Table 2 within a paragraph and the top two lines on page 6 being in the wrong format. These examples provide a clear rationale for the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the organization and layout of the paper, providing clear and actionable feedback. It highlights problems such as small font sizes, unclear figure drawings, and incorrect placement of a table, which are all concrete examples of areas that need improvement. Additionally, it points out formatting errors, such as the top two lines on page 6 being in the wrong format. This level of detail and specificity empowers the authors to make significant improvements to the clarity and organization of their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue in the notation used in the paper, specifically the lack of definition for the notation \"{\\\\cal P} with a subscript.\" This provides a clear and direct action for the authors to take, which is to define the notation before using it. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the same section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"{\\\\cal P} with a subscript\" being used without definition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"{\\\\cal P} with a subscript\" is used several times without being defined. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, specifically the lack of definition for \"{\\\\cal P} with a subscript.\" This is a clear and actionable feedback that can help the authors improve the clarity and consistency of their notation. By addressing this issue, the authors can ensure that their notation is properly defined and understood by readers. However, the comment could be more helpful if it provided suggestions on how to define the notation or offered examples of how it should be used consistently throughout the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It points out specific lines (l148 and l156) where the text uses \"known\" instead of \"know\" and requests clarification on the definition of \\u03b3_0^{***} in the caption. Additionally, it asks for clarification on the meaning of the colors used in Figure 1, both in the caption and the text. These actions are clear and direct, providing the authors with specific guidance on how to improve their draft. The feedback is concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the use of \"known\" instead of \"know\" and the need for clarification on the definition of \\u03b3_0^{***} in the caption. Additionally, it requests clarification on the meaning of the colors used in Figure 1, both in the caption and the text. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple requests for clarification and corrections, which are factual in nature. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying multiple areas that need clarification or correction. It points out the use of \"known\" instead of \"know\" in specific lines, which is a minor but important detail. Additionally, it requests clarification on the definition of \\u03b3_0^{***} in the caption and the meaning of the colors used in Figure 1, both in the caption and the text. This feedback is clear and direct, offering the authors specific steps to improve the clarity and accuracy of their draft. By addressing these points, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" in the context of neural network decision boundaries. While the comment identifies specific areas that need clarification or explanation, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks actionable guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not offer specific steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" in the context of neural network decision boundaries. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need clarification. While the comment is specific in its requests for clarification, it lacks grounding as it does not identify the exact sections of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process, as well as the variable \"p\" in the context of neural network decision boundaries. While the comment identifies areas that need clarification or explanation, it does not provide specific examples or references to support the claims. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it highlights areas for improvement but lacks sufficient justification or evidence to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, including the clarification of terms like \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p\" in the context of neural network decision boundaries, which is problematic as it has been used extensively throughout the paper. The comment provides clear and actionable feedback by suggesting that the authors should clarify these concepts and definitions to enhance the clarity and coherence of their work. However, it could be more helpful if it offered specific suggestions on how to improve the explanations or provided examples of how these concepts have been addressed in similar works. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the proposed method, specifically mentioning the two major components: generative shape model and the word parsing model. It also suggests evaluating the method separately from baseline detection or parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses these components or the evaluation method. While the authors can infer that it relates to the methodology or results sections, the lack of explicit references makes it weakly grounded. The comment is specific in suggesting an evaluation approach, but it lacks grounding in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests evaluating the method separately from baseline detection or parsing techniques to better support the claim. The comment provides a logical reasoning by suggesting that following the detection-parsing paradigm requires separate evaluations to substantiate the claim. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, but the reasoning is sound. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that it is unclear which component of the proposed method contributes to the performance gain. It suggests that the authors should evaluate their method separately from baseline detection or parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the issue of attribution. However, the comment could be more helpful if it offered additional guidance on how to conduct these separate evaluations or suggested specific baseline techniques to use. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationales behind certain decisions in the experimental dataset, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these decisions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify these points but may not know exactly how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental dataset need clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the experimental dataset and the rationale behind certain decisions. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationales behind certain decisions in the experimental dataset, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment identifies areas that need clarification, it does not provide specific guidance or suggestions on how the authors might address these questions or improve their draft. The feedback is somewhat helpful as it prompts the authors to clarify their experimental setup, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific about what needs to be added, ensuring that the authors know exactly what steps to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 4 is incomplete and suggests that it should include results for all four datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is crucial for the credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the writing or presentation is \"jumbled\" at times, but it does not provide any specific guidance or suggestions on how to improve the clarity or organization. There is no explicit or implicit action for the authors to take, such as suggesting ways to restructure the content or improve the flow. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"writing / presentation,\" which suggests it relates to the content or structure of the paper. However, it does not specify which part of the paper is being addressed, such as sections, figures, or tables. The lack of explicit references makes it difficult for the authors to pinpoint the exact part of the paper being discussed. The comment is specific in detailing the issue of jumbled writing or presentation, but it lacks grounding as it does not specify where this issue occurs. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled\" at times. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment mentions that the writing or presentation is \"jumbled\" at times, indicating that the paper may be difficult to follow or understand. However, it does not provide specific examples or suggestions on how to improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes to make or how to enhance the readability of their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the crucial nature of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that may outweigh the bias reductions achieved by using IWAE in the first place. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the potential impact of the annealing scheme on their results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the crucial nature of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. However, it does not specify which part of the paper this question pertains to, such as the last paragraph in Section 4 or a specific figure or table. The authors can infer that it relates to the annealing scheme, but the lack of explicit mention makes it weakly grounded. The comment is specific in its concern about the potential bias induced by the annealing scheme when $\\\\alpha$ is not decreased to $0$. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the crucial nature of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer speculates that this could induce a bias that may outweigh the bias reductions achieved by using IWAE in the first place. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide sufficient evidence or references to substantiate the claim, making it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the crucial nature of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that may outweigh the bias reductions achieved by using IWAE in the first place. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider the implications of their annealing scheme, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an incorrect statement in the paper regarding the attention of certain heads in the base IOI circuit. It explicitly corrects the statement by referencing Section 3 of Wang et al. (2023), where the correct information is provided. This provides a clear and explicit action for the authors to take, which is to update the statement to reflect the correct information. The comment is highly actionable as it directly instructs the authors on what to change in their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect, namely that these heads primarily attend to the S2 token, rather than primarily attending to it, as stated in Section 3 of Wang et al. (2023). This provides clear guidance on what needs to be corrected in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect according to Section 3 of Wang et al. (2023). The reviewer provides a specific reference to the source, which supports the claim by offering a clear and precise explanation of the correct information. This makes the claim fully verifiable, as it provides a direct and accurate reference to the source. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies an incorrect statement in the paper regarding the attention of certain heads in the base IOI circuit. It provides a specific reference to Section 3 of Wang et al. (2023) to support its claim, which is a clear and actionable piece of feedback. By pointing out the discrepancy between the paper and the referenced work, the comment offers a straightforward correction that the authors can make to improve the accuracy of their draft. This level of detail and specificity makes the comment highly helpful, as it guides the authors toward a clear and effective revision. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how to improve the pipeline or what specific aspects of the contribution are lacking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity regarding what aspects of the pipeline are considered a \"pack of tricks\" or how the defense evaluation could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a collection of tricks to improve defense evaluation, which could be seen as a negative critique. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors could enhance the originality or impact of their work, leaving the authors without a clear path forward. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion on L15 regarding certain RNNs working well for certain natural language reasoning tasks is vague. It suggests providing more specific examples or references, such as the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. Additionally, the reviewer questions the relevance of the reinforcement learning/agent analogy in the context of the paper, suggesting that it might be better illustrated by examples later in the paper. While the comment provides some guidance on what could be improved, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more specific examples or references to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L15 and L16-18), allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback by suggesting that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and that the reinforcement learning/agent analogy might be out of place. The comment further suggests that the examples later in the paper might better illustrate the generalization capabilities. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests providing more specific examples or references, such as the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. The reviewer also questions the relevance of the reinforcement learning/agent analogy in the context of the paper, suggesting that it might be better illustrated by examples later in the paper. While the comment provides some reasoning and examples, it lacks detailed justification or specific references to fully substantiate the claim. The authors would need to make a significant effort to understand and address the feedback, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of certain statements in the paper, particularly regarding the effectiveness of certain RNNs for natural language reasoning tasks. It suggests providing more specific examples or references, such as the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. Additionally, the reviewer questions the relevance of the reinforcement learning/agent analogy, suggesting that it might be better illustrated by examples later in the paper. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and relevance of their discussion. However, it could be more helpful if it provided additional examples or suggestions on how to better integrate these concepts into the paper. Overall, the comment is mostly helpful as it directs the authors toward improving the clarity and relevance of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific observation in Figure 5, where the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and it highlights the lack of mathematical or theoretical justification for Algorithm 1. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The feedback is vague and lacks concrete suggestions on how to improve the draft, such as suggesting specific mathematical or theoretical justifications to be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of mathematical or theoretical justification for Algorithm 1 and the observation that the proposed sensitive-layer selection does not make a significant difference in terms of StableDiffusion. This provides clear guidance on what needs to be improved or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for Algorithm 1. The comment provides some reasoning by referencing the third figure in Figure 5, which supports the claim about the lack of difference in StableDiffusion. However, the comment lacks specific examples or references to mathematical or theoretical justifications, which would strengthen the claim. This makes the claim somewhat verifiable, as it provides some evidence but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation in Figure 5, noting that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion. It also highlights the lack of mathematical or theoretical justification for Algorithm 1, which is a critical aspect of the paper. While the comment points out areas for improvement, it does not provide actionable suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to specific areas needing improvement, but it lacks depth and detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that in line 122, the use of the notation $(e_1, r, e_2)$ should be changed to show the tuple-like structure of the triples instead of using sets. This is a clear and direct action for the authors to take, as it provides a specific suggestion for improving the presentation of their work. The comment is explicit and concrete, leaving no ambiguity about what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of the notation $(e_1, r, e_2)$ and its implication on the structure of the triples. This provides clear guidance on how to improve the presentation of the work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in line 122, the notation $(e_1, r, e_2)$ should be changed to show the tuple-like structure of the triples instead of using sets. However, the comment does not provide any reasoning, examples, or references to support why this change is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the presentation of the paper. By pointing out that the notation $(e_1, r, e_2)$ should be changed to show the tuple-like structure of the triples instead of using sets, the reviewer offers a clear and constructive feedback that can help the authors enhance the clarity and accuracy of their work. This feedback is valuable as it directly addresses a potential issue in the presentation, providing the authors with a concrete step to improve their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a statement claiming that every kernel can be described by a feature space parameterized by a neural network, which is considered trivially not true. The reviewer suggests that the limitation of representing infinite-dimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address this limitation or what specific changes should be made to clarify the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinite-dimensional RKHSs with neural networks. The comment provides a clear rationale for why this limitation should be made more clear, which helps the authors understand the issue and how to address it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, arguing that this is not true due to the limitations of representing infinite-dimensional RKHSs with neural networks. The reviewer provides a specific example of RBF kernels and their infinite-dimensional RKHS, which is a well-known limitation. This logical reasoning and reference to a well-accepted concept in the field supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with a claim made in the paper regarding the ability of neural networks to represent every kernel. The reviewer provides a clear and detailed explanation of why this claim is not accurate, citing the limitation of representing infinite-dimensional RKHSs with neural networks. This feedback is valuable as it not only highlights a potential misconception but also offers a constructive suggestion for clarifying the limitation. By pointing out the need for more clarity on this issue, the comment provides actionable guidance for the authors to improve their draft. However, the comment could be more helpful if it suggested specific ways to clarify the limitation or provided examples of how this issue might be addressed. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also questions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional evidence or analysis to address these concerns, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or analysis to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also questions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also questions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. The comment is somewhat verifiable as it provides a logical basis for the questions raised, but it lacks specific examples or references to support the claims. The authors would need to further explore and substantiate the claims to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions and suggestions that could help the authors improve their draft. It points out a potential issue with the reproducibility of GPI with noise added in Fig. 4, suggesting that there might be other measures to show that GPI cannot have as good a fit with behavioral data. This is a relevant observation that could prompt the authors to explore alternative methods or consider additional data analysis. The comment also questions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. This is a valuable suggestion that could lead to a more comprehensive understanding of the approach's limitations and potential applications. However, the comment could be more helpful if it provided specific suggestions or examples of alternative measures or analyses. Overall, the comment is mostly helpful as it identifies areas for improvement and offers a direction for further exploration, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the performance gains or what specific aspects of the results should be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains, specifically noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper these performance gains are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the performance gains but lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific issue with the performance gains, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This feedback is somewhat helpful as it identifies a potential area for improvement, namely increasing the performance gains. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the results need further exploration. While it points out a weakness, the feedback could be more actionable and comprehensive to be rated higher. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the information about incorrect phrases/corrected phrases and the type of mistake in helping the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the comment implies that the authors should analyze the impact of these different types of information on the feedback network, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis to address the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of the information about incorrect phrases/corrected phrases and the type of mistake in helping the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the impact of different types of information on the feedback network, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the information about incorrect phrases/corrected phrases and the type of mistake in helping the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the feedback network. Without such justification, the claim remains unverifiable, as it lacks the necessary details to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the effectiveness of the information about incorrect phrases/corrected phrases and the type of mistake in helping the feedback network. It also inquires about the performance without and with each of these two types of information and the performance with just natural language feedback. This question prompts the authors to consider the importance of different types of feedback information and their impact on the feedback network. While the comment does not provide specific suggestions or guidance on how to address this question, it does offer a clear direction for the authors to explore and potentially improve their draft. Therefore, the comment is somewhat helpful, as it encourages the authors to consider a specific aspect of their work and its potential impact on performance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether the use of a better Unary baseline would still result in a performance boost. While the comment implies that the authors should consider using a better Unary baseline as a baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their baseline choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and suggests considering a better Unary baseline. The comment is specific in its inquiry about the performance boost and the need to reconsider the baseline choice. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether the use of a better Unary baseline would still result in a performance boost. The comment suggests that the current baseline might not be optimal, as it compares unfavorably to a different neural network used in a previous work. However, the comment lacks specific references or detailed reasoning to support the claim that the current baseline is suboptimal. Without additional evidence or examples, the claim remains somewhat verifiable, as it provides a logical basis but lacks detailed justification. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether the use of a better Unary baseline would still result in a performance boost. It suggests that the current baseline might not be optimal, as it compares unfavorably to a different neural network used in a previous work. This is a thought-provoking observation that prompts the authors to reconsider their baseline choice and potentially improve their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a specific baseline or methodology. While it identifies a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the final used learning rates for the deep models, particularly for CIFAR-10 and CIFAR-100. It suggests that the authors should provide this information, as it could impact the results if the optimal learning rate for the baseline is outside the tested interval. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors know they need to include this information but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR-10 and CIFAR-100,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates\u2014and why it is important, as it could impact the results if the optimal learning rate for the baseline is outside the tested interval. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the final used learning rates for the deep models, particularly for CIFAR-10 and CIFAR-100. It suggests that the authors should provide this information because the optimal learning rate for the baseline could be outside the tested interval, which could affect the results. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the optimal learning rate is outside the tested interval. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the significance of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental setup, specifically regarding the final used learning rates for the deep models, particularly for CIFAR-10 and CIFAR-100. It suggests that the authors should provide this information, as it could impact the results if the optimal learning rate for the baseline is outside the tested interval. This feedback is clear and actionable, as it directs the authors to include specific details that could enhance the robustness and transparency of their work. However, the comment could be more helpful if it provided additional context or examples of how this information could be presented. Overall, the comment is mostly helpful as it highlights an important aspect of the experimental setup that the authors should address to improve the quality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more in-depth analysis are needed to better justify the claims in the paper. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the analysis should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments or provide more detailed analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed approaches only outperform the baselines in one setup out of three, and that there is no consistent trend in the results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more in-depth analysis are necessary to justify the claims in the paper. This claim is somewhat verifiable as it provides a logical reasoning for the need of additional experiments, but it lacks specific examples or references to support the claim. The authors would need to infer the need for additional experiments themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more in-depth analysis are necessary to better justify the claims in the paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by suggesting additional experiments or analysis. However, the comment could be more helpful if it offered specific suggestions on what types of experiments or analysis would be beneficial. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with some figures being not self-explanatory, particularly in Figure 4, where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting how to make the figures more self-explanatory or what additional explanations should be included. The action is implicit and somewhat vague, as the authors can infer that they need to make the figures more understandable but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically mentioning that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\\'s clarity. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some figures are not self-explanatory, specifically mentioning Figure 4 as an example. The reviewer provides a specific observation about the figure, noting that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This provides a clear and concrete example of what needs to be addressed, making the claim mostly verifiable. However, the comment could be strengthened by providing additional context or suggestions on how to improve the figure\\'s clarity. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with some figures being not self-explanatory, particularly in Figure 4. It provides a detailed example by pointing out that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation, which is a clear and actionable observation. This feedback is valuable as it highlights a specific area where the figures could be improved, offering the authors a concrete step to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it suggested ways to improve the figures or provided additional guidance on how to make them more self-explanatory. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should evaluate the sampling method more thoroughly, but it lacks specific instructions on how to do so or what specific aspects to focus on. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the sampling method used to obtain different initializations x_0, noting its importance for convergence to the optimum. It mentions that this sampling is not evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary material. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of thorough evaluation of the sampling method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling method is not evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, it lacks specific examples or detailed analysis to substantiate the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that this method is important for convergence to the optimum. However, it points out that this sampling is not evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment highlights a potential gap in the experimental evaluation, it lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation. The feedback is somewhat helpful as it directs the authors\\' attention to a potential area for improvement, but it does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas that need clarification and potential issues, it does not provide explicit guidance on how the authors should address these questions or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or discussion of these comparisons and their significance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"the proposed method\" and \"the computational cost,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the logic and comparisons made in the paper, such as why the authors compare the proposed method with [9] first and then [16], and why they only compare computational cost with [9]. The comment provides clear guidance on what needs to be addressed, namely the rationale behind the comparisons and the significance of the computational cost. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions why the authors compare the proposed method with [9] first and then [16], and why they only compare computational cost with [9]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, as it provides some basis for the critique but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions are relevant and could lead to a deeper understanding of the paper\\'s contributions and limitations. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas that need clarification, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific arXiv paper. While this question implies that the authors should address the comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific arXiv paper. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the comparison should be addressed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is weakly grounded because it does not specify where the comparison should be made, and it is not specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for a comparison between the PL condition used in the paper and the PL conditions proposed in a specific arXiv paper. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific arXiv paper. While this question highlights an area for potential comparison and potential enhancement, it does not provide any guidance or suggestions on how the authors might address this comparison or improve their work. The comment lacks depth and actionable feedback, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and directs the authors to include specific information in their draft, making it highly actionable. The authors know exactly what needs to be added to improve their draft, providing concrete guidance on how to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-stage training\" and \"multiple discriminators,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. This provides clear guidance on what the authors need to include in their analysis for a fair comparison with the baseline references. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it directs the authors to include specific information that would enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided examples or suggestions on how to conduct this analysis or what specific aspects to consider. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide theoretical evidence or clarify the trend across different model architectures, but it does not specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more theoretical evidence or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking in the analysis, namely the absence of theoretical evidence and clarity on the trend across different model architectures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and lacks theoretical evidence, which is a critical aspect of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the analysis. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It also questions the conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and its implications for SSL algorithms. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should consider the potential for information leaking and the implications of the dataset matching for SSL algorithms. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about information leaking in AutoAugment and questions the conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity. The comment further specifies that this could be a setback for SSL algorithms and suggests that combining two datasets might not lead to better representation learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It questions the conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and its implications for SSL algorithms. The comment provides some reasoning by suggesting that combining two datasets might not lead to better representation learning. However, it lacks specific examples or references to support the claim about information leaking or the implications for SSL algorithms. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the potential for information leaking in AutoAugment, which is used as a stronger augmentation strategy. It questions the conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and its implications for SSL algorithms. The comment suggests that combining two datasets might not lead to better representation learning. While the comment identifies a potential issue and raises important questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it prompts the authors to consider the potential implications of their method, but it could be more beneficial with additional actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should move the information to the supplementary materials. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that the empirical version should be moved to the supplementary materials, providing a clear direction for the authors to consider. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any reasoning, evidence, or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it could improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for improving the organization and presentation of the paper, it lacks depth and does not explain why this change would be beneficial or how it would enhance the clarity or impact of the paper. The comment is somewhat helpful as it identifies a potential area for improvement but does not offer detailed guidance or reasoning to support the suggestion. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific line of code (ln. 180--182) and questions the conclusion drawn from it. It suggests that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or clarification to support their conclusion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 180--182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the conclusion drawn from Corollar 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the conclusion drawn from Corollar 10, suggesting that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss but does not necessarily imply that it is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitations of the evidence presented, which is a valid observation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the evidence or provide additional reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific line of code (ln. 180--182) and questions the conclusion drawn from it. It points out that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that it is minimizing the expected convex surrogate. This feedback is somewhat helpful as it highlights a potential weakness in the authors\\' argument and encourages them to provide additional evidence or clarification to support their conclusion. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of alternative analyses that could strengthen the paper\\'s argument. Overall, the comment offers some guidance but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014to use tables to present the performance improvement\u2014it does not specify which tables should be used or how to present the information in a more detailed manner. The authors are left with a general idea of what to do but lack concrete guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the performance improvement, noting that it is not significant and suggesting the use of tables to show key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3. However, the comment does not provide specific details or references to support this claim, such as specific performance metrics or comparisons to other methods. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the performance improvement of the proposed methods seems not to be significant, as evidenced by figure 3. It also suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. However, the comment could be more helpful if it offered specific guidance on which tables or metrics should be used to present the improvements. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental validation, including the use of shallow networks, the lack of description of the optimization strategy, and the limited positioning with respect to related works. It also mentions a minor issue with the positioning in relation to network pruning. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed descriptions of the optimization strategy and consider more diverse network architectures. The feedback is somewhat actionable as it identifies areas for improvement but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the limited positioning with respect to related works. The comment provides specific guidance on what needs to be addressed, such as the need to consider more diverse network architectures and the need to describe the optimization strategy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks and the lack of description of the optimization strategy. It also highlights a minor issue with positioning relative to related works, such as the consideration of layer redundancy in network pruning. The reviewer provides a reference to a specific paper that discusses network pruning, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the experimental validation, including the use of shallow networks and the lack of description of the optimization strategy. It also points out a minor issue with the positioning of the work relative to related works, specifically mentioning the consideration of layer redundancy in network pruning. While the comment highlights areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it identifies areas that need attention, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, as it does not involve significant technical advancements or extensions beyond a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit suggestions for how the authors might improve their technical contribution or what specific aspects of the model could be enhanced. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it lacks significant advancements or extensions beyond a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section, figure, or methodology. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its critique of the technical contribution, but without explicit references or detailed guidance, it remains weakly grounded. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, as it does not involve significant technical advancements or extensions beyond a typical model for the cross-domain recommendation setting. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general assertion without sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, stating that it lacks significant advancements or extensions beyond a typical model for the cross-domain recommendation setting. While this feedback identifies a potential weakness in the paper\\'s contribution, it does not provide specific suggestions or guidance on how the authors might enhance their technical contribution or what aspects of the model could be improved. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path for improvement. Therefore, the comment is rated as barely helpful, as it points out an area for improvement but does not offer concrete guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment explicitly states what needs to be added, it does not provide detailed guidance on how to implement this suggestion or what specific fully-supervised baselines should be used. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its suggestion to add fully-supervised baselines, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of small models under different supervision settings. However, the comment could be more helpful if it explained why this addition is necessary or how it would enhance the understanding of the gap. Despite this, the suggestion is a valuable addition to the feedback, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the specific components of the approach are not novel, as they rely on commonly used models like MLP, Regression Tree, and Random Forest for NAS performance prediction. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should make their approach more novel or differentiate it from existing work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"specific components of the approach\" and \"WeakNAS,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out that the specific components are not novel, as they rely on commonly used models like MLP, Regression Tree, and Random Forest, and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach are not novel, as they rely on commonly used models like MLP, Regression Tree, and Random Forest for NAS performance prediction. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it states that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. The comment provides specific references to external works, such as [2,3,7] and [5], which supports the claim by citing examples of previously used models and strategies. This makes the claim mostly verifiable, as it provides sufficient evidence to substantiate the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific components of the approach that are not novel, as they rely on commonly used models like MLP, Regression Tree, and Random Forest for NAS performance prediction. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it points out that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This feedback highlights areas where the authors could improve their approach by differentiating it from existing work or by introducing novelty. However, the comment does not provide specific suggestions or guidance on how to address these issues, leaving the authors with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the OT sample selection process, suggesting that more details and a flowchart would be helpful for readers to understand the process. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flowchart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flowchart to address the questions raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the OT sample selection process, specifically asking about whether it runs iteratively and whether the EP module is updated during the training steps. It also requests more details and a flowchart to clarify the process. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the OT sample selection process is described. The comment is specific in detailing what needs to be clarified or added, making it fully grounded. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the OT sample selection process, specifically asking whether it runs iteratively and whether the EP module is updated during the training steps. It also requests more details and a flowchart to clarify the process. While the comment identifies areas for clarification, it lacks specific evidence or references to support the claim that these details are necessary or beneficial for the readers. The questions themselves are logical and relevant, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions about the OT sample selection process, specifically asking whether it runs iteratively and whether the EP module is updated during the training steps. It also requests more details and a flowchart to clarify the process, which would make it easier for readers to understand. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for improvement and provides clear questions, it lacks specific suggestions on how to address these issues or improve the clarity of the paper. The feedback is somewhat helpful as it highlights important areas for enhancement but could be more comprehensive with actionable guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the absence of experiments with continuous tasks and questions why the entropy methods for conditional optimization are not included in the experiments. It also asks how the empirical performance of these methods compares to ConBO. While the comment identifies a gap in the experimental setup and suggests a potential area for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they need to include experiments with continuous tasks and consider including the entropy methods for conditional optimization, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not offer specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the continuous task setting\" and \"Section 7 in the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the absence of experiments with continuous tasks and asks why the entropy methods for conditional optimization are not included in the experiments. It further specifies that the empirical performance of these methods should be compared to ConBO. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the absence of experiments with continuous tasks and questions why the entropy methods for conditional optimization are not included in the experiments. It also asks for a comparison with ConBO. While the comment highlights a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included or how they might compare to ConBO. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the experimental setup by pointing out the absence of experiments with continuous tasks and questions why the entropy methods for conditional optimization are not included in the experiments. It also asks for a comparison with ConBO, which is a relevant benchmark. This feedback is clear and actionable, as it highlights an area where the authors could enhance their experimental analysis and provide a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this gap or provided examples of how to conduct the missing experiments. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details in their paper, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these details. However, the feedback is somewhat actionable because it provides a clear direction for improvement, albeit not as direct as it could be.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4-class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on how precision/recall/F1-score were calculated and suggests providing AUC results for breast cancer detection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions seeking clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. By asking for clarification on the methodology and suggesting additional metrics for comparison, the comment provides actionable feedback that can help the authors improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to present these additional details or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to important areas for clarification and enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the novelty of the transformer and the limited impact of the proposed modification. It suggests that the self-cross attention does not bring significant improvement and that the main improvements come from using a naive transformer. However, the comment does not provide specific guidance on how the authors should address these concerns or what changes they should make to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their proposed modification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Transformer\" and \"cross-layer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed modification does not bring much insight in the aspect of machine learning and that the self-cross attention brings limited improvement. Additionally, it provides specific feedback on the ablation study results, suggesting that the self-cross attention does not contribute significantly to the improvements over other methods. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the transformer is no longer novel in the field and that the proposed modification does not bring significant insight. It also questions the significance of the self-cross attention improvement, suggesting that the main improvements come from using a naive transformer instead of the proposed modification. The comment provides some reasoning by pointing out that the transformer has been widely adopted in NLP and vision tasks, but it lacks specific examples or detailed evidence to fully substantiate the claim. The suggestion to consider the naive transformer as a baseline is somewhat valid, but the comment could be strengthened with more detailed evidence or comparisons. Overall, the claim is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the novelty and impact of the proposed modification to the transformer. It points out that the transformer has been widely adopted in NLP and vision tasks, making it no longer novel. Additionally, it questions the significance of the self-cross attention modification, suggesting that it does not bring much insight in the aspect of machine learning. The comment also highlights the limited improvement of the self-cross attention in the ablation study, which further supports the argument that the proposed modification is not significant. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve their work. Overall, the comment offers valuable insights and critiques, but it lacks actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks they should include in their experiments. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sentence similarity tasks and open domain QA tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the experiments are limited and should include more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what additional experiments are needed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited because they only focus on sentence similarity tasks and open domain QA tasks. The reviewer suggests that there are many other tasks involving sentence pairs, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a logical reasoning for why the experiments should be expanded to include more tasks. However, it lacks specific examples or references to support the claim that these tasks are necessary or how they would enhance the experiments. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experiments to enhance the scope and relevance of their work. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful as it effectively points out a gap in the experimental design and offers a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. It also suggests that the abstract could be rephrased for better clarity and that Figure 2 lacks labeled y-axes, which are specific issues that the authors can address. While the comment is explicit and provides concrete guidance, it could be improved by offering more detailed suggestions on how to rephrase the abstract or improve the figure. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the prompt, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the abstract, suggesting that lines 016-019 are difficult to understand and recommends rephrasing. Additionally, it points out an issue with Figure 2, noting that it lacks labeled y-axes. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for clarification about the prompt's location and a critique of the abstract and Figure 2. The first part is a request for clarification, which does not involve an opinion or claim. The second part consists of two separate critiques: one about the abstract's clarity and the other about Figure 2\\'s labeling. The first critique is somewhat verifiable as it suggests that the prompt might be in a supplement that the reviewer cannot access, but it lacks specific details or examples. The second critique is more verifiable as it provides specific issues with the abstract and Figure 2, such as the difficulty in understanding lines 016-019 and the lack of labeled y-axes in Figure 2. However, the comment could be strengthened by providing more detailed reasoning or examples to fully support the claims. Overall, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it requests that the prompt be included in the appendix or supplement, ensuring that all necessary information is available for readers. This is a clear and actionable suggestion that can help the authors improve the accessibility of their work. Second, it points out issues with the abstract, specifically mentioning lines 016-019 as difficult to understand and suggesting a possible rephrasing. Additionally, it critiques Figure 2, noting that it lacks labeled y-axes and is unclear about its purpose. While the comment identifies specific areas for improvement, it could be more helpful by providing additional guidance or examples on how to address these issues. Overall, the comment is mostly helpful as it offers actionable feedback on clarity and accessibility, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim in the introduction regarding the shape constraints, noting that while the constraints themselves may not require tuning, the choice of convex or concave, increasing or decreasing constraints can be considered a hyperparameter that needs to be chosen or tuned. This comment implies that the authors should clarify or rephrase their statement to account for the choice of constraints as a hyperparameter. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The feedback is somewhat actionable as it identifies a specific issue but lacks concrete guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim regarding the shape constraints, noting that the choice of convex or concave, increasing or decreasing constraints can be considered a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" The reviewer provides a logical reasoning by pointing out that the choice of convex or concave, increasing or decreasing constraints can be considered a hyperparameter that needs to be chosen or tuned. This reasoning is based on the common understanding of hyperparameters and their importance in model selection. However, the comment could be strengthened by providing specific examples or references to similar works that address this issue. Despite this, the claim is mostly verifiable, as it effectively challenges the initial claim and provides a clear rationale for the need to consider the constraints as hyperparameters. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim in the introduction regarding the shape constraints, noting that while technically true, the choice of convex or concave, increasing or decreasing constraints can be considered a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it highlights a specific area where the authors may need to clarify or rephrase their statement to avoid misleading readers. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the constraints as hyperparameters. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the theoretical proof for convergence appears trivial and suggests that it lacks substantial novelty and rigor. It provides a specific example of how the proof can be adapted from Modification 1 in Appendix C, which indicates that the authors should make changes to the proof. The comment is clear and provides concrete guidance on how to address the issue, making it highly actionable. Authors can easily identify the parts of the proof that need to be revised and follow the suggested modifications to enhance the rigor and novelty of the convergence proof.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, pointing out that it lacks substantial novelty and rigor due to the trivial adaptation from Modification 1. The comment provides a clear direction for improvement by suggesting that the authors should address the issue of non-i.i.d. Assumption 4.1 and provide a more rigorous proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical proof for convergence appears trivial and lacks substantial novelty and rigor. The reviewer supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted from Modification 1 in Appendix C, providing a specific example of how the proof can be adapted. This detailed explanation and example make the claim mostly verifiable, as it provides a clear rationale for the critique. However, the comment could be further strengthened by referencing specific theorems or references to support the claim of lacking novelty and rigor. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical proof for convergence, suggesting that it lacks substantial novelty and rigor due to the trivial adaptation from Modification 1 in Appendix C. It provides a specific example of how the proof can be adapted and offers a clear direction for improvement by suggesting that the authors address the issue of non-i.i.d. Assumption 4.1. This feedback is actionable and provides the authors with a concrete step to enhance the rigor and novelty of their convergence proof. However, the comment could be more helpful if it offered additional guidance on how to improve the proof or provided specific suggestions for addressing the identified issues. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and provides a clear path for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between two statements: one stating a performance loss and the other claiming outperformance due to knowledge sharing. The reviewer requests clarification, indicating that the authors need to address this contradiction. While the comment explicitly identifies the issue and suggests a clarification, it does not provide specific guidance on how to resolve the contradiction or improve the clarity of the statements. The action is clear but somewhat vague, as the authors know they need to clarify but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statements about the multi-env model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the contradiction between the claims of performance loss and outperformance due to knowledge sharing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the contradiction between two statements about the multi-env model: one claiming a performance loss and the other claiming outperformance due to knowledge sharing. The reviewer requests clarification, indicating that the authors need to address this contradiction. However, the comment does not provide specific examples or references to support the claim of contradiction, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a contradiction in the paper regarding the performance of the multi-env model. It points out that the paper claims both a performance loss and outperformance due to knowledge sharing, which seems to be conflicting. The comment requests clarification, prompting the authors to address this contradiction and provide a clearer explanation of their findings. This feedback is clear and actionable, as it directs the authors to resolve a potential inconsistency in their work. However, it could be more helpful if it offered suggestions on how to clarify the statements or provided examples of how the contradiction might be resolved. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and coherence of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It suggests that the paper should spend more time motivating the need for such algorithms. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of motivation should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more motivation but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s objective of designing fast label aggregation algorithms for a streaming setting. It points out that the paper does not spend enough time motivating the applications of these algorithms, as all the datasets used in the empirical analysis are static. The comment suggests that the paper should provide more motivation for the problem it considers. While the comment is specific in identifying the lack of motivation and the need for more context, it does not explicitly mention which sections of the paper should be revised or how the motivation should be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It suggests that the paper should spend more time motivating the need for such algorithms, as all the datasets used in the empirical analysis are static. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks specific guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which undermines the utility of the paper. The comment suggests that the paper should spend more time motivating the problem it considers, which is a crucial aspect of the paper\\'s contribution. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how to address this issue. This limits the comment\\'s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the scope of the study is under-specified and suggests that additional relevant CoT baselines for in-context learning of large language models should be included in Table 2 and 3. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement this change or which specific CoT baselines should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for in-context learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that additional relevant CoT baselines for in-context learning of large language models should be included in Table 2 and 3. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the authors may find it challenging to verify the claim and make the necessary improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the scope of the study, noting that it focuses on injecting a CoT-based approach to small-scale language models. The comment suggests that if this is not the case, additional relevant CoT baselines for in-context learning of large language models should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides specific guidance on how to enhance the study's scope and improve the comprehensiveness of the results. However, the comment could be more helpful if it included examples of the missing CoT baselines or explained why these are important for the study. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While it identifies a potential gap in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this issue or what specific aspects of the connection should be explored. As a result, it offers limited value to the authors in terms of enhancing their draft. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the system, specifically the performance degradation with the growth of the maximum number of identities. It suggests that the capacity should be set to a small number, like 10, and questions how the authors plan to scale up without compromising performance. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The authors are left to infer that they need to consider scalability and performance trade-offs, but the comment lacks detailed guidance on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the specific issue of performance degradation with the growth of the maximum number of identities. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the problem with the scalability of the system and suggests a potential solution by recommending a capacity limit of 10. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of the system degrades with the growth of the maximum number of identities, suggesting that the capacity should be limited to a small number, like 10. The reviewer provides a logical reasoning by explaining that in real-world scenarios, the number of objects can be more than 10, and the authors should consider how to scale up without compromising performance. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scalability of the system, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be limited to a small number, like 10, to address this issue. The comment also raises a relevant question about how the authors plan to scale up without compromising performance, prompting the authors to consider a critical aspect of their system\\'s scalability. While the comment provides valuable insights and actionable suggestions, it could be more helpful if it offered additional guidance or examples on how to implement these changes. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their work and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim their work as preliminary but question the NLP-specific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to align with an NLP-specific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding their work being preliminary and discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of NLP-specific aspects in the approach, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim made by the authors that their work is preliminary and discusses the application of LLP to NLP tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a discrepancy between the authors\\' claim of their work being preliminary and the lack of NLP-specific aspects in their approach. This feedback highlights an inconsistency in the authors\\' claims, which could be addressed by providing more detailed information about the NLP-specific aspects of their work. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or what aspects of their approach should be clarified or expanded. While it identifies a potential weakness, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs, as existing methods are not discussed in terms of their applicability. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or what specific aspects of the existing methods should be discussed. The comment implies that the authors should provide a rationale for the need to develop a new method, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of justification for the need to design a new curriculum learning method for text graphs, particularly in the context of existing methods not being discussed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods are not discussed. However, the comment lacks specific examples or references to existing methods that could be applied, making it difficult for the authors to understand the basis of the claim. Without detailed reasoning or evidence, the authors may find it challenging to address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that existing methods are not discussed in terms of their applicability, which is a critical area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of existing methods should be discussed. While it highlights a significant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the writing could be improved, such as the definition of \"relevant\" auxiliary model weights in 2.1. It provides explicit actions for the authors to take, such as clarifying the definition or rephrasing it for better understanding. The comment also suggests that the writing could be improved in other places, but it does not specify which parts need further attention. While the action is explicit, the comment lacks concrete details on how to implement these improvements, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the definition of \"relevant\" auxiliary model weights. The comment provides a clear direction for the authors to enhance the clarity of their writing. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the definition in \"definition 2.1,\" specifically regarding the term \"relevant\" auxiliary model weights. The reviewer questions the interpretation of this term and suggests that the definition could be improved for better understanding. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or difficult to interpret. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the writing could be improved, such as the definition of \"relevant\" auxiliary model weights in 2.1. It provides clear and actionable feedback by pointing out that the definition is difficult to interpret and suggests clarifying or rephrasing it for better understanding. Additionally, the comment implies that the writing could be improved in other places, but it does not specify which areas need attention. While the feedback is valuable, it could be more helpful if it included additional examples or suggestions for improvement. Overall, the comment is mostly helpful as it directs the authors to specific areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing. While the comment implies that the authors should conduct a quantitative comparison on the final outputs, it does not explicitly instruct them to do so. The action is clear but not explicitly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a quantitative comparison on the final outputs to confirm ModelAngelo's superiority. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and not the final outputs, which is a subjective observation. The reviewer suggests that a quantitative comparison on the final outputs would be more convincing to confirm ModelAngelo's superiority. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the significance of the claim and potentially conduct additional analysis to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing to confirm ModelAngelo's superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their evaluation section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the explanations are qualitative and that the procedures are described minimally or not at all, which is a clear indication of what needs to be improved. The reviewer also points out specific issues, such as the confusion over \"sample count\" in Figure 2 and the lack of error bars or p-values for statistical inferences. This feedback is detailed and provides specific guidance on how to enhance the clarity and rigor of the paper. Therefore, the comment is highly actionable, as it clearly instructs the authors on what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"explanations,\" \"simulation or experiment-based evidence,\" \"procedures,\" \"figures,\" and \"statistical inferences,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the explanations, such as their qualitative nature and the lack of detailed procedures or figures, as well as the need for error bars or p-values for statistical inferences. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, the comment highlights the absence of error bars or p-values for statistical inferences, which is a common expectation in scientific literature. The comment provides specific examples of issues, such as the confusion over \"sample count\" in Figure 2, and logically reasons that more details are needed to clarify the procedures and statistical inferences. This makes the claim mostly verifiable, as it provides a clear rationale for the need for improvement.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the paper\\'s explanations and procedures. It points out that the explanations are qualitative and that the procedures are described minimally or not at all, which is a critical issue that needs attention. The reviewer also highlights specific areas of confusion, such as the \"sample count\" in Figure 2, and suggests that more details should be added to the paper and/or supplementary information. Additionally, the comment emphasizes the importance of including error bars or p-values for statistical inferences, which is a common expectation in scientific literature. This feedback is clear and provides the authors with a concrete path to enhance the clarity and rigor of their work. Therefore, the comment is highly helpful, as it offers detailed guidance on how to improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide explicit instructions on how to implement this suggestion, leaving the authors to infer the necessary actions. While the action is clear, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that providing these settings would help the community by providing a single review of advances in this area. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment lacks specific examples or references to support the claim that this would help the community by providing a single review of advances in this area. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is somewhat helpful as it identifies a specific area for improvement, which could enhance the clarity and usefulness of the paper to the community. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as its originality or contributions. While the feedback points out a potential improvement, it could be more actionable and comprehensive to be rated as highly helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the bias can happen, the general applicability of these situations is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific ways to clarify the general applicability or suggesting additional examples to illustrate the points. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the general applicability of the examples presented. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises an issue with the clarity of specific examples of biases and prediction shifts presented in the paper. It acknowledges that the bias can happen but questions the general applicability of these situations. However, the comment lacks specific examples or references to support the claim that these situations are not generalizable. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the clarity of examples presented in the paper, particularly regarding the applicability of biases and prediction shifts. It acknowledges that the authors have provided examples but questions their generalizability. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it highlights a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the 3D Gaussians generation section, which is currently following previous work. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies what the authors need to address and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether there is any additional novel effort in this section, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussians generation is novel or follows previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence or reasoning to substantiate the claim that it is unoriginal. The comment lacks specific examples or references to support the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the novelty of the 3D Gaussians generation section, which is currently following previous work. It prompts the authors to clarify whether there is any additional effort or innovation in this part of the paper. While the comment identifies a potential weakness, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement but does not offer detailed guidance or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the tractability of the MMD DRO method compared to other methods like phi-divergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude and that the nonnegative constraint on the distribution is dropped, requiring further approximation. Additionally, the comment suggests that assuming the loss function \\ell_f belongs to the RKHS is restrictive. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the tractability and robustness of their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3.1\" and \"MMD DRO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of tractability in the upper bound provided in Theorem 3.1 and the need for further approximation, as well as the assumption of the loss function \\ell_f belonging to the RKHS. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the MMD DRO method does not enjoy a tractable exact equivalent reformulation, which is a severe drawback. The reviewer supports this claim by pointing out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and further approximation is still needed. Additionally, the reviewer questions the assumption that the loss function \\ell_f belongs to the RKHS, which is already pointed out by the authors. The comment provides specific examples and logical reasoning to support the claim, making it mostly verifiable. However, it could be strengthened by referencing specific literature or examples to further substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the tractability of the MMD DRO method compared to other methods like phi-divergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and further approximation is still needed even for a simple kernel ridge regression problem. Additionally, the comment questions the assumption that the loss function \\ell_f belongs to the RKHS, which is already pointed out by the authors. This feedback is somewhat helpful as it highlights specific areas where the method could be improved, but it lacks detailed guidance or suggestions on how to address these issues. The authors are given a direction to explore but are not provided with actionable steps to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve the draft. The comment is specific about the issue and provides a concrete suggestion for reorganization, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reorganization of the section to improve its clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. While it provides a clear and actionable suggestion for improvement, it lacks depth and does not offer specific guidance on how to reorganize the section or what changes would improve its clarity. The comment is somewhat helpful as it points out a problem but does not provide detailed guidance on how to address it, leaving the authors with a general idea of what needs to be improved. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detailed information in the paper and supplementary material, specifically regarding the RNN implementation and other technical details needed for reproducibility. While it identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The comment implies that more details are required, but it does not offer concrete steps or suggestions on what those details should be. As a result, the authors are left with a general understanding of the issue but without clear instructions on how to resolve it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the specific technical details that are missing, such as the number of units in the RNN implementation, and it suggests that these details are necessary for reproducibility. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not written to be reproduced, as it lacks detailed technical information required for reproduction. The reviewer supports this claim by mentioning specific details, such as the number of units in the RNN implementation, which are not provided in the paper or supplementary material. This provides a clear and specific rationale for the claim, making it fully verifiable. The authors can understand the need for these details and the importance of addressing them to improve reproducibility. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that while it provides an intuitive understanding of the work, it lacks detailed technical information required for reproducibility. The comment highlights specific areas that are missing, such as details about the RNN implementation, which are necessary for replicating the work. This feedback is clear and actionable, as it directs the authors to specific areas where they need to provide more detailed information to improve the reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of what additional details might be needed. Overall, the comment is mostly helpful as it effectively points out a critical gap in the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include error bars or more trials. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any specific reasoning or evidence to support why error bars or more trials would be beneficial. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in Figure 1, suggesting that the addition of error bars or more random trials could potentially reduce random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\\'s robustness and clarity. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or explained why error bars or more trials are beneficial. Overall, the comment is mostly helpful as it directs the authors\\' attention to a meaningful improvement but lacks depth in its execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references specific works related to context-aware robust fine-tuning, fine-tuning impact on foundation models, and robust fine-tuning of zero-shot models. While the comment provides explicit actions and concrete details on how to implement them, such as including an introduction to energy models and clarifying Figure 1, it does not specify the exact sections where these additions should be made. Therefore, the comment is mostly actionable, as it provides clear guidance on what needs to be done but lacks detailed instructions on how to execute it.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a brief introduction to energy models in the related work section and the lack of clarity regarding the correspondence between different learning rates and steps in Figure 1. The references to specific works, such as [1] Context-aware robust fine-tuning, [2] Fine-tuning can cripple your foundation model; preserving features may be the solution, and [3] Robust fine-tuning of zero-shot models, provide additional guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It references specific works related to context-aware robust fine-tuning, fine-tuning impact on foundation models, and robust fine-tuning of zero-shot models. These references provide a logical basis for the claim, but the comment could be strengthened by including more detailed explanations or examples of how these references relate to the paper. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. It also points out a lack of clarity in Figure 1, specifically regarding the correspondence between different learning rates and steps. The comment references relevant works on context-aware robust fine-tuning, fine-tuning impact on foundation models, and robust fine-tuning of zero-shot models, which can help the authors contextualize their work and provide additional insights. This feedback is clear and provides a clear direction for improvement, making it mostly helpful. However, it could be more comprehensive by offering suggestions on how to integrate these references into the paper or explaining why they are relevant. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the introduction should focus on drift, which is the paper's core focus. The comment provides a clear and direct action for the authors to take, which is to revise the introduction to better align with the paper's core focus. The feedback is specific and concrete, giving the authors a clear idea of what needs to be changed to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper's focus. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is somewhat verifiable as it logically argues that the introduction should focus on drift, which is the paper's core focus. However, the comment lacks specific examples or references to support the claim that the current introduction is inappropriate or ineffective. Providing more detailed reasoning or evidence would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\\'s core focus. The comment suggests that this paragraph provides little valuable information to readers and recommends that the introduction should focus on drift. This feedback is clear and actionable, as it directs the authors to revise the introduction to better align with the paper\\'s core focus. However, the comment could be more helpful if it provided suggestions on how to effectively integrate the discussion of drift into the introduction. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using styles or colors to distinguish between the different curves in Figure 2. This feedback provides a clear and explicit action for the authors to take, which is to enhance the visual clarity of the figure. The suggestion is concrete and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to enhance the visual clarity of the figure by using styles or colors to distinguish between the different curves. This level of detail provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to enhance the visual clarity by using styles or colors. This feedback is based on a logical observation about the figure\\'s clarity, but it lacks detailed reasoning or examples to fully substantiate the claim. While the suggestion is clear, the lack of detailed justification or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to enhance the clarity of Figure 2 by using styles or colors to distinguish between the different curves. This feedback is clear and direct, offering a concrete way for the authors to improve the visual presentation of their data. By addressing this issue, the authors can significantly improve the readability and comprehension of their figure, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors tone down the introduction and avoid calling the task \"language learning.\" It suggests that the task is more accurately described as a feedback-driven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is highly actionable as it offers a specific and detailed suggestion for improvement, ensuring that the authors know exactly how to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claims made in the introduction, suggesting that the authors should tone down the introduction and avoid calling it \"language learning.\" The comment provides a clear rationale for the suggestion, making it easy for the authors to understand and address the issue. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and avoid calling it \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedback-driven QA in the form of a dialog. This claim is somewhat verifiable as it provides a logical argument for the reframing of the introduction, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the introduction of the paper, noting that the claims made are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and avoid calling it \"language learning,\" as it is more accurately described as a feedback-driven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the clarity and accuracy of their introduction. By addressing this issue, the authors can enhance the credibility and effectiveness of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. It provides specific performance metrics for these models, such as GLaMM achieving 83.2 RES cIoU on RefCOCO TestA and UNINEXT achieving 89.4 REC accuracy (IoU>0.5) on RefCOCOg Test. This feedback implies that the authors should compare their model's performance with recent state-of-the-art models and potentially explain the gap. However, the comment does not explicitly instruct the authors to conduct this comparison or provide guidance on how to do so. While the action is implied, it is not as explicit as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by comparing the performance of the model on REC and RES with more recent models, such as GLaMM and UNINEXT, and providing specific performance metrics like cIoU and REC accuracy. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. The comment provides specific performance metrics for these models, such as GLaMM achieving 83.2 RES cIoU on RefCOCO TestA and UNINEXT achieving 89.4 REC accuracy (IoU>0.5) on RefCOCOg Test. This provides a clear and concrete basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights a significant issue with the performance of the model on REC and RES, noting that it is behind more recent models. It provides specific examples by referencing GLaMM and UNINEXT, which achieved higher performance on REC and RES. This feedback is clear and actionable, as it directs the authors to compare their model's performance with recent state-of-the-art models and potentially explain the gap. By identifying specific metrics and models, the comment offers a concrete direction for improvement. However, it could be more helpful if it provided suggestions on how to improve the model's performance or addressed potential limitations in the comparison. Overall, the comment is mostly helpful as it provides valuable insights and guidance for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This feedback provides a clear and specific action for the authors to take, which is to revise the wording of the statement to be more accurate and appropriate. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of the term \"evidence\" in a specific figure (Fig. 5), suggesting that it might be too strong. However, it does not specify which part of the paper Figure 5 is discussed in, making it weakly grounded. The comment is specific in suggesting a more appropriate term, but without full grounding, it is difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the term \"evidence\" might be too strong, suggesting a more appropriate wording like \"Fig.\" However, the comment does not provide any reasoning or examples to support why \"evidence\" might be inappropriate. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"evidence\" in the context of a specific figure (Fig. 5). It suggests that the term might be too strong and recommends a more appropriate wording, such as \"Fig.\" This feedback is specific and actionable, as it provides the authors with a clear suggestion for improving the clarity and accuracy of their language. However, the comment could be more helpful if it explained why \"evidence\" might be inappropriate or provided additional context on the figure or its significance. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanation for the implementation of kernels with OpenAI's Triton is unnecessary due to well-known engineering improvements. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this feedback or what specific improvements should be made. As a result, the comment lacks actionability, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, it does not specify which part of the paper this explanation pertains to, such as a specific section or figure. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its suggestion that the explanation is unnecessary, but without grounding, it lacks actionable guidance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. While it identifies a potential area for simplification, it does not provide specific guidance or suggestions on how to streamline the explanation or what aspects of the explanation are redundant. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, it is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these issues or improve their analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not specify which part of the paper this critique pertains to, such as sections 3.2 or 3.3. The authors can infer that it relates to the analysis of neural networks, but the lack of explicit mention makes it weakly grounded. The comment is specific in detailing the critique of the analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. The comment provides some reasoning by referencing the existing NTK theorem and the work of considering only easy wide fully-connected neural networks. However, it lacks specific examples or references to support the claim that the analysis is trivial or that the work bypasses the core problem. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It points out that the work only considers easy wide fully-connected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is somewhat helpful, as it provides insight into a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of results with larger models like ResNet101/152, which is a specific observation about the experimental setup. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the results with smaller models could be improved. The comment lacks explicit instructions or concrete details on how to proceed, leaving the authors uncertain about what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper this observation is based on, such as a specific section or table where these results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, namely results with larger models, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples, references, or detailed explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the experimental setup, noting the absence of results with larger models like ResNet101/152. This feedback highlights a potential gap in the paper\\'s evaluation, which could be addressed by including results with these models. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the results with smaller models could be improved. While it points out a relevant area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential confusion in the paper regarding the use of the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the first line of the introduction. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this confusion or suggest specific changes to the language. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms to avoid confusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the multi-fidelity framework and sequential design for learning quantities, specifically mentioning a reference to a specific work by Stroh et al. (2017). This provides a clear grounding for the authors, as they can easily identify the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the terms \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that these terms are confusing. The reference to a specific work by Stroh et al. (2017) provides some context but does not fully substantiate the claim. The comment is somewhat verifiable, as it highlights a potential issue but lacks detailed justification or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the terms \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. It suggests that this inconsistency is confusing and provides a specific reference to a related work by Stroh et al. (2017) to illustrate the issue. While the comment highlights a potential problem, it does not offer specific suggestions or guidance on how to address this confusion. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captioning experiment should compare results on the official COOC leader board on the blind test set, rather than using a non-official test set or development set. It also recommends that the paper should compare its results to those on the leaderboard, specifically mentioning that [5,17] have won the challenge and been evaluated on the blind challenge set. Additionally, the comment suggests that the paper should compare its results to other approaches that have been proposed since the work was published, as these have significantly improved. While the comment provides explicit actions for the authors to take, such as referencing the official leaderboard and comparing results, it does not specify how to implement these actions or provide detailed guidance on which specific approaches to compare with. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare results on the official COOC leader board on the blind test set and to include comparisons to other approaches that have been published since the work was conducted. This provides clear guidance on how the authors can improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the captioning experiment should compare results on the official COOC leader board on the blind test set, rather than using non-official test sets or development sets. The reviewer provides a reference to the official COOC leaderboard, which supports the claim by suggesting that [5,17] have won the challenge and been evaluated on the blind challenge set. Additionally, the comment suggests that the paper should compare its results to other approaches that have been proposed since the work was published, which could significantly improve the results. This provides a logical and verifiable basis for the claim, as it highlights the importance of using official test sets and referencing relevant work. Therefore, the comment is fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the captioning experiment, suggesting that the paper should compare results on the official COOC leader board on the blind test set, rather than using non-official test sets or development sets. It also recommends that the paper should compare its results to those on the leaderboard, specifically mentioning [5,17] as examples of successful approaches. Additionally, the comment suggests that the paper should compare its results to other approaches that have been proposed since the work was published, which could significantly improve the results. This feedback is detailed and provides specific guidance on how the authors can enhance the robustness and credibility of their results. However, it could be more helpful if it included suggestions on how to implement these comparisons or what specific aspects of the results should be compared. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what steps to take to validate them. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable feedback or suggestions for improvement, such as recommending further analysis or clarifying the discrepancy. Without specific guidance or additional context, the authors may struggle to address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a problem but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or ways to differentiate their methodology from existing ones. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as specific sections, figures, or methodologies. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing what is considered a lack of novelty, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or comparisons, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. While it identifies a potential weakness in the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their methodology from existing ones. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it provides some insight but not enough to be fully beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify the meaning of \"wrong\" in the context of the paper, noting that the paper discusses the nuances of this position at line 255. The reviewer provides a specific action by suggesting that the authors clarify the meaning of \"good/bad/wrong\" before using those concepts. This feedback is clear and direct, giving the authors a concrete step to take in order to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" in the context of the paper. The reviewer suggests that the paper should clarify the concepts of \"good,\" \"bad,\" and \"wrong\" explanations before using them, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"wrong\" in the context of the paper, suggesting that the authors should clarify what is meant by \"good,\" \"bad,\" or \"wrong\" explanations before using those concepts. This is a request for clarification rather than a claim or opinion, as it does not express a subjective judgment or suggestion for improvement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the use of the terms \"good,\" \"bad,\" and \"wrong\" explanations. It suggests that the authors should clarify these concepts before using them in the paper. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring that the concepts are well-defined and understood by the reader. However, the comment could be more helpful if it offered additional guidance on how to clarify these terms or provided examples of how they might be clarified. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide specific guidance on what additional information or analysis should be included to address this gap. The comment implies that the authors should expand their discussion on this topic, but it lacks concrete suggestions or examples of what should be covered. As a result, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or dataset description. The authors can infer that it relates to the datasets or analysis sections, but this inference is not direct. The comment is specific in detailing what is missing, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not cover the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the omission or how it affects the paper\\'s contribution. Without concrete evidence or reasoning, the claim remains unverifiable, as it does not provide a clear rationale for the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of coverage on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it highlights a gap in the paper\\'s discussion that the authors can address to enhance their contribution. However, the comment could be more helpful if it provided specific examples or suggestions on how to expand the discussion or incorporate this information. Overall, the comment is mostly helpful as it directs the authors\\' attention to a relevant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard R-GCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take in addressing this observation. While it implies that the authors should investigate the reason behind the difference, it lacks detailed guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for further exploration but does not offer specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the tendency of a generator equipped with a standard R-GCN as a discriminator to collapse after several iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a generator equipped with a standard R-GCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the importance of this observation and the potential reasons behind the difference in behavior. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard R-GCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or explain this difference. While it points out an area for further exploration, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, specifically questioning whether it is an extension of a previous study or introduces novel contributions. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how the authors might demonstrate originality or differentiate their work from the referenced study. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the paper, specifically questioning whether it is an extension of a previous study or introduces novel contributions. However, it does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results sections. The authors cannot confidently determine which sections of the paper are being addressed, making this comment weakly grounded. The comment is specific in its concern about originality, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the originality of the paper, suggesting that it may be an extension of a previous study. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed evidence or reasoning makes it challenging for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, questioning whether it is an extension of a previous study or introduces novel contributions. This is an important issue that the authors should address to ensure their work is distinct and valuable. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might differentiate their work from the referenced study. Without detailed guidance or examples, the authors may find it challenging to address the originality concerns effectively. Therefore, the comment is somewhat helpful, as it identifies a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to improve the clarity. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical comparisons to adaptive learning of GPRGNN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning of GPRGNN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for the paper\\'s theoretical foundation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a missing component in the experiments, specifically the lack of explanation regarding the different queries used in spatio-temporal representation. It suggests that the authors should include experiments and explanation regarding the use of spatial, temporal, and summary queries, which are key differences between their work and VideoChatGPT and other works. While the comment implies that the authors should include these components, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact details of what is missing and how to address it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experiments - Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the lack of explanation regarding the different queries used in spatio-temporal representation, and how this relates to the key difference between their work and VideoChatGPT and other works. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments lack an explanation of the different queries used in spatio-temporal representation, specifically spatial, temporal, and summary. The reviewer suggests that this is a key difference between their work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they contribute to the key difference. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of explanation regarding the different queries used in spatio-temporal representation. It highlights the importance of this aspect, as it is a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation regarding the use of spatial, temporal, and summary queries, which would enhance the understanding of their approach and its novelty. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to implement these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a general direction for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider the potential negative social impacts of their work, such as increased automation or dual use risks. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The authors are left to infer that they need to discuss these topics, but the comment lacks specific guidance on what aspects to focus on or how to integrate them into the paper. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential negative social impacts of the work and the risks from the dual use of the method. The comment provides a clear direction for improvement by suggesting that the authors should consider these aspects. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should consider the potential negative social impacts of their work, such as increased automation or dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the potential negative impacts. Without detailed reasoning or evidence, the claim remains unverifiable, as it does not provide a clear rationale for the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors consider the potential negative social impacts of their work, such as increased automation or dual use risks. While the comment acknowledges that the authors may not believe their work has significant negative social impacts, it provides a clear direction for enhancing the paper by addressing these aspects. However, the comment could be more helpful if it offered specific examples or guidance on how to integrate these considerations into the paper. Overall, the comment is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the notation used in the paper, specifically regarding the use of \"\\hat v\" in equation L434. The reviewer suggests that this notation might be confusing, as it is not consistent with the standard use of \"\\hat\" for empirical estimates. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting alternative notation or explaining the intended use of \"\\hat\" in this context. While the comment identifies a potential problem, it lacks concrete steps for the authors to take, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L434,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"\\\\hat v_t,\" suggesting that it is confusing and inconsistent with standard usage. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the notation used in equation L434, specifically the use of \"\\hat\" in the context of empirical estimates. The reviewer suggests that this notation might be confusing, as it is not consistent with the standard use of \"\\hat\" for empirical estimates. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this notation is confusing or why it should be changed. Without additional context or explanation, the claim remains somewhat verifiable, as it lacks the necessary justification to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation used in the paper, specifically regarding the use of \"\\hat\" in equation L434. The reviewer points out that this notation might be confusing, as it is not consistent with the standard use of \"\\hat\" for empirical estimates. This feedback is somewhat helpful as it highlights a potential source of confusion that the authors should address to improve the clarity of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to resolve this issue, such as suggesting alternative notation or explaining the intended use of \"\\hat\" in this context. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. While it identifies a specific area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more details or examples, but it lacks concrete steps or suggestions on what additional information should be included. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the paper\\'s validity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as suggesting additional experimental details or references to similar works. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add \"on the subword level\" to the phrase \"thousands\" in L006, as mentioned in the main text. This feedback is clear and provides a specific action for the authors to take, ensuring that the language is accurate. The comment is concrete, as it specifies the exact change needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the phrase \"thousands\" and suggests adding \"on the subword level.\" This provides clear guidance on how to improve the accuracy of the language used. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"thousands\" is not accurate in L006, as mentioned in the main text. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the paper, noting that the phrase \"thousands\" may not be accurate in L006, as mentioned in the main text. It suggests adding \"on the subword level\" to clarify the intended meaning. This feedback is clear and actionable, as it provides a specific suggestion for improving the accuracy and clarity of the language used in the paper. By addressing this issue, the authors can enhance the precision and credibility of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement. It notes that certain hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the y-value in the latent path figures is always 0 at x=0. The reviewer also expresses interest in further analysis of the model, specifically mentioning interpolations. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague and lack detailed guidance, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and suggestions for improvement, but it does not specify which part of the paper these issues pertain to. The mention of \"hyperparameters\" and \"latent path figures\" suggests that it relates to the methodology or results sections, but without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. The comment also lacks specificity in terms of what needs to be clarified or improved, such as the y-value at x=0 or the need for further analysis. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises several questions and observations, including the absence of certain hyperparameters, the y-value at x=0 in latent path figures, and the need for further analysis of the model. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or detailed reasoning to support the claims. The questions are somewhat valid but require more context and explanation to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the absence of certain hyperparameters, the y-value at x=0 in latent path figures, and the need for further analysis of the model. It raises specific questions about the clarity of the description and the normalization of the y-value, which are important aspects that the authors should address to improve the quality of their work. The suggestion for further analysis on the model is also valuable, as it could lead to a deeper understanding of the model's behavior and potential applications. However, the comment could be more helpful if it provided more detailed guidance or examples on how to address these issues. Overall, the feedback is somewhat helpful as it highlights important areas for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to provide more information about the error bound, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not offer specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the process of rounding core tensors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effect of rounding on the full tensor error and asks for clarification on the error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effect of rounding core tensors on the full tensor error and asks for clarification on the error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of justification or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the effect of rounding core tensors on the full tensor error and asks for clarification on the error bound in terms of epsilon. This feedback is clear and actionable, as it highlights a potential gap in the paper\\'s explanation and provides a specific question that the authors can address to improve the clarity of their work. By addressing this question, the authors can enhance the comprehensibility and rigor of their analysis. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar concepts have been addressed in related literature. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the test settings used in visual dialog and questions the relevance of the discriminative setting for real applications. It implies that the authors should include results from the generative setting as well. While the comment implies that the authors should include results from the generative setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include results from the generative setting. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"visual dialog\" and \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Table 1 only shows results on the discriminative setting, which is not applicable to real applications. The comment further questions the results on the generative setting, providing clear guidance on what additional information is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the test settings used in visual dialog and questions the relevance of the discriminative setting for real applications. It suggests that the authors should include results from the generative setting as well. While the comment highlights a potential issue with the current setup, it lacks specific examples or references to support the claim that the discriminative setting is not applicable to real applications. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the full implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the test settings used in the paper, noting that the Table 1 only shows results on the discriminative setting, which is not applicable to real applications. It raises a valid point about the relevance of the discriminative setting and suggests that the authors should include results from the generative setting as well. This feedback is clear and actionable, providing the authors with a specific direction for improving their work by addressing the applicability of the discriminative setting. However, the comment could be more helpful if it offered suggestions on how to conduct the generative setting tests or provided examples of how this might be done. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what exactly this evidence or reasoning should entail, leaving the authors without clear guidance on how to address the feedback. The comment lacks explicit instructions or concrete suggestions, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for additional evidence or reasoning, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. While it identifies a potential weakness in the paper\\'s argument, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment is somewhat helpful as it points out a potential area for improvement, but it does not offer detailed suggestions or examples to help the authors enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that it would be helpful to describe the form of p, which is assumed to be a Gaussian distribution, near line 135. It also references an earlier comment about the form of p, providing a clear action for the authors to take. The comment is specific about where the information should be included and what needs to be clarified, making it highly actionable. Authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the form of p should be described, particularly regarding its assumed Gaussian distribution. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the form of p, which is assumed to be a Gaussian distribution, should be explicitly stated in the paper. While the comment references an earlier comment about the form of p, it does not provide specific reasoning or evidence to support why this information should be included or how it would enhance the paper. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of including this information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the form of p, which is assumed to be a Gaussian distribution, is not explicitly stated. It references an earlier comment about the form of p, providing some context for the authors. However, the comment lacks depth and does not offer suggestions or guidance on how to address this issue or improve the clarity of the paper. While it points out a potential gap, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It explicitly asks the authors to clarify whether they mean that the prediction error over the entire horizon T cannot be sublinear. This feedback is clear and provides a specific action for the authors to take, which is to clarify their statement regarding the regret and the method\\'s achievement of T^{1/2} regret. The action is explicit and concrete, as it directs the authors to make a specific correction in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret, and it asks for clarification on whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the discrepancy between the discussion on the regret being sublinear and the proof of achieving T^{1/2} regret. It does not contain any subjective claims or opinions but rather seeks clarification on the authors\\' statements. Therefore, it is a factual observation and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy in the paper regarding the discussion of regret and the proof of achieving T^{1/2} regret. It points out that the authors discuss the inability of the regret to be sublinear but proceed to prove that their method achieves T^{1/2} regret. This feedback is clear and actionable, as it directs the authors to clarify their statement regarding the regret and the method\\'s achievement of T^{1/2} regret. By addressing this issue, the authors can improve the coherence and accuracy of their paper. Therefore, the comment is highly helpful as it provides a concrete and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the details of the forward-prediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. It also mentions that the connection between the text and the figure, as well as the equations, is unclear. This provides a clear and concrete action for the authors to take, which is to redraw Figure 2(b) and improve the connection between the text and the visual elements. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forward-prediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the lack of a clear schematic representation of the forward-prediction model in Figure 2(b) and the difficulty in connecting the text with the figure and equations. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. The comment provides a specific example of the issue, namely the lack of clarity in the figure, and suggests a specific action to improve it. This provides a clear and actionable claim, making it mostly verifiable. The authors can understand the need for improvement and the specific steps to take, making the comment mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the explanation of the forward-prediction model in Figure 2(b). It points out that the figure does not provide a clear schematic representation of the model, making it difficult for readers to connect the text and equations with the visual elements. The comment suggests that the figure should be redrawn to improve clarity. This feedback is clear and actionable, as it directs the authors to a specific area needing improvement and provides a concrete suggestion for enhancing the clarity of the paper. However, the comment could be more helpful if it offered additional guidance on how to redraw the figure or what specific elements should be included. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is vague and lacks specific guidance on how to implement this. The authors are left with a general idea of what needs to be addressed but without clear direction on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, while the comment suggests a direction for the conclusion, it does not provide specific guidance on how to address these issues or what specific aspects of the comparison with reinforcement learning should be discussed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not state-of-the-art, and that there is no discussion of limitations. It also suggests a direction for the conclusion, which is to discuss the similarity and difference with reinforcement learning and the generalizability of the results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The suggestion for the conclusion is somewhat vague, leaving the authors with a general idea of what needs to be improved but without detailed guidance. Therefore, the comment is somewhat verifiable, as it provides some basis for the claims but lacks sufficient evidence or specificity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It also suggests a direction for the conclusion, which is to discuss the similarity and difference with reinforcement learning and the generalizability of the results. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general idea of what needs to be improved but without detailed, actionable advice. Therefore, the comment is somewhat helpful, as it provides insight into potential areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that running VGAE with a vamp prior could help determine whether the benefits are due to a better generative model or better inference. It also proposes a method to compare representations by keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIG-VAE or VGAE. While the comment provides a clear action to take, it lacks specific guidance on how to implement this suggestion, such as which specific VGAE variant to use or how to set up the comparison. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests running VGAE with a vamp prior to better match the doubly stochastic construction in this work, which could help determine whether the benefits are due to a better generative model or better inference. It also proposes a method to compare representations by keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIG-VAE or VGAE. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the modeling and inference aspects. The suggestion is specific, as it provides a concrete action to take, but it lacks grounding as it does not specify which part of the paper this suggestion pertains to. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in this work, which could help determine whether the benefits are due to a better generative model or better inference. The comment also proposes a method to compare representations by keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIG-VAE or VGAE. This suggestion is based on logical reasoning and provides a clear rationale for the proposed experiment. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to improve the paper by running VGAE with a vamp prior to better match the doubly stochastic construction. This could help determine whether the benefits are due to a better generative model or better inference. Additionally, the comment suggests a method to compare representations by keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIG-VAE or VGAE. This feedback is clear and actionable, offering the authors a concrete way to enhance their work. However, it could be more helpful if it provided additional context or examples on how to implement these suggestions. Overall, the comment is mostly helpful as it offers valuable insights and guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It notes that while the paper acknowledges this importance, the reviewer is uncertain about its full requirement. The comment suggests that a discussion about this issue might be needed, but it does not provide explicit guidance on how to conduct this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that a discussion about this issue might be needed, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that they can see this happening in visualizations but questions whether it is fully required. The comment suggests that the truth lies somewhere in between and proposes a discussion about this issue. However, the comment lacks specific examples or references to support the claim that learning long-range dependencies is not fully required. This makes the claim somewhat verifiable, as it provides a logical basis for questioning the importance but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the paper acknowledges this importance but questions whether it is fully required. The comment suggests that a discussion about this issue might be needed, which is a constructive suggestion for the authors to consider. However, the comment could be more helpful if it provided specific examples or references to support the claim or offered guidance on how to conduct the discussion. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The comment suggests that this exponential dependence may indicate a weakness in the proposed approaches or theoretical results. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the definition of $e_l$ and consider the impact of the diameter $M$ on their results. However, without concrete suggestions or examples, the comment lacks actionability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3 and Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data, which affects the constant factor of the required feature size. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It suggests that this dependence may indicate a weakness in the proposed approaches or theoretical results. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed explanations to substantiate the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, so the comment is rated as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the definition of $e_l$ in Equation (3). It also points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data, which affects the constant factor of the required feature size. The comment suggests that this dependence may indicate a weakness in the proposed approaches or theoretical results. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it highlights a potential area for concern, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or observations related to this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or observations to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for evidence or results related to the model collapsing less than other methods, and it raises a question about the observation of gradients becoming 0 and collapsing. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making a claim or expressing an opinion. It does not contain subjective statements or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically references line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is somewhat helpful as it prompts the authors to provide evidence or observations related to this claim, which could strengthen their argument. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue. To be more helpful, the comment could provide examples of similar observations or suggest ways to improve the presentation of results. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results for linear scalarization combined with the SOTA heuristic-based solver Concorde for a better comparison. This feedback is explicit and provides a clear action for the authors to take, as it specifies the exact combination to include in the experimental results. The comment also explains why this addition is necessary, by noting that the Pareto front is not highly non-convex, which affects the comparison. This level of detail makes the action explicit and concrete, ensuring that the authors know exactly what to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the comparison, namely the results for linear scalarization combined with the SOTA heuristic-based solver Concorde. This provides clear guidance on how to enhance the comparison and improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers are better than heuristic-based solvers, but it suggests that for single-objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually has the best performance. The reviewer provides a rationale by explaining that the Pareto front is not highly non-convex, which affects the comparison. However, the comment lacks specific examples or references to support the claim about the superiority of learning-based solvers. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves, which justifies a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It highlights a gap in the experimental results by pointing out that the learning-based solvers are better than heuristic-based solvers, but for single-objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization combined with Concorde to provide a better comparison. This feedback is clear and offers a concrete way for the authors to enhance their experimental results and improve the comprehensiveness of their analysis. By addressing this suggestion, the authors can significantly enhance the quality and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide glosses in Figure 2. This is a clear and direct action, as it specifies exactly what the authors need to do to improve their draft. The comment is specific and provides a concrete step for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing glosses in Figure 2, but it does not specify which part of the figure requires glosses or where the glosses should be placed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. However, the comment is specific in its suggestion to include glosses, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests providing glosses in Figure 2, which is a specific request for clarification or enhancement. However, it does not provide any reasoning, evidence, or examples to support why glosses are necessary or how they would improve the figure. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary justification to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests providing glosses in Figure 2, which is a specific and actionable suggestion. By including glosses, the authors can enhance the clarity and accessibility of their figure, making it more understandable for readers. However, the comment does not provide further context or explanation about why glosses are necessary or how they would benefit the figure. While it offers a clear and actionable suggestion, it could be more helpful if it included additional guidance or reasoning. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of grouping for quantization, specifically questioning whether finer grouping (per-tensor and per-channel) is appropriate. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or what specific changes they should consider. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. As a result, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of grouping for quantization, specifically questioning whether finer grouping (per-tensor and per-channel) is appropriate. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its question about the choice of grouping, but without explicit references to sections or details, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of grouping for quantization, specifically questioning whether finer grouping (per-tensor and per-channel) is appropriate. However, it does not provide any reasoning, evidence, or examples to support why finer grouping might be more appropriate or why the current choice is problematic. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of grouping for quantization, specifically questioning whether finer grouping (per-tensor and per-channel) is appropriate. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or reasoning for why finer grouping might be beneficial. The comment is somewhat helpful as it prompts the authors to consider a different approach, but it does not offer actionable guidance or detailed reasoning to support the change. Therefore, it aligns with a score of 3: Somewhat Helpful, as it provides a starting point for the authors but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the terminology, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the definition of \"active vertices,\" but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and requests clarification on how this term is used in the context of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the definition of \"active vertices\" in a particular line of the paper. By doing so, it prompts the authors to clarify a potentially confusing aspect of their work, which could improve the clarity and accessibility of their manuscript. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the explanation. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the theoretical limitations mentioned in the paper and the actual limitations that are not addressed. It suggests that the authors should clarify the theoretical limitations by mentioning the inapplicability of their theory to the used model. Additionally, it recommends elaborating on the potential negative societal impact of graph neural networks in general. While the comment provides specific actions for the authors to take, such as clarifying the theoretical limitations and discussing the societal impact, it does not offer detailed guidance on how to implement these actions. The feedback is explicit but somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vagueness of unspecified 'structural assumptions'\" in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the theoretical limitations and the potential negative societal impact of graph neural networks. The comment provides a clear direction for improvement by suggesting that the authors should elaborate on these aspects. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not mention the theoretical limitations of the model, specifically the inapplicability of the theory to the used model, despite the vagueness of unspecified \"structural assumptions\" in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends elaborating on the potential negative societal impact of graph neural networks in general. The comment provides a logical reasoning and references the appendix to support the claim, making it mostly verifiable. However, it could be strengthened by providing specific examples or references to industry applications or studies that demonstrate the widespread use of graph neural networks. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the theoretical limitations of the model, specifically the inapplicability of the theory to the used model. It highlights the vagueness of unspecified \"structural assumptions\" in the appendix, making it difficult for readers to understand the theoretical limitations. The comment also suggests that the authors underestimate the current use of graph neural networks in industry and recommends elaborating on the potential negative societal impact of graph neural networks in general. This feedback is clear and actionable, providing the authors with specific areas to address and enhance their paper. By addressing these points, the authors can improve the clarity and comprehensiveness of their theoretical limitations and societal impact discussion. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the importance of a particular part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of a particular part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment also lacks specificity regarding what aspect of the framework is vital or how it contributes to the paper\\'s distinction from other related work. Without clear guidance on which part of the paper needs attention, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the importance of a particular part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the discussion is necessary or how it would enhance the paper\\'s distinction. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the importance of a particular part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their framework. Without actionable feedback or detailed insights, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the weakness of the analogy between HOI analysis and Harmonic analysis, noting that there is only a limited basis for forming an HOI. It also questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas that need clarification or reconsideration, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or connections to strengthen the analogy. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. However, the comment does not specify which part of the paper discusses these analyses or where the weaknesses lie. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks specificity in terms of grounding. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and questions the connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is tenuous. It also questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis, suggesting that the analogy is not well-founded. While the comment highlights areas that need clarification or further development, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out potential weaknesses but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the limited focus on focusing distances in Figure 8, noting that it only shows 1m and 5m, both of which exist in the training data. It suggests that the paper should consider focusing distances other than those shown in the training data to determine if the model generalizes well. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the limited focus on focusing distances in the figure, suggesting that the paper should consider focusing distances other than those shown in the training data to determine if the model generalizes well. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the limited focus of Figure 8, which only shows 1m and 5m, both of which exist in the training data. The comment suggests that the paper should consider focusing distances other than those shown in the training data to determine if the model generalizes well. However, the comment lacks specific examples or references to support the claim that other focusing distances should be considered. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup by pointing out that Figure 8 only shows images with focusing distances of 1m and 5m, both of which exist in the training data. It raises a valid question about the generalizability of the model to other focusing distances. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation. Providing more detailed advice or examples on how to expand the analysis would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a broader range of focusing distances but does not fully guide them on how to implement this suggestion.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. The comment also raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. The comment also raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the authors\\' neural application and the definition of style. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. The reviewer provides an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. The comment also raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is mostly verifiable as it provides a logical reasoning and examples to support the claim. However, it could be strengthened by referencing specific sections of the paper where the authors discuss their neural application or style, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. Additionally, the comment raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially enhance the clarity of their work. However, the comment could be more helpful if it provided specific guidance on how to broaden the definition or addressed the question about the temporal dynamic structure. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of depth in the analysis of vit quantification, specifically mentioning the argument about information distortion and the quantization of MHSA. It provides specific examples of the variance difference between the proposed approach and existing methods, such as Q-BERT, Q8BERT, BinaryBERT, FullyBinaryBert, and others. The comment also suggests that the quantization of MHSA introduces a large loss of precision, which is not unique to the ViT model. While the comment provides a clear direction for improvement by suggesting a more in-depth analysis, it does not explicitly instruct the authors on how to implement this improvement. The action is implicit but concrete, as it specifies what needs to be addressed and provides examples of what could be improved. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the analysis, such as the argument about information distortion and the quantization of MHSA, providing examples of the variance difference between the proposed approach and existing methods like Q-BERT, Q8BERT, and BinaryBERT. This level of detail helps the authors understand what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the argument about information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference between the proposed approach and existing methods like Q-BERT, Q8BERT, BinaryBERT, FullyBinaryBert, and others. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific studies or literature that discuss the information distortion and quantization of MHSA in the context of transformer quantization. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the argument about information distortion and the quantization of MHSA. It highlights the variance difference between the proposed approach and existing methods like Q-BERT, Q8BERT, BinaryBERT, FullyBinaryBert, and others, which suggests that the proposed approach does not improve the phenomenon of information distortion. The comment also notes that the quantization of MHSA introduces a large loss of precision, which is not unique to the ViT model but has been observed in transformer quantization in NLP. This feedback is highly helpful as it identifies specific areas where the analysis could be improved and provides examples of existing methods that could be used for comparison. By offering actionable suggestions, the comment empowers the authors to enhance the depth and rigor of their analysis, which is crucial for the paper\\'s credibility and impact. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a main weakness of the paper, which is the lack of technical novelty regarding spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons should be included. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons and provide more novelty, but the comment lacks detailed instructions on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"spatial transformer networks (STN)\" and the \"X-transformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the main weakness of the paper, which is the lack of technical novelty and the absence of comparisons to STN. The comment provides specific feedback on the similarity of the proposed X-transformation to STN and the need for empirical or conceptual comparisons to STN. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to similarities with spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer provides some reasoning by mentioning existing works that propose STN in a local pixel neighborhood and the use of STN in PointNet. However, the comment lacks specific examples or references to support the claim that the proposed X-transformation is similar to STN. Additionally, it does not provide detailed justification for the importance of comparisons to STN, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks sufficient evidence or detailed explanation to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, which is the lack of technical novelty regarding spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important for the work's contribution. The comment provides clear and actionable feedback by highlighting specific areas where the paper could be improved, such as including comparisons to STN and providing more novelty. However, it could be more helpful if it offered suggestions on how to address these issues or what specific comparisons should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first comment suggests that the authors should mention that |Y_t - Y_{t-1}| \\leq c_t almost surely. This is an explicit action that the authors can directly implement by adding the mentioned statement. The second comment points out a typo, suggesting that \\mu_t should be corrected to \\tilde \\mu_t. Both comments are explicit and provide clear actions for the authors to take, making the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L384\" and \"L431,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a statement about the inequality |Y_t - Y_{t-1}| \\leq c_t almost surely and the correction of \\mu_t to \\tilde \\mu_t. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate comments, each of which is a request for clarification or correction. The first comment suggests adding a statement about the inequality |Y_t - Y_{t-1}| \\leq c_t almost surely, which is a factual observation. The second comment points out a typo, suggesting that \\mu_t should be corrected to \\tilde \\mu_t. These are factual statements that do not require justification or evidence to support the claim. Therefore, the comments are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two separate points, each of which is a request for clarification or correction. The first point suggests adding a statement about the inequality |Y_t - Y_{t-1}| \\leq c_t almost surely, which is a factual observation that could enhance the clarity of the paper. The second point points out a typo, suggesting that \\mu_t should be corrected to \\tilde \\mu_t. While these comments are specific and actionable, they do not provide detailed guidance or suggestions for improvement beyond the correction of errors. The feedback is somewhat helpful as it identifies areas for clarity and accuracy but lacks depth and context for the authors to fully address the issues. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion regarding the origin of the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It also provides references to external works that might help the authors understand the topic better. While the comment explicitly points out the need for clarification and provides references, it does not offer specific guidance on how to address the confusion or improve the clarity of the explanation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the confusion regarding the origin of the reward and suggests improving clarity by explaining the network model with equations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful, but the comment itself does not provide sufficient evidence or detailed reasoning to fully support the claim. Therefore, the comment is somewhat verifiable, as it highlights an area for improvement but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the origin of the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that might help the authors understand the topic better. While the comment highlights a critical issue in the paper\\'s clarity, it lacks specific guidance or suggestions on how to address the confusion or improve the explanation. The references are helpful but do not fully address the feedback\\'s lack of actionable advice. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not provide detailed guidance for the authors to follow.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on two issues: the incorrect labeling of Figure 7 in Supplementary Page 31 and the need to attach each theorem and corollary to its corresponding proof. It also mentions the primary concerns of motivation, methodology soundness, and experiment persuasion. While the comment identifies specific issues, it lacks concrete guidance on how to address them, such as suggesting specific changes to the labeling or providing detailed instructions on how to attach the theorems and corollaries. The authors are left with a general understanding of what needs to be improved but without actionable steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (the labeling of Figure 7 to Figure 12) and suggests attaching each theorem and corollary to its corresponding proof to improve clarity. This provides clear guidance on how to address the issues raised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations, such as identifying the incorrect labeling of Figure 7 in Supplementary Page 31 and suggesting the need to attach each theorem and corollary to its corresponding proof. It also provides an overall positive assessment of the paper, mentioning its novelty, clear theoretical guarantees, and convincing empirical results. These statements are factual and do not contain subjective opinions or claims that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two issues: the incorrect labeling of Figure 7 in Supplementary Page 31 and the need to attach each theorem and corollary to its corresponding proof to enhance clarity for the reader. It also acknowledges the paper\\'s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results. However, the comment could be more helpful if it offered suggestions on how to address the primary concerns of motivation, methodology soundness, and experiment persuasion. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to specific areas for improvement and highlights the paper\\'s positive aspects.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the definition and selection of action verbs and action frames, prompting the authors to clarify their choices. While it identifies specific areas that need clarification, it does not provide explicit instructions on how to address these questions. The authors can infer that they need to provide more detailed explanations or examples, but the comment lacks concrete guidance on what specific information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the determiner missing in Section 3 and the selection of action verbs and action frames, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making a subjective claim or opinion. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the definition and selection of action verbs and action frames, prompting the authors to clarify their choices. It identifies specific areas that need clarification, such as the determiner missing in Section 3 and the selection of action verbs and action frames. While the comment provides some guidance on what needs to be addressed, it lacks depth and does not offer specific suggestions or examples on how to improve the draft. The authors are given a direction to clarify their choices, but the feedback could be more comprehensive to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a single spelling error on line 32 of page 1, suggesting that the word \"Empiically\" should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the spelling error of \"Empiically\" on line 32. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation, specifically pointing out a spelling error (\"Empiically\" should be \"Empirically\") on line 32 of page 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific and minor issue with the paper, namely a spelling error on line 32 of page 1. By pointing out this mistake, the authors are given clear and actionable feedback to correct a minor oversight in their draft. This type of feedback is valuable as it ensures the paper\\'s accuracy and professionalism. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalizability of a model to different numbers of entities, specifically mentioning Figure 3 of INs as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the generalizability of the model. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or improvements are needed to enhance the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on how to generalize a model to different numbers of entities. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, referencing Figure 3 of INs as an example. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the generalizability of a model to different numbers of entities. It references Figure 3 of INs as an example, which provides some context for the reviewer. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve the generalizability of their model. Without actionable feedback or constructive advice, the comment is barely helpful, as it points out a problem but does not provide a path for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or make the method less straightforward. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not specify which part of the paper discusses the novelty or the method, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity regarding what aspects of the novelty or method are not adequate, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide specific feedback or suggestions on how to enhance the novelty or make the method less straightforward. Without actionable advice or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper\\'s framing may oversell the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors could address this issue. The comment lacks actionable details, such as recommending changes to the framing or suggesting ways to clarify the contribution. Without explicit instructions or concrete suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. The authors cannot confidently determine where the issue is located, making this comment weakly grounded. The comment is specific in identifying the issue with the framing, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s framing oversells the method, making the contribution less clear. However, the comment does not provide specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the paper\\'s framing, suggesting that it may oversell the method and make the contribution less clear. While this observation highlights a potential weakness, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. Without detailed feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or provide detailed guidance on how to structure the presentation. The authors are given an idea of what needs to be improved but are left to infer the specific actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the model description or methodology sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting improvements, such as presenting the process in steps and using a notation table, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the description or understanding of the model. The suggestion is somewhat verifiable as it provides a general direction for improvement but lacks the necessary evidence or justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the model description, suggesting that presenting the generative process in separate steps could enhance understanding. It also recommends reducing the number of symbols and using a notation table, which could improve clarity. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples or guidance on how to implement these improvements. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the paper. It suggests that the authors consider using a different color or a larger font for the \"bold\" text in Figure 2 to enhance the visibility of the human-identified rationales. This feedback is clear and actionable, as it specifies a concrete way to improve the presentation of the figures. Additionally, the comment acknowledges that identifying rationales is not a simple problem, which adds context to the feedback. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure by suggesting a change in color or font size to enhance the visibility of the human-identified rationales. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is well-organized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution by suggesting another color or a bigger font. This feedback is mostly verifiable as it provides a logical reasoning for the complexity of identifying rationales and acknowledges the paper\\'s organization. However, the suggestion to improve the figure could be more specific, such as recommending a specific color or font size. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the clarity and visibility of Figure 2. It identifies that the figure is cluttered and suggests a solution by proposing a change in color or font size to enhance the visibility of the human-identified rationales. This feedback is clear and constructive, offering a concrete way for the authors to improve the presentation of their data. Additionally, the comment acknowledges the complexity of identifying rationales for more complicated NLP tasks like machine translation, which adds context and relevance to the feedback. Overall, the comment is highly helpful as it guides the authors on how to improve the clarity and readability of their figures, while also acknowledging the challenges in the field.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should verify the effectiveness and universality of the Flipped-QA framework beyond LLM-based models, specifically mentioning HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for further verification, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the Flipped-QA framework is a general framework for various generative VideoQA models, but the authors only apply it to LLM-based models. It recommends verifying the effectiveness and universality of the framework with non-LLM-based models like HiTeA and InternVideo. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the application or evaluation of the Flipped-QA framework. The suggestion is specific in terms of what needs to be addressed, namely the need for further verification with non-LLM-based models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the Flipped-QA framework is a general framework for various generative VideoQA models but is only applied to LLM-based models. The reviewer suggests that verifying the effectiveness and universality of the framework with non-LLM-based models like HiTeA and InternVideo would be beneficial. This claim is somewhat verifiable as it provides a logical reasoning for expanding the application of the framework, but it lacks specific examples or references to support the claim. The authors would need to make a concerted effort to verify the claim themselves, which makes the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the application of the Flipped-QA framework, suggesting that it is a general framework for various generative VideoQA models but is only applied to LLM-based models. The reviewer recommends further verifying the effectiveness and universality of the framework by testing it with non-LLM-based models like HiTeA and InternVideo. This feedback is clear and actionable, providing the authors with a specific direction for improving their work by expanding the scope of their experiments. However, the comment could be more helpful if it included examples or references to similar studies that have successfully tested the framework with non-LLM-based models. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"existing methods\" that it builds upon, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concerns about the lack of theoretical novelty and the need for addressing these concerns. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer provides references to Clopper-Pearson intervals and Gaussian elimination, suggesting that the method is not innovative. However, the comment does not provide detailed reasoning or examples to support why these existing methods are insufficient or how the proposed method could be improved. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique to address it effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern about the proposed method, noting that it primarily builds upon existing methods and lacks significant theoretical novelty. It acknowledges the authors\\' willingness to improve their score and encourages them to address these concerns. However, the comment does not provide specific suggestions or guidance on how to improve the theoretical novelty or address the concerns effectively. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. While it raises an interesting question, it does not provide any guidance or suggestions on how the authors should address this issue or what specific changes they should make. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation process, but without explicit references to sections or details, the authors cannot confidently determine where this question fits within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the concatenation of text input by the four text elements of an object. While it identifies a potential area of interest, it lacks depth and does not provide any guidance or suggestions on how the authors might address this question or what implications it might have for their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the sentence in lines 12-17 of the abstract is cumbersome and could be made clearer. While it does not provide specific guidance on how to improve the clarity, it implies that the authors should revise the sentence to make it more concise and easier to understand. The action is implicit but concrete, as it provides a clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence in lines 12-17 of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the sentence. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in lines 12-17 of the abstract is cumbersome and could be made clearer. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 12-17. It points out that the sentence is cumbersome and suggests that it could be made clearer. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to revise the sentence to enhance its clarity. The feedback is somewhat helpful as it directs the authors\\' attention to a specific issue but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a trade-off between head and tail categories but does not fully investigate the trade-off for baselines. The reviewer suggests that the authors should investigate the trade-off for baselines, such as by changing hyperparameters in Decouple [Kang et al.]. This feedback provides a clear and explicit action for the authors to take, which is to investigate the trade-off for baselines. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests investigating the trade-off for baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. The comment also suggests that the trade-off between head and tail categories has not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. This provides a logical and somewhat verifiable claim, as it offers a specific example of an area that needs further investigation. However, the comment could be strengthened by providing more detailed evidence or references to support the claim about the performance of Decouple [Kang et al.] and the trade-off for baselines. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories, as shown in Table 5, but points out that similar trade-offs have not been fully investigated for baselines. The comment suggests that the authors should investigate the trade-off for baselines, such as by changing hyperparameters in Decouple [Kang et al.], which could significantly improve tail accuracy while slightly decreasing head accuracy. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing these points, the authors can enhance the rigor and comprehensiveness of their analysis, making the paper more robust and ready for submission. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and the implications of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), but not $N(s, a)$. While the comment implies that the authors should provide a rationale for the specific choice of $\\\\lambda_t$ and consider the implications of excluding $\\\\epsilon$, it does not explicitly instruct the authors to do so. The questions are somewhat actionable as they guide the authors to provide a deeper understanding of the algorithm, but the feedback lacks concrete steps for implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed E2W algorithm\" and \"Equation (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the specific choice of $\\\\lambda_t$ and the implications of not including the exploration parameter $\\\\epsilon$. Additionally, it questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), providing clear guidance on what aspects of the algorithm need further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and the implications of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), but not $N(s, a)$. These questions are logical and relevant, as they seek to understand the rationale behind certain choices in the algorithm. However, the comment does not provide specific references or detailed explanations to support the claims, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the questions raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the specific choice of parameters in the proposed E2W algorithm, particularly the exploration parameter $\\\\epsilon$ and the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7). This feedback is valuable as it prompts the authors to consider the implications of these choices and to provide a deeper understanding of the rationale behind them. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative approaches. Overall, the comment is somewhat helpful as it directs the authors to consider the implications of their choices, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the evaluation, specifically the reliance on four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for additional datasets, but it is vague in terms of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, which is the limited scope of the evaluation and the potential unreliability due to the reliance on only four datasets. The suggestion to include more scenarios like the LLaVA benchmark is also specific, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited and relies on four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing the admission in Figure 4(5) and suggesting that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This provides a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the LLaVA benchmark, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation by pointing out that it relies heavily on four OCR QA datasets, which may be unreliable. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for expanding the evaluation to include additional datasets, which could enhance the robustness and credibility of the results. However, the comment could be more helpful if it explained why the LLaVA benchmark is particularly relevant or how it might be integrated into the evaluation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might consider mentioning that pi is a function from R^m to \\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\xce\\x94\\"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it critiques the authors\\' method of generating tweets by mentioning that the authors\\' embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to reconsider the realism of their evaluation and explore alternative methods for generating tweets. The action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the method of generating tweets by averaging artificial tweets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the realism of the evaluated tweets and questions the method of generating tweets by averaging artificial tweets. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim that the evaluation is not realistic. The suggestion to consider alternative methods for generating tweets is somewhat vague, leaving the authors to infer the need for more detailed evaluation. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks sufficient evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it critiques the authors\\' method of generating tweets by mentioning that the authors\\' embeddings are initialized by averaging artificial tweets. This feedback is clear and actionable, as it highlights areas where the evaluation could be improved and suggests alternative methods for generating more realistic tweets. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it directs the authors to consider the realism of their evaluation and offers a constructive critique.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include \"keypoint detection results\" in the experiments section. This is a direct and concrete action, as it specifies exactly what needs to be added to the paper. The authors know exactly what information is expected and how to incorporate it into their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"keypoint detection results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the experiments section, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for improving the paper. By recommending that the keypoint detection results be included in the experiments section, the reviewer offers a clear and direct way for the authors to enhance the clarity and completeness of their work. This feedback is valuable as it guides the authors on how to present their results more effectively, ensuring that readers can better understand and appreciate the findings. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment implies that the authors should make this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. However, the suggestion is clear enough for the authors to understand the need for this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, nor does it provide detailed guidance on how to conduct the comparison. The authors can infer that it relates to the results or comparisons section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide specific examples or detailed reasoning to support why the ternary potential is the primary factor or how the proposed model compares to existing models. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis for the suggestion and potentially conduct additional research to fully understand the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison that could enhance the understanding of the model's performance. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. To be more helpful, the comment could provide detailed suggestions on which models to compare, what metrics to use, or how to interpret the results. As it stands, the feedback provides a general direction but lacks depth and actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" might be misused. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific actions or clarifications to be made. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" might be misused. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" might be misused. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" might be misused. This is a relevant point that could prompt the authors to reconsider their terminology or methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential area for consideration, it does not offer actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the use of hyperparameters and possibly extend the curve further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"soft labels\" and \"CRM and Cross entropy,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the potential for the results to be impressive but not fully understood. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results, at first blush, seem impressive but expresses concern about the use of subpar hyperparameters. While the comment identifies potential issues, it lacks specific examples or references to support the claims about the use of subpar hyperparameters or the need for further curve extension. This makes the claim somewhat verifiable, as the authors would need to make additional efforts to understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results, at first blush, seem impressive but expresses concern about the use of subpar hyperparameters. This feedback is somewhat helpful as it identifies potential issues with the methodology and results, prompting the authors to reconsider their approach and potentially improve their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns or improve the methodology. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It recommends adding more evaluation on classifying unseen words and proposes adding translations to Figure 6 for non-Chinese speakers. While the comment provides a clear action to take, it lacks specific guidance on how to implement the evaluation or the translations. The authors are given a general direction but need more detailed instructions to fully execute the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It recommends adding more evaluation on classifying unseen words and proposes adding translations to Figure 6 for non-Chinese speakers. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental setup or results, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting additional evaluations and translations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It recommends adding more evaluation on classifying unseen words and proposes adding translations to Figure 6 for non-Chinese speakers. While the comment identifies a potential issue with the presentation of the experiment, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to add translations is somewhat helpful, but the overall comment could be more verifiable with additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. It recommends adding more evaluation on classifying unseen words and proposes adding translations to Figure 6 for non-Chinese speakers. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to implement these suggestions or what specific evaluations should be included. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides specific references to the missing symbol in the algorithm and suggests that the authors should include it. Additionally, the comment mentions that the references are not properly formatted. While the comment identifies specific issues, it does not provide detailed guidance on how to address them, such as suggesting font size changes or specific formatting adjustments. The action is explicit but somewhat vague, as the authors know what needs to be done but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in table 1 and the missing gradient symbol in Algorithm 1, as well as suggesting specific references for the missing symbol. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations about the paper, such as the font size in Table 1 being too small and the gradient symbol being missing in Algorithm 1. It also provides references to external works, which are relevant but not directly related to the claims being made. The comment does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as the font size in Table 1 being too small and the gradient symbol being missing in Algorithm 1. It also provides references to relevant works, which could be helpful for the authors to address these issues. However, the comment lacks depth and does not offer detailed guidance or suggestions on how to improve the paper. It could be more helpful if it provided specific suggestions on how to address the identified issues or improved the formatting. Therefore, the comment is somewhat helpful, as it provides some direction but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should render Figure 1 in a more natural way by using the bracketed arguments in the citation. However, it does not provide explicit instructions on how to implement this suggestion or what specific changes are needed. The comment also mentions that the authors should consider how this change might impact hyperref, but it does not provide guidance on how to address this concern. The action is implicit and vague, leaving the authors without clear steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should render Figure 1 more naturally by using the bracketed arguments in the citation. However, it does not specify which part of the paper Figure 1 is located in or where the bracketed arguments are mentioned. Additionally, the comment mentions the potential impact on hyperref, but it does not provide specific guidance on how to address this concern. Without clear references or detailed instructions, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should render Figure 1 more naturally by using the bracketed arguments in the citation. However, the comment does not provide any reasoning, evidence, or examples to support why this change would be beneficial or how it would improve the figure. The mention of hyperref is vague and does not offer a clear explanation of the potential impact or how to address it. Without detailed justification or examples, the claim is difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should render Figure 1 more naturally by using the bracketed arguments in the citation, specifically mentioning Wright et al. (1934) and Figure 1. However, it does not provide any explanation or guidance on how this change might impact the figure or how it could be implemented. Additionally, the mention of hyperref is unclear and does not offer any specific suggestions or examples to help the authors understand the potential impact of this change. While the comment identifies a specific area for improvement, it lacks depth and actionable advice, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix as a place where some discussion is present, but it does not provide detailed guidance on what aspects of the computational aspects are lacking or how they could be improved. The comment also mentions the experiments being performed on small datasets, but it does not specify which parts of the paper these issues pertain to. While the authors can infer that the computational aspects are a concern, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors do not discuss computational aspects in detail, particularly regarding the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by mentioning the appendix as a place where some discussion is present, but it is unclear whether this discussion is sufficient. The comment also highlights the complexity of solving several LPs in high dimensions, which is a significant challenge for practical applications. However, the reviewer does not provide specific examples or references to support the claim about the practical usefulness of the proposed methods. This lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides a general understanding of the issue but lacks specific examples or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in relation to the practical usefulness of the proposed methods for high dimensions. It highlights the complexity of solving several LPs in high dimensions and notes that the experiments are performed on small datasets, which raises questions about the applicability of the methods. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it provides insight into a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies specific errors in the equations and provides clear guidance on how to correct them. It points out that the '+' sign after \\nu_j should be a '-' sign, and that there should be a '-' sign before \\sum_{j=1}^m in the definition of B under Line 503. Additionally, it suggests changing the '-' sign after \\nu_j to a '+' sign in Line 504. These are direct and concrete actions that the authors can take to improve their draft. The comment is highly actionable as it provides explicit instructions on how to correct the errors, making it easy for the authors to implement the suggested changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the equations, such as the incorrect signs in the '+' and '-' signs. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations about the equations in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific errors in the equations, such as incorrect sign placement in the equations under Lines 502, 503, and 504. It provides clear and actionable feedback by suggesting that the '+' sign after \\nu_j should be a '-' sign, and that there should be a '-' sign before \\sum_{j=1}^m in the definition of B under Line 503. Additionally, it suggests changing the '-' sign after \\nu_j to a '+' sign in Line 504. These detailed corrections are highly helpful as they directly address issues in the equations, ensuring that the paper is accurate and clear. The comment is mostly helpful as it provides specific guidance on how to correct the errors, making it valuable for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a potentially interesting baseline could be to compare it to a deeper ResNet with parameter sharing, which would be equivalent to an ODE net with a fixed time-step Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the ResNet in the experiments shares parameters between the residual blocks, and it suggests a potential baseline for comparison. The comment provides a clear direction for further exploration, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether the ResNet in the experiments shares parameters between the residual blocks. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the ResNet used in the experiments, asking whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity and comparability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what potential implications it might have. While it identifies a potential area for improvement, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting it is an odd choice given that the question model is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is considered odd or why it is problematic. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words. This feedback points out a potential issue with the methodology, which could be a source of confusion or inefficiency. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional ad-hoc post-analysis might be required to extract shared motifs and explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this lack of clarity or what specific steps they should take to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or examples to clarify the methodology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional ad-hoc post-analysis might be required to extract shared motifs and explain a set of instances, which is a specific critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional ad-hoc post-analysis might be required to extract shared motifs and explain a set of instances, which seems necessary even with the proposed method. The comment provides a logical reasoning and a specific example (Line 48) to support the claim, making it mostly verifiable. However, it could be strengthened by providing more detailed examples or references to similar studies that demonstrate the need for additional analysis. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and appears to require additional ad-hoc post-analysis to extract shared motifs and explain a set of instances. This feedback is valuable as it highlights a potential gap in the clarity of the methodology, which could be confusing for readers. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve the explanation. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that Non-convexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific properties of Z should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 182--184, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential non-convexity of the function Z and its impact on the SGD convergence. However, the comment lacks specificity regarding what properties of Z should be considered or how the authors might address this issue. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that Non-convexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the assertion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (lines 182--184) and raises a concern about the potential non-convexity of the function Z and its impact on the SGD convergence. While the comment highlights an area of potential concern, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or what specific properties of Z should be considered. The feedback is somewhat helpful as it points out a potential weakness, but it does not offer detailed guidance for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. While these issues are identified, the comment does not provide explicit guidance on how the authors should address them. It does not specify which sections are confusing or which models should be compared, nor does it offer suggestions on how to resolve the missing citations or unreferenced notation. The authors are left with a general understanding of the issues but without concrete steps to improve their draft. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. However, it does not specify which sections or parts of the paper are confusing or where the missing citations occur, making it difficult for the authors to pinpoint the exact areas needing attention. The comment also lacks specificity regarding the unreferenced notation, as it does not provide examples or details on how to address this issue. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises several claims, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of specific references or detailed explanations makes it challenging for the authors to verify the claims and improve their work. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some indication of issues but lacks sufficient detail for the authors to fully understand and address them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment acknowledges the effort made by the authors to acknowledge limitations, but it does not offer actionable advice or detailed feedback to help the authors improve their draft. The feedback is somewhat helpful as it points out areas needing attention, but it lacks depth and specificity, making it challenging for the authors to fully understand and address the issues. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). While it identifies a specific part of the paper that requires clarification, it does not provide any guidance on how the authors should address this question or what changes should be made to the equation. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2), which could be a significant oversight or a point of confusion for readers. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might clarify or address this confusion. The comment lacks actionable feedback or constructive advice, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific lines in the SuppMat that should be changed from red to green. This provides clear and direct instructions on what the authors need to do to improve their draft. The actions are concrete, as they specify the exact lines that need to be updated, and the feedback is specific, allowing the authors to make the necessary changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, providing detailed guidance on the corrections needed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific lines in the SuppMat that should be changed from red to green, providing clear and actionable feedback. This guidance is valuable as it directly addresses a formatting issue that could impact the clarity and readability of the paper. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall presentation of the SuppMat. Despite this, the feedback is mostly helpful as it offers a concrete way for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of concern regarding the evaluation of online learning approaches. It suggests that a proper comparison against online learning and reinforcement learning (RL) is missing, and it questions why online learning cannot be used. The reviewer implies that the authors should address these issues by providing a comparison of retraining costs and incremental updates in online learning. However, the comment does not explicitly instruct the authors to make these comparisons or provide specific guidance on how to do so. While the action is implied, it is not as clear as it could be, leaving the authors with a somewhat actionable comment.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper, allowing the authors to accurately identify the sections being addressed. It is also specific because it raises several questions about the evaluation of online learning formulations, including the absence of a proper comparison against online learning approaches and reinforcement learning (RL), the reasons for the inability of online learning to be used, and the challenges of including retraining cost in the evaluation. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about the evaluation of online learning approaches, suggesting that a proper comparison against online learning and reinforcement learning is missing. The reviewer questions why online learning cannot be used and highlights the absence of a discussion on retraining cost. The comment is somewhat verifiable as it provides a logical basis for the critique by questioning the omission of important aspects in the evaluation. However, it lacks specific examples or references to support the claims, which would make it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically regarding the evaluation of online learning approaches. It points out that a proper comparison against online learning and reinforcement learning is missing, and questions why online learning cannot be used. The comment raises important questions about the practical considerations and challenges of including retraining cost in the evaluation. While it provides a clear direction for improvement, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it highlights critical areas for enhancement, but it lacks detailed guidance on how to implement the suggested improvements.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. It encourages the authors to conduct a comprehensive comparison with these works. While the comment provides a clear action\u2014conducting a comparison\u2014it does not specify how to conduct this comparison or what aspects to focus on. The authors are given a direction but lack detailed guidance on how to execute the action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific details or examples of how these references are relevant to the current work or how a comparison would enhance the paper. While the references are mentioned, the lack of detailed justification or explanation makes the claim somewhat verifiable, as the authors would need to infer the significance of these references themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. It encourages the authors to conduct a comprehensive comparison with these works, which could enhance the paper\\'s contribution and relevance. While the comment highlights a critical area for improvement, it lacks specific guidance on how to conduct the comparison or what aspects to focus on. This limits the comment\\'s helpfulness, as it provides a clear direction but does not offer detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific steps they should take to support their claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the slight improvement reported in these tables and the claim that experimental results prove the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the slight improvement reported in Tables 6 and 7 does not support the claim that experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results and the claim made in the paper regarding the effectiveness of the proposed prompts. It points out that the slight improvement reported in Tables 6 and 7 does not support the claim, which is a critical observation that could impact the credibility of the experimental results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the analysis, suggesting that it could be insufficient and that there could be different designs that could be explored, such as experiments or analysis with different sampling intervals and sample sizes. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to explore different designs but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the analysis of Cycle FC align features, specifically mentioning that the analysis is \"slightly insufficient.\" However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment suggests exploring different designs, such as experiments or analysis with different sampling intervals and sample sizes, but it does not provide specific guidance on where these suggestions should be integrated into the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the analysis of Cycle FC align features is \"slightly insufficient,\" suggesting that there could be different designs that could be explored, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of specific examples or detailed reasoning makes the claim borderline verifiable, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analysis of Cycle FC align features, suggesting that it could be insufficient and that there could be different designs that could be explored, such as experiments or analysis with different sampling intervals and sample sizes. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what specific designs they should consider. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. It suggests that the authors should provide experimental results to demonstrate the algorithms' effectiveness in practice. While the comment highlights a potential issue, it does not explicitly instruct the authors to conduct experiments or specify which aspects of the algorithms should be tested. The action is implicit and somewhat vague, as the authors need to infer that they should provide experimental results to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the practical performance of the algorithms, particularly the numerical instability of Vandermonde matrices, and suggests providing experimental results to demonstrate the algorithms\\' effectiveness. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of Vandermonde matrices and their known numerical instability. The reviewer supports this claim by referencing the large size of $n$, $k$, and $L$ and the potential for failure even for moderate-sized values. However, the comment lacks specific examples or references to support the claim about the numerical instability, which would strengthen the verifiability. The suggestion to provide experimental results is a logical step, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern about the practical performance of the proposed algorithms, particularly the use of Vandermonde matrices, which are known to be numerically unstable. It highlights the potential for failure even for moderate-sized values of $n$, $k$, and $L$. The comment suggests that providing experimental results would enhance the paper\\'s credibility and make it more convincing. This feedback is clear and actionable, as it directs the authors to address a critical issue in their work. However, it could be more helpful if it provided specific guidance on which aspects of the algorithms should be tested or how to mitigate the numerical instability. Overall, the comment is mostly helpful as it effectively points out a potential weakness and offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that standard deviations are not displayed, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to ensure that the best method is indeed the best and to determine if other RF configurations are close to the best one. While the comment implies that the authors should include standard deviations, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the exact steps to include standard deviations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the lack of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue is related to, such as a particular figure or table where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment identifies a specific concern, it lacks specificity in terms of how the authors should address this issue, such as by including standard deviations or explaining the methodology. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that standard deviations are not displayed, which raises questions about the validity of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without detailed evidence or reasoning, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation without sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity of the results, as it raises questions about the best method being truly the best and whether other RF configurations are close to the best one. However, the comment does not provide specific guidance on how the authors might address this issue, such as suggesting ways to include standard deviations or explaining why they are important. While it highlights a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification on this aspect of the paper. While the comment implies that the authors should provide an explanation or justification for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not know exactly how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4, indicating what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable request for clarification. By asking for an explanation or justification of this choice, the reviewer prompts the authors to provide additional detail or context that could enhance the transparency and understanding of their work. This feedback is somewhat helpful as it directs the authors to a specific area that needs clarification, but it could be more helpful if it included suggestions on how to address this issue or why this choice is important. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically highlights the need for clarification regarding the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback is clear and provides concrete actions for the authors to take, such as explaining the negative numbers and the implications of the figures. The comment is highly actionable as it directs the authors to specific areas where they need to provide additional information and analysis, ensuring that they know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This level of specificity and grounding makes the comment highly actionable. Therefore, it aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is somewhat verifiable as it provides a logical reasoning for the need of explanations and analysis, but it lacks specific examples or references to support the claim. The authors would need to infer the exact nature of the issues and provide their own analysis to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It highlights the need for clarification regarding the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback is clear and actionable, as it directs the authors to specific areas where they need to provide additional information and analysis. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how similar analyses have been explained in other works. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of RLCD compared to RLAIF, noting that the advantage of RLCD shrinks as the model size increases from 7B to 30B. It suggests that RLCD (or RLCD-Rescore) may not scale well to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this issue and possibly explore ways to scale their method to larger models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the advantage of RLCD over RLAIF and the potential limitation of RLCD in scaling to larger language models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, from 7B to 30B. It suggests that RLCD (or RLCD-Rescore) may not scale well to larger language models that are better at differentiating responses near the decision boundary. While the comment provides some reasoning by referencing the table (Tab. 2), it lacks specific examples or detailed evidence to fully substantiate the claim. The authors would need to make a significant effort to verify the claim, as the reasoning is not fully developed. Therefore, the comment is somewhat verifiable, as it provides some basis but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of RLCD compared to RLAIF, noting that the advantage of RLCD shrinks as the model size increases from 7B to 30B. It suggests that RLCD (or RLCD-Rescore) may not scale well to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or improve their approach. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large datasets like ImageNet. It suggests that the authors should address this scalability issue to maintain practical relevance. While the comment identifies a potential problem, it does not provide explicit guidance on how to address the scalability issue or suggest specific solutions. The action is implicit and somewhat vague, as the authors need to infer that they should consider scalability and provide a solution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large datasets like ImageNet. However, it does not specify which part of the paper this concern is related to, such as a specific section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its concern about scalability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large datasets like ImageNet. The comment suggests that the practical contribution of the paper will be significantly reduced if the scalability issue is not addressed. However, the comment lacks specific examples or references to support the claim that the method cannot be applied to large datasets. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the concern but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large datasets like ImageNet. It suggests that the practical contribution of the paper will be significantly reduced if the scalability issue is not addressed. While the comment identifies a potential weakness in the methodology, it lacks specific suggestions or guidance on how the authors might address the scalability issue. The feedback is somewhat helpful as it highlights a critical area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance boost of the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. The reviewer suggests that comparisons to UNets are necessary, as UNets have shown strong performance on regular gridded domains. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"fractional transform\" and \"UNet operation in the fractional Fourier domain,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance boost of the CoNO model and suggests that comparisons to UNets are necessary, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance boost of the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. The reviewer suggests that comparisons to UNets are necessary, as UNets have shown strong performance on regular gridded domains. While the comment raises a valid point about the potential sources of performance, it lacks specific examples or references to support the claim that UNets have shown strong performance. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the performance boost of the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. The reviewer suggests that comparisons to UNets are necessary, as UNets have shown strong performance on regular gridded domains. This feedback is valuable as it highlights a potential area for improvement by suggesting that the authors should make comparisons to UNets, which could help clarify the source of the performance boost. However, the comment could be more helpful if it provided specific examples or references to support the claim about UNets or offered guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights a specific aspect of the method, namely the calculation of all flipped previous layer outputs into the current layer in algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. While the action is explicit, as it clearly instructs the authors to include a comparison of computation complexity, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific metrics should be considered. Overall, the comment is mostly actionable, as it clearly identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed PSA method, noting that it requires more computation than baselines and highlighting the calculation of all flipped previous layer outputs into the current layer. The comment also suggests a specific area for improvement, namely the inclusion of a comparison of computation complexity in the experiment part. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in algorithm 1. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is specific and provides a clear rationale for the observation, it lacks detailed evidence or references to support the claim. The authors would need to conduct their own analysis to verify the claim, making the comment somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights a specific aspect of the method, namely the calculation of all flipped previous layer outputs into the current layer in algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a concrete suggestion for enhancing the experimental evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct the computation complexity comparison or what specific metrics should be considered. Overall, the comment is mostly helpful, as it effectively guides the authors on how to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger and increasing the size of certain labels like V_mem, Th_i, and U_i^t. It also points out the need for a \"table\" manner to emphasize details, like epochs and number of parameters, in comparison with other state-of-the-art Transformer designs. While the comment provides explicit actions and concrete details on how to implement these changes, it could be more helpful if it included suggestions on how to present this information in a table or what specific metrics should be included. Overall, the comment is mostly actionable as it clearly identifies areas for improvement and provides concrete guidance on how to implement them.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the font size in figure 2. Additionally, it provides specific suggestions for improvement, such as increasing the font size of certain labels and using a \"table\" manner to emphasize details. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the font size, label size, and the need for more detailed comparisons with other state-of-the-art Transformer designs. While the comment provides specific examples of font size issues, it lacks detailed reasoning or references to support the claim that these changes would improve the clarity or effectiveness of the figures. The suggestion to use a \"table\" manner for comparisons is vague without further explanation or examples of what specific metrics should be included. Overall, the comment is somewhat verifiable as it identifies specific issues but lacks detailed justification or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, noting issues with font size and suggesting improvements like increasing the size of certain labels and using a \"table\" manner to emphasize details. It also points out the need for more detailed comparisons with other state-of-the-art Transformer designs, which could help justify the improved accuracy. However, the comment could be more helpful if it provided examples of what specific metrics or comparisons should be included in the \"table\" manner. Overall, the comment is mostly helpful as it identifies areas for improvement and offers concrete suggestions, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps\" because it is unclear. It provides a specific action by referencing pages 5 and 3, line, allowing the authors to know exactly what needs to be revised. The comment is clear and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"P. 5, p. 3, l.\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and a specific instruction to rewrite a sentence. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" by asking for a rewrite. This feedback is clear and actionable, as it provides a direct request for improvement and specifies the pages where the issue is located. By addressing this issue, the authors can enhance the clarity and coherence of their draft. However, the comment could be more helpful if it offered suggestions on how to rewrite the sentence to improve its comprehensibility. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. It suggests that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks if there are any other motivations for using PBSD besides improving the discriminative representation of tail classes. While the comment identifies a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the motivation behind PBSD. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivation behind the use of PBSD. The comment further highlights that the paper is primarily motivated by supervised contrastive learning, which is the DSCL part. The reviewer asks if there are any other motivations for using PBSD besides improving the discriminative representation of tail classes. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. The reviewer references the ablation study, which suggests that the performance gain is mostly from PBSD, but the paper is primarily motivated by supervised contrastive learning. The comment asks if there are any other motivations for using PBSD besides improving the discriminative representation of tail classes. This claim is somewhat verifiable as it highlights a potential inconsistency in the paper\\'s motivation and suggests a need for clarification. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the main contribution, specifically questioning the motivation behind the use of PBSD. It points out that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning, which is the DSCL part. The reviewer asks if there are any other motivations for using PBSD besides improving the discriminative representation of tail classes. This feedback is somewhat helpful as it highlights a potential inconsistency in the paper\\'s motivation and suggests a need for clarification. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as providing more context or examples. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the tester for the spread parameter, specifically asking if it yields an (\\\\epsilon,\\\\delta)-identity tester. It also questions how it handles certain pairs, such as when \\\\phi = \\\\phi{0} but dK(\\\\pi{0}, \\\\pi) is large. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the tester and its handling of specific cases. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific section or figure in the paper. It also specifies the issue by questioning whether the tester for the spread parameter yields an (\\\\epsilon,\\\\delta)-identity tester and how it handles certain pairs, such as when \\\\phi = \\\\phi{0} but dK(\\\\pi{0}, \\\\pi) is large. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the tester for the spread parameter and its ability to yield an (\\\\epsilon,\\\\delta)-identity tester. It questions how it handles specific cases, such as when \\\\phi = \\\\phi{0} but dK(\\\\pi{0}, \\\\pi) is large. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the tester is inadequate. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the question but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the tester for the spread parameter, questioning whether it yields an (\\\\epsilon,\\\\delta)-identity tester and how it handles certain cases, such as when \\\\phi = \\\\phi{0} but dK(\\\\pi{0}, \\\\pi) is large. This feedback is somewhat helpful as it identifies a potential area of confusion or lack of clarity in the paper. However, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the clarity of their explanation. While it points out a relevant concern, the comment lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the description of the \"active learning pipeline\" method, suggesting that it might be misleading if it is not the same as traditional active learning. However, it does not provide explicit guidance or suggestions on how the authors should clarify this description or address the potential misconception. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the description of the \"active learning pipeline\" method, suggesting that it might be misleading if it is not the same as traditional active learning. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the distinction between the two methods, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the description of the \"active learning pipeline\" method, suggesting that it might be misleading if it is not the same as traditional active learning. The comment provides a logical reasoning by pointing out that the distinction between the two methods is important for clarity. However, it lacks specific examples or references to support the claim that the description is misleading. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical issue regarding the description of the \"active learning pipeline\" method, suggesting that it might be misleading if it is not the same as traditional active learning. This is an important point that could lead to confusion for readers, as the distinction between the two methods is crucial for understanding the methodology. The comment prompts the authors to clarify this distinction, which is a clear and actionable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to clarify the distinction or examples of how the two methods differ. Overall, the comment is mostly helpful as it identifies a critical issue and offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It also proposes an alternative approach of a self-supervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for a self-supervised approach and how to incorporate it into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the proposed method in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It suggests an alternative approach of a self-supervised pretraining approach without annotations, which could be more appealing. However, the comment does not specify which part of the paper discusses the method or the annotation requirement, making it weakly grounded. The suggestion to consider a self-supervised approach is specific, but without explicit references to the method or its implementation, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It suggests an alternative approach of a self-supervised pretraining approach without annotations, which could be more appealing. However, the comment lacks specific examples or detailed reasoning to support why the proposed method is limited or how the alternative approach could be more effective. The suggestion is somewhat verifiable, as it provides a logical argument but lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach of a self-supervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it points out a potential weakness in the methodology and provides a constructive suggestion for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement the self-supervised approach. Overall, the comment is mostly helpful as it directs the authors toward a potential solution to enhance the applicability of their method.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after [citation],\" instead of just \"attain greater expressivity.\" It also recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions\u2014changing the language in the abstract and including learning curves\u2014it does so in a concrete manner, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides the authors with clear direction on how to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests changes to the abstract, specifically recommending a more precise measurement of expressivity and the inclusion of learning curves for all experiments. While the comment provides a logical reasoning for the changes, it lacks specific examples or references to support the claim that the current language is insufficient or inaccurate. The suggestion to include learning curves is reasonable, but the lack of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the feedback, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the abstract section of the paper. It suggests a more precise measurement for expressivity, which is a clear and constructive suggestion. Additionally, it recommends including learning curves for all experiments, which could help the authors better understand and present their results. This level of detail and specificity is valuable for the authors, as it guides them on how to improve their abstract and enhance the clarity of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the paper\\'s motivation and suggests that the authors should demonstrate the methodology\\'s use on tasks involving domain adaptation. While the comment implies that the authors should provide examples of how the method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of domain adaptation tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"results mapping one RGB image to another RGB image,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a clear application or motivation for the proposed method. The comment suggests that the authors should demonstrate the methodology\\'s use on tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation of the paper and suggests that the method demonstrated is unclear in terms of its application and utility. The reviewer provides a logical reasoning by pointing out that the results are limited to mapping one RGB image to another with a different style, which does not necessarily demonstrate the need for domain adaptation or its practical applications. However, the comment lacks specific examples or references to support the claim that the method could be useful in real-world scenarios. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s motivation by questioning the clear application and utility of the proposed method. It points out that the results demonstrated are limited to mapping one RGB image to another with a different style, without addressing the need for domain adaptation or its practical applications. The comment suggests that the authors should demonstrate the methodology\\'s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a concrete application of the method. However, it could be more helpful if it included examples of such tasks or detailed guidance on how to implement them. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete guidance on how the authors should improve their draft. It explicitly instructs them to clarify the comparison against other models in the experiments, specifying that the value of the used ranks for all models is omitted, making a fair comparison impossible. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters to demonstrate the superiority of TW over TT and TR. This feedback is clear and provides specific actions for the authors to take, such as computing the number of model parameters by adding the number of entries of all core tensors for each model. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and \"comparison against other models,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unclear comparison against other models and the omission of the value of the used ranks, which makes a fair comparison impossible. The comment provides a detailed suggestion on how to improve the comparison by comparing tensor completion results for all models with the same number of model parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making a fair comparison impossible. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters to demonstrate the superiority of TW over TT and TR. The comment provides a logical reasoning by explaining the importance of comparing results with the same number of model parameters to ensure fairness. However, it lacks specific examples or references to support the claim about the omission of rank values, which could strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but requires additional evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a critical issue with the experimental comparison against other models. It points out that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. The reviewer provides a specific suggestion to address this issue by comparing tensor completion results for all models with the same number of model parameters, which would help demonstrate the superiority of TW over TT and TR. This feedback is clear, actionable, and constructive, empowering the authors to make significant improvements to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" as ATA is reported to be better than FP according to the results in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include ATA in the comparison. The suggestion is concrete and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of \"ATA\" in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" because ATA is reported to be better than FP according to the results in Table 1. This claim is somewhat verifiable as it provides a logical reasoning for why ATA should be included in the comparison, based on the results in Table 1. However, the comment lacks specific examples or references to support the claim that ATA is indeed better than FP. Providing more detailed evidence or examples would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in Table 2, noting that the proposed method is only compared to \"LFP\" under the leave one out setting, despite ATA being reported as better than FP in Table 1. This feedback is clear and actionable, as it suggests that including ATA in the comparison would be more convincing. By providing a specific suggestion for improvement, the comment empowers the authors to enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why ATA is considered a better comparison or provided additional context on the significance of this comparison. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and offers a clear path for enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the normalization module, suggesting that it appears different in two versions but is described as the same in the text. It also points out the need for standardization of pictograms and provides specific feedback on Fig. 4, noting that the chosen symbols overlap. Additionally, the comment mentions minor issues with the text, such as overlapping symbols in Fig. 4 and unclear text on page 4 after equation. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors can infer that they need to standardize the pictograms and address the overlapping symbols issue. However, the comment lacks detailed guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. Additionally, it provides specific feedback on the figures, including the need for standardization of pictograms and the confusion caused by overlapping symbols in Fig. 4. The comment also mentions minor issues with the text, such as overlapping symbols on page 4 after equation. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the normalization module, suggesting that it appears different in two versions but is described as the same in the text. It also mentions the need for standardization of pictograms and provides specific feedback on Fig. 4, noting that the chosen symbols overlap. The comment identifies minor issues with the text, such as overlapping symbols on page 4 after equation. While the comment highlights these concerns, it does not provide detailed reasoning or references to support the claims, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to ensure consistency in their presentation. Additionally, the comment highlights the importance of standardizing pictograms, which is a valuable suggestion for improving the clarity and consistency of the figures. The feedback also points out minor issues with the text, such as overlapping symbols on page 4 after equation, and suggests clarifying the text to avoid confusion. Overall, the comment provides clear and actionable feedback that can help the authors improve the clarity and consistency of their draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' claim regarding the usefulness of subdivision splines for decision boundaries and questions the lack of detail in the theoretical part regarding the proposed algorithm for removing these splines. It explicitly asks for clarification on whether the algorithm requires extra computation cost for space partitioning and suggests that the authors provide more detail on this aspect. The feedback is clear and provides specific actions for the authors to take, such as elaborating on the algorithm and its computational requirements. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim made by the authors regarding the usefulness of subdivision splines for decision boundaries and the goal of pruning. It also specifies the lack of detail in the theoretical part regarding the proposed algorithm for removing these splines, particularly questioning whether the algorithm requires extra computation cost for space partitioning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made by the authors regarding the usefulness of subdivision splines for decision boundaries and the goal of pruning. It suggests that the theoretical part lacks detail on how the proposed algorithm removes these splines, specifically questioning whether it requires extra computation cost for space partitioning. The comment is somewhat verifiable as it raises a logical point about the lack of detail in the theoretical part, but it does not provide specific examples or references to support the claim. The authors would need to further explore the claim and provide more detailed explanations to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' claim regarding the usefulness of subdivision splines for decision boundaries and questions the lack of detail in the theoretical part regarding the proposed algorithm for removing these splines. It raises a critical point about the algorithm\\'s computational requirements, suggesting that the authors need to provide more detail on how the algorithm works and its potential impact on computation. This feedback is clear and actionable, as it directs the authors to clarify and expand on the theoretical part of their paper. However, it could be more helpful if it offered suggestions on how to address the computational concerns or provided examples of similar algorithms. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and depth of their theoretical section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of confusion, but it does not provide explicit or implicit actions for the authors to take. It asks why the output-side layers do not benefit from a particular technique, questions the clarity of Figure 4, and seeks clarification on the details of the Pixel-shuffle operation. Additionally, it mentions the lack of discussion on potential negative societal impacts, but does not offer suggestions on how to address these issues. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed with these points. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several questions and points of confusion, but it does not specify which part of the paper these issues pertain to. It mentions \"Figure 4\" and \"Pixel-shuffle,\" but these references are not explicit enough for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in terms of what needs to be addressed or clarified regarding the output-side layers, the Pixel-shuffle operation, or the societal impact of the work. Without clear guidance, the authors may find it challenging to identify and address these issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises several questions and observations, including the lack of clarity in Figure 4, the potential negative societal impact of the work, and the use of the Pixel-shuffle operation in the super-resolution field. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without detailed explanations or examples, the authors may find it challenging to address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions and points of confusion, including the lack of clarity in Figure 4, the potential negative societal impact of the work, and the use of the Pixel-shuffle operation in the super-resolution field. It also questions the dimensionality after upsampling in Figure 2(b) and the clarity of the Pixel-shuffle details. While the comment identifies areas that need clarification and potential limitations, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need attention, but it lacks actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, despite most baselines not using the 300W-LP dataset. The reviewer questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the experimental methodology and provide more detailed information about the dataset usage. However, it does not explicitly instruct the authors to make these changes, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage and its impact on the results, but the exact steps for doing so are not explicitly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental methodology\" and \"300W-LP dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that the same procedure is used as for baselines, despite most baselines not using the 300W-LP dataset. The comment further questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset for training. It points out that the paper claims the same procedure is used as for baselines, despite most baselines not using the 300W-LP dataset. The reviewer questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This claim is somewhat verifiable as it highlights a potential issue with the experimental setup and methodology, but it lacks specific examples or references to support the claim that 300W-LP provides an unfair advantage. The authors would need to provide more detailed information or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, despite most baselines not using the 300W-LP dataset. This raises a concern about the fairness of the comparison and highlights a potential source of bias. The comment questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify their experimental methodology and address the issue of dataset bias. By providing this guidance, the comment offers valuable insights for improving the paper\\'s rigor and transparency. Therefore, it is mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the formulation of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also questions the assumption that observations are obtained by averaging over the corresponding support. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their formulation. The action is implicit and vague, as the authors are left to infer that they need to reconsider their assumptions or provide additional clarification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and provides specific references to the works \"Law et al., NeurIPS\\'18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the assumption that observations are obtained by averaging over the corresponding support, and it raises concerns about the data aggregation process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the formulation of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It questions the assumption that observations are obtained by averaging over the corresponding support. While the comment identifies specific references to external works, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the critique, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formulation of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It questions the assumption that observations are obtained by averaging over the corresponding support, pointing out that data might be aggregated by other methods, such as simple summation or population weighted averages. The comment also notes that disease incident data is often available in count or rate per number of residents, which could affect the interpretation of the results. While the comment highlights a potential weakness in the formulation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. It suggests that a formal definition of these concepts would be beneficial for readers to understand. While the comment implies that the authors should provide a formal definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a formal definition, but the comment is clear in its suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multi-head attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is lacking in the paper, namely a formal definition of the mathematical concepts, such as multi-head attention, and the purpose of the split arrow in Figure 2. The comment provides a clear direction for improvement by suggesting that a formal definition would be beneficial for readers to understand the architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. The reviewer assumes that the inputs for the attention layer are represented by the query, keys, and values, and asks whether the same vectors are used for keys and values. The comment suggests that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment identifies a potential gap in the paper\\'s explanation, it lacks specific examples or references to support the claim that a formal definition is necessary. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors could improve the clarity and comprehensiveness of their explanation. It points out the lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. The reviewer assumes that the inputs for the attention layer are the query, keys, and values, and asks whether the same vectors are used for keys and values. The comment suggests that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment highlights a potential gap in the explanation, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it points out an area for improvement but lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the assumption that each individual's data is independently and identically distributed (i.i.d.) drawn from the same distribution, which is a prerequisite for the proposed algorithm. The reviewer questions how the \\u00b8m argument in Section 5.1 and Theorem 6 can be applied to prove Theorem 7 if this assumption is not met. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to justify the assumption or provide evidence for its validity, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the results of the proposed algorithm, particularly regarding the assumption of i.i.d. data drawn from the same distribution. It questions how the \\u00b8m argument in Section 5.1 and Theorem 6 can be applied if this assumption is not met. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or theorem. While the authors might have an idea of where this discussion takes place, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the results presented in the paper, specifically regarding the assumption of i.i.d. data drawn from the same distribution. The reviewer claims that this assumption is unjustifiable due to the unique nature of individual users' preferred emojis. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully understood and addressed by the authors.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the assumption of i.i.d. data drawn from the same distribution, which is a prerequisite for the proposed algorithm. It questions how the \\u00b8m argument in Section 5.1 and Theorem 6 can be applied if this assumption is not met, as it is unjustifiable in practice. The reviewer points out that individual users' preferred emojis are very different, which challenges the validity of the assumption. This feedback is somewhat helpful as it highlights a potential weakness in the paper's theoretical foundation, prompting the authors to consider whether the assumption is justified or if additional evidence is needed. However, the comment could be more helpful if it provided suggestions on how to address this issue or what alternative assumptions might be considered. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider tasks that are more complex to challenge the fixed policy, and then compare the results with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their approach to include more complex tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should modify their approach to include more complex tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider tasks that are more complex to challenge the fixed policy, and then compare the results with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a potential improvement by adding more complex tasks and comparing with a baseline, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider tasks that are more complex to challenge the fixed policy, and then compare the results with a reinforcement learning algorithm baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would improve the study. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider tasks that are more complex to challenge the fixed policy, and then compare the results with a reinforcement learning algorithm baseline. This feedback is somewhat helpful as it provides a direction for the authors to explore and potentially improve their work. However, the comment lacks specific guidance on how to implement this suggestion or what specific aspects of the current approach need to be addressed. Additionally, it does not explain why the current approach is insufficient or what specific benefits the authors might gain by incorporating more complex tasks. While the feedback points to a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It questions the extent to which the performance improvement can be attributed to the authors\\' claim regarding the method. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analyses and explanations of the method and its performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiments, noting that they focus too much on the presentation of results and lack comprehensive analyses of the method and experimental outcomes. The comment further questions the extent to which the performance improvement can be attributed to the authors\\' claim, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments focus too much on the presentation of results and lack comprehensive analyses of the method and experimental outcomes. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of \"moving code-switched pretraining from the word level to the sense level, by leveraging word sense-specific information from Knowledge Bases.\" The comment provides a logical reasoning for the critique, suggesting that the lack of comprehensive analysis undermines the authors\\' claims. However, it lacks specific examples or references to support the claim about the baseline performance or the method\\'s effectiveness. This makes the claim somewhat verifiable, as it provides a reasonable basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s experimental design, noting that the focus on presentation of results overshadows the comprehensiveness of the analyses and experimental outcomes. It questions the extent to which the performance improvement attributed to the authors\\' method can be attributed to their claim of \"moving code-switched pretraining from the word level to the sense level, by leveraging word sense-specific information from Knowledge Bases.\" This feedback is clear and actionable, as it prompts the authors to reconsider the balance between presenting results and providing detailed analyses of the method and its performance. However, the comment could be more helpful if it offered specific suggestions on how to improve the experimental design or what aspects of the method should be further explored. Overall, the comment is mostly helpful, as it directs the authors\\' attention to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VR-MARINA and DASHA-MVR, mentioned in these papers, might be relevant to the authors\\' work and could potentially provide better results than QSGD in the stochastic regime. However, the comment does not explicitly instruct the authors to include these papers or provide guidance on how to incorporate them into their analysis. While the action is implied, it is vague and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the next section\" and \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VR-MARINA and DASHA-MVR might be relevant to the authors\\' work. The comment provides a clear direction for the authors to consider these papers and potentially improve their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer suggests that VR-MARINA and DASHA-MVR, mentioned in these papers, might be relevant to the authors\\' work and could potentially provide better results than QSGD in the stochastic regime. However, the comment lacks specific references or detailed comparisons to support the claim that these papers are relevant or superior. While the reviewer provides some context, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the literature review, noting that it ignores several relevant papers. It provides a specific example of two papers, [1] and [2], which are mentioned in the literature review and could be relevant to the authors\\' work. The comment suggests that VR-MARINA and DASHA-MVR, mentioned in these papers, might be relevant to the authors\\' analysis and could potentially provide better results than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to consider these papers and potentially incorporate them into their analysis. However, the comment could be more helpful if it provided more detailed guidance on how to integrate these papers into the existing literature review. Overall, the comment is mostly helpful, as it effectively points out a gap in the literature review and offers a specific direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors could improve the presentation to make it more understandable. The comment lacks actionable details, such as recommending specific changes or improvements, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging to understand. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what aspects of the presentation are confusing or how they could be clarified. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not provide any specific feedback or suggestions on how the authors could improve the presentation. Without detailed guidance or examples, the authors are left without actionable steps to enhance the clarity and accessibility of their work. This lack of specificity and actionable advice makes the comment not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more detailed information about the compared models, specifically the differences between KVAE and the other models. It highlights that KVAE is simpler due to linear state space transitions but requires the computation of time-dependent LGSSM parameters \\u03b3. The reviewer asks for clarification on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the detailed presentation of the compared models, particularly the differences between KVAE and the other models. The comment provides a clear request for more detailed information about the computation requirements of the models compared in Table 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide more detailed information about the compared models, specifically the differences between KVAE and the other models. The reviewer acknowledges some understanding of the models but requests more detailed presentation. The comment provides a logical reasoning for the need for more information, as it highlights the complexity of KVAE compared to the other models. However, it lacks specific examples or references to support the claim that KVAE is simpler due to linear state space transitions. This makes the claim somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement. It highlights the need for more detailed information about the compared models, particularly the differences between KVAE and the other models. The reviewer acknowledges that they have a basic understanding of the models but emphasizes the need for more detailed presentation. This feedback is clear and constructive, as it guides the authors to enhance the clarity and comprehensiveness of their paper. By addressing this suggestion, the authors can improve the comprehensibility and depth of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or specify how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments should be conducted on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what additional experiments should be conducted or how they would impact the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more experiments should be conducted on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. However, the comment lacks specific reasoning or evidence to support why these additional experiments are necessary or how they would impact the results. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that more experiments should be conducted on different LLMs, such as LLaMA and Falcon, to serve as benchmark baselines. This feedback is somewhat helpful as it highlights a gap in the experimental setup and suggests a specific direction for further exploration. However, the comment lacks depth and does not provide detailed guidance on how to conduct these additional experiments or why they are necessary. To be more helpful, the comment could offer suggestions on how to incorporate these additional experiments into the existing study or explain why these specific LLMs are important for benchmarking. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison of the real search cost in terms of GPU days. This provides clear guidance on what aspect of the table needs improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the understanding of the table. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is somewhat helpful as it identifies a potential area for improvement in the presentation of the table, which could enhance the understanding of the search cost. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what additional insights this comparison might offer. While it points out a potential improvement, it does not fully address the authors\\' needs for enhancing their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific typographical error in the phrase \"for 'in-between' uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with explicit guidance on how to correct the error. The comment is highly actionable as it directly instructs the authors on what to change to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"for 'in-between' uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the typographical error, providing detailed guidance on how to correct it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about a typographical error in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific typographical error in the paper, noting that the first quotation mark in the phrase \"for 'in-between' uncertainty\" should be a forward mark rather than a backward mark. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and readability of their draft. However, the comment does not provide any additional context or explanation about why this error is important or how it might impact the overall presentation of the paper. While it is helpful in pointing out a specific issue, it could be more beneficial if it included suggestions for how to avoid similar errors in the future. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit definitions of \"Omega\" and the \"link function\" mentioned in L178. It also suggests being more explicit about the \"OMD family of algorithms\" and the theorem in [32] that is being referred to for the regret guarantee. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the feedback lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as the definition of \"Omega\" and the link function, and suggests being more explicit about the \"OMD family of algorithms\" and the theorem in [32] that is being referred to for the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved by requesting clarification on certain terms and concepts. It points out that the definition of \"Omega\" is not provided and suggests being more explicit about the \"OMD family of algorithms.\" Additionally, it asks for clarification on the \"link function\" and the theorem in [32] that is being referred to for the regret guarantee. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in specific areas of the paper. However, it could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it guides the authors toward enhancing the clarity and comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the usefulness of the sequence example but raises a concern about the mention of a \"common\" practice in Example 2, specifically the use of the Hamming distance as a scoring loss over entire parts of the sequence. The reviewer suggests that this approach is uncommon and requests references to support this claim. While the comment identifies an area for clarification, it does not provide explicit guidance on how to address this issue or what specific references to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide references to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the use of the Hamming distance as a scoring loss over entire parts of the sequence, suggesting that this approach is uncommon and requests references to support this claim. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of the Hamming distance as a scoring loss over entire parts of the sequence, suggesting that this approach is uncommon. The reviewer provides a specific example of a \"common\" practice, which is using the Hamming distance node-wise, and requests references to support this claim. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to specific works that support the alternative approach. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the usefulness of the sequence example but raises a concern about the mention of a \"common\" practice in Example 2, specifically the use of the Hamming distance as a scoring loss over entire parts of the sequence. The reviewer suggests that this approach is uncommon and requests references to support this claim. This feedback is somewhat helpful as it identifies a potential inconsistency in the paper and prompts the authors to provide evidence or clarification for their claims. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what references to include. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to change the name and suggests removing sections, it lacks specific guidance on how to implement the suggested changes or which sections to remove. The action is explicit but somewhat vague, as the authors need to infer the exact sections to remove and the exact wording for the captions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion is specific in terms of the suggested change and the need to mention metrics, making the comment fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. The comment provides a logical reasoning for the name change, as \"evaluation\" can have a more general meaning, and suggests mentioning the metrics along with the datasets or in the captions of the tables. This reasoning is supported by the observation that most, if not all, of the metrics are well-known and used as standard practice. However, the comment could be strengthened by providing specific examples of metrics or references to standard practices, which would further substantiate the claim. Overall, the suggestion is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a more accurate and precise term. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This feedback is clear and offers a straightforward way for the authors to improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided examples of specific metrics that should be included or explained why the current evaluation sections are unnecessary. Overall, the comment is mostly helpful as it offers clear guidance on how to improve the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use more objective terms than \"remarkable\" to describe the accuracy improvement, as the axes appear squished. The reviewer provides a specific example of the term \"remarkable\" and suggests using more objective terms. However, the comment does not provide guidance on what alternative terms should be used or how to effectively communicate the improvement. While the suggestion is clear, it lacks concrete details on how to implement it, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" to describe the accuracy improvement, and it points out that the improvement is difficult to characterize as remarkable due to the squished axes. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"remarkable\" is not objective and that the axes appear squished, making it difficult to characterize the accuracy improvement as remarkable. The reviewer provides a specific example of the term \"remarkable\" and suggests using more objective terms. However, the comment lacks detailed reasoning or references to support why \"remarkable\" is not an objective term or how the squished axes affect the interpretation of the accuracy improvement. This makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to use more objective terms than \"remarkable\" to describe the accuracy improvement, noting that the axes appear squished and making it difficult to characterize the improvement as remarkable. This feedback is actionable and constructive, as it offers a clear and concrete way for the authors to improve the clarity and precision of their language. By suggesting alternative terms, the comment helps the authors communicate their findings more effectively. However, the comment could be more helpful if it provided additional guidance on how to effectively use objective terms or examples of alternative terms that might be more appropriate. Overall, the comment is mostly helpful, as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a general observation about the synthesized results for UCF-101, noting issues with inconsistent motion, changing color, or object disappearing over time. It suggests that running the LSTM over many time steps could potentially address these issues. However, the comment does not provide explicit instructions or concrete steps for the authors to take to implement this suggestion. It lacks specific guidance on how to conduct the longer-duration experiments or what specific aspects of the results need improvement. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the synthesized results for UCF-101, specifically noting issues with inconsistent motion, changing color, or object disappearing over time. It suggests running the LSTM over many time steps to address these issues. However, the comment does not specify which part of the paper discusses these results or where the synthesized results are presented, making it weakly grounded. The comment is specific in detailing the issues with the synthesized results and suggesting a potential solution, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the synthesized results for UCF-101, noting issues with inconsistent motion, changing color, or object disappearing over time. It suggests that running the LSTM over many time steps could address these issues. However, the comment lacks specific examples or detailed reasoning to support the claim about the synthesized results. It does not provide references or detailed explanations to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a general observation about the synthesized results for UCF-101, noting issues with inconsistent motion, changing color, or object disappearing over time. It suggests that running the LSTM over many time steps could potentially address these issues. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might implement this suggestion or what specific aspects of the results need improvement. While it highlights an interesting idea and extensive experiments, the feedback is limited in its usefulness for the authors to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the unfairness of the comparison with [5] because it is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting alternative evaluation methods or suggesting ways to make the comparison more fair. The comment lacks concrete actions or detailed suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with [5], allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the unfairness of the comparison with [5]. However, the comment does not provide specific reasoning or evidence to support why the comparison is unfair or how it affects the validity of the evaluation. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This feedback is somewhat helpful as it highlights an area where the authors could improve the paper by providing a more comprehensive evaluation or justification for the comparison. However, the comment lacks specific suggestions on how to address this issue or what additional evaluation methods could be used. While it points out a relevant concern, it does not offer detailed guidance on how to improve the draft, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack, suggesting that it might improve robustness against a more powerful adversary. The reviewer implies that this experiment could strengthen the paper but does not explicitly instruct the authors to conduct it. The action is implicit and somewhat vague, as the authors can infer that they might want to include this experiment but are not given explicit guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"PGD attack\" and \"logits,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effectiveness of studying numbers of bits in logits against a larger epsilon in the PGD attack, suggesting that this might improve robustness against a more powerful adversary. The comment does not provide specific suggestions or examples, but it does prompt the authors to consider conducting an additional experiment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of studying numbers of bits in logits against a larger epsilon in the PGD attack, suggesting that it might improve robustness against a more powerful adversary. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of studying numbers of bits in logits against a larger epsilon in the PGD attack, suggesting that it might improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific insights it might yield. The feedback is somewhat helpful as it prompts the authors to consider an additional experiment that could strengthen their paper, but it lacks detailed guidance or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to refine the performance or what specific areas need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as specific results or sections where the enhancements are discussed. The authors cannot confidently determine which part of the paper is being addressed, making this comment not grounded. Additionally, the comment lacks specificity regarding what aspects need refinement or how to improve the performance. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any specific evidence, reasoning, or examples to support this claim. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the observation. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what areas need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It explicitly instructs them to provide references for two specific passages in Section 3.2 and asks for clarification on \"MLP\" in Figure 2. These are clear and concrete instructions that the authors can follow to improve their draft. Additionally, the comment highlights a missing description of \"MLP\" in Figure 2, which is also a direct action for the authors to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in Section 3.2 (230-234 and 234-235) and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two specific passages and requests clarification on \"MLP\" in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for references and clarification, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying specific lines in the paper that lack references and clarification. It requests references for two passages and points out the absence of a description for \"MLP\" in Figure 2. This level of detail helps the authors understand where their draft needs improvement and provides clear guidance on how to address these issues. By addressing these points, the authors can enhance the clarity and completeness of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not explicitly instruct the authors to address this discrepancy or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider alternative methods like bilinear sampling. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about a discrepancy between the equations and the figure, questioning whether the output patches are cropped or masked versions of the input image. The comment suggests that the figure might be misleading and proposes an alternative method for better results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions where most pixels are black. The reviewer suggests that the figure might be misleading and proposes an alternative method for better results. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use bilinear sampling is not fully explained, leaving the authors to infer the reasoning behind the suggestion. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is somewhat helpful as it points out a potential issue with the clarity of the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better option. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early down-sampling layers. It suggests that this issue has not been revisited in the Discussion section, which is fine if the authors choose to delete \"Discussion.\" However, the comment does not explicitly instruct the authors to revise the Discussion section or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should revise the Discussion section to address the training time reduction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the discussion regarding the training time reduction and parameter reduction, suggesting that the issue has not been revisited. The comment provides clear guidance on what needs to be addressed in the Discussion section, which is the deletion of \"Discussion.\" Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the training time reduction being less drastic than the parameter reduction. It points out that this discrepancy has not been addressed in the Discussion section, suggesting that the authors should revisit this issue. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the discussion. While it highlights a potential area for improvement, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. The comment is specific about the issue, allowing the authors to easily identify the problem and address it by increasing the font size. The action is concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a factual observation about the font size in Figure 6 being too small. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. While this feedback is clear and actionable, it does not provide any context or explanation about why the font size is a concern or how it affects the overall presentation of the figure. Additionally, it does not offer suggestions on how to address this issue, such as recommending a specific font size or discussing the impact of font size on readability. Despite being clear and direct, the comment could be more helpful with additional guidance or context. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks explicit guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to focus on but without detailed instructions on how to execute the suggested changes. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction does not provide a clear picture of the paper's goal and questions the relevance of the examples chosen. It provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the examples chosen in the paper do not convincingly demonstrate problems requiring inter-process communication, particularly in the second paragraph where sampling-based Bayesian methods are mentioned. The reviewer suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. The comment provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the current examples are insufficient. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s introduction, suggesting that the examples chosen do not effectively demonstrate the need for inter-process communication. It provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. This feedback is clear and actionable, as it offers a concrete direction for improvement by suggesting a specific area to focus on. However, the comment could be more helpful if it provided additional context or examples of how the authors might address this issue. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, specifically noting that PMEF lacks a pre-training module. It suggests that to ensure fairness, the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback provides a clear and explicit action for the authors to take, which is to modify the comparison to ensure fairness and demonstrate the advantages of their model. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529-lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This provides a clear and actionable suggestion for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pre-training module in PMEF. The reviewer suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness and showcase the advantage of the innovative pre-training module design of CPEF. This claim is mostly verifiable as it provides a logical reasoning for the need to compare CPEF with another pre-trained model. However, the comment could be strengthened by providing specific examples or references to similar studies that demonstrate the importance of pre-training for fair comparisons. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the fairness of the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pre-training module. It provides a clear and actionable suggestion by recommending that the authors compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness and showcase the advantage of the innovative pre-training module design of CPEF. This feedback is valuable as it guides the authors on how to improve the fairness and clarity of their comparison, which is crucial for the validity and impact of their findings. However, the comment could be more helpful if it included specific examples or references to similar studies that demonstrate the importance of pre-training for fair comparisons. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
