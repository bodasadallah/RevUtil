{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# def split_into_batches(df, batch_size=1000):\n",
    "#     \"\"\"Yield consecutive batches of given size from DataFrame.\"\"\"\n",
    "#     for i in range(0, len(df), batch_size):\n",
    "#         yield df.iloc[i:i + batch_size]\n",
    "\n",
    "# # Load the Excel file and sheet\n",
    "# file_path = \"main_data/500_points.csv\"  # Change this to your file\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Filter rows where chatgpt_discard == 0\n",
    "# filtered_df = df[df[\"chatgpt_discard\"] == 0]\n",
    "\n",
    "# print(f\"Original DataFrame: {df.shape}\")\n",
    "# print(f\"Filtered DataFrame: {filtered_df.shape}\")\n",
    "\n",
    "# ## shuffle the data\n",
    "# filtered_df = filtered_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# ## remove the chatgpt_discard column\n",
    "# filtered_df = filtered_df.drop(columns=['chatgpt_discard'])\n",
    "# # rename column point to review_point\n",
    "# filtered_df = filtered_df.rename(columns={\"point\": \"review_point\"})\n",
    "\n",
    "# # Take only the first 10000 rows\n",
    "# filtered_df = filtered_df.head(500)\n",
    "\n",
    "# # Split into batches of 1000\n",
    "# batches = list(split_into_batches(filtered_df, batch_size=5000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def clean_cell(value):\n",
    "#     \"\"\"Remove illegal characters from cell values.\"\"\"\n",
    "#     if isinstance(value, str):\n",
    "#         return re.sub(r'[\\x00-\\x1F\\x7F]', '', value)  # Remove control characters\n",
    "#     return value  # Return non-string values unchanged\n",
    "\n",
    "# for i, batch in enumerate(batches):\n",
    "#         file_path = f\"main_data/batches/batch_{i+3}.xlsx\"\n",
    "#         print(f\"Writing {file_path}...\")\n",
    "#         df = batch.copy()\n",
    "#         # Clean the dataframe to remove illegal characters\n",
    "#         df = df.applymap(clean_cell)\n",
    "\n",
    "#         with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "#             for aspect in ['actionability', 'grounding_specificity', 'verifiability', 'helpfulness']:\n",
    "#                 df.to_excel(writer, sheet_name=aspect, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "dotenv.load_dotenv()\n",
    "from prompt import *\n",
    "client = OpenAI(api_key=os.environ.get(\"review_evaluation_mbzuai\"))\n",
    "\n",
    "model_name = 'gpt-4o'\n",
    "\n",
    "import json \n",
    "import pandas as pd\n",
    "aspects = [ 'actionability', 'grounding_specificity','verifiability_extraction', 'helpfulness']\n",
    "# aspects = ['helpfulness']\n",
    "\n",
    "all_incontext_examples = pd.read_excel('/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/test_data/in_context_examples.xlsx', sheet_name=None)\n",
    "\n",
    "\n",
    "\n",
    "BATCH = \"gold\"\n",
    "# data_path = f'main_data/batches/batch_{BATCH}.xlsx'\n",
    "TEMP = 0.1\n",
    "num_examples_per_label = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_prompt(review_point,aspect, in_context_examples,num_examples_per_label=1,):\n",
    "\n",
    "    prompt = ''\n",
    "    examples = ''\n",
    "    examples_str = []\n",
    "    ##3 group examples by the label and choose a random example from each group\n",
    "    for label in in_context_examples[f'{aspect}_label'].unique():\n",
    "        for _ in range(num_examples_per_label):\n",
    "            ## keep sampling a line till it is not the same as the currrent review point\n",
    "            while True:\n",
    "                row = in_context_examples[in_context_examples[f'{aspect}_label']==label].sample(1)\n",
    "                row = row.iloc[0]\n",
    "                if row['review_point'] != review_point:\n",
    "                    break\n",
    "            \n",
    "            score = row[f'{aspect}_label']\n",
    "            rationale = row['rationale']\n",
    "\n",
    "\n",
    "            examples_str.append(f'''\n",
    "Review Point: {row['review_point']}\n",
    "rationale: {rationale}\n",
    "score: {score}\n",
    "''')\n",
    "    ## shuffle the list \n",
    "    random.shuffle(examples_str)\n",
    "    examples = '\\n'.join(examples_str)\n",
    "    \n",
    "    ## for verifiability, we have two tasks\n",
    "    prompt = BASE_PROMPT_EXAMPLES.format(review_point=review_point,aspect=aspect,aspect_description=ASPECTS_WITH_EXAMPLES[aspect],examples=examples)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_batch_inf(test_data,aspect, batch,temp=0, num_examples_per_label=1):\n",
    "   in_context_examples =  all_incontext_examples[aspect]\n",
    "   lines = []\n",
    "\n",
    "   for i,row in test_data.iterrows():\n",
    "      review_point = row['review_point']\n",
    "      prompt = get_prompt(review_point=review_point,aspect=aspect, in_context_examples=in_context_examples, num_examples_per_label=num_examples_per_label)   \n",
    "      line = {\n",
    "         \"custom_id\": f\"{row['id']}\", \n",
    "         \"method\": \"POST\", \n",
    "         \"url\": \"/v1/chat/completions\", \n",
    "         \"body\": {\"model\": model_name,\n",
    "         \"temperature\": temp,\n",
    "         \"messages\": \n",
    "         [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "         {\"role\": \"user\", \"content\": prompt}],}}\n",
    "      lines.append(line)\n",
    "\n",
    "   print(f'sample of the prompts is {lines[0]}')\n",
    "\n",
    "   ### Write batch input file\n",
    "   batch_file_path = f\"batch_data/main_data_batch_{batch}_{aspect}_input.jsonl\"\n",
    "   with open(batch_file_path, 'w') as f:\n",
    "      for l in lines:\n",
    "         json.dump(l, f)\n",
    "         f.write('\\n')\n",
    "\n",
    "   ### upload the batch file\n",
    "   batch_input_file = client.files.create(\n",
    "   file=open(batch_file_path, \"rb\"),\n",
    "   purpose=\"batch\")\n",
    "\n",
    "   ### create the batch request\n",
    "   batch_input_file_id = batch_input_file.id\n",
    "   batch_data = client.batches.create(\n",
    "      input_file_id=batch_input_file_id,\n",
    "      endpoint=\"/v1/chat/completions\",\n",
    "      completion_window=\"24h\",\n",
    "      metadata={\n",
    "         \"description\": f\"batch file for  {aspect} model gpt-4o, temperature {temp} for batch {batch}\",\n",
    "      })\n",
    "   batch_metadata = {\n",
    "      \"batch_id\": batch_data.id,\n",
    "      \"aspect\": aspect,\n",
    "      \"batch_input_file_id\": batch_input_file_id,\n",
    "      \"batch_file_path\": batch_file_path,\n",
    "      \"batch\": batch,\n",
    "   }\n",
    "\n",
    "   with open(f\"batch_data/main_data_batch_{batch}_{aspect}_input_meta_data.json\", 'w') as f:\n",
    "      json.dump(batch_metadata, f, indent=4)\n",
    "      \n",
    "   print(f\"Batch file for {aspect}, and  batch {batch} is created and uploaded to the server\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "# for aspect in aspects:\n",
    "#     if aspect in ['verifiability_extraction']:\n",
    "#         sheet_name = 'verifiability'\n",
    "#     else:\n",
    "#         sheet_name = aspect\n",
    "\n",
    "\n",
    "#     # test_data = pd.read_excel(data_path, sheet_name=sheet_name)\n",
    "#     test_data = datasets.load_dataset('boda/review_evaluation_human_annotation', name=sheet_name, split=BATCH).to_pandas()\n",
    "#     ### check if test_data has id column and add one if not\n",
    "#     if 'id' not in test_data.columns:\n",
    "#         test_data['id'] = range(1, len(test_data) + 1)\n",
    "#         with pd.ExcelWriter(data_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "#             test_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # print(f'Size of {aspect} data is {test_data.shape[0]}')\n",
    "    # chatgpt_batch_inf(test_data=test_data,\n",
    "    #                     aspect=aspect, \n",
    "    #                     batch=BATCH,\n",
    "    #                     temp=TEMP,\n",
    "    #                     num_examples_per_label=num_examples_per_label)\n",
    "\n",
    "\n",
    "\n",
    "########################### VERIFIABILITY CODE ########################################\n",
    "# check for data of verifiability_extraction if it's done, then do the verifiability_verification\n",
    "\n",
    "# extraction_results_path = f'outputs/main_data_batch_{BATCH}_results.xlsx'\n",
    "# for file in os.listdir('batch_data'):\n",
    "#     if 'verifiability_extraction' in file and 'meta_data' in file :\n",
    "#         verifiability_extraction_batch_data = json.load(open(f'batch_data/{file}'))\n",
    "# if client.batches.retrieve(verifiability_extraction_batch_data['batch_id']).status == 'completed':\n",
    "#     ## get the saved data, and only consider the ones with labes yes\n",
    "#     test_data = pd.read_excel(extraction_results_path, sheet_name='verifiability_extraction')\n",
    "#     test_data = test_data[test_data['chatgpt_verifiability_extraction_score']!='X']\n",
    "\n",
    "#     print(f'Verifiability extraction is done, moving to verifiability verification')\n",
    "#     print(f'Size of verifiability verification data is {test_data.shape[0]}')\n",
    "#     chatgpt_batch_inf(test_data=test_data,aspect='verifiability_verification', \n",
    "#                       batch=BATCH, \n",
    "#                       temp=TEMP,\n",
    "#                       num_examples_per_label=num_examples_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_rationale_and_score(text):\n",
    "    valid_score_values = {\"yes\", \"no\", \"x\", \"1\", \"2\", \"3\", \"4\", \"5\"}\n",
    "    \n",
    "    # Extract rationale\n",
    "    rationale_match = re.search(r\"(?i)\\*?\\*?rationale:\\*?\\*?\\s*(.*?)(?=\\n\\s*\\*?\\*?(?i)score:\\*?\\*?|$)\", text, re.DOTALL)\n",
    "    rationale = rationale_match.group(1).strip() if rationale_match else None\n",
    "    \n",
    "    # Extract score\n",
    "    score_match = re.search(r\"(?i)\\*?\\*?score:\\*?\\*?\\s*([a-zA-Z0-9]+)\", text)\n",
    "    score = score_match.group(1).strip().lower() if score_match else None\n",
    "    \n",
    "    if not score:\n",
    "        # Try to extract a number within five words after \"score\" or \"rated\"\n",
    "        score_context_match = re.search(r'(?i)(score|rated)[:\\s]+((?:\\S+\\s+){0,5}?)[\"\\']?(\\d+)', text)\n",
    "        if score_context_match:\n",
    "            score = score_context_match.group(3)  # Extract the number if found\n",
    "\n",
    "    if score:\n",
    "        ## remove trailing spaces and dots from the score\n",
    "        score = score.strip().rstrip('.')\n",
    "        score = str(score)\n",
    "        # Ensure final score is valid\n",
    "        if score not in valid_score_values:\n",
    "            score = None  # Invalidate if it's not a valid score\n",
    "    \n",
    "    return {\"rationale\": rationale, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27507/1965320185.py:7: DeprecationWarning: Flags not at the start of the expression '(?i)\\\\*?\\\\*?rationale:' (truncated) but at position 48\n",
      "  rationale_match = re.search(r\"(?i)\\*?\\*?rationale:\\*?\\*?\\s*(.*?)(?=\\n\\s*\\*?\\*?(?i)score:\\*?\\*?|$)\", text, re.DOTALL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rationale': 'The review point suggests investigating the use of contextualized vectors for note embeddings by proposing three additional ablation studies. However, it does not provide any justification or reasoning for why these specific ablations are necessary or how they would contribute to the understanding of the issue. The lack of explanation or supporting evidence makes it difficult for the authors to grasp the importance or relevance of the suggested ablations. Consequently, the comment is rated as \"1: Unverifiable\" due to the absence of verifiable support or rationale.',\n",
       " 'score': '1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '''rationale: The review point suggests investigating the use of contextualized vectors for note embeddings by proposing three additional ablation studies. However, it does not provide any justification or reasoning for why these specific ablations are necessary or how they would contribute to the understanding of the issue. The lack of explanation or supporting evidence makes it difficult for the authors to grasp the importance or relevance of the suggested ablations. Consequently, the comment is rated as \"1: Unverifiable\" due to the absence of verifiable support or rationale.'''\n",
    "extract_rationale_and_score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_batch_and_save_results(batch_data, chatgpt_output_path):\n",
    "    aspect = batch_data['aspect']\n",
    "    batch_id = batch_data['batch_id']\n",
    "    output_file_id = client.batches.retrieve(batch_id).output_file_id\n",
    "    chatgpt_response =  client.files.content(output_file_id)\n",
    "    file_path = chatgpt_output_path\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(chatgpt_response.text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def remove_illegal_chars(value):\n",
    "    \"\"\"Remove illegal characters from strings.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return \"\".join(c for c in value if c.isprintable())\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "aspects = [ 'actionability', 'grounding_specificity', 'verifiability', 'helpfulness']\n",
    "def write_results_in_original_file(batch_data, chatgpt_output_path, raw_data_path, chatgpt_input_path, write_path):\n",
    "    errors = 0\n",
    "    aspect = batch_data['aspect']\n",
    "\n",
    "    if aspect in ['verifiability_extraction']:\n",
    "        sheet_name = 'verifiability'\n",
    "    elif aspect in ['verifiability_verification']:\n",
    "        sheet_name = 'verifiability_extraction'\n",
    "    else:\n",
    "        sheet_name = aspect\n",
    "    \n",
    "    chatgpt_response = pd.read_json(chatgpt_output_path, lines=True)\n",
    "\n",
    "    if 'boda' in raw_data_path and aspect not in ['verifiability_verification']:\n",
    "        raw_data_df = datasets.load_dataset('boda/review_evaluation_human_annotation', name=sheet_name, split=BATCH).to_pandas()\n",
    "    else:\n",
    "        raw_data_df = pd.read_excel(raw_data_path, sheet_name=sheet_name)\n",
    "\n",
    "        \n",
    "    chatgpt_input = pd.read_json(chatgpt_input_path, lines=True)\n",
    "\n",
    "    ### iterate over the review_points in the raw dataframe and make sure they are aligned with the chatgpt input data\n",
    "    final_df = []\n",
    "    for i in range(raw_data_df.shape[0]):\n",
    "        id = raw_data_df.iloc[i]['id']\n",
    "\n",
    "        row = raw_data_df.iloc[i].copy()\n",
    "\n",
    "        ## if this is verifiability_verification, and we don't find the id, then the was an X case, and we don't do anything\n",
    "        if  aspect == 'verifiability_verification' and  id not in chatgpt_response['custom_id'].values:\n",
    "            continue\n",
    "\n",
    "        chatgpt_row = chatgpt_response[chatgpt_response['custom_id']==id]\n",
    "\n",
    "        ## if the row is not found, then it was failed, then skip it\n",
    "        if chatgpt_row.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "\n",
    "        input = chatgpt_input[chatgpt_input['custom_id']==id].iloc[0]['body']['messages'][1]['content']\n",
    "\n",
    "        chatgpt_row = chatgpt_row.iloc[0].copy()\n",
    "\n",
    "        answer = chatgpt_row['response']['body']['choices'][0]['message']['content']\n",
    "\n",
    "        extracted_output = extract_rationale_and_score(answer)\n",
    "        rationale, score = extracted_output['rationale'], extracted_output['score']\n",
    "        aspect_save_name = aspect\n",
    "        if aspect in ['verifiability_extraction', 'verifiability_verification']:\n",
    "            score = 'X' if score == 'no' else score\n",
    "        if aspect in ['verifiability_verification']:\n",
    "            aspect_save_name = 'verifiability'\n",
    "        row [f'chatgpt_{aspect_save_name}_score'] = score\n",
    "        row [f'chatgpt_{aspect_save_name}_rationale'] = rationale\n",
    "        row [f'prompt'] = input\n",
    "\n",
    "        if not score:\n",
    "            errors += 1\n",
    "            print(f\"can't process {answer}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        final_df.append(row)\n",
    "\n",
    "    final_df = pd.DataFrame(final_df)\n",
    "\n",
    "    ## if the aspect is verifiability_verification, we need to merge the results with the extraction results\n",
    "    ## rename the aspect to verifiability\n",
    "    if aspect == 'verifiability_verification':\n",
    "        extraction_results = raw_data_df[raw_data_df['chatgpt_verifiability_extraction_score']=='X']\n",
    "        extraction_results['chatgpt_verifiability_score'] = extraction_results['chatgpt_verifiability_extraction_score']\n",
    "        extraction_results['chatgpt_verifiability_rationale'] = extraction_results['chatgpt_verifiability_extraction_rationale']\n",
    "        extraction_results.drop(['chatgpt_verifiability_extraction_score','chatgpt_verifiability_extraction_rationale'], axis=1, inplace=True)\n",
    "        final_df = pd.concat([final_df, extraction_results], axis=0)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    if aspect in [ 'verifiability_verification']:\n",
    "        aspect = 'verifiability'\n",
    "    ## remove all the columns that related to another aspects\n",
    "    # for any column if it has the aspect name of other aspects, remove it\n",
    "    ## grap the other aspects list\n",
    "    ## remove all cloulmns expptr for this hlise \n",
    "    main_aspect_name = aspect if aspect not in ['verifiability_extraction'] else 'verifiability'\n",
    "    exclude = ['review_point','paper_id','id','venue','focused_review','batch','prompt', f'{main_aspect_name}_label']\n",
    "\n",
    "    for col in final_df.columns:\n",
    "\n",
    "        if col in exclude:\n",
    "            continue\n",
    "        if aspect in col:\n",
    "            continue\n",
    "        if col in aspect:\n",
    "            continue\n",
    "        final_df.drop(col, axis=1, inplace=True)         \n",
    "    ## rewrite the existing sheet, but keep the other sheets\n",
    "    file_path = write_path\n",
    "\n",
    "    final_df = final_df.applymap(remove_illegal_chars)\n",
    "\n",
    "\n",
    "    ## if the file does not exist, create a new one\n",
    "    if not os.path.exists(file_path):\n",
    "        final_df.to_excel(file_path, sheet_name=aspect, index=False)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "            final_df.to_excel(writer, sheet_name=aspect, index=False)\n",
    "    \n",
    "    print(final_df[f'chatgpt_{aspect_save_name}_score'].value_counts())\n",
    "    print(final_df.columns)\n",
    "\n",
    "    print(f'number of errors for {aspect} is {errors}. The number of rows processed is {final_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'The project you are requesting has been archived and is no longer accessable', 'type': 'invalid_request_error', 'param': None, 'code': 'not_authorized_invalid_project'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_data\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_meta_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(BATCH) \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverifiability\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch file for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m         aspect \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/openai/resources/batches.py:141\u001b[0m, in \u001b[0;36mBatches.retrieve\u001b[0;34m(self, batch_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_id:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `batch_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/batches/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py:1236\u001b[0m, in \u001b[0;36mSyncAPIClient.get\u001b[0;34m(self, path, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1233\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[0;32m-> 1236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'The project you are requesting has been archived and is no longer accessable', 'type': 'invalid_request_error', 'param': None, 'code': 'not_authorized_invalid_project'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "for file in os.listdir('batch_data'):\n",
    "    if 'main_data' in file and 'input_meta_data.json' in file and str(BATCH) in file and 'verifiability' in file:\n",
    "        batch_data = json.load(open(f'batch_data/{file}'))\n",
    "\n",
    "        if client.batches.retrieve(batch_data['batch_id']).status == 'completed':\n",
    "            print(f\"Batch file for {batch_data['aspect']} and batch {batch_data['batch']} has been completed\")\n",
    "            aspect = batch_data['aspect']\n",
    "\n",
    "            chatgpt_output_path = f\"batch_output/main_data_batch_{BATCH}_{aspect}_chatgpt_output.jsonl\"\n",
    "\n",
    "            # raw_data_path = f\"main_data/batches/batch_{BATCH}.xlsx\"\n",
    "            raw_data_path = f'boda/review_evaluation_human_annotation'\n",
    "            \n",
    "\n",
    "            chatgpt_input_path =  f\"batch_data/main_data_batch_{BATCH}_{aspect}_input.jsonl\"\n",
    "            write_path = f\"outputs/main_data_batch_{BATCH}_results.xlsx\"\n",
    "\n",
    "            retrive_batch_and_save_results (batch_data, chatgpt_output_path=chatgpt_output_path)\n",
    "\n",
    "            if aspect == 'verifiability_verification':\n",
    "                raw_data_path = write_path\n",
    "                \n",
    "            write_results_in_original_file(batch_data,\n",
    "                                        chatgpt_output_path=chatgpt_output_path,\n",
    "                                        raw_data_path=raw_data_path,\n",
    "                                        chatgpt_input_path=chatgpt_input_path,\n",
    "                                        write_path=write_path)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Batch file for {batch_data['aspect']} and batch {batch_data['batch']} has not been completed yet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_excel('outputs/main_data_batch_gold_results.xlsx', sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_point', 'paper_id', 'venue', 'focused_review', 'batch',\n",
       "       'verifiability', 'verifiability_label', 'id',\n",
       "       'chatgpt_verifiability_extraction_score',\n",
       "       'chatgpt_verifiability_extraction_rationale', 'prompt',\n",
       "       'chatgpt_verifiability_score', 'chatgpt_verifiability_rationale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verifiability'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pick a random row from the data, and print the revew point, and the rationale. do this for each asepct\n",
    "## write this into a file\n",
    "with open('outputs/sample_results.txt', 'w') as f:\n",
    "    for aspect in data.keys():\n",
    "        sample = data[aspect].sample(1)\n",
    "        review_point = sample['review_point'].values[0]\n",
    "        rationale = sample[f'chatgpt_{aspect}_rationale'].values[0]\n",
    "        f.write(f'Aspect: {aspect}\\n')\n",
    "        f.write(f'Review Point: {review_point}\\n\\n')\n",
    "        f.write(f'Rationale: {rationale}\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch\n",
       "2    39\n",
       "3    38\n",
       "6    27\n",
       "5    21\n",
       "4    18\n",
       "1     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/test_data/gold_human_annotations.xlsx'\n",
    ", sheet_name='verifiability')\n",
    "\n",
    "df['batch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch\n",
       "6    27\n",
       "8    27\n",
       "7    23\n",
       "5    21\n",
       "4    18\n",
       "3    13\n",
       "2     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset('boda/review_evaluation_human_annotation', name='verifiability', split='gold').to_pandas()\n",
    "\n",
    "ds['batch'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
