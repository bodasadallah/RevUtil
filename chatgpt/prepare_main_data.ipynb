{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "all_data = pd.read_csv('/home/abdelrahman.sadallah/mbzuai/review_rewrite/data/all_review_points.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204917"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### remove the taken examples: \n",
    "taken = pd.read_csv(f'../data/taken_for_human_data/taken_1k_samples_human_annotation_sampled.csv')['point']\n",
    "taken  = pd.concat([taken, pd.read_csv(f'../data/human_annotation_gathered/all_human_annotations_processed.csv')['review_point']])\n",
    "taken = pd.concat([taken, pd.read_csv(f'../data/taken_for_human_data/filtered_samples.csv')['point']])\n",
    "print(len(all_data))\n",
    "## remove the taken samples from all\n",
    "all_data = all_data[~all_data['point'].isin(taken)]\n",
    "len(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "venue\n",
       "ICLR_2025     119142\n",
       "ICLR_2024      63115\n",
       "EMNLP_2023      8462\n",
       "NIPS_2020       6475\n",
       "ICLR_2023       1925\n",
       "ARR_2022        1562\n",
       "ICLR_2022       1296\n",
       "NIPS_2018        737\n",
       "NIPS_2022        586\n",
       "ICLR_2021        444\n",
       "ACL_2017         422\n",
       "NIPS_2019        361\n",
       "NIPS_2021        294\n",
       "NIPS_2017         96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['venue'].value_counts( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'venue', 'focused_review', 'point'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bad_points(point):\n",
    "    ## remove the points that have less than 5 words\n",
    "    ## remove points that ends in ; or :\n",
    "    ## remove points that starts with . or + \n",
    "    ## remove points that has avg word length less than 4\n",
    "    ## if the word \"Strengths\" is in the first few words\n",
    "    ## if @ in in the begining of the first few words\n",
    "\n",
    "    point = point['point']\n",
    "    if len(point.split()) < 5:\n",
    "        return False\n",
    "    if point[-1] in [';', ':']:\n",
    "        return False\n",
    "    if point[0] in ['.', '+', '@']:\n",
    "        return False\n",
    "    if np.mean([len(w) for w in point.split()]) < 4:\n",
    "        return False\n",
    "    first_5 = point.split()[:5]\n",
    "    for w in first_5:\n",
    "        if 'strength' in w.lower():\n",
    "            return False\n",
    "        if 'recommndation' in w.lower():\n",
    "            return False\n",
    "        if '@' in w:\n",
    "            return False\n",
    "\n",
    "    \n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate over the points and filter the bad ones\n",
    "all_data = all_data[all_data.apply(filter_bad_points, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193998"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatgpt filteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3061\n",
      "venue\n",
      "ICLR_2025     2733\n",
      "ICLR_2024     1819\n",
      "EMNLP_2023     980\n",
      "NIPS_2020      949\n",
      "ARR_2022       857\n",
      "ICLR_2022      857\n",
      "ICLR_2023      857\n",
      "NIPS_2018      745\n",
      "NIPS_2022      586\n",
      "ICLR_2021      444\n",
      "ACL_2017       422\n",
      "NIPS_2019      361\n",
      "NIPS_2021      294\n",
      "NIPS_2017       96\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_894818/4081315792.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped.apply(lambda group: group.sample(n=min(len(group), samples_per_group), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Total number of samples\n",
    "total_samples = 12000\n",
    "\n",
    "# Uniform sampling\n",
    "grouped = all_data.groupby(\"venue\")\n",
    "samples_per_group = max(1, total_samples // grouped.ngroups)  # Divide total_samples evenly\n",
    "sampled_df = (\n",
    "    grouped.apply(lambda group: group.sample(n=min(len(group), samples_per_group), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# If more rows are still needed due to rounding, sample the remainder\n",
    "remainder = total_samples - len(sampled_df)\n",
    "print(remainder)\n",
    "if remainder > 0:\n",
    "    remaining_sample = all_data.loc[~all_data.index.isin(sampled_df.index)].sample(n=remainder, random_state=42)\n",
    "    sampled_df = pd.concat([sampled_df, remaining_sample]).reset_index(drop=True)\n",
    "\n",
    "print(sampled_df.value_counts(\"venue\"))\n",
    "\n",
    "# sampled_df['id'] = range(1, len(sampled_df) + 1)\n",
    "# sampled_df.to_csv(f'/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/unfiltered_main_chatgpt_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/abdelrahman.sadallah/mbzuai/review_rewrite/data/taken_for_human_data/filtered_samples.csv'\n",
    "\n",
    "# unfiltered_data = pd.read_csv(path)\n",
    "# ### get rows that has the human_difficulty column as 1\n",
    "# unfiltered_data = unfiltered_data[unfiltered_data['human_discard'] == 1]\n",
    "# unfiltered_data.to_csv(f'/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/discarded_by_human.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/discarded_by_human.csv'\n",
    "# unfiltered_data = pd.read_csv(path)\n",
    "\n",
    "# unfiltered_data = unfiltered_data[unfiltered_data.apply(filter_bad_points, axis=1)]\n",
    "# before_len = len(unfiltered_data)\n",
    "# after_len = len(unfiltered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = '''Evaluate the following review point and determine if it should be discarded based on these criteria:\n",
    "\n",
    "**discard the point if:**\n",
    "- It is incomplete or cut off.\n",
    "- It highlights a strength or positive aspect of the paper.\n",
    "- It's just some typo fixes. \n",
    "- It does not address a limitation or weakness of the paper.\n",
    "- if the whole point is just mentions of some references.\n",
    "**Output \"1\" for dicarded points and \"0\" for accepted points.**\n",
    "**Review Point:**\n",
    "{point}\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "dotenv.load_dotenv()\n",
    "from prompt import *\n",
    "client = OpenAI(api_key=os.environ.get(\"review_evaluation_mbzuai\"))\n",
    "\n",
    "model_name = 'gpt-4o'\n",
    "path = '/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/unfiltered_main_chatgpt_data.csv'\n",
    "unfiltered_data = pd.read_csv(path)\n",
    "\n",
    "print(len(unfiltered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample of the prompts is {'custom_id': '1', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4o', 'temperature': 0, 'messages': [{'role': 'user', 'content': 'Evaluate the following review point and determine if it should be discarded based on these criteria:\\n\\n**discard the point if:**\\n- It is incomplete or cut off.\\n- It highlights a strength or positive aspect of the paper.\\n- It\\'s just some typo fixes. \\n- It does not address a limitation or weakness of the paper.\\n- if the whole point is just mentions of some references.\\n**Output \"1\" for dicarded points and \"0\" for accepted points.**\\n**Review Point:**\\n6) 279: add \"be\"7) l. 352: give an example of a nontrivial internal path.\\n'}]}}\n",
      "Batch file for main chatgpt unfiltered data of 15k model gpt-4o, temperature 0 is created with id batch_67add443e26c8190a6d82c9a0b19e24b\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "\n",
    "for i,row in unfiltered_data.iterrows():\n",
    "    review_point = row['point']\n",
    "    prompt = PROMPT.format(point=review_point)  \n",
    "    line = {\n",
    "        \"custom_id\": f\"{row['id']}\", \n",
    "        \"method\": \"POST\", \n",
    "        \"url\": \"/v1/chat/completions\", \n",
    "        \"body\": {\"model\": model_name,\n",
    "        ########### UNCOMMENT AGAIN #########\n",
    "        # \"response_format\" :{ \"type\": \"json_object\" },\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": \n",
    "        [{\"role\": \"user\", \"content\": prompt}],}}\n",
    "    lines.append(line)\n",
    "\n",
    "print(f'sample of the prompts is {lines[0]}')\n",
    "\n",
    "### Write batch input file\n",
    "batch_file_path = f\"main_data/main_chatgpt_data_unfiltered_batch_input.jsonl\"\n",
    "with open(batch_file_path, 'w') as f:\n",
    "    for l in lines:\n",
    "        json.dump(l, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "### upload the batch file\n",
    "batch_input_file = client.files.create(\n",
    "file=open(batch_file_path, \"rb\"),\n",
    "purpose=\"batch\")\n",
    "\n",
    "### create the batch request\n",
    "batch_input_file_id = batch_input_file.id\n",
    "batch_data = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": f\"batch file for  main chatgpt unfiltered data of 15k model gpt-4o, temperature 0\"\n",
    "    })\n",
    "batch_metadata = {\n",
    "    \"batch_id\": batch_data.id,\n",
    "    \"data_pth\": path,\n",
    "    \"batch_input_file_id\": batch_input_file_id,\n",
    "    \"batch_file_path\": batch_file_path\n",
    "}\n",
    "\n",
    "with open(f\"main_data/main_chatgpt_data_unfiltered_batch_input_meta_data.json\", 'w') as f:\n",
    "    json.dump(batch_metadata, f, indent=4)\n",
    "print(f\"Batch file for main chatgpt unfiltered data of 15k model gpt-4o, temperature 0 is created with id {batch_data.id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_batch_and_save_results(batch_data):\n",
    "    \n",
    "    batch_id = batch_data['batch_id']\n",
    "    output_file_id = client.batches.retrieve(batch_id).output_file_id\n",
    "    chatgpt_response =  client.files.content(output_file_id)\n",
    "    file_path = f\"main_data/main_chatgpt_data_unfiltered_batch_output.jsonl\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(chatgpt_response.text + '\\n')\n",
    "\n",
    "def save_results(batch_data):\n",
    "    errors = 0\n",
    "    chatgpt_response = pd.read_json(f\"main_data/main_chatgpt_data_unfiltered_batch_output.jsonl\", lines=True)\n",
    "\n",
    "    # raw_data_df = pd.read_csv(path)\n",
    "    raw_data_df = unfiltered_data.copy()\n",
    "    ones = 0\n",
    "\n",
    "    ### iterate over the review_points in the raw dataframe and make sure they are aligned with the chatgpt input data\n",
    "    final_df = []\n",
    "    for i in range(raw_data_df.shape[0]):\n",
    "\n",
    "        ## try to load the answer as a json object\n",
    "        try:\n",
    "            id = raw_data_df.iloc[i]['id']\n",
    "            chatgpt_row = chatgpt_response[chatgpt_response['custom_id']==id]\n",
    "            chatgpt_row = chatgpt_row.iloc[0].copy()\n",
    "            answer = chatgpt_row['response']['body']['choices'][0]['message']['content']\n",
    "            ## assert that the answer is  0 or 1\n",
    "            assert answer in ['0', '1']\n",
    "            if answer == '1':\n",
    "                ones += 1\n",
    "            row = raw_data_df.iloc[i].copy()\n",
    "            row [f'chatgpt_discard'] = answer\n",
    "            final_df.append(row)\n",
    "        except:\n",
    "            errors += 1\n",
    "            print(\"No valid JSON found.\")\n",
    "            continue\n",
    "    print(f\"Errors: {errors}\")\n",
    "    print(f\"Total ones: {ones}\")\n",
    "    final_df = pd.DataFrame(final_df)\n",
    "    final_df.to_csv(f\"/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/human_chatgpt_filtered_data.csv\", index=False)\n",
    "\n",
    "    print(f\"Final data size is {len (final_df[final_df['chatgpt_discard']=='0'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file for main chatgpt data is completed\n",
      "No valid JSON found.\n",
      "No valid JSON found.\n",
      "No valid JSON found.\n",
      "No valid JSON found.\n",
      "No valid JSON found.\n",
      "Errors: 5\n",
      "Total ones: 919\n",
      "Final data size is 11076\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "batch_data = json.load(open(f'main_data/main_chatgpt_data_unfiltered_batch_input_meta_data.json'))\n",
    "\n",
    "if client.batches.retrieve(batch_data['batch_id']).status == 'completed':\n",
    "    print(f\"Batch file for main chatgpt data is completed\")\n",
    "    retrive_batch_and_save_results(batch_data)\n",
    "    save_results(batch_data)\n",
    "else:\n",
    "    print(f\"Batch file for main chatgpt data is not completed yet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score,cohen_kappa_score, accuracy_score, recall_score\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(f'/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/archive/discarded_by_human.csv')\n",
    "print(len(data))\n",
    "data.rename(columns={'Discard': 'human_discard'}, inplace=True)\n",
    "data['human_discard'] = data['human_discard'].apply(lambda x: 1 if x == 1.0 else 0)\n",
    "data['chatgpt_discard'] = data['chatgpt_discard'].astype(int)\n",
    "data['human_discard'] = data['human_discard'].astype(int)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(data['human_discard'], data['chatgpt_discard'])}\")\n",
    "print(f\"Recall: {recall_score(data['human_discard'], data['chatgpt_discard'])}\")\n",
    "print(f\"F1 Score: {f1_score(data['human_discard'], data['chatgpt_discard'])}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(data['human_discard'], data['chatgpt_discard'])}\")\n",
    "\n",
    "cm = confusion_matrix(data['human_discard'], data['chatgpt_discard'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0', '1'])\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(f'/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/chatgpt_filtered_data_unlabeled.csv')\n",
    "print(len(data))\n",
    "\n",
    "aspects = [ 'actionability', 'grounding_specificity','verifiability', 'helpfulness']\n",
    "\n",
    "synthetic_data = {}\n",
    "for aspect in aspects:\n",
    "    d1 = pd.read_excel('/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/outputs/main_data_batch_1_results.xlsx', sheet_name=aspect)\n",
    "    d2 = pd.read_excel('/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/outputs/main_data_batch_2_results.xlsx', sheet_name=aspect)\n",
    "    synthetic_data[aspect] = pd.concat([d1, d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11076"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['chatgpt_discard'] == 0]\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose 500 samples from data that has review_points that are not in any of  the synthetic data\n",
    "synthetic_review_points = []\n",
    "for aspect in aspects:\n",
    "    synthetic_review_points += synthetic_data[aspect]['review_point'].tolist()\n",
    "\n",
    "data = data[~data['point'].isin(synthetic_review_points)]\n",
    "\n",
    "len(data)\n",
    "\n",
    "data = data.sample(500, random_state=42)\n",
    "\n",
    "data.to_csv(f'/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/main_data/500_points.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
